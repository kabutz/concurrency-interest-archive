From bbossola at gmail.com  Tue Sep  3 11:55:56 2013
From: bbossola at gmail.com (bruno bossola)
Date: Tue, 3 Sep 2013 16:55:56 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue - feedback?
Message-ID: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>

Hi all,

I am writing here following a suggestion by Ben Evans. I wanted to check
with you about an issue that my teams found on the JVM and that's very
frightening. I already started the discussion with the engineers of the
hotspot VM team but it looks like we need more awareness to solve this one
and I'd really appreciate some help and some push :)
It looks to me that this issue is affecting every JVM64 running on Linux64,
so imho it's quite important to be looked at.

*Executive summary
*The implementation of the concurrency primitive LockSupport.parkNanos(),
the function that controls most concurrency primitive on the JVM, is
flawed, and any NTP sync, or system time change, can potentially break it
with unexpected results across the board.

*What we need to do?
*This is an old issue, and the
bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was
declared private. I somehow managed to have the bug reopened to the
public, but it's still a  P4, that means that probably won't be fixed. I
think we need to push for a resolution ASAP, be sure that's in for JDK9,
make all the possible effort to make this fix for JDK8 or, at least, to
include it in a later patch release. In an ideal world it would be nice to
have a patch for JDK7. As far as I understand the hotspot engineering team
works based on priorities: being this qualified as P4 means it won't be
probably worked on (if you follow the breadcrumbs of bugs and fixes you can
go back to 2002!) They acknowledge the problem, it has been flagged to
management, but 1) it's low priority 2) it's too risky to fix for JDK8


*Why all this urgency?
*If a system time change happens then all the threads parked will hang,
with unpredictable/corrupted/useless results to the end user. Same applies
to Future, Queue, Executor, and (I guess) any other construct that it's
somehow related to concurrency. This is a big issue for us and for any near
time application: please think about trading and betting, where the JVM is
largely used, and  do not restrain yourself to the Java language: add Scala
and any other JVM-based language to the picture (JRuby, Jython...)

*Tech details**
*To be more clear about the issue, the extent of it and the concurrency
library, let me introduce this very simple program:

import java.util.concurrent.locks.LockSupport;

public class Main {

    public static void main(String[] args) {

        for (int i=100; i>0; i--) {
            System.out.println(i);
            LockSupport.parkNanos(1000L*1000L*1000L);
        }

        System.out.println("Done!");
    }
}

Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour
and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and
latest JDK8 beta running on various Ubuntu distros. It's not just a matter
of (old?) sleep() and wait() primitives, this issue it affects the whole
concurrency library.

To prove that this is fixable, I reimplemented the program above above
substituting  LockSupport.parkNanos()  with  a JNI call to
clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(

This is due to the fact  that the CPP code is calling the
pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
unfortunately is affected by settime()/settimeofday() calls (on Linux): for
that reason it cannot be used to measure nanoseconds delays, which is what
the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
CLOCK_REALTIME is not guaranteed to monotonically count as this is the
actual "system time": each time my system syncs time using a NTP server on
the net, the time might jump forward or backward. The correct call (again
on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)

The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is
infact clear, as it states "...setting the value of the CLOCK_REALTIME
clock via clock_settime() shall have no effect on threads that are blocked
waiting for a *relative* time service based upon this clock...": it
definitely states "relative".  Having a look at the hotspot
code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
it appears that the park() is using compute_abstime() (which uses
timeofday) and then waits on an absolute period: for that reason it's
influenced by the system clock change. *Very wrong*.

I will be happy to know what you think, and if you can help me to escalate
this issue I think that the all Java community will benefit from it.

Cheers,

    Bruno
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/f12b0e99/attachment.html>

From nathan.reynolds at oracle.com  Tue Sep  3 12:46:25 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 03 Sep 2013 09:46:25 -0700
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
Message-ID: <52261261.9090707@oracle.com>

Full disclosure: I work at Oracle and talk with HotSpot JVM engineers.

I have tried several times to influence the HotSpot engineers to act on 
some optimizations and bugs.  I have hit this prioritization wall as 
well.  Some times I am able to make a really good justification for the 
work and I actually get their attention and time!  Some times I am able 
to make a really good justification but the amount of work is tremendous 
and hence it takes a long time.  Many times, though, my ideas are left 
in the bug queue and are rarely addressed.  I definitely can understand 
your frustration.

For example, Intel's Ivy Bridge processor introduced a new instruction 
called RDRAND.  This supplies a cryptographically-secure random number.  
I filed an enhancement for the JVM team to intrinsify a few methods so 
that RDRAND is used instead of slower OS API calls.  Knowing that I 
needed justification to get the enhancement in a higher priority bucket, 
I looked for it.  It turns out that I couldn't find anything significant 
enough.  So, this instruction probably won't be used by the JVM any time 
soon.

My priorities are some times very different from the JVM team.  If I, an 
Oracle employee, have a hard time convincing the JVM team to work on all 
of my wacky ideas, I imagine it could be harder for those outside the 
company to convince the JVM team.  So, if you want to raise the priority 
of the bug, find better justification... which is kind of the point of 
your email.

If your enhancement is super important to you, then why not fix the bug 
yourself?  You could create a patch on top of OpenJDK and submit it.  If 
you also include a backport patch for JDK 7, then that's a bonus to 
you.  Patches require a lot less of the JVM team's time to incorporate 
the change and makes the threshold much lower for incorporation.  If 
fixing it is not worth your time, then I am not sure how you can justify 
it for the JVM team.

-Nathan

On 9/3/2013 8:55 AM, bruno bossola wrote:
> Hi all,
>
> I am writing here following a suggestion by Ben Evans. I wanted to 
> check with you about an issue that my teams found on the JVM and 
> that's very frightening. I already started the discussion with the 
> engineers of the hotspot VM team but it looks like we need more 
> awareness to solve this one and I'd really appreciate some help and 
> some push :)
> It looks to me that this issue is affecting every JVM64 running on 
> Linux64, so imho it's quite important to be looked at.
>
> *Executive summary
> *The implementation of the concurrency primitive 
> LockSupport.parkNanos(), the function that controls most concurrency 
> primitive on the JVM, is flawed, and any NTP sync, or system time 
> change, can potentially break it with unexpected results across the board.
>
> *What we need to do?
> *This is an old issue, and the bug 
> <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441> was 
> declared private. I somehow managed to have the bug reopened to the 
> public, but it's still a  P4, that means that probably won't be fixed. 
> I think we need to push for a resolution ASAP, be sure that's in for 
> JDK9, make all the possible effort to make this fix for JDK8 or, at 
> least, to include it in a later patch release. In an ideal world it 
> would be nice to have a patch for JDK7. As far as I understand the 
> hotspot engineering team works based on priorities: being this 
> qualified as P4 means it won't be probably worked on (if you follow 
> the breadcrumbs of bugs and fixes you can go back to 2002!) They 
> acknowledge the problem, it has been flagged to management, but 1) 
> it's low priority 2) it's too risky to fix for JDK8
>
>
> *Why all this urgency?
> *If a system time change happens then all the threads parked will 
> hang, with unpredictable/corrupted/useless results to the end user. 
> Same applies to Future, Queue, Executor, and (I guess) any other 
> construct that it's somehow related to concurrency. This is a big 
> issue for us and for any near time application: please think about 
> trading and betting, where the JVM is largely used, and  do not 
> restrain yourself to the Java language: add Scala and any other 
> JVM-based language to the picture (JRuby, Jython...)
>
> *Tech details**
> *To be more clear about the issue, the extent of it and the 
> concurrency library, let me introduce this very simple program:
>
> import java.util.concurrent.locks.LockSupport;
>
> public class Main {
>
>     public static void main(String[] args) {
>
>         for (int i=100; i>0; i--) {
>             System.out.println(i);
>             LockSupport.parkNanos(1000L*1000L*1000L);
>         }
>
>         System.out.println("Done!");
>     }
> }
>
> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one 
> hour and wait until the counter stops... magic!  I tested this on 
> JDK6, JDK7 and latest JDK8 beta running on various Ubuntu distros. 
> It's not just a matter of (old?) sleep() and wait() primitives, this 
> issue it affects the whole concurrency library.
>
> To prove that this is fixable, I reimplemented the program above above 
> substituting LockSupport.parkNanos() with  a JNI call to 
> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>
> This is due to the fact  that the CPP code is calling the 
> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) 
> which, unfortunately is affected by settime()/settimeofday() calls (on 
> Linux): for that reason it cannot be used to measure nanoseconds 
> delays, which is what the specification 
> <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29> 
> requires. CLOCK_REALTIME is not guaranteed to monotonically count as 
> this is the actual "system time": each time my system syncs time using 
> a NTP server on the net, the time might jump forward or backward. The 
> correct call (again on Linux)  would require to use CLOCK_MONOTONIC as 
> clock id, which are defined by POSIX specs since 2002. (or better 
> CLOCK_MONOTONIC_RAW)
>
> The POSIX spec 
> <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html> 
> is infact clear, as it states "...setting the value of the 
> CLOCK_REALTIME clock via clock_settime() shall have no effect on 
> threads that are blocked waiting for a *relative* time service based 
> upon this clock...": it definitely states "relative".  Having a look 
> at the hotspot code 
> <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>, 
> it appears that the park() is using compute_abstime() (which uses 
> timeofday) and then waits on an absolute period: for that reason it's 
> influenced by the system clock change. *Very wrong*.
>
> I will be happy to know what you think, and if you can help me to 
> escalate this issue I think that the all Java community will benefit 
> from it.
>
> Cheers,
>
>     Bruno
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/2188b1b7/attachment.html>

From sjr at sjrx.net  Tue Sep  3 12:48:41 2013
From: sjr at sjrx.net (=?windows-1252?Q?Steve_Ramage?=)
Date: Tue, 3 Sep 2013 09:48:41 -0700
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
Message-ID: <zarafa.522612e9.6074.5d5406ba37617b92@fermat.vc.shawcable.net>

Hello,

?

I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.

?

Thanks,

?

Steve Ramage
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/f0c9c4b7/attachment.html>

From aph at redhat.com  Tue Sep  3 13:03:41 2013
From: aph at redhat.com (Andrew Haley)
Date: Tue, 03 Sep 2013 18:03:41 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
Message-ID: <5226166D.1080408@redhat.com>

On 09/03/2013 04:55 PM, bruno bossola wrote:
> If a system time change happens then all the threads parked will hang, with unpredictable/corrupted/useless results to the end user.

Is that really true?  I thought that timers will wait for longer than you
expect, that's all.

Andrew.


From aph at redhat.com  Tue Sep  3 13:06:06 2013
From: aph at redhat.com (Andrew Haley)
Date: Tue, 03 Sep 2013 18:06:06 +0100
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <zarafa.522612e9.6074.5d5406ba37617b92@fermat.vc.shawcable.net>
References: <zarafa.522612e9.6074.5d5406ba37617b92@fermat.vc.shawcable.net>
Message-ID: <522616FE.30401@redhat.com>

On 09/03/2013 05:48 PM, Steve Ramage wrote:
> I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.

How can the Java program see this value in memory?  Do you call
a JNI function to do it?  If not, how?

Andrew.


From sjr at sjrx.net  Tue Sep  3 13:07:19 2013
From: sjr at sjrx.net (=?windows-1252?Q?Steve_Ramage?=)
Date: Tue, 3 Sep 2013 10:07:19 -0700
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <522616FE.30401@redhat.com>
References: <522616FE.30401@redhat.com>
Message-ID: <zarafa.52261747.610d.095c3ae540864166@fermat.vc.shawcable.net>

Yes a separate thread will invoke another JNI call to set it the flag.?
?
-----Original message-----
To:Steve Ramage <sjr at sjrx.net>; 
CC:concurrency-interest at cs.oswego.edu; 
From:Andrew Haley <aph at redhat.com>
Sent:Tue 03-09-2013 10:06
Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
On 09/03/2013 05:48 PM, Steve Ramage wrote:
> I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.

How can the Java program see this value in memory? ?Do you call
a JNI function to do it? ?If not, how?

Andrew.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/90e34a9f/attachment.html>

From aph at redhat.com  Tue Sep  3 13:09:36 2013
From: aph at redhat.com (Andrew Haley)
Date: Tue, 03 Sep 2013 18:09:36 +0100
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <zarafa.52261747.610d.095c3ae540864166@fermat.vc.shawcable.net>
References: <522616FE.30401@redhat.com>
	<zarafa.52261747.610d.095c3ae540864166@fermat.vc.shawcable.net>
Message-ID: <522617D0.7080400@redhat.com>

On 09/03/2013 06:07 PM, Steve Ramage wrote:
>  
> -----Original message-----
> To:Steve Ramage <sjr at sjrx.net>; 
> CC:concurrency-interest at cs.oswego.edu; 
> From:Andrew Haley <aph at redhat.com>
> Sent:Tue 03-09-2013 10:06
> Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
> On 09/03/2013 05:48 PM, Steve Ramage wrote:
>> I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.
> 
> How can the Java program see this value in memory?  Do you call
> a JNI function to do it?  If not, how?
> 
> Yes a separate thread will invoke another JNI call to set it the flag. 

I'm sorry, I can't cope with top-posting.  Please bear with me.

So, another thread sets a Java variable?  Then you should be fine as long
as that Java variable is volatile.

Andrew.


From sjr at sjrx.net  Tue Sep  3 13:14:22 2013
From: sjr at sjrx.net (=?windows-1252?Q?Steve_Ramage?=)
Date: Tue, 3 Sep 2013 10:14:22 -0700
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <522617D0.7080400@redhat.com>
References: <522617D0.7080400@redhat.com>
Message-ID: <zarafa.522618ee.6153.3dcf5ff325f190bf@fermat.vc.shawcable.net>

Another thread in Java invokes a call via JNI into C which will set a variable visible only in C.


?
-----Original message-----
To:Steve Ramage <sjr at sjrx.net>; 
CC:concurrency-interest at cs.oswego.edu; 
From:Andrew Haley <aph at redhat.com>
Sent:Tue 03-09-2013 10:09
Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
On 09/03/2013 06:07 PM, Steve Ramage wrote:
> ?
> -----Original message-----
> To:Steve Ramage <sjr at sjrx.net>; 
> CC:concurrency-interest at cs.oswego.edu; 
> From:Andrew Haley <aph at redhat.com>
> Sent:Tue 03-09-2013 10:06
> Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
> On 09/03/2013 05:48 PM, Steve Ramage wrote:
>> I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.
> 
> How can the Java program see this value in memory? ?Do you call
> a JNI function to do it? ?If not, how?
> 
> Yes a separate thread will invoke another JNI call to set it the flag. 

I'm sorry, I can't cope with top-posting. ?Please bear with me.

So, another thread sets a Java variable? ?Then you should be fine as long
as that Java variable is volatile.

Andrew.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/4639e85e/attachment.html>

From bbossola at gmail.com  Tue Sep  3 13:24:28 2013
From: bbossola at gmail.com (bruno bossola)
Date: Tue, 3 Sep 2013 18:24:28 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5226166D.1080408@redhat.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<5226166D.1080408@redhat.com>
Message-ID: <CAJU-cAKebgE+gYqyTN0=SEkXOpvCj8WwhNTF1Ri=tgw4Bjinow@mail.gmail.com>

>
> If a system time change happens then all the threads parked will hang,
>> with unpredictable/corrupted/useless results to the end user.
>>
>
> Is that really true?  I thought that timers will wait for longer than you
> expect, that's all.


>
Ehm... I guess it depends on the system you are developing: this is
probably not an issue if you are developing a blog :), I guess your users
can wait an hour or whatever time it's needed to get an update.

However, if you are working in banking and/or betting and/or any near time
system then it's really important that your "timers" are kind of precise.
But hey, maybe it's me being picky.

Cheers,

    Bruno


On Tue, Sep 3, 2013 at 6:03 PM, Andrew Haley <aph at redhat.com> wrote:

> On 09/03/2013 04:55 PM, bruno bossola wrote:
> > If a system time change happens then all the threads parked will hang,
> with unpredictable/corrupted/useless results to the end user.
>
> Is that really true?  I thought that timers will wait for longer than you
> expect, that's all.
>
> Andrew.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/1867b154/attachment.html>

From aph at redhat.com  Tue Sep  3 13:34:52 2013
From: aph at redhat.com (Andrew Haley)
Date: Tue, 03 Sep 2013 18:34:52 +0100
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <zarafa.522618ee.6153.3dcf5ff325f190bf@fermat.vc.shawcable.net>
References: <522617D0.7080400@redhat.com>
	<zarafa.522618ee.6153.3dcf5ff325f190bf@fermat.vc.shawcable.net>
Message-ID: <52261DBC.70709@redhat.com>

On 09/03/2013 06:14 PM, Steve Ramage wrote:
> Another thread in Java invokes a call via JNI into C which will set a variable visible only in C.

You're not making sense.  Is this a Java variable or a C variable?


> -----Original message-----
> To:Steve Ramage <sjr at sjrx.net>; 
> CC:concurrency-interest at cs.oswego.edu; 
> From:Andrew Haley <aph at redhat.com>
> Sent:Tue 03-09-2013 10:09
> Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
> On 09/03/2013 06:07 PM, Steve Ramage wrote:
>>  
>> -----Original message-----
>> To:Steve Ramage <sjr at sjrx.net>; 
>> CC:concurrency-interest at cs.oswego.edu; 
>> From:Andrew Haley <aph at redhat.com>
>> Sent:Tue 03-09-2013 10:06
>> Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
>> On 09/03/2013 05:48 PM, Steve Ramage wrote:
>>> I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.
>>
>> How can the Java program see this value in memory?  Do you call
>> a JNI function to do it?  If not, how?
>>
>> Yes a separate thread will invoke another JNI call to set it the flag. 
> 
> I'm sorry, I can't cope with top-posting.  Please bear with me.
> 
> So, another thread sets a Java variable?  Then you should be fine as long
> as that Java variable is volatile.
> 
> Andrew.
> 
> 
> 
> 


From sjr at sjrx.net  Tue Sep  3 13:35:34 2013
From: sjr at sjrx.net (=?windows-1252?Q?Steve_Ramage?=)
Date: Tue, 3 Sep 2013 10:35:34 -0700
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <52261DBC.70709@redhat.com>
References: <52261DBC.70709@redhat.com>
Message-ID: <zarafa.52261de6.61fc.0034ba9b4d5e2be2@fermat.vc.shawcable.net>

It is a C variable?
?
-----Original message-----
To:Steve Ramage <sjr at sjrx.net>; 
CC:concurrency-interest at cs.oswego.edu; 
From:Andrew Haley <aph at redhat.com>
Sent:Tue 03-09-2013 10:35
Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
On 09/03/2013 06:14 PM, Steve Ramage wrote:
> Another thread in Java invokes a call via JNI into C which will set a variable visible only in C.

You're not making sense. ?Is this a Java variable or a C variable?


> -----Original message-----
> To:Steve Ramage <sjr at sjrx.net>; 
> CC:concurrency-interest at cs.oswego.edu; 
> From:Andrew Haley <aph at redhat.com>
> Sent:Tue 03-09-2013 10:09
> Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
> On 09/03/2013 06:07 PM, Steve Ramage wrote:
>> ?
>> -----Original message-----
>> To:Steve Ramage <sjr at sjrx.net>; 
>> CC:concurrency-interest at cs.oswego.edu; 
>> From:Andrew Haley <aph at redhat.com>
>> Sent:Tue 03-09-2013 10:06
>> Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
>> On 09/03/2013 05:48 PM, Steve Ramage wrote:
>>> I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.
>>
>> How can the Java program see this value in memory? ?Do you call
>> a JNI function to do it? ?If not, how?
>>
>> Yes a separate thread will invoke another JNI call to set it the flag. 
> 
> I'm sorry, I can't cope with top-posting. ?Please bear with me.
> 
> So, another thread sets a Java variable? ?Then you should be fine as long
> as that Java variable is volatile.
> 
> Andrew.
> 
> 
> 
> 



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/8dd012ec/attachment-0001.html>

From aph at redhat.com  Tue Sep  3 13:47:17 2013
From: aph at redhat.com (Andrew Haley)
Date: Tue, 03 Sep 2013 18:47:17 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cAKebgE+gYqyTN0=SEkXOpvCj8WwhNTF1Ri=tgw4Bjinow@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<5226166D.1080408@redhat.com>
	<CAJU-cAKebgE+gYqyTN0=SEkXOpvCj8WwhNTF1Ri=tgw4Bjinow@mail.gmail.com>
Message-ID: <522620A5.8080508@redhat.com>

On 09/03/2013 06:24 PM, bruno bossola wrote:
>>
>> If a system time change happens then all the threads parked will hang,
>>> with unpredictable/corrupted/useless results to the end user.
>>>
>>
>> Is that really true?  I thought that timers will wait for longer than you
>> expect, that's all.
>>
> Ehm... I guess it depends on the system you are developing: this is
> probably not an issue if you are developing a blog :), I guess your users
> can wait an hour or whatever time it's needed to get an update.

Right, but timers waiting for an event will still be fine.

> However, if you are working in banking and/or betting and/or any near time
> system then it's really important that your "timers" are kind of precise.

I you are working in banking and/or betting and you change the
system time then you should not be allowed the root password.

> But hey, maybe it's me being picky.

Me too.

Andrew.


From ariel at weisberg.ws  Tue Sep  3 14:09:18 2013
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Tue, 03 Sep 2013 14:09:18 -0400
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <zarafa.522612e9.6074.5d5406ba37617b92@fermat.vc.shawcable.net>
References: <zarafa.522612e9.6074.5d5406ba37617b92@fermat.vc.shawcable.net>
Message-ID: <1378231758.19504.17447973.2F91F40E@webmail.messagingengine.com>

Hi,



My understanding is that once you have crossed the JNI boundary you are
running native code with the instructions generated by the compiler you
chose. Java doesn't munge any of the outputted assembly.



You don't have to do anything special beyond what you would normally do
to get your compiler to correctly publish between threads.



As Andrew points out it isn't clear what you are describing WRT to how
the memory location is going to be visible to each thread. If both
threads are running native code and the memory is native (not on the
Java heap) then when they check the flag the behavior is
straightforward and follows the rules for your
compiler/architecture/threading library. A pthread mutex will have the
fewest surprises WRT to reordering surrounding code although volatile
is sufficient for the value to eventually propagate.



If the memory is on the Java heap you can follow the rules of the JMM
to publish the value (volatile, AtomicBoolean etc.).



If it's in native memory and shared to Java via a direct byte buffer I
think you can still rely on the JMM to see the value propagate. To do
that you would synchronize on the same monitor from Java and C++.



Ariel



On Tue, Sep 3, 2013, at 12:48 PM, Steve Ramage wrote:

  Hello,

  I am hooking a C library into Java via JNI. The C library
  essentially processes a specialized task, and has been augmented to
  support a primitive form of interruption by setting a boolean value
  in memory to true, which is periodically checked. In Java land, one
  thread will begin processing the request, and later another thread
  might decide to interrupt it. I'm not sure of the best way to ensure
  that this change is visible to working thread. My question is once I
  am in C land, is my programs correctness under concurrency entirely
  dictated by what I would do in C (something with pthreads probably),
  or do I need to do something special to ensure that the other thread
  will see the interrupted flag once set.

  Thanks,

  Steve Ramage

_______________________________________________

Concurrency-interest mailing list

[1]Concurrency-interest at cs.oswego.edu

[2]http://cs.oswego.edu/mailman/listinfo/concurrency-interest

References

1. mailto:Concurrency-interest at cs.oswego.edu
2. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/186c6c74/attachment.html>

From sjr at sjrx.net  Tue Sep  3 14:26:29 2013
From: sjr at sjrx.net (=?windows-1252?Q?Steve_Ramage?=)
Date: Tue, 3 Sep 2013 11:26:29 -0700
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <1378231758.19504.17447973.2F91F40E@webmail.messagingengine.com>
References: <1378231758.19504.17447973.2F91F40E@webmail.messagingengine.com>
Message-ID: <zarafa.522629d5.63c0.2c511a4f57157096@fermat.vc.shawcable.net>

Thank you both of you, this answers my question. Just to sort of answer yours the variable will be only visible in native code, probably a static variable in C, all the threads will be invoked starting in Java, and then cross the boundary into native code when reading or writing this value.

?

Thanks again,

?

Steve Ramage

?

?

?

?


?
-----Original message-----
To:concurrency-interest at cs.oswego.edu; 
From:Ariel Weisberg <ariel at weisberg.ws>
Sent:Tue 03-09-2013 11:20
Subject:Re: [concurrency-interest] Memory Visibility Guarantees with JNI
Attachment:inline.txt
Hi,
?
My understanding is that once you have crossed the JNI boundary you are running native code with the instructions generated by the compiler you chose. Java doesn't munge any of the outputted assembly.
?
You don't have to do anything special beyond what you would normally do to get your compiler to correctly publish between threads.
?
As Andrew points out it isn't clear what you are describing WRT to how the memory location is going to be visible to each thread. If both threads are running native code and the memory is native (not on the Java heap) then when they check the flag the behavior is straightforward and follows the rules for your compiler/architecture/threading library. A pthread mutex will have the fewest surprises WRT to reordering surrounding code although volatile is sufficient for the value to eventually propagate.
?
If the memory is on the Java heap you can follow the rules of the JMM to publish the value (volatile, AtomicBoolean etc.).
?
If it's in native memory and shared to Java via a direct byte buffer I think you can still rely on the JMM to see the value propagate. To do that you would synchronize on the same monitor from Java and C++.
?
Ariel
?
On Tue, Sep 3, 2013, at 12:48 PM, Steve Ramage wrote:

Hello,

?

I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.

?

Thanks,

?

Steve Ramage
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/8b09d004/attachment.html>

From aph at redhat.com  Tue Sep  3 13:49:55 2013
From: aph at redhat.com (Andrew Haley)
Date: Tue, 03 Sep 2013 18:49:55 +0100
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <zarafa.52261de6.61fc.0034ba9b4d5e2be2@fermat.vc.shawcable.net>
References: <52261DBC.70709@redhat.com>
	<zarafa.52261de6.61fc.0034ba9b4d5e2be2@fermat.vc.shawcable.net>
Message-ID: <52262143.4040408@redhat.com>

On 09/03/2013 06:35 PM, Steve Ramage wrote:
> It is a C variable 

Ok, it must be volatile, and you may need to do a cache flush.  How
you do that depends on the system, but if you are using gcc you can
use __sync_synchronize().

An alternative would be to use a POSIX mutex around accesses.
This is more portable.

Andrew.


From hans.boehm at hp.com  Tue Sep  3 14:46:43 2013
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 3 Sep 2013 18:46:43 +0000
Subject: [concurrency-interest] Memory Visibility Guarantees with JNI
In-Reply-To: <zarafa.522629d5.63c0.2c511a4f57157096@fermat.vc.shawcable.net>
References: <1378231758.19504.17447973.2F91F40E@webmail.messagingengine.com>
	<zarafa.522629d5.63c0.2c511a4f57157096@fermat.vc.shawcable.net>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23D49890A@G9W0725.americas.hpqcorp.net>

As stated, you should follow the C rules if the variable is set and read in C code.  That means that you should do one of the following:


-          protect it with whatever kind of mutex your system supports.

-          if your compiler supports C11, declare it as atomic_int or atomic_flag.

If neither one of those works, declaring it as volatile is an incorrect hack that may work here, but is not sanctioned by the standard, and may break with a future compiler, even if it works now.  C "volatile" is not at all the same as Java "volatile".   C "volatile"s may be updated and accessed non-atomically e.g. a byte at a time, and they typically do not ensure reasonable memory ordering.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Steve Ramage
Sent: Tuesday, September 03, 2013 11:26 AM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Memory Visibility Guarantees with JNI


Thank you both of you, this answers my question. Just to sort of answer yours the variable will be only visible in native code, probably a static variable in C, all the threads will be invoked starting in Java, and then cross the boundary into native code when reading or writing this value.



Thanks again,



Steve Ramage










-----Original message-----
To: concurrency-interest at cs.oswego.edu;
From: Ariel Weisberg <ariel at weisberg.ws>
Sent: Tue 03-09-2013 11:20
Subject: Re: [concurrency-interest] Memory Visibility Guarantees with JNI
Attachment: inline.txt
Hi,

My understanding is that once you have crossed the JNI boundary you are running native code with the instructions generated by the compiler you chose. Java doesn't munge any of the outputted assembly.

You don't have to do anything special beyond what you would normally do to get your compiler to correctly publish between threads.

As Andrew points out it isn't clear what you are describing WRT to how the memory location is going to be visible to each thread. If both threads are running native code and the memory is native (not on the Java heap) then when they check the flag the behavior is straightforward and follows the rules for your compiler/architecture/threading library. A pthread mutex will have the fewest surprises WRT to reordering surrounding code although volatile is sufficient for the value to eventually propagate.

If the memory is on the Java heap you can follow the rules of the JMM to publish the value (volatile, AtomicBoolean etc.).

If it's in native memory and shared to Java via a direct byte buffer I think you can still rely on the JMM to see the value propagate. To do that you would synchronize on the same monitor from Java and C++.

Ariel

On Tue, Sep 3, 2013, at 12:48 PM, Steve Ramage wrote:

Hello,



I am hooking a C library into Java via JNI. The C library essentially processes a specialized task, and has been augmented to support a primitive form of interruption by setting a boolean value in memory to true, which is periodically checked. In Java land, one thread will begin processing the request, and later another thread might decide to interrupt it. I'm not sure of the best way to ensure that this change is visible to working thread. My question is once I am in C land, is my programs correctness under concurrency entirely dictated by what I would do in C (something with pthreads probably), or do I need to do something special to ensure that the other thread will see the interrupted flag once set.



Thanks,



Steve Ramage
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/3a2c5823/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue Sep  3 19:14:14 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 4 Sep 2013 09:14:14 +1000
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>

Hi Bruno,

I have raised the priority on 6900441 (which to my knowledge - and I created
it! - has never been a private bug).

A few notes on the "very frightening" aspect of this:

1. It doesn't affect "every JVM64 running on Linux64". A fix has been
introduced into a specific glibc version for the futex-wait code such that
it now responds to changes in the system time for absolute waits, where for
all the years previous it did not. The fix seems to have been applied in
late 2011 or early 2012 but I don't know the exact glibc version. There is
also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
will eventually make its way into 32-bit linux too.

2. The effects of this is not that "all the threads parked will hang, with
unpredictable/corrupted/useless"! The effects are very simple an quite
predictable. If the system time goes forward then timed-waits (Object.wait,
LockSupport.park) (which should be relative times) will return early as the
absolute-time that the relative time was converted to will be seen to have
been reached (Thread.sleep contains a guard against early returns). This is
not actually a problem as you can not distinguish this case from a "spurious
wakeup" which code is supposed to account for. If the time is changed
backwards then these timed-waits & sleeps will not timeout when expected as
the the for that is now further in the future, by the amount of the backward
time change. Hence small time changes as typically done via NTP are NOT a
problem. Timed-waits use timeouts as a heuristics for recovering when the
expected real event notification does not occur - so a delayed timeout does
not affect operation in a correctly functioning system. Early timeouts are
indistinguishable from spurious wakeups, which code has to account for, so
again not a problem for regular code. The only time a significant "hang"
will occur is with Thread.sleep and a large backward time shift - but there
is little real code that uses Thread.sleep in any critical way.

So there is an issue that needs to be addressed but the situation is nowhere
near as dire as you make out.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno
bossola
  Sent: Wednesday, 4 September 2013 1:56 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Outstanding concurrency JVM issue -
feedback?


  Hi all,

  I am writing here following a suggestion by Ben Evans. I wanted to check
with you about an issue that my teams found on the JVM and that's very
frightening. I already started the discussion with the engineers of the
hotspot VM team but it looks like we need more awareness to solve this one
and I'd really appreciate some help and some push :)

  It looks to me that this issue is affecting every JVM64 running on
Linux64, so imho it's quite important to be looked at.

  Executive summary
  The implementation of the concurrency primitive LockSupport.parkNanos(),
the function that controls most concurrency primitive on the JVM, is flawed,
and any NTP sync, or system time change, can potentially break it with
unexpected results across the board.

  What we need to do?
  This is an old issue, and the bug was declared private. I somehow managed
to have the bug reopened to the public, but it's still a  P4, that means
that probably won't be fixed. I think we need to push for a resolution ASAP,
be sure that's in for JDK9, make all the possible effort to make this fix
for JDK8 or, at least, to include it in a later patch release. In an ideal
world it would be nice to have a patch for JDK7. As far as I understand the
hotspot engineering team works based on priorities: being this qualified as
P4 means it won't be probably worked on (if you follow the breadcrumbs of
bugs and fixes you can go back to 2002!) They acknowledge the problem, it
has been flagged to management, but 1) it's low priority 2) it's too risky
to fix for JDK8


  Why all this urgency?
  If a system time change happens then all the threads parked will hang,
with unpredictable/corrupted/useless results to the end user. Same applies
to Future, Queue, Executor, and (I guess) any other construct that it's
somehow related to concurrency. This is a big issue for us and for any near
time application: please think about trading and betting, where the JVM is
largely used, and  do not restrain yourself to the Java language: add Scala
and any other JVM-based language to the picture (JRuby, Jython...)

  Tech details
  To be more clear about the issue, the extent of it and the concurrency
library, let me introduce this very simple program:

  import java.util.concurrent.locks.LockSupport;

  public class Main {

      public static void main(String[] args) {

          for (int i=100; i>0; i--) {
              System.out.println(i);
              LockSupport.parkNanos(1000L*1000L*1000L);
          }

          System.out.println("Done!");
      }
  }

  Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour
and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and
latest JDK8 beta running on various Ubuntu distros. It's not just a matter
of (old?) sleep() and wait() primitives, this issue it affects the whole
concurrency library.


  To prove that this is fixable, I reimplemented the program above above
substituting  LockSupport.parkNanos()  with  a JNI call to
clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(



  This is due to the fact  that the CPP code is calling the
pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
unfortunately is affected by settime()/settimeofday() calls (on Linux): for
that reason it cannot be used to measure nanoseconds delays, which is what
the specification requires. CLOCK_REALTIME is not guaranteed to
monotonically count as this is the actual "system time": each time my system
syncs time using a NTP server on the net, the time might jump forward or
backward. The correct call (again on Linux)  would require to use
CLOCK_MONOTONIC as clock id, which are defined by POSIX specs since 2002.
(or better CLOCK_MONOTONIC_RAW)

  The POSIX spec is infact clear, as it states "...setting the value of the
CLOCK_REALTIME clock via clock_settime() shall have no effect on threads
that are blocked waiting for a relative time service based upon this
clock...": it definitely states "relative".  Having a look at the hotspot
code, it appears that the park() is using compute_abstime() (which uses
timeofday) and then waits on an absolute period: for that reason it's
influenced by the system clock change. Very wrong.


  I will be happy to know what you think, and if you can help me to escalate
this issue I think that the all Java community will benefit from it.

  Cheers,


      Bruno
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/2407af6e/attachment.html>

From vitalyd at gmail.com  Tue Sep  3 19:47:37 2013
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 3 Sep 2013 19:47:37 -0400
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37FcxAOvkrS+HXpEGU4QO6ZnUgOQZj667z-KM3AjF442mQ@mail.gmail.com>

I believe it's also the case that NTP usually tries to smooth out
adjustments whereby it'll slowly/gradually move the clock to be inline
rather than do abrupt jumps.  This would imply that the more problematic
backward jumps shouldn't actually cause a much longer than expected wait.
So the only "real" case of significant problems due to this is root
changing the clock, but as others have said, that's an operational error.

Sent from my phone
On Sep 3, 2013 7:20 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> **
> Hi Bruno,
>
> I have raised the priority on 6900441 (which to my knowledge - and I
> created it! - has never been a private bug).
>
> A few notes on the "very frightening" aspect of this:
>
> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
> introduced into a specific glibc version for the futex-wait code such that
> it now responds to changes in the system time for absolute waits, where for
> all the years previous it did not. The fix seems to have been applied in
> late 2011 or early 2012 but I don't know the exact glibc version. There is
> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
> will eventually make its way into 32-bit linux too.
>
> 2. The effects of this is not that "all the threads parked will hang,
> with unpredictable/corrupted/useless"! The effects are very simple an
> quite predictable. If the system time goes forward then timed-waits
> (Object.wait, LockSupport.park) (which should be relative times) will
> return early as the absolute-time that the relative time was converted to
> will be seen to have been reached (Thread.sleep contains a guard against
> early returns). This is not actually a problem as you can not distinguish
> this case from a "spurious wakeup" which code is supposed to account
> for. If the time is changed backwards then these timed-waits & sleeps will
> not timeout when expected as the the for that is now further in the future,
> by the amount of the backward time change. Hence small time changes as
> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
> heuristics for recovering when the expected real event notification does
> not occur - so a delayed timeout does not affect operation in a correctly
> functioning system. Early timeouts are indistinguishable from spurious
> wakeups, which code has to account for, so again not a problem for regular
> code. The only time a significant "hang" will occur is with Thread.sleep
> and a large backward time shift - but there is little real code that uses
> Thread.sleep in any critical way.
>
> So there is an issue that needs to be addressed but the situation is
> nowhere near as dire as you make out.
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
> *Sent:* Wednesday, 4 September 2013 1:56 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
> feedback?
>
>  Hi all,
>
> I am writing here following a suggestion by Ben Evans. I wanted to check
> with you about an issue that my teams found on the JVM and that's very
> frightening. I already started the discussion with the engineers of the
> hotspot VM team but it looks like we need more awareness to solve this one
> and I'd really appreciate some help and some push :)
> It looks to me that this issue is affecting every JVM64 running on
> Linux64, so imho it's quite important to be looked at.
>
> *Executive summary
> *The implementation of the concurrency primitive LockSupport.parkNanos(),
> the function that controls most concurrency primitive on the JVM, is
> flawed, and any NTP sync, or system time change, can potentially break it
> with unexpected results across the board.
>
> *What we need to do?
> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
> public, but it's still a  P4, that means that probably won't be fixed. I
> think we need to push for a resolution ASAP, be sure that's in for JDK9,
> make all the possible effort to make this fix for JDK8 or, at least, to
> include it in a later patch release. In an ideal world it would be nice to
> have a patch for JDK7. As far as I understand the hotspot engineering team
> works based on priorities: being this qualified as P4 means it won't be
> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
> go back to 2002!) They acknowledge the problem, it has been flagged to
> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>
>
> *Why all this urgency?
> *If a system time change happens then all the threads parked will hang,
> with unpredictable/corrupted/useless results to the end user. Same applies
> to Future, Queue, Executor, and (I guess) any other construct that it's
> somehow related to concurrency. This is a big issue for us and for any near
> time application: please think about trading and betting, where the JVM is
> largely used, and  do not restrain yourself to the Java language: add Scala
> and any other JVM-based language to the picture (JRuby, Jython...)
>
> *Tech details**
> *To be more clear about the issue, the extent of it and the concurrency
> library, let me introduce this very simple program:
>
> import java.util.concurrent.locks.LockSupport;
>
> public class Main {
>
>     public static void main(String[] args) {
>
>         for (int i=100; i>0; i--) {
>             System.out.println(i);
>             LockSupport.parkNanos(1000L*1000L*1000L);
>         }
>
>         System.out.println("Done!");
>     }
> }
>
> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour
> and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and
> latest JDK8 beta running on various Ubuntu distros. It's not just a matter
> of (old?) sleep() and wait() primitives, this issue it affects the whole
> concurrency library.
>
> To prove that this is fixable, I reimplemented the program above above
> substituting  LockSupport.parkNanos()  with  a JNI call to
> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>
> This is due to the fact  that the CPP code is calling the
> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
> unfortunately is affected by settime()/settimeofday() calls (on Linux): for
> that reason it cannot be used to measure nanoseconds delays, which is what
> the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
> actual "system time": each time my system syncs time using a NTP server on
> the net, the time might jump forward or backward. The correct call (again
> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>
> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
> clock via clock_settime() shall have no effect on threads that are blocked
> waiting for a *relative* time service based upon this clock...": it
> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
> it appears that the park() is using compute_abstime() (which uses
> timeofday) and then waits on an absolute period: for that reason it's
> influenced by the system clock change. *Very wrong*.
>
> I will be happy to know what you think, and if you can help me to escalate
> this issue I think that the all Java community will benefit from it.
>
> Cheers,
>
>     Bruno
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/7656ccbe/attachment-0001.html>

From bbossola at gmail.com  Tue Sep  3 21:14:15 2013
From: bbossola at gmail.com (bruno bossola)
Date: Wed, 4 Sep 2013 02:14:15 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
Message-ID: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>

Hi David,

thanks for following up.



> I have raised the priority on 6900441
>


Thanks, but it looks still like a P4:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
See also the attached snapshot, just in case it changes :)

[image: Inline image 2]

[...] which to my knowledge [...] has never been a private bug
>

It was not accessible using bugs.sun.com, this was translated to private. I
also received the same info indirectly from the 7u lead:
"I'm not sure why 6900441 isn't public. (I'll follow up with owner of
bugs.sun.com)", I guess you can check with him.


It doesn't affect "every JVM64 running on Linux64".  A fix has been
> introduced into a specific glibc version...
>

...and apparently did not make it. I was able to reproduce this even with
the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13
+ some random Debian. I did not have a JDK5, so I cannot say, but on JDK4
everything works (that's the reason why I call it a regression). (ah, if
you look at the bug, it lists also JDK5, so I think we are pretty much
covered here).
If you still have doubts tough, please have also a look on stackoverflow to
see how it was reproduced consistently on probably every 64bitJVM over
64bitLinux in the world.


The effects of this is not that "all the threads parked will hang, with
> unpredictable/corrupted/useless"! The effects are very simple an quite
> predictable... [deletia]s.



We have very different views, and I find quite difficult to accept yours.
You are confusing my sample program which contains a single thread in a for
loop with any other complex multi-threading concurrent system written in
Java. For example, if you ever worked in a bank you surely know what I
mean. You are comparing some random sleep() put into a program by some
newbie, with the complex ecosystem of a concurrent platform written to
manage trading information on very fast market. In that condition, I am
sorry, statements such "...delayed timeout does not affect operation in a
correctly functioning system..." and "...small time changes [...] are not a
problem" are really not applicable. Let your system place an order three
seconds late and your are out of the door so quickly you cannot even
realize it.

But let's not limit ourselves to banks: how do you think your previous
statements stands in these scenarios?
- air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/>
(what
about a few seconds delay in control when fying planes?)
- city traffic control
systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
if just for a couple of seconds all traffic lights become green?)

Not good enough.


...small time changes as typically done via NTP



NTP is only one of the possible sources of this problem. The root of it is
that the JVM is counting nanoseconds delays using absolute values based on
a wallclock: I do not think it's that smart.


So there is an issue that needs to be addressed but the situation is
> nowhere near as dire as you make out
>


Let's try to put this in perspective, shall we? In case the clock run
backwards LockSupport.park() will be waiting for the nanoseconds requested
plus the amount of seconds/minute/hours/days requested to compensate. Now,
this primitive is used by almost *every* concurrency construct available on
the platform, such as AbstractQueuedSynchronizer (and subclasses),
ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
subclasses), Executors, FutureTask, .... (too long to list them all, but I
think we have the picture) and also low levels synchronization primitives
of the language itself, so Object::wait(:long) and the related sychronized
blocks.

I think it's pretty dire.


Cheers,

    Bruno





On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> Hi Bruno,
>
> I have raised the priority on 6900441 (which to my knowledge - and I
> created it! - has never been a private bug).
>
> A few notes on the "very frightening" aspect of this:
>
> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
> introduced into a specific glibc version for the futex-wait code such that
> it now responds to changes in the system time for absolute waits, where for
> all the years previous it did not. The fix seems to have been applied in
> late 2011 or early 2012 but I don't know the exact glibc version. There is
> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
> will eventually make its way into 32-bit linux too.
>
> 2. The effects of this is not that "all the threads parked will hang,
> with unpredictable/corrupted/useless"! The effects are very simple an
> quite predictable. If the system time goes forward then timed-waits
> (Object.wait, LockSupport.park) (which should be relative times) will
> return early as the absolute-time that the relative time was converted to
> will be seen to have been reached (Thread.sleep contains a guard against
> early returns). This is not actually a problem as you can not distinguish
> this case from a "spurious wakeup" which code is supposed to account
> for. If the time is changed backwards then these timed-waits & sleeps will
> not timeout when expected as the the for that is now further in the future,
> by the amount of the backward time change. Hence small time changes as
> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
> heuristics for recovering when the expected real event notification does
> not occur - so a delayed timeout does not affect operation in a correctly
> functioning system. Early timeouts are indistinguishable from spurious
> wakeups, which code has to account for, so again not a problem for regular
> code. The only time a significant "hang" will occur is with Thread.sleep
> and a large backward time shift - but there is little real code that uses
> Thread.sleep in any critical way.
>
> So there is an issue that needs to be addressed but the situation is
> nowhere near as dire as you make out.
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
> *Sent:* Wednesday, 4 September 2013 1:56 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
> feedback?
>
>  Hi all,
>
> I am writing here following a suggestion by Ben Evans. I wanted to check
> with you about an issue that my teams found on the JVM and that's very
> frightening. I already started the discussion with the engineers of the
> hotspot VM team but it looks like we need more awareness to solve this one
> and I'd really appreciate some help and some push :)
> It looks to me that this issue is affecting every JVM64 running on
> Linux64, so imho it's quite important to be looked at.
>
> *Executive summary
> *The implementation of the concurrency primitive LockSupport.parkNanos(),
> the function that controls most concurrency primitive on the JVM, is
> flawed, and any NTP sync, or system time change, can potentially break it
> with unexpected results across the board.
>
> *What we need to do?
> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
> public, but it's still a  P4, that means that probably won't be fixed. I
> think we need to push for a resolution ASAP, be sure that's in for JDK9,
> make all the possible effort to make this fix for JDK8 or, at least, to
> include it in a later patch release. In an ideal world it would be nice to
> have a patch for JDK7. As far as I understand the hotspot engineering team
> works based on priorities: being this qualified as P4 means it won't be
> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
> go back to 2002!) They acknowledge the problem, it has been flagged to
> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>
>
> *Why all this urgency?
> *If a system time change happens then all the threads parked will hang,
> with unpredictable/corrupted/useless results to the end user. Same applies
> to Future, Queue, Executor, and (I guess) any other construct that it's
> somehow related to concurrency. This is a big issue for us and for any near
> time application: please think about trading and betting, where the JVM is
> largely used, and  do not restrain yourself to the Java language: add Scala
> and any other JVM-based language to the picture (JRuby, Jython...)
>
> *Tech details**
> *To be more clear about the issue, the extent of it and the concurrency
> library, let me introduce this very simple program:
>
> import java.util.concurrent.locks.LockSupport;
>
> public class Main {
>
>     public static void main(String[] args) {
>
>         for (int i=100; i>0; i--) {
>             System.out.println(i);
>             LockSupport.parkNanos(1000L*1000L*1000L);
>         }
>
>         System.out.println("Done!");
>     }
> }
>
> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour
> and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and
> latest JDK8 beta running on various Ubuntu distros. It's not just a matter
> of (old?) sleep() and wait() primitives, this issue it affects the whole
> concurrency library.
>
> To prove that this is fixable, I reimplemented the program above above
> substituting  LockSupport.parkNanos()  with  a JNI call to
> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>
> This is due to the fact  that the CPP code is calling the
> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
> unfortunately is affected by settime()/settimeofday() calls (on Linux): for
> that reason it cannot be used to measure nanoseconds delays, which is what
> the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
> actual "system time": each time my system syncs time using a NTP server on
> the net, the time might jump forward or backward. The correct call (again
> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>
> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
> clock via clock_settime() shall have no effect on threads that are blocked
> waiting for a *relative* time service based upon this clock...": it
> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
> it appears that the park() is using compute_abstime() (which uses
> timeofday) and then waits on an absolute period: for that reason it's
> influenced by the system clock change. *Very wrong*.
>
> I will be happy to know what you think, and if you can help me to escalate
> this issue I think that the all Java community will benefit from it.
>
> Cheers,
>
>     Bruno
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/2776963d/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 67892 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/2776963d/attachment-0001.png>

From davidcholmes at aapt.net.au  Tue Sep  3 21:32:45 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 4 Sep 2013 11:32:45 +1000
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>

Bruno,

bugs.sun.com is not a live reflection of the bug database but gets updated
periodically (every 12 hours I think).

The issue arises on certain 64-bit linux kernel/glibc versions. If you have
an older version this does not impact you.

As for the rest, show me real code in such systems that rely on sleep for
correctness or performance/timeliness and I will show you broken code. We
are not talking about real-time systems here. park(nanos)/wait(millis) will
only be affected by the backward time change if the real notification they
are waiting for does not happen. Timeouts with these APIs are heuristics,
they are defensive programming to cover the case "what if the notification
I'm waiting for does not come". The code that would be affected by this
issue is a very small % of the code that uses the API.

If this was as dire as you make out do you not think that this issue would
have been raised far more than it has? This issue does need addressing
because the number of affected systems will grow as these newer linux
systems are adopted, but prudent developers/companies trial platform
upgrades to check for these kinds of issues before swicthing to them in
production environments.

Regards,
David
  -----Original Message-----
  From: bruno bossola [mailto:bbossola at gmail.com]
  Sent: Wednesday, 4 September 2013 11:14 AM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Outstanding concurrency JVM issue -
feedback?


  Hi David,


  thanks for following up.



    I have raised the priority on 6900441


  Thanks, but it looks still like a P4:
  http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
  See also the attached snapshot, just in case it changes :)






    [...] which to my knowledge [...] has never been a private bug

  It was not accessible using bugs.sun.com, this was translated to private.
I also received the same info indirectly from the 7u lead:
  "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
bugs.sun.com)", I guess you can check with him.




    It doesn't affect "every JVM64 running on Linux64".  A fix has been
introduced into a specific glibc version...

  ...and apparently did not make it. I was able to reproduce this even with
the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13 +
some random Debian. I did not have a JDK5, so I cannot say, but on JDK4
everything works (that's the reason why I call it a regression). (ah, if you
look at the bug, it lists also JDK5, so I think we are pretty much covered
here).
  If you still have doubts tough, please have also a look on stackoverflow
to see how it was reproduced consistently on probably every 64bitJVM over
64bitLinux in the world.




    The effects of this is not that "all the threads parked will hang, with
unpredictable/corrupted/useless"! The effects are very simple an quite
predictable... [deletia]s.

  We have very different views, and I find quite difficult to accept yours.
You are confusing my sample program which contains a single thread in a for
loop with any other complex multi-threading concurrent system written in
Java. For example, if you ever worked in a bank you surely know what I mean.
You are comparing some random sleep() put into a program by some newbie,
with the complex ecosystem of a concurrent platform written to manage
trading information on very fast market. In that condition, I am sorry,
statements such "...delayed timeout does not affect operation in a correctly
functioning system..." and "...small time changes [...] are not a problem"
are really not applicable. Let your system place an order three seconds late
and your are out of the door so quickly you cannot even realize it.


  But let's not limit ourselves to banks: how do you think your previous
statements stands in these scenarios?
  - air control systems (what about a few seconds delay in control when
fying planes?)
  - city traffic control systems (what if just for a couple of seconds all
traffic lights become green?)



  Not good enough.




    ...small time changes as typically done via NTP

  NTP is only one of the possible sources of this problem. The root of it is
that the JVM is counting nanoseconds delays using absolute values based on a
wallclock: I do not think it's that smart.




    So there is an issue that needs to be addressed but the situation is
nowhere near as dire as you make out


  Let's try to put this in perspective, shall we? In case the clock run
backwards LockSupport.park() will be waiting for the nanoseconds requested
plus the amount of seconds/minute/hours/days requested to compensate. Now,
this primitive is used by almost *every* concurrency construct available on
the platform, such as AbstractQueuedSynchronizer (and subclasses),
ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
subclasses), Executors, FutureTask, .... (too long to list them all, but I
think we have the picture) and also low levels synchronization primitives of
the language itself, so Object::wait(:long) and the related sychronized
blocks.


  I think it's pretty dire.




  Cheers,


      Bruno









  On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:

    Hi Bruno,

    I have raised the priority on 6900441 (which to my knowledge - and I
created it! - has never been a private bug).

    A few notes on the "very frightening" aspect of this:

    1. It doesn't affect "every JVM64 running on Linux64". A fix has been
introduced into a specific glibc version for the futex-wait code such that
it now responds to changes in the system time for absolute waits, where for
all the years previous it did not. The fix seems to have been applied in
late 2011 or early 2012 but I don't know the exact glibc version. There is
also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
will eventually make its way into 32-bit linux too.

    2. The effects of this is not that "all the threads parked will hang,
with unpredictable/corrupted/useless"! The effects are very simple an quite
predictable. If the system time goes forward then timed-waits (Object.wait,
LockSupport.park) (which should be relative times) will return early as the
absolute-time that the relative time was converted to will be seen to have
been reached (Thread.sleep contains a guard against early returns). This is
not actually a problem as you can not distinguish this case from a "spurious
wakeup" which code is supposed to account for. If the time is changed
backwards then these timed-waits & sleeps will not timeout when expected as
the the for that is now further in the future, by the amount of the backward
time change. Hence small time changes as typically done via NTP are NOT a
problem. Timed-waits use timeouts as a heuristics for recovering when the
expected real event notification does not occur - so a delayed timeout does
not affect operation in a correctly functioning system. Early timeouts are
indistinguishable from spurious wakeups, which code has to account for, so
again not a problem for regular code. The only time a significant "hang"
will occur is with Thread.sleep and a large backward time shift - but there
is little real code that uses Thread.sleep in any critical way.

    So there is an issue that needs to be addressed but the situation is
nowhere near as dire as you make out.

    David Holmes
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno
bossola
      Sent: Wednesday, 4 September 2013 1:56 AM
      To: concurrency-interest at cs.oswego.edu
      Subject: [concurrency-interest] Outstanding concurrency JVM issue -
feedback?


      Hi all,

      I am writing here following a suggestion by Ben Evans. I wanted to
check with you about an issue that my teams found on the JVM and that's very
frightening. I already started the discussion with the engineers of the
hotspot VM team but it looks like we need more awareness to solve this one
and I'd really appreciate some help and some push :)

      It looks to me that this issue is affecting every JVM64 running on
Linux64, so imho it's quite important to be looked at.

      Executive summary
      The implementation of the concurrency primitive
LockSupport.parkNanos(), the function that controls most concurrency
primitive on the JVM, is flawed, and any NTP sync, or system time change,
can potentially break it with unexpected results across the board.

      What we need to do?
      This is an old issue, and the bug was declared private. I somehow
managed to have the bug reopened to the public, but it's still a  P4, that
means that probably won't be fixed. I think we need to push for a resolution
ASAP, be sure that's in for JDK9, make all the possible effort to make this
fix for JDK8 or, at least, to include it in a later patch release. In an
ideal world it would be nice to have a patch for JDK7. As far as I
understand the hotspot engineering team works based on priorities: being
this qualified as P4 means it won't be probably worked on (if you follow the
breadcrumbs of bugs and fixes you can go back to 2002!) They acknowledge the
problem, it has been flagged to management, but 1) it's low priority 2) it's
too risky to fix for JDK8


      Why all this urgency?
      If a system time change happens then all the threads parked will hang,
with unpredictable/corrupted/useless results to the end user. Same applies
to Future, Queue, Executor, and (I guess) any other construct that it's
somehow related to concurrency. This is a big issue for us and for any near
time application: please think about trading and betting, where the JVM is
largely used, and  do not restrain yourself to the Java language: add Scala
and any other JVM-based language to the picture (JRuby, Jython...)

      Tech details
      To be more clear about the issue, the extent of it and the concurrency
library, let me introduce this very simple program:

      import java.util.concurrent.locks.LockSupport;

      public class Main {

          public static void main(String[] args) {

              for (int i=100; i>0; i--) {
                  System.out.println(i);
                  LockSupport.parkNanos(1000L*1000L*1000L);
              }

              System.out.println("Done!");
          }
      }

      Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
hour and wait until the counter stops... magic!  I tested this on JDK6, JDK7
and latest JDK8 beta running on various Ubuntu distros. It's not just a
matter of (old?) sleep() and wait() primitives, this issue it affects the
whole concurrency library.


      To prove that this is fixable, I reimplemented the program above above
substituting  LockSupport.parkNanos()  with  a JNI call to
clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(



      This is due to the fact  that the CPP code is calling the
pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
unfortunately is affected by settime()/settimeofday() calls (on Linux): for
that reason it cannot be used to measure nanoseconds delays, which is what
the specification requires. CLOCK_REALTIME is not guaranteed to
monotonically count as this is the actual "system time": each time my system
syncs time using a NTP server on the net, the time might jump forward or
backward. The correct call (again on Linux)  would require to use
CLOCK_MONOTONIC as clock id, which are defined by POSIX specs since 2002.
(or better CLOCK_MONOTONIC_RAW)

      The POSIX spec is infact clear, as it states "...setting the value of
the CLOCK_REALTIME clock via clock_settime() shall have no effect on threads
that are blocked waiting for a relative time service based upon this
clock...": it definitely states "relative".  Having a look at the hotspot
code, it appears that the park() is using compute_abstime() (which uses
timeofday) and then waits on an absolute period: for that reason it's
influenced by the system clock change. Very wrong.


      I will be happy to know what you think, and if you can help me to
escalate this issue I think that the all Java community will benefit from
it.

      Cheers,


          Bruno


  No virus found in this message.
  Checked by AVG - www.avg.com
  Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date: 09/03/13
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/0f8a0132/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 67892 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/0f8a0132/attachment-0001.png>

From jean.morissette at gmail.com  Tue Sep  3 21:52:28 2013
From: jean.morissette at gmail.com (Jean Morissette)
Date: Tue, 3 Sep 2013 21:52:28 -0400
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
	<CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
Message-ID: <CAEGsZX1DKY2OKvOvF+fEg-9Q8Qyi1TFoCsDwKibhmRyNZ44PBg@mail.gmail.com>

If you are looking for predictable performance, you may be interested by
Real Time JVM, such WebSphere Real Time [1], PERC [2], JamaicaVM [3].

Regards,
Jean

[1] http://www-03.ibm.com/software/products/us/en/real-time/
[2] http://www.atego.com/products/aonix-perc/
[3] http://www.aicas.com/jamaica.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130903/d50a1844/attachment.html>

From ash2kk at gmail.com  Wed Sep  4 00:56:13 2013
From: ash2kk at gmail.com (Mikhail Mazursky)
Date: Wed, 4 Sep 2013 10:56:13 +0600
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAHjP37FcxAOvkrS+HXpEGU4QO6ZnUgOQZj667z-KM3AjF442mQ@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
	<CAHjP37FcxAOvkrS+HXpEGU4QO6ZnUgOQZj667z-KM3AjF442mQ@mail.gmail.com>
Message-ID: <CAGg1-iOAbBavWoh=5abo0+ffdPhjvJNYF9C_34p9MTQT9Sb22g@mail.gmail.com>

>From my own experience time can drift A LOT in virtualized environments.
Especially when the CPU is overloaded (even in another VM on the same
physical server). For example (and this is only a single case, but there
were many others), few days ago we discovered that one of our servers was
using time in the past - more than 1 hour lag. nptd was running there but
it didn't help for some reason.
- this is significant drift that affects JVM itself;
- such drift makes distributed systems misbehave in a very odd ways (we use
Cassandra and request timeouts happen when time drifts. But this is
probably not its fault). But this last point is probably unrelevant here.

Just wanted to add more context information.

2013/9/4 Vitaly Davidovich <vitalyd at gmail.com>

> I believe it's also the case that NTP usually tries to smooth out
> adjustments whereby it'll slowly/gradually move the clock to be inline
> rather than do abrupt jumps.  This would imply that the more problematic
> backward jumps shouldn't actually cause a much longer than expected wait.
> So the only "real" case of significant problems due to this is root
> changing the clock, but as others have said, that's an operational error.
>
> Sent from my phone
> On Sep 3, 2013 7:20 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:
>
>> **
>> Hi Bruno,
>>
>> I have raised the priority on 6900441 (which to my knowledge - and I
>> created it! - has never been a private bug).
>>
>> A few notes on the "very frightening" aspect of this:
>>
>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>> introduced into a specific glibc version for the futex-wait code such that
>> it now responds to changes in the system time for absolute waits, where for
>> all the years previous it did not. The fix seems to have been applied in
>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>> will eventually make its way into 32-bit linux too.
>>
>> 2. The effects of this is not that "all the threads parked will hang,
>> with unpredictable/corrupted/useless"! The effects are very simple an
>> quite predictable. If the system time goes forward then timed-waits
>> (Object.wait, LockSupport.park) (which should be relative times) will
>> return early as the absolute-time that the relative time was converted to
>> will be seen to have been reached (Thread.sleep contains a guard against
>> early returns). This is not actually a problem as you can not distinguish
>> this case from a "spurious wakeup" which code is supposed to account
>> for. If the time is changed backwards then these timed-waits & sleeps will
>> not timeout when expected as the the for that is now further in the future,
>> by the amount of the backward time change. Hence small time changes as
>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>> heuristics for recovering when the expected real event notification does
>> not occur - so a delayed timeout does not affect operation in a correctly
>> functioning system. Early timeouts are indistinguishable from spurious
>> wakeups, which code has to account for, so again not a problem for regular
>> code. The only time a significant "hang" will occur is with Thread.sleep
>> and a large backward time shift - but there is little real code that uses
>> Thread.sleep in any critical way.
>>
>> So there is an issue that needs to be addressed but the situation is
>> nowhere near as dire as you make out.
>>
>> David Holmes
>>
>> -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>> *To:* concurrency-interest at cs.oswego.edu
>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>> feedback?
>>
>>  Hi all,
>>
>> I am writing here following a suggestion by Ben Evans. I wanted to check
>> with you about an issue that my teams found on the JVM and that's very
>> frightening. I already started the discussion with the engineers of the
>> hotspot VM team but it looks like we need more awareness to solve this one
>> and I'd really appreciate some help and some push :)
>> It looks to me that this issue is affecting every JVM64 running on
>> Linux64, so imho it's quite important to be looked at.
>>
>> *Executive summary
>> *The implementation of the concurrency primitive LockSupport.parkNanos(),
>> the function that controls most concurrency primitive on the JVM, is
>> flawed, and any NTP sync, or system time change, can potentially break it
>> with unexpected results across the board.
>>
>> *What we need to do?
>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>> public, but it's still a  P4, that means that probably won't be fixed. I
>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>> make all the possible effort to make this fix for JDK8 or, at least, to
>> include it in a later patch release. In an ideal world it would be nice to
>> have a patch for JDK7. As far as I understand the hotspot engineering team
>> works based on priorities: being this qualified as P4 means it won't be
>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>> go back to 2002!) They acknowledge the problem, it has been flagged to
>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>
>>
>> *Why all this urgency?
>> *If a system time change happens then all the threads parked will hang,
>> with unpredictable/corrupted/useless results to the end user. Same applies
>> to Future, Queue, Executor, and (I guess) any other construct that it's
>> somehow related to concurrency. This is a big issue for us and for any near
>> time application: please think about trading and betting, where the JVM is
>> largely used, and  do not restrain yourself to the Java language: add Scala
>> and any other JVM-based language to the picture (JRuby, Jython...)
>>
>> *Tech details**
>> *To be more clear about the issue, the extent of it and the concurrency
>> library, let me introduce this very simple program:
>>
>> import java.util.concurrent.locks.LockSupport;
>>
>> public class Main {
>>
>>     public static void main(String[] args) {
>>
>>         for (int i=100; i>0; i--) {
>>             System.out.println(i);
>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>         }
>>
>>         System.out.println("Done!");
>>     }
>> }
>>
>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour
>> and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and
>> latest JDK8 beta running on various Ubuntu distros. It's not just a matter
>> of (old?) sleep() and wait() primitives, this issue it affects the whole
>> concurrency library.
>>
>> To prove that this is fixable, I reimplemented the program above above
>> substituting  LockSupport.parkNanos()  with  a JNI call to
>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>
>> This is due to the fact  that the CPP code is calling the
>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
>> unfortunately is affected by settime()/settimeofday() calls (on Linux): for
>> that reason it cannot be used to measure nanoseconds delays, which is what
>> the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
>> actual "system time": each time my system syncs time using a NTP server on
>> the net, the time might jump forward or backward. The correct call (again
>> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
>> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>
>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>> clock via clock_settime() shall have no effect on threads that are blocked
>> waiting for a *relative* time service based upon this clock...": it
>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>> it appears that the park() is using compute_abstime() (which uses
>> timeofday) and then waits on an absolute period: for that reason it's
>> influenced by the system clock change. *Very wrong*.
>>
>> I will be happy to know what you think, and if you can help me to
>> escalate this issue I think that the all Java community will benefit from
>> it.
>>
>> Cheers,
>>
>>     Bruno
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/57fc9268/attachment.html>

From mthornton at optrak.co.uk  Wed Sep  4 06:28:01 2013
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Wed, 4 Sep 2013 11:28:01 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAGg1-iOAbBavWoh=5abo0+ffdPhjvJNYF9C_34p9MTQT9Sb22g@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
	<CAHjP37FcxAOvkrS+HXpEGU4QO6ZnUgOQZj667z-KM3AjF442mQ@mail.gmail.com>
	<CAGg1-iOAbBavWoh=5abo0+ffdPhjvJNYF9C_34p9MTQT9Sb22g@mail.gmail.com>
Message-ID: <CAC_SY738SqZKEVZ78n7wLHRQZkND1PWGH4OXuRe6nOuNOTG48w@mail.gmail.com>

Then perhaps you should look at the VM system in use. Some tie time in VM's
to the time on the physical machine. In such cases running ntpd on the VM
won't help. You must run ntpd on the physical machine. On physical
machines, I see ntpd maintaining time to within ~ 10ms or so unless there
is a network failure (in which case the time drift is the least of the
problems).

So while one could get problems with root changing the clock or when
resuming suspended VM's, I don't think either of these should occur on time
critical systems.

Mark Thornton


On Wednesday, 4 September 2013, Mikhail Mazursky wrote:

> From my own experience time can drift A LOT in virtualized environments.
> Especially when the CPU is overloaded (even in another VM on the same
> physical server). For example (and this is only a single case, but there
> were many others), few days ago we discovered that one of our servers was
> using time in the past - more than 1 hour lag. nptd was running there but
> it didn't help for some reason.
> - this is significant drift that affects JVM itself;
> - such drift makes distributed systems misbehave in a very odd ways (we
> use Cassandra and request timeouts happen when time drifts. But this is
> probably not its fault). But this last point is probably unrelevant here.
>
> Just wanted to add more context information.
>
> 2013/9/4 Vitaly Davidovich <vitalyd at gmail.com>
>
> I believe it's also the case that NTP usually tries to smooth out
> adjustments whereby it'll slowly/gradually move the clock to be inline
> rather than do abrupt jumps.  This would imply that the more problematic
> backward jumps shouldn't actually cause a much longer than expected wait.
> So the only "real" case of significant problems due to this is root
> changing the clock, but as others have said, that's an operational error.
>
> Sent from my phone
> On Sep 3, 2013 7:20 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:
>
> **
> Hi Bruno,
>
> I have raised the priority on 6900441 (which to my knowledge - and I
> created it! - has never been a private bug).
>
> A few notes on the "very frightening" aspect of this:
>
> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
> introduced into a specific glibc version for the futex-wait code such that
> it now responds to changes in the system time for absolute waits, where for
> all the years previous it did not. The fix seems to have been applied in
> late 2011 or early 2012 but I don't know the exact glibc version. There is
> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
> will eventually make its way into 32-bit linux too.
>
> 2. The effects of this is not that "all the threads parked will hang,
> with unpredictable/corrupted/useless"! The effects are very simple an
> quite predictable. If the system time goes forward then timed-waits
> (Object.wait, LockSupport.park) (which should be relative times) will
> return early as the absolute-time that the relative time was converted to
> will be seen to have been reached (Thread.sleep contains a guard against
> early returns). This is not actually a problem as you can not distinguish
> this case from a "spurious wakeup" which code is supposed to account
> for. If the time is changed backwards then these timed-waits & sleeps will
> not timeout when expected as the the for that is now further in the future,
> by the amount of the backward time change. Hence small time changes as
> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
> heuristics for recovering when the expected real event notification does
> not occur - so a delayed timeout does not affect operation in a correctly
> functioning system. Early timeouts are indistinguishable from spurious
> wakeups, which code has to account for, so again not a problem for regular
> code. The only time a significant "hang" will occur is with Thread.sleep
> and a large backward time shift - but there is little real code that uses
> Thread.sleep in any critical way.
>
> So there is an issue that needs to be addressed but the situation is
> nowhere near as dire as you make out.
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
> *Sent:* Wedne
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/11d44ec7/attachment-0001.html>

From bbossola at gmail.com  Wed Sep  4 06:54:57 2013
From: bbossola at gmail.com (bruno bossola)
Date: Wed, 4 Sep 2013 11:54:57 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAGg1-iOAbBavWoh=5abo0+ffdPhjvJNYF9C_34p9MTQT9Sb22g@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEBKAAA.davidcholmes@aapt.net.au>
	<CAHjP37FcxAOvkrS+HXpEGU4QO6ZnUgOQZj667z-KM3AjF442mQ@mail.gmail.com>
	<CAGg1-iOAbBavWoh=5abo0+ffdPhjvJNYF9C_34p9MTQT9Sb22g@mail.gmail.com>
Message-ID: <CAJU-cA+EMEE5Zq3Pd9oQ11-0Gk7HqmLrvrys5gWXHpmEB-1YcQ@mail.gmail.com>

Yes, this is exactly what's happening to us. We have NO control over our
application when installed on customer premises, and also on our cloud, it
may happen.

I understand that you can build your own cloud, and fully control it, but
we are not always in this privileged position.
Cheers,

    Bruno


On Wed, Sep 4, 2013 at 5:56 AM, Mikhail Mazursky <ash2kk at gmail.com> wrote:

> From my own experience time can drift A LOT in virtualized environments.
> Especially when the CPU is overloaded (even in another VM on the same
> physical server). For example (and this is only a single case, but there
> were many others), few days ago we discovered that one of our servers was
> using time in the past - more than 1 hour lag. nptd was running there but
> it didn't help for some reason.
> - this is significant drift that affects JVM itself;
> - such drift makes distributed systems misbehave in a very odd ways (we
> use Cassandra and request timeouts happen when time drifts. But this is
> probably not its fault). But this last point is probably unrelevant here.
>
> Just wanted to add more context information.
>
>
> 2013/9/4 Vitaly Davidovich <vitalyd at gmail.com>
>
>> I believe it's also the case that NTP usually tries to smooth out
>> adjustments whereby it'll slowly/gradually move the clock to be inline
>> rather than do abrupt jumps.  This would imply that the more problematic
>> backward jumps shouldn't actually cause a much longer than expected wait.
>> So the only "real" case of significant problems due to this is root
>> changing the clock, but as others have said, that's an operational error.
>>
>> Sent from my phone
>> On Sep 3, 2013 7:20 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:
>>
>>> **
>>> Hi Bruno,
>>>
>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>> created it! - has never been a private bug).
>>>
>>> A few notes on the "very frightening" aspect of this:
>>>
>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>>> introduced into a specific glibc version for the futex-wait code such that
>>> it now responds to changes in the system time for absolute waits, where for
>>> all the years previous it did not. The fix seems to have been applied in
>>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>>> will eventually make its way into 32-bit linux too.
>>>
>>> 2. The effects of this is not that "all the threads parked will hang,
>>> with unpredictable/corrupted/useless"! The effects are very simple an
>>> quite predictable. If the system time goes forward then timed-waits
>>> (Object.wait, LockSupport.park) (which should be relative times) will
>>> return early as the absolute-time that the relative time was converted to
>>> will be seen to have been reached (Thread.sleep contains a guard against
>>> early returns). This is not actually a problem as you can not distinguish
>>> this case from a "spurious wakeup" which code is supposed to account
>>> for. If the time is changed backwards then these timed-waits & sleeps will
>>> not timeout when expected as the the for that is now further in the future,
>>> by the amount of the backward time change. Hence small time changes as
>>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>>> heuristics for recovering when the expected real event notification does
>>> not occur - so a delayed timeout does not affect operation in a correctly
>>> functioning system. Early timeouts are indistinguishable from spurious
>>> wakeups, which code has to account for, so again not a problem for regular
>>> code. The only time a significant "hang" will occur is with Thread.sleep
>>> and a large backward time shift - but there is little real code that uses
>>> Thread.sleep in any critical way.
>>>
>>> So there is an issue that needs to be addressed but the situation is
>>> nowhere near as dire as you make out.
>>>
>>> David Holmes
>>>
>>> -----Original Message-----
>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>> *To:* concurrency-interest at cs.oswego.edu
>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>>> feedback?
>>>
>>>  Hi all,
>>>
>>> I am writing here following a suggestion by Ben Evans. I wanted to check
>>> with you about an issue that my teams found on the JVM and that's very
>>> frightening. I already started the discussion with the engineers of the
>>> hotspot VM team but it looks like we need more awareness to solve this one
>>> and I'd really appreciate some help and some push :)
>>> It looks to me that this issue is affecting every JVM64 running on
>>> Linux64, so imho it's quite important to be looked at.
>>>
>>> *Executive summary
>>> *The implementation of the concurrency primitive LockSupport.parkNanos(),
>>> the function that controls most concurrency primitive on the JVM, is
>>> flawed, and any NTP sync, or system time change, can potentially break it
>>> with unexpected results across the board.
>>>
>>> *What we need to do?
>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>> include it in a later patch release. In an ideal world it would be nice to
>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>> works based on priorities: being this qualified as P4 means it won't be
>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>
>>>
>>> *Why all this urgency?
>>> *If a system time change happens then all the threads parked will hang,
>>> with unpredictable/corrupted/useless results to the end user. Same applies
>>> to Future, Queue, Executor, and (I guess) any other construct that it's
>>> somehow related to concurrency. This is a big issue for us and for any near
>>> time application: please think about trading and betting, where the JVM is
>>> largely used, and  do not restrain yourself to the Java language: add Scala
>>> and any other JVM-based language to the picture (JRuby, Jython...)
>>>
>>> *Tech details**
>>> *To be more clear about the issue, the extent of it and the concurrency
>>> library, let me introduce this very simple program:
>>>
>>> import java.util.concurrent.locks.LockSupport;
>>>
>>> public class Main {
>>>
>>>     public static void main(String[] args) {
>>>
>>>         for (int i=100; i>0; i--) {
>>>             System.out.println(i);
>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>         }
>>>
>>>         System.out.println("Done!");
>>>     }
>>> }
>>>
>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>> whole concurrency library.
>>>
>>> To prove that this is fixable, I reimplemented the program above above
>>> substituting  LockSupport.parkNanos()  with  a JNI call to
>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>
>>> This is due to the fact  that the CPP code is calling the
>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
>>> actual "system time": each time my system syncs time using a NTP server on
>>> the net, the time might jump forward or backward. The correct call (again
>>> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
>>> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>>
>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>> clock via clock_settime() shall have no effect on threads that are blocked
>>> waiting for a *relative* time service based upon this clock...": it
>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>> it appears that the park() is using compute_abstime() (which uses
>>> timeofday) and then waits on an absolute period: for that reason it's
>>> influenced by the system clock change. *Very wrong*.
>>>
>>> I will be happy to know what you think, and if you can help me to
>>> escalate this issue I think that the all Java community will benefit from
>>> it.
>>>
>>> Cheers,
>>>
>>>     Bruno
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/b4cd9885/attachment.html>

From bbossola at gmail.com  Wed Sep  4 07:05:48 2013
From: bbossola at gmail.com (bruno bossola)
Date: Wed, 4 Sep 2013 12:05:48 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
Message-ID: <CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>

Hi David


bugs.sun.com is not a live reflection of the bug database but gets updated
> periodically (every 12 hours I think).
>

>
Good to know :) I will be eagerly clicking on it to discover the new
priority! Thanks for that, I really appreciate it.


The issue arises on certain 64-bit linux kernel/glibc versions. If you have
> an older version this does not impact you.
>

>
You saw my list: nobody will use an older Kernel/glibc version in
production.


As for the rest, show me real code in such systems that rely on sleep for
> correctness or performance/timeliness and I will show you broken code.


>
You are still hitting about the sleep(), I understand and I agree about
this. But here we are not talking about sleeps: we are talking about the
whole concurrency lot. And yes, as I already said, we are talking about
near time systems, like trading application, betting applications, air
traffic control systems, car traffic control systems. Don't you think this
bug might place Oracle JVM outside of these markets?



> If this was as dire as you make out do you not think that this issue would
> have been raised far more than it has? [....] prudent developers/companies
> trial platform upgrades to check for these kinds of issues before switching
> to them in production environments.
>
> I am waiting now for the part where you say that we should throw away
Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
action "in the middle", and I think that Oracle cannot oversee that. For
example a lot of trading software system can be installed on premises,
where you usually have no control over the environment: what I would do is
to put a native daemon in my app so that if I see the system clock change I
would kill myself, just in case. And this is a solution that I know for a
fact (sorry, I cannot make a reference) it's used in production in a very
important trading application.

Regarding that specific bug, it was not accessible to the external until
two days ago, so I guess nobody really knew a lot about it, but I will make
sure it will :) so that we can get more traction.

Cheers,

    Bruno



On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> Bruno,
>
>  bugs.sun.com is not a live reflection of the bug database but gets
> updated periodically (every 12 hours I think).
>
> The issue arises on certain 64-bit linux kernel/glibc versions. If you
> have an older version this does not impact you.
>
> As for the rest, show me real code in such systems that rely on sleep for
> correctness or performance/timeliness and I will show you broken code. We
> are not talking about real-time systems here. park(nanos)/wait(millis)
> will only be affected by the backward time change if the real notification
> they are waiting for does not happen. Timeouts with these APIs are
> heuristics, they are defensive programming to cover the case "what if the
> notification I'm waiting for does not come". The code that would be
> affected by this issue is a very small % of the code that uses the API.
>
> If this was as dire as you make out do you not think that this issue would
> have been raised far more than it has? This issue does need addressing
> because the number of affected systems will grow as these newer linux
> systems are adopted, but prudent developers/companies trial platform
> upgrades to check for these kinds of issues before swicthing to them in
> production environments.
>
> Regards,
> David
>
> -----Original Message-----
> *From:* bruno bossola [mailto:bbossola at gmail.com]
> *Sent:* Wednesday, 4 September 2013 11:14 AM
> *To:* dholmes at ieee.org
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM issue -
> feedback?
>
>   Hi David,
>
> thanks for following up.
>
>
>
>> I have raised the priority on 6900441
>>
>
>
> Thanks, but it looks still like a P4:
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
> See also the attached snapshot, just in case it changes :)
>
> [image: Inline image 2]
>
> [...] which to my knowledge [...] has never been a private bug
>>
>
> It was not accessible using bugs.sun.com, this was translated to private.
> I also received the same info indirectly from the 7u lead:
> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
> bugs.sun.com)", I guess you can check with him.
>
>
> It doesn't affect "every JVM64 running on Linux64".  A fix has been
>> introduced into a specific glibc version...
>>
>
> ...and apparently did not make it. I was able to reproduce this even with
> the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13
> + some random Debian. I did not have a JDK5, so I cannot say, but on JDK4
> everything works (that's the reason why I call it a regression). (ah, if
> you look at the bug, it lists also JDK5, so I think we are pretty much
> covered here).
> If you still have doubts tough, please have also a look on stackoverflow
> to see how it was reproduced consistently on probably every 64bitJVM over
> 64bitLinux in the world.
>
>
> The effects of this is not that "all the threads parked will hang, with
>> unpredictable/corrupted/useless"! The effects are very simple an quite
>> predictable... [deletia]s.
>
>
>
> We have very different views, and I find quite difficult to accept yours.
> You are confusing my sample program which contains a single thread in a for
> loop with any other complex multi-threading concurrent system written in
> Java. For example, if you ever worked in a bank you surely know what I
> mean. You are comparing some random sleep() put into a program by some
> newbie, with the complex ecosystem of a concurrent platform written to
> manage trading information on very fast market. In that condition, I am
> sorry, statements such "...delayed timeout does not affect operation in a
> correctly functioning system..." and "...small time changes [...] are not a
> problem" are really not applicable. Let your system place an order three
> seconds late and your are out of the door so quickly you cannot even
> realize it.
>
> But let's not limit ourselves to banks: how do you think your previous
> statements stands in these scenarios?
> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
> about a few seconds delay in control when fying planes?)
> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
> if just for a couple of seconds all traffic lights become green?)
>
> Not good enough.
>
>
> ...small time changes as typically done via NTP
>
>
>
> NTP is only one of the possible sources of this problem. The root of it is
> that the JVM is counting nanoseconds delays using absolute values based on
> a wallclock: I do not think it's that smart.
>
>
>  So there is an issue that needs to be addressed but the situation is
>> nowhere near as dire as you make out
>>
>
>
> Let's try to put this in perspective, shall we? In case the clock run
> backwards LockSupport.park() will be waiting for the nanoseconds requested
> plus the amount of seconds/minute/hours/days requested to compensate. Now,
> this primitive is used by almost *every* concurrency construct available on
> the platform, such as AbstractQueuedSynchronizer (and subclasses),
> ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
> subclasses), Executors, FutureTask, .... (too long to list them all, but I
> think we have the picture) and also low levels synchronization primitives
> of the language itself, so Object::wait(:long) and the related sychronized
> blocks.
>
> I think it's pretty dire.
>
>
> Cheers,
>
>     Bruno
>
>
>
>
>
> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>> **
>> Hi Bruno,
>>
>> I have raised the priority on 6900441 (which to my knowledge - and I
>> created it! - has never been a private bug).
>>
>> A few notes on the "very frightening" aspect of this:
>>
>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>> introduced into a specific glibc version for the futex-wait code such that
>> it now responds to changes in the system time for absolute waits, where for
>> all the years previous it did not. The fix seems to have been applied in
>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>> will eventually make its way into 32-bit linux too.
>>
>> 2. The effects of this is not that "all the threads parked will hang,
>> with unpredictable/corrupted/useless"! The effects are very simple an
>> quite predictable. If the system time goes forward then timed-waits
>> (Object.wait, LockSupport.park) (which should be relative times) will
>> return early as the absolute-time that the relative time was converted to
>> will be seen to have been reached (Thread.sleep contains a guard against
>> early returns). This is not actually a problem as you can not distinguish
>> this case from a "spurious wakeup" which code is supposed to account
>> for. If the time is changed backwards then these timed-waits & sleeps will
>> not timeout when expected as the the for that is now further in the future,
>> by the amount of the backward time change. Hence small time changes as
>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>> heuristics for recovering when the expected real event notification does
>> not occur - so a delayed timeout does not affect operation in a correctly
>> functioning system. Early timeouts are indistinguishable from spurious
>> wakeups, which code has to account for, so again not a problem for regular
>> code. The only time a significant "hang" will occur is with Thread.sleep
>> and a large backward time shift - but there is little real code that uses
>> Thread.sleep in any critical way.
>>
>> So there is an issue that needs to be addressed but the situation is
>> nowhere near as dire as you make out.
>>
>> David Holmes
>>
>> -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>> *To:* concurrency-interest at cs.oswego.edu
>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>> feedback?
>>
>>  Hi all,
>>
>> I am writing here following a suggestion by Ben Evans. I wanted to check
>> with you about an issue that my teams found on the JVM and that's very
>> frightening. I already started the discussion with the engineers of the
>> hotspot VM team but it looks like we need more awareness to solve this one
>> and I'd really appreciate some help and some push :)
>> It looks to me that this issue is affecting every JVM64 running on
>> Linux64, so imho it's quite important to be looked at.
>>
>> *Executive summary
>> *The implementation of the concurrency primitive LockSupport.parkNanos(),
>> the function that controls most concurrency primitive on the JVM, is
>> flawed, and any NTP sync, or system time change, can potentially break it
>> with unexpected results across the board.
>>
>> *What we need to do?
>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>> public, but it's still a  P4, that means that probably won't be fixed. I
>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>> make all the possible effort to make this fix for JDK8 or, at least, to
>> include it in a later patch release. In an ideal world it would be nice to
>> have a patch for JDK7. As far as I understand the hotspot engineering team
>> works based on priorities: being this qualified as P4 means it won't be
>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>> go back to 2002!) They acknowledge the problem, it has been flagged to
>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>
>>
>> *Why all this urgency?
>> *If a system time change happens then all the threads parked will hang,
>> with unpredictable/corrupted/useless results to the end user. Same applies
>> to Future, Queue, Executor, and (I guess) any other construct that it's
>> somehow related to concurrency. This is a big issue for us and for any near
>> time application: please think about trading and betting, where the JVM is
>> largely used, and  do not restrain yourself to the Java language: add Scala
>> and any other JVM-based language to the picture (JRuby, Jython...)
>>
>> *Tech details**
>> *To be more clear about the issue, the extent of it and the concurrency
>> library, let me introduce this very simple program:
>>
>> import java.util.concurrent.locks.LockSupport;
>>
>> public class Main {
>>
>>     public static void main(String[] args) {
>>
>>         for (int i=100; i>0; i--) {
>>             System.out.println(i);
>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>         }
>>
>>         System.out.println("Done!");
>>     }
>> }
>>
>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour
>> and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and
>> latest JDK8 beta running on various Ubuntu distros. It's not just a matter
>> of (old?) sleep() and wait() primitives, this issue it affects the whole
>> concurrency library.
>>
>> To prove that this is fixable, I reimplemented the program above above
>> substituting  LockSupport.parkNanos()  with  a JNI call to
>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>
>> This is due to the fact  that the CPP code is calling the
>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
>> unfortunately is affected by settime()/settimeofday() calls (on Linux): for
>> that reason it cannot be used to measure nanoseconds delays, which is what
>> the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
>> actual "system time": each time my system syncs time using a NTP server on
>> the net, the time might jump forward or backward. The correct call (again
>> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
>> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>
>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>> clock via clock_settime() shall have no effect on threads that are blocked
>> waiting for a *relative* time service based upon this clock...": it
>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>> it appears that the park() is using compute_abstime() (which uses
>> timeofday) and then waits on an absolute period: for that reason it's
>> influenced by the system clock change. *Very wrong*.
>>
>> I will be happy to know what you think, and if you can help me to
>> escalate this issue I think that the all Java community will benefit from
>> it.
>>
>> Cheers,
>>
>>     Bruno
>>
>>
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date: 09/03/13
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/2ed69855/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  4 12:36:21 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 04 Sep 2013 17:36:21 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
Message-ID: <52276185.6070902@oracle.com>

You are missing the point.

Where in the design of those systems is a real-time timer? The one that 
delivers time events uncompromised even by GC latency?

The whole concurrency lot does not depend on the timeout magnitude for 
correctness.

Alex

On 04/09/2013 12:05, bruno bossola wrote:
> Hi David
>
>
>     bugs.sun.com <http://bugs.sun.com> is not a live reflection of the
>     bug database but gets updated periodically (every 12 hours I think).
>
>
> Good to know :) I will be eagerly clicking on it to discover the new 
> priority! Thanks for that, I really appreciate it.
>
>
>     The issue arises on certain 64-bit linux kernel/glibc versions. If
>     you have an older version this does not impact you.
>
> You saw my list: nobody will use an older Kernel/glibc version in 
> production.
>
>
>     As for the rest, show me real code in such systems that rely on
>     sleep for correctness or performance/timeliness and I will show
>     you broken code.
>
> You are still hitting about the sleep(), I understand and I agree 
> about this. But here we are not talking about sleeps: we are talking 
> about the whole concurrency lot. And yes, as I already said, we are 
> talking about near time systems, like trading application, betting 
> applications, air traffic control systems, car traffic control 
> systems. Don't you think this bug might place Oracle JVM outside of 
> these markets?
>
>
>     If this was as dire as you make out do you not think that this
>     issue would have been raised far more than it has? [....] prudent
>     developers/companies trial platform upgrades to check for these
>     kinds of issues before switching to them in production environments.
>
> I am waiting now for the part where you say that we should throw away 
> Linux and use Oracle Solaris :)  In all seriousness, there's a lot of 
> action "in the middle", and I think that Oracle cannot oversee that. 
> For example a lot of trading software system can be installed on 
> premises, where you usually have no control over the environment: what 
> I would do is to put a native daemon in my app so that if I see the 
> system clock change I would kill myself, just in case. And this is a 
> solution that I know for a fact (sorry, I cannot make a reference) 
> it's used in production in a very important trading application.
>
> Regarding that specific bug, it was not accessible to the external 
> until two days ago, so I guess nobody really knew a lot about it, but 
> I will make sure it will :) so that we can get more traction.
>
> Cheers,
>
>     Bruno
>
>
>
> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au 
> <mailto:davidcholmes at aapt.net.au>> wrote:
>
>     Bruno,
>     bugs.sun.com <http://bugs.sun.com> is not a live reflection of the
>     bug database but gets updated periodically (every 12 hours I think).
>     The issue arises on certain 64-bit linux kernel/glibc versions. If
>     you have an older version this does not impact you.
>     As for the rest, show me real code in such systems that rely on
>     sleep for correctness or performance/timelinessand I will show you
>     broken code. We are not talking about real-time systemshere.
>     park(nanos)/wait(millis) will only be affected by the backward
>     time change if the real notification they are waiting for does not
>     happen. Timeouts with these APIs are heuristics, they are
>     defensive programming to cover the case "what if the notification
>     I'm waiting for does not come". The code that would be affected by
>     this issue is a very small % of the code that uses the API.
>     If this was as dire as you make out do you not think that this
>     issue would have been raised far more than it has? This issue does
>     need addressing because the number of affected systems will grow
>     as these newer linux systems are adopted, but prudent
>     developers/companies trial platform upgrades to check for these
>     kinds of issues before swicthing to them in production environments.
>     Regards,
>     David
>
>         -----Original Message-----
>         *From:* bruno bossola [mailto:bbossola at gmail.com
>         <mailto:bbossola at gmail.com>]
>         *Sent:* Wednesday, 4 September 2013 11:14 AM
>         *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>         *Cc:* concurrency-interest at cs.oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>
>         *Subject:* Re: [concurrency-interest] Outstanding concurrency
>         JVM issue - feedback?
>
>         Hi David,
>
>         thanks for following up.
>
>             I have raised the priority on 6900441
>
>         Thanks, but it looks still like a P4:
>         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>         See also the attached snapshot, just in case it changes :)
>
>         Inline image 2
>
>             [...] which to my knowledge [...] has never been a private bug
>
>         It was not accessible using bugs.sun.com
>         <http://bugs.sun.com/>, this was translated to private. I also
>         received the same info indirectly from the 7u lead:
>         "I'm not sure why 6900441 isn't public. (I'll follow up with
>         owner of bugs.sun.com <http://bugs.sun.com/>)", I guess you
>         can check with him.
>
>
>             It doesn't affect "every JVM64 running on Linux64".  A fix
>             has been introduced into a specific glibc version...
>
>         ...and apparently did not make it. I was able to reproduce
>         this even with the IBM VM, so to speak. I tried JDK6, JDK7,
>         JDK8 on Ubuntu 10, 11, 12, 13 + some random Debian. I did not
>         have a JDK5, so I cannot say, but on JDK4 everything works
>         (that's the reason why I call it a regression). (ah, if you
>         look at the bug, it lists also JDK5, so I think we are pretty
>         much covered here).
>         If you still have doubts tough, please have also a look on
>         stackoverflow to see how it was reproduced consistently on
>         probably every 64bitJVM over 64bitLinux in the world.
>
>
>             The effects of this is not that "all the threads parked
>             will hang, with unpredictable/corrupted/useless"! The
>             effects are very simple an quite predictable... [deletia]s.
>
>         We have very different views, and I find quite difficult to
>         accept yours. You are confusing my sample program which
>         contains a single thread in a for loop with any other complex
>         multi-threading concurrent system written in Java. For
>         example, if you ever worked in a bank you surely know what I
>         mean. You are comparing some random sleep() put into a program
>         by some newbie, with the complex ecosystem of a concurrent
>         platform written to manage trading information on very fast
>         market. In that condition, I am sorry, statements such
>         "...delayed timeout does not affect operation in a correctly
>         functioning system..." and "...small time changes [...] are
>         not a problem" are really not applicable. Let your system
>         place an order three seconds late and your are out of the door
>         so quickly you cannot even realize it.
>
>         But let's not limit ourselves to banks: how do you think your
>         previous statements stands in these scenarios?
>         - air control systems
>         <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>         about a few seconds delay in control when fying planes?)
>         - city traffic control systems
>         <http://www.iisigroup.com/en/solutions/tra-city.html> (what if
>         just for a couple of seconds all traffic lights become green?)
>
>         Not good enough.
>
>
>             ...small time changes as typically done via NTP
>
>         NTP is only one of the possible sources of this problem. The
>         root of it is that the JVM is counting nanoseconds delays
>         using absolute values based on a wallclock: I do not think
>         it's that smart.
>
>
>             So there is an issue that needs to be addressed but the
>             situation is nowhere near as dire as you make out
>
>         Let's try to put this in perspective, shall we? In case the
>         clock run backwards LockSupport.park() will be waiting for the
>         nanoseconds requested plus the amount of
>         seconds/minute/hours/days requested to compensate. Now, this
>         primitive is used by almost *every* concurrency construct
>         available on the platform, such as AbstractQueuedSynchronizer
>         (and subclasses), ReentrantLock (and subclasses),
>         CyclicBarrier, BlockingQueue (and subclasses), Executors,
>         FutureTask, .... (too long to list them all, but I think we
>         have the picture) and also low levels synchronization
>         primitives of the language itself, so Object::wait(:long) and
>         the related sychronized blocks.
>
>         I think it's pretty dire.
>
>
>         Cheers,
>
>             Bruno
>
>
>
>
>
>         On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
>         <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>>
>         wrote:
>
>             Hi Bruno,
>             I have raised the priority on 6900441 (which to my
>             knowledge - and I created it! - has never been a private bug).
>             A few notes on the "very frightening" aspect of this:
>             1. It doesn't affect "every JVM64 running on Linux64". A
>             fix has been introduced into a specific glibc version for
>             the futex-wait code such that it now responds to changes
>             in the system time for absolute waits, where for all the
>             years previous it did not. The fix seems to have been
>             applied in late 2011 or early 2012 but I don't know the
>             exact glibc version. There is also a 32-bit version of the
>             fix that was proposed on Nov 27, 2012, so it will
>             eventually make its way into 32-bit linux too.
>             2. The effects of this is not that "all the threads parked
>             will hang, with unpredictable/corrupted/useless"! The
>             effects are very simple an quite predictable. If the
>             system time goes forward then timed-waits (Object.wait,
>             LockSupport.park) (which should be relative times) will
>             return early as the absolute-time that the relative time
>             was converted to will be seen to have been reached
>             (Thread.sleep contains a guard against early returns).
>             This is not actually a problem as you can not distinguish
>             this case from a "spurious wakeup" which code is supposed
>             to account for. If the time is changed backwards then
>             these timed-waits & sleeps will not timeout when expected
>             as the the for that is now further in the future, by the
>             amount of the backward time change. Hence small time
>             changes as typically done via NTP are NOT a problem.
>             Timed-waits use timeouts as a heuristics for recovering
>             when the expected real event notification does not occur -
>             so a delayed timeout does not affect operation in a
>             correctly functioning system. Early timeouts are
>             indistinguishable from spurious wakeups, which code has to
>             account for, so again not a problem for regular code. The
>             only time a significant "hang" will occur is with
>             Thread.sleep and a large backward time shift - but there
>             is little real code that uses Thread.sleep in any critical
>             way.
>             So there is an issue that needs to be addressed but the
>             situation is nowhere near as dire as you make out.
>             David Holmes
>
>                 -----Original Message-----
>                 *From:* concurrency-interest-bounces at cs.oswego.edu
>                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf
>                 Of *bruno bossola
>                 *Sent:* Wednesday, 4 September 2013 1:56 AM
>                 *To:* concurrency-interest at cs.oswego.edu
>                 <mailto:concurrency-interest at cs.oswego.edu>
>                 *Subject:* [concurrency-interest] Outstanding
>                 concurrency JVM issue - feedback?
>
>                 Hi all,
>
>                 I am writing here following a suggestion by Ben Evans.
>                 I wanted to check with you about an issue that my
>                 teams found on the JVM and that's very frightening. I
>                 already started the discussion with the engineers of
>                 the hotspot VM team but it looks like we need more
>                 awareness to solve this one and I'd really appreciate
>                 some help and some push :)
>                 It looks to me that this issue is affecting every
>                 JVM64 running on Linux64, so imho it's quite important
>                 to be looked at.
>
>                 *Executive summary
>                 *The implementation of the concurrency primitive
>                 LockSupport.parkNanos(), the function that controls
>                 most concurrency primitive on the JVM, is flawed, and
>                 any NTP sync, or system time change, can potentially
>                 break it with unexpected results across the board.
>
>                 *What we need to do?
>                 *This is an old issue, and the bug
>                 <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>                 was declared private. I somehow managed to have the
>                 bug reopened to the public, but it's still a P4, that
>                 means that probably won't be fixed. I think we need to
>                 push for a resolution ASAP, be sure that's in for
>                 JDK9, make all the possible effort to make this fix
>                 for JDK8 or, at least, to include it in a later patch
>                 release. In an ideal world it would be nice to have a
>                 patch for JDK7. As far as I understand the hotspot
>                 engineering team works based on priorities: being this
>                 qualified as P4 means it won't be probably worked on
>                 (if you follow the breadcrumbs of bugs and fixes you
>                 can go back to 2002!) They acknowledge the problem, it
>                 has been flagged to management, but 1) it's low
>                 priority 2) it's too risky to fix for JDK8
>
>
>                 *Why all this urgency?
>                 *If a system time change happens then all the threads
>                 parked will hang, with unpredictable/corrupted/useless
>                 results to the end user. Same applies to Future,
>                 Queue, Executor, and (I guess) any other construct
>                 that it's somehow related to concurrency. This is a
>                 big issue for us and for any near time application:
>                 please think about trading and betting, where the JVM
>                 is largely used, and  do not restrain yourself to the
>                 Java language: add Scala and any other JVM-based
>                 language to the picture (JRuby, Jython...)
>
>                 *Tech details**
>                 *To be more clear about the issue, the extent of it
>                 and the concurrency library, let me introduce this
>                 very simple program:
>
>                 import java.util.concurrent.locks.LockSupport;
>
>                 public class Main {
>
>                     public static void main(String[] args) {
>
>                         for (int i=100; i>0; i--) {
>                 System.out.println(i);
>                 LockSupport.parkNanos(1000L*1000L*1000L);
>                         }
>
>                 System.out.println("Done!");
>                     }
>                 }
>
>                 Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the
>                 clock down one hour and wait until the counter
>                 stops... magic!  I tested this on JDK6, JDK7 and
>                 latest JDK8 beta running on various Ubuntu distros.
>                 It's not just a matter of (old?) sleep() and wait()
>                 primitives, this issue it affects the whole
>                 concurrency library.
>
>                 To prove that this is fixable, I reimplemented the
>                 program above above substituting
>                 LockSupport.parkNanos() with  a JNI call to
>                 clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>
>                 This is due to the fact  that the CPP code is calling
>                 the pthread_cond_timedwait() using its default clock
>                 (CLOCK_REALTIME) which, unfortunately is affected by
>                 settime()/settimeofday() calls (on Linux): for that
>                 reason it cannot be used to measure nanoseconds
>                 delays, which is what the specification
>                 <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>                 requires. CLOCK_REALTIME is not guaranteed to
>                 monotonically count as this is the actual "system
>                 time": each time my system syncs time using a NTP
>                 server on the net, the time might jump forward or
>                 backward. The correct call (again on Linux)  would
>                 require to use CLOCK_MONOTONIC as clock id, which are
>                 defined by POSIX specs since 2002. (or better
>                 CLOCK_MONOTONIC_RAW)
>
>                 The POSIX spec
>                 <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>                 is infact clear, as it states "...setting the value of
>                 the CLOCK_REALTIME clock via clock_settime() shall
>                 have no effect on threads that are blocked waiting for
>                 a *relative* time service based upon this clock...":
>                 it definitely states "relative".  Having a look at the
>                 hotspot code
>                 <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>                 it appears that the park() is using compute_abstime()
>                 (which uses timeofday) and then waits on an absolute
>                 period: for that reason it's influenced by the system
>                 clock change. *Very wrong*.
>
>                 I will be happy to know what you think, and if you can
>                 help me to escalate this issue I think that the all
>                 Java community will benefit from it.
>
>                 Cheers,
>
>                     Bruno
>
>
>         No virus found in this message.
>         Checked by AVG - www.avg.com <http://www.avg.com>
>         Version: 2013.0.3392 / Virus Database: 3222/6633 - Release
>         Date: 09/03/13
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/f1c59ac3/attachment-0001.html>

From bbossola at gmail.com  Wed Sep  4 13:54:25 2013
From: bbossola at gmail.com (bruno bossola)
Date: Wed, 4 Sep 2013 18:54:25 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <52276185.6070902@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
Message-ID: <CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>

Hi Oleksandr,

Where in the design of those systems is a real-time timer? The one that
> delivers time events uncompromised even by GC latency?
>

>
I don't think so :) If somebody needs a real time implementation he needs
to go for a real time JVM, like Jean correctly pointed out.  The
concurrency primitives are depending on LockSupport.parkNanos(...) to park
a thread: if this for any reason is not working (like it is) then strange
things may happen.

Imagine, for example, that you are using a ReentrantLock to control a very
precious resource used across the board (what about a database connection
pool?) and you are unlucky enough to have a system time change (backwards)
while you are locking: all the threads that want to use such resource will
be progressively locked: not forever, but for the amount of time the clock
went back. Probably most (all?) of your system freezes, and the only option
you have is to wait, or restart.
Now place this in a large application server, that provide services for
hunreds (thousands) of users. How does it sound to you?

BTW, at the moment we could have a watchdog (in Python :)) that restarts
it, but, I dunno why, I don't like it a lot...

Cheers,

    Bruno



>

On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  You are missing the point.
>
> Where in the design of those systems is a real-time timer? The one that
> delivers time events uncompromised even by GC latency?
>
> The whole concurrency lot does not depend on the timeout magnitude for
> correctness.
>
> Alex
>
>
> On 04/09/2013 12:05, bruno bossola wrote:
>
>  Hi David
>
>
>  bugs.sun.com is not a live reflection of the bug database but gets
>> updated periodically (every 12 hours I think).
>>
>
>>
> Good to know :) I will be eagerly clicking on it to discover the new
> priority! Thanks for that, I really appreciate it.
>
>
> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>> have an older version this does not impact you.
>>
>
>>
> You saw my list: nobody will use an older Kernel/glibc version in
> production.
>
>
> As for the rest, show me real code in such systems that rely on sleep for
>> correctness or performance/timeliness and I will show you broken code.
>
>
>>
>  You are still hitting about the sleep(), I understand and I agree about
> this. But here we are not talking about sleeps: we are talking about the
> whole concurrency lot. And yes, as I already said, we are talking about
> near time systems, like trading application, betting applications, air
> traffic control systems, car traffic control systems. Don't you think this
> bug might place Oracle JVM outside of these markets?
>
>
>
>> If this was as dire as you make out do you not think that this issue
>> would have been raised far more than it has? [....] prudent
>> developers/companies trial platform upgrades to check for these kinds of
>> issues before switching to them in production environments.
>>
>>  I am waiting now for the part where you say that we should throw away
> Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
> action "in the middle", and I think that Oracle cannot oversee that. For
> example a lot of trading software system can be installed on premises,
> where you usually have no control over the environment: what I would do is
> to put a native daemon in my app so that if I see the system clock change I
> would kill myself, just in case. And this is a solution that I know for a
> fact (sorry, I cannot make a reference) it's used in production in a very
> important trading application.
>
> Regarding that specific bug, it was not accessible to the external until
> two days ago, so I guess nobody really knew a lot about it, but I will make
> sure it will :) so that we can get more traction.
>
>  Cheers,
>
>      Bruno
>
>
>
> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>>  Bruno,
>>
>>  bugs.sun.com is not a live reflection of the bug database but gets
>> updated periodically (every 12 hours I think).
>>
>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>> have an older version this does not impact you.
>>
>> As for the rest, show me real code in such systems that rely on sleep for
>> correctness or performance/timeliness and I will show you broken code.
>> We are not talking about real-time systems here. park(nanos)/wait(millis)
>> will only be affected by the backward time change if the real notification
>> they are waiting for does not happen. Timeouts with these APIs are
>> heuristics, they are defensive programming to cover the case "what if the
>> notification I'm waiting for does not come". The code that would be
>> affected by this issue is a very small % of the code that uses the API.
>>
>> If this was as dire as you make out do you not think that this issue
>> would have been raised far more than it has? This issue does need
>> addressing because the number of affected systems will grow as these newer
>> linux systems are adopted, but prudent developers/companies trial platform
>> upgrades to check for these kinds of issues before swicthing to them in
>> production environments.
>>
>> Regards,
>> David
>>
>>  -----Original Message-----
>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>> *To:* dholmes at ieee.org
>> *Cc:* concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM issue
>> - feedback?
>>
>>    Hi David,
>>
>>  thanks for following up.
>>
>>
>>
>>> I have raised the priority on 6900441
>>>
>>
>>
>>  Thanks, but it looks still like a P4:
>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>> See also the attached snapshot, just in case it changes :)
>>
>>  [image: Inline image 2]
>>
>>  [...] which to my knowledge [...] has never been a private bug
>>>
>>
>> It was not accessible using bugs.sun.com, this was translated to
>> private. I also received the same info indirectly from the 7u lead:
>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>> bugs.sun.com)", I guess you can check with him.
>>
>>
>>  It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>> introduced into a specific glibc version...
>>>
>>
>> ...and apparently did not make it. I was able to reproduce this even with
>> the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13
>> + some random Debian. I did not have a JDK5, so I cannot say, but on JDK4
>> everything works (that's the reason why I call it a regression). (ah, if
>> you look at the bug, it lists also JDK5, so I think we are pretty much
>> covered here).
>> If you still have doubts tough, please have also a look on stackoverflow
>> to see how it was reproduced consistently on probably every 64bitJVM over
>> 64bitLinux in the world.
>>
>>
>>  The effects of this is not that "all the threads parked will hang, with
>>> unpredictable/corrupted/useless"! The effects are very simple an quite
>>> predictable... [deletia]s.
>>
>>
>>
>> We have very different views, and I find quite difficult to accept yours.
>> You are confusing my sample program which contains a single thread in a for
>> loop with any other complex multi-threading concurrent system written in
>> Java. For example, if you ever worked in a bank you surely know what I
>> mean. You are comparing some random sleep() put into a program by some
>> newbie, with the complex ecosystem of a concurrent platform written to
>> manage trading information on very fast market. In that condition, I am
>> sorry, statements such "...delayed timeout does not affect operation in a
>> correctly functioning system..." and "...small time changes [...] are not a
>> problem" are really not applicable. Let your system place an order three
>> seconds late and your are out of the door so quickly you cannot even
>> realize it.
>>
>>  But let's not limit ourselves to banks: how do you think your previous
>> statements stands in these scenarios?
>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>> about a few seconds delay in control when fying planes?)
>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>> if just for a couple of seconds all traffic lights become green?)
>>
>>  Not good enough.
>>
>>
>>  ...small time changes as typically done via NTP
>>
>>
>>
>> NTP is only one of the possible sources of this problem. The root of it
>> is that the JVM is counting nanoseconds delays using absolute values based
>> on a wallclock: I do not think it's that smart.
>>
>>
>>   So there is an issue that needs to be addressed but the situation is
>>> nowhere near as dire as you make out
>>>
>>
>>
>>  Let's try to put this in perspective, shall we? In case the clock run
>> backwards LockSupport.park() will be waiting for the nanoseconds requested
>> plus the amount of seconds/minute/hours/days requested to compensate. Now,
>> this primitive is used by almost *every* concurrency construct available on
>> the platform, such as AbstractQueuedSynchronizer (and subclasses),
>> ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
>> subclasses), Executors, FutureTask, .... (too long to list them all, but I
>> think we have the picture) and also low levels synchronization primitives
>> of the language itself, so Object::wait(:long) and the related sychronized
>> blocks.
>>
>>  I think it's pretty dire.
>>
>>
>>  Cheers,
>>
>>      Bruno
>>
>>
>>
>>
>>
>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>
>>>  Hi Bruno,
>>>
>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>> created it! - has never been a private bug).
>>>
>>> A few notes on the "very frightening" aspect of this:
>>>
>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>>> introduced into a specific glibc version for the futex-wait code such that
>>> it now responds to changes in the system time for absolute waits, where for
>>> all the years previous it did not. The fix seems to have been applied in
>>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>>> will eventually make its way into 32-bit linux too.
>>>
>>> 2. The effects of this is not that "all the threads parked will hang,
>>> with unpredictable/corrupted/useless"! The effects are very simple an
>>> quite predictable. If the system time goes forward then timed-waits
>>> (Object.wait, LockSupport.park) (which should be relative times) will
>>> return early as the absolute-time that the relative time was converted to
>>> will be seen to have been reached (Thread.sleep contains a guard against
>>> early returns). This is not actually a problem as you can not distinguish
>>> this case from a "spurious wakeup" which code is supposed to account
>>> for. If the time is changed backwards then these timed-waits & sleeps will
>>> not timeout when expected as the the for that is now further in the future,
>>> by the amount of the backward time change. Hence small time changes as
>>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>>> heuristics for recovering when the expected real event notification does
>>> not occur - so a delayed timeout does not affect operation in a correctly
>>> functioning system. Early timeouts are indistinguishable from spurious
>>> wakeups, which code has to account for, so again not a problem for regular
>>> code. The only time a significant "hang" will occur is with Thread.sleep
>>> and a large backward time shift - but there is little real code that uses
>>> Thread.sleep in any critical way.
>>>
>>> So there is an issue that needs to be addressed but the situation is
>>> nowhere near as dire as you make out.
>>>
>>> David Holmes
>>>
>>> -----Original Message-----
>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>> *To:* concurrency-interest at cs.oswego.edu
>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>>> feedback?
>>>
>>>   Hi all,
>>>
>>> I am writing here following a suggestion by Ben Evans. I wanted to check
>>> with you about an issue that my teams found on the JVM and that's very
>>> frightening. I already started the discussion with the engineers of the
>>> hotspot VM team but it looks like we need more awareness to solve this one
>>> and I'd really appreciate some help and some push :)
>>>  It looks to me that this issue is affecting every JVM64 running on
>>> Linux64, so imho it's quite important to be looked at.
>>>
>>> *Executive summary
>>> *The implementation of the concurrency primitive LockSupport.parkNanos(),
>>> the function that controls most concurrency primitive on the JVM, is
>>> flawed, and any NTP sync, or system time change, can potentially break it
>>> with unexpected results across the board.
>>>
>>> *What we need to do?
>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>> include it in a later patch release. In an ideal world it would be nice to
>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>> works based on priorities: being this qualified as P4 means it won't be
>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>
>>>
>>> *Why all this urgency?
>>> *If a system time change happens then all the threads parked will hang,
>>> with unpredictable/corrupted/useless results to the end user. Same applies
>>> to Future, Queue, Executor, and (I guess) any other construct that it's
>>> somehow related to concurrency. This is a big issue for us and for any near
>>> time application: please think about trading and betting, where the JVM is
>>> largely used, and  do not restrain yourself to the Java language: add Scala
>>> and any other JVM-based language to the picture (JRuby, Jython...)
>>>
>>> *Tech details**
>>> *To be more clear about the issue, the extent of it and the concurrency
>>> library, let me introduce this very simple program:
>>>
>>> import java.util.concurrent.locks.LockSupport;
>>>
>>> public class Main {
>>>
>>>     public static void main(String[] args) {
>>>
>>>         for (int i=100; i>0; i--) {
>>>             System.out.println(i);
>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>         }
>>>
>>>         System.out.println("Done!");
>>>     }
>>> }
>>>
>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>> whole concurrency library.
>>>
>>>  To prove that this is fixable, I reimplemented the program above above
>>> substituting  LockSupport.parkNanos()  with  a JNI call to
>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>
>>>  This is due to the fact  that the CPP code is calling the
>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
>>> actual "system time": each time my system syncs time using a NTP server on
>>> the net, the time might jump forward or backward. The correct call (again
>>> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
>>> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>>
>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>> clock via clock_settime() shall have no effect on threads that are blocked
>>> waiting for a *relative* time service based upon this clock...": it
>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>> it appears that the park() is using compute_abstime() (which uses
>>> timeofday) and then waits on an absolute period: for that reason it's
>>> influenced by the system clock change. *Very wrong*.
>>>
>>>  I will be happy to know what you think, and if you can help me to
>>> escalate this issue I think that the all Java community will benefit from
>>> it.
>>>
>>> Cheers,
>>>
>>>      Bruno
>>>
>>>
>>   No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date: 09/03/13
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/19b57707/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  4 14:02:07 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 04 Sep 2013 19:02:07 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
Message-ID: <5227759F.7060300@oracle.com>

n 04/09/2013 18:54, bruno bossola wrote:
> Hi Oleksandr,
>
>     Where in the design of those systems is a real-time timer? The one
>     that delivers time events uncompromised even by GC latency?
>
> I don't think so :) If somebody needs a real time implementation he 
> needs to go for a real time JVM, like Jean correctly pointed out.  The 
> concurrency primitives are depending on LockSupport.parkNanos(...) to 
> park a thread: if this for any reason is not working (like it is) then 
> strange things may happen.
Your assumption is that it is not working, if the elapsed time is 
longer. This is the flawed assumption.

Also, you need to read fine print on those "real time" JVMs. The catch 
is in the definition of "real time".



> Imagine, for example, that you are using a ReentrantLock to control a 
> very precious resource used across the board (what about a database 
> connection pool?) and you are unlucky enough to have a system time 
> change (backwards) while you are locking: all the threads that want to 
> use such resource will be progressively locked: not forever, but for 
> the amount of time the clock went back. Probably most (all?) of your 
> system freezes, and the only option you have is to wait, or restart.
> Now place this in a large application server, that provide services 
> for hunreds (thousands) of users. How does it sound to you?
It sounds like you don't understand how the locks work.


Alex

>
> BTW, at the moment we could have a watchdog (in Python :)) that 
> restarts it, but, I dunno why, I don't like it a lot...
>
> Cheers,
>
>     Bruno
>
>
>
>
>
> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     You are missing the point.
>
>     Where in the design of those systems is a real-time timer? The one
>     that delivers time events uncompromised even by GC latency?
>
>     The whole concurrency lot does not depend on the timeout magnitude
>     for correctness.
>
>     Alex
>
>
>     On 04/09/2013 12:05, bruno bossola wrote:
>>     Hi David
>>
>>
>>         bugs.sun.com <http://bugs.sun.com> is not a live reflection
>>         of the bug database but gets updated periodically (every 12
>>         hours I think).
>>
>>
>>     Good to know :) I will be eagerly clicking on it to discover the
>>     new priority! Thanks for that, I really appreciate it.
>>
>>
>>         The issue arises on certain 64-bit linux kernel/glibc
>>         versions. If you have an older version this does not impact you.
>>
>>     You saw my list: nobody will use an older Kernel/glibc version in
>>     production.
>>
>>
>>         As for the rest, show me real code in such systems that rely
>>         on sleep for correctness or performance/timeliness and I will
>>         show you broken code.
>>
>>     You are still hitting about the sleep(), I understand and I agree
>>     about this. But here we are not talking about sleeps: we are
>>     talking about the whole concurrency lot. And yes, as I already
>>     said, we are talking about near time systems, like trading
>>     application, betting applications, air traffic control systems,
>>     car traffic control systems. Don't you think this bug might place
>>     Oracle JVM outside of these markets?
>>
>>
>>         If this was as dire as you make out do you not think that
>>         this issue would have been raised far more than it has?
>>         [....] prudent developers/companies trial platform upgrades
>>         to check for these kinds of issues before switching to them
>>         in production environments.
>>
>>     I am waiting now for the part where you say that we should throw
>>     away Linux and use Oracle Solaris :)  In all seriousness, there's
>>     a lot of action "in the middle", and I think that Oracle cannot
>>     oversee that. For example a lot of trading software system can be
>>     installed on premises, where you usually have no control over the
>>     environment: what I would do is to put a native daemon in my app
>>     so that if I see the system clock change I would kill myself,
>>     just in case. And this is a solution that I know for a fact
>>     (sorry, I cannot make a reference) it's used in production in a
>>     very important trading application.
>>
>>     Regarding that specific bug, it was not accessible to the
>>     external until two days ago, so I guess nobody really knew a lot
>>     about it, but I will make sure it will :) so that we can get more
>>     traction.
>>
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>     On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>     <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>         Bruno,
>>         bugs.sun.com <http://bugs.sun.com> is not a live reflection
>>         of the bug database but gets updated periodically (every 12
>>         hours I think).
>>         The issue arises on certain 64-bit linux kernel/glibc
>>         versions. If you have an older version this does not impact you.
>>         As for the rest, show me real code in such systems that rely
>>         on sleep for correctness or performance/timelinessand I will
>>         show you broken code. We are not talking about real-time
>>         systemshere. park(nanos)/wait(millis) will only be affected
>>         by the backward time change if the real notification they are
>>         waiting for does not happen. Timeouts with these APIs are
>>         heuristics, they are defensive programming to cover the case
>>         "what if the notification I'm waiting for does not come". The
>>         code that would be affected by this issue is a very small %
>>         of the code that uses the API.
>>         If this was as dire as you make out do you not think that
>>         this issue would have been raised far more than it has? This
>>         issue does need addressing because the number of affected
>>         systems will grow as these newer linux systems are adopted,
>>         but prudent developers/companies trial platform upgrades to
>>         check for these kinds of issues before swicthing to them in
>>         production environments.
>>         Regards,
>>         David
>>
>>             -----Original Message-----
>>             *From:* bruno bossola [mailto:bbossola at gmail.com
>>             <mailto:bbossola at gmail.com>]
>>             *Sent:* Wednesday, 4 September 2013 11:14 AM
>>             *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>             *Cc:* concurrency-interest at cs.oswego.edu
>>             <mailto:concurrency-interest at cs.oswego.edu>
>>             *Subject:* Re: [concurrency-interest] Outstanding
>>             concurrency JVM issue - feedback?
>>
>>             Hi David,
>>
>>             thanks for following up.
>>
>>                 I have raised the priority on 6900441
>>
>>             Thanks, but it looks still like a P4:
>>             http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>             See also the attached snapshot, just in case it changes :)
>>
>>             Inline image 2
>>
>>                 [...] which to my knowledge [...] has never been a
>>                 private bug
>>
>>             It was not accessible using bugs.sun.com
>>             <http://bugs.sun.com/>, this was translated to private. I
>>             also received the same info indirectly from the 7u lead:
>>             "I'm not sure why 6900441 isn't public. (I'll follow up
>>             with owner of bugs.sun.com <http://bugs.sun.com/>)", I
>>             guess you can check with him.
>>
>>
>>                 It doesn't affect "every JVM64 running on
>>                 Linux64".  A fix has been introduced into a specific
>>                 glibc version...
>>
>>             ...and apparently did not make it. I was able to
>>             reproduce this even with the IBM VM, so to speak. I tried
>>             JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13 + some random
>>             Debian. I did not have a JDK5, so I cannot say, but on
>>             JDK4 everything works (that's the reason why I call it a
>>             regression). (ah, if you look at the bug, it lists also
>>             JDK5, so I think we are pretty much covered here).
>>             If you still have doubts tough, please have also a look
>>             on stackoverflow to see how it was reproduced
>>             consistently on probably every 64bitJVM over 64bitLinux
>>             in the world.
>>
>>
>>                 The effects of this is not that "all the threads
>>                 parked will hang, with
>>                 unpredictable/corrupted/useless"! The effects are
>>                 very simple an quite predictable... [deletia]s.
>>
>>             We have very different views, and I find quite difficult
>>             to accept yours. You are confusing my sample program
>>             which contains a single thread in a for loop with any
>>             other complex multi-threading concurrent system written
>>             in Java. For example, if you ever worked in a bank you
>>             surely know what I mean. You are comparing some random
>>             sleep() put into a program by some newbie, with the
>>             complex ecosystem of a concurrent platform written to
>>             manage trading information on very fast market. In that
>>             condition, I am sorry, statements such "...delayed
>>             timeout does not affect operation in a correctly
>>             functioning system..." and "...small time changes [...]
>>             are not a problem" are really not applicable. Let your
>>             system place an order three seconds late and your are out
>>             of the door so quickly you cannot even realize it.
>>
>>             But let's not limit ourselves to banks: how do you think
>>             your previous statements stands in these scenarios?
>>             - air control systems
>>             <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>             about a few seconds delay in control when fying planes?)
>>             - city traffic control systems
>>             <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>             if just for a couple of seconds all traffic lights become
>>             green?)
>>
>>             Not good enough.
>>
>>
>>                 ...small time changes as typically done via NTP
>>
>>             NTP is only one of the possible sources of this problem.
>>             The root of it is that the JVM is counting nanoseconds
>>             delays using absolute values based on a wallclock: I do
>>             not think it's that smart.
>>
>>
>>                 So there is an issue that needs to be addressed but
>>                 the situation is nowhere near as dire as you make out
>>
>>             Let's try to put this in perspective, shall we? In case
>>             the clock run backwards LockSupport.park() will be
>>             waiting for the nanoseconds requested plus the amount of
>>             seconds/minute/hours/days requested to compensate. Now,
>>             this primitive is used by almost *every* concurrency
>>             construct available on the platform, such as
>>             AbstractQueuedSynchronizer (and subclasses),
>>             ReentrantLock (and subclasses), CyclicBarrier,
>>             BlockingQueue (and subclasses), Executors, FutureTask,
>>             .... (too long to list them all, but I think we have the
>>             picture) and also low levels synchronization primitives
>>             of the language itself, so Object::wait(:long) and the
>>             related sychronized blocks.
>>
>>             I think it's pretty dire.
>>
>>
>>             Cheers,
>>
>>                 Bruno
>>
>>
>>
>>
>>
>>             On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
>>             <davidcholmes at aapt.net.au
>>             <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>                 Hi Bruno,
>>                 I have raised the priority on 6900441 (which to my
>>                 knowledge - and I created it! - has never been a
>>                 private bug).
>>                 A few notes on the "very frightening" aspect of this:
>>                 1. It doesn't affect "every JVM64 running on
>>                 Linux64". A fix has been introduced into a specific
>>                 glibc version for the futex-wait code such that it
>>                 now responds to changes in the system time for
>>                 absolute waits, where for all the years previous it
>>                 did not. The fix seems to have been applied in late
>>                 2011 or early 2012 but I don't know the exact glibc
>>                 version. There is also a 32-bit version of the fix
>>                 that was proposed on Nov 27, 2012, so it will
>>                 eventually make its way into 32-bit linux too.
>>                 2. The effects of this is not that "all the threads
>>                 parked will hang, with
>>                 unpredictable/corrupted/useless"! The effects are
>>                 very simple an quite predictable. If the system time
>>                 goes forward then timed-waits (Object.wait,
>>                 LockSupport.park) (which should be relative times)
>>                 will return early as the absolute-time that the
>>                 relative time was converted to will be seen to have
>>                 been reached (Thread.sleep contains a guard against
>>                 early returns). This is not actually a problem as you
>>                 can not distinguish this case from a "spurious
>>                 wakeup" which code is supposed to account for. If the
>>                 time is changed backwards then these timed-waits &
>>                 sleeps will not timeout when expected as the the for
>>                 that is now further in the future, by the amount of
>>                 the backward time change. Hence small time changes as
>>                 typically done via NTP are NOT a problem. Timed-waits
>>                 use timeouts as a heuristics for recovering when the
>>                 expected real event notification does not occur - so
>>                 a delayed timeout does not affect operation in a
>>                 correctly functioning system. Early timeouts are
>>                 indistinguishable from spurious wakeups, which code
>>                 has to account for, so again not a problem for
>>                 regular code. The only time a significant "hang" will
>>                 occur is with Thread.sleep and a large backward time
>>                 shift - but there is little real code that uses
>>                 Thread.sleep in any critical way.
>>                 So there is an issue that needs to be addressed but
>>                 the situation is nowhere near as dire as you make out.
>>                 David Holmes
>>
>>                     -----Original Message-----
>>                     *From:*
>>                     concurrency-interest-bounces at cs.oswego.edu
>>                     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>                     [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>                     Behalf Of *bruno bossola
>>                     *Sent:* Wednesday, 4 September 2013 1:56 AM
>>                     *To:* concurrency-interest at cs.oswego.edu
>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>                     *Subject:* [concurrency-interest] Outstanding
>>                     concurrency JVM issue - feedback?
>>
>>                     Hi all,
>>
>>                     I am writing here following a suggestion by Ben
>>                     Evans. I wanted to check with you about an issue
>>                     that my teams found on the JVM and that's very
>>                     frightening. I already started the discussion
>>                     with the engineers of the hotspot VM team but it
>>                     looks like we need more awareness to solve this
>>                     one and I'd really appreciate some help and some
>>                     push :)
>>                     It looks to me that this issue is affecting every
>>                     JVM64 running on Linux64, so imho it's quite
>>                     important to be looked at.
>>
>>                     *Executive summary
>>                     *The implementation of the concurrency primitive
>>                     LockSupport.parkNanos(), the function that
>>                     controls most concurrency primitive on the JVM,
>>                     is flawed, and any NTP sync, or system time
>>                     change, can potentially break it with unexpected
>>                     results across the board.
>>
>>                     *What we need to do?
>>                     *This is an old issue, and the bug
>>                     <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>                     was declared private. I somehow managed to have
>>                     the bug reopened to the public, but it's still a 
>>                     P4, that means that probably won't be fixed. I
>>                     think we need to push for a resolution ASAP, be
>>                     sure that's in for JDK9, make all the possible
>>                     effort to make this fix for JDK8 or, at least, to
>>                     include it in a later patch release. In an ideal
>>                     world it would be nice to have a patch for JDK7.
>>                     As far as I understand the hotspot engineering
>>                     team works based on priorities: being this
>>                     qualified as P4 means it won't be probably worked
>>                     on (if you follow the breadcrumbs of bugs and
>>                     fixes you can go back to 2002!) They acknowledge
>>                     the problem, it has been flagged to management,
>>                     but 1) it's low priority 2) it's too risky to fix
>>                     for JDK8
>>
>>
>>                     *Why all this urgency?
>>                     *If a system time change happens then all the
>>                     threads parked will hang, with
>>                     unpredictable/corrupted/useless results to the
>>                     end user. Same applies to Future, Queue,
>>                     Executor, and (I guess) any other construct that
>>                     it's somehow related to concurrency. This is a
>>                     big issue for us and for any near time
>>                     application: please think about trading and
>>                     betting, where the JVM is largely used, and  do
>>                     not restrain yourself to the Java language: add
>>                     Scala and any other JVM-based language to the
>>                     picture (JRuby, Jython...)
>>
>>                     *Tech details**
>>                     *To be more clear about the issue, the extent of
>>                     it and the concurrency library, let me introduce
>>                     this very simple program:
>>
>>                     import java.util.concurrent.locks.LockSupport;
>>
>>                     public class Main {
>>
>>                         public static void main(String[] args) {
>>
>>                             for (int i=100; i>0; i--) {
>>                     System.out.println(i);
>>                     LockSupport.parkNanos(1000L*1000L*1000L);
>>                             }
>>
>>                     System.out.println("Done!");
>>                         }
>>                     }
>>
>>                     Run it with a 64bit 1.6+ JVM on 64bit Linux, turn
>>                     the clock down one hour and wait until the
>>                     counter stops... magic!  I tested this on JDK6,
>>                     JDK7 and latest JDK8 beta running on various
>>                     Ubuntu distros. It's not just a matter of (old?)
>>                     sleep() and wait() primitives, this issue it
>>                     affects the whole concurrency library.
>>
>>                     To prove that this is fixable, I reimplemented
>>                     the program above above substituting
>>                     LockSupport.parkNanos() with  a JNI call to
>>                     clock_nanosleep(CLOCK_MONOTONIC...): works like a
>>                     charm :(
>>
>>                     This is due to the fact  that the CPP code is
>>                     calling the pthread_cond_timedwait() using its
>>                     default clock (CLOCK_REALTIME) which,
>>                     unfortunately is affected by
>>                     settime()/settimeofday() calls (on Linux): for
>>                     that reason it cannot be used to measure
>>                     nanoseconds delays, which is what the
>>                     specification
>>                     <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>                     requires. CLOCK_REALTIME is not guaranteed to
>>                     monotonically count as this is the actual "system
>>                     time": each time my system syncs time using a NTP
>>                     server on the net, the time might jump forward or
>>                     backward. The correct call (again on Linux) 
>>                     would require to use CLOCK_MONOTONIC as clock id,
>>                     which are defined by POSIX specs since 2002. (or
>>                     better CLOCK_MONOTONIC_RAW)
>>
>>                     The POSIX spec
>>                     <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>                     is infact clear, as it states "...setting the
>>                     value of the CLOCK_REALTIME clock via
>>                     clock_settime() shall have no effect on threads
>>                     that are blocked waiting for a *relative* time
>>                     service based upon this clock...": it definitely
>>                     states "relative".  Having a look at the hotspot
>>                     code
>>                     <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>                     it appears that the park() is using
>>                     compute_abstime() (which uses timeofday) and then
>>                     waits on an absolute period: for that reason it's
>>                     influenced by the system clock change. *Very wrong*.
>>
>>                     I will be happy to know what you think, and if
>>                     you can help me to escalate this issue I think
>>                     that the all Java community will benefit from it.
>>
>>                     Cheers,
>>
>>                         Bruno
>>
>>
>>             No virus found in this message.
>>             Checked by AVG - www.avg.com <http://www.avg.com>
>>             Version: 2013.0.3392 / Virus Database: 3222/6633 -
>>             Release Date: 09/03/13
>>
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130904/1422319f/attachment-0001.html>

From bbossola at gmail.com  Wed Sep  4 21:12:37 2013
From: bbossola at gmail.com (bruno bossola)
Date: Thu, 5 Sep 2013 02:12:37 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5227759F.7060300@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
Message-ID: <CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>

Hi Oaleksandr,

Please apologize me if my english was not good enough to provide you an
example that make sense: for that reason I decided to go back to a binary
deliverable (code) that shows the problem, hope this helps!

This is my PreciousPool class, that handles Precious resources:

import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class PreciousPool {

    public static class Precious {
        private final int id;

        private Precious() {
            this.id = 100+(int)(Math.random()*900.0);
        }

        public String toString() {
            return "Precious n."+id;
        }
    }

    private final Lock lock;
    private final Condition ready;
    private final long timeoutInMillis;

    private final List<Precious> preciousLended;
    private final List<Precious> preciousAvailable;

    public PreciousPool(int size, long timeoutInSeconds) {
        this.lock = new ReentrantLock();
        this.ready = lock.newCondition();

        this.timeoutInMillis = 1000L*timeoutInSeconds;
        this.preciousLended =  new ArrayList<Precious>();
        this.preciousAvailable = new ArrayList<Precious>();

        for (int i = 0; i < size; i++) {
            preciousAvailable.add(new Precious());
        }
    }

    public Precious obtain()  {
        lock.lock();
        try {
            // if no precious are available we wait for the specified
timeout (releasing the lock so that others can try)
            if (preciousAvailable.size() == 0) {
                try {
                    ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    throw new RuntimeException("Somebody interrupted me!",
e);
                }
            }

            // if a precious is available we unload it and return to the
caller, otherwise null
            if (preciousAvailable.size() > 0) {
                Precious value = preciousAvailable.remove(0);
                preciousLended.add(value);
                return value;
            } else {
                return null;
            }
        } finally {
            lock.unlock();
        }
    }

    public void release(Precious value) {
        lock.lock();
        try {
            if (!preciousLended.remove(value))
                throw new RuntimeException("Element "+value+" was not
lended!");

            // if a precious is returned we put it back and signal to
anybody waiting
            preciousAvailable.add(value);
            ready.signalAll();
        } finally {
            lock.unlock();
        }
    }

    public static void main(String args[]) {
        final int size = 3;
        final PreciousPool pool = new PreciousPool(size, 5);

        // let's exhaust the pool
        for (int i=0; i<size; i++)
            dump(pool.obtain());

        // and as we are stubborn we continuosly ask for a new one
        while(true) {
            dump(pool.obtain());
        }
    }

    private static void dump(Precious precious) {
        if (precious == null)
            log("I did not get my precious :(");
        else
            log("I did get my precious! "+precious);
    }

    private static void log(String message) {
        final String now = new SimpleDateFormat("HH:mm:ss:SSSS
").format(new Date());
        System.out.println(now + message);
    }
}

So, the main is a single thread (no need for multithreading here, let's
keep it simple), that first exhaust the whole pool and then keep asking,
without success, for a resource. Stubborn guy, I say, but it happens. If
you run this program everything works as expected: you are greeted by a
three successful Precious and then an endless list of failures, that it
continuously grow. All good :)

02:34:40:0061 I did get my precious! Precious n.156
02:34:40:0062 I did get my precious! Precious n.991
02:34:40:0062 I did get my precious! Precious n.953
02:34:45:0064 I did not get my precious :(
02:34:50:0065 I did not get my precious :(
02:34:55:0066 I did not get my precious :(
02:35:00:0067 I did not get my precious :(
02:35:05:0068 I did not get my precious :(
[...]

But guess what happens when, while the program is running, I change the
date of my system back of one hour? Everything stops,  it's simple as that.
No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
wait one hour in order to have my program restored to his normal process,
but as a customer I won't be terribly happy :)

I hope my point is now clear.
Cheers,

    Bruno






On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  n 04/09/2013 18:54, bruno bossola wrote:
>
>   Hi Oleksandr,
>
> Where in the design of those systems is a real-time timer? The one that
>> delivers time events uncompromised even by GC latency?
>>
>
>>
>  I don't think so :) If somebody needs a real time implementation he needs
> to go for a real time JVM, like Jean correctly pointed out.  The
> concurrency primitives are depending on LockSupport.parkNanos(...) to park
> a thread: if this for any reason is not working (like it is) then strange
> things may happen.
>
> Your assumption is that it is not working, if the elapsed time is longer.
> This is the flawed assumption.
>
> Also, you need to read fine print on those "real time" JVMs. The catch is
> in the definition of "real time".
>
>
>
>
>  Imagine, for example, that you are using a ReentrantLock to control a
> very precious resource used across the board (what about a database
> connection pool?) and you are unlucky enough to have a system time change
> (backwards) while you are locking: all the threads that want to use such
> resource will be progressively locked: not forever, but for the amount of
> time the clock went back. Probably most (all?) of your system freezes, and
> the only option you have is to wait, or restart.
>  Now place this in a large application server, that provide services for
> hunreds (thousands) of users. How does it sound to you?
>
> It sounds like you don't understand how the locks work.
>
>
> Alex
>
>
>
>  BTW, at the moment we could have a watchdog (in Python :)) that restarts
> it, but, I dunno why, I don't like it a lot...
>
>  Cheers,
>
>      Bruno
>
>
>
>>
>
> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  You are missing the point.
>>
>> Where in the design of those systems is a real-time timer? The one that
>> delivers time events uncompromised even by GC latency?
>>
>> The whole concurrency lot does not depend on the timeout magnitude for
>> correctness.
>>
>> Alex
>>
>>
>> On 04/09/2013 12:05, bruno bossola wrote:
>>
>>   Hi David
>>
>>
>>  bugs.sun.com is not a live reflection of the bug database but gets
>>> updated periodically (every 12 hours I think).
>>>
>>
>>>
>> Good to know :) I will be eagerly clicking on it to discover the new
>> priority! Thanks for that, I really appreciate it.
>>
>>
>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>> have an older version this does not impact you.
>>>
>>
>>>
>> You saw my list: nobody will use an older Kernel/glibc version in
>> production.
>>
>>
>> As for the rest, show me real code in such systems that rely on sleep for
>>> correctness or performance/timeliness and I will show you broken code.
>>
>>
>>>
>>  You are still hitting about the sleep(), I understand and I agree about
>> this. But here we are not talking about sleeps: we are talking about the
>> whole concurrency lot. And yes, as I already said, we are talking about
>> near time systems, like trading application, betting applications, air
>> traffic control systems, car traffic control systems. Don't you think this
>> bug might place Oracle JVM outside of these markets?
>>
>>
>>
>>> If this was as dire as you make out do you not think that this issue
>>> would have been raised far more than it has? [....] prudent
>>> developers/companies trial platform upgrades to check for these kinds of
>>> issues before switching to them in production environments.
>>>
>>>  I am waiting now for the part where you say that we should throw away
>> Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
>> action "in the middle", and I think that Oracle cannot oversee that. For
>> example a lot of trading software system can be installed on premises,
>> where you usually have no control over the environment: what I would do is
>> to put a native daemon in my app so that if I see the system clock change I
>> would kill myself, just in case. And this is a solution that I know for a
>> fact (sorry, I cannot make a reference) it's used in production in a very
>> important trading application.
>>
>> Regarding that specific bug, it was not accessible to the external until
>> two days ago, so I guess nobody really knew a lot about it, but I will make
>> sure it will :) so that we can get more traction.
>>
>>  Cheers,
>>
>>      Bruno
>>
>>
>>
>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>
>>>  Bruno,
>>>
>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>> updated periodically (every 12 hours I think).
>>>
>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>> have an older version this does not impact you.
>>>
>>> As for the rest, show me real code in such systems that rely on sleep
>>> for correctness or performance/timeliness and I will show you broken
>>> code. We are not talking about real-time systems here. park(nanos)/wait(millis)
>>> will only be affected by the backward time change if the real notification
>>> they are waiting for does not happen. Timeouts with these APIs are
>>> heuristics, they are defensive programming to cover the case "what if the
>>> notification I'm waiting for does not come". The code that would be
>>> affected by this issue is a very small % of the code that uses the API.
>>>
>>> If this was as dire as you make out do you not think that this issue
>>> would have been raised far more than it has? This issue does need
>>> addressing because the number of affected systems will grow as these newer
>>> linux systems are adopted, but prudent developers/companies trial platform
>>> upgrades to check for these kinds of issues before swicthing to them in
>>> production environments.
>>>
>>> Regards,
>>> David
>>>
>>>  -----Original Message-----
>>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>>> *To:* dholmes at ieee.org
>>> *Cc:* concurrency-interest at cs.oswego.edu
>>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM issue
>>> - feedback?
>>>
>>>    Hi David,
>>>
>>>  thanks for following up.
>>>
>>>
>>>
>>>> I have raised the priority on 6900441
>>>>
>>>
>>>
>>>  Thanks, but it looks still like a P4:
>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>> See also the attached snapshot, just in case it changes :)
>>>
>>>  [image: Inline image 2]
>>>
>>>  [...] which to my knowledge [...] has never been a private bug
>>>>
>>>
>>> It was not accessible using bugs.sun.com, this was translated to
>>> private. I also received the same info indirectly from the 7u lead:
>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>>> bugs.sun.com)", I guess you can check with him.
>>>
>>>
>>>  It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>>> introduced into a specific glibc version...
>>>>
>>>
>>> ...and apparently did not make it. I was able to reproduce this even
>>> with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>> 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on
>>> JDK4 everything works (that's the reason why I call it a regression). (ah,
>>> if you look at the bug, it lists also JDK5, so I think we are pretty much
>>> covered here).
>>> If you still have doubts tough, please have also a look on stackoverflow
>>> to see how it was reproduced consistently on probably every 64bitJVM over
>>> 64bitLinux in the world.
>>>
>>>
>>>  The effects of this is not that "all the threads parked will hang,
>>>> with unpredictable/corrupted/useless"! The effects are very simple an quite
>>>> predictable... [deletia]s.
>>>
>>>
>>>
>>> We have very different views, and I find quite difficult to accept
>>> yours. You are confusing my sample program which contains a single thread
>>> in a for loop with any other complex multi-threading concurrent system
>>> written in Java. For example, if you ever worked in a bank you surely know
>>> what I mean. You are comparing some random sleep() put into a program by
>>> some newbie, with the complex ecosystem of a concurrent platform written to
>>> manage trading information on very fast market. In that condition, I am
>>> sorry, statements such "...delayed timeout does not affect operation in a
>>> correctly functioning system..." and "...small time changes [...] are not a
>>> problem" are really not applicable. Let your system place an order three
>>> seconds late and your are out of the door so quickly you cannot even
>>> realize it.
>>>
>>>  But let's not limit ourselves to banks: how do you think your previous
>>> statements stands in these scenarios?
>>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>> about a few seconds delay in control when fying planes?)
>>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>> if just for a couple of seconds all traffic lights become green?)
>>>
>>>  Not good enough.
>>>
>>>
>>>  ...small time changes as typically done via NTP
>>>
>>>
>>>
>>> NTP is only one of the possible sources of this problem. The root of it
>>> is that the JVM is counting nanoseconds delays using absolute values based
>>> on a wallclock: I do not think it's that smart.
>>>
>>>
>>>   So there is an issue that needs to be addressed but the situation is
>>>> nowhere near as dire as you make out
>>>>
>>>
>>>
>>>  Let's try to put this in perspective, shall we? In case the clock run
>>> backwards LockSupport.park() will be waiting for the nanoseconds requested
>>> plus the amount of seconds/minute/hours/days requested to compensate. Now,
>>> this primitive is used by almost *every* concurrency construct available on
>>> the platform, such as AbstractQueuedSynchronizer (and subclasses),
>>> ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
>>> subclasses), Executors, FutureTask, .... (too long to list them all, but I
>>> think we have the picture) and also low levels synchronization primitives
>>> of the language itself, so Object::wait(:long) and the related sychronized
>>> blocks.
>>>
>>>  I think it's pretty dire.
>>>
>>>
>>>  Cheers,
>>>
>>>      Bruno
>>>
>>>
>>>
>>>
>>>
>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>>
>>>>  Hi Bruno,
>>>>
>>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>>> created it! - has never been a private bug).
>>>>
>>>> A few notes on the "very frightening" aspect of this:
>>>>
>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>>>> introduced into a specific glibc version for the futex-wait code such that
>>>> it now responds to changes in the system time for absolute waits, where for
>>>> all the years previous it did not. The fix seems to have been applied in
>>>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>>>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>>>> will eventually make its way into 32-bit linux too.
>>>>
>>>> 2. The effects of this is not that "all the threads parked will hang,
>>>> with unpredictable/corrupted/useless"! The effects are very simple an
>>>> quite predictable. If the system time goes forward then timed-waits
>>>> (Object.wait, LockSupport.park) (which should be relative times) will
>>>> return early as the absolute-time that the relative time was converted to
>>>> will be seen to have been reached (Thread.sleep contains a guard against
>>>> early returns). This is not actually a problem as you can not distinguish
>>>> this case from a "spurious wakeup" which code is supposed to account
>>>> for. If the time is changed backwards then these timed-waits & sleeps will
>>>> not timeout when expected as the the for that is now further in the future,
>>>> by the amount of the backward time change. Hence small time changes as
>>>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>>>> heuristics for recovering when the expected real event notification does
>>>> not occur - so a delayed timeout does not affect operation in a correctly
>>>> functioning system. Early timeouts are indistinguishable from spurious
>>>> wakeups, which code has to account for, so again not a problem for regular
>>>> code. The only time a significant "hang" will occur is with Thread.sleep
>>>> and a large backward time shift - but there is little real code that uses
>>>> Thread.sleep in any critical way.
>>>>
>>>> So there is an issue that needs to be addressed but the situation is
>>>> nowhere near as dire as you make out.
>>>>
>>>> David Holmes
>>>>
>>>> -----Original Message-----
>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
>>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>> *To:* concurrency-interest at cs.oswego.edu
>>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>>>> feedback?
>>>>
>>>>   Hi all,
>>>>
>>>> I am writing here following a suggestion by Ben Evans. I wanted to
>>>> check with you about an issue that my teams found on the JVM and that's
>>>> very frightening. I already started the discussion with the engineers of
>>>> the hotspot VM team but it looks like we need more awareness to solve this
>>>> one and I'd really appreciate some help and some push :)
>>>>  It looks to me that this issue is affecting every JVM64 running on
>>>> Linux64, so imho it's quite important to be looked at.
>>>>
>>>> *Executive summary
>>>> *The implementation of the concurrency primitive
>>>> LockSupport.parkNanos(), the function that controls most concurrency
>>>> primitive on the JVM, is flawed, and any NTP sync, or system time change,
>>>> can potentially break it with unexpected results across the board.
>>>>
>>>> *What we need to do?
>>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>>> include it in a later patch release. In an ideal world it would be nice to
>>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>>> works based on priorities: being this qualified as P4 means it won't be
>>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>
>>>>
>>>> *Why all this urgency?
>>>> *If a system time change happens then all the threads parked will
>>>> hang, with unpredictable/corrupted/useless results to the end user. Same
>>>> applies to Future, Queue, Executor, and (I guess) any other construct that
>>>> it's somehow related to concurrency. This is a big issue for us and for any
>>>> near time application: please think about trading and betting, where the
>>>> JVM is largely used, and  do not restrain yourself to the Java language:
>>>> add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>
>>>> *Tech details**
>>>> *To be more clear about the issue, the extent of it and the
>>>> concurrency library, let me introduce this very simple program:
>>>>
>>>> import java.util.concurrent.locks.LockSupport;
>>>>
>>>> public class Main {
>>>>
>>>>     public static void main(String[] args) {
>>>>
>>>>         for (int i=100; i>0; i--) {
>>>>             System.out.println(i);
>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>         }
>>>>
>>>>         System.out.println("Done!");
>>>>     }
>>>> }
>>>>
>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>>> whole concurrency library.
>>>>
>>>>  To prove that this is fixable, I reimplemented the program above
>>>> above substituting  LockSupport.parkNanos()  with  a JNI call to
>>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>
>>>>  This is due to the fact  that the CPP code is calling the
>>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is the
>>>> actual "system time": each time my system syncs time using a NTP server on
>>>> the net, the time might jump forward or backward. The correct call (again
>>>> on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are
>>>> defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>>>
>>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>>> clock via clock_settime() shall have no effect on threads that are blocked
>>>> waiting for a *relative* time service based upon this clock...": it
>>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>> it appears that the park() is using compute_abstime() (which uses
>>>> timeofday) and then waits on an absolute period: for that reason it's
>>>> influenced by the system clock change. *Very wrong*.
>>>>
>>>>  I will be happy to know what you think, and if you can help me to
>>>> escalate this issue I think that the all Java community will benefit from
>>>> it.
>>>>
>>>> Cheers,
>>>>
>>>>      Bruno
>>>>
>>>>
>>>   No virus found in this message.
>>> Checked by AVG - www.avg.com
>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date: 09/03/13
>>>
>>>
>>
>>
>>   _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/7db72cee/attachment-0001.html>

From davidcholmes at aapt.net.au  Wed Sep  4 22:27:34 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 5 Sep 2013 12:27:34 +1000
Subject: [concurrency-interest] Outstanding concurrency JVM issue
	-feedback?
In-Reply-To: <CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEELKAAA.davidcholmes@aapt.net.au>

Bruno,

The issue is not that a problem can exist in some code - we already know
that is the case and we know exactly how it will manifest. The problem is
your claim "we are talking about the whole concurrency lot" and "all the
threads parked will hang, with unpredictable/corrupted/useless" - which is
simply untrue.

Anyway I am working to get this fixed.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno
bossola
  Sent: Thursday, 5 September 2013 11:13 AM
  To: Oleksandr Otenko
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Outstanding concurrency JVM
issue -feedback?


  Hi Oaleksandr,


  Please apologize me if my english was not good enough to provide you an
example that make sense: for that reason I decided to go back to a binary
deliverable (code) that shows the problem, hope this helps!


  This is my PreciousPool class, that handles Precious resources:

  import java.text.SimpleDateFormat;
  import java.util.ArrayList;
  import java.util.Date;
  import java.util.List;
  import java.util.concurrent.TimeUnit;
  import java.util.concurrent.locks.Condition;
  import java.util.concurrent.locks.Lock;
  import java.util.concurrent.locks.ReentrantLock;

  public class PreciousPool {

      public static class Precious {
          private final int id;

          private Precious() {
              this.id = 100+(int)(Math.random()*900.0);
          }

          public String toString() {
              return "Precious n."+id;
          }
      }

      private final Lock lock;
      private final Condition ready;
      private final long timeoutInMillis;

      private final List<Precious> preciousLended;
      private final List<Precious> preciousAvailable;

      public PreciousPool(int size, long timeoutInSeconds) {
          this.lock = new ReentrantLock();
          this.ready = lock.newCondition();

          this.timeoutInMillis = 1000L*timeoutInSeconds;
          this.preciousLended =  new ArrayList<Precious>();
          this.preciousAvailable = new ArrayList<Precious>();

          for (int i = 0; i < size; i++) {
              preciousAvailable.add(new Precious());
          }
      }

      public Precious obtain()  {
          lock.lock();
          try {
              // if no precious are available we wait for the specified
timeout (releasing the lock so that others can try)
              if (preciousAvailable.size() == 0) {
                  try {
                      ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
                  } catch (InterruptedException e) {
                      Thread.currentThread().interrupt();
                      throw new RuntimeException("Somebody interrupted me!",
e);
                  }
              }

              // if a precious is available we unload it and return to the
caller, otherwise null
              if (preciousAvailable.size() > 0) {
                  Precious value = preciousAvailable.remove(0);
                  preciousLended.add(value);
                  return value;
              } else {
                  return null;
              }
          } finally {
              lock.unlock();
          }
      }

      public void release(Precious value) {
          lock.lock();
          try {
              if (!preciousLended.remove(value))
                  throw new RuntimeException("Element "+value+" was not
lended!");

              // if a precious is returned we put it back and signal to
anybody waiting
              preciousAvailable.add(value);
              ready.signalAll();
          } finally {
              lock.unlock();
          }
      }

      public static void main(String args[]) {
          final int size = 3;
          final PreciousPool pool = new PreciousPool(size, 5);

          // let's exhaust the pool
          for (int i=0; i<size; i++)
              dump(pool.obtain());

          // and as we are stubborn we continuosly ask for a new one
          while(true) {
              dump(pool.obtain());
          }
      }

      private static void dump(Precious precious) {
          if (precious == null)
              log("I did not get my precious :(");
          else
              log("I did get my precious! "+precious);
      }

      private static void log(String message) {
          final String now = new SimpleDateFormat("HH:mm:ss:SSSS
").format(new Date());
          System.out.println(now + message);
      }
  }


  So, the main is a single thread (no need for multithreading here, let's
keep it simple), that first exhaust the whole pool and then keep asking,
without success, for a resource. Stubborn guy, I say, but it happens. If you
run this program everything works as expected: you are greeted by a three
successful Precious and then an endless list of failures, that it
continuously grow. All good :)

  02:34:40:0061 I did get my precious! Precious n.156
  02:34:40:0062 I did get my precious! Precious n.991
  02:34:40:0062 I did get my precious! Precious n.953
  02:34:45:0064 I did not get my precious :(
  02:34:50:0065 I did not get my precious :(
  02:34:55:0066 I did not get my precious :(
  02:35:00:0067 I did not get my precious :(
  02:35:05:0068 I did not get my precious :(
  [...]


  But guess what happens when, while the program is running, I change the
date of my system back of one hour? Everything stops,  it's simple as that.
No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
wait one hour in order to have my program restored to his normal process,
but as a customer I won't be terribly happy :)


  I hope my point is now clear.

  Cheers,


      Bruno










  On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
<oleksandr.otenko at oracle.com> wrote:

    n 04/09/2013 18:54, bruno bossola wrote:

      Hi Oleksandr,


        Where in the design of those systems is a real-time timer? The one
that delivers time events uncompromised even by GC latency?


      I don't think so :) If somebody needs a real time implementation he
needs to go for a real time JVM, like Jean correctly pointed out.  The
concurrency primitives are depending on LockSupport.parkNanos(...) to park a
thread: if this for any reason is not working (like it is) then strange
things may happen.

    Your assumption is that it is not working, if the elapsed time is
longer. This is the flawed assumption.

    Also, you need to read fine print on those "real time" JVMs. The catch
is in the definition of "real time".





      Imagine, for example, that you are using a ReentrantLock to control a
very precious resource used across the board (what about a database
connection pool?) and you are unlucky enough to have a system time change
(backwards) while you are locking: all the threads that want to use such
resource will be progressively locked: not forever, but for the amount of
time the clock went back. Probably most (all?) of your system freezes, and
the only option you have is to wait, or restart.

      Now place this in a large application server, that provide services
for hunreds (thousands) of users. How does it sound to you?

    It sounds like you don't understand how the locks work.


    Alex





      BTW, at the moment we could have a watchdog (in Python :)) that
restarts it, but, I dunno why, I don't like it a lot...


      Cheers,


          Bruno









      On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
<oleksandr.otenko at oracle.com> wrote:

        You are missing the point.

        Where in the design of those systems is a real-time timer? The one
that delivers time events uncompromised even by GC latency?

        The whole concurrency lot does not depend on the timeout magnitude
for correctness.

        Alex



        On 04/09/2013 12:05, bruno bossola wrote:

          Hi David




            bugs.sun.com is not a live reflection of the bug database but
gets updated periodically (every 12 hours I think).



          Good to know :) I will be eagerly clicking on it to discover the
new priority! Thanks for that, I really appreciate it.



            The issue arises on certain 64-bit linux kernel/glibc versions.
If you have an older version this does not impact you.


          You saw my list: nobody will use an older Kernel/glibc version in
production.



            As for the rest, show me real code in such systems that rely on
sleep for correctness or performance/timeliness and I will show you broken
code.

          You are still hitting about the sleep(), I understand and I agree
about this. But here we are not talking about sleeps: we are talking about
the whole concurrency lot. And yes, as I already said, we are talking about
near time systems, like trading application, betting applications, air
traffic control systems, car traffic control systems. Don't you think this
bug might place Oracle JVM outside of these markets?



            If this was as dire as you make out do you not think that this
issue would have been raised far more than it has? [....] prudent
developers/companies trial platform upgrades to check for these kinds of
issues before switching to them in production environments.


          I am waiting now for the part where you say that we should throw
away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
action "in the middle", and I think that Oracle cannot oversee that. For
example a lot of trading software system can be installed on premises, where
you usually have no control over the environment: what I would do is to put
a native daemon in my app so that if I see the system clock change I would
kill myself, just in case. And this is a solution that I know for a fact
(sorry, I cannot make a reference) it's used in production in a very
important trading application.

          Regarding that specific bug, it was not accessible to the external
until two days ago, so I guess nobody really knew a lot about it, but I will
make sure it will :) so that we can get more traction.


          Cheers,


              Bruno





          On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
<davidcholmes at aapt.net.au> wrote:

            Bruno,

            bugs.sun.com is not a live reflection of the bug database but
gets updated periodically (every 12 hours I think).

            The issue arises on certain 64-bit linux kernel/glibc versions.
If you have an older version this does not impact you.

            As for the rest, show me real code in such systems that rely on
sleep for correctness or performance/timeliness and I will show you broken
code. We are not talking about real-time systems here.
park(nanos)/wait(millis) will only be affected by the backward time change
if the real notification they are waiting for does not happen. Timeouts with
these APIs are heuristics, they are defensive programming to cover the case
"what if the notification I'm waiting for does not come". The code that
would be affected by this issue is a very small % of the code that uses the
API.

            If this was as dire as you make out do you not think that this
issue would have been raised far more than it has? This issue does need
addressing because the number of affected systems will grow as these newer
linux systems are adopted, but prudent developers/companies trial platform
upgrades to check for these kinds of issues before swicthing to them in
production environments.

            Regards,
            David
              -----Original Message-----
              From: bruno bossola [mailto:bbossola at gmail.com]
              Sent: Wednesday, 4 September 2013 11:14 AM
              To: dholmes at ieee.org
              Cc: concurrency-interest at cs.oswego.edu
              Subject: Re: [concurrency-interest] Outstanding concurrency
JVM issue - feedback?


              Hi David,


              thanks for following up.



                I have raised the priority on 6900441


              Thanks, but it looks still like a P4:
              http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
              See also the attached snapshot, just in case it changes :)






                [...] which to my knowledge [...] has never been a private
bug

              It was not accessible using bugs.sun.com, this was translated
to private. I also received the same info indirectly from the 7u lead:
              "I'm not sure why 6900441 isn't public. (I'll follow up with
owner of bugs.sun.com)", I guess you can check with him.




                It doesn't affect "every JVM64 running on Linux64".  A fix
has been introduced into a specific glibc version...

              ...and apparently did not make it. I was able to reproduce
this even with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu
10, 11, 12, 13 + some random Debian. I did not have a JDK5, so I cannot say,
but on JDK4 everything works (that's the reason why I call it a regression).
(ah, if you look at the bug, it lists also JDK5, so I think we are pretty
much covered here).
              If you still have doubts tough, please have also a look on
stackoverflow to see how it was reproduced consistently on probably every
64bitJVM over 64bitLinux in the world.




                The effects of this is not that "all the threads parked will
hang, with unpredictable/corrupted/useless"! The effects are very simple an
quite predictable... [deletia]s.

              We have very different views, and I find quite difficult to
accept yours. You are confusing my sample program which contains a single
thread in a for loop with any other complex multi-threading concurrent
system written in Java. For example, if you ever worked in a bank you surely
know what I mean. You are comparing some random sleep() put into a program
by some newbie, with the complex ecosystem of a concurrent platform written
to manage trading information on very fast market. In that condition, I am
sorry, statements such "...delayed timeout does not affect operation in a
correctly functioning system..." and "...small time changes [...] are not a
problem" are really not applicable. Let your system place an order three
seconds late and your are out of the door so quickly you cannot even realize
it.


              But let's not limit ourselves to banks: how do you think your
previous statements stands in these scenarios?
              - air control systems (what about a few seconds delay in
control when fying planes?)
              - city traffic control systems (what if just for a couple of
seconds all traffic lights become green?)



              Not good enough.




                ...small time changes as typically done via NTP

              NTP is only one of the possible sources of this problem. The
root of it is that the JVM is counting nanoseconds delays using absolute
values based on a wallclock: I do not think it's that smart.




                So there is an issue that needs to be addressed but the
situation is nowhere near as dire as you make out


              Let's try to put this in perspective, shall we? In case the
clock run backwards LockSupport.park() will be waiting for the nanoseconds
requested plus the amount of seconds/minute/hours/days requested to
compensate. Now, this primitive is used by almost *every* concurrency
construct available on the platform, such as AbstractQueuedSynchronizer (and
subclasses), ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue
(and subclasses), Executors, FutureTask, .... (too long to list them all,
but I think we have the picture) and also low levels synchronization
primitives of the language itself, so Object::wait(:long) and the related
sychronized blocks.


              I think it's pretty dire.




              Cheers,


                  Bruno









              On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
<davidcholmes at aapt.net.au> wrote:

                Hi Bruno,

                I have raised the priority on 6900441 (which to my
knowledge - and I created it! - has never been a private bug).

                A few notes on the "very frightening" aspect of this:

                1. It doesn't affect "every JVM64 running on Linux64". A fix
has been introduced into a specific glibc version for the futex-wait code
such that it now responds to changes in the system time for absolute waits,
where for all the years previous it did not. The fix seems to have been
applied in late 2011 or early 2012 but I don't know the exact glibc version.
There is also a 32-bit version of the fix that was proposed on Nov 27, 2012,
so it will eventually make its way into 32-bit linux too.

                2. The effects of this is not that "all the threads parked
will hang, with unpredictable/corrupted/useless"! The effects are very
simple an quite predictable. If the system time goes forward then
timed-waits (Object.wait, LockSupport.park) (which should be relative times)
will return early as the absolute-time that the relative time was converted
to will be seen to have been reached (Thread.sleep contains a guard against
early returns). This is not actually a problem as you can not distinguish
this case from a "spurious wakeup" which code is supposed to account for. If
the time is changed backwards then these timed-waits & sleeps will not
timeout when expected as the the for that is now further in the future, by
the amount of the backward time change. Hence small time changes as
typically done via NTP are NOT a problem. Timed-waits use timeouts as a
heuristics for recovering when the expected real event notification does not
occur - so a delayed timeout does not affect operation in a correctly
functioning system. Early timeouts are indistinguishable from spurious
wakeups, which code has to account for, so again not a problem for regular
code. The only time a significant "hang" will occur is with Thread.sleep and
a large backward time shift - but there is little real code that uses
Thread.sleep in any critical way.

                So there is an issue that needs to be addressed but the
situation is nowhere near as dire as you make out.

                David Holmes
                  -----Original Message-----
                  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno
bossola
                  Sent: Wednesday, 4 September 2013 1:56 AM
                  To: concurrency-interest at cs.oswego.edu
                  Subject: [concurrency-interest] Outstanding concurrency
JVM issue - feedback?


                  Hi all,

                  I am writing here following a suggestion by Ben Evans. I
wanted to check with you about an issue that my teams found on the JVM and
that's very frightening. I already started the discussion with the engineers
of the hotspot VM team but it looks like we need more awareness to solve
this one and I'd really appreciate some help and some push :)

                  It looks to me that this issue is affecting every JVM64
running on Linux64, so imho it's quite important to be looked at.

                  Executive summary
                  The implementation of the concurrency primitive
LockSupport.parkNanos(), the function that controls most concurrency
primitive on the JVM, is flawed, and any NTP sync, or system time change,
can potentially break it with unexpected results across the board.

                  What we need to do?
                  This is an old issue, and the bug was declared private. I
somehow managed to have the bug reopened to the public, but it's still a
P4, that means that probably won't be fixed. I think we need to push for a
resolution ASAP, be sure that's in for JDK9, make all the possible effort to
make this fix for JDK8 or, at least, to include it in a later patch release.
In an ideal world it would be nice to have a patch for JDK7. As far as I
understand the hotspot engineering team works based on priorities: being
this qualified as P4 means it won't be probably worked on (if you follow the
breadcrumbs of bugs and fixes you can go back to 2002!) They acknowledge the
problem, it has been flagged to management, but 1) it's low priority 2) it's
too risky to fix for JDK8


                  Why all this urgency?
                  If a system time change happens then all the threads
parked will hang, with unpredictable/corrupted/useless results to the end
user. Same applies to Future, Queue, Executor, and (I guess) any other
construct that it's somehow related to concurrency. This is a big issue for
us and for any near time application: please think about trading and
betting, where the JVM is largely used, and  do not restrain yourself to the
Java language: add Scala and any other JVM-based language to the picture
(JRuby, Jython...)

                  Tech details
                  To be more clear about the issue, the extent of it and the
concurrency library, let me introduce this very simple program:

                  import java.util.concurrent.locks.LockSupport;

                  public class Main {

                      public static void main(String[] args) {

                          for (int i=100; i>0; i--) {
                              System.out.println(i);
                              LockSupport.parkNanos(1000L*1000L*1000L);
                          }

                          System.out.println("Done!");
                      }
                  }

                  Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the
clock down one hour and wait until the counter stops... magic!  I tested
this on JDK6, JDK7 and latest JDK8 beta running on various Ubuntu distros.
It's not just a matter of (old?) sleep() and wait() primitives, this issue
it affects the whole concurrency library.


                  To prove that this is fixable, I reimplemented the program
above above substituting  LockSupport.parkNanos()  with  a JNI call to
clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(



                  This is due to the fact  that the CPP code is calling the
pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
unfortunately is affected by settime()/settimeofday() calls (on Linux): for
that reason it cannot be used to measure nanoseconds delays, which is what
the specification requires. CLOCK_REALTIME is not guaranteed to
monotonically count as this is the actual "system time": each time my system
syncs time using a NTP server on the net, the time might jump forward or
backward. The correct call (again on Linux)  would require to use
CLOCK_MONOTONIC as clock id, which are defined by POSIX specs since 2002.
(or better CLOCK_MONOTONIC_RAW)

                  The POSIX spec is infact clear, as it states "...setting
the value of the CLOCK_REALTIME clock via clock_settime() shall have no
effect on threads that are blocked waiting for a relative time service based
upon this clock...": it definitely states "relative".  Having a look at the
hotspot code, it appears that the park() is using compute_abstime() (which
uses timeofday) and then waits on an absolute period: for that reason it's
influenced by the system clock change. Very wrong.


                  I will be happy to know what you think, and if you can
help me to escalate this issue I think that the all Java community will
benefit from it.

                  Cheers,


                      Bruno


              No virus found in this message.
              Checked by AVG - www.avg.com
              Version: 2013.0.3392 / Virus Database: 3222/6633 - Release
Date: 09/03/13






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/e3b324a6/attachment-0001.html>

From howard.lovatt at gmail.com  Thu Sep  5 00:24:54 2013
From: howard.lovatt at gmail.com (Howard Lovatt)
Date: Thu, 5 Sep 2013 14:24:54 +1000
Subject: [concurrency-interest] Coordinated Runnables
In-Reply-To: <17354802-F051-4A26-90B4-6B48B84707D4@rkuhn.info>
References: <loom.20130829T134152-308@post.gmane.org>
	<CACuKZqESAPOuhU9Dw8uSDG=Dw8wR=HqtRGp1gQQdhZQsTzrmxA@mail.gmail.com>
	<CALCS1ZVfVMaqDO-EVF0b0jqiesmC+6B5_oFgDL6gK9qR2MJUQA@mail.gmail.com>
	<CANPzfU86zVgaE8hL5j+Jz1VWOJrzALv5Suy_vygvjw=Z7VoVQg@mail.gmail.com>
	<CALCS1ZV2sneM8Bd=Wa_DHPq8A+=MVJD=Ojh8JHxUgnTOvqUTQQ@mail.gmail.com>
	<17354802-F051-4A26-90B4-6B48B84707D4@rkuhn.info>
Message-ID: <CACR_FB4G+7jr-Jb+-SyRgGBU=XAV2vqk2J=GNDzjshwryxdAmA@mail.gmail.com>

Hi Alexei,

For this type of problem I use my own Graph library, works well for me. See
below for an example. It might give you some ideas at least.

 -- Howard.

===========================================================================

package graph;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import static java.lang.System.*;
import java.util.concurrent.Callable;
import java.util.concurrent.Future;

/**
 * Basic Graph classes.
 *
 * @author Howard Lovatt
 */
public class Graph {

  @FunctionalInterface
  public interface Action0 extends Callable<Void> {
    void act() throws Exception;

    default Void call() throws Exception {
      act();
      return null;
    }

    @SuppressWarnings("rawtypes")
    static Action0 none = () -> {};
  }

  @FunctionalInterface
  public interface Action1<E1> {
    void act(E1 e1) throws Exception;

    @SuppressWarnings("rawtypes")
    static Action1 none = (notUsed) -> {};
  }

  public static class Vertex1<E1> {

    protected final Object action;

    protected E1 e1 = null;

    protected E1 currentE1;

    protected volatile boolean actionRequired = false;

    protected Vertex1(final Object action) {
      this.action = action;
    }

    public Vertex1(final Action1<E1> action) {
      this((Object) (action == null ? Action1.none : action));
    }

    public boolean maybeSetE1(final E1 e1) throws Exception {
      synchronized (this) {
        if (this.e1 != null) {
          return false;
        }
        this.e1 = e1;
        checkAction();
      }
      maybeDoAction();
      return true;
    }

    public void setE1(final E1 e1) throws Exception {
      for (;;) {
        if (this.e1 == null) {
          if (maybeSetE1(e1)) {
            return;
          }
        }
        checkInterrupt();
      }
    }

    public static void checkInterrupt() throws InterruptedException {
      if (Thread.interrupted()) {
        throw new InterruptedException();
      }
    }

    protected void checkAction() {
      if (e1 == null || actionRequired) {
        return;
      }
      actionRequired = true;
      currentE1 = e1;
      e1 = null;
    }

    @SuppressWarnings("unchecked")
    protected void maybeDoAction() throws Exception {
      if (!actionRequired) {
        return;
      }
      ((Action1<E1>) action).act(currentE1);
      actionRequired = false;
    }
  }

  public static <E1> Vertex1<E1> v1(final Action1<E1> action) {
    return new Vertex1<>(action);
  }

  @FunctionalInterface
  public interface Action2<E1, E2> {
    void act(E1 e1, E2 e2) throws Exception;

    @SuppressWarnings("rawtypes")
    static Action2 none = (notUsed1, notUsed2) -> {};
  }

  public static class Vertex2<E1, E2> extends Vertex1<E1> {

    protected E2 e2 = null;

    protected E2 currentE2;

    public Vertex2(final Action2<E1, E2> action) {
      super((Object) (action == null ? Action2.none : action));
    }

    public synchronized boolean maybeSetE2(final E2 e2) throws Exception {
      synchronized (this) {
        if (this.e2 != null) {
          return false;
        }
        this.e2 = e2;
        checkAction();
      }
      maybeDoAction();
      return true;
    }

    public void setE2(final E2 e2) throws Exception {
      for (;;) {
        if (this.e2 == null) {
          if (maybeSetE2(e2)) {
            return;
          }
        }
        checkInterrupt();
      }
    }

    @Override
    protected void checkAction() {
      if (e1 == null || e2 == null || actionRequired) {
        return;
      }
      actionRequired = true;
      currentE1 = e1;
      currentE2 = e2;
      e1 = null;
      e2 = null;
    }

    @SuppressWarnings("unchecked")
    @Override
    protected void maybeDoAction() throws Exception {
      if (!actionRequired) {
        return;
      }
      ((Action2<E1, E2>) action).act(currentE1, currentE2);
      actionRequired = false;
    }
  }

  public static <E1, E2> Vertex2<E1, E2> v2(final Action2<E1, E2> action) {
    return new Vertex2<>(action);
  }

  public static class BufferingVertex<E> extends Vertex1<List<E>> {

    private volatile List<E> values = null;

    public BufferingVertex(final Action1<List<E>> action) {
      super(action);
    }

    public synchronized boolean maybeAdd(final E e) {
      if (values == null) {
        return false;
      }
      values.add(e);
      return true;
    }

    public void add(final E e) throws InterruptedException {
      for (;;) {
        if (values != null) {
          if (maybeAdd(e)) {
            return;
          }
        }
        checkInterrupt();
      }
    }

    @Override
    protected void checkAction() {
      if (e1 == null || actionRequired) {
        return;
      }
      actionRequired = true;
      currentE1 = values;
      values = e1;
      e1 = null;
    }
  }

  public static <E> BufferingVertex<E> bv(final Action1<List<E>> action) {
    return new BufferingVertex<>(action);
  }

  /**
   * Example graph.
   * Could well be better written using classes; but wanted to experiment
with lambdas!
   * </p>
   * <pre>
   * Input -&gt; Output &lt;- Control
   * </pre>
   *
   * @param notUsed Command line arguments not used.
   */
  public static void main(final String... notUsed) throws
InterruptedException {
    // Setup
    final AtomicBoolean end = new AtomicBoolean(false);
    final BufferingVertex<Integer> output = bv((list) -> {
      Thread.sleep(71); // Do some work
      if (list != null) { // First call to buffer's action marked by null
argument
        out.println(list);
        list.clear();
      }
    });
    final Action0 inputTask = () -> {
      for (int i = 0; i < 100; i++) {
        Thread.sleep(7); // Do some work!
        output.add(i);
      }
      end.set(true);
    };
    final List<Integer> values1 = new ArrayList<>();
    final List<Integer> values2 = new ArrayList<>();
    final Action0 controlTask = () -> {
      for (;;) {
        output.setE1(values1);
        if (end.get()) {
          output.setE1(values2); // Flush
          return;
        }
        output.setE1(values2);
        if (end.get()) {
          output.setE1(values1); // Flush
          return;
        }
      }
    };

    // Run
    final ExecutorService pool = Executors.newCachedThreadPool();
    final Future<Void> inputFuture = pool.submit(inputTask);
    final Future<Void> outputFuture = pool.submit(controlTask);
    pool.shutdown();
    final boolean ok = pool.awaitTermination(10, TimeUnit.SECONDS);
    pool.shutdownNow();
    out.println(ok ? "Terminated OK" : "Failed to terminate");
    try {
      inputFuture.get();
    } catch (final Exception e) {
      out.println("Input threw: " + e);
    }
    try {
      outputFuture.get();
    } catch (final Exception e) {
      out.println("Output threw: " + e);
    }
  }
}


On 30 August 2013 02:40, Roland Kuhn <rk at rkuhn.info> wrote:

> Hi Alexei,
>
> Akka implements the Actor Model as described by Carl Hewitt in 1973 quite
> closely (the deviations are not relevant for this discussion); what you
> describe is closer to CSP or the (synchronous) ? calculus. Asynchronous
> message passing results in a better decoupling of sender and receiver of a
> communication, which is the important distinction here.
>
> Petri nets can be used to model anything you want, including Actors or
> CSP, but directly implementing them will probably not achieve good
> scalability due to their synchronous (and therefore synchronized)
> transition semantics.
>
> Regards,
>
> *Dr. Roland Kuhn*
> *Akka Tech Lead*
> Typesafe ? Reactive apps on the JVM
> twitter: @rolandkuhn
>
> 29 aug 2013 kl. 18:24 skrev Alexei Kaigorodov:
>
>
> Place is a term in Petri Net model - place where tokens wait to be
> processed. "Of type queue" means that tokens are stored in a queue. Another
> possible type, for "colorless" tokens, is just a counter for events, like
> semaphore. Single means actors in Scala and Akka can have only one input
> place (queue) for messages, while Petri Net Nodes (transitions) can have
> several, and this is very  natural for asynchronous programming, as
> illustrated at the picture in the referenced googledoc paper.
>
> On Thu, Aug 29, 2013 at 11:04 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>> Single place of type queue <-- wdym?
>>
>>
>> On Thu, Aug 29, 2013 at 7:42 AM, Alexei Kaigorodov <
>> alexei.kaigorodov at gmail.com> wrote:
>>
>>> Yes it is an actor, in its initial meaning. But unfortunately, the term
>>> "actor" today mainly means restricted actor of Scala or Akka style (with
>>> single place of type queue), and I am in doubt if "actor" would not cause
>>> misunderstanding.
>>>
>>>
>>> On Thu, Aug 29, 2013 at 9:26 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>
>>>> Hi Alexei, if in your model one place can be connected to only one
>>>> transition, can't we model one transition with its input places as one
>>>> actor?
>>>>
>>>> Zhong Yu  ://cs.oswego.edu/mailman/listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>
>>>
>>>
>>
>>
>> --
>> *Viktor Klang*
>> *Director of Engineering*
>> Typesafe <http://www.typesafe.com/>
>>
>> Twitter: @viktorklang
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> --
> Simplicity and elegance are unpopular because they require hard work and
> discipline to achieve and education to be appreciated.
>   -- Dijkstra
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
  -- Howard.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/e8fd1876/attachment-0001.html>

From bbossola at gmail.com  Thu Sep  5 05:47:09 2013
From: bbossola at gmail.com (bruno bossola)
Date: Thu, 5 Sep 2013 10:47:09 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue
	-feedback?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEELKAAA.davidcholmes@aapt.net.au>
References: <CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEELKAAA.davidcholmes@aapt.net.au>
Message-ID: <CAJU-cA++M-faVGLGPJk=ZiLQjiL44VMLVA4rrqSScgcV4bWWvQ@mail.gmail.com>

Hi David,

Thanks for you answer and your support about this issue. Can you please
still confirm that such patch will NOT be available in JDK7 and JDK8? And
that you do not plan to ship it as an hotfix?

Regarding the previous statement, it depends of the lens you are looking at
that problem. I guess that that the GC threads will not be affected :), but
most of the other will be. Just for the sake of the experiment:
- make sure you are running Eclipse using a JVM 64bit on a 64bit Linux
- open Eclipse
- change the date of your system
- see Eclipse hanging :)

It's true, not all the JVM Eclipse threads will hang, and I do not know
which one(s) are causing/impactedby the issue, but the end result is that
the application freezes. And i just picked up one application that
sometimes I use... what about the rest?

Cheers,

    Bruno


On Thu, Sep 5, 2013 at 3:27 AM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> Bruno,
>
> The issue is not that a problem can exist in some code - we already know
> that is the case and we know exactly how it will manifest. The problem is
> your claim "we are talking about the whole concurrency lot" and "all the
> threads parked will hang, with unpredictable/corrupted/useless" - which
> is simply untrue.
>
> Anyway I am working to get this fixed.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno bossola
> *Sent:* Thursday, 5 September 2013 11:13 AM
> *To:* Oleksandr Otenko
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM issue
> -feedback?
>
>  Hi Oaleksandr,
>
> Please apologize me if my english was not good enough to provide you an
> example that make sense: for that reason I decided to go back to a binary
> deliverable (code) that shows the problem, hope this helps!
>
> This is my PreciousPool class, that handles Precious resources:
>
> import java.text.SimpleDateFormat;
> import java.util.ArrayList;
> import java.util.Date;
> import java.util.List;
> import java.util.concurrent.TimeUnit;
> import java.util.concurrent.locks.Condition;
> import java.util.concurrent.locks.Lock;
> import java.util.concurrent.locks.ReentrantLock;
>
> public class PreciousPool {
>
>     public static class Precious {
>         private final int id;
>
>         private Precious() {
>             this.id = 100+(int)(Math.random()*900.0);
>         }
>
>         public String toString() {
>             return "Precious n."+id;
>         }
>     }
>
>     private final Lock lock;
>     private final Condition ready;
>     private final long timeoutInMillis;
>
>     private final List<Precious> preciousLended;
>     private final List<Precious> preciousAvailable;
>
>     public PreciousPool(int size, long timeoutInSeconds) {
>         this.lock = new ReentrantLock();
>         this.ready = lock.newCondition();
>
>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>         this.preciousLended =  new ArrayList<Precious>();
>         this.preciousAvailable = new ArrayList<Precious>();
>
>         for (int i = 0; i < size; i++) {
>             preciousAvailable.add(new Precious());
>         }
>     }
>
>     public Precious obtain()  {
>         lock.lock();
>         try {
>             // if no precious are available we wait for the specified
> timeout (releasing the lock so that others can try)
>             if (preciousAvailable.size() == 0) {
>                 try {
>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>                 } catch (InterruptedException e) {
>                     Thread.currentThread().interrupt();
>                     throw new RuntimeException("Somebody interrupted me!",
> e);
>                 }
>             }
>
>             // if a precious is available we unload it and return to the
> caller, otherwise null
>             if (preciousAvailable.size() > 0) {
>                 Precious value = preciousAvailable.remove(0);
>                 preciousLended.add(value);
>                 return value;
>             } else {
>                 return null;
>             }
>         } finally {
>             lock.unlock();
>         }
>     }
>
>     public void release(Precious value) {
>         lock.lock();
>         try {
>             if (!preciousLended.remove(value))
>                 throw new RuntimeException("Element "+value+" was not
> lended!");
>
>             // if a precious is returned we put it back and signal to
> anybody waiting
>             preciousAvailable.add(value);
>             ready.signalAll();
>         } finally {
>             lock.unlock();
>         }
>     }
>
>     public static void main(String args[]) {
>         final int size = 3;
>         final PreciousPool pool = new PreciousPool(size, 5);
>
>         // let's exhaust the pool
>         for (int i=0; i<size; i++)
>             dump(pool.obtain());
>
>         // and as we are stubborn we continuosly ask for a new one
>         while(true) {
>             dump(pool.obtain());
>         }
>     }
>
>     private static void dump(Precious precious) {
>         if (precious == null)
>             log("I did not get my precious :(");
>         else
>             log("I did get my precious! "+precious);
>     }
>
>     private static void log(String message) {
>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS
> ").format(new Date());
>         System.out.println(now + message);
>     }
> }
>
> So, the main is a single thread (no need for multithreading here, let's
> keep it simple), that first exhaust the whole pool and then keep asking,
> without success, for a resource. Stubborn guy, I say, but it happens. If
> you run this program everything works as expected: you are greeted by a
> three successful Precious and then an endless list of failures, that it
> continuously grow. All good :)
>
> 02:34:40:0061 I did get my precious! Precious n.156
> 02:34:40:0062 I did get my precious! Precious n.991
> 02:34:40:0062 I did get my precious! Precious n.953
> 02:34:45:0064 I did not get my precious :(
> 02:34:50:0065 I did not get my precious :(
> 02:34:55:0066 I did not get my precious :(
> 02:35:00:0067 I did not get my precious :(
> 02:35:05:0068 I did not get my precious :(
> [...]
>
> But guess what happens when, while the program is running, I change the
> date of my system back of one hour? Everything stops,  it's simple as that.
> No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
> wait one hour in order to have my program restored to his normal process,
> but as a customer I won't be terribly happy :)
>
> I hope my point is now clear.
> Cheers,
>
>     Bruno
>
>
>
>
>
>
> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  n 04/09/2013 18:54, bruno bossola wrote:
>>
>>   Hi Oleksandr,
>>
>> Where in the design of those systems is a real-time timer? The one that
>>> delivers time events uncompromised even by GC latency?
>>>
>>
>>>
>> I don't think so :) If somebody needs a real time implementation he needs
>> to go for a real time JVM, like Jean correctly pointed out.  The
>> concurrency primitives are depending on LockSupport.parkNanos(...) to park
>> a thread: if this for any reason is not working (like it is) then strange
>> things may happen.
>>
>> Your assumption is that it is not working, if the elapsed time is longer.
>> This is the flawed assumption.
>>
>> Also, you need to read fine print on those "real time" JVMs. The catch is
>> in the definition of "real time".
>>
>>
>>
>>
>>  Imagine, for example, that you are using a ReentrantLock to control a
>> very precious resource used across the board (what about a database
>> connection pool?) and you are unlucky enough to have a system time change
>> (backwards) while you are locking: all the threads that want to use such
>> resource will be progressively locked: not forever, but for the amount of
>> time the clock went back. Probably most (all?) of your system freezes, and
>> the only option you have is to wait, or restart.
>> Now place this in a large application server, that provide services for
>> hunreds (thousands) of users. How does it sound to you?
>>
>> It sounds like you don't understand how the locks work.
>>
>>
>> Alex
>>
>>
>>
>> BTW, at the moment we could have a watchdog (in Python :)) that restarts
>> it, but, I dunno why, I don't like it a lot...
>>
>> Cheers,
>>
>>     Bruno
>>
>>
>>
>>>
>>
>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>> You are missing the point.
>>>
>>> Where in the design of those systems is a real-time timer? The one that
>>> delivers time events uncompromised even by GC latency?
>>>
>>> The whole concurrency lot does not depend on the timeout magnitude for
>>> correctness.
>>>
>>> Alex
>>>
>>>
>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>
>>>   Hi David
>>>
>>>
>>>
>>>
>>>> bugs.sun.com is not a live reflection of the bug database but gets
>>>> updated periodically (every 12 hours I think).
>>>>
>>>
>>>> Good to know :) I will be eagerly clicking on it to discover the new
>>> priority! Thanks for that, I really appreciate it.
>>>
>>>
>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>> have an older version this does not impact you.
>>>>
>>>
>>>>
>>> You saw my list: nobody will use an older Kernel/glibc version in
>>> production.
>>>
>>>
>>> As for the rest, show me real code in such systems that rely on sleep
>>>> for correctness or performance/timeliness and I will show you broken code.
>>>
>>>
>>>>
>>> You are still hitting about the sleep(), I understand and I agree about
>>> this. But here we are not talking about sleeps: we are talking about the
>>> whole concurrency lot. And yes, as I already said, we are talking about
>>> near time systems, like trading application, betting applications, air
>>> traffic control systems, car traffic control systems. Don't you think this
>>> bug might place Oracle JVM outside of these markets?
>>>
>>>
>>>
>>>> If this was as dire as you make out do you not think that this issue
>>>> would have been raised far more than it has? [....] prudent
>>>> developers/companies trial platform upgrades to check for these kinds of
>>>> issues before switching to them in production environments.
>>>>
>>>> I am waiting now for the part where you say that we should throw away
>>> Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
>>> action "in the middle", and I think that Oracle cannot oversee that. For
>>> example a lot of trading software system can be installed on premises,
>>> where you usually have no control over the environment: what I would do is
>>> to put a native daemon in my app so that if I see the system clock change I
>>> would kill myself, just in case. And this is a solution that I know for a
>>> fact (sorry, I cannot make a reference) it's used in production in a very
>>> important trading application.
>>>
>>> Regarding that specific bug, it was not accessible to the external until
>>> two days ago, so I guess nobody really knew a lot about it, but I will make
>>> sure it will :) so that we can get more traction.
>>>
>>> Cheers,
>>>
>>>     Bruno
>>>
>>>
>>>
>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>>
>>>>  Bruno,
>>>>
>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>> updated periodically (every 12 hours I think).
>>>>
>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>> have an older version this does not impact you.
>>>>
>>>> As for the rest, show me real code in such systems that rely on sleep
>>>> for correctness or performance/timeliness and I will show you broken
>>>> code. We are not talking about real-time systems here. park(nanos)/wait(millis)
>>>> will only be affected by the backward time change if the real notification
>>>> they are waiting for does not happen. Timeouts with these APIs are
>>>> heuristics, they are defensive programming to cover the case "what if the
>>>> notification I'm waiting for does not come". The code that would be
>>>> affected by this issue is a very small % of the code that uses the API.
>>>>
>>>> If this was as dire as you make out do you not think that this issue
>>>> would have been raised far more than it has? This issue does need
>>>> addressing because the number of affected systems will grow as these newer
>>>> linux systems are adopted, but prudent developers/companies trial platform
>>>> upgrades to check for these kinds of issues before swicthing to them in
>>>> production environments.
>>>>
>>>> Regards,
>>>> David
>>>>
>>>>  -----Original Message-----
>>>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>>>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>> *To:* dholmes at ieee.org
>>>> *Cc:* concurrency-interest at cs.oswego.edu
>>>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM
>>>> issue - feedback?
>>>>
>>>>   Hi David,
>>>>
>>>> thanks for following up.
>>>>
>>>>
>>>>
>>>>> I have raised the priority on 6900441
>>>>>
>>>>
>>>>
>>>> Thanks, but it looks still like a P4:
>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>> See also the attached snapshot, just in case it changes :)
>>>>
>>>> [image: Inline image 2]
>>>>
>>>> [...] which to my knowledge [...] has never been a private bug
>>>>>
>>>>
>>>> It was not accessible using bugs.sun.com, this was translated to
>>>> private. I also received the same info indirectly from the 7u lead:
>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>>>> bugs.sun.com)", I guess you can check with him.
>>>>
>>>>
>>>> It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>>>> introduced into a specific glibc version...
>>>>>
>>>>
>>>> ...and apparently did not make it. I was able to reproduce this even
>>>> with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>> 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on
>>>> JDK4 everything works (that's the reason why I call it a regression). (ah,
>>>> if you look at the bug, it lists also JDK5, so I think we are pretty much
>>>> covered here).
>>>> If you still have doubts tough, please have also a look on
>>>> stackoverflow to see how it was reproduced consistently on probably every
>>>> 64bitJVM over 64bitLinux in the world.
>>>>
>>>>
>>>> The effects of this is not that "all the threads parked will hang, with
>>>>> unpredictable/corrupted/useless"! The effects are very simple an quite
>>>>> predictable... [deletia]s.
>>>>
>>>>
>>>>
>>>> We have very different views, and I find quite difficult to accept
>>>> yours. You are confusing my sample program which contains a single thread
>>>> in a for loop with any other complex multi-threading concurrent system
>>>> written in Java. For example, if you ever worked in a bank you surely know
>>>> what I mean. You are comparing some random sleep() put into a program by
>>>> some newbie, with the complex ecosystem of a concurrent platform written to
>>>> manage trading information on very fast market. In that condition, I am
>>>> sorry, statements such "...delayed timeout does not affect operation in a
>>>> correctly functioning system..." and "...small time changes [...] are not a
>>>> problem" are really not applicable. Let your system place an order three
>>>> seconds late and your are out of the door so quickly you cannot even
>>>> realize it.
>>>>
>>>> But let's not limit ourselves to banks: how do you think your previous
>>>> statements stands in these scenarios?
>>>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>> about a few seconds delay in control when fying planes?)
>>>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>> if just for a couple of seconds all traffic lights become green?)
>>>>
>>>> Not good enough.
>>>>
>>>>
>>>> ...small time changes as typically done via NTP
>>>>
>>>>
>>>>
>>>> NTP is only one of the possible sources of this problem. The root of it
>>>> is that the JVM is counting nanoseconds delays using absolute values based
>>>> on a wallclock: I do not think it's that smart.
>>>>
>>>>
>>>>  So there is an issue that needs to be addressed but the situation is
>>>>> nowhere near as dire as you make out
>>>>>
>>>>
>>>>
>>>> Let's try to put this in perspective, shall we? In case the clock run
>>>> backwards LockSupport.park() will be waiting for the nanoseconds requested
>>>> plus the amount of seconds/minute/hours/days requested to compensate. Now,
>>>> this primitive is used by almost *every* concurrency construct available on
>>>> the platform, such as AbstractQueuedSynchronizer (and subclasses),
>>>> ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
>>>> subclasses), Executors, FutureTask, .... (too long to list them all, but I
>>>> think we have the picture) and also low levels synchronization primitives
>>>> of the language itself, so Object::wait(:long) and the related sychronized
>>>> blocks.
>>>>
>>>> I think it's pretty dire.
>>>>
>>>>
>>>> Cheers,
>>>>
>>>>     Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au
>>>> > wrote:
>>>>
>>>>>  Hi Bruno,
>>>>>
>>>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>>>> created it! - has never been a private bug).
>>>>>
>>>>> A few notes on the "very frightening" aspect of this:
>>>>>
>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>>>>> introduced into a specific glibc version for the futex-wait code such that
>>>>> it now responds to changes in the system time for absolute waits, where for
>>>>> all the years previous it did not. The fix seems to have been applied in
>>>>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>>>>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>>>>> will eventually make its way into 32-bit linux too.
>>>>>
>>>>> 2. The effects of this is not that "all the threads parked will hang,
>>>>> with unpredictable/corrupted/useless"! The effects are very simple an
>>>>> quite predictable. If the system time goes forward then timed-waits
>>>>> (Object.wait, LockSupport.park) (which should be relative times) will
>>>>> return early as the absolute-time that the relative time was converted to
>>>>> will be seen to have been reached (Thread.sleep contains a guard against
>>>>> early returns). This is not actually a problem as you can not distinguish
>>>>> this case from a "spurious wakeup" which code is supposed to account
>>>>> for. If the time is changed backwards then these timed-waits & sleeps will
>>>>> not timeout when expected as the the for that is now further in the future,
>>>>> by the amount of the backward time change. Hence small time changes as
>>>>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>>>>> heuristics for recovering when the expected real event notification does
>>>>> not occur - so a delayed timeout does not affect operation in a correctly
>>>>> functioning system. Early timeouts are indistinguishable from spurious
>>>>> wakeups, which code has to account for, so again not a problem for regular
>>>>> code. The only time a significant "hang" will occur is with Thread.sleep
>>>>> and a large backward time shift - but there is little real code that uses
>>>>> Thread.sleep in any critical way.
>>>>>
>>>>> So there is an issue that needs to be addressed but the situation is
>>>>> nowhere near as dire as you make out.
>>>>>
>>>>> David Holmes
>>>>>
>>>>> -----Original Message-----
>>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno
>>>>> bossola
>>>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>> *To:* concurrency-interest at cs.oswego.edu
>>>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>>>>> feedback?
>>>>>
>>>>>  Hi all,
>>>>>
>>>>> I am writing here following a suggestion by Ben Evans. I wanted to
>>>>> check with you about an issue that my teams found on the JVM and that's
>>>>> very frightening. I already started the discussion with the engineers of
>>>>> the hotspot VM team but it looks like we need more awareness to solve this
>>>>> one and I'd really appreciate some help and some push :)
>>>>> It looks to me that this issue is affecting every JVM64 running on
>>>>> Linux64, so imho it's quite important to be looked at.
>>>>>
>>>>> *Executive summary
>>>>> *The implementation of the concurrency primitive
>>>>> LockSupport.parkNanos(), the function that controls most concurrency
>>>>> primitive on the JVM, is flawed, and any NTP sync, or system time change,
>>>>> can potentially break it with unexpected results across the board.
>>>>>
>>>>> *What we need to do?
>>>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>>>> include it in a later patch release. In an ideal world it would be nice to
>>>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>>>> works based on priorities: being this qualified as P4 means it won't be
>>>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>
>>>>>
>>>>> *Why all this urgency?
>>>>> *If a system time change happens then all the threads parked will
>>>>> hang, with unpredictable/corrupted/useless results to the end user. Same
>>>>> applies to Future, Queue, Executor, and (I guess) any other construct that
>>>>> it's somehow related to concurrency. This is a big issue for us and for any
>>>>> near time application: please think about trading and betting, where the
>>>>> JVM is largely used, and  do not restrain yourself to the Java language:
>>>>> add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>
>>>>> *Tech details**
>>>>> *To be more clear about the issue, the extent of it and the
>>>>> concurrency library, let me introduce this very simple program:
>>>>>
>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>
>>>>> public class Main {
>>>>>
>>>>>     public static void main(String[] args) {
>>>>>
>>>>>         for (int i=100; i>0; i--) {
>>>>>             System.out.println(i);
>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>         }
>>>>>
>>>>>         System.out.println("Done!");
>>>>>     }
>>>>> }
>>>>>
>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>>>> whole concurrency library.
>>>>>
>>>>> To prove that this is fixable, I reimplemented the program above above
>>>>> substituting  LockSupport.parkNanos()  with  a JNI call to
>>>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>
>>>>> This is due to the fact  that the CPP code is calling the
>>>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is
>>>>> the actual "system time": each time my system syncs time using a NTP server
>>>>> on the net, the time might jump forward or backward. The correct call
>>>>> (again on Linux)  would require to use CLOCK_MONOTONIC as clock id,
>>>>> which are defined by POSIX specs since 2002. (or better
>>>>> CLOCK_MONOTONIC_RAW)
>>>>>
>>>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>>>> clock via clock_settime() shall have no effect on threads that are blocked
>>>>> waiting for a *relative* time service based upon this clock...": it
>>>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>> it appears that the park() is using compute_abstime() (which uses
>>>>> timeofday) and then waits on an absolute period: for that reason it's
>>>>> influenced by the system clock change. *Very wrong*.
>>>>>
>>>>> I will be happy to know what you think, and if you can help me to
>>>>> escalate this issue I think that the all Java community will benefit from
>>>>> it.
>>>>>
>>>>> Cheers,
>>>>>
>>>>>     Bruno
>>>>>
>>>>>
>>>> No virus found in this message.
>>>> Checked by AVG - www.avg.com
>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date:
>>>> 09/03/13
>>>>
>>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/fb4a3dde/attachment-0001.html>

From alexei.kaigorodov at gmail.com  Thu Sep  5 07:10:13 2013
From: alexei.kaigorodov at gmail.com (Alexei Kaigorodov)
Date: Thu, 5 Sep 2013 11:10:13 +0000 (UTC)
Subject: [concurrency-interest] Coordinated Runnables
References: <loom.20130829T134152-308@post.gmane.org>
	<CACuKZqESAPOuhU9Dw8uSDG=Dw8wR=HqtRGp1gQQdhZQsTzrmxA@mail.gmail.com>
	<CALCS1ZVfVMaqDO-EVF0b0jqiesmC+6B5_oFgDL6gK9qR2MJUQA@mail.gmail.com>
	<CANPzfU86zVgaE8hL5j+Jz1VWOJrzALv5Suy_vygvjw=Z7VoVQg@mail.gmail.com>
	<CALCS1ZV2sneM8Bd=Wa_DHPq8A+=MVJD=Ojh8JHxUgnTOvqUTQQ@mail.gmail.com>
	<17354802-F051-4A26-90B4-6B48B84707D4@rkuhn.info>
	<CACR_FB4G+7jr-Jb+-SyRgGBU=XAV2vqk2J=GNDzjshwryxdAmA@mail.gmail.com>
Message-ID: <loom.20130905T130213-237@post.gmane.org>

Howard Lovatt <howard.lovatt <at> gmail.com> writes:

> 
> 
> Hi Alexei,
> For this type of problem I use my own Graph library, works well for me.
See below for an example. It might give you some ideas at least.
> 
> ?-- Howard.
> 
> 

Are you serious? Your program falls in infinite loop when thread pool of
fixed size 1 was used. Indeed, some methods (e.g. BufferingVertex.add())
cycle while some value become not null, but because they occupy the single
working thread, other tasks have no chance to set that value. This is not
the way multithreading programs are designed.

thanks,
Alexei




From oleksandr.otenko at oracle.com  Thu Sep  5 11:12:43 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 16:12:43 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
Message-ID: <52289F6B.7020405@oracle.com>

This is far from reproducing the problem with arbitrary j.u.c locks and 
queues hanging.

Condition.awaitNanos can return a negative value. If you are expecting 
the negative value to be small, then how small do you expect it to be?


Alex


On 05/09/2013 02:12, bruno bossola wrote:
> Hi Oaleksandr,
>
> Please apologize me if my english was not good enough to provide you 
> an example that make sense: for that reason I decided to go back to a 
> binary deliverable (code) that shows the problem, hope this helps!
>
> This is my PreciousPool class, that handles Precious resources:
>
> import java.text.SimpleDateFormat;
> import java.util.ArrayList;
> import java.util.Date;
> import java.util.List;
> import java.util.concurrent.TimeUnit;
> import java.util.concurrent.locks.Condition;
> import java.util.concurrent.locks.Lock;
> import java.util.concurrent.locks.ReentrantLock;
>
> public class PreciousPool {
>
>     public static class Precious {
>         private final int id;
>
>         private Precious() {
> this.id <http://this.id> = 100+(int)(Math.random()*900.0);
>         }
>
>         public String toString() {
>             return "Precious n."+id;
>         }
>     }
>
>     private final Lock lock;
>     private final Condition ready;
>     private final long timeoutInMillis;
>
>     private final List<Precious> preciousLended;
>     private final List<Precious> preciousAvailable;
>
>     public PreciousPool(int size, long timeoutInSeconds) {
>         this.lock = new ReentrantLock();
>         this.ready = lock.newCondition();
>
>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>         this.preciousLended =  new ArrayList<Precious>();
>         this.preciousAvailable = new ArrayList<Precious>();
>
>         for (int i = 0; i < size; i++) {
>             preciousAvailable.add(new Precious());
>         }
>     }
>
>     public Precious obtain()  {
>         lock.lock();
>         try {
>             // if no precious are available we wait for the specified 
> timeout (releasing the lock so that others can try)
>             if (preciousAvailable.size() == 0) {
>                 try {
>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>                 } catch (InterruptedException e) {
>                     Thread.currentThread().interrupt();
>                     throw new RuntimeException("Somebody interrupted 
> me!", e);
>                 }
>             }
>
>             // if a precious is available we unload it and return to 
> the caller, otherwise null
>             if (preciousAvailable.size() > 0) {
>                 Precious value = preciousAvailable.remove(0);
>                 preciousLended.add(value);
>                 return value;
>             } else {
>                 return null;
>             }
>         } finally {
>             lock.unlock();
>         }
>     }
>
>     public void release(Precious value) {
>         lock.lock();
>         try {
>             if (!preciousLended.remove(value))
>                 throw new RuntimeException("Element "+value+" was not 
> lended!");
>
>             // if a precious is returned we put it back and signal to 
> anybody waiting
>             preciousAvailable.add(value);
>             ready.signalAll();
>         } finally {
>             lock.unlock();
>         }
>     }
>
>     public static void main(String args[]) {
>         final int size = 3;
>         final PreciousPool pool = new PreciousPool(size, 5);
>
>         // let's exhaust the pool
>         for (int i=0; i<size; i++)
>             dump(pool.obtain());
>
>         // and as we are stubborn we continuosly ask for a new one
>         while(true) {
>             dump(pool.obtain());
>         }
>     }
>
>     private static void dump(Precious precious) {
>         if (precious == null)
>             log("I did not get my precious :(");
>         else
>             log("I did get my precious! "+precious);
>     }
>
>     private static void log(String message) {
>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS 
> ").format(new Date());
>         System.out.println(now + message);
>     }
> }
>
> So, the main is a single thread (no need for multithreading here, 
> let's keep it simple), that first exhaust the whole pool and then keep 
> asking, without success, for a resource. Stubborn guy, I say, but it 
> happens. If you run this program everything works as expected: you are 
> greeted by a three successful Precious and then an endless list of 
> failures, that it continuously grow. All good :)
>
> 02:34:40:0061 I did get my precious! Precious n.156
> 02:34:40:0062 I did get my precious! Precious n.991
> 02:34:40:0062 I did get my precious! Precious n.953
> 02:34:45:0064 I did not get my precious :(
> 02:34:50:0065 I did not get my precious :(
> 02:34:55:0066 I did not get my precious :(
> 02:35:00:0067 I did not get my precious :(
> 02:35:05:0068 I did not get my precious :(
> [...]
>
> But guess what happens when, while the program is running, I change 
> the date of my system back of one hour? Everything stops,  it's simple 
> as that. No prints, nothing, zero, nada. Now, If it wasn't so late, I 
> would probably wait one hour in order to have my program restored to 
> his normal process, but as a customer I won't be terribly happy :)
>
> I hope my point is now clear.
> Cheers,
>
>     Bruno
>
>
>
>
>
>
> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     n 04/09/2013 18:54, bruno bossola wrote:
>>     Hi Oleksandr,
>>
>>         Where in the design of those systems is a real-time timer?
>>         The one that delivers time events uncompromised even by GC
>>         latency?
>>
>>     I don't think so :) If somebody needs a real time implementation
>>     he needs to go for a real time JVM, like Jean correctly pointed
>>     out.  The concurrency primitives are depending on
>>     LockSupport.parkNanos(...) to park a thread: if this for any
>>     reason is not working (like it is) then strange things may happen.
>     Your assumption is that it is not working, if the elapsed time is
>     longer. This is the flawed assumption.
>
>     Also, you need to read fine print on those "real time" JVMs. The
>     catch is in the definition of "real time".
>
>
>
>
>>     Imagine, for example, that you are using a ReentrantLock to
>>     control a very precious resource used across the board (what
>>     about a database connection pool?) and you are unlucky enough to
>>     have a system time change (backwards) while you are locking: all
>>     the threads that want to use such resource will be progressively
>>     locked: not forever, but for the amount of time the clock went
>>     back. Probably most (all?) of your system freezes, and the only
>>     option you have is to wait, or restart.
>>     Now place this in a large application server, that provide
>>     services for hunreds (thousands) of users. How does it sound to you?
>     It sounds like you don't understand how the locks work.
>
>
>     Alex
>
>
>>
>>     BTW, at the moment we could have a watchdog (in Python :)) that
>>     restarts it, but, I dunno why, I don't like it a lot...
>>
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>
>>
>>     On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         You are missing the point.
>>
>>         Where in the design of those systems is a real-time timer?
>>         The one that delivers time events uncompromised even by GC
>>         latency?
>>
>>         The whole concurrency lot does not depend on the timeout
>>         magnitude for correctness.
>>
>>         Alex
>>
>>
>>         On 04/09/2013 12:05, bruno bossola wrote:
>>>         Hi David
>>>
>>>
>>>             bugs.sun.com <http://bugs.sun.com> is not a live
>>>             reflection of the bug database but gets updated
>>>             periodically (every 12 hours I think).
>>>
>>>
>>>         Good to know :) I will be eagerly clicking on it to discover
>>>         the new priority! Thanks for that, I really appreciate it.
>>>
>>>
>>>             The issue arises on certain 64-bit linux kernel/glibc
>>>             versions. If you have an older version this does not
>>>             impact you.
>>>
>>>         You saw my list: nobody will use an older Kernel/glibc
>>>         version in production.
>>>
>>>
>>>             As for the rest, show me real code in such systems that
>>>             rely on sleep for correctness or performance/timeliness
>>>             and I will show you broken code.
>>>
>>>         You are still hitting about the sleep(), I understand and I
>>>         agree about this. But here we are not talking about sleeps:
>>>         we are talking about the whole concurrency lot. And yes, as
>>>         I already said, we are talking about near time systems, like
>>>         trading application, betting applications, air traffic
>>>         control systems, car traffic control systems. Don't you
>>>         think this bug might place Oracle JVM outside of these markets?
>>>
>>>
>>>             If this was as dire as you make out do you not think
>>>             that this issue would have been raised far more than it
>>>             has? [....] prudent developers/companies trial platform
>>>             upgrades to check for these kinds of issues before
>>>             switching to them in production environments.
>>>
>>>         I am waiting now for the part where you say that we should
>>>         throw away Linux and use Oracle Solaris :)  In all
>>>         seriousness, there's a lot of action "in the middle", and I
>>>         think that Oracle cannot oversee that. For example a lot of
>>>         trading software system can be installed on premises, where
>>>         you usually have no control over the environment: what I
>>>         would do is to put a native daemon in my app so that if I
>>>         see the system clock change I would kill myself, just in
>>>         case. And this is a solution that I know for a fact (sorry,
>>>         I cannot make a reference) it's used in production in a very
>>>         important trading application.
>>>
>>>         Regarding that specific bug, it was not accessible to the
>>>         external until two days ago, so I guess nobody really knew a
>>>         lot about it, but I will make sure it will :) so that we can
>>>         get more traction.
>>>
>>>         Cheers,
>>>
>>>             Bruno
>>>
>>>
>>>
>>>         On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>         <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>>
>>>         wrote:
>>>
>>>             Bruno,
>>>             bugs.sun.com <http://bugs.sun.com> is not a live
>>>             reflection of the bug database but gets updated
>>>             periodically (every 12 hours I think).
>>>             The issue arises on certain 64-bit linux kernel/glibc
>>>             versions. If you have an older version this does not
>>>             impact you.
>>>             As for the rest, show me real code in such systems that
>>>             rely on sleep for correctness or
>>>             performance/timelinessand I will show you broken code.
>>>             We are not talking about real-time systemshere.
>>>             park(nanos)/wait(millis) will only be affected by the
>>>             backward time change if the real notification they are
>>>             waiting for does not happen. Timeouts with these APIs
>>>             are heuristics, they are defensive programming to cover
>>>             the case "what if the notification I'm waiting for does
>>>             not come". The code that would be affected by this issue
>>>             is a very small % of the code that uses the API.
>>>             If this was as dire as you make out do you not think
>>>             that this issue would have been raised far more than it
>>>             has? This issue does need addressing because the number
>>>             of affected systems will grow as these newer linux
>>>             systems are adopted, but prudent developers/companies
>>>             trial platform upgrades to check for these kinds of
>>>             issues before swicthing to them in production environments.
>>>             Regards,
>>>             David
>>>
>>>                 -----Original Message-----
>>>                 *From:* bruno bossola [mailto:bbossola at gmail.com
>>>                 <mailto:bbossola at gmail.com>]
>>>                 *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>                 *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>                 *Cc:* concurrency-interest at cs.oswego.edu
>>>                 <mailto:concurrency-interest at cs.oswego.edu>
>>>                 *Subject:* Re: [concurrency-interest] Outstanding
>>>                 concurrency JVM issue - feedback?
>>>
>>>                 Hi David,
>>>
>>>                 thanks for following up.
>>>
>>>                     I have raised the priority on 6900441
>>>
>>>                 Thanks, but it looks still like a P4:
>>>                 http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>                 See also the attached snapshot, just in case it
>>>                 changes :)
>>>
>>>                 Inline image 2
>>>
>>>                     [...] which to my knowledge [...] has never been
>>>                     a private bug
>>>
>>>                 It was not accessible using bugs.sun.com
>>>                 <http://bugs.sun.com/>, this was translated to
>>>                 private. I also received the same info indirectly
>>>                 from the 7u lead:
>>>                 "I'm not sure why 6900441 isn't public. (I'll follow
>>>                 up with owner of bugs.sun.com
>>>                 <http://bugs.sun.com/>)", I guess you can check with
>>>                 him.
>>>
>>>
>>>                     It doesn't affect "every JVM64 running on
>>>                     Linux64".  A fix has been introduced into a
>>>                     specific glibc version...
>>>
>>>                 ...and apparently did not make it. I was able to
>>>                 reproduce this even with the IBM VM, so to speak. I
>>>                 tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13 +
>>>                 some random Debian. I did not have a JDK5, so I
>>>                 cannot say, but on JDK4 everything works (that's the
>>>                 reason why I call it a regression). (ah, if you look
>>>                 at the bug, it lists also JDK5, so I think we are
>>>                 pretty much covered here).
>>>                 If you still have doubts tough, please have also a
>>>                 look on stackoverflow to see how it was reproduced
>>>                 consistently on probably every 64bitJVM over
>>>                 64bitLinux in the world.
>>>
>>>
>>>                     The effects of this is not that "all the threads
>>>                     parked will hang, with
>>>                     unpredictable/corrupted/useless"! The effects
>>>                     are very simple an quite predictable... [deletia]s.
>>>
>>>                 We have very different views, and I find quite
>>>                 difficult to accept yours. You are confusing my
>>>                 sample program which contains a single thread in a
>>>                 for loop with any other complex multi-threading
>>>                 concurrent system written in Java. For example, if
>>>                 you ever worked in a bank you surely know what I
>>>                 mean. You are comparing some random sleep() put into
>>>                 a program by some newbie, with the complex ecosystem
>>>                 of a concurrent platform written to manage trading
>>>                 information on very fast market. In that condition,
>>>                 I am sorry, statements such "...delayed timeout does
>>>                 not affect operation in a correctly functioning
>>>                 system..." and "...small time changes [...] are not
>>>                 a problem" are really not applicable. Let your
>>>                 system place an order three seconds late and your
>>>                 are out of the door so quickly you cannot even
>>>                 realize it.
>>>
>>>                 But let's not limit ourselves to banks: how do you
>>>                 think your previous statements stands in these
>>>                 scenarios?
>>>                 - air control systems
>>>                 <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>                 about a few seconds delay in control when fying planes?)
>>>                 - city traffic control systems
>>>                 <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>                 if just for a couple of seconds all traffic lights
>>>                 become green?)
>>>
>>>                 Not good enough.
>>>
>>>
>>>                     ...small time changes as typically done via NTP
>>>
>>>                 NTP is only one of the possible sources of this
>>>                 problem. The root of it is that the JVM is counting
>>>                 nanoseconds delays using absolute values based on a
>>>                 wallclock: I do not think it's that smart.
>>>
>>>
>>>                     So there is an issue that needs to be addressed
>>>                     but the situation is nowhere near as dire as you
>>>                     make out
>>>
>>>                 Let's try to put this in perspective, shall we? In
>>>                 case the clock run backwards LockSupport.park() will
>>>                 be waiting for the nanoseconds requested plus the
>>>                 amount of seconds/minute/hours/days requested to
>>>                 compensate. Now, this primitive is used by almost
>>>                 *every* concurrency construct available on the
>>>                 platform, such as AbstractQueuedSynchronizer (and
>>>                 subclasses), ReentrantLock (and subclasses),
>>>                 CyclicBarrier, BlockingQueue (and subclasses),
>>>                 Executors, FutureTask, .... (too long to list them
>>>                 all, but I think we have the picture) and also low
>>>                 levels synchronization primitives of the language
>>>                 itself, so Object::wait(:long) and the related
>>>                 sychronized blocks.
>>>
>>>                 I think it's pretty dire.
>>>
>>>
>>>                 Cheers,
>>>
>>>                     Bruno
>>>
>>>
>>>
>>>
>>>
>>>                 On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
>>>                 <davidcholmes at aapt.net.au
>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>
>>>                     Hi Bruno,
>>>                     I have raised the priority on 6900441 (which to
>>>                     my knowledge - and I created it! - has never
>>>                     been a private bug).
>>>                     A few notes on the "very frightening" aspect of
>>>                     this:
>>>                     1. It doesn't affect "every JVM64 running on
>>>                     Linux64". A fix has been introduced into a
>>>                     specific glibc version for the futex-wait code
>>>                     such that it now responds to changes in the
>>>                     system time for absolute waits, where for all
>>>                     the years previous it did not. The fix seems to
>>>                     have been applied in late 2011 or early 2012 but
>>>                     I don't know the exact glibc version. There is
>>>                     also a 32-bit version of the fix that was
>>>                     proposed on Nov 27, 2012, so it will eventually
>>>                     make its way into 32-bit linux too.
>>>                     2. The effects of this is not that "all the
>>>                     threads parked will hang, with
>>>                     unpredictable/corrupted/useless"! The effects
>>>                     are very simple an quite predictable. If the
>>>                     system time goes forward then timed-waits
>>>                     (Object.wait, LockSupport.park) (which should be
>>>                     relative times) will return early as the
>>>                     absolute-time that the relative time was
>>>                     converted to will be seen to have been reached
>>>                     (Thread.sleep contains a guard against early
>>>                     returns). This is not actually a problem as you
>>>                     can not distinguish this case from a "spurious
>>>                     wakeup" which code is supposed to account
>>>                     for. If the time is changed backwards then these
>>>                     timed-waits & sleeps will not timeout when
>>>                     expected as the the for that is now further in
>>>                     the future, by the amount of the backward time
>>>                     change. Hence small time changes as typically
>>>                     done via NTP are NOT a problem. Timed-waits use
>>>                     timeouts as a heuristics for recovering when the
>>>                     expected real event notification does not occur
>>>                     - so a delayed timeout does not affect operation
>>>                     in a correctly functioning system. Early
>>>                     timeouts are indistinguishable from spurious
>>>                     wakeups, which code has to account for, so again
>>>                     not a problem for regular code. The only time a
>>>                     significant "hang" will occur is with
>>>                     Thread.sleep and a large backward time shift -
>>>                     but there is little real code that uses
>>>                     Thread.sleep in any critical way.
>>>                     So there is an issue that needs to be addressed
>>>                     but the situation is nowhere near as dire as you
>>>                     make out.
>>>                     David Holmes
>>>
>>>                         -----Original Message-----
>>>                         *From:*
>>>                         concurrency-interest-bounces at cs.oswego.edu
>>>                         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>                         [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>                         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>                         Behalf Of *bruno bossola
>>>                         *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>                         *To:* concurrency-interest at cs.oswego.edu
>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>                         *Subject:* [concurrency-interest]
>>>                         Outstanding concurrency JVM issue - feedback?
>>>
>>>                         Hi all,
>>>
>>>                         I am writing here following a suggestion by
>>>                         Ben Evans. I wanted to check with you about
>>>                         an issue that my teams found on the JVM and
>>>                         that's very frightening. I already started
>>>                         the discussion with the engineers of the
>>>                         hotspot VM team but it looks like we need
>>>                         more awareness to solve this one and I'd
>>>                         really appreciate some help and some push :)
>>>                         It looks to me that this issue is affecting
>>>                         every JVM64 running on Linux64, so imho it's
>>>                         quite important to be looked at.
>>>
>>>                         *Executive summary
>>>                         *The implementation of the concurrency
>>>                         primitive LockSupport.parkNanos(), the
>>>                         function that controls most concurrency
>>>                         primitive on the JVM, is flawed, and any NTP
>>>                         sync, or system time change, can potentially
>>>                         break it with unexpected results across the
>>>                         board.
>>>
>>>                         *What we need to do?
>>>                         *This is an old issue, and the bug
>>>                         <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>                         was declared private. I somehow managed to
>>>                         have the bug reopened to the public, but
>>>                         it's still a  P4, that means that probably
>>>                         won't be fixed. I think we need to push for
>>>                         a resolution ASAP, be sure that's in for
>>>                         JDK9, make all the possible effort to make
>>>                         this fix for JDK8 or, at least, to include
>>>                         it in a later patch release. In an ideal
>>>                         world it would be nice to have a patch for
>>>                         JDK7. As far as I understand the hotspot
>>>                         engineering team works based on priorities:
>>>                         being this qualified as P4 means it won't be
>>>                         probably worked on (if you follow the
>>>                         breadcrumbs of bugs and fixes you can go
>>>                         back to 2002!) They acknowledge the problem,
>>>                         it has been flagged to management, but 1)
>>>                         it's low priority 2) it's too risky to fix
>>>                         for JDK8
>>>
>>>
>>>                         *Why all this urgency?
>>>                         *If a system time change happens then all
>>>                         the threads parked will hang, with
>>>                         unpredictable/corrupted/useless results to
>>>                         the end user. Same applies to Future, Queue,
>>>                         Executor, and (I guess) any other construct
>>>                         that it's somehow related to concurrency.
>>>                         This is a big issue for us and for any near
>>>                         time application: please think about trading
>>>                         and betting, where the JVM is largely used,
>>>                         and  do not restrain yourself to the Java
>>>                         language: add Scala and any other JVM-based
>>>                         language to the picture (JRuby, Jython...)
>>>
>>>                         *Tech details**
>>>                         *To be more clear about the issue, the
>>>                         extent of it and the concurrency library,
>>>                         let me introduce this very simple program:
>>>
>>>                         import java.util.concurrent.locks.LockSupport;
>>>
>>>                         public class Main {
>>>
>>>                             public static void main(String[] args) {
>>>
>>>                                 for (int i=100; i>0; i--) {
>>>                         System.out.println(i);
>>>                         LockSupport.parkNanos(1000L*1000L*1000L);
>>>                                 }
>>>
>>>                         System.out.println("Done!");
>>>                             }
>>>                         }
>>>
>>>                         Run it with a 64bit 1.6+ JVM on 64bit Linux,
>>>                         turn the clock down one hour and wait until
>>>                         the counter stops... magic!  I tested this
>>>                         on JDK6, JDK7 and latest JDK8 beta running
>>>                         on various Ubuntu distros. It's not just a
>>>                         matter of (old?) sleep() and wait()
>>>                         primitives, this issue it affects the whole
>>>                         concurrency library.
>>>
>>>                         To prove that this is fixable, I
>>>                         reimplemented the program above above
>>>                         substituting LockSupport.parkNanos() with  a
>>>                         JNI call to
>>>                         clock_nanosleep(CLOCK_MONOTONIC...): works
>>>                         like a charm :(
>>>
>>>                         This is due to the fact  that the CPP code
>>>                         is calling the pthread_cond_timedwait()
>>>                         using its default clock (CLOCK_REALTIME)
>>>                         which, unfortunately is affected by
>>>                         settime()/settimeofday() calls (on Linux):
>>>                         for that reason it cannot be used to measure
>>>                         nanoseconds delays, which is what the
>>>                         specification
>>>                         <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>                         requires. CLOCK_REALTIME is not guaranteed
>>>                         to monotonically count as this is the actual
>>>                         "system time": each time my system syncs
>>>                         time using a NTP server on the net, the time
>>>                         might jump forward or backward. The correct
>>>                         call (again on Linux)  would require to use
>>>                         CLOCK_MONOTONIC as clock id, which are
>>>                         defined by POSIX specs since 2002. (or
>>>                         better CLOCK_MONOTONIC_RAW)
>>>
>>>                         The POSIX spec
>>>                         <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>                         is infact clear, as it states "...setting
>>>                         the value of the CLOCK_REALTIME clock via
>>>                         clock_settime() shall have no effect on
>>>                         threads that are blocked waiting for a
>>>                         *relative* time service based upon this
>>>                         clock...": it definitely states "relative".
>>>                         Having a look at the hotspot code
>>>                         <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>                         it appears that the park() is using
>>>                         compute_abstime() (which uses timeofday) and
>>>                         then waits on an absolute period: for that
>>>                         reason it's influenced by the system clock
>>>                         change. *Very wrong*.
>>>
>>>                         I will be happy to know what you think, and
>>>                         if you can help me to escalate this issue I
>>>                         think that the all Java community will
>>>                         benefit from it.
>>>
>>>                         Cheers,
>>>
>>>                             Bruno
>>>
>>>
>>>                 No virus found in this message.
>>>                 Checked by AVG - www.avg.com <http://www.avg.com>
>>>                 Version: 2013.0.3392 / Virus Database: 3222/6633 -
>>>                 Release Date: 09/03/13
>>>
>>>
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/cdf7606d/attachment-0001.html>

From bbossola at gmail.com  Thu Sep  5 12:50:34 2013
From: bbossola at gmail.com (bruno bossola)
Date: Thu, 5 Sep 2013 17:50:34 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <52289F6B.7020405@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
Message-ID: <CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>

I am sorry but I really cannot spend more time creating more samples and I
am quite sure you could do a better work at that! At the moment to me that
matter is clear enough, but feel free to ask, I will very happy to help! In
the meantime I prefer spend my time to work on a patch that I can apply on
my JVMs :)

Cheers,

    Bruno



On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  This is far from reproducing the problem with arbitrary j.u.c locks and
> queues hanging.
>
> Condition.awaitNanos can return a negative value. If you are expecting the
> negative value to be small, then how small do you expect it to be?
>
>
> Alex
>
>
> On 05/09/2013 02:12, bruno bossola wrote:
>
>  Hi Oaleksandr,
>
>  Please apologize me if my english was not good enough to provide you an
> example that make sense: for that reason I decided to go back to a binary
> deliverable (code) that shows the problem, hope this helps!
>
>  This is my PreciousPool class, that handles Precious resources:
>
> import java.text.SimpleDateFormat;
> import java.util.ArrayList;
> import java.util.Date;
> import java.util.List;
> import java.util.concurrent.TimeUnit;
> import java.util.concurrent.locks.Condition;
> import java.util.concurrent.locks.Lock;
> import java.util.concurrent.locks.ReentrantLock;
>
> public class PreciousPool {
>
>     public static class Precious {
>         private final int id;
>
>         private Precious() {
>             this.id = 100+(int)(Math.random()*900.0);
>         }
>
>         public String toString() {
>             return "Precious n."+id;
>         }
>     }
>
>     private final Lock lock;
>     private final Condition ready;
>     private final long timeoutInMillis;
>
>     private final List<Precious> preciousLended;
>     private final List<Precious> preciousAvailable;
>
>     public PreciousPool(int size, long timeoutInSeconds) {
>         this.lock = new ReentrantLock();
>         this.ready = lock.newCondition();
>
>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>         this.preciousLended =  new ArrayList<Precious>();
>         this.preciousAvailable = new ArrayList<Precious>();
>
>         for (int i = 0; i < size; i++) {
>             preciousAvailable.add(new Precious());
>         }
>     }
>
>     public Precious obtain()  {
>         lock.lock();
>         try {
>             // if no precious are available we wait for the specified
> timeout (releasing the lock so that others can try)
>             if (preciousAvailable.size() == 0) {
>                 try {
>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>                 } catch (InterruptedException e) {
>                     Thread.currentThread().interrupt();
>                     throw new RuntimeException("Somebody interrupted me!",
> e);
>                 }
>             }
>
>             // if a precious is available we unload it and return to the
> caller, otherwise null
>             if (preciousAvailable.size() > 0) {
>                 Precious value = preciousAvailable.remove(0);
>                 preciousLended.add(value);
>                 return value;
>             } else {
>                 return null;
>             }
>         } finally {
>             lock.unlock();
>         }
>     }
>
>     public void release(Precious value) {
>         lock.lock();
>         try {
>             if (!preciousLended.remove(value))
>                 throw new RuntimeException("Element "+value+" was not
> lended!");
>
>             // if a precious is returned we put it back and signal to
> anybody waiting
>             preciousAvailable.add(value);
>             ready.signalAll();
>         } finally {
>             lock.unlock();
>         }
>     }
>
>     public static void main(String args[]) {
>         final int size = 3;
>         final PreciousPool pool = new PreciousPool(size, 5);
>
>         // let's exhaust the pool
>         for (int i=0; i<size; i++)
>             dump(pool.obtain());
>
>         // and as we are stubborn we continuosly ask for a new one
>         while(true) {
>             dump(pool.obtain());
>         }
>     }
>
>     private static void dump(Precious precious) {
>         if (precious == null)
>             log("I did not get my precious :(");
>         else
>             log("I did get my precious! "+precious);
>     }
>
>     private static void log(String message) {
>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS
> ").format(new Date());
>         System.out.println(now + message);
>     }
> }
>
> So, the main is a single thread (no need for multithreading here, let's
> keep it simple), that first exhaust the whole pool and then keep asking,
> without success, for a resource. Stubborn guy, I say, but it happens. If
> you run this program everything works as expected: you are greeted by a
> three successful Precious and then an endless list of failures, that it
> continuously grow. All good :)
>
> 02:34:40:0061 I did get my precious! Precious n.156
> 02:34:40:0062 I did get my precious! Precious n.991
> 02:34:40:0062 I did get my precious! Precious n.953
> 02:34:45:0064 I did not get my precious :(
> 02:34:50:0065 I did not get my precious :(
> 02:34:55:0066 I did not get my precious :(
> 02:35:00:0067 I did not get my precious :(
> 02:35:05:0068 I did not get my precious :(
> [...]
>
>  But guess what happens when, while the program is running, I change the
> date of my system back of one hour? Everything stops,  it's simple as that.
> No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
> wait one hour in order to have my program restored to his normal process,
> but as a customer I won't be terribly happy :)
>
>  I hope my point is now clear.
>  Cheers,
>
>      Bruno
>
>
>
>
>
>
> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  n 04/09/2013 18:54, bruno bossola wrote:
>>
>>   Hi Oleksandr,
>>
>> Where in the design of those systems is a real-time timer? The one that
>>> delivers time events uncompromised even by GC latency?
>>>
>>
>>>
>>  I don't think so :) If somebody needs a real time implementation he
>> needs to go for a real time JVM, like Jean correctly pointed out.  The
>> concurrency primitives are depending on LockSupport.parkNanos(...) to park
>> a thread: if this for any reason is not working (like it is) then strange
>> things may happen.
>>
>>  Your assumption is that it is not working, if the elapsed time is
>> longer. This is the flawed assumption.
>>
>> Also, you need to read fine print on those "real time" JVMs. The catch is
>> in the definition of "real time".
>>
>>
>>
>>
>>  Imagine, for example, that you are using a ReentrantLock to control a
>> very precious resource used across the board (what about a database
>> connection pool?) and you are unlucky enough to have a system time change
>> (backwards) while you are locking: all the threads that want to use such
>> resource will be progressively locked: not forever, but for the amount of
>> time the clock went back. Probably most (all?) of your system freezes, and
>> the only option you have is to wait, or restart.
>>  Now place this in a large application server, that provide services for
>> hunreds (thousands) of users. How does it sound to you?
>>
>>  It sounds like you don't understand how the locks work.
>>
>>
>> Alex
>>
>>
>>
>>  BTW, at the moment we could have a watchdog (in Python :)) that
>> restarts it, but, I dunno why, I don't like it a lot...
>>
>>  Cheers,
>>
>>      Bruno
>>
>>
>>
>>>
>>
>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>>  You are missing the point.
>>>
>>> Where in the design of those systems is a real-time timer? The one that
>>> delivers time events uncompromised even by GC latency?
>>>
>>> The whole concurrency lot does not depend on the timeout magnitude for
>>> correctness.
>>>
>>> Alex
>>>
>>>
>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>
>>>   Hi David
>>>
>>>
>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>> updated periodically (every 12 hours I think).
>>>>
>>>
>>>>
>>> Good to know :) I will be eagerly clicking on it to discover the new
>>> priority! Thanks for that, I really appreciate it.
>>>
>>>
>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>> have an older version this does not impact you.
>>>>
>>>
>>>>
>>> You saw my list: nobody will use an older Kernel/glibc version in
>>> production.
>>>
>>>
>>> As for the rest, show me real code in such systems that rely on sleep
>>>> for correctness or performance/timeliness and I will show you broken code.
>>>
>>>
>>>>
>>>  You are still hitting about the sleep(), I understand and I agree about
>>> this. But here we are not talking about sleeps: we are talking about the
>>> whole concurrency lot. And yes, as I already said, we are talking about
>>> near time systems, like trading application, betting applications, air
>>> traffic control systems, car traffic control systems. Don't you think this
>>> bug might place Oracle JVM outside of these markets?
>>>
>>>
>>>
>>>> If this was as dire as you make out do you not think that this issue
>>>> would have been raised far more than it has? [....] prudent
>>>> developers/companies trial platform upgrades to check for these kinds of
>>>> issues before switching to them in production environments.
>>>>
>>>>  I am waiting now for the part where you say that we should throw away
>>> Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
>>> action "in the middle", and I think that Oracle cannot oversee that. For
>>> example a lot of trading software system can be installed on premises,
>>> where you usually have no control over the environment: what I would do is
>>> to put a native daemon in my app so that if I see the system clock change I
>>> would kill myself, just in case. And this is a solution that I know for a
>>> fact (sorry, I cannot make a reference) it's used in production in a very
>>> important trading application.
>>>
>>> Regarding that specific bug, it was not accessible to the external until
>>> two days ago, so I guess nobody really knew a lot about it, but I will make
>>> sure it will :) so that we can get more traction.
>>>
>>>  Cheers,
>>>
>>>      Bruno
>>>
>>>
>>>
>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>>
>>>>  Bruno,
>>>>
>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>> updated periodically (every 12 hours I think).
>>>>
>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>> have an older version this does not impact you.
>>>>
>>>> As for the rest, show me real code in such systems that rely on sleep
>>>> for correctness or performance/timeliness and I will show you broken
>>>> code. We are not talking about real-time systems here. park(nanos)/wait(millis)
>>>> will only be affected by the backward time change if the real notification
>>>> they are waiting for does not happen. Timeouts with these APIs are
>>>> heuristics, they are defensive programming to cover the case "what if the
>>>> notification I'm waiting for does not come". The code that would be
>>>> affected by this issue is a very small % of the code that uses the API.
>>>>
>>>> If this was as dire as you make out do you not think that this issue
>>>> would have been raised far more than it has? This issue does need
>>>> addressing because the number of affected systems will grow as these newer
>>>> linux systems are adopted, but prudent developers/companies trial platform
>>>> upgrades to check for these kinds of issues before swicthing to them in
>>>> production environments.
>>>>
>>>> Regards,
>>>> David
>>>>
>>>>  -----Original Message-----
>>>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>>>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>> *To:* dholmes at ieee.org
>>>> *Cc:* concurrency-interest at cs.oswego.edu
>>>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM
>>>> issue - feedback?
>>>>
>>>>    Hi David,
>>>>
>>>>  thanks for following up.
>>>>
>>>>
>>>>
>>>>> I have raised the priority on 6900441
>>>>>
>>>>
>>>>
>>>>  Thanks, but it looks still like a P4:
>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>> See also the attached snapshot, just in case it changes :)
>>>>
>>>>  [image: Inline image 2]
>>>>
>>>>  [...] which to my knowledge [...] has never been a private bug
>>>>>
>>>>
>>>> It was not accessible using bugs.sun.com, this was translated to
>>>> private. I also received the same info indirectly from the 7u lead:
>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>>>> bugs.sun.com)", I guess you can check with him.
>>>>
>>>>
>>>>  It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>>>> introduced into a specific glibc version...
>>>>>
>>>>
>>>> ...and apparently did not make it. I was able to reproduce this even
>>>> with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>> 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on
>>>> JDK4 everything works (that's the reason why I call it a regression). (ah,
>>>> if you look at the bug, it lists also JDK5, so I think we are pretty much
>>>> covered here).
>>>> If you still have doubts tough, please have also a look on
>>>> stackoverflow to see how it was reproduced consistently on probably every
>>>> 64bitJVM over 64bitLinux in the world.
>>>>
>>>>
>>>>  The effects of this is not that "all the threads parked will hang,
>>>>> with unpredictable/corrupted/useless"! The effects are very simple an quite
>>>>> predictable... [deletia]s.
>>>>
>>>>
>>>>
>>>> We have very different views, and I find quite difficult to accept
>>>> yours. You are confusing my sample program which contains a single thread
>>>> in a for loop with any other complex multi-threading concurrent system
>>>> written in Java. For example, if you ever worked in a bank you surely know
>>>> what I mean. You are comparing some random sleep() put into a program by
>>>> some newbie, with the complex ecosystem of a concurrent platform written to
>>>> manage trading information on very fast market. In that condition, I am
>>>> sorry, statements such "...delayed timeout does not affect operation in a
>>>> correctly functioning system..." and "...small time changes [...] are not a
>>>> problem" are really not applicable. Let your system place an order three
>>>> seconds late and your are out of the door so quickly you cannot even
>>>> realize it.
>>>>
>>>>  But let's not limit ourselves to banks: how do you think your
>>>> previous statements stands in these scenarios?
>>>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>> about a few seconds delay in control when fying planes?)
>>>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>> if just for a couple of seconds all traffic lights become green?)
>>>>
>>>>  Not good enough.
>>>>
>>>>
>>>>  ...small time changes as typically done via NTP
>>>>
>>>>
>>>>
>>>> NTP is only one of the possible sources of this problem. The root of it
>>>> is that the JVM is counting nanoseconds delays using absolute values based
>>>> on a wallclock: I do not think it's that smart.
>>>>
>>>>
>>>>   So there is an issue that needs to be addressed but the situation is
>>>>> nowhere near as dire as you make out
>>>>>
>>>>
>>>>
>>>>  Let's try to put this in perspective, shall we? In case the clock run
>>>> backwards LockSupport.park() will be waiting for the nanoseconds requested
>>>> plus the amount of seconds/minute/hours/days requested to compensate. Now,
>>>> this primitive is used by almost *every* concurrency construct available on
>>>> the platform, such as AbstractQueuedSynchronizer (and subclasses),
>>>> ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and
>>>> subclasses), Executors, FutureTask, .... (too long to list them all, but I
>>>> think we have the picture) and also low levels synchronization primitives
>>>> of the language itself, so Object::wait(:long) and the related sychronized
>>>> blocks.
>>>>
>>>>  I think it's pretty dire.
>>>>
>>>>
>>>>  Cheers,
>>>>
>>>>      Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au
>>>> > wrote:
>>>>
>>>>>  Hi Bruno,
>>>>>
>>>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>>>> created it! - has never been a private bug).
>>>>>
>>>>> A few notes on the "very frightening" aspect of this:
>>>>>
>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been
>>>>> introduced into a specific glibc version for the futex-wait code such that
>>>>> it now responds to changes in the system time for absolute waits, where for
>>>>> all the years previous it did not. The fix seems to have been applied in
>>>>> late 2011 or early 2012 but I don't know the exact glibc version. There is
>>>>> also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it
>>>>> will eventually make its way into 32-bit linux too.
>>>>>
>>>>> 2. The effects of this is not that "all the threads parked will hang,
>>>>> with unpredictable/corrupted/useless"! The effects are very simple an
>>>>> quite predictable. If the system time goes forward then timed-waits
>>>>> (Object.wait, LockSupport.park) (which should be relative times) will
>>>>> return early as the absolute-time that the relative time was converted to
>>>>> will be seen to have been reached (Thread.sleep contains a guard against
>>>>> early returns). This is not actually a problem as you can not distinguish
>>>>> this case from a "spurious wakeup" which code is supposed to account
>>>>> for. If the time is changed backwards then these timed-waits & sleeps will
>>>>> not timeout when expected as the the for that is now further in the future,
>>>>> by the amount of the backward time change. Hence small time changes as
>>>>> typically done via NTP are NOT a problem. Timed-waits use timeouts as a
>>>>> heuristics for recovering when the expected real event notification does
>>>>> not occur - so a delayed timeout does not affect operation in a correctly
>>>>> functioning system. Early timeouts are indistinguishable from spurious
>>>>> wakeups, which code has to account for, so again not a problem for regular
>>>>> code. The only time a significant "hang" will occur is with Thread.sleep
>>>>> and a large backward time shift - but there is little real code that uses
>>>>> Thread.sleep in any critical way.
>>>>>
>>>>> So there is an issue that needs to be addressed but the situation is
>>>>> nowhere near as dire as you make out.
>>>>>
>>>>> David Holmes
>>>>>
>>>>> -----Original Message-----
>>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno
>>>>> bossola
>>>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>> *To:* concurrency-interest at cs.oswego.edu
>>>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue -
>>>>> feedback?
>>>>>
>>>>>   Hi all,
>>>>>
>>>>> I am writing here following a suggestion by Ben Evans. I wanted to
>>>>> check with you about an issue that my teams found on the JVM and that's
>>>>> very frightening. I already started the discussion with the engineers of
>>>>> the hotspot VM team but it looks like we need more awareness to solve this
>>>>> one and I'd really appreciate some help and some push :)
>>>>>  It looks to me that this issue is affecting every JVM64 running on
>>>>> Linux64, so imho it's quite important to be looked at.
>>>>>
>>>>> *Executive summary
>>>>> *The implementation of the concurrency primitive
>>>>> LockSupport.parkNanos(), the function that controls most concurrency
>>>>> primitive on the JVM, is flawed, and any NTP sync, or system time change,
>>>>> can potentially break it with unexpected results across the board.
>>>>>
>>>>> *What we need to do?
>>>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>>>> include it in a later patch release. In an ideal world it would be nice to
>>>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>>>> works based on priorities: being this qualified as P4 means it won't be
>>>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>
>>>>>
>>>>> *Why all this urgency?
>>>>> *If a system time change happens then all the threads parked will
>>>>> hang, with unpredictable/corrupted/useless results to the end user. Same
>>>>> applies to Future, Queue, Executor, and (I guess) any other construct that
>>>>> it's somehow related to concurrency. This is a big issue for us and for any
>>>>> near time application: please think about trading and betting, where the
>>>>> JVM is largely used, and  do not restrain yourself to the Java language:
>>>>> add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>
>>>>> *Tech details**
>>>>> *To be more clear about the issue, the extent of it and the
>>>>> concurrency library, let me introduce this very simple program:
>>>>>
>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>
>>>>> public class Main {
>>>>>
>>>>>     public static void main(String[] args) {
>>>>>
>>>>>         for (int i=100; i>0; i--) {
>>>>>             System.out.println(i);
>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>         }
>>>>>
>>>>>         System.out.println("Done!");
>>>>>     }
>>>>> }
>>>>>
>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>>>> whole concurrency library.
>>>>>
>>>>>  To prove that this is fixable, I reimplemented the program above
>>>>> above substituting  LockSupport.parkNanos()  with  a JNI call to
>>>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>
>>>>>  This is due to the fact  that the CPP code is calling the
>>>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is
>>>>> the actual "system time": each time my system syncs time using a NTP server
>>>>> on the net, the time might jump forward or backward. The correct call
>>>>> (again on Linux)  would require to use CLOCK_MONOTONIC as clock id,
>>>>> which are defined by POSIX specs since 2002. (or better
>>>>> CLOCK_MONOTONIC_RAW)
>>>>>
>>>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>>>> clock via clock_settime() shall have no effect on threads that are blocked
>>>>> waiting for a *relative* time service based upon this clock...": it
>>>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>> it appears that the park() is using compute_abstime() (which uses
>>>>> timeofday) and then waits on an absolute period: for that reason it's
>>>>> influenced by the system clock change. *Very wrong*.
>>>>>
>>>>>  I will be happy to know what you think, and if you can help me to
>>>>> escalate this issue I think that the all Java community will benefit from
>>>>> it.
>>>>>
>>>>> Cheers,
>>>>>
>>>>>      Bruno
>>>>>
>>>>>
>>>>   No virus found in this message.
>>>> Checked by AVG - www.avg.com
>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date:
>>>> 09/03/13
>>>>
>>>>
>>>
>>>
>>>   _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/8da5dc3e/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 13:03:28 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 18:03:28 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
Message-ID: <5228B960.6010305@oracle.com>

Quite the opposite. You presented a design that relies on the magnitude 
of the negative value of awaitNanos, which is not defined. I can't find 
a example of such algorithm in j.u.c, and I don't think your concurrent 
design is sound.

Alex

On 05/09/2013 17:50, bruno bossola wrote:
> I am sorry but I really cannot spend more time creating more samples 
> and I am quite sure you could do a better work at that! At the moment 
> to me that matter is clear enough, but feel free to ask, I will very 
> happy to help! In the meantime I prefer spend my time to work on a 
> patch that I can apply on my JVMs :)
>
> Cheers,
>
>     Bruno
>
>
>
> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     This is far from reproducing the problem with arbitrary j.u.c
>     locks and queues hanging.
>
>     Condition.awaitNanos can return a negative value. If you are
>     expecting the negative value to be small, then how small do you
>     expect it to be?
>
>
>     Alex
>
>
>     On 05/09/2013 02:12, bruno bossola wrote:
>>     Hi Oaleksandr,
>>
>>     Please apologize me if my english was not good enough to provide
>>     you an example that make sense: for that reason I decided to go
>>     back to a binary deliverable (code) that shows the problem, hope
>>     this helps!
>>
>>     This is my PreciousPool class, that handles Precious resources:
>>
>>     import java.text.SimpleDateFormat;
>>     import java.util.ArrayList;
>>     import java.util.Date;
>>     import java.util.List;
>>     import java.util.concurrent.TimeUnit;
>>     import java.util.concurrent.locks.Condition;
>>     import java.util.concurrent.locks.Lock;
>>     import java.util.concurrent.locks.ReentrantLock;
>>
>>     public class PreciousPool {
>>
>>         public static class Precious {
>>             private final int id;
>>
>>             private Precious() {
>>     this.id <http://this.id> = 100+(int)(Math.random()*900.0);
>>             }
>>
>>             public String toString() {
>>                 return "Precious n."+id;
>>             }
>>         }
>>
>>         private final Lock lock;
>>         private final Condition ready;
>>         private final long timeoutInMillis;
>>
>>         private final List<Precious> preciousLended;
>>         private final List<Precious> preciousAvailable;
>>
>>         public PreciousPool(int size, long timeoutInSeconds) {
>>             this.lock = new ReentrantLock();
>>             this.ready = lock.newCondition();
>>
>>             this.timeoutInMillis = 1000L*timeoutInSeconds;
>>             this.preciousLended =  new ArrayList<Precious>();
>>             this.preciousAvailable = new ArrayList<Precious>();
>>
>>             for (int i = 0; i < size; i++) {
>>                 preciousAvailable.add(new Precious());
>>             }
>>         }
>>
>>         public Precious obtain()  {
>>             lock.lock();
>>             try {
>>                 // if no precious are available we wait for the
>>     specified timeout (releasing the lock so that others can try)
>>                 if (preciousAvailable.size() == 0) {
>>                     try {
>>                         ready.await(timeoutInMillis,
>>     TimeUnit.MILLISECONDS);
>>                     } catch (InterruptedException e) {
>>     Thread.currentThread().interrupt();
>>                         throw new RuntimeException("Somebody
>>     interrupted me!", e);
>>                     }
>>                 }
>>
>>                 // if a precious is available we unload it and return
>>     to the caller, otherwise null
>>                 if (preciousAvailable.size() > 0) {
>>                     Precious value = preciousAvailable.remove(0);
>>                     preciousLended.add(value);
>>                     return value;
>>                 } else {
>>                     return null;
>>                 }
>>             } finally {
>>                 lock.unlock();
>>             }
>>         }
>>
>>         public void release(Precious value) {
>>             lock.lock();
>>             try {
>>                 if (!preciousLended.remove(value))
>>                     throw new RuntimeException("Element "+value+" was
>>     not lended!");
>>
>>                 // if a precious is returned we put it back and
>>     signal to anybody waiting
>>                 preciousAvailable.add(value);
>>                 ready.signalAll();
>>             } finally {
>>                 lock.unlock();
>>             }
>>         }
>>
>>         public static void main(String args[]) {
>>             final int size = 3;
>>             final PreciousPool pool = new PreciousPool(size, 5);
>>
>>             // let's exhaust the pool
>>             for (int i=0; i<size; i++)
>>                 dump(pool.obtain());
>>
>>             // and as we are stubborn we continuosly ask for a new one
>>             while(true) {
>>                 dump(pool.obtain());
>>             }
>>         }
>>
>>         private static void dump(Precious precious) {
>>             if (precious == null)
>>                 log("I did not get my precious :(");
>>             else
>>                 log("I did get my precious! "+precious);
>>         }
>>
>>         private static void log(String message) {
>>             final String now = new SimpleDateFormat("HH:mm:ss:SSSS
>>     ").format(new Date());
>>             System.out.println(now + message);
>>         }
>>     }
>>
>>     So, the main is a single thread (no need for multithreading here,
>>     let's keep it simple), that first exhaust the whole pool and then
>>     keep asking, without success, for a resource. Stubborn guy, I
>>     say, but it happens. If you run this program everything works as
>>     expected: you are greeted by a three successful Precious and then
>>     an endless list of failures, that it continuously grow. All good :)
>>
>>     02:34:40:0061 I did get my precious! Precious n.156
>>     02:34:40:0062 I did get my precious! Precious n.991
>>     02:34:40:0062 I did get my precious! Precious n.953
>>     02:34:45:0064 I did not get my precious :(
>>     02:34:50:0065 I did not get my precious :(
>>     02:34:55:0066 I did not get my precious :(
>>     02:35:00:0067 I did not get my precious :(
>>     02:35:05:0068 I did not get my precious :(
>>     [...]
>>
>>     But guess what happens when, while the program is running, I
>>     change the date of my system back of one hour? Everything stops, 
>>     it's simple as that. No prints, nothing, zero, nada. Now, If it
>>     wasn't so late, I would probably wait one hour in order to have
>>     my program restored to his normal process, but as a customer I
>>     won't be terribly happy :)
>>
>>     I hope my point is now clear.
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>
>>
>>
>>     On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         n 04/09/2013 18:54, bruno bossola wrote:
>>>         Hi Oleksandr,
>>>
>>>             Where in the design of those systems is a real-time
>>>             timer? The one that delivers time events uncompromised
>>>             even by GC latency?
>>>
>>>         I don't think so :) If somebody needs a real time
>>>         implementation he needs to go for a real time JVM, like Jean
>>>         correctly pointed out.  The concurrency primitives are
>>>         depending on LockSupport.parkNanos(...) to park a thread: if
>>>         this for any reason is not working (like it is) then strange
>>>         things may happen.
>>         Your assumption is that it is not working, if the elapsed
>>         time is longer. This is the flawed assumption.
>>
>>         Also, you need to read fine print on those "real time" JVMs.
>>         The catch is in the definition of "real time".
>>
>>
>>
>>
>>>         Imagine, for example, that you are using a ReentrantLock to
>>>         control a very precious resource used across the board (what
>>>         about a database connection pool?) and you are unlucky
>>>         enough to have a system time change (backwards) while you
>>>         are locking: all the threads that want to use such resource
>>>         will be progressively locked: not forever, but for the
>>>         amount of time the clock went back. Probably most (all?) of
>>>         your system freezes, and the only option you have is to
>>>         wait, or restart.
>>>         Now place this in a large application server, that provide
>>>         services for hunreds (thousands) of users. How does it sound
>>>         to you?
>>         It sounds like you don't understand how the locks work.
>>
>>
>>         Alex
>>
>>
>>>
>>>         BTW, at the moment we could have a watchdog (in Python :))
>>>         that restarts it, but, I dunno why, I don't like it a lot...
>>>
>>>         Cheers,
>>>
>>>             Bruno
>>>
>>>
>>>
>>>
>>>
>>>         On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             You are missing the point.
>>>
>>>             Where in the design of those systems is a real-time
>>>             timer? The one that delivers time events uncompromised
>>>             even by GC latency?
>>>
>>>             The whole concurrency lot does not depend on the timeout
>>>             magnitude for correctness.
>>>
>>>             Alex
>>>
>>>
>>>             On 04/09/2013 12:05, bruno bossola wrote:
>>>>             Hi David
>>>>
>>>>
>>>>                 bugs.sun.com <http://bugs.sun.com> is not a live
>>>>                 reflection of the bug database but gets updated
>>>>                 periodically (every 12 hours I think).
>>>>
>>>>
>>>>             Good to know :) I will be eagerly clicking on it to
>>>>             discover the new priority! Thanks for that, I really
>>>>             appreciate it.
>>>>
>>>>
>>>>                 The issue arises on certain 64-bit linux
>>>>                 kernel/glibc versions. If you have an older version
>>>>                 this does not impact you.
>>>>
>>>>             You saw my list: nobody will use an older Kernel/glibc
>>>>             version in production.
>>>>
>>>>
>>>>                 As for the rest, show me real code in such systems
>>>>                 that rely on sleep for correctness or
>>>>                 performance/timeliness and I will show you broken code.
>>>>
>>>>             You are still hitting about the sleep(), I understand
>>>>             and I agree about this. But here we are not talking
>>>>             about sleeps: we are talking about the whole
>>>>             concurrency lot. And yes, as I already said, we are
>>>>             talking about near time systems, like trading
>>>>             application, betting applications, air traffic control
>>>>             systems, car traffic control systems. Don't you think
>>>>             this bug might place Oracle JVM outside of these markets?
>>>>
>>>>
>>>>                 If this was as dire as you make out do you not
>>>>                 think that this issue would have been raised far
>>>>                 more than it has? [....] prudent
>>>>                 developers/companies trial platform upgrades to
>>>>                 check for these kinds of issues before switching to
>>>>                 them in production environments.
>>>>
>>>>             I am waiting now for the part where you say that we
>>>>             should throw away Linux and use Oracle Solaris :) In
>>>>             all seriousness, there's a lot of action "in the
>>>>             middle", and I think that Oracle cannot oversee that.
>>>>             For example a lot of trading software system can be
>>>>             installed on premises, where you usually have no
>>>>             control over the environment: what I would do is to put
>>>>             a native daemon in my app so that if I see the system
>>>>             clock change I would kill myself, just in case. And
>>>>             this is a solution that I know for a fact (sorry, I
>>>>             cannot make a reference) it's used in production in a
>>>>             very important trading application.
>>>>
>>>>             Regarding that specific bug, it was not accessible to
>>>>             the external until two days ago, so I guess nobody
>>>>             really knew a lot about it, but I will make sure it
>>>>             will :) so that we can get more traction.
>>>>
>>>>             Cheers,
>>>>
>>>>                 Bruno
>>>>
>>>>
>>>>
>>>>             On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>             <davidcholmes at aapt.net.au
>>>>             <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>
>>>>                 Bruno,
>>>>                 bugs.sun.com <http://bugs.sun.com> is not a live
>>>>                 reflection of the bug database but gets updated
>>>>                 periodically (every 12 hours I think).
>>>>                 The issue arises on certain 64-bit linux
>>>>                 kernel/glibc versions. If you have an older version
>>>>                 this does not impact you.
>>>>                 As for the rest, show me real code in such systems
>>>>                 that rely on sleep for correctness or
>>>>                 performance/timelinessand I will show you broken
>>>>                 code. We are not talking about real-time
>>>>                 systemshere. park(nanos)/wait(millis) will only be
>>>>                 affected by the backward time change if the real
>>>>                 notification they are waiting for does not happen.
>>>>                 Timeouts with these APIs are heuristics, they are
>>>>                 defensive programming to cover the case "what if
>>>>                 the notification I'm waiting for does not come".
>>>>                 The code that would be affected by this issue is a
>>>>                 very small % of the code that uses the API.
>>>>                 If this was as dire as you make out do you not
>>>>                 think that this issue would have been raised far
>>>>                 more than it has? This issue does need addressing
>>>>                 because the number of affected systems will grow as
>>>>                 these newer linux systems are adopted, but prudent
>>>>                 developers/companies trial platform upgrades to
>>>>                 check for these kinds of issues before swicthing to
>>>>                 them in production environments.
>>>>                 Regards,
>>>>                 David
>>>>
>>>>                     -----Original Message-----
>>>>                     *From:* bruno bossola
>>>>                     [mailto:bbossola at gmail.com
>>>>                     <mailto:bbossola at gmail.com>]
>>>>                     *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>                     *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>                     *Cc:* concurrency-interest at cs.oswego.edu
>>>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>                     *Subject:* Re: [concurrency-interest]
>>>>                     Outstanding concurrency JVM issue - feedback?
>>>>
>>>>                     Hi David,
>>>>
>>>>                     thanks for following up.
>>>>
>>>>                         I have raised the priority on 6900441
>>>>
>>>>                     Thanks, but it looks still like a P4:
>>>>                     http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>                     See also the attached snapshot, just in case it
>>>>                     changes :)
>>>>
>>>>                     Inline image 2
>>>>
>>>>                         [...] which to my knowledge [...] has never
>>>>                         been a private bug
>>>>
>>>>                     It was not accessible using bugs.sun.com
>>>>                     <http://bugs.sun.com/>, this was translated to
>>>>                     private. I also received the same info
>>>>                     indirectly from the 7u lead:
>>>>                     "I'm not sure why 6900441 isn't public. (I'll
>>>>                     follow up with owner of bugs.sun.com
>>>>                     <http://bugs.sun.com/>)", I guess you can check
>>>>                     with him.
>>>>
>>>>
>>>>                         It doesn't affect "every JVM64 running on
>>>>                         Linux64".  A fix has been introduced into a
>>>>                         specific glibc version...
>>>>
>>>>                     ...and apparently did not make it. I was able
>>>>                     to reproduce this even with the IBM VM, so to
>>>>                     speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10,
>>>>                     11, 12, 13 + some random Debian. I did not have
>>>>                     a JDK5, so I cannot say, but on JDK4 everything
>>>>                     works (that's the reason why I call it a
>>>>                     regression). (ah, if you look at the bug, it
>>>>                     lists also JDK5, so I think we are pretty much
>>>>                     covered here).
>>>>                     If you still have doubts tough, please have
>>>>                     also a look on stackoverflow to see how it was
>>>>                     reproduced consistently on probably every
>>>>                     64bitJVM over 64bitLinux in the world.
>>>>
>>>>
>>>>                         The effects of this is not that "all the
>>>>                         threads parked will hang, with
>>>>                         unpredictable/corrupted/useless"! The
>>>>                         effects are very simple an quite
>>>>                         predictable... [deletia]s.
>>>>
>>>>                     We have very different views, and I find quite
>>>>                     difficult to accept yours. You are confusing my
>>>>                     sample program which contains a single thread
>>>>                     in a for loop with any other complex
>>>>                     multi-threading concurrent system written in
>>>>                     Java. For example, if you ever worked in a bank
>>>>                     you surely know what I mean. You are comparing
>>>>                     some random sleep() put into a program by some
>>>>                     newbie, with the complex ecosystem of a
>>>>                     concurrent platform written to manage trading
>>>>                     information on very fast market. In that
>>>>                     condition, I am sorry, statements such
>>>>                     "...delayed timeout does not affect operation
>>>>                     in a correctly functioning system..." and
>>>>                     "...small time changes [...] are not a problem"
>>>>                     are really not applicable. Let your system
>>>>                     place an order three seconds late and your are
>>>>                     out of the door so quickly you cannot even
>>>>                     realize it.
>>>>
>>>>                     But let's not limit ourselves to banks: how do
>>>>                     you think your previous statements stands in
>>>>                     these scenarios?
>>>>                     - air control systems
>>>>                     <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>                     about a few seconds delay in control when fying
>>>>                     planes?)
>>>>                     - city traffic control systems
>>>>                     <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>                     if just for a couple of seconds all traffic
>>>>                     lights become green?)
>>>>
>>>>                     Not good enough.
>>>>
>>>>
>>>>                         ...small time changes as typically done via NTP
>>>>
>>>>                     NTP is only one of the possible sources of this
>>>>                     problem. The root of it is that the JVM is
>>>>                     counting nanoseconds delays using absolute
>>>>                     values based on a wallclock: I do not think
>>>>                     it's that smart.
>>>>
>>>>
>>>>                         So there is an issue that needs to be
>>>>                         addressed but the situation is nowhere near
>>>>                         as dire as you make out
>>>>
>>>>                     Let's try to put this in perspective, shall we?
>>>>                     In case the clock run
>>>>                     backwards LockSupport.park() will be waiting
>>>>                     for the nanoseconds requested plus the amount
>>>>                     of seconds/minute/hours/days requested to
>>>>                     compensate. Now, this primitive is used by
>>>>                     almost *every* concurrency construct available
>>>>                     on the platform, such as
>>>>                     AbstractQueuedSynchronizer (and subclasses),
>>>>                     ReentrantLock (and subclasses), CyclicBarrier,
>>>>                     BlockingQueue (and subclasses), Executors,
>>>>                     FutureTask, .... (too long to list them all,
>>>>                     but I think we have the picture) and also low
>>>>                     levels synchronization primitives of the
>>>>                     language itself, so Object::wait(:long) and the
>>>>                     related sychronized blocks.
>>>>
>>>>                     I think it's pretty dire.
>>>>
>>>>
>>>>                     Cheers,
>>>>
>>>>                         Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>                     On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
>>>>                     <davidcholmes at aapt.net.au
>>>>                     <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>
>>>>                         Hi Bruno,
>>>>                         I have raised the priority on 6900441
>>>>                         (which to my knowledge - and I created it!
>>>>                         - has never been a private bug).
>>>>                         A few notes on the "very frightening"
>>>>                         aspect of this:
>>>>                         1. It doesn't affect "every JVM64 running
>>>>                         on Linux64". A fix has been introduced into
>>>>                         a specific glibc version for the futex-wait
>>>>                         code such that it now responds to changes
>>>>                         in the system time for absolute waits,
>>>>                         where for all the years previous it did
>>>>                         not. The fix seems to have been applied in
>>>>                         late 2011 or early 2012 but I don't know
>>>>                         the exact glibc version. There is also a
>>>>                         32-bit version of the fix that was proposed
>>>>                         on Nov 27, 2012, so it will eventually make
>>>>                         its way into 32-bit linux too.
>>>>                         2. The effects of this is not that "all the
>>>>                         threads parked will hang, with
>>>>                         unpredictable/corrupted/useless"! The
>>>>                         effects are very simple an quite
>>>>                         predictable. If the system time goes
>>>>                         forward then timed-waits (Object.wait,
>>>>                         LockSupport.park) (which should be relative
>>>>                         times) will return early as the
>>>>                         absolute-time that the relative time was
>>>>                         converted to will be seen to have been
>>>>                         reached (Thread.sleep contains a guard
>>>>                         against early returns). This is not
>>>>                         actually a problem as you can not
>>>>                         distinguish this case from a "spurious
>>>>                         wakeup" which code is supposed to account
>>>>                         for. If the time is changed backwards then
>>>>                         these timed-waits & sleeps will not timeout
>>>>                         when expected as the the for that is now
>>>>                         further in the future, by the amount of the
>>>>                         backward time change. Hence small time
>>>>                         changes as typically done via NTP are NOT a
>>>>                         problem. Timed-waits use timeouts as a
>>>>                         heuristics for recovering when the expected
>>>>                         real event notification does not occur - so
>>>>                         a delayed timeout does not affect operation
>>>>                         in a correctly functioning system. Early
>>>>                         timeouts are indistinguishable from
>>>>                         spurious wakeups, which code has to account
>>>>                         for, so again not a problem for regular
>>>>                         code. The only time a significant "hang"
>>>>                         will occur is with Thread.sleep and a large
>>>>                         backward time shift - but there is little
>>>>                         real code that uses Thread.sleep in any
>>>>                         critical way.
>>>>                         So there is an issue that needs to be
>>>>                         addressed but the situation is nowhere near
>>>>                         as dire as you make out.
>>>>                         David Holmes
>>>>
>>>>                             -----Original Message-----
>>>>                             *From:*
>>>>                             concurrency-interest-bounces at cs.oswego.edu
>>>>                             <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>                             [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>                             <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>                             Behalf Of *bruno bossola
>>>>                             *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>                             *To:*
>>>>                             concurrency-interest at cs.oswego.edu
>>>>                             <mailto:concurrency-interest at cs.oswego.edu>
>>>>                             *Subject:* [concurrency-interest]
>>>>                             Outstanding concurrency JVM issue -
>>>>                             feedback?
>>>>
>>>>                             Hi all,
>>>>
>>>>                             I am writing here following a
>>>>                             suggestion by Ben Evans. I wanted to
>>>>                             check with you about an issue that my
>>>>                             teams found on the JVM and that's very
>>>>                             frightening. I already started the
>>>>                             discussion with the engineers of the
>>>>                             hotspot VM team but it looks like we
>>>>                             need more awareness to solve this one
>>>>                             and I'd really appreciate some help and
>>>>                             some push :)
>>>>                             It looks to me that this issue is
>>>>                             affecting every JVM64 running on
>>>>                             Linux64, so imho it's quite important
>>>>                             to be looked at.
>>>>
>>>>                             *Executive summary
>>>>                             *The implementation of the concurrency
>>>>                             primitive LockSupport.parkNanos(), the
>>>>                             function that controls most concurrency
>>>>                             primitive on the JVM, is flawed, and
>>>>                             any NTP sync, or system time change,
>>>>                             can potentially break it with
>>>>                             unexpected results across the board.
>>>>
>>>>                             *What we need to do?
>>>>                             *This is an old issue, and the bug
>>>>                             <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>                             was declared private. I somehow managed
>>>>                             to have the bug reopened to the public,
>>>>                             but it's still a  P4, that means that
>>>>                             probably won't be fixed. I think we
>>>>                             need to push for a resolution ASAP, be
>>>>                             sure that's in for JDK9, make all the
>>>>                             possible effort to make this fix for
>>>>                             JDK8 or, at least, to include it in a
>>>>                             later patch release. In an ideal world
>>>>                             it would be nice to have a patch for
>>>>                             JDK7. As far as I understand the
>>>>                             hotspot engineering team works based on
>>>>                             priorities: being this qualified as P4
>>>>                             means it won't be probably worked on
>>>>                             (if you follow the breadcrumbs of bugs
>>>>                             and fixes you can go back to 2002!)
>>>>                             They acknowledge the problem, it has
>>>>                             been flagged to management, but 1) it's
>>>>                             low priority 2) it's too risky to fix
>>>>                             for JDK8
>>>>
>>>>
>>>>                             *Why all this urgency?
>>>>                             *If a system time change happens then
>>>>                             all the threads parked will hang, with
>>>>                             unpredictable/corrupted/useless results
>>>>                             to the end user. Same applies to
>>>>                             Future, Queue, Executor, and (I guess)
>>>>                             any other construct that it's somehow
>>>>                             related to concurrency. This is a big
>>>>                             issue for us and for any near time
>>>>                             application: please think about trading
>>>>                             and betting, where the JVM is largely
>>>>                             used, and  do not restrain yourself to
>>>>                             the Java language: add Scala and any
>>>>                             other JVM-based language to the picture
>>>>                             (JRuby, Jython...)
>>>>
>>>>                             *Tech details**
>>>>                             *To be more clear about the issue, the
>>>>                             extent of it and the concurrency
>>>>                             library, let me introduce this very
>>>>                             simple program:
>>>>
>>>>                             import
>>>>                             java.util.concurrent.locks.LockSupport;
>>>>
>>>>                             public class Main {
>>>>
>>>>                                 public static void main(String[]
>>>>                             args) {
>>>>
>>>>                                     for (int i=100; i>0; i--) {
>>>>                             System.out.println(i);
>>>>                             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>                                     }
>>>>
>>>>                             System.out.println("Done!");
>>>>                                 }
>>>>                             }
>>>>
>>>>                             Run it with a 64bit 1.6+ JVM on 64bit
>>>>                             Linux, turn the clock down one hour and
>>>>                             wait until the counter stops... magic! 
>>>>                             I tested this on JDK6, JDK7 and latest
>>>>                             JDK8 beta running on various Ubuntu
>>>>                             distros. It's not just a matter of
>>>>                             (old?) sleep() and wait() primitives,
>>>>                             this issue it affects the whole
>>>>                             concurrency library.
>>>>
>>>>                             To prove that this is fixable, I
>>>>                             reimplemented the program above above
>>>>                             substituting LockSupport.parkNanos()
>>>>                             with  a JNI call to
>>>>                             clock_nanosleep(CLOCK_MONOTONIC...):
>>>>                             works like a charm :(
>>>>
>>>>                             This is due to the fact  that the CPP
>>>>                             code is calling the
>>>>                             pthread_cond_timedwait() using its
>>>>                             default clock (CLOCK_REALTIME) which,
>>>>                             unfortunately is affected by
>>>>                             settime()/settimeofday() calls (on
>>>>                             Linux): for that reason it cannot be
>>>>                             used to measure nanoseconds delays,
>>>>                             which is what the specification
>>>>                             <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>                             requires. CLOCK_REALTIME is not
>>>>                             guaranteed to monotonically count as
>>>>                             this is the actual "system time": each
>>>>                             time my system syncs time using a NTP
>>>>                             server on the net, the time might jump
>>>>                             forward or backward. The correct call
>>>>                             (again on Linux)  would require to use
>>>>                             CLOCK_MONOTONIC as clock id, which are
>>>>                             defined by POSIX specs since 2002. (or
>>>>                             better CLOCK_MONOTONIC_RAW)
>>>>
>>>>                             The POSIX spec
>>>>                             <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>                             is infact clear, as it states
>>>>                             "...setting the value of the
>>>>                             CLOCK_REALTIME clock via
>>>>                             clock_settime() shall have no effect on
>>>>                             threads that are blocked waiting for a
>>>>                             *relative* time service based upon this
>>>>                             clock...": it definitely states
>>>>                             "relative". Having a look at the
>>>>                             hotspot code
>>>>                             <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>                             it appears that the park() is using
>>>>                             compute_abstime() (which uses
>>>>                             timeofday) and then waits on an
>>>>                             absolute period: for that reason it's
>>>>                             influenced by the system clock change.
>>>>                             *Very wrong*.
>>>>
>>>>                             I will be happy to know what you think,
>>>>                             and if you can help me to escalate this
>>>>                             issue I think that the all Java
>>>>                             community will benefit from it.
>>>>
>>>>                             Cheers,
>>>>
>>>>                                 Bruno
>>>>
>>>>
>>>>                     No virus found in this message.
>>>>                     Checked by AVG - www.avg.com <http://www.avg.com>
>>>>                     Version: 2013.0.3392 / Virus Database:
>>>>                     3222/6633 - Release Date: 09/03/13
>>>>
>>>>
>>>>
>>>>
>>>>             _______________________________________________
>>>>             Concurrency-interest mailing list
>>>>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/ea8ef664/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 13:06:19 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 18:06:19 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
Message-ID: <5228BA0B.2050306@oracle.com>

Oh, and now someone else is going to complain that awaitNanos returns a 
negative number, even though it waited for only 1 ms out of 100.

Alex

On 05/09/2013 17:50, bruno bossola wrote:
> I am sorry but I really cannot spend more time creating more samples 
> and I am quite sure you could do a better work at that! At the moment 
> to me that matter is clear enough, but feel free to ask, I will very 
> happy to help! In the meantime I prefer spend my time to work on a 
> patch that I can apply on my JVMs :)
>
> Cheers,
>
>     Bruno
>
>
>
> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     This is far from reproducing the problem with arbitrary j.u.c
>     locks and queues hanging.
>
>     Condition.awaitNanos can return a negative value. If you are
>     expecting the negative value to be small, then how small do you
>     expect it to be?
>
>
>     Alex
>
>
>     On 05/09/2013 02:12, bruno bossola wrote:
>>     Hi Oaleksandr,
>>
>>     Please apologize me if my english was not good enough to provide
>>     you an example that make sense: for that reason I decided to go
>>     back to a binary deliverable (code) that shows the problem, hope
>>     this helps!
>>
>>     This is my PreciousPool class, that handles Precious resources:
>>
>>     import java.text.SimpleDateFormat;
>>     import java.util.ArrayList;
>>     import java.util.Date;
>>     import java.util.List;
>>     import java.util.concurrent.TimeUnit;
>>     import java.util.concurrent.locks.Condition;
>>     import java.util.concurrent.locks.Lock;
>>     import java.util.concurrent.locks.ReentrantLock;
>>
>>     public class PreciousPool {
>>
>>         public static class Precious {
>>             private final int id;
>>
>>             private Precious() {
>>     this.id <http://this.id> = 100+(int)(Math.random()*900.0);
>>             }
>>
>>             public String toString() {
>>                 return "Precious n."+id;
>>             }
>>         }
>>
>>         private final Lock lock;
>>         private final Condition ready;
>>         private final long timeoutInMillis;
>>
>>         private final List<Precious> preciousLended;
>>         private final List<Precious> preciousAvailable;
>>
>>         public PreciousPool(int size, long timeoutInSeconds) {
>>             this.lock = new ReentrantLock();
>>             this.ready = lock.newCondition();
>>
>>             this.timeoutInMillis = 1000L*timeoutInSeconds;
>>             this.preciousLended =  new ArrayList<Precious>();
>>             this.preciousAvailable = new ArrayList<Precious>();
>>
>>             for (int i = 0; i < size; i++) {
>>                 preciousAvailable.add(new Precious());
>>             }
>>         }
>>
>>         public Precious obtain()  {
>>             lock.lock();
>>             try {
>>                 // if no precious are available we wait for the
>>     specified timeout (releasing the lock so that others can try)
>>                 if (preciousAvailable.size() == 0) {
>>                     try {
>>                         ready.await(timeoutInMillis,
>>     TimeUnit.MILLISECONDS);
>>                     } catch (InterruptedException e) {
>>     Thread.currentThread().interrupt();
>>                         throw new RuntimeException("Somebody
>>     interrupted me!", e);
>>                     }
>>                 }
>>
>>                 // if a precious is available we unload it and return
>>     to the caller, otherwise null
>>                 if (preciousAvailable.size() > 0) {
>>                     Precious value = preciousAvailable.remove(0);
>>                     preciousLended.add(value);
>>                     return value;
>>                 } else {
>>                     return null;
>>                 }
>>             } finally {
>>                 lock.unlock();
>>             }
>>         }
>>
>>         public void release(Precious value) {
>>             lock.lock();
>>             try {
>>                 if (!preciousLended.remove(value))
>>                     throw new RuntimeException("Element "+value+" was
>>     not lended!");
>>
>>                 // if a precious is returned we put it back and
>>     signal to anybody waiting
>>                 preciousAvailable.add(value);
>>                 ready.signalAll();
>>             } finally {
>>                 lock.unlock();
>>             }
>>         }
>>
>>         public static void main(String args[]) {
>>             final int size = 3;
>>             final PreciousPool pool = new PreciousPool(size, 5);
>>
>>             // let's exhaust the pool
>>             for (int i=0; i<size; i++)
>>                 dump(pool.obtain());
>>
>>             // and as we are stubborn we continuosly ask for a new one
>>             while(true) {
>>                 dump(pool.obtain());
>>             }
>>         }
>>
>>         private static void dump(Precious precious) {
>>             if (precious == null)
>>                 log("I did not get my precious :(");
>>             else
>>                 log("I did get my precious! "+precious);
>>         }
>>
>>         private static void log(String message) {
>>             final String now = new SimpleDateFormat("HH:mm:ss:SSSS
>>     ").format(new Date());
>>             System.out.println(now + message);
>>         }
>>     }
>>
>>     So, the main is a single thread (no need for multithreading here,
>>     let's keep it simple), that first exhaust the whole pool and then
>>     keep asking, without success, for a resource. Stubborn guy, I
>>     say, but it happens. If you run this program everything works as
>>     expected: you are greeted by a three successful Precious and then
>>     an endless list of failures, that it continuously grow. All good :)
>>
>>     02:34:40:0061 I did get my precious! Precious n.156
>>     02:34:40:0062 I did get my precious! Precious n.991
>>     02:34:40:0062 I did get my precious! Precious n.953
>>     02:34:45:0064 I did not get my precious :(
>>     02:34:50:0065 I did not get my precious :(
>>     02:34:55:0066 I did not get my precious :(
>>     02:35:00:0067 I did not get my precious :(
>>     02:35:05:0068 I did not get my precious :(
>>     [...]
>>
>>     But guess what happens when, while the program is running, I
>>     change the date of my system back of one hour? Everything stops, 
>>     it's simple as that. No prints, nothing, zero, nada. Now, If it
>>     wasn't so late, I would probably wait one hour in order to have
>>     my program restored to his normal process, but as a customer I
>>     won't be terribly happy :)
>>
>>     I hope my point is now clear.
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>
>>
>>
>>     On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         n 04/09/2013 18:54, bruno bossola wrote:
>>>         Hi Oleksandr,
>>>
>>>             Where in the design of those systems is a real-time
>>>             timer? The one that delivers time events uncompromised
>>>             even by GC latency?
>>>
>>>         I don't think so :) If somebody needs a real time
>>>         implementation he needs to go for a real time JVM, like Jean
>>>         correctly pointed out.  The concurrency primitives are
>>>         depending on LockSupport.parkNanos(...) to park a thread: if
>>>         this for any reason is not working (like it is) then strange
>>>         things may happen.
>>         Your assumption is that it is not working, if the elapsed
>>         time is longer. This is the flawed assumption.
>>
>>         Also, you need to read fine print on those "real time" JVMs.
>>         The catch is in the definition of "real time".
>>
>>
>>
>>
>>>         Imagine, for example, that you are using a ReentrantLock to
>>>         control a very precious resource used across the board (what
>>>         about a database connection pool?) and you are unlucky
>>>         enough to have a system time change (backwards) while you
>>>         are locking: all the threads that want to use such resource
>>>         will be progressively locked: not forever, but for the
>>>         amount of time the clock went back. Probably most (all?) of
>>>         your system freezes, and the only option you have is to
>>>         wait, or restart.
>>>         Now place this in a large application server, that provide
>>>         services for hunreds (thousands) of users. How does it sound
>>>         to you?
>>         It sounds like you don't understand how the locks work.
>>
>>
>>         Alex
>>
>>
>>>
>>>         BTW, at the moment we could have a watchdog (in Python :))
>>>         that restarts it, but, I dunno why, I don't like it a lot...
>>>
>>>         Cheers,
>>>
>>>             Bruno
>>>
>>>
>>>
>>>
>>>
>>>         On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             You are missing the point.
>>>
>>>             Where in the design of those systems is a real-time
>>>             timer? The one that delivers time events uncompromised
>>>             even by GC latency?
>>>
>>>             The whole concurrency lot does not depend on the timeout
>>>             magnitude for correctness.
>>>
>>>             Alex
>>>
>>>
>>>             On 04/09/2013 12:05, bruno bossola wrote:
>>>>             Hi David
>>>>
>>>>
>>>>                 bugs.sun.com <http://bugs.sun.com> is not a live
>>>>                 reflection of the bug database but gets updated
>>>>                 periodically (every 12 hours I think).
>>>>
>>>>
>>>>             Good to know :) I will be eagerly clicking on it to
>>>>             discover the new priority! Thanks for that, I really
>>>>             appreciate it.
>>>>
>>>>
>>>>                 The issue arises on certain 64-bit linux
>>>>                 kernel/glibc versions. If you have an older version
>>>>                 this does not impact you.
>>>>
>>>>             You saw my list: nobody will use an older Kernel/glibc
>>>>             version in production.
>>>>
>>>>
>>>>                 As for the rest, show me real code in such systems
>>>>                 that rely on sleep for correctness or
>>>>                 performance/timeliness and I will show you broken code.
>>>>
>>>>             You are still hitting about the sleep(), I understand
>>>>             and I agree about this. But here we are not talking
>>>>             about sleeps: we are talking about the whole
>>>>             concurrency lot. And yes, as I already said, we are
>>>>             talking about near time systems, like trading
>>>>             application, betting applications, air traffic control
>>>>             systems, car traffic control systems. Don't you think
>>>>             this bug might place Oracle JVM outside of these markets?
>>>>
>>>>
>>>>                 If this was as dire as you make out do you not
>>>>                 think that this issue would have been raised far
>>>>                 more than it has? [....] prudent
>>>>                 developers/companies trial platform upgrades to
>>>>                 check for these kinds of issues before switching to
>>>>                 them in production environments.
>>>>
>>>>             I am waiting now for the part where you say that we
>>>>             should throw away Linux and use Oracle Solaris :) In
>>>>             all seriousness, there's a lot of action "in the
>>>>             middle", and I think that Oracle cannot oversee that.
>>>>             For example a lot of trading software system can be
>>>>             installed on premises, where you usually have no
>>>>             control over the environment: what I would do is to put
>>>>             a native daemon in my app so that if I see the system
>>>>             clock change I would kill myself, just in case. And
>>>>             this is a solution that I know for a fact (sorry, I
>>>>             cannot make a reference) it's used in production in a
>>>>             very important trading application.
>>>>
>>>>             Regarding that specific bug, it was not accessible to
>>>>             the external until two days ago, so I guess nobody
>>>>             really knew a lot about it, but I will make sure it
>>>>             will :) so that we can get more traction.
>>>>
>>>>             Cheers,
>>>>
>>>>                 Bruno
>>>>
>>>>
>>>>
>>>>             On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>             <davidcholmes at aapt.net.au
>>>>             <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>
>>>>                 Bruno,
>>>>                 bugs.sun.com <http://bugs.sun.com> is not a live
>>>>                 reflection of the bug database but gets updated
>>>>                 periodically (every 12 hours I think).
>>>>                 The issue arises on certain 64-bit linux
>>>>                 kernel/glibc versions. If you have an older version
>>>>                 this does not impact you.
>>>>                 As for the rest, show me real code in such systems
>>>>                 that rely on sleep for correctness or
>>>>                 performance/timelinessand I will show you broken
>>>>                 code. We are not talking about real-time
>>>>                 systemshere. park(nanos)/wait(millis) will only be
>>>>                 affected by the backward time change if the real
>>>>                 notification they are waiting for does not happen.
>>>>                 Timeouts with these APIs are heuristics, they are
>>>>                 defensive programming to cover the case "what if
>>>>                 the notification I'm waiting for does not come".
>>>>                 The code that would be affected by this issue is a
>>>>                 very small % of the code that uses the API.
>>>>                 If this was as dire as you make out do you not
>>>>                 think that this issue would have been raised far
>>>>                 more than it has? This issue does need addressing
>>>>                 because the number of affected systems will grow as
>>>>                 these newer linux systems are adopted, but prudent
>>>>                 developers/companies trial platform upgrades to
>>>>                 check for these kinds of issues before swicthing to
>>>>                 them in production environments.
>>>>                 Regards,
>>>>                 David
>>>>
>>>>                     -----Original Message-----
>>>>                     *From:* bruno bossola
>>>>                     [mailto:bbossola at gmail.com
>>>>                     <mailto:bbossola at gmail.com>]
>>>>                     *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>                     *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>                     *Cc:* concurrency-interest at cs.oswego.edu
>>>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>                     *Subject:* Re: [concurrency-interest]
>>>>                     Outstanding concurrency JVM issue - feedback?
>>>>
>>>>                     Hi David,
>>>>
>>>>                     thanks for following up.
>>>>
>>>>                         I have raised the priority on 6900441
>>>>
>>>>                     Thanks, but it looks still like a P4:
>>>>                     http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>                     See also the attached snapshot, just in case it
>>>>                     changes :)
>>>>
>>>>                     Inline image 2
>>>>
>>>>                         [...] which to my knowledge [...] has never
>>>>                         been a private bug
>>>>
>>>>                     It was not accessible using bugs.sun.com
>>>>                     <http://bugs.sun.com/>, this was translated to
>>>>                     private. I also received the same info
>>>>                     indirectly from the 7u lead:
>>>>                     "I'm not sure why 6900441 isn't public. (I'll
>>>>                     follow up with owner of bugs.sun.com
>>>>                     <http://bugs.sun.com/>)", I guess you can check
>>>>                     with him.
>>>>
>>>>
>>>>                         It doesn't affect "every JVM64 running on
>>>>                         Linux64".  A fix has been introduced into a
>>>>                         specific glibc version...
>>>>
>>>>                     ...and apparently did not make it. I was able
>>>>                     to reproduce this even with the IBM VM, so to
>>>>                     speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10,
>>>>                     11, 12, 13 + some random Debian. I did not have
>>>>                     a JDK5, so I cannot say, but on JDK4 everything
>>>>                     works (that's the reason why I call it a
>>>>                     regression). (ah, if you look at the bug, it
>>>>                     lists also JDK5, so I think we are pretty much
>>>>                     covered here).
>>>>                     If you still have doubts tough, please have
>>>>                     also a look on stackoverflow to see how it was
>>>>                     reproduced consistently on probably every
>>>>                     64bitJVM over 64bitLinux in the world.
>>>>
>>>>
>>>>                         The effects of this is not that "all the
>>>>                         threads parked will hang, with
>>>>                         unpredictable/corrupted/useless"! The
>>>>                         effects are very simple an quite
>>>>                         predictable... [deletia]s.
>>>>
>>>>                     We have very different views, and I find quite
>>>>                     difficult to accept yours. You are confusing my
>>>>                     sample program which contains a single thread
>>>>                     in a for loop with any other complex
>>>>                     multi-threading concurrent system written in
>>>>                     Java. For example, if you ever worked in a bank
>>>>                     you surely know what I mean. You are comparing
>>>>                     some random sleep() put into a program by some
>>>>                     newbie, with the complex ecosystem of a
>>>>                     concurrent platform written to manage trading
>>>>                     information on very fast market. In that
>>>>                     condition, I am sorry, statements such
>>>>                     "...delayed timeout does not affect operation
>>>>                     in a correctly functioning system..." and
>>>>                     "...small time changes [...] are not a problem"
>>>>                     are really not applicable. Let your system
>>>>                     place an order three seconds late and your are
>>>>                     out of the door so quickly you cannot even
>>>>                     realize it.
>>>>
>>>>                     But let's not limit ourselves to banks: how do
>>>>                     you think your previous statements stands in
>>>>                     these scenarios?
>>>>                     - air control systems
>>>>                     <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>                     about a few seconds delay in control when fying
>>>>                     planes?)
>>>>                     - city traffic control systems
>>>>                     <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>                     if just for a couple of seconds all traffic
>>>>                     lights become green?)
>>>>
>>>>                     Not good enough.
>>>>
>>>>
>>>>                         ...small time changes as typically done via NTP
>>>>
>>>>                     NTP is only one of the possible sources of this
>>>>                     problem. The root of it is that the JVM is
>>>>                     counting nanoseconds delays using absolute
>>>>                     values based on a wallclock: I do not think
>>>>                     it's that smart.
>>>>
>>>>
>>>>                         So there is an issue that needs to be
>>>>                         addressed but the situation is nowhere near
>>>>                         as dire as you make out
>>>>
>>>>                     Let's try to put this in perspective, shall we?
>>>>                     In case the clock run
>>>>                     backwards LockSupport.park() will be waiting
>>>>                     for the nanoseconds requested plus the amount
>>>>                     of seconds/minute/hours/days requested to
>>>>                     compensate. Now, this primitive is used by
>>>>                     almost *every* concurrency construct available
>>>>                     on the platform, such as
>>>>                     AbstractQueuedSynchronizer (and subclasses),
>>>>                     ReentrantLock (and subclasses), CyclicBarrier,
>>>>                     BlockingQueue (and subclasses), Executors,
>>>>                     FutureTask, .... (too long to list them all,
>>>>                     but I think we have the picture) and also low
>>>>                     levels synchronization primitives of the
>>>>                     language itself, so Object::wait(:long) and the
>>>>                     related sychronized blocks.
>>>>
>>>>                     I think it's pretty dire.
>>>>
>>>>
>>>>                     Cheers,
>>>>
>>>>                         Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>                     On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
>>>>                     <davidcholmes at aapt.net.au
>>>>                     <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>
>>>>                         Hi Bruno,
>>>>                         I have raised the priority on 6900441
>>>>                         (which to my knowledge - and I created it!
>>>>                         - has never been a private bug).
>>>>                         A few notes on the "very frightening"
>>>>                         aspect of this:
>>>>                         1. It doesn't affect "every JVM64 running
>>>>                         on Linux64". A fix has been introduced into
>>>>                         a specific glibc version for the futex-wait
>>>>                         code such that it now responds to changes
>>>>                         in the system time for absolute waits,
>>>>                         where for all the years previous it did
>>>>                         not. The fix seems to have been applied in
>>>>                         late 2011 or early 2012 but I don't know
>>>>                         the exact glibc version. There is also a
>>>>                         32-bit version of the fix that was proposed
>>>>                         on Nov 27, 2012, so it will eventually make
>>>>                         its way into 32-bit linux too.
>>>>                         2. The effects of this is not that "all the
>>>>                         threads parked will hang, with
>>>>                         unpredictable/corrupted/useless"! The
>>>>                         effects are very simple an quite
>>>>                         predictable. If the system time goes
>>>>                         forward then timed-waits (Object.wait,
>>>>                         LockSupport.park) (which should be relative
>>>>                         times) will return early as the
>>>>                         absolute-time that the relative time was
>>>>                         converted to will be seen to have been
>>>>                         reached (Thread.sleep contains a guard
>>>>                         against early returns). This is not
>>>>                         actually a problem as you can not
>>>>                         distinguish this case from a "spurious
>>>>                         wakeup" which code is supposed to account
>>>>                         for. If the time is changed backwards then
>>>>                         these timed-waits & sleeps will not timeout
>>>>                         when expected as the the for that is now
>>>>                         further in the future, by the amount of the
>>>>                         backward time change. Hence small time
>>>>                         changes as typically done via NTP are NOT a
>>>>                         problem. Timed-waits use timeouts as a
>>>>                         heuristics for recovering when the expected
>>>>                         real event notification does not occur - so
>>>>                         a delayed timeout does not affect operation
>>>>                         in a correctly functioning system. Early
>>>>                         timeouts are indistinguishable from
>>>>                         spurious wakeups, which code has to account
>>>>                         for, so again not a problem for regular
>>>>                         code. The only time a significant "hang"
>>>>                         will occur is with Thread.sleep and a large
>>>>                         backward time shift - but there is little
>>>>                         real code that uses Thread.sleep in any
>>>>                         critical way.
>>>>                         So there is an issue that needs to be
>>>>                         addressed but the situation is nowhere near
>>>>                         as dire as you make out.
>>>>                         David Holmes
>>>>
>>>>                             -----Original Message-----
>>>>                             *From:*
>>>>                             concurrency-interest-bounces at cs.oswego.edu
>>>>                             <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>                             [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>                             <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>                             Behalf Of *bruno bossola
>>>>                             *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>                             *To:*
>>>>                             concurrency-interest at cs.oswego.edu
>>>>                             <mailto:concurrency-interest at cs.oswego.edu>
>>>>                             *Subject:* [concurrency-interest]
>>>>                             Outstanding concurrency JVM issue -
>>>>                             feedback?
>>>>
>>>>                             Hi all,
>>>>
>>>>                             I am writing here following a
>>>>                             suggestion by Ben Evans. I wanted to
>>>>                             check with you about an issue that my
>>>>                             teams found on the JVM and that's very
>>>>                             frightening. I already started the
>>>>                             discussion with the engineers of the
>>>>                             hotspot VM team but it looks like we
>>>>                             need more awareness to solve this one
>>>>                             and I'd really appreciate some help and
>>>>                             some push :)
>>>>                             It looks to me that this issue is
>>>>                             affecting every JVM64 running on
>>>>                             Linux64, so imho it's quite important
>>>>                             to be looked at.
>>>>
>>>>                             *Executive summary
>>>>                             *The implementation of the concurrency
>>>>                             primitive LockSupport.parkNanos(), the
>>>>                             function that controls most concurrency
>>>>                             primitive on the JVM, is flawed, and
>>>>                             any NTP sync, or system time change,
>>>>                             can potentially break it with
>>>>                             unexpected results across the board.
>>>>
>>>>                             *What we need to do?
>>>>                             *This is an old issue, and the bug
>>>>                             <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>                             was declared private. I somehow managed
>>>>                             to have the bug reopened to the public,
>>>>                             but it's still a  P4, that means that
>>>>                             probably won't be fixed. I think we
>>>>                             need to push for a resolution ASAP, be
>>>>                             sure that's in for JDK9, make all the
>>>>                             possible effort to make this fix for
>>>>                             JDK8 or, at least, to include it in a
>>>>                             later patch release. In an ideal world
>>>>                             it would be nice to have a patch for
>>>>                             JDK7. As far as I understand the
>>>>                             hotspot engineering team works based on
>>>>                             priorities: being this qualified as P4
>>>>                             means it won't be probably worked on
>>>>                             (if you follow the breadcrumbs of bugs
>>>>                             and fixes you can go back to 2002!)
>>>>                             They acknowledge the problem, it has
>>>>                             been flagged to management, but 1) it's
>>>>                             low priority 2) it's too risky to fix
>>>>                             for JDK8
>>>>
>>>>
>>>>                             *Why all this urgency?
>>>>                             *If a system time change happens then
>>>>                             all the threads parked will hang, with
>>>>                             unpredictable/corrupted/useless results
>>>>                             to the end user. Same applies to
>>>>                             Future, Queue, Executor, and (I guess)
>>>>                             any other construct that it's somehow
>>>>                             related to concurrency. This is a big
>>>>                             issue for us and for any near time
>>>>                             application: please think about trading
>>>>                             and betting, where the JVM is largely
>>>>                             used, and  do not restrain yourself to
>>>>                             the Java language: add Scala and any
>>>>                             other JVM-based language to the picture
>>>>                             (JRuby, Jython...)
>>>>
>>>>                             *Tech details**
>>>>                             *To be more clear about the issue, the
>>>>                             extent of it and the concurrency
>>>>                             library, let me introduce this very
>>>>                             simple program:
>>>>
>>>>                             import
>>>>                             java.util.concurrent.locks.LockSupport;
>>>>
>>>>                             public class Main {
>>>>
>>>>                                 public static void main(String[]
>>>>                             args) {
>>>>
>>>>                                     for (int i=100; i>0; i--) {
>>>>                             System.out.println(i);
>>>>                             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>                                     }
>>>>
>>>>                             System.out.println("Done!");
>>>>                                 }
>>>>                             }
>>>>
>>>>                             Run it with a 64bit 1.6+ JVM on 64bit
>>>>                             Linux, turn the clock down one hour and
>>>>                             wait until the counter stops... magic! 
>>>>                             I tested this on JDK6, JDK7 and latest
>>>>                             JDK8 beta running on various Ubuntu
>>>>                             distros. It's not just a matter of
>>>>                             (old?) sleep() and wait() primitives,
>>>>                             this issue it affects the whole
>>>>                             concurrency library.
>>>>
>>>>                             To prove that this is fixable, I
>>>>                             reimplemented the program above above
>>>>                             substituting LockSupport.parkNanos()
>>>>                             with  a JNI call to
>>>>                             clock_nanosleep(CLOCK_MONOTONIC...):
>>>>                             works like a charm :(
>>>>
>>>>                             This is due to the fact  that the CPP
>>>>                             code is calling the
>>>>                             pthread_cond_timedwait() using its
>>>>                             default clock (CLOCK_REALTIME) which,
>>>>                             unfortunately is affected by
>>>>                             settime()/settimeofday() calls (on
>>>>                             Linux): for that reason it cannot be
>>>>                             used to measure nanoseconds delays,
>>>>                             which is what the specification
>>>>                             <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>                             requires. CLOCK_REALTIME is not
>>>>                             guaranteed to monotonically count as
>>>>                             this is the actual "system time": each
>>>>                             time my system syncs time using a NTP
>>>>                             server on the net, the time might jump
>>>>                             forward or backward. The correct call
>>>>                             (again on Linux)  would require to use
>>>>                             CLOCK_MONOTONIC as clock id, which are
>>>>                             defined by POSIX specs since 2002. (or
>>>>                             better CLOCK_MONOTONIC_RAW)
>>>>
>>>>                             The POSIX spec
>>>>                             <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>                             is infact clear, as it states
>>>>                             "...setting the value of the
>>>>                             CLOCK_REALTIME clock via
>>>>                             clock_settime() shall have no effect on
>>>>                             threads that are blocked waiting for a
>>>>                             *relative* time service based upon this
>>>>                             clock...": it definitely states
>>>>                             "relative". Having a look at the
>>>>                             hotspot code
>>>>                             <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>                             it appears that the park() is using
>>>>                             compute_abstime() (which uses
>>>>                             timeofday) and then waits on an
>>>>                             absolute period: for that reason it's
>>>>                             influenced by the system clock change.
>>>>                             *Very wrong*.
>>>>
>>>>                             I will be happy to know what you think,
>>>>                             and if you can help me to escalate this
>>>>                             issue I think that the all Java
>>>>                             community will benefit from it.
>>>>
>>>>                             Cheers,
>>>>
>>>>                                 Bruno
>>>>
>>>>
>>>>                     No virus found in this message.
>>>>                     Checked by AVG - www.avg.com <http://www.avg.com>
>>>>                     Version: 2013.0.3392 / Virus Database:
>>>>                     3222/6633 - Release Date: 09/03/13
>>>>
>>>>
>>>>
>>>>
>>>>             _______________________________________________
>>>>             Concurrency-interest mailing list
>>>>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/4704c8f3/attachment-0001.html>

From viktor.klang at gmail.com  Thu Sep  5 13:31:16 2013
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 5 Sep 2013 13:31:16 -0400
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5228BA0B.2050306@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
Message-ID: <CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>

For Condition.awaitNanos it states:

Returns:an estimate of the nanosTimeout value minus the time spent waiting
upon return from this method. A positive value may be used as the argument
to a subsequent call to this method to finish waiting out the desired time.
*A value less than or equal to zero indicates that no time remains.*





On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  Oh, and now someone else is going to complain that awaitNanos returns a
> negative number, even though it waited for only 1 ms out of 100.
>
> Alex
>
> On 05/09/2013 17:50, bruno bossola wrote:
>
>  I am sorry but I really cannot spend more time creating more samples and
> I am quite sure you could do a better work at that! At the moment to me
> that matter is clear enough, but feel free to ask, I will very happy to
> help! In the meantime I prefer spend my time to work on a patch that I can
> apply on my JVMs :)
>
>  Cheers,
>
>      Bruno
>
>
>
> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  This is far from reproducing the problem with arbitrary j.u.c locks and
>> queues hanging.
>>
>> Condition.awaitNanos can return a negative value. If you are expecting
>> the negative value to be small, then how small do you expect it to be?
>>
>>
>> Alex
>>
>>
>> On 05/09/2013 02:12, bruno bossola wrote:
>>
>>  Hi Oaleksandr,
>>
>>  Please apologize me if my english was not good enough to provide you an
>> example that make sense: for that reason I decided to go back to a binary
>> deliverable (code) that shows the problem, hope this helps!
>>
>>  This is my PreciousPool class, that handles Precious resources:
>>
>> import java.text.SimpleDateFormat;
>> import java.util.ArrayList;
>> import java.util.Date;
>> import java.util.List;
>> import java.util.concurrent.TimeUnit;
>> import java.util.concurrent.locks.Condition;
>> import java.util.concurrent.locks.Lock;
>> import java.util.concurrent.locks.ReentrantLock;
>>
>> public class PreciousPool {
>>
>>     public static class Precious {
>>         private final int id;
>>
>>         private Precious() {
>>             this.id = 100+(int)(Math.random()*900.0);
>>         }
>>
>>         public String toString() {
>>             return "Precious n."+id;
>>         }
>>     }
>>
>>     private final Lock lock;
>>     private final Condition ready;
>>     private final long timeoutInMillis;
>>
>>     private final List<Precious> preciousLended;
>>     private final List<Precious> preciousAvailable;
>>
>>     public PreciousPool(int size, long timeoutInSeconds) {
>>         this.lock = new ReentrantLock();
>>         this.ready = lock.newCondition();
>>
>>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>>         this.preciousLended =  new ArrayList<Precious>();
>>         this.preciousAvailable = new ArrayList<Precious>();
>>
>>         for (int i = 0; i < size; i++) {
>>             preciousAvailable.add(new Precious());
>>         }
>>     }
>>
>>     public Precious obtain()  {
>>         lock.lock();
>>         try {
>>             // if no precious are available we wait for the specified
>> timeout (releasing the lock so that others can try)
>>             if (preciousAvailable.size() == 0) {
>>                 try {
>>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>                 } catch (InterruptedException e) {
>>                     Thread.currentThread().interrupt();
>>                     throw new RuntimeException("Somebody interrupted
>> me!", e);
>>                 }
>>             }
>>
>>             // if a precious is available we unload it and return to the
>> caller, otherwise null
>>             if (preciousAvailable.size() > 0) {
>>                 Precious value = preciousAvailable.remove(0);
>>                 preciousLended.add(value);
>>                 return value;
>>             } else {
>>                 return null;
>>             }
>>         } finally {
>>             lock.unlock();
>>         }
>>     }
>>
>>     public void release(Precious value) {
>>         lock.lock();
>>         try {
>>             if (!preciousLended.remove(value))
>>                 throw new RuntimeException("Element "+value+" was not
>> lended!");
>>
>>             // if a precious is returned we put it back and signal to
>> anybody waiting
>>             preciousAvailable.add(value);
>>             ready.signalAll();
>>         } finally {
>>             lock.unlock();
>>         }
>>     }
>>
>>     public static void main(String args[]) {
>>         final int size = 3;
>>         final PreciousPool pool = new PreciousPool(size, 5);
>>
>>         // let's exhaust the pool
>>         for (int i=0; i<size; i++)
>>             dump(pool.obtain());
>>
>>         // and as we are stubborn we continuosly ask for a new one
>>         while(true) {
>>             dump(pool.obtain());
>>         }
>>     }
>>
>>     private static void dump(Precious precious) {
>>         if (precious == null)
>>             log("I did not get my precious :(");
>>         else
>>             log("I did get my precious! "+precious);
>>     }
>>
>>     private static void log(String message) {
>>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS
>> ").format(new Date());
>>         System.out.println(now + message);
>>     }
>> }
>>
>> So, the main is a single thread (no need for multithreading here, let's
>> keep it simple), that first exhaust the whole pool and then keep asking,
>> without success, for a resource. Stubborn guy, I say, but it happens. If
>> you run this program everything works as expected: you are greeted by a
>> three successful Precious and then an endless list of failures, that it
>> continuously grow. All good :)
>>
>> 02:34:40:0061 I did get my precious! Precious n.156
>> 02:34:40:0062 I did get my precious! Precious n.991
>> 02:34:40:0062 I did get my precious! Precious n.953
>> 02:34:45:0064 I did not get my precious :(
>> 02:34:50:0065 I did not get my precious :(
>> 02:34:55:0066 I did not get my precious :(
>> 02:35:00:0067 I did not get my precious :(
>> 02:35:05:0068 I did not get my precious :(
>> [...]
>>
>>  But guess what happens when, while the program is running, I change the
>> date of my system back of one hour? Everything stops,  it's simple as that.
>> No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
>> wait one hour in order to have my program restored to his normal process,
>> but as a customer I won't be terribly happy :)
>>
>>  I hope my point is now clear.
>>  Cheers,
>>
>>      Bruno
>>
>>
>>
>>
>>
>>
>> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>>  n 04/09/2013 18:54, bruno bossola wrote:
>>>
>>>   Hi Oleksandr,
>>>
>>> Where in the design of those systems is a real-time timer? The one that
>>>> delivers time events uncompromised even by GC latency?
>>>>
>>>
>>>>
>>>  I don't think so :) If somebody needs a real time implementation he
>>> needs to go for a real time JVM, like Jean correctly pointed out.  The
>>> concurrency primitives are depending on LockSupport.parkNanos(...) to park
>>> a thread: if this for any reason is not working (like it is) then strange
>>> things may happen.
>>>
>>>  Your assumption is that it is not working, if the elapsed time is
>>> longer. This is the flawed assumption.
>>>
>>> Also, you need to read fine print on those "real time" JVMs. The catch
>>> is in the definition of "real time".
>>>
>>>
>>>
>>>
>>>  Imagine, for example, that you are using a ReentrantLock to control a
>>> very precious resource used across the board (what about a database
>>> connection pool?) and you are unlucky enough to have a system time change
>>> (backwards) while you are locking: all the threads that want to use such
>>> resource will be progressively locked: not forever, but for the amount of
>>> time the clock went back. Probably most (all?) of your system freezes, and
>>> the only option you have is to wait, or restart.
>>>  Now place this in a large application server, that provide services
>>> for hunreds (thousands) of users. How does it sound to you?
>>>
>>>  It sounds like you don't understand how the locks work.
>>>
>>>
>>> Alex
>>>
>>>
>>>
>>>  BTW, at the moment we could have a watchdog (in Python :)) that
>>> restarts it, but, I dunno why, I don't like it a lot...
>>>
>>>  Cheers,
>>>
>>>      Bruno
>>>
>>>
>>>
>>>>
>>>
>>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
>>> oleksandr.otenko at oracle.com> wrote:
>>>
>>>>  You are missing the point.
>>>>
>>>> Where in the design of those systems is a real-time timer? The one that
>>>> delivers time events uncompromised even by GC latency?
>>>>
>>>> The whole concurrency lot does not depend on the timeout magnitude for
>>>> correctness.
>>>>
>>>> Alex
>>>>
>>>>
>>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>>
>>>>   Hi David
>>>>
>>>>
>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>>> updated periodically (every 12 hours I think).
>>>>>
>>>>
>>>>>
>>>> Good to know :) I will be eagerly clicking on it to discover the new
>>>> priority! Thanks for that, I really appreciate it.
>>>>
>>>>
>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>>> have an older version this does not impact you.
>>>>>
>>>>
>>>>>
>>>> You saw my list: nobody will use an older Kernel/glibc version in
>>>> production.
>>>>
>>>>
>>>> As for the rest, show me real code in such systems that rely on sleep
>>>>> for correctness or performance/timeliness and I will show you broken code.
>>>>
>>>>
>>>>>
>>>>  You are still hitting about the sleep(), I understand and I agree
>>>> about this. But here we are not talking about sleeps: we are talking about
>>>> the whole concurrency lot. And yes, as I already said, we are talking about
>>>> near time systems, like trading application, betting applications, air
>>>> traffic control systems, car traffic control systems. Don't you think this
>>>> bug might place Oracle JVM outside of these markets?
>>>>
>>>>
>>>>
>>>>> If this was as dire as you make out do you not think that this issue
>>>>> would have been raised far more than it has? [....] prudent
>>>>> developers/companies trial platform upgrades to check for these kinds of
>>>>> issues before switching to them in production environments.
>>>>>
>>>>>  I am waiting now for the part where you say that we should throw
>>>> away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
>>>> action "in the middle", and I think that Oracle cannot oversee that. For
>>>> example a lot of trading software system can be installed on premises,
>>>> where you usually have no control over the environment: what I would do is
>>>> to put a native daemon in my app so that if I see the system clock change I
>>>> would kill myself, just in case. And this is a solution that I know for a
>>>> fact (sorry, I cannot make a reference) it's used in production in a very
>>>> important trading application.
>>>>
>>>> Regarding that specific bug, it was not accessible to the external
>>>> until two days ago, so I guess nobody really knew a lot about it, but I
>>>> will make sure it will :) so that we can get more traction.
>>>>
>>>>  Cheers,
>>>>
>>>>      Bruno
>>>>
>>>>
>>>>
>>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>>>
>>>>>  Bruno,
>>>>>
>>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>>> updated periodically (every 12 hours I think).
>>>>>
>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>>> have an older version this does not impact you.
>>>>>
>>>>> As for the rest, show me real code in such systems that rely on sleep
>>>>> for correctness or performance/timeliness and I will show you broken
>>>>> code. We are not talking about real-time systems here. park(nanos)/wait(millis)
>>>>> will only be affected by the backward time change if the real notification
>>>>> they are waiting for does not happen. Timeouts with these APIs are
>>>>> heuristics, they are defensive programming to cover the case "what if the
>>>>> notification I'm waiting for does not come". The code that would be
>>>>> affected by this issue is a very small % of the code that uses the API.
>>>>>
>>>>> If this was as dire as you make out do you not think that this issue
>>>>> would have been raised far more than it has? This issue does need
>>>>> addressing because the number of affected systems will grow as these newer
>>>>> linux systems are adopted, but prudent developers/companies trial platform
>>>>> upgrades to check for these kinds of issues before swicthing to them in
>>>>> production environments.
>>>>>
>>>>> Regards,
>>>>> David
>>>>>
>>>>>  -----Original Message-----
>>>>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>>>>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>> *To:* dholmes at ieee.org
>>>>> *Cc:* concurrency-interest at cs.oswego.edu
>>>>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM
>>>>> issue - feedback?
>>>>>
>>>>>    Hi David,
>>>>>
>>>>>  thanks for following up.
>>>>>
>>>>>
>>>>>
>>>>>> I have raised the priority on 6900441
>>>>>>
>>>>>
>>>>>
>>>>>  Thanks, but it looks still like a P4:
>>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>> See also the attached snapshot, just in case it changes :)
>>>>>
>>>>>  [image: Inline image 2]
>>>>>
>>>>>  [...] which to my knowledge [...] has never been a private bug
>>>>>>
>>>>>
>>>>> It was not accessible using bugs.sun.com, this was translated to
>>>>> private. I also received the same info indirectly from the 7u lead:
>>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>>>>> bugs.sun.com)", I guess you can check with him.
>>>>>
>>>>>
>>>>>  It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>>>>> introduced into a specific glibc version...
>>>>>>
>>>>>
>>>>> ...and apparently did not make it. I was able to reproduce this even
>>>>> with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>>> 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on
>>>>> JDK4 everything works (that's the reason why I call it a regression). (ah,
>>>>> if you look at the bug, it lists also JDK5, so I think we are pretty much
>>>>> covered here).
>>>>> If you still have doubts tough, please have also a look on
>>>>> stackoverflow to see how it was reproduced consistently on probably every
>>>>> 64bitJVM over 64bitLinux in the world.
>>>>>
>>>>>
>>>>>  The effects of this is not that "all the threads parked will hang,
>>>>>> with unpredictable/corrupted/useless"! The effects are very simple an quite
>>>>>> predictable... [deletia]s.
>>>>>
>>>>>
>>>>>
>>>>> We have very different views, and I find quite difficult to accept
>>>>> yours. You are confusing my sample program which contains a single thread
>>>>> in a for loop with any other complex multi-threading concurrent system
>>>>> written in Java. For example, if you ever worked in a bank you surely know
>>>>> what I mean. You are comparing some random sleep() put into a program by
>>>>> some newbie, with the complex ecosystem of a concurrent platform written to
>>>>> manage trading information on very fast market. In that condition, I am
>>>>> sorry, statements such "...delayed timeout does not affect operation in a
>>>>> correctly functioning system..." and "...small time changes [...] are not a
>>>>> problem" are really not applicable. Let your system place an order three
>>>>> seconds late and your are out of the door so quickly you cannot even
>>>>> realize it.
>>>>>
>>>>>  But let's not limit ourselves to banks: how do you think your
>>>>> previous statements stands in these scenarios?
>>>>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>> about a few seconds delay in control when fying planes?)
>>>>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>> if just for a couple of seconds all traffic lights become green?)
>>>>>
>>>>>  Not good enough.
>>>>>
>>>>>
>>>>>  ...small time changes as typically done via NTP
>>>>>
>>>>>
>>>>>
>>>>> NTP is only one of the possible sources of this problem. The root of
>>>>> it is that the JVM is counting nanoseconds delays using absolute values
>>>>> based on a wallclock: I do not think it's that smart.
>>>>>
>>>>>
>>>>>   So there is an issue that needs to be addressed but the situation
>>>>>> is nowhere near as dire as you make out
>>>>>>
>>>>>
>>>>>
>>>>>  Let's try to put this in perspective, shall we? In case the clock
>>>>> run backwards LockSupport.park() will be waiting for the nanoseconds
>>>>> requested plus the amount of seconds/minute/hours/days requested to
>>>>> compensate. Now, this primitive is used by almost *every* concurrency
>>>>> construct available on the platform, such as AbstractQueuedSynchronizer
>>>>> (and subclasses), ReentrantLock (and subclasses), CyclicBarrier,
>>>>> BlockingQueue (and subclasses), Executors, FutureTask, .... (too long to
>>>>> list them all, but I think we have the picture) and also low levels
>>>>> synchronization primitives of the language itself, so Object::wait(:long)
>>>>> and the related sychronized blocks.
>>>>>
>>>>>  I think it's pretty dire.
>>>>>
>>>>>
>>>>>  Cheers,
>>>>>
>>>>>      Bruno
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <
>>>>> davidcholmes at aapt.net.au> wrote:
>>>>>
>>>>>>  Hi Bruno,
>>>>>>
>>>>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>>>>> created it! - has never been a private bug).
>>>>>>
>>>>>> A few notes on the "very frightening" aspect of this:
>>>>>>
>>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has
>>>>>> been introduced into a specific glibc version for the futex-wait code such
>>>>>> that it now responds to changes in the system time for absolute waits,
>>>>>> where for all the years previous it did not. The fix seems to have been
>>>>>> applied in late 2011 or early 2012 but I don't know the exact glibc
>>>>>> version. There is also a 32-bit version of the fix that was proposed on Nov
>>>>>> 27, 2012, so it will eventually make its way into 32-bit linux too.
>>>>>>
>>>>>> 2. The effects of this is not that "all the threads parked will
>>>>>> hang, with unpredictable/corrupted/useless"! The effects are very
>>>>>> simple an quite predictable. If the system time goes forward then
>>>>>> timed-waits (Object.wait, LockSupport.park) (which should be relative
>>>>>> times) will return early as the absolute-time that the relative time was
>>>>>> converted to will be seen to have been reached (Thread.sleep contains a
>>>>>> guard against early returns). This is not actually a problem as you can not
>>>>>> distinguish this case from a "spurious wakeup" which code is supposed to
>>>>>> account for. If the time is changed backwards then these timed-waits &
>>>>>> sleeps will not timeout when expected as the the for that is now further in
>>>>>> the future, by the amount of the backward time change. Hence small time
>>>>>> changes as typically done via NTP are NOT a problem. Timed-waits use
>>>>>> timeouts as a heuristics for recovering when the expected real event
>>>>>> notification does not occur - so a delayed timeout does not affect
>>>>>> operation in a correctly functioning system. Early timeouts are
>>>>>> indistinguishable from spurious wakeups, which code has to account for, so
>>>>>> again not a problem for regular code. The only time a significant "hang"
>>>>>> will occur is with Thread.sleep and a large backward time shift - but there
>>>>>> is little real code that uses Thread.sleep in any critical way.
>>>>>>
>>>>>> So there is an issue that needs to be addressed but the situation is
>>>>>> nowhere near as dire as you make out.
>>>>>>
>>>>>> David Holmes
>>>>>>
>>>>>> -----Original Message-----
>>>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno
>>>>>> bossola
>>>>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>>> *To:* concurrency-interest at cs.oswego.edu
>>>>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue
>>>>>> - feedback?
>>>>>>
>>>>>>   Hi all,
>>>>>>
>>>>>> I am writing here following a suggestion by Ben Evans. I wanted to
>>>>>> check with you about an issue that my teams found on the JVM and that's
>>>>>> very frightening. I already started the discussion with the engineers of
>>>>>> the hotspot VM team but it looks like we need more awareness to solve this
>>>>>> one and I'd really appreciate some help and some push :)
>>>>>>  It looks to me that this issue is affecting every JVM64 running on
>>>>>> Linux64, so imho it's quite important to be looked at.
>>>>>>
>>>>>> *Executive summary
>>>>>> *The implementation of the concurrency primitive
>>>>>> LockSupport.parkNanos(), the function that controls most concurrency
>>>>>> primitive on the JVM, is flawed, and any NTP sync, or system time change,
>>>>>> can potentially break it with unexpected results across the board.
>>>>>>
>>>>>> *What we need to do?
>>>>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>>>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>>>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>>>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>>>>> include it in a later patch release. In an ideal world it would be nice to
>>>>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>>>>> works based on priorities: being this qualified as P4 means it won't be
>>>>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>>>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>>>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>>
>>>>>>
>>>>>> *Why all this urgency?
>>>>>> *If a system time change happens then all the threads parked will
>>>>>> hang, with unpredictable/corrupted/useless results to the end user. Same
>>>>>> applies to Future, Queue, Executor, and (I guess) any other construct that
>>>>>> it's somehow related to concurrency. This is a big issue for us and for any
>>>>>> near time application: please think about trading and betting, where the
>>>>>> JVM is largely used, and  do not restrain yourself to the Java language:
>>>>>> add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>>
>>>>>> *Tech details**
>>>>>> *To be more clear about the issue, the extent of it and the
>>>>>> concurrency library, let me introduce this very simple program:
>>>>>>
>>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>>
>>>>>> public class Main {
>>>>>>
>>>>>>     public static void main(String[] args) {
>>>>>>
>>>>>>         for (int i=100; i>0; i--) {
>>>>>>             System.out.println(i);
>>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>         }
>>>>>>
>>>>>>         System.out.println("Done!");
>>>>>>     }
>>>>>> }
>>>>>>
>>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>>>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>>>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>>>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>>>>> whole concurrency library.
>>>>>>
>>>>>>  To prove that this is fixable, I reimplemented the program above
>>>>>> above substituting  LockSupport.parkNanos()  with  a JNI call to
>>>>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>>
>>>>>>  This is due to the fact  that the CPP code is calling the
>>>>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>>>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>>>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>>>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>>>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is
>>>>>> the actual "system time": each time my system syncs time using a NTP server
>>>>>> on the net, the time might jump forward or backward. The correct call
>>>>>> (again on Linux)  would require to use CLOCK_MONOTONIC as clock id,
>>>>>> which are defined by POSIX specs since 2002. (or better
>>>>>> CLOCK_MONOTONIC_RAW)
>>>>>>
>>>>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>>>>> clock via clock_settime() shall have no effect on threads that are blocked
>>>>>> waiting for a *relative* time service based upon this clock...": it
>>>>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>> it appears that the park() is using compute_abstime() (which uses
>>>>>> timeofday) and then waits on an absolute period: for that reason it's
>>>>>> influenced by the system clock change. *Very wrong*.
>>>>>>
>>>>>>  I will be happy to know what you think, and if you can help me to
>>>>>> escalate this issue I think that the all Java community will benefit from
>>>>>> it.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>>      Bruno
>>>>>>
>>>>>>
>>>>>   No virus found in this message.
>>>>> Checked by AVG - www.avg.com
>>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date:
>>>>> 09/03/13
>>>>>
>>>>>
>>>>
>>>>
>>>>   _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/efe90f8e/attachment-0001.html>

From bbossola at gmail.com  Thu Sep  5 13:38:25 2013
From: bbossola at gmail.com (bruno bossola)
Date: Thu, 5 Sep 2013 18:38:25 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5228B960.6010305@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228B960.6010305@oracle.com>
Message-ID: <CAJU-cA+xn-8ONmTWu2Oa+R47-T+_Ws-4WqS+23K5VgYp_2=CLQ@mail.gmail.com>

> You presented a design that relies on the magnitude of the negative value
of awaitNanos...
>
No :) it's a very simple and legitimate example of usage of locking, that
fails because the park(..) function is implemented using an absolute
deadline based on a wall clock: that's what I call a design "not sound".

Cheers,

    Bruno



On Thu, Sep 5, 2013 at 6:03 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  Quite the opposite. You presented a design that relies on the magnitude
> of the negative value of awaitNanos, which is not defined. I can't find a
> example of such algorithm in j.u.c, and I don't think your concurrent
> design is sound.
>
> Alex
>
> On 05/09/2013 17:50, bruno bossola wrote:
>
>  I am sorry but I really cannot spend more time creating more samples and
> I am quite sure you could do a better work at that! At the moment to me
> that matter is clear enough, but feel free to ask, I will very happy to
> help! In the meantime I prefer spend my time to work on a patch that I can
> apply on my JVMs :)
>
>  Cheers,
>
>      Bruno
>
>
>
> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  This is far from reproducing the problem with arbitrary j.u.c locks and
>> queues hanging.
>>
>> Condition.awaitNanos can return a negative value. If you are expecting
>> the negative value to be small, then how small do you expect it to be?
>>
>>
>> Alex
>>
>>
>> On 05/09/2013 02:12, bruno bossola wrote:
>>
>>  Hi Oaleksandr,
>>
>>  Please apologize me if my english was not good enough to provide you an
>> example that make sense: for that reason I decided to go back to a binary
>> deliverable (code) that shows the problem, hope this helps!
>>
>>  This is my PreciousPool class, that handles Precious resources:
>>
>> import java.text.SimpleDateFormat;
>> import java.util.ArrayList;
>> import java.util.Date;
>> import java.util.List;
>> import java.util.concurrent.TimeUnit;
>> import java.util.concurrent.locks.Condition;
>> import java.util.concurrent.locks.Lock;
>> import java.util.concurrent.locks.ReentrantLock;
>>
>> public class PreciousPool {
>>
>>     public static class Precious {
>>         private final int id;
>>
>>         private Precious() {
>>             this.id = 100+(int)(Math.random()*900.0);
>>         }
>>
>>         public String toString() {
>>             return "Precious n."+id;
>>         }
>>     }
>>
>>     private final Lock lock;
>>     private final Condition ready;
>>     private final long timeoutInMillis;
>>
>>     private final List<Precious> preciousLended;
>>     private final List<Precious> preciousAvailable;
>>
>>     public PreciousPool(int size, long timeoutInSeconds) {
>>         this.lock = new ReentrantLock();
>>         this.ready = lock.newCondition();
>>
>>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>>         this.preciousLended =  new ArrayList<Precious>();
>>         this.preciousAvailable = new ArrayList<Precious>();
>>
>>         for (int i = 0; i < size; i++) {
>>             preciousAvailable.add(new Precious());
>>         }
>>     }
>>
>>     public Precious obtain()  {
>>         lock.lock();
>>         try {
>>             // if no precious are available we wait for the specified
>> timeout (releasing the lock so that others can try)
>>             if (preciousAvailable.size() == 0) {
>>                 try {
>>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>                 } catch (InterruptedException e) {
>>                     Thread.currentThread().interrupt();
>>                     throw new RuntimeException("Somebody interrupted
>> me!", e);
>>                 }
>>             }
>>
>>             // if a precious is available we unload it and return to the
>> caller, otherwise null
>>             if (preciousAvailable.size() > 0) {
>>                 Precious value = preciousAvailable.remove(0);
>>                 preciousLended.add(value);
>>                 return value;
>>             } else {
>>                 return null;
>>             }
>>         } finally {
>>             lock.unlock();
>>         }
>>     }
>>
>>     public void release(Precious value) {
>>         lock.lock();
>>         try {
>>             if (!preciousLended.remove(value))
>>                 throw new RuntimeException("Element "+value+" was not
>> lended!");
>>
>>             // if a precious is returned we put it back and signal to
>> anybody waiting
>>             preciousAvailable.add(value);
>>             ready.signalAll();
>>         } finally {
>>             lock.unlock();
>>         }
>>     }
>>
>>     public static void main(String args[]) {
>>         final int size = 3;
>>         final PreciousPool pool = new PreciousPool(size, 5);
>>
>>         // let's exhaust the pool
>>         for (int i=0; i<size; i++)
>>             dump(pool.obtain());
>>
>>         // and as we are stubborn we continuosly ask for a new one
>>         while(true) {
>>             dump(pool.obtain());
>>         }
>>     }
>>
>>     private static void dump(Precious precious) {
>>         if (precious == null)
>>             log("I did not get my precious :(");
>>         else
>>             log("I did get my precious! "+precious);
>>     }
>>
>>     private static void log(String message) {
>>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS
>> ").format(new Date());
>>         System.out.println(now + message);
>>     }
>> }
>>
>> So, the main is a single thread (no need for multithreading here, let's
>> keep it simple), that first exhaust the whole pool and then keep asking,
>> without success, for a resource. Stubborn guy, I say, but it happens. If
>> you run this program everything works as expected: you are greeted by a
>> three successful Precious and then an endless list of failures, that it
>> continuously grow. All good :)
>>
>> 02:34:40:0061 I did get my precious! Precious n.156
>> 02:34:40:0062 I did get my precious! Precious n.991
>> 02:34:40:0062 I did get my precious! Precious n.953
>> 02:34:45:0064 I did not get my precious :(
>> 02:34:50:0065 I did not get my precious :(
>> 02:34:55:0066 I did not get my precious :(
>> 02:35:00:0067 I did not get my precious :(
>> 02:35:05:0068 I did not get my precious :(
>> [...]
>>
>>  But guess what happens when, while the program is running, I change the
>> date of my system back of one hour? Everything stops,  it's simple as that.
>> No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
>> wait one hour in order to have my program restored to his normal process,
>> but as a customer I won't be terribly happy :)
>>
>>  I hope my point is now clear.
>>  Cheers,
>>
>>      Bruno
>>
>>
>>
>>
>>
>>
>> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>>  n 04/09/2013 18:54, bruno bossola wrote:
>>>
>>>   Hi Oleksandr,
>>>
>>> Where in the design of those systems is a real-time timer? The one that
>>>> delivers time events uncompromised even by GC latency?
>>>>
>>>
>>>>
>>>  I don't think so :) If somebody needs a real time implementation he
>>> needs to go for a real time JVM, like Jean correctly pointed out.  The
>>> concurrency primitives are depending on LockSupport.parkNanos(...) to park
>>> a thread: if this for any reason is not working (like it is) then strange
>>> things may happen.
>>>
>>>  Your assumption is that it is not working, if the elapsed time is
>>> longer. This is the flawed assumption.
>>>
>>> Also, you need to read fine print on those "real time" JVMs. The catch
>>> is in the definition of "real time".
>>>
>>>
>>>
>>>
>>>  Imagine, for example, that you are using a ReentrantLock to control a
>>> very precious resource used across the board (what about a database
>>> connection pool?) and you are unlucky enough to have a system time change
>>> (backwards) while you are locking: all the threads that want to use such
>>> resource will be progressively locked: not forever, but for the amount of
>>> time the clock went back. Probably most (all?) of your system freezes, and
>>> the only option you have is to wait, or restart.
>>>  Now place this in a large application server, that provide services
>>> for hunreds (thousands) of users. How does it sound to you?
>>>
>>>  It sounds like you don't understand how the locks work.
>>>
>>>
>>> Alex
>>>
>>>
>>>
>>>  BTW, at the moment we could have a watchdog (in Python :)) that
>>> restarts it, but, I dunno why, I don't like it a lot...
>>>
>>>  Cheers,
>>>
>>>      Bruno
>>>
>>>
>>>
>>>>
>>>
>>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
>>> oleksandr.otenko at oracle.com> wrote:
>>>
>>>>  You are missing the point.
>>>>
>>>> Where in the design of those systems is a real-time timer? The one that
>>>> delivers time events uncompromised even by GC latency?
>>>>
>>>> The whole concurrency lot does not depend on the timeout magnitude for
>>>> correctness.
>>>>
>>>> Alex
>>>>
>>>>
>>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>>
>>>>   Hi David
>>>>
>>>>
>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>>> updated periodically (every 12 hours I think).
>>>>>
>>>>
>>>>>
>>>> Good to know :) I will be eagerly clicking on it to discover the new
>>>> priority! Thanks for that, I really appreciate it.
>>>>
>>>>
>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>>> have an older version this does not impact you.
>>>>>
>>>>
>>>>>
>>>> You saw my list: nobody will use an older Kernel/glibc version in
>>>> production.
>>>>
>>>>
>>>> As for the rest, show me real code in such systems that rely on sleep
>>>>> for correctness or performance/timeliness and I will show you broken code.
>>>>
>>>>
>>>>>
>>>>  You are still hitting about the sleep(), I understand and I agree
>>>> about this. But here we are not talking about sleeps: we are talking about
>>>> the whole concurrency lot. And yes, as I already said, we are talking about
>>>> near time systems, like trading application, betting applications, air
>>>> traffic control systems, car traffic control systems. Don't you think this
>>>> bug might place Oracle JVM outside of these markets?
>>>>
>>>>
>>>>
>>>>> If this was as dire as you make out do you not think that this issue
>>>>> would have been raised far more than it has? [....] prudent
>>>>> developers/companies trial platform upgrades to check for these kinds of
>>>>> issues before switching to them in production environments.
>>>>>
>>>>>  I am waiting now for the part where you say that we should throw
>>>> away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
>>>> action "in the middle", and I think that Oracle cannot oversee that. For
>>>> example a lot of trading software system can be installed on premises,
>>>> where you usually have no control over the environment: what I would do is
>>>> to put a native daemon in my app so that if I see the system clock change I
>>>> would kill myself, just in case. And this is a solution that I know for a
>>>> fact (sorry, I cannot make a reference) it's used in production in a very
>>>> important trading application.
>>>>
>>>> Regarding that specific bug, it was not accessible to the external
>>>> until two days ago, so I guess nobody really knew a lot about it, but I
>>>> will make sure it will :) so that we can get more traction.
>>>>
>>>>  Cheers,
>>>>
>>>>      Bruno
>>>>
>>>>
>>>>
>>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>>>
>>>>>  Bruno,
>>>>>
>>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>>> updated periodically (every 12 hours I think).
>>>>>
>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>>> have an older version this does not impact you.
>>>>>
>>>>> As for the rest, show me real code in such systems that rely on sleep
>>>>> for correctness or performance/timeliness and I will show you broken
>>>>> code. We are not talking about real-time systems here. park(nanos)/wait(millis)
>>>>> will only be affected by the backward time change if the real notification
>>>>> they are waiting for does not happen. Timeouts with these APIs are
>>>>> heuristics, they are defensive programming to cover the case "what if the
>>>>> notification I'm waiting for does not come". The code that would be
>>>>> affected by this issue is a very small % of the code that uses the API.
>>>>>
>>>>> If this was as dire as you make out do you not think that this issue
>>>>> would have been raised far more than it has? This issue does need
>>>>> addressing because the number of affected systems will grow as these newer
>>>>> linux systems are adopted, but prudent developers/companies trial platform
>>>>> upgrades to check for these kinds of issues before swicthing to them in
>>>>> production environments.
>>>>>
>>>>> Regards,
>>>>> David
>>>>>
>>>>>  -----Original Message-----
>>>>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>>>>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>> *To:* dholmes at ieee.org
>>>>> *Cc:* concurrency-interest at cs.oswego.edu
>>>>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM
>>>>> issue - feedback?
>>>>>
>>>>>    Hi David,
>>>>>
>>>>>  thanks for following up.
>>>>>
>>>>>
>>>>>
>>>>>> I have raised the priority on 6900441
>>>>>>
>>>>>
>>>>>
>>>>>  Thanks, but it looks still like a P4:
>>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>> See also the attached snapshot, just in case it changes :)
>>>>>
>>>>>  [image: Inline image 2]
>>>>>
>>>>>  [...] which to my knowledge [...] has never been a private bug
>>>>>>
>>>>>
>>>>> It was not accessible using bugs.sun.com, this was translated to
>>>>> private. I also received the same info indirectly from the 7u lead:
>>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>>>>> bugs.sun.com)", I guess you can check with him.
>>>>>
>>>>>
>>>>>  It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>>>>> introduced into a specific glibc version...
>>>>>>
>>>>>
>>>>> ...and apparently did not make it. I was able to reproduce this even
>>>>> with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>>> 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on
>>>>> JDK4 everything works (that's the reason why I call it a regression). (ah,
>>>>> if you look at the bug, it lists also JDK5, so I think we are pretty much
>>>>> covered here).
>>>>> If you still have doubts tough, please have also a look on
>>>>> stackoverflow to see how it was reproduced consistently on probably every
>>>>> 64bitJVM over 64bitLinux in the world.
>>>>>
>>>>>
>>>>>  The effects of this is not that "all the threads parked will hang,
>>>>>> with unpredictable/corrupted/useless"! The effects are very simple an quite
>>>>>> predictable... [deletia]s.
>>>>>
>>>>>
>>>>>
>>>>> We have very different views, and I find quite difficult to accept
>>>>> yours. You are confusing my sample program which contains a single thread
>>>>> in a for loop with any other complex multi-threading concurrent system
>>>>> written in Java. For example, if you ever worked in a bank you surely know
>>>>> what I mean. You are comparing some random sleep() put into a program by
>>>>> some newbie, with the complex ecosystem of a concurrent platform written to
>>>>> manage trading information on very fast market. In that condition, I am
>>>>> sorry, statements such "...delayed timeout does not affect operation in a
>>>>> correctly functioning system..." and "...small time changes [...] are not a
>>>>> problem" are really not applicable. Let your system place an order three
>>>>> seconds late and your are out of the door so quickly you cannot even
>>>>> realize it.
>>>>>
>>>>>  But let's not limit ourselves to banks: how do you think your
>>>>> previous statements stands in these scenarios?
>>>>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>> about a few seconds delay in control when fying planes?)
>>>>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>> if just for a couple of seconds all traffic lights become green?)
>>>>>
>>>>>  Not good enough.
>>>>>
>>>>>
>>>>>  ...small time changes as typically done via NTP
>>>>>
>>>>>
>>>>>
>>>>> NTP is only one of the possible sources of this problem. The root of
>>>>> it is that the JVM is counting nanoseconds delays using absolute values
>>>>> based on a wallclock: I do not think it's that smart.
>>>>>
>>>>>
>>>>>   So there is an issue that needs to be addressed but the situation
>>>>>> is nowhere near as dire as you make out
>>>>>>
>>>>>
>>>>>
>>>>>  Let's try to put this in perspective, shall we? In case the clock
>>>>> run backwards LockSupport.park() will be waiting for the nanoseconds
>>>>> requested plus the amount of seconds/minute/hours/days requested to
>>>>> compensate. Now, this primitive is used by almost *every* concurrency
>>>>> construct available on the platform, such as AbstractQueuedSynchronizer
>>>>> (and subclasses), ReentrantLock (and subclasses), CyclicBarrier,
>>>>> BlockingQueue (and subclasses), Executors, FutureTask, .... (too long to
>>>>> list them all, but I think we have the picture) and also low levels
>>>>> synchronization primitives of the language itself, so Object::wait(:long)
>>>>> and the related sychronized blocks.
>>>>>
>>>>>  I think it's pretty dire.
>>>>>
>>>>>
>>>>>  Cheers,
>>>>>
>>>>>      Bruno
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <
>>>>> davidcholmes at aapt.net.au> wrote:
>>>>>
>>>>>>  Hi Bruno,
>>>>>>
>>>>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>>>>> created it! - has never been a private bug).
>>>>>>
>>>>>> A few notes on the "very frightening" aspect of this:
>>>>>>
>>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has
>>>>>> been introduced into a specific glibc version for the futex-wait code such
>>>>>> that it now responds to changes in the system time for absolute waits,
>>>>>> where for all the years previous it did not. The fix seems to have been
>>>>>> applied in late 2011 or early 2012 but I don't know the exact glibc
>>>>>> version. There is also a 32-bit version of the fix that was proposed on Nov
>>>>>> 27, 2012, so it will eventually make its way into 32-bit linux too.
>>>>>>
>>>>>> 2. The effects of this is not that "all the threads parked will
>>>>>> hang, with unpredictable/corrupted/useless"! The effects are very
>>>>>> simple an quite predictable. If the system time goes forward then
>>>>>> timed-waits (Object.wait, LockSupport.park) (which should be relative
>>>>>> times) will return early as the absolute-time that the relative time was
>>>>>> converted to will be seen to have been reached (Thread.sleep contains a
>>>>>> guard against early returns). This is not actually a problem as you can not
>>>>>> distinguish this case from a "spurious wakeup" which code is supposed to
>>>>>> account for. If the time is changed backwards then these timed-waits &
>>>>>> sleeps will not timeout when expected as the the for that is now further in
>>>>>> the future, by the amount of the backward time change. Hence small time
>>>>>> changes as typically done via NTP are NOT a problem. Timed-waits use
>>>>>> timeouts as a heuristics for recovering when the expected real event
>>>>>> notification does not occur - so a delayed timeout does not affect
>>>>>> operation in a correctly functioning system. Early timeouts are
>>>>>> indistinguishable from spurious wakeups, which code has to account for, so
>>>>>> again not a problem for regular code. The only time a significant "hang"
>>>>>> will occur is with Thread.sleep and a large backward time shift - but there
>>>>>> is little real code that uses Thread.sleep in any critical way.
>>>>>>
>>>>>> So there is an issue that needs to be addressed but the situation is
>>>>>> nowhere near as dire as you make out.
>>>>>>
>>>>>> David Holmes
>>>>>>
>>>>>> -----Original Message-----
>>>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno
>>>>>> bossola
>>>>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>>> *To:* concurrency-interest at cs.oswego.edu
>>>>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue
>>>>>> - feedback?
>>>>>>
>>>>>>   Hi all,
>>>>>>
>>>>>> I am writing here following a suggestion by Ben Evans. I wanted to
>>>>>> check with you about an issue that my teams found on the JVM and that's
>>>>>> very frightening. I already started the discussion with the engineers of
>>>>>> the hotspot VM team but it looks like we need more awareness to solve this
>>>>>> one and I'd really appreciate some help and some push :)
>>>>>>  It looks to me that this issue is affecting every JVM64 running on
>>>>>> Linux64, so imho it's quite important to be looked at.
>>>>>>
>>>>>> *Executive summary
>>>>>> *The implementation of the concurrency primitive
>>>>>> LockSupport.parkNanos(), the function that controls most concurrency
>>>>>> primitive on the JVM, is flawed, and any NTP sync, or system time change,
>>>>>> can potentially break it with unexpected results across the board.
>>>>>>
>>>>>> *What we need to do?
>>>>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>>>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>>>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>>>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>>>>> include it in a later patch release. In an ideal world it would be nice to
>>>>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>>>>> works based on priorities: being this qualified as P4 means it won't be
>>>>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>>>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>>>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>>
>>>>>>
>>>>>> *Why all this urgency?
>>>>>> *If a system time change happens then all the threads parked will
>>>>>> hang, with unpredictable/corrupted/useless results to the end user. Same
>>>>>> applies to Future, Queue, Executor, and (I guess) any other construct that
>>>>>> it's somehow related to concurrency. This is a big issue for us and for any
>>>>>> near time application: please think about trading and betting, where the
>>>>>> JVM is largely used, and  do not restrain yourself to the Java language:
>>>>>> add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>>
>>>>>> *Tech details**
>>>>>> *To be more clear about the issue, the extent of it and the
>>>>>> concurrency library, let me introduce this very simple program:
>>>>>>
>>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>>
>>>>>> public class Main {
>>>>>>
>>>>>>     public static void main(String[] args) {
>>>>>>
>>>>>>         for (int i=100; i>0; i--) {
>>>>>>             System.out.println(i);
>>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>         }
>>>>>>
>>>>>>         System.out.println("Done!");
>>>>>>     }
>>>>>> }
>>>>>>
>>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>>>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>>>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>>>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>>>>> whole concurrency library.
>>>>>>
>>>>>>  To prove that this is fixable, I reimplemented the program above
>>>>>> above substituting  LockSupport.parkNanos()  with  a JNI call to
>>>>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>>
>>>>>>  This is due to the fact  that the CPP code is calling the
>>>>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>>>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>>>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>>>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>>>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is
>>>>>> the actual "system time": each time my system syncs time using a NTP server
>>>>>> on the net, the time might jump forward or backward. The correct call
>>>>>> (again on Linux)  would require to use CLOCK_MONOTONIC as clock id,
>>>>>> which are defined by POSIX specs since 2002. (or better
>>>>>> CLOCK_MONOTONIC_RAW)
>>>>>>
>>>>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>>>>> clock via clock_settime() shall have no effect on threads that are blocked
>>>>>> waiting for a *relative* time service based upon this clock...": it
>>>>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>> it appears that the park() is using compute_abstime() (which uses
>>>>>> timeofday) and then waits on an absolute period: for that reason it's
>>>>>> influenced by the system clock change. *Very wrong*.
>>>>>>
>>>>>>  I will be happy to know what you think, and if you can help me to
>>>>>> escalate this issue I think that the all Java community will benefit from
>>>>>> it.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>>      Bruno
>>>>>>
>>>>>>
>>>>>   No virus found in this message.
>>>>> Checked by AVG - www.avg.com
>>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date:
>>>>> 09/03/13
>>>>>
>>>>>
>>>>
>>>>
>>>>   _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/798eb4a3/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 13:45:53 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 18:45:53 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
Message-ID: <5228C351.4070009@oracle.com>

Exactly my point.

Now someone needs to take care of negative time returned, when the clock 
goes back, even if the wait was shorter than timeout. Or, if we report 
the actual time waited, then deal with the inconsistency between 
apparent System.nanoTime() and the wait.

Alex

On 05/09/2013 18:31, ?iktor ?lang wrote:
> For Condition.awaitNanos it states:
>
> Returns:
>     an estimate of the |nanosTimeout| value minus the time spent
>     waiting upon return from this method. A positive value may be used
>     as the argument to a subsequent call to this method to finish
>     waiting out the desired time. *A value less than or equal to zero
>     indicates that no time remains.*
>
>
>
>
>
> On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Oh, and now someone else is going to complain that awaitNanos
>     returns a negative number, even though it waited for only 1 ms out
>     of 100.
>
>     Alex
>
>     On 05/09/2013 17:50, bruno bossola wrote:
>>     I am sorry but I really cannot spend more time creating more
>>     samples and I am quite sure you could do a better work at that!
>>     At the moment to me that matter is clear enough, but feel free to
>>     ask, I will very happy to help! In the meantime I prefer spend my
>>     time to work on a patch that I can apply on my JVMs :)
>>
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>     On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         This is far from reproducing the problem with arbitrary j.u.c
>>         locks and queues hanging.
>>
>>         Condition.awaitNanos can return a negative value. If you are
>>         expecting the negative value to be small, then how small do
>>         you expect it to be?
>>
>>
>>         Alex
>>
>>
>>         On 05/09/2013 02:12, bruno bossola wrote:
>>>         Hi Oaleksandr,
>>>
>>>         Please apologize me if my english was not good enough to
>>>         provide you an example that make sense: for that reason I
>>>         decided to go back to a binary deliverable (code) that shows
>>>         the problem, hope this helps!
>>>
>>>         This is my PreciousPool class, that handles Precious resources:
>>>
>>>         import java.text.SimpleDateFormat;
>>>         import java.util.ArrayList;
>>>         import java.util.Date;
>>>         import java.util.List;
>>>         import java.util.concurrent.TimeUnit;
>>>         import java.util.concurrent.locks.Condition;
>>>         import java.util.concurrent.locks.Lock;
>>>         import java.util.concurrent.locks.ReentrantLock;
>>>
>>>         public class PreciousPool {
>>>
>>>             public static class Precious {
>>>                 private final int id;
>>>
>>>                 private Precious() {
>>>         this.id <http://this.id> = 100+(int)(Math.random()*900.0);
>>>                 }
>>>
>>>                 public String toString() {
>>>                     return "Precious n."+id;
>>>                 }
>>>             }
>>>
>>>             private final Lock lock;
>>>             private final Condition ready;
>>>             private final long timeoutInMillis;
>>>
>>>             private final List<Precious> preciousLended;
>>>             private final List<Precious> preciousAvailable;
>>>
>>>             public PreciousPool(int size, long timeoutInSeconds) {
>>>                 this.lock = new ReentrantLock();
>>>                 this.ready = lock.newCondition();
>>>
>>>                 this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>                 this.preciousLended =  new ArrayList<Precious>();
>>>                 this.preciousAvailable = new ArrayList<Precious>();
>>>
>>>                 for (int i = 0; i < size; i++) {
>>>                     preciousAvailable.add(new Precious());
>>>                 }
>>>             }
>>>
>>>             public Precious obtain()  {
>>>                 lock.lock();
>>>                 try {
>>>                     // if no precious are available we wait for the
>>>         specified timeout (releasing the lock so that others can try)
>>>                     if (preciousAvailable.size() == 0) {
>>>                         try {
>>>         ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>                         } catch (InterruptedException e) {
>>>         Thread.currentThread().interrupt();
>>>                             throw new RuntimeException("Somebody
>>>         interrupted me!", e);
>>>                         }
>>>                     }
>>>
>>>                     // if a precious is available we unload it and
>>>         return to the caller, otherwise null
>>>                     if (preciousAvailable.size() > 0) {
>>>                         Precious value = preciousAvailable.remove(0);
>>>         preciousLended.add(value);
>>>                         return value;
>>>                     } else {
>>>                         return null;
>>>                     }
>>>                 } finally {
>>>                     lock.unlock();
>>>                 }
>>>             }
>>>
>>>             public void release(Precious value) {
>>>                 lock.lock();
>>>                 try {
>>>                     if (!preciousLended.remove(value))
>>>                         throw new RuntimeException("Element
>>>         "+value+" was not lended!");
>>>
>>>                     // if a precious is returned we put it back and
>>>         signal to anybody waiting
>>>         preciousAvailable.add(value);
>>>                     ready.signalAll();
>>>                 } finally {
>>>                     lock.unlock();
>>>                 }
>>>             }
>>>
>>>             public static void main(String args[]) {
>>>                 final int size = 3;
>>>                 final PreciousPool pool = new PreciousPool(size, 5);
>>>
>>>                 // let's exhaust the pool
>>>                 for (int i=0; i<size; i++)
>>>                     dump(pool.obtain());
>>>
>>>                 // and as we are stubborn we continuosly ask for a
>>>         new one
>>>                 while(true) {
>>>                     dump(pool.obtain());
>>>                 }
>>>             }
>>>
>>>             private static void dump(Precious precious) {
>>>                 if (precious == null)
>>>                     log("I did not get my precious :(");
>>>                 else
>>>                     log("I did get my precious! "+precious);
>>>             }
>>>
>>>             private static void log(String message) {
>>>                 final String now = new
>>>         SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>                 System.out.println(now + message);
>>>             }
>>>         }
>>>
>>>         So, the main is a single thread (no need for multithreading
>>>         here, let's keep it simple), that first exhaust the whole
>>>         pool and then keep asking, without success, for a resource.
>>>         Stubborn guy, I say, but it happens. If you run this program
>>>         everything works as expected: you are greeted by a three
>>>         successful Precious and then an endless list of failures,
>>>         that it continuously grow. All good :)
>>>
>>>         02:34:40:0061 I did get my precious! Precious n.156
>>>         02:34:40:0062 I did get my precious! Precious n.991
>>>         02:34:40:0062 I did get my precious! Precious n.953
>>>         02:34:45:0064 I did not get my precious :(
>>>         02:34:50:0065 I did not get my precious :(
>>>         02:34:55:0066 I did not get my precious :(
>>>         02:35:00:0067 I did not get my precious :(
>>>         02:35:05:0068 I did not get my precious :(
>>>         [...]
>>>
>>>         But guess what happens when, while the program is running, I
>>>         change the date of my system back of one hour? Everything
>>>         stops,  it's simple as that. No prints, nothing, zero, nada.
>>>         Now, If it wasn't so late, I would probably wait one hour in
>>>         order to have my program restored to his normal process, but
>>>         as a customer I won't be terribly happy :)
>>>
>>>         I hope my point is now clear.
>>>         Cheers,
>>>
>>>             Bruno
>>>
>>>
>>>
>>>
>>>
>>>
>>>         On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             n 04/09/2013 18:54, bruno bossola wrote:
>>>>             Hi Oleksandr,
>>>>
>>>>                 Where in the design of those systems is a real-time
>>>>                 timer? The one that delivers time events
>>>>                 uncompromised even by GC latency?
>>>>
>>>>             I don't think so :) If somebody needs a real time
>>>>             implementation he needs to go for a real time JVM, like
>>>>             Jean correctly pointed out.  The concurrency primitives
>>>>             are depending on LockSupport.parkNanos(...) to park a
>>>>             thread: if this for any reason is not working (like it
>>>>             is) then strange things may happen.
>>>             Your assumption is that it is not working, if the
>>>             elapsed time is longer. This is the flawed assumption.
>>>
>>>             Also, you need to read fine print on those "real time"
>>>             JVMs. The catch is in the definition of "real time".
>>>
>>>
>>>
>>>
>>>>             Imagine, for example, that you are using a
>>>>             ReentrantLock to control a very precious resource used
>>>>             across the board (what about a database connection
>>>>             pool?) and you are unlucky enough to have a system time
>>>>             change (backwards) while you are locking: all the
>>>>             threads that want to use such resource will be
>>>>             progressively locked: not forever, but for the amount
>>>>             of time the clock went back. Probably most (all?) of
>>>>             your system freezes, and the only option you have is to
>>>>             wait, or restart.
>>>>             Now place this in a large application server, that
>>>>             provide services for hunreds (thousands) of users. How
>>>>             does it sound to you?
>>>             It sounds like you don't understand how the locks work.
>>>
>>>
>>>             Alex
>>>
>>>
>>>>
>>>>             BTW, at the moment we could have a watchdog (in Python
>>>>             :)) that restarts it, but, I dunno why, I don't like it
>>>>             a lot...
>>>>
>>>>             Cheers,
>>>>
>>>>                 Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>             On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>>             <oleksandr.otenko at oracle.com
>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>
>>>>                 You are missing the point.
>>>>
>>>>                 Where in the design of those systems is a real-time
>>>>                 timer? The one that delivers time events
>>>>                 uncompromised even by GC latency?
>>>>
>>>>                 The whole concurrency lot does not depend on the
>>>>                 timeout magnitude for correctness.
>>>>
>>>>                 Alex
>>>>
>>>>
>>>>                 On 04/09/2013 12:05, bruno bossola wrote:
>>>>>                 Hi David
>>>>>
>>>>>
>>>>>                     bugs.sun.com <http://bugs.sun.com> is not a
>>>>>                     live reflection of the bug database but gets
>>>>>                     updated periodically (every 12 hours I think).
>>>>>
>>>>>
>>>>>                 Good to know :) I will be eagerly clicking on it
>>>>>                 to discover the new priority! Thanks for that, I
>>>>>                 really appreciate it.
>>>>>
>>>>>
>>>>>                     The issue arises on certain 64-bit linux
>>>>>                     kernel/glibc versions. If you have an older
>>>>>                     version this does not impact you.
>>>>>
>>>>>                 You saw my list: nobody will use an older
>>>>>                 Kernel/glibc version in production.
>>>>>
>>>>>
>>>>>                     As for the rest, show me real code in such
>>>>>                     systems that rely on sleep for correctness or
>>>>>                     performance/timeliness and I will show you
>>>>>                     broken code.
>>>>>
>>>>>                 You are still hitting about the sleep(), I
>>>>>                 understand and I agree about this. But here we are
>>>>>                 not talking about sleeps: we are talking about the
>>>>>                 whole concurrency lot. And yes, as I already said,
>>>>>                 we are talking about near time systems, like
>>>>>                 trading application, betting applications, air
>>>>>                 traffic control systems, car traffic control
>>>>>                 systems. Don't you think this bug might place
>>>>>                 Oracle JVM outside of these markets?
>>>>>
>>>>>
>>>>>                     If this was as dire as you make out do you not
>>>>>                     think that this issue would have been raised
>>>>>                     far more than it has? [....] prudent
>>>>>                     developers/companies trial platform upgrades
>>>>>                     to check for these kinds of issues before
>>>>>                     switching to them in production environments.
>>>>>
>>>>>                 I am waiting now for the part where you say that
>>>>>                 we should throw away Linux and use Oracle Solaris
>>>>>                 :)  In all seriousness, there's a lot of action
>>>>>                 "in the middle", and I think that Oracle cannot
>>>>>                 oversee that. For example a lot of trading
>>>>>                 software system can be installed on premises,
>>>>>                 where you usually have no control over the
>>>>>                 environment: what I would do is to put a native
>>>>>                 daemon in my app so that if I see the system clock
>>>>>                 change I would kill myself, just in case. And this
>>>>>                 is a solution that I know for a fact (sorry, I
>>>>>                 cannot make a reference) it's used in production
>>>>>                 in a very important trading application.
>>>>>
>>>>>                 Regarding that specific bug, it was not accessible
>>>>>                 to the external until two days ago, so I guess
>>>>>                 nobody really knew a lot about it, but I will make
>>>>>                 sure it will :) so that we can get more traction.
>>>>>
>>>>>                 Cheers,
>>>>>
>>>>>                     Bruno
>>>>>
>>>>>
>>>>>
>>>>>                 On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>>                 <davidcholmes at aapt.net.au
>>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>
>>>>>                     Bruno,
>>>>>                     bugs.sun.com <http://bugs.sun.com> is not a
>>>>>                     live reflection of the bug database but gets
>>>>>                     updated periodically (every 12 hours I think).
>>>>>                     The issue arises on certain 64-bit linux
>>>>>                     kernel/glibc versions. If you have an older
>>>>>                     version this does not impact you.
>>>>>                     As for the rest, show me real code in such
>>>>>                     systems that rely on sleep for correctness or
>>>>>                     performance/timelinessand I will show you
>>>>>                     broken code. We are not talking about
>>>>>                     real-time systemshere.
>>>>>                     park(nanos)/wait(millis) will only be affected
>>>>>                     by the backward time change if the real
>>>>>                     notification they are waiting for does not
>>>>>                     happen. Timeouts with these APIs are
>>>>>                     heuristics, they are defensive programming to
>>>>>                     cover the case "what if the notification I'm
>>>>>                     waiting for does not come". The code that
>>>>>                     would be affected by this issue is a very
>>>>>                     small % of the code that uses the API.
>>>>>                     If this was as dire as you make out do you not
>>>>>                     think that this issue would have been raised
>>>>>                     far more than it has? This issue does need
>>>>>                     addressing because the number of affected
>>>>>                     systems will grow as these newer linux systems
>>>>>                     are adopted, but prudent developers/companies
>>>>>                     trial platform upgrades to check for these
>>>>>                     kinds of issues before swicthing to them in
>>>>>                     production environments.
>>>>>                     Regards,
>>>>>                     David
>>>>>
>>>>>                         -----Original Message-----
>>>>>                         *From:* bruno bossola
>>>>>                         [mailto:bbossola at gmail.com
>>>>>                         <mailto:bbossola at gmail.com>]
>>>>>                         *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>>                         *To:* dholmes at ieee.org
>>>>>                         <mailto:dholmes at ieee.org>
>>>>>                         *Cc:* concurrency-interest at cs.oswego.edu
>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>                         Outstanding concurrency JVM issue - feedback?
>>>>>
>>>>>                         Hi David,
>>>>>
>>>>>                         thanks for following up.
>>>>>
>>>>>                             I have raised the priority on 6900441
>>>>>
>>>>>                         Thanks, but it looks still like a P4:
>>>>>                         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>                         See also the attached snapshot, just in
>>>>>                         case it changes :)
>>>>>
>>>>>                         Inline image 2
>>>>>
>>>>>                             [...] which to my knowledge [...] has
>>>>>                             never been a private bug
>>>>>
>>>>>                         It was not accessible using bugs.sun.com
>>>>>                         <http://bugs.sun.com/>, this was
>>>>>                         translated to private. I also received the
>>>>>                         same info indirectly from the 7u lead:
>>>>>                         "I'm not sure why 6900441 isn't public.
>>>>>                         (I'll follow up with owner of bugs.sun.com
>>>>>                         <http://bugs.sun.com/>)", I guess you can
>>>>>                         check with him.
>>>>>
>>>>>
>>>>>                             It doesn't affect "every JVM64 running
>>>>>                             on Linux64".  A fix has been
>>>>>                             introduced into a specific glibc
>>>>>                             version...
>>>>>
>>>>>                         ...and apparently did not make it. I was
>>>>>                         able to reproduce this even with the IBM
>>>>>                         VM, so to speak. I tried JDK6, JDK7, JDK8
>>>>>                         on Ubuntu 10, 11, 12, 13 + some random
>>>>>                         Debian. I did not have a JDK5, so I cannot
>>>>>                         say, but on JDK4 everything works (that's
>>>>>                         the reason why I call it a regression).
>>>>>                         (ah, if you look at the bug, it lists also
>>>>>                         JDK5, so I think we are pretty much
>>>>>                         covered here).
>>>>>                         If you still have doubts tough, please
>>>>>                         have also a look on stackoverflow to see
>>>>>                         how it was reproduced consistently on
>>>>>                         probably every 64bitJVM over 64bitLinux in
>>>>>                         the world.
>>>>>
>>>>>
>>>>>                             The effects of this is not that "all
>>>>>                             the threads parked will hang, with
>>>>>                             unpredictable/corrupted/useless"! The
>>>>>                             effects are very simple an quite
>>>>>                             predictable... [deletia]s.
>>>>>
>>>>>                         We have very different views, and I find
>>>>>                         quite difficult to accept yours. You are
>>>>>                         confusing my sample program which contains
>>>>>                         a single thread in a for loop with any
>>>>>                         other complex multi-threading concurrent
>>>>>                         system written in Java. For example, if
>>>>>                         you ever worked in a bank you surely know
>>>>>                         what I mean. You are comparing some random
>>>>>                         sleep() put into a program by some newbie,
>>>>>                         with the complex ecosystem of a concurrent
>>>>>                         platform written to manage trading
>>>>>                         information on very fast market. In that
>>>>>                         condition, I am sorry, statements such
>>>>>                         "...delayed timeout does not affect
>>>>>                         operation in a correctly functioning
>>>>>                         system..." and "...small time changes
>>>>>                         [...] are not a problem" are really not
>>>>>                         applicable. Let your system place an order
>>>>>                         three seconds late and your are out of the
>>>>>                         door so quickly you cannot even realize it.
>>>>>
>>>>>                         But let's not limit ourselves to banks:
>>>>>                         how do you think your previous statements
>>>>>                         stands in these scenarios?
>>>>>                         - air control systems
>>>>>                         <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>                         about a few seconds delay in control when
>>>>>                         fying planes?)
>>>>>                         - city traffic control systems
>>>>>                         <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>                         if just for a couple of seconds all
>>>>>                         traffic lights become green?)
>>>>>
>>>>>                         Not good enough.
>>>>>
>>>>>
>>>>>                             ...small time changes as typically
>>>>>                             done via NTP
>>>>>
>>>>>                         NTP is only one of the possible sources of
>>>>>                         this problem. The root of it is that the
>>>>>                         JVM is counting nanoseconds delays using
>>>>>                         absolute values based on a wallclock: I do
>>>>>                         not think it's that smart.
>>>>>
>>>>>
>>>>>                             So there is an issue that needs to be
>>>>>                             addressed but the situation is nowhere
>>>>>                             near as dire as you make out
>>>>>
>>>>>                         Let's try to put this in perspective,
>>>>>                         shall we? In case the clock run
>>>>>                         backwards LockSupport.park() will be
>>>>>                         waiting for the nanoseconds requested plus
>>>>>                         the amount of seconds/minute/hours/days
>>>>>                         requested to compensate. Now, this
>>>>>                         primitive is used by almost *every*
>>>>>                         concurrency construct available on the
>>>>>                         platform, such as
>>>>>                         AbstractQueuedSynchronizer (and
>>>>>                         subclasses), ReentrantLock (and
>>>>>                         subclasses), CyclicBarrier, BlockingQueue
>>>>>                         (and subclasses), Executors, FutureTask,
>>>>>                         .... (too long to list them all, but I
>>>>>                         think we have the picture) and also low
>>>>>                         levels synchronization primitives of the
>>>>>                         language itself, so Object::wait(:long)
>>>>>                         and the related sychronized blocks.
>>>>>
>>>>>                         I think it's pretty dire.
>>>>>
>>>>>
>>>>>                         Cheers,
>>>>>
>>>>>                             Bruno
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>                         On Wed, Sep 4, 2013 at 12:14 AM, David
>>>>>                         Holmes <davidcholmes at aapt.net.au
>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>
>>>>>                             Hi Bruno,
>>>>>                             I have raised the priority on 6900441
>>>>>                             (which to my knowledge - and I created
>>>>>                             it! - has never been a private bug).
>>>>>                             A few notes on the "very frightening"
>>>>>                             aspect of this:
>>>>>                             1. It doesn't affect "every JVM64
>>>>>                             running on Linux64". A fix has been
>>>>>                             introduced into a specific glibc
>>>>>                             version for the futex-wait code such
>>>>>                             that it now responds to changes in the
>>>>>                             system time for absolute waits, where
>>>>>                             for all the years previous it did not.
>>>>>                             The fix seems to have been applied in
>>>>>                             late 2011 or early 2012 but I don't
>>>>>                             know the exact glibc version. There is
>>>>>                             also a 32-bit version of the fix that
>>>>>                             was proposed on Nov 27, 2012, so it
>>>>>                             will eventually make its way into
>>>>>                             32-bit linux too.
>>>>>                             2. The effects of this is not that
>>>>>                             "all the threads parked will hang,
>>>>>                             with unpredictable/corrupted/useless"!
>>>>>                             The effects are very simple an quite
>>>>>                             predictable. If the system time goes
>>>>>                             forward then timed-waits (Object.wait,
>>>>>                             LockSupport.park) (which should be
>>>>>                             relative times) will return early as
>>>>>                             the absolute-time that the relative
>>>>>                             time was converted to will be seen to
>>>>>                             have been reached (Thread.sleep
>>>>>                             contains a guard against early
>>>>>                             returns). This is not actually a
>>>>>                             problem as you can not distinguish
>>>>>                             this case from a "spurious wakeup"
>>>>>                             which code is supposed to account
>>>>>                             for. If the time is changed backwards
>>>>>                             then these timed-waits & sleeps will
>>>>>                             not timeout when expected as the the
>>>>>                             for that is now further in the future,
>>>>>                             by the amount of the backward time
>>>>>                             change. Hence small time changes as
>>>>>                             typically done via NTP are NOT a
>>>>>                             problem. Timed-waits use timeouts as a
>>>>>                             heuristics for recovering when the
>>>>>                             expected real event notification does
>>>>>                             not occur - so a delayed timeout does
>>>>>                             not affect operation in a correctly
>>>>>                             functioning system. Early timeouts are
>>>>>                             indistinguishable from spurious
>>>>>                             wakeups, which code has to account
>>>>>                             for, so again not a problem for
>>>>>                             regular code. The only time a
>>>>>                             significant "hang" will occur is with
>>>>>                             Thread.sleep and a large backward time
>>>>>                             shift - but there is little real code
>>>>>                             that uses Thread.sleep in any critical
>>>>>                             way.
>>>>>                             So there is an issue that needs to be
>>>>>                             addressed but the situation is nowhere
>>>>>                             near as dire as you make out.
>>>>>                             David Holmes
>>>>>
>>>>>                                 -----Original Message-----
>>>>>                                 *From:*
>>>>>                                 concurrency-interest-bounces at cs.oswego.edu
>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>                                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>>                                 Behalf Of *bruno bossola
>>>>>                                 *Sent:* Wednesday, 4 September
>>>>>                                 2013 1:56 AM
>>>>>                                 *To:*
>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                                 *Subject:* [concurrency-interest]
>>>>>                                 Outstanding concurrency JVM issue
>>>>>                                 - feedback?
>>>>>
>>>>>                                 Hi all,
>>>>>
>>>>>                                 I am writing here following a
>>>>>                                 suggestion by Ben Evans. I wanted
>>>>>                                 to check with you about an issue
>>>>>                                 that my teams found on the JVM and
>>>>>                                 that's very frightening. I already
>>>>>                                 started the discussion with the
>>>>>                                 engineers of the hotspot VM team
>>>>>                                 but it looks like we need more
>>>>>                                 awareness to solve this one and
>>>>>                                 I'd really appreciate some help
>>>>>                                 and some push :)
>>>>>                                 It looks to me that this issue is
>>>>>                                 affecting every JVM64 running on
>>>>>                                 Linux64, so imho it's quite
>>>>>                                 important to be looked at.
>>>>>
>>>>>                                 *Executive summary
>>>>>                                 *The implementation of the
>>>>>                                 concurrency primitive
>>>>>                                 LockSupport.parkNanos(), the
>>>>>                                 function that controls most
>>>>>                                 concurrency primitive on the JVM,
>>>>>                                 is flawed, and any NTP sync, or
>>>>>                                 system time change, can
>>>>>                                 potentially break it with
>>>>>                                 unexpected results across the board.
>>>>>
>>>>>                                 *What we need to do?
>>>>>                                 *This is an old issue, and the bug
>>>>>                                 <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>>                                 was declared private. I somehow
>>>>>                                 managed to have the bug reopened
>>>>>                                 to the public, but it's still a 
>>>>>                                 P4, that means that probably won't
>>>>>                                 be fixed. I think we need to push
>>>>>                                 for a resolution ASAP, be sure
>>>>>                                 that's in for JDK9, make all the
>>>>>                                 possible effort to make this fix
>>>>>                                 for JDK8 or, at least, to include
>>>>>                                 it in a later patch release. In an
>>>>>                                 ideal world it would be nice to
>>>>>                                 have a patch for JDK7. As far as I
>>>>>                                 understand the hotspot engineering
>>>>>                                 team works based on priorities:
>>>>>                                 being this qualified as P4 means
>>>>>                                 it won't be probably worked on (if
>>>>>                                 you follow the breadcrumbs of bugs
>>>>>                                 and fixes you can go back to
>>>>>                                 2002!) They acknowledge the
>>>>>                                 problem, it has been flagged to
>>>>>                                 management, but 1) it's low
>>>>>                                 priority 2) it's too risky to fix
>>>>>                                 for JDK8
>>>>>
>>>>>
>>>>>                                 *Why all this urgency?
>>>>>                                 *If a system time change happens
>>>>>                                 then all the threads parked will
>>>>>                                 hang, with
>>>>>                                 unpredictable/corrupted/useless
>>>>>                                 results to the end user. Same
>>>>>                                 applies to Future, Queue,
>>>>>                                 Executor, and (I guess) any other
>>>>>                                 construct that it's somehow
>>>>>                                 related to concurrency. This is a
>>>>>                                 big issue for us and for any near
>>>>>                                 time application: please think
>>>>>                                 about trading and betting, where
>>>>>                                 the JVM is largely used, and  do
>>>>>                                 not restrain yourself to the Java
>>>>>                                 language: add Scala and any other
>>>>>                                 JVM-based language to the picture
>>>>>                                 (JRuby, Jython...)
>>>>>
>>>>>                                 *Tech details**
>>>>>                                 *To be more clear about the issue,
>>>>>                                 the extent of it and the
>>>>>                                 concurrency library, let me
>>>>>                                 introduce this very simple program:
>>>>>
>>>>>                                 import
>>>>>                                 java.util.concurrent.locks.LockSupport;
>>>>>
>>>>>                                 public class Main {
>>>>>
>>>>>                                     public static void
>>>>>                                 main(String[] args) {
>>>>>
>>>>>                                         for (int i=100; i>0; i--) {
>>>>>                                 System.out.println(i);
>>>>>                                 LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>                                         }
>>>>>
>>>>>                                 System.out.println("Done!");
>>>>>                                     }
>>>>>                                 }
>>>>>
>>>>>                                 Run it with a 64bit 1.6+ JVM on
>>>>>                                 64bit Linux, turn the clock down
>>>>>                                 one hour and wait until the
>>>>>                                 counter stops... magic!  I tested
>>>>>                                 this on JDK6, JDK7 and latest JDK8
>>>>>                                 beta running on various Ubuntu
>>>>>                                 distros. It's not just a matter of
>>>>>                                 (old?) sleep() and wait()
>>>>>                                 primitives, this issue it affects
>>>>>                                 the whole concurrency library.
>>>>>
>>>>>                                 To prove that this is fixable, I
>>>>>                                 reimplemented the program above
>>>>>                                 above substituting
>>>>>                                 LockSupport.parkNanos() with  a
>>>>>                                 JNI call to
>>>>>                                 clock_nanosleep(CLOCK_MONOTONIC...):
>>>>>                                 works like a charm :(
>>>>>
>>>>>                                 This is due to the fact  that the
>>>>>                                 CPP code is calling the
>>>>>                                 pthread_cond_timedwait() using its
>>>>>                                 default clock (CLOCK_REALTIME)
>>>>>                                 which, unfortunately is affected
>>>>>                                 by settime()/settimeofday() calls
>>>>>                                 (on Linux): for that reason it
>>>>>                                 cannot be used to measure
>>>>>                                 nanoseconds delays, which is what
>>>>>                                 the specification
>>>>>                                 <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>>                                 requires. CLOCK_REALTIME is not
>>>>>                                 guaranteed to monotonically count
>>>>>                                 as this is the actual "system
>>>>>                                 time": each time my system syncs
>>>>>                                 time using a NTP server on the
>>>>>                                 net, the time might jump forward
>>>>>                                 or backward. The correct call
>>>>>                                 (again on Linux)  would require to
>>>>>                                 use CLOCK_MONOTONIC as clock id,
>>>>>                                 which are defined by POSIX specs
>>>>>                                 since 2002. (or better
>>>>>                                 CLOCK_MONOTONIC_RAW)
>>>>>
>>>>>                                 The POSIX spec
>>>>>                                 <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>>                                 is infact clear, as it states
>>>>>                                 "...setting the value of the
>>>>>                                 CLOCK_REALTIME clock via
>>>>>                                 clock_settime() shall have no
>>>>>                                 effect on threads that are blocked
>>>>>                                 waiting for a *relative* time
>>>>>                                 service based upon this clock...":
>>>>>                                 it definitely states "relative".
>>>>>                                 Having a look at the hotspot code
>>>>>                                 <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>                                 it appears that the park() is
>>>>>                                 using compute_abstime() (which
>>>>>                                 uses timeofday) and then waits on
>>>>>                                 an absolute period: for that
>>>>>                                 reason it's influenced by the
>>>>>                                 system clock change. *Very wrong*.
>>>>>
>>>>>                                 I will be happy to know what you
>>>>>                                 think, and if you can help me to
>>>>>                                 escalate this issue I think that
>>>>>                                 the all Java community will
>>>>>                                 benefit from it.
>>>>>
>>>>>                                 Cheers,
>>>>>
>>>>>                                     Bruno
>>>>>
>>>>>
>>>>>                         No virus found in this message.
>>>>>                         Checked by AVG - www.avg.com
>>>>>                         <http://www.avg.com>
>>>>>                         Version: 2013.0.3392 / Virus Database:
>>>>>                         3222/6633 - Release Date: 09/03/13
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>                 _______________________________________________
>>>>>                 Concurrency-interest mailing list
>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>>
>>
>>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> *Viktor Klang*
> /Director of Engineering/
> Typesafe <http://www.typesafe.com/>
>
> Twitter: @viktorklang

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/84ec5cd1/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 13:48:15 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 18:48:15 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cA+xn-8ONmTWu2Oa+R47-T+_Ws-4WqS+23K5VgYp_2=CLQ@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228B960.6010305@oracle.com>
	<CAJU-cA+xn-8ONmTWu2Oa+R47-T+_Ws-4WqS+23K5VgYp_2=CLQ@mail.gmail.com>
Message-ID: <5228C3DF.9050008@oracle.com>

I don't know why you keep ignoring the point that the magnitude of the 
negative time returned by awaitNanos is not required to be small.

Alex

On 05/09/2013 18:38, bruno bossola wrote:
> > You presented a design that relies on the magnitude of the negative 
> value of awaitNanos...
> >
> No :) it's a very simple and legitimate example of usage of locking, 
> that fails because the park(..) function is implemented using an 
> absolute deadline based on a wall clock: that's what I call a design 
> "not sound".
>
> Cheers,
>
>     Bruno
>
>
>
> On Thu, Sep 5, 2013 at 6:03 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Quite the opposite. You presented a design that relies on the
>     magnitude of the negative value of awaitNanos, which is not
>     defined. I can't find a example of such algorithm in j.u.c, and I
>     don't think your concurrent design is sound.
>
>     Alex
>
>     On 05/09/2013 17:50, bruno bossola wrote:
>>     I am sorry but I really cannot spend more time creating more
>>     samples and I am quite sure you could do a better work at that!
>>     At the moment to me that matter is clear enough, but feel free to
>>     ask, I will very happy to help! In the meantime I prefer spend my
>>     time to work on a patch that I can apply on my JVMs :)
>>
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>     On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         This is far from reproducing the problem with arbitrary j.u.c
>>         locks and queues hanging.
>>
>>         Condition.awaitNanos can return a negative value. If you are
>>         expecting the negative value to be small, then how small do
>>         you expect it to be?
>>
>>
>>         Alex
>>
>>
>>         On 05/09/2013 02:12, bruno bossola wrote:
>>>         Hi Oaleksandr,
>>>
>>>         Please apologize me if my english was not good enough to
>>>         provide you an example that make sense: for that reason I
>>>         decided to go back to a binary deliverable (code) that shows
>>>         the problem, hope this helps!
>>>
>>>         This is my PreciousPool class, that handles Precious resources:
>>>
>>>         import java.text.SimpleDateFormat;
>>>         import java.util.ArrayList;
>>>         import java.util.Date;
>>>         import java.util.List;
>>>         import java.util.concurrent.TimeUnit;
>>>         import java.util.concurrent.locks.Condition;
>>>         import java.util.concurrent.locks.Lock;
>>>         import java.util.concurrent.locks.ReentrantLock;
>>>
>>>         public class PreciousPool {
>>>
>>>             public static class Precious {
>>>                 private final int id;
>>>
>>>                 private Precious() {
>>>         this.id <http://this.id> = 100+(int)(Math.random()*900.0);
>>>                 }
>>>
>>>                 public String toString() {
>>>                     return "Precious n."+id;
>>>                 }
>>>             }
>>>
>>>             private final Lock lock;
>>>             private final Condition ready;
>>>             private final long timeoutInMillis;
>>>
>>>             private final List<Precious> preciousLended;
>>>             private final List<Precious> preciousAvailable;
>>>
>>>             public PreciousPool(int size, long timeoutInSeconds) {
>>>                 this.lock = new ReentrantLock();
>>>                 this.ready = lock.newCondition();
>>>
>>>                 this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>                 this.preciousLended =  new ArrayList<Precious>();
>>>                 this.preciousAvailable = new ArrayList<Precious>();
>>>
>>>                 for (int i = 0; i < size; i++) {
>>>                     preciousAvailable.add(new Precious());
>>>                 }
>>>             }
>>>
>>>             public Precious obtain()  {
>>>                 lock.lock();
>>>                 try {
>>>                     // if no precious are available we wait for the
>>>         specified timeout (releasing the lock so that others can try)
>>>                     if (preciousAvailable.size() == 0) {
>>>                         try {
>>>         ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>                         } catch (InterruptedException e) {
>>>         Thread.currentThread().interrupt();
>>>                             throw new RuntimeException("Somebody
>>>         interrupted me!", e);
>>>                         }
>>>                     }
>>>
>>>                     // if a precious is available we unload it and
>>>         return to the caller, otherwise null
>>>                     if (preciousAvailable.size() > 0) {
>>>                         Precious value = preciousAvailable.remove(0);
>>>         preciousLended.add(value);
>>>                         return value;
>>>                     } else {
>>>                         return null;
>>>                     }
>>>                 } finally {
>>>                     lock.unlock();
>>>                 }
>>>             }
>>>
>>>             public void release(Precious value) {
>>>                 lock.lock();
>>>                 try {
>>>                     if (!preciousLended.remove(value))
>>>                         throw new RuntimeException("Element
>>>         "+value+" was not lended!");
>>>
>>>                     // if a precious is returned we put it back and
>>>         signal to anybody waiting
>>>         preciousAvailable.add(value);
>>>                     ready.signalAll();
>>>                 } finally {
>>>                     lock.unlock();
>>>                 }
>>>             }
>>>
>>>             public static void main(String args[]) {
>>>                 final int size = 3;
>>>                 final PreciousPool pool = new PreciousPool(size, 5);
>>>
>>>                 // let's exhaust the pool
>>>                 for (int i=0; i<size; i++)
>>>                     dump(pool.obtain());
>>>
>>>                 // and as we are stubborn we continuosly ask for a
>>>         new one
>>>                 while(true) {
>>>                     dump(pool.obtain());
>>>                 }
>>>             }
>>>
>>>             private static void dump(Precious precious) {
>>>                 if (precious == null)
>>>                     log("I did not get my precious :(");
>>>                 else
>>>                     log("I did get my precious! "+precious);
>>>             }
>>>
>>>             private static void log(String message) {
>>>                 final String now = new
>>>         SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>                 System.out.println(now + message);
>>>             }
>>>         }
>>>
>>>         So, the main is a single thread (no need for multithreading
>>>         here, let's keep it simple), that first exhaust the whole
>>>         pool and then keep asking, without success, for a resource.
>>>         Stubborn guy, I say, but it happens. If you run this program
>>>         everything works as expected: you are greeted by a three
>>>         successful Precious and then an endless list of failures,
>>>         that it continuously grow. All good :)
>>>
>>>         02:34:40:0061 I did get my precious! Precious n.156
>>>         02:34:40:0062 I did get my precious! Precious n.991
>>>         02:34:40:0062 I did get my precious! Precious n.953
>>>         02:34:45:0064 I did not get my precious :(
>>>         02:34:50:0065 I did not get my precious :(
>>>         02:34:55:0066 I did not get my precious :(
>>>         02:35:00:0067 I did not get my precious :(
>>>         02:35:05:0068 I did not get my precious :(
>>>         [...]
>>>
>>>         But guess what happens when, while the program is running, I
>>>         change the date of my system back of one hour? Everything
>>>         stops,  it's simple as that. No prints, nothing, zero, nada.
>>>         Now, If it wasn't so late, I would probably wait one hour in
>>>         order to have my program restored to his normal process, but
>>>         as a customer I won't be terribly happy :)
>>>
>>>         I hope my point is now clear.
>>>         Cheers,
>>>
>>>             Bruno
>>>
>>>
>>>
>>>
>>>
>>>
>>>         On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             n 04/09/2013 18:54, bruno bossola wrote:
>>>>             Hi Oleksandr,
>>>>
>>>>                 Where in the design of those systems is a real-time
>>>>                 timer? The one that delivers time events
>>>>                 uncompromised even by GC latency?
>>>>
>>>>             I don't think so :) If somebody needs a real time
>>>>             implementation he needs to go for a real time JVM, like
>>>>             Jean correctly pointed out. The concurrency primitives
>>>>             are depending on LockSupport.parkNanos(...) to park a
>>>>             thread: if this for any reason is not working (like it
>>>>             is) then strange things may happen.
>>>             Your assumption is that it is not working, if the
>>>             elapsed time is longer. This is the flawed assumption.
>>>
>>>             Also, you need to read fine print on those "real time"
>>>             JVMs. The catch is in the definition of "real time".
>>>
>>>
>>>
>>>
>>>>             Imagine, for example, that you are using a
>>>>             ReentrantLock to control a very precious resource used
>>>>             across the board (what about a database connection
>>>>             pool?) and you are unlucky enough to have a system time
>>>>             change (backwards) while you are locking: all the
>>>>             threads that want to use such resource will be
>>>>             progressively locked: not forever, but for the amount
>>>>             of time the clock went back. Probably most (all?) of
>>>>             your system freezes, and the only option you have is to
>>>>             wait, or restart.
>>>>             Now place this in a large application server, that
>>>>             provide services for hunreds (thousands) of users. How
>>>>             does it sound to you?
>>>             It sounds like you don't understand how the locks work.
>>>
>>>
>>>             Alex
>>>
>>>
>>>>
>>>>             BTW, at the moment we could have a watchdog (in Python
>>>>             :)) that restarts it, but, I dunno why, I don't like it
>>>>             a lot...
>>>>
>>>>             Cheers,
>>>>
>>>>                 Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>             On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>>             <oleksandr.otenko at oracle.com
>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>
>>>>                 You are missing the point.
>>>>
>>>>                 Where in the design of those systems is a real-time
>>>>                 timer? The one that delivers time events
>>>>                 uncompromised even by GC latency?
>>>>
>>>>                 The whole concurrency lot does not depend on the
>>>>                 timeout magnitude for correctness.
>>>>
>>>>                 Alex
>>>>
>>>>
>>>>                 On 04/09/2013 12:05, bruno bossola wrote:
>>>>>                 Hi David
>>>>>
>>>>>
>>>>>                     bugs.sun.com <http://bugs.sun.com> is not a
>>>>>                     live reflection of the bug database but gets
>>>>>                     updated periodically (every 12 hours I think).
>>>>>
>>>>>
>>>>>                 Good to know :) I will be eagerly clicking on it
>>>>>                 to discover the new priority! Thanks for that, I
>>>>>                 really appreciate it.
>>>>>
>>>>>
>>>>>                     The issue arises on certain 64-bit linux
>>>>>                     kernel/glibc versions. If you have an older
>>>>>                     version this does not impact you.
>>>>>
>>>>>                 You saw my list: nobody will use an older
>>>>>                 Kernel/glibc version in production.
>>>>>
>>>>>
>>>>>                     As for the rest, show me real code in such
>>>>>                     systems that rely on sleep for correctness or
>>>>>                     performance/timeliness and I will show you
>>>>>                     broken code.
>>>>>
>>>>>                 You are still hitting about the sleep(), I
>>>>>                 understand and I agree about this. But here we are
>>>>>                 not talking about sleeps: we are talking about the
>>>>>                 whole concurrency lot. And yes, as I already said,
>>>>>                 we are talking about near time systems, like
>>>>>                 trading application, betting applications, air
>>>>>                 traffic control systems, car traffic control
>>>>>                 systems. Don't you think this bug might place
>>>>>                 Oracle JVM outside of these markets?
>>>>>
>>>>>
>>>>>                     If this was as dire as you make out do you not
>>>>>                     think that this issue would have been raised
>>>>>                     far more than it has? [....] prudent
>>>>>                     developers/companies trial platform upgrades
>>>>>                     to check for these kinds of issues before
>>>>>                     switching to them in production environments.
>>>>>
>>>>>                 I am waiting now for the part where you say that
>>>>>                 we should throw away Linux and use Oracle Solaris
>>>>>                 :)  In all seriousness, there's a lot of action
>>>>>                 "in the middle", and I think that Oracle cannot
>>>>>                 oversee that. For example a lot of trading
>>>>>                 software system can be installed on premises,
>>>>>                 where you usually have no control over the
>>>>>                 environment: what I would do is to put a native
>>>>>                 daemon in my app so that if I see the system clock
>>>>>                 change I would kill myself, just in case. And this
>>>>>                 is a solution that I know for a fact (sorry, I
>>>>>                 cannot make a reference) it's used in production
>>>>>                 in a very important trading application.
>>>>>
>>>>>                 Regarding that specific bug, it was not accessible
>>>>>                 to the external until two days ago, so I guess
>>>>>                 nobody really knew a lot about it, but I will make
>>>>>                 sure it will :) so that we can get more traction.
>>>>>
>>>>>                 Cheers,
>>>>>
>>>>>                     Bruno
>>>>>
>>>>>
>>>>>
>>>>>                 On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>>                 <davidcholmes at aapt.net.au
>>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>
>>>>>                     Bruno,
>>>>>                     bugs.sun.com <http://bugs.sun.com> is not a
>>>>>                     live reflection of the bug database but gets
>>>>>                     updated periodically (every 12 hours I think).
>>>>>                     The issue arises on certain 64-bit linux
>>>>>                     kernel/glibc versions. If you have an older
>>>>>                     version this does not impact you.
>>>>>                     As for the rest, show me real code in such
>>>>>                     systems that rely on sleep for correctness or
>>>>>                     performance/timelinessand I will show you
>>>>>                     broken code. We are not talking about
>>>>>                     real-time systemshere.
>>>>>                     park(nanos)/wait(millis) will only be affected
>>>>>                     by the backward time change if the real
>>>>>                     notification they are waiting for does not
>>>>>                     happen. Timeouts with these APIs are
>>>>>                     heuristics, they are defensive programming to
>>>>>                     cover the case "what if the notification I'm
>>>>>                     waiting for does not come". The code that
>>>>>                     would be affected by this issue is a very
>>>>>                     small % of the code that uses the API.
>>>>>                     If this was as dire as you make out do you not
>>>>>                     think that this issue would have been raised
>>>>>                     far more than it has? This issue does need
>>>>>                     addressing because the number of affected
>>>>>                     systems will grow as these newer linux systems
>>>>>                     are adopted, but prudent developers/companies
>>>>>                     trial platform upgrades to check for these
>>>>>                     kinds of issues before swicthing to them in
>>>>>                     production environments.
>>>>>                     Regards,
>>>>>                     David
>>>>>
>>>>>                         -----Original Message-----
>>>>>                         *From:* bruno bossola
>>>>>                         [mailto:bbossola at gmail.com
>>>>>                         <mailto:bbossola at gmail.com>]
>>>>>                         *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>>                         *To:* dholmes at ieee.org
>>>>>                         <mailto:dholmes at ieee.org>
>>>>>                         *Cc:* concurrency-interest at cs.oswego.edu
>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>                         Outstanding concurrency JVM issue - feedback?
>>>>>
>>>>>                         Hi David,
>>>>>
>>>>>                         thanks for following up.
>>>>>
>>>>>                             I have raised the priority on 6900441
>>>>>
>>>>>                         Thanks, but it looks still like a P4:
>>>>>                         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>                         See also the attached snapshot, just in
>>>>>                         case it changes :)
>>>>>
>>>>>                         Inline image 2
>>>>>
>>>>>                             [...] which to my knowledge [...] has
>>>>>                             never been a private bug
>>>>>
>>>>>                         It was not accessible using bugs.sun.com
>>>>>                         <http://bugs.sun.com/>, this was
>>>>>                         translated to private. I also received the
>>>>>                         same info indirectly from the 7u lead:
>>>>>                         "I'm not sure why 6900441 isn't public.
>>>>>                         (I'll follow up with owner of bugs.sun.com
>>>>>                         <http://bugs.sun.com/>)", I guess you can
>>>>>                         check with him.
>>>>>
>>>>>
>>>>>                             It doesn't affect "every JVM64 running
>>>>>                             on Linux64".  A fix has been
>>>>>                             introduced into a specific glibc
>>>>>                             version...
>>>>>
>>>>>                         ...and apparently did not make it. I was
>>>>>                         able to reproduce this even with the IBM
>>>>>                         VM, so to speak. I tried JDK6, JDK7, JDK8
>>>>>                         on Ubuntu 10, 11, 12, 13 + some random
>>>>>                         Debian. I did not have a JDK5, so I cannot
>>>>>                         say, but on JDK4 everything works (that's
>>>>>                         the reason why I call it a regression).
>>>>>                         (ah, if you look at the bug, it lists also
>>>>>                         JDK5, so I think we are pretty much
>>>>>                         covered here).
>>>>>                         If you still have doubts tough, please
>>>>>                         have also a look on stackoverflow to see
>>>>>                         how it was reproduced consistently on
>>>>>                         probably every 64bitJVM over 64bitLinux in
>>>>>                         the world.
>>>>>
>>>>>
>>>>>                             The effects of this is not that "all
>>>>>                             the threads parked will hang, with
>>>>>                             unpredictable/corrupted/useless"! The
>>>>>                             effects are very simple an quite
>>>>>                             predictable... [deletia]s.
>>>>>
>>>>>                         We have very different views, and I find
>>>>>                         quite difficult to accept yours. You are
>>>>>                         confusing my sample program which contains
>>>>>                         a single thread in a for loop with any
>>>>>                         other complex multi-threading concurrent
>>>>>                         system written in Java. For example, if
>>>>>                         you ever worked in a bank you surely know
>>>>>                         what I mean. You are comparing some random
>>>>>                         sleep() put into a program by some newbie,
>>>>>                         with the complex ecosystem of a concurrent
>>>>>                         platform written to manage trading
>>>>>                         information on very fast market. In that
>>>>>                         condition, I am sorry, statements such
>>>>>                         "...delayed timeout does not affect
>>>>>                         operation in a correctly functioning
>>>>>                         system..." and "...small time changes
>>>>>                         [...] are not a problem" are really not
>>>>>                         applicable. Let your system place an order
>>>>>                         three seconds late and your are out of the
>>>>>                         door so quickly you cannot even realize it.
>>>>>
>>>>>                         But let's not limit ourselves to banks:
>>>>>                         how do you think your previous statements
>>>>>                         stands in these scenarios?
>>>>>                         - air control systems
>>>>>                         <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>                         about a few seconds delay in control when
>>>>>                         fying planes?)
>>>>>                         - city traffic control systems
>>>>>                         <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>                         if just for a couple of seconds all
>>>>>                         traffic lights become green?)
>>>>>
>>>>>                         Not good enough.
>>>>>
>>>>>
>>>>>                             ...small time changes as typically
>>>>>                             done via NTP
>>>>>
>>>>>                         NTP is only one of the possible sources of
>>>>>                         this problem. The root of it is that the
>>>>>                         JVM is counting nanoseconds delays using
>>>>>                         absolute values based on a wallclock: I do
>>>>>                         not think it's that smart.
>>>>>
>>>>>
>>>>>                             So there is an issue that needs to be
>>>>>                             addressed but the situation is nowhere
>>>>>                             near as dire as you make out
>>>>>
>>>>>                         Let's try to put this in perspective,
>>>>>                         shall we? In case the clock run
>>>>>                         backwards LockSupport.park() will be
>>>>>                         waiting for the nanoseconds requested plus
>>>>>                         the amount of seconds/minute/hours/days
>>>>>                         requested to compensate. Now, this
>>>>>                         primitive is used by almost *every*
>>>>>                         concurrency construct available on the
>>>>>                         platform, such as
>>>>>                         AbstractQueuedSynchronizer (and
>>>>>                         subclasses), ReentrantLock (and
>>>>>                         subclasses), CyclicBarrier, BlockingQueue
>>>>>                         (and subclasses), Executors, FutureTask,
>>>>>                         .... (too long to list them all, but I
>>>>>                         think we have the picture) and also low
>>>>>                         levels synchronization primitives of the
>>>>>                         language itself, so Object::wait(:long)
>>>>>                         and the related sychronized blocks.
>>>>>
>>>>>                         I think it's pretty dire.
>>>>>
>>>>>
>>>>>                         Cheers,
>>>>>
>>>>>                             Bruno
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>                         On Wed, Sep 4, 2013 at 12:14 AM, David
>>>>>                         Holmes <davidcholmes at aapt.net.au
>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>
>>>>>                             Hi Bruno,
>>>>>                             I have raised the priority on 6900441
>>>>>                             (which to my knowledge - and I created
>>>>>                             it! - has never been a private bug).
>>>>>                             A few notes on the "very frightening"
>>>>>                             aspect of this:
>>>>>                             1. It doesn't affect "every JVM64
>>>>>                             running on Linux64". A fix has been
>>>>>                             introduced into a specific glibc
>>>>>                             version for the futex-wait code such
>>>>>                             that it now responds to changes in the
>>>>>                             system time for absolute waits, where
>>>>>                             for all the years previous it did not.
>>>>>                             The fix seems to have been applied in
>>>>>                             late 2011 or early 2012 but I don't
>>>>>                             know the exact glibc version. There is
>>>>>                             also a 32-bit version of the fix that
>>>>>                             was proposed on Nov 27, 2012, so it
>>>>>                             will eventually make its way into
>>>>>                             32-bit linux too.
>>>>>                             2. The effects of this is not that
>>>>>                             "all the threads parked will hang,
>>>>>                             with unpredictable/corrupted/useless"!
>>>>>                             The effects are very simple an quite
>>>>>                             predictable. If the system time goes
>>>>>                             forward then timed-waits (Object.wait,
>>>>>                             LockSupport.park) (which should be
>>>>>                             relative times) will return early as
>>>>>                             the absolute-time that the relative
>>>>>                             time was converted to will be seen to
>>>>>                             have been reached (Thread.sleep
>>>>>                             contains a guard against early
>>>>>                             returns). This is not actually a
>>>>>                             problem as you can not distinguish
>>>>>                             this case from a "spurious wakeup"
>>>>>                             which code is supposed to account
>>>>>                             for. If the time is changed backwards
>>>>>                             then these timed-waits & sleeps will
>>>>>                             not timeout when expected as the the
>>>>>                             for that is now further in the future,
>>>>>                             by the amount of the backward time
>>>>>                             change. Hence small time changes as
>>>>>                             typically done via NTP are NOT a
>>>>>                             problem. Timed-waits use timeouts as a
>>>>>                             heuristics for recovering when the
>>>>>                             expected real event notification does
>>>>>                             not occur - so a delayed timeout does
>>>>>                             not affect operation in a correctly
>>>>>                             functioning system. Early timeouts are
>>>>>                             indistinguishable from spurious
>>>>>                             wakeups, which code has to account
>>>>>                             for, so again not a problem for
>>>>>                             regular code. The only time a
>>>>>                             significant "hang" will occur is with
>>>>>                             Thread.sleep and a large backward time
>>>>>                             shift - but there is little real code
>>>>>                             that uses Thread.sleep in any critical
>>>>>                             way.
>>>>>                             So there is an issue that needs to be
>>>>>                             addressed but the situation is nowhere
>>>>>                             near as dire as you make out.
>>>>>                             David Holmes
>>>>>
>>>>>                                 -----Original Message-----
>>>>>                                 *From:*
>>>>>                                 concurrency-interest-bounces at cs.oswego.edu
>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>                                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>>                                 Behalf Of *bruno bossola
>>>>>                                 *Sent:* Wednesday, 4 September
>>>>>                                 2013 1:56 AM
>>>>>                                 *To:*
>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                                 *Subject:* [concurrency-interest]
>>>>>                                 Outstanding concurrency JVM issue
>>>>>                                 - feedback?
>>>>>
>>>>>                                 Hi all,
>>>>>
>>>>>                                 I am writing here following a
>>>>>                                 suggestion by Ben Evans. I wanted
>>>>>                                 to check with you about an issue
>>>>>                                 that my teams found on the JVM and
>>>>>                                 that's very frightening. I already
>>>>>                                 started the discussion with the
>>>>>                                 engineers of the hotspot VM team
>>>>>                                 but it looks like we need more
>>>>>                                 awareness to solve this one and
>>>>>                                 I'd really appreciate some help
>>>>>                                 and some push :)
>>>>>                                 It looks to me that this issue is
>>>>>                                 affecting every JVM64 running on
>>>>>                                 Linux64, so imho it's quite
>>>>>                                 important to be looked at.
>>>>>
>>>>>                                 *Executive summary
>>>>>                                 *The implementation of the
>>>>>                                 concurrency primitive
>>>>>                                 LockSupport.parkNanos(), the
>>>>>                                 function that controls most
>>>>>                                 concurrency primitive on the JVM,
>>>>>                                 is flawed, and any NTP sync, or
>>>>>                                 system time change, can
>>>>>                                 potentially break it with
>>>>>                                 unexpected results across the board.
>>>>>
>>>>>                                 *What we need to do?
>>>>>                                 *This is an old issue, and the bug
>>>>>                                 <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>>                                 was declared private. I somehow
>>>>>                                 managed to have the bug reopened
>>>>>                                 to the public, but it's still a 
>>>>>                                 P4, that means that probably won't
>>>>>                                 be fixed. I think we need to push
>>>>>                                 for a resolution ASAP, be sure
>>>>>                                 that's in for JDK9, make all the
>>>>>                                 possible effort to make this fix
>>>>>                                 for JDK8 or, at least, to include
>>>>>                                 it in a later patch release. In an
>>>>>                                 ideal world it would be nice to
>>>>>                                 have a patch for JDK7. As far as I
>>>>>                                 understand the hotspot engineering
>>>>>                                 team works based on priorities:
>>>>>                                 being this qualified as P4 means
>>>>>                                 it won't be probably worked on (if
>>>>>                                 you follow the breadcrumbs of bugs
>>>>>                                 and fixes you can go back to
>>>>>                                 2002!) They acknowledge the
>>>>>                                 problem, it has been flagged to
>>>>>                                 management, but 1) it's low
>>>>>                                 priority 2) it's too risky to fix
>>>>>                                 for JDK8
>>>>>
>>>>>
>>>>>                                 *Why all this urgency?
>>>>>                                 *If a system time change happens
>>>>>                                 then all the threads parked will
>>>>>                                 hang, with
>>>>>                                 unpredictable/corrupted/useless
>>>>>                                 results to the end user. Same
>>>>>                                 applies to Future, Queue,
>>>>>                                 Executor, and (I guess) any other
>>>>>                                 construct that it's somehow
>>>>>                                 related to concurrency. This is a
>>>>>                                 big issue for us and for any near
>>>>>                                 time application: please think
>>>>>                                 about trading and betting, where
>>>>>                                 the JVM is largely used, and  do
>>>>>                                 not restrain yourself to the Java
>>>>>                                 language: add Scala and any other
>>>>>                                 JVM-based language to the picture
>>>>>                                 (JRuby, Jython...)
>>>>>
>>>>>                                 *Tech details**
>>>>>                                 *To be more clear about the issue,
>>>>>                                 the extent of it and the
>>>>>                                 concurrency library, let me
>>>>>                                 introduce this very simple program:
>>>>>
>>>>>                                 import
>>>>>                                 java.util.concurrent.locks.LockSupport;
>>>>>
>>>>>                                 public class Main {
>>>>>
>>>>>                                     public static void
>>>>>                                 main(String[] args) {
>>>>>
>>>>>                                         for (int i=100; i>0; i--) {
>>>>>                                 System.out.println(i);
>>>>>                                 LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>                                         }
>>>>>
>>>>>                                 System.out.println("Done!");
>>>>>                                     }
>>>>>                                 }
>>>>>
>>>>>                                 Run it with a 64bit 1.6+ JVM on
>>>>>                                 64bit Linux, turn the clock down
>>>>>                                 one hour and wait until the
>>>>>                                 counter stops... magic!  I tested
>>>>>                                 this on JDK6, JDK7 and latest JDK8
>>>>>                                 beta running on various Ubuntu
>>>>>                                 distros. It's not just a matter of
>>>>>                                 (old?) sleep() and wait()
>>>>>                                 primitives, this issue it affects
>>>>>                                 the whole concurrency library.
>>>>>
>>>>>                                 To prove that this is fixable, I
>>>>>                                 reimplemented the program above
>>>>>                                 above substituting
>>>>>                                 LockSupport.parkNanos() with  a
>>>>>                                 JNI call to
>>>>>                                 clock_nanosleep(CLOCK_MONOTONIC...):
>>>>>                                 works like a charm :(
>>>>>
>>>>>                                 This is due to the fact  that the
>>>>>                                 CPP code is calling the
>>>>>                                 pthread_cond_timedwait() using its
>>>>>                                 default clock (CLOCK_REALTIME)
>>>>>                                 which, unfortunately is affected
>>>>>                                 by settime()/settimeofday() calls
>>>>>                                 (on Linux): for that reason it
>>>>>                                 cannot be used to measure
>>>>>                                 nanoseconds delays, which is what
>>>>>                                 the specification
>>>>>                                 <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>>                                 requires. CLOCK_REALTIME is not
>>>>>                                 guaranteed to monotonically count
>>>>>                                 as this is the actual "system
>>>>>                                 time": each time my system syncs
>>>>>                                 time using a NTP server on the
>>>>>                                 net, the time might jump forward
>>>>>                                 or backward. The correct call
>>>>>                                 (again on Linux)  would require to
>>>>>                                 use CLOCK_MONOTONIC as clock id,
>>>>>                                 which are defined by POSIX specs
>>>>>                                 since 2002. (or better
>>>>>                                 CLOCK_MONOTONIC_RAW)
>>>>>
>>>>>                                 The POSIX spec
>>>>>                                 <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>>                                 is infact clear, as it states
>>>>>                                 "...setting the value of the
>>>>>                                 CLOCK_REALTIME clock via
>>>>>                                 clock_settime() shall have no
>>>>>                                 effect on threads that are blocked
>>>>>                                 waiting for a *relative* time
>>>>>                                 service based upon this clock...":
>>>>>                                 it definitely states "relative".
>>>>>                                 Having a look at the hotspot code
>>>>>                                 <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>                                 it appears that the park() is
>>>>>                                 using compute_abstime() (which
>>>>>                                 uses timeofday) and then waits on
>>>>>                                 an absolute period: for that
>>>>>                                 reason it's influenced by the
>>>>>                                 system clock change. *Very wrong*.
>>>>>
>>>>>                                 I will be happy to know what you
>>>>>                                 think, and if you can help me to
>>>>>                                 escalate this issue I think that
>>>>>                                 the all Java community will
>>>>>                                 benefit from it.
>>>>>
>>>>>                                 Cheers,
>>>>>
>>>>>                                     Bruno
>>>>>
>>>>>
>>>>>                         No virus found in this message.
>>>>>                         Checked by AVG - www.avg.com
>>>>>                         <http://www.avg.com>
>>>>>                         Version: 2013.0.3392 / Virus Database:
>>>>>                         3222/6633 - Release Date: 09/03/13
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>                 _______________________________________________
>>>>>                 Concurrency-interest mailing list
>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/73851060/attachment-0001.html>

From rk at rkuhn.info  Thu Sep  5 14:15:23 2013
From: rk at rkuhn.info (Roland Kuhn)
Date: Thu, 5 Sep 2013 20:15:23 +0200
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5228C351.4070009@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
	<5228C351.4070009@oracle.com>
Message-ID: <966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>


5 sep 2013 kl. 19:45 skrev Oleksandr Otenko:

> Exactly my point.
> 
> Now someone needs to take care of negative time returned, when the clock goes back, even if the wait was shorter than timeout.

Why would that lead to a negative return value?

> Or, if we report the actual time waited, then deal with the inconsistency between apparent System.nanoTime() and the wait.

There are two very different time sources in the JVM, and the one which has ?nano? in its name is supposed to be monotonic and independent of the system?s wall time clock. I share Bruno?s view that a method called awaitNanos() should measure time using System.nanoTime and not with System.currentTimeMillis (conceptually). It is unfortunate that the API docs of awaitNanos() do not specify which of these choices was made.

Regards,

Roland

> 
> Alex
> 
> On 05/09/2013 18:31, ?iktor ?lang wrote:
>> For Condition.awaitNanos it states:
>> 
>> Returns:
>> an estimate of the nanosTimeout value minus the time spent waiting upon return from this method. A positive value may be used as the argument to a subsequent call to this method to finish waiting out the desired time. A value less than or equal to zero indicates that no time remains.
>> 
>> 
>> 
>> 
>> 
>> On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>> Oh, and now someone else is going to complain that awaitNanos returns a negative number, even though it waited for only 1 ms out of 100.
>> 
>> Alex
>> 
>> On 05/09/2013 17:50, bruno bossola wrote:
>>> I am sorry but I really cannot spend more time creating more samples and I am quite sure you could do a better work at that! At the moment to me that matter is clear enough, but feel free to ask, I will very happy to help! In the meantime I prefer spend my time to work on a patch that I can apply on my JVMs :)
>>> 
>>> Cheers,
>>> 
>>>     Bruno
>>> 
>>> 
>>> 
>>> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>> This is far from reproducing the problem with arbitrary j.u.c locks and queues hanging.
>>> 
>>> Condition.awaitNanos can return a negative value. If you are expecting the negative value to be small, then how small do you expect it to be?
>>> 
>>> 
>>> Alex
>>> 
>>> 
>>> On 05/09/2013 02:12, bruno bossola wrote:
>>>> Hi Oaleksandr,
>>>> 
>>>> Please apologize me if my english was not good enough to provide you an example that make sense: for that reason I decided to go back to a binary deliverable (code) that shows the problem, hope this helps!
>>>> 
>>>> This is my PreciousPool class, that handles Precious resources:
>>>> 
>>>> import java.text.SimpleDateFormat;
>>>> import java.util.ArrayList;
>>>> import java.util.Date;
>>>> import java.util.List;
>>>> import java.util.concurrent.TimeUnit;
>>>> import java.util.concurrent.locks.Condition;
>>>> import java.util.concurrent.locks.Lock;
>>>> import java.util.concurrent.locks.ReentrantLock;
>>>> 
>>>> public class PreciousPool {
>>>>     
>>>>     public static class Precious {
>>>>         private final int id;
>>>> 
>>>>         private Precious() {
>>>>             this.id = 100+(int)(Math.random()*900.0);
>>>>         }
>>>> 
>>>>         public String toString() {
>>>>             return "Precious n."+id;
>>>>         }
>>>>     }
>>>>     
>>>>     private final Lock lock;
>>>>     private final Condition ready;
>>>>     private final long timeoutInMillis;
>>>> 
>>>>     private final List<Precious> preciousLended;
>>>>     private final List<Precious> preciousAvailable;
>>>>     
>>>>     public PreciousPool(int size, long timeoutInSeconds) {
>>>>         this.lock = new ReentrantLock();
>>>>         this.ready = lock.newCondition();
>>>> 
>>>>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>>         this.preciousLended =  new ArrayList<Precious>();
>>>>         this.preciousAvailable = new ArrayList<Precious>();
>>>> 
>>>>         for (int i = 0; i < size; i++) {
>>>>             preciousAvailable.add(new Precious());
>>>>         }
>>>>     }
>>>>     
>>>>     public Precious obtain()  {
>>>>         lock.lock();
>>>>         try {
>>>>             // if no precious are available we wait for the specified timeout (releasing the lock so that others can try)
>>>>             if (preciousAvailable.size() == 0) {
>>>>                 try {
>>>>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>>                 } catch (InterruptedException e) {
>>>>                     Thread.currentThread().interrupt();
>>>>                     throw new RuntimeException("Somebody interrupted me!", e);
>>>>                 }
>>>>             }
>>>>             
>>>>             // if a precious is available we unload it and return to the caller, otherwise null
>>>>             if (preciousAvailable.size() > 0) {
>>>>                 Precious value = preciousAvailable.remove(0);
>>>>                 preciousLended.add(value);
>>>>                 return value;
>>>>             } else {
>>>>                 return null;
>>>>             }
>>>>         } finally {
>>>>             lock.unlock();
>>>>         }
>>>>     }
>>>> 
>>>>     public void release(Precious value) {
>>>>         lock.lock();
>>>>         try {
>>>>             if (!preciousLended.remove(value))
>>>>                 throw new RuntimeException("Element "+value+" was not lended!");
>>>>             
>>>>             // if a precious is returned we put it back and signal to anybody waiting
>>>>             preciousAvailable.add(value);
>>>>             ready.signalAll();
>>>>         } finally {
>>>>             lock.unlock();
>>>>         }
>>>>     }
>>>>     
>>>>     public static void main(String args[]) {
>>>>         final int size = 3;
>>>>         final PreciousPool pool = new PreciousPool(size, 5);
>>>> 
>>>>         // let's exhaust the pool
>>>>         for (int i=0; i<size; i++)
>>>>             dump(pool.obtain());
>>>> 
>>>>         // and as we are stubborn we continuosly ask for a new one
>>>>         while(true) {
>>>>             dump(pool.obtain());
>>>>         }
>>>>     }
>>>> 
>>>>     private static void dump(Precious precious) {
>>>>         if (precious == null)
>>>>             log("I did not get my precious :(");
>>>>         else
>>>>             log("I did get my precious! "+precious);
>>>>     }
>>>> 
>>>>     private static void log(String message) {
>>>>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>>         System.out.println(now + message);
>>>>     }
>>>> }
>>>> 
>>>> So, the main is a single thread (no need for multithreading here, let's keep it simple), that first exhaust the whole                                 pool and then keep asking, without success, for a resource. Stubborn guy, I say, but it happens. If you run this program everything works as expected: you are greeted by a three successful Precious and then an endless list of failures, that it continuously grow. All good :) 
>>>> 
>>>> 02:34:40:0061 I did get my precious! Precious n.156
>>>> 02:34:40:0062 I did get my precious! Precious n.991
>>>> 02:34:40:0062 I did get my precious! Precious n.953
>>>> 02:34:45:0064 I did not get my precious :(
>>>> 02:34:50:0065 I did not get my precious :(
>>>> 02:34:55:0066 I did not get my precious :(
>>>> 02:35:00:0067 I did not get my precious :(
>>>> 02:35:05:0068 I did not get my precious :(
>>>> [...]
>>>> 
>>>> But guess what happens when, while the program is running, I change the date of my system back of one hour? Everything stops,  it's simple as that. No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably wait one hour in order to have my program restored to his normal process, but as a customer I won't be terribly happy :)
>>>> 
>>>> I hope my point is now clear.
>>>> Cheers,
>>>> 
>>>>     Bruno
>>>> 
>>>> 
>>>> 
>>>>    
>>>> 
>>>> 
>>>> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>>> n 04/09/2013 18:54, bruno bossola wrote:
>>>>> Hi Oleksandr,
>>>>> 
>>>>> Where in the design of those systems is a real-time timer? The one that delivers time events uncompromised even by GC latency?
>>>>>  
>>>>> I don't think so :) If somebody needs a real time implementation he needs to go for a real time JVM, like Jean correctly pointed out.  The concurrency primitives are depending on LockSupport.parkNanos(...) to park a thread: if this for any reason is not working (like it is) then strange things may happen.
>>>> Your assumption is that it is not working, if the elapsed time is longer. This is the flawed assumption.
>>>> 
>>>> Also, you need to read fine print on those "real time" JVMs. The catch is in the definition of "real time".
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> Imagine, for example, that you are using a ReentrantLock to control a very precious resource used across the board (what about a database connection pool?) and you are unlucky enough to have a system time change (backwards) while you are locking: all the threads that want to use such resource will be progressively locked: not forever, but for the amount of time the clock went back. Probably most (all?) of your system freezes, and the only option you have is to wait, or restart. 
>>>>> Now place this in a large application server, that provide services for hunreds (thousands) of users. How does it sound to you?
>>>> It sounds like you don't understand how the locks work.
>>>> 
>>>> 
>>>> Alex
>>>> 
>>>> 
>>>>> 
>>>>> BTW, at the moment we could have a watchdog (in Python :)) that restarts it, but, I dunno why, I don't like it a lot...
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>>     Bruno
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>>>> You are missing the point.
>>>>> 
>>>>> Where in the design of those systems is a real-time timer? The one that delivers time events uncompromised even by GC latency?
>>>>> 
>>>>> The whole concurrency lot does not depend on the timeout magnitude for correctness.
>>>>> 
>>>>> Alex
>>>>> 
>>>>> 
>>>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>>>> Hi David
>>>>>>  
>>>>>> 
>>>>>> bugs.sun.com is not a live reflection of the bug database but gets updated periodically (every 12 hours I think).
>>>>>>   
>>>>>> Good to know :) I will be eagerly clicking on it to discover the new priority! Thanks for that, I really appreciate it.
>>>>>> 
>>>>>> 
>>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you have an older version this does not                                                           impact you.
>>>>>>  
>>>>>> You saw my list: nobody will use an older Kernel/glibc version in production.
>>>>>> 
>>>>>> 
>>>>>> As for the rest, show me real code in such systems that rely on sleep for correctness or performance/timeliness and I will show you broken code.
>>>>>>  
>>>>>> You are still hitting about the sleep(), I understand and I agree about this. But here we are not talking about sleeps: we are talking about the whole concurrency lot. And yes, as I already said, we are talking about near time systems, like trading application, betting applications, air traffic control systems, car traffic control systems. Don't you think this bug might place Oracle JVM outside of these markets?
>>>>>> 
>>>>>>  
>>>>>> If this was as dire as you make out do you not think that this issue would have been raised far more than it has? [....] prudent developers/companies trial platform upgrades to check for these kinds of issues before switching to them in production environments.
>>>>>> 
>>>>>> I am waiting now for the part where you say that we should throw away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of action "in the middle", and I think that Oracle cannot oversee that. For example a lot of trading software system can be installed on premises, where you usually have no control                                                           over the environment: what I would do is to put a native daemon in my app so that if I see the system clock change I would kill myself, just in case. And this is a solution that I know for a fact (sorry, I cannot make a reference) it's used in production in a very important trading application.
>>>>>> 
>>>>>> Regarding that specific bug, it was not accessible to the external until two days ago, so I guess nobody really knew a lot about it, but I will make sure it will :) so that we can get more traction.
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>>     Bruno
>>>>>>  
>>>>>> 
>>>>>> 
>>>>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>>>> Bruno,
>>>>>>  
>>>>>> bugs.sun.com is not a live reflection of the bug database but gets updated periodically (every 12 hours I think).
>>>>>>  
>>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you have an older version this does not impact you.
>>>>>>  
>>>>>> As for the rest, show me real code in such systems that rely on sleep for correctness or performance/timeliness and I will show you broken code. We are not talking about                                                           real-time systems here. park(nanos)/wait(millis) will only be affected by the backward                                                           time change if the real notification they are waiting for does not happen. Timeouts with these APIs are heuristics, they are defensive programming to cover the case "what if the notification I'm waiting for does not come". The code that would be affected by this issue is a very small % of the code that uses the API.
>>>>>>  
>>>>>> If this was as dire as you make out do you not think that this issue would have been raised far more than it has? This issue does need addressing because the number of                                                           affected systems will grow as these newer linux systems are adopted, but prudent developers/companies trial platform upgrades to check for these kinds of issues before swicthing to them in production environments.
>>>>>>  
>>>>>> Regards,
>>>>>> David
>>>>>> -----Original Message-----
>>>>>> From: bruno bossola [mailto:bbossola at gmail.com]
>>>>>> Sent: Wednesday, 4 September 2013 11:14 AM
>>>>>> To: dholmes at ieee.org
>>>>>> Cc: concurrency-interest at cs.oswego.edu
>>>>>> Subject: Re: [concurrency-interest] Outstanding concurrency JVM issue - feedback?
>>>>>> 
>>>>>> Hi David,
>>>>>> 
>>>>>> thanks for following up.
>>>>>> 
>>>>>>  
>>>>>> I have raised the priority on 6900441
>>>>>>  
>>>>>> Thanks, but it looks still like a P4:
>>>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>> See also the attached snapshot, just in case it changes :) 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> [...] which to my knowledge [...] has never been a private bug
>>>>>>  
>>>>>> It was not accessible using bugs.sun.com, this was translated to private. I also received the same info indirectly from the 7u lead:
>>>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of bugs.sun.com)", I guess you can check with him.
>>>>>> 
>>>>>> 
>>>>>> It doesn't affect "every JVM64 running on Linux64".  A fix has been introduced into a specific glibc version...
>>>>>>   
>>>>>> ...and apparently did not make it. I was able to reproduce this even with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on JDK4 everything works (that's the reason why I call it a regression). (ah, if you look at the bug, it lists also JDK5, so I think we are pretty much covered here). 
>>>>>> If you still have doubts tough, please have also a look on stackoverflow to see how it was reproduced                                                           consistently on probably every 64bitJVM over 64bitLinux in the world.
>>>>>> 
>>>>>> 
>>>>>> The effects of this is not that "all the threads parked will hang, with unpredictable/corrupted/useless"! The effects are very simple an quite predictable... [deletia]s.
>>>>>>  
>>>>>> We have very different views, and I find quite difficult to accept yours. You are confusing my sample program which contains a single thread in a for loop with any other complex multi-threading concurrent system written in Java. For example, if you ever worked in a bank you surely know what I mean. You are comparing some random sleep() put into a program by some newbie, with the complex ecosystem of a concurrent platform written to manage trading information on very fast market. In that condition, I am sorry, statements such "...delayed timeout does not affect operation in a correctly functioning system..." and "...small time changes [...] are not a problem" are really not applicable. Let your system place an order three seconds late and your are out of the door so quickly you cannot even realize it.
>>>>>> 
>>>>>> But let's not limit ourselves to banks: how do you think your previous statements stands in these scenarios?
>>>>>> - air control systems (what about a few seconds delay in control when fying planes?)
>>>>>> - city traffic control systems (what if just for a couple of seconds all traffic lights become green?)
>>>>>> 
>>>>>> Not good enough.
>>>>>> 
>>>>>> 
>>>>>> ...small time changes as typically done via NTP
>>>>>>   
>>>>>> NTP is only one of the possible sources of this problem. The root of it is that the JVM is counting nanoseconds delays using absolute values based on a wallclock: I do not think it's that smart. 
>>>>>> 
>>>>>> 
>>>>>> So there is an issue that needs to be addressed but the situation is nowhere near as dire as you make                                                           out
>>>>>>   
>>>>>> Let's try to put this in perspective, shall we? In case the clock run backwards LockSupport.park() will be waiting for the nanoseconds requested plus the amount of seconds/minute/hours/days requested to compensate. Now, this primitive is used by almost *every* concurrency construct available on the platform, such as AbstractQueuedSynchronizer (and subclasses), ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and subclasses), Executors, FutureTask, .... (too long to list them all, but I think we have the picture) and also low levels synchronization primitives of the language itself, so Object::wait(:long) and the related sychronized blocks. 
>>>>>> 
>>>>>> I think it's pretty dire.
>>>>>> 
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>>     Bruno
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>>>> Hi Bruno,
>>>>>>  
>>>>>> I have raised the priority on 6900441 (which to my knowledge - and I created it! - has never been a private bug).
>>>>>>  
>>>>>> A few notes on the "very frightening" aspect of this:
>>>>>>  
>>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been introduced into a specific glibc version for the futex-wait code such that it now responds to changes in the system time for absolute waits, where for all the years previous it did not. The fix seems to have been applied in late 2011 or early 2012 but I don't know the exact glibc version. There is also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it will eventually make its way into 32-bit linux too.
>>>>>>  
>>>>>> 2. The effects of this is not that "all the threads parked will hang, with unpredictable/corrupted/useless"! The effects are very simple an quite predictable. If the system time goes forward then timed-waits (Object.wait, LockSupport.park) (which should be relative times) will return early as the absolute-time that the relative time was converted to will be seen to have been reached (Thread.sleep contains a guard against early returns). This is not actually a problem as you can not distinguish this case from a "spurious wakeup" which code is supposed to account for. If the time is changed backwards then these timed-waits & sleeps will not timeout when expected as the the for that is now further in the future, by the amount of the backward time change. Hence small time changes as typically done via NTP are NOT a problem. Timed-waits use timeouts as a heuristics for recovering when the expected real event notification does not occur - so a delayed timeout does not affect operation in a correctly functioning system. Early timeouts are indistinguishable from spurious wakeups, which code has to account for, so again not a problem for regular code. The only time a significant "hang" will                                                           occur is with Thread.sleep and a large backward time shift - but there is little real code that uses Thread.sleep in any critical way.
>>>>>>  
>>>>>> So there is an issue that needs to be addressed but the situation is nowhere near as dire as you make out.
>>>>>>  
>>>>>> David Holmes
>>>>>> -----Original Message-----
>>>>>> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno bossola
>>>>>> Sent: Wednesday, 4 September 2013 1:56 AM
>>>>>> To: concurrency-interest at cs.oswego.edu
>>>>>> Subject: [concurrency-interest] Outstanding concurrency JVM issue - feedback?
>>>>>> 
>>>>>> Hi all,
>>>>>> 
>>>>>> I am writing here following a suggestion by Ben Evans. I wanted to check with you about an issue that my teams found on the JVM and that's very frightening. I already started the discussion with the engineers of the hotspot VM team but it looks like we need more awareness to solve this one and I'd really appreciate some help and some push :) 
>>>>>> It looks to me that this issue is affecting every JVM64 running on Linux64, so imho it's quite important to be looked at.
>>>>>> 
>>>>>> Executive summary
>>>>>> The implementation of the concurrency primitive LockSupport.parkNanos(), the function that controls most concurrency primitive on the JVM, is flawed, and any NTP sync, or system time change, can potentially break it with unexpected results across the board.
>>>>>> 
>>>>>> What we need to do?
>>>>>> This is an old issue, and the bug was declared private. I somehow managed to have the bug reopened to the public, but it's still a  P4, that means that probably won't be fixed. I think we need to push for a resolution ASAP, be sure that's in for JDK9, make all the possible effort to make this fix for JDK8 or, at least, to include it in a later patch release. In an ideal world it would be nice to have a patch for JDK7. As far as I understand the hotspot engineering team works based on priorities: being this qualified as P4 means it won't be probably worked on (if you follow the breadcrumbs of bugs and fixes you can go back to 2002!) They acknowledge the problem, it has been flagged to management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>> 
>>>>>> 
>>>>>> Why all this urgency?
>>>>>> If a system time change happens then all the threads parked will hang, with unpredictable/corrupted/useless results to the end user. Same applies to Future, Queue, Executor, and (I guess) any other construct that it's somehow related to concurrency. This is a big issue for us and for any near time application: please think about trading and betting, where the JVM is largely used, and  do not restrain yourself to the Java language: add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>> 
>>>>>> Tech details
>>>>>> To be more clear about the issue, the extent of it and the concurrency library, let me introduce this very simple program:
>>>>>> 
>>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>> 
>>>>>> public class Main {
>>>>>> 
>>>>>>     public static void main(String[] args) {
>>>>>> 
>>>>>>         for (int i=100; i>0; i--) {
>>>>>>             System.out.println(i);
>>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>         }
>>>>>> 
>>>>>>         System.out.println("Done!");
>>>>>>     }
>>>>>> }
>>>>>> 
>>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour and wait until the                                                           counter stops... magic!  I tested this on JDK6, JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just a matter of (old?) sleep() and wait() primitives, this issue it affects the whole concurrency library. 
>>>>>> 
>>>>>> To prove that this is fixable, I reimplemented the program above above substituting  LockSupport.parkNanos()  with  a JNI call to clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>> 
>>>>>> This is due to the fact  that the CPP code is calling the pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which, unfortunately is affected by settime()/settimeofday() calls (on Linux): for that reason it cannot be used to measure nanoseconds delays, which is what the specification requires. CLOCK_REALTIME is not guaranteed to monotonically count as this is the actual "system time": each time my system syncs time using a NTP server on the net, the time might jump forward or backward. The correct call (again on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>>>>> 
>>>>>> The POSIX spec is infact clear, as it states "...setting the value of the CLOCK_REALTIME clock via clock_settime() shall have no effect on threads that are blocked waiting for a relative time service based upon this clock...": it definitely states "relative".  Having a look at the hotspot code, it appears that the park() is using compute_abstime() (which uses timeofday) and then waits on an absolute period: for that reason it's influenced by the system clock change. Very wrong.
>>>>>> 
>>>>>> I will be happy to know what you think, and if you can help me to escalate this issue I think that the all Java community will benefit from it.
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>>     Bruno
>>>>>> 
>>>>>> No virus found in this message.
>>>>>> Checked by AVG - www.avg.com
>>>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date: 09/03/13
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>>> 
>>>> 
>>>> 
>>> 
>>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
>> 
>> 
>> -- 
>> Viktor Klang
>> Director of Engineering
>> Typesafe
>> 
>> Twitter: @viktorklang
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/bc5af4c9/attachment-0001.html>

From bbossola at gmail.com  Thu Sep  5 14:20:03 2013
From: bbossola at gmail.com (bruno bossola)
Date: Thu, 5 Sep 2013 19:20:03 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5228C3DF.9050008@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228B960.6010305@oracle.com>
	<CAJU-cA+xn-8ONmTWu2Oa+R47-T+_Ws-4WqS+23K5VgYp_2=CLQ@mail.gmail.com>
	<5228C3DF.9050008@oracle.com>
Message-ID: <CAJU-cA+pun+6ajyzpP9j8Zd=RfnU+5Gys-R5Qh8u4uuovCvUFw@mail.gmail.com>

Maybe because, if we pick the scenario presented in my example, we are
talking about an order of magnitude of 10^(-12)?


On Thu, Sep 5, 2013 at 6:48 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  I don't know why you keep ignoring the point that the magnitude of the
> negative time returned by awaitNanos is not required to be small.
>
> Alex
>
> On 05/09/2013 18:38, bruno bossola wrote:
>
>  > You presented a design that relies on the magnitude of the negative
> value of awaitNanos...
> >
>  No :) it's a very simple and legitimate example of usage of locking, that
> fails because the park(..) function is implemented using an absolute
> deadline based on a wall clock: that's what I call a design "not sound".
>
> Cheers,
>
>      Bruno
>
>
>
> On Thu, Sep 5, 2013 at 6:03 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  Quite the opposite. You presented a design that relies on the magnitude
>> of the negative value of awaitNanos, which is not defined. I can't find a
>> example of such algorithm in j.u.c, and I don't think your concurrent
>> design is sound.
>>
>> Alex
>>
>> On 05/09/2013 17:50, bruno bossola wrote:
>>
>>  I am sorry but I really cannot spend more time creating more samples
>> and I am quite sure you could do a better work at that! At the moment to me
>> that matter is clear enough, but feel free to ask, I will very happy to
>> help! In the meantime I prefer spend my time to work on a patch that I can
>> apply on my JVMs :)
>>
>>  Cheers,
>>
>>      Bruno
>>
>>
>>
>> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>>  This is far from reproducing the problem with arbitrary j.u.c locks and
>>> queues hanging.
>>>
>>> Condition.awaitNanos can return a negative value. If you are expecting
>>> the negative value to be small, then how small do you expect it to be?
>>>
>>>
>>> Alex
>>>
>>>
>>> On 05/09/2013 02:12, bruno bossola wrote:
>>>
>>>  Hi Oaleksandr,
>>>
>>>  Please apologize me if my english was not good enough to provide you an
>>> example that make sense: for that reason I decided to go back to a binary
>>> deliverable (code) that shows the problem, hope this helps!
>>>
>>>  This is my PreciousPool class, that handles Precious resources:
>>>
>>> import java.text.SimpleDateFormat;
>>> import java.util.ArrayList;
>>> import java.util.Date;
>>> import java.util.List;
>>> import java.util.concurrent.TimeUnit;
>>> import java.util.concurrent.locks.Condition;
>>> import java.util.concurrent.locks.Lock;
>>> import java.util.concurrent.locks.ReentrantLock;
>>>
>>> public class PreciousPool {
>>>
>>>     public static class Precious {
>>>         private final int id;
>>>
>>>         private Precious() {
>>>             this.id = 100+(int)(Math.random()*900.0);
>>>         }
>>>
>>>         public String toString() {
>>>             return "Precious n."+id;
>>>         }
>>>     }
>>>
>>>     private final Lock lock;
>>>     private final Condition ready;
>>>     private final long timeoutInMillis;
>>>
>>>     private final List<Precious> preciousLended;
>>>     private final List<Precious> preciousAvailable;
>>>
>>>     public PreciousPool(int size, long timeoutInSeconds) {
>>>         this.lock = new ReentrantLock();
>>>         this.ready = lock.newCondition();
>>>
>>>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>         this.preciousLended =  new ArrayList<Precious>();
>>>         this.preciousAvailable = new ArrayList<Precious>();
>>>
>>>         for (int i = 0; i < size; i++) {
>>>             preciousAvailable.add(new Precious());
>>>         }
>>>     }
>>>
>>>     public Precious obtain()  {
>>>         lock.lock();
>>>         try {
>>>             // if no precious are available we wait for the specified
>>> timeout (releasing the lock so that others can try)
>>>             if (preciousAvailable.size() == 0) {
>>>                 try {
>>>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>                 } catch (InterruptedException e) {
>>>                     Thread.currentThread().interrupt();
>>>                     throw new RuntimeException("Somebody interrupted
>>> me!", e);
>>>                 }
>>>             }
>>>
>>>             // if a precious is available we unload it and return to the
>>> caller, otherwise null
>>>             if (preciousAvailable.size() > 0) {
>>>                 Precious value = preciousAvailable.remove(0);
>>>                 preciousLended.add(value);
>>>                 return value;
>>>             } else {
>>>                 return null;
>>>             }
>>>         } finally {
>>>             lock.unlock();
>>>         }
>>>     }
>>>
>>>     public void release(Precious value) {
>>>         lock.lock();
>>>         try {
>>>             if (!preciousLended.remove(value))
>>>                 throw new RuntimeException("Element "+value+" was not
>>> lended!");
>>>
>>>             // if a precious is returned we put it back and signal to
>>> anybody waiting
>>>             preciousAvailable.add(value);
>>>             ready.signalAll();
>>>         } finally {
>>>             lock.unlock();
>>>         }
>>>     }
>>>
>>>     public static void main(String args[]) {
>>>         final int size = 3;
>>>         final PreciousPool pool = new PreciousPool(size, 5);
>>>
>>>         // let's exhaust the pool
>>>         for (int i=0; i<size; i++)
>>>             dump(pool.obtain());
>>>
>>>         // and as we are stubborn we continuosly ask for a new one
>>>         while(true) {
>>>             dump(pool.obtain());
>>>         }
>>>     }
>>>
>>>     private static void dump(Precious precious) {
>>>         if (precious == null)
>>>             log("I did not get my precious :(");
>>>         else
>>>             log("I did get my precious! "+precious);
>>>     }
>>>
>>>     private static void log(String message) {
>>>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS
>>> ").format(new Date());
>>>         System.out.println(now + message);
>>>     }
>>> }
>>>
>>> So, the main is a single thread (no need for multithreading here, let's
>>> keep it simple), that first exhaust the whole pool and then keep asking,
>>> without success, for a resource. Stubborn guy, I say, but it happens. If
>>> you run this program everything works as expected: you are greeted by a
>>> three successful Precious and then an endless list of failures, that it
>>> continuously grow. All good :)
>>>
>>> 02:34:40:0061 I did get my precious! Precious n.156
>>> 02:34:40:0062 I did get my precious! Precious n.991
>>> 02:34:40:0062 I did get my precious! Precious n.953
>>> 02:34:45:0064 I did not get my precious :(
>>> 02:34:50:0065 I did not get my precious :(
>>> 02:34:55:0066 I did not get my precious :(
>>> 02:35:00:0067 I did not get my precious :(
>>> 02:35:05:0068 I did not get my precious :(
>>> [...]
>>>
>>>  But guess what happens when, while the program is running, I change
>>> the date of my system back of one hour? Everything stops,  it's simple as
>>> that. No prints, nothing, zero, nada. Now, If it wasn't so late, I would
>>> probably wait one hour in order to have my program restored to his normal
>>> process, but as a customer I won't be terribly happy :)
>>>
>>>  I hope my point is now clear.
>>>  Cheers,
>>>
>>>      Bruno
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <
>>> oleksandr.otenko at oracle.com> wrote:
>>>
>>>>  n 04/09/2013 18:54, bruno bossola wrote:
>>>>
>>>>   Hi Oleksandr,
>>>>
>>>> Where in the design of those systems is a real-time timer? The one that
>>>>> delivers time events uncompromised even by GC latency?
>>>>>
>>>>
>>>>>
>>>>  I don't think so :) If somebody needs a real time implementation he
>>>> needs to go for a real time JVM, like Jean correctly pointed out.  The
>>>> concurrency primitives are depending on LockSupport.parkNanos(...) to park
>>>> a thread: if this for any reason is not working (like it is) then strange
>>>> things may happen.
>>>>
>>>>  Your assumption is that it is not working, if the elapsed time is
>>>> longer. This is the flawed assumption.
>>>>
>>>> Also, you need to read fine print on those "real time" JVMs. The catch
>>>> is in the definition of "real time".
>>>>
>>>>
>>>>
>>>>
>>>>  Imagine, for example, that you are using a ReentrantLock to control a
>>>> very precious resource used across the board (what about a database
>>>> connection pool?) and you are unlucky enough to have a system time change
>>>> (backwards) while you are locking: all the threads that want to use such
>>>> resource will be progressively locked: not forever, but for the amount of
>>>> time the clock went back. Probably most (all?) of your system freezes, and
>>>> the only option you have is to wait, or restart.
>>>>  Now place this in a large application server, that provide services
>>>> for hunreds (thousands) of users. How does it sound to you?
>>>>
>>>>  It sounds like you don't understand how the locks work.
>>>>
>>>>
>>>> Alex
>>>>
>>>>
>>>>
>>>>  BTW, at the moment we could have a watchdog (in Python :)) that
>>>> restarts it, but, I dunno why, I don't like it a lot...
>>>>
>>>>  Cheers,
>>>>
>>>>      Bruno
>>>>
>>>>
>>>>
>>>>>
>>>>
>>>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <
>>>> oleksandr.otenko at oracle.com> wrote:
>>>>
>>>>>  You are missing the point.
>>>>>
>>>>> Where in the design of those systems is a real-time timer? The one
>>>>> that delivers time events uncompromised even by GC latency?
>>>>>
>>>>> The whole concurrency lot does not depend on the timeout magnitude for
>>>>> correctness.
>>>>>
>>>>> Alex
>>>>>
>>>>>
>>>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>>>
>>>>>   Hi David
>>>>>
>>>>>
>>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>>>> updated periodically (every 12 hours I think).
>>>>>>
>>>>>
>>>>>>
>>>>> Good to know :) I will be eagerly clicking on it to discover the new
>>>>> priority! Thanks for that, I really appreciate it.
>>>>>
>>>>>
>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you
>>>>>> have an older version this does not impact you.
>>>>>>
>>>>>
>>>>>>
>>>>> You saw my list: nobody will use an older Kernel/glibc version in
>>>>> production.
>>>>>
>>>>>
>>>>> As for the rest, show me real code in such systems that rely on sleep
>>>>>> for correctness or performance/timeliness and I will show you broken code.
>>>>>
>>>>>
>>>>>>
>>>>>  You are still hitting about the sleep(), I understand and I agree
>>>>> about this. But here we are not talking about sleeps: we are talking about
>>>>> the whole concurrency lot. And yes, as I already said, we are talking about
>>>>> near time systems, like trading application, betting applications, air
>>>>> traffic control systems, car traffic control systems. Don't you think this
>>>>> bug might place Oracle JVM outside of these markets?
>>>>>
>>>>>
>>>>>
>>>>>> If this was as dire as you make out do you not think that this issue
>>>>>> would have been raised far more than it has? [....] prudent
>>>>>> developers/companies trial platform upgrades to check for these kinds of
>>>>>> issues before switching to them in production environments.
>>>>>>
>>>>>>  I am waiting now for the part where you say that we should throw
>>>>> away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
>>>>> action "in the middle", and I think that Oracle cannot oversee that. For
>>>>> example a lot of trading software system can be installed on premises,
>>>>> where you usually have no control over the environment: what I would do is
>>>>> to put a native daemon in my app so that if I see the system clock change I
>>>>> would kill myself, just in case. And this is a solution that I know for a
>>>>> fact (sorry, I cannot make a reference) it's used in production in a very
>>>>> important trading application.
>>>>>
>>>>> Regarding that specific bug, it was not accessible to the external
>>>>> until two days ago, so I guess nobody really knew a lot about it, but I
>>>>> will make sure it will :) so that we can get more traction.
>>>>>
>>>>>  Cheers,
>>>>>
>>>>>      Bruno
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au
>>>>> > wrote:
>>>>>
>>>>>>  Bruno,
>>>>>>
>>>>>>  bugs.sun.com is not a live reflection of the bug database but gets
>>>>>> updated periodically (every 12 hours I think).
>>>>>>
>>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If
>>>>>> you have an older version this does not impact you.
>>>>>>
>>>>>> As for the rest, show me real code in such systems that rely on sleep
>>>>>> for correctness or performance/timeliness and I will show you broken
>>>>>> code. We are not talking about real-time systems here. park(nanos)/wait(millis)
>>>>>> will only be affected by the backward time change if the real notification
>>>>>> they are waiting for does not happen. Timeouts with these APIs are
>>>>>> heuristics, they are defensive programming to cover the case "what if the
>>>>>> notification I'm waiting for does not come". The code that would be
>>>>>> affected by this issue is a very small % of the code that uses the API.
>>>>>>
>>>>>> If this was as dire as you make out do you not think that this issue
>>>>>> would have been raised far more than it has? This issue does need
>>>>>> addressing because the number of affected systems will grow as these newer
>>>>>> linux systems are adopted, but prudent developers/companies trial platform
>>>>>> upgrades to check for these kinds of issues before swicthing to them in
>>>>>> production environments.
>>>>>>
>>>>>> Regards,
>>>>>> David
>>>>>>
>>>>>>  -----Original Message-----
>>>>>> *From:* bruno bossola [mailto:bbossola at gmail.com]
>>>>>> *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>>> *To:* dholmes at ieee.org
>>>>>> *Cc:* concurrency-interest at cs.oswego.edu
>>>>>> *Subject:* Re: [concurrency-interest] Outstanding concurrency JVM
>>>>>> issue - feedback?
>>>>>>
>>>>>>    Hi David,
>>>>>>
>>>>>>  thanks for following up.
>>>>>>
>>>>>>
>>>>>>
>>>>>>> I have raised the priority on 6900441
>>>>>>>
>>>>>>
>>>>>>
>>>>>>  Thanks, but it looks still like a P4:
>>>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>> See also the attached snapshot, just in case it changes :)
>>>>>>
>>>>>>  [image: Inline image 2]
>>>>>>
>>>>>>  [...] which to my knowledge [...] has never been a private bug
>>>>>>>
>>>>>>
>>>>>> It was not accessible using bugs.sun.com, this was translated to
>>>>>> private. I also received the same info indirectly from the 7u lead:
>>>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of
>>>>>> bugs.sun.com)", I guess you can check with him.
>>>>>>
>>>>>>
>>>>>>  It doesn't affect "every JVM64 running on Linux64".  A fix has been
>>>>>>> introduced into a specific glibc version...
>>>>>>>
>>>>>>
>>>>>> ...and apparently did not make it. I was able to reproduce this even
>>>>>> with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>>>> 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on
>>>>>> JDK4 everything works (that's the reason why I call it a regression). (ah,
>>>>>> if you look at the bug, it lists also JDK5, so I think we are pretty much
>>>>>> covered here).
>>>>>> If you still have doubts tough, please have also a look on
>>>>>> stackoverflow to see how it was reproduced consistently on probably every
>>>>>> 64bitJVM over 64bitLinux in the world.
>>>>>>
>>>>>>
>>>>>>  The effects of this is not that "all the threads parked will hang,
>>>>>>> with unpredictable/corrupted/useless"! The effects are very simple an quite
>>>>>>> predictable... [deletia]s.
>>>>>>
>>>>>>
>>>>>>
>>>>>> We have very different views, and I find quite difficult to accept
>>>>>> yours. You are confusing my sample program which contains a single thread
>>>>>> in a for loop with any other complex multi-threading concurrent system
>>>>>> written in Java. For example, if you ever worked in a bank you surely know
>>>>>> what I mean. You are comparing some random sleep() put into a program by
>>>>>> some newbie, with the complex ecosystem of a concurrent platform written to
>>>>>> manage trading information on very fast market. In that condition, I am
>>>>>> sorry, statements such "...delayed timeout does not affect operation in a
>>>>>> correctly functioning system..." and "...small time changes [...] are not a
>>>>>> problem" are really not applicable. Let your system place an order three
>>>>>> seconds late and your are out of the door so quickly you cannot even
>>>>>> realize it.
>>>>>>
>>>>>>  But let's not limit ourselves to banks: how do you think your
>>>>>> previous statements stands in these scenarios?
>>>>>> - air control systems<http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>> about a few seconds delay in control when fying planes?)
>>>>>> - city traffic control systems<http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>> if just for a couple of seconds all traffic lights become green?)
>>>>>>
>>>>>>  Not good enough.
>>>>>>
>>>>>>
>>>>>>  ...small time changes as typically done via NTP
>>>>>>
>>>>>>
>>>>>>
>>>>>> NTP is only one of the possible sources of this problem. The root of
>>>>>> it is that the JVM is counting nanoseconds delays using absolute values
>>>>>> based on a wallclock: I do not think it's that smart.
>>>>>>
>>>>>>
>>>>>>   So there is an issue that needs to be addressed but the situation
>>>>>>> is nowhere near as dire as you make out
>>>>>>>
>>>>>>
>>>>>>
>>>>>>  Let's try to put this in perspective, shall we? In case the clock
>>>>>> run backwards LockSupport.park() will be waiting for the nanoseconds
>>>>>> requested plus the amount of seconds/minute/hours/days requested to
>>>>>> compensate. Now, this primitive is used by almost *every* concurrency
>>>>>> construct available on the platform, such as AbstractQueuedSynchronizer
>>>>>> (and subclasses), ReentrantLock (and subclasses), CyclicBarrier,
>>>>>> BlockingQueue (and subclasses), Executors, FutureTask, .... (too long to
>>>>>> list them all, but I think we have the picture) and also low levels
>>>>>> synchronization primitives of the language itself, so Object::wait(:long)
>>>>>> and the related sychronized blocks.
>>>>>>
>>>>>>  I think it's pretty dire.
>>>>>>
>>>>>>
>>>>>>  Cheers,
>>>>>>
>>>>>>      Bruno
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <
>>>>>> davidcholmes at aapt.net.au> wrote:
>>>>>>
>>>>>>>  Hi Bruno,
>>>>>>>
>>>>>>> I have raised the priority on 6900441 (which to my knowledge - and I
>>>>>>> created it! - has never been a private bug).
>>>>>>>
>>>>>>> A few notes on the "very frightening" aspect of this:
>>>>>>>
>>>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has
>>>>>>> been introduced into a specific glibc version for the futex-wait code such
>>>>>>> that it now responds to changes in the system time for absolute waits,
>>>>>>> where for all the years previous it did not. The fix seems to have been
>>>>>>> applied in late 2011 or early 2012 but I don't know the exact glibc
>>>>>>> version. There is also a 32-bit version of the fix that was proposed on Nov
>>>>>>> 27, 2012, so it will eventually make its way into 32-bit linux too.
>>>>>>>
>>>>>>> 2. The effects of this is not that "all the threads parked will
>>>>>>> hang, with unpredictable/corrupted/useless"! The effects are very
>>>>>>> simple an quite predictable. If the system time goes forward then
>>>>>>> timed-waits (Object.wait, LockSupport.park) (which should be relative
>>>>>>> times) will return early as the absolute-time that the relative time was
>>>>>>> converted to will be seen to have been reached (Thread.sleep contains a
>>>>>>> guard against early returns). This is not actually a problem as you can not
>>>>>>> distinguish this case from a "spurious wakeup" which code is supposed to
>>>>>>> account for. If the time is changed backwards then these timed-waits &
>>>>>>> sleeps will not timeout when expected as the the for that is now further in
>>>>>>> the future, by the amount of the backward time change. Hence small time
>>>>>>> changes as typically done via NTP are NOT a problem. Timed-waits use
>>>>>>> timeouts as a heuristics for recovering when the expected real event
>>>>>>> notification does not occur - so a delayed timeout does not affect
>>>>>>> operation in a correctly functioning system. Early timeouts are
>>>>>>> indistinguishable from spurious wakeups, which code has to account for, so
>>>>>>> again not a problem for regular code. The only time a significant "hang"
>>>>>>> will occur is with Thread.sleep and a large backward time shift - but there
>>>>>>> is little real code that uses Thread.sleep in any critical way.
>>>>>>>
>>>>>>> So there is an issue that needs to be addressed but the situation is
>>>>>>> nowhere near as dire as you make out.
>>>>>>>
>>>>>>> David Holmes
>>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *bruno
>>>>>>> bossola
>>>>>>> *Sent:* Wednesday, 4 September 2013 1:56 AM
>>>>>>> *To:* concurrency-interest at cs.oswego.edu
>>>>>>> *Subject:* [concurrency-interest] Outstanding concurrency JVM issue
>>>>>>> - feedback?
>>>>>>>
>>>>>>>   Hi all,
>>>>>>>
>>>>>>> I am writing here following a suggestion by Ben Evans. I wanted to
>>>>>>> check with you about an issue that my teams found on the JVM and that's
>>>>>>> very frightening. I already started the discussion with the engineers of
>>>>>>> the hotspot VM team but it looks like we need more awareness to solve this
>>>>>>> one and I'd really appreciate some help and some push :)
>>>>>>>  It looks to me that this issue is affecting every JVM64 running on
>>>>>>> Linux64, so imho it's quite important to be looked at.
>>>>>>>
>>>>>>> *Executive summary
>>>>>>> *The implementation of the concurrency primitive
>>>>>>> LockSupport.parkNanos(), the function that controls most
>>>>>>> concurrency primitive on the JVM, is flawed, and any NTP sync, or system
>>>>>>> time change, can potentially break it with unexpected results across the
>>>>>>> board.
>>>>>>>
>>>>>>> *What we need to do?
>>>>>>> *This is an old issue, and the bug<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>was declared private. I somehow managed to have the bug reopened to the
>>>>>>> public, but it's still a  P4, that means that probably won't be fixed. I
>>>>>>> think we need to push for a resolution ASAP, be sure that's in for JDK9,
>>>>>>> make all the possible effort to make this fix for JDK8 or, at least, to
>>>>>>> include it in a later patch release. In an ideal world it would be nice to
>>>>>>> have a patch for JDK7. As far as I understand the hotspot engineering team
>>>>>>> works based on priorities: being this qualified as P4 means it won't be
>>>>>>> probably worked on (if you follow the breadcrumbs of bugs and fixes you can
>>>>>>> go back to 2002!) They acknowledge the problem, it has been flagged to
>>>>>>> management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>>>
>>>>>>>
>>>>>>> *Why all this urgency?
>>>>>>> *If a system time change happens then all the threads parked will
>>>>>>> hang, with unpredictable/corrupted/useless results to the end user. Same
>>>>>>> applies to Future, Queue, Executor, and (I guess) any other construct that
>>>>>>> it's somehow related to concurrency. This is a big issue for us and for any
>>>>>>> near time application: please think about trading and betting, where the
>>>>>>> JVM is largely used, and  do not restrain yourself to the Java language:
>>>>>>> add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>>>
>>>>>>> *Tech details**
>>>>>>> *To be more clear about the issue, the extent of it and the
>>>>>>> concurrency library, let me introduce this very simple program:
>>>>>>>
>>>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>>>
>>>>>>> public class Main {
>>>>>>>
>>>>>>>     public static void main(String[] args) {
>>>>>>>
>>>>>>>         for (int i=100; i>0; i--) {
>>>>>>>             System.out.println(i);
>>>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>>         }
>>>>>>>
>>>>>>>         System.out.println("Done!");
>>>>>>>     }
>>>>>>> }
>>>>>>>
>>>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one
>>>>>>> hour and wait until the counter stops... magic!  I tested this on JDK6,
>>>>>>> JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just
>>>>>>> a matter of (old?) sleep() and wait() primitives, this issue it affects the
>>>>>>> whole concurrency library.
>>>>>>>
>>>>>>>  To prove that this is fixable, I reimplemented the program above
>>>>>>> above substituting  LockSupport.parkNanos()  with  a JNI call to
>>>>>>> clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>>>
>>>>>>>  This is due to the fact  that the CPP code is calling the
>>>>>>> pthread_cond_timedwait() using its default clock (CLOCK_REALTIME)
>>>>>>> which, unfortunately is affected by settime()/settimeofday() calls (on
>>>>>>> Linux): for that reason it cannot be used to measure nanoseconds delays,
>>>>>>> which is what the specification<http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>requires.
>>>>>>> CLOCK_REALTIME is not guaranteed to monotonically count as this is
>>>>>>> the actual "system time": each time my system syncs time using a NTP server
>>>>>>> on the net, the time might jump forward or backward. The correct call
>>>>>>> (again on Linux)  would require to use CLOCK_MONOTONIC as clock id,
>>>>>>> which are defined by POSIX specs since 2002. (or better
>>>>>>> CLOCK_MONOTONIC_RAW)
>>>>>>>
>>>>>>> The POSIX spec<http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>is infact clear, as it states "...setting the value of the CLOCK_REALTIME
>>>>>>> clock via clock_settime() shall have no effect on threads that are blocked
>>>>>>> waiting for a *relative* time service based upon this clock...": it
>>>>>>> definitely states "relative".  Having a look at the hotspot code<http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>>> it appears that the park() is using compute_abstime() (which uses
>>>>>>> timeofday) and then waits on an absolute period: for that reason it's
>>>>>>> influenced by the system clock change. *Very wrong*.
>>>>>>>
>>>>>>>  I will be happy to know what you think, and if you can help me to
>>>>>>> escalate this issue I think that the all Java community will benefit from
>>>>>>> it.
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>>      Bruno
>>>>>>>
>>>>>>>
>>>>>>   No virus found in this message.
>>>>>> Checked by AVG - www.avg.com
>>>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date:
>>>>>> 09/03/13
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>   _______________________________________________
>>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/55e35d99/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 14:42:09 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 19:42:09 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
	<5228C351.4070009@oracle.com>
	<966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>
Message-ID: <5228D081.9040705@oracle.com>

On 05/09/2013 19:15, Roland Kuhn wrote:
>
> 5 sep 2013 kl. 19:45 skrev Oleksandr Otenko:
>
>> Exactly my point.
>>
>> Now someone needs to take care of negative time returned, when the 
>> clock goes back, even if the wait was shorter than timeout.
>
> Why would that lead to a negative return value?

Depending on how you work out the elapsed time, of course.

>> Or, if we report the actual time waited, then deal with the 
>> inconsistency between apparent System.nanoTime() and the wait.
>
> There are two very different time sources in the JVM, and the one 
> which has ?nano? in its name is supposed to be monotonic and 
> independent of the system?s wall time clock. I share Bruno?s view that 
> a method called awaitNanos() should measure time using System.nanoTime 
> and not with System.currentTimeMillis (conceptually). It is 
> unfortunate that the API docs of awaitNanos() do not specify which of 
> these choices was made.

Conceptually awaitNanos() returns timeout-elapsedTime. How will 
System.nanoTime() work out the elapsed time in nanoseconds after 
suspend-modify wall clock-resume? Who tells it how many nanoseconds were 
missed?

Alex


>
> Regards,
>
> Roland
>
>>
>> Alex
>>
>> On 05/09/2013 18:31, ?iktor ?lang wrote:
>>> For Condition.awaitNanos it states:
>>>
>>> Returns:
>>>     an estimate of the |nanosTimeout| value minus the time spent
>>>     waiting upon return from this method. A positive value may be
>>>     used as the argument to a subsequent call to this method to
>>>     finish waiting out the desired time. *A value less than or equal
>>>     to zero indicates that no time remains.*
>>>
>>>
>>>
>>>
>>>
>>> On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko 
>>> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> 
>>> wrote:
>>>
>>>     Oh, and now someone else is going to complain that awaitNanos
>>>     returns a negative number, even though it waited for only 1 ms
>>>     out of 100.
>>>
>>>     Alex
>>>
>>>     On 05/09/2013 17:50, bruno bossola wrote:
>>>>     I am sorry but I really cannot spend more time creating more
>>>>     samples and I am quite sure you could do a better work at that!
>>>>     At the moment to me that matter is clear enough, but feel free
>>>>     to ask, I will very happy to help! In the meantime I prefer
>>>>     spend my time to work on a patch that I can apply on my JVMs :)
>>>>
>>>>     Cheers,
>>>>
>>>>         Bruno
>>>>
>>>>
>>>>
>>>>     On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko
>>>>     <oleksandr.otenko at oracle.com
>>>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>
>>>>         This is far from reproducing the problem with arbitrary
>>>>         j.u.c locks and queues hanging.
>>>>
>>>>         Condition.awaitNanos can return a negative value. If you
>>>>         are expecting the negative value to be small, then how
>>>>         small do you expect it to be?
>>>>
>>>>
>>>>         Alex
>>>>
>>>>
>>>>         On 05/09/2013 02:12, bruno bossola wrote:
>>>>>         Hi Oaleksandr,
>>>>>
>>>>>         Please apologize me if my english was not good enough to
>>>>>         provide you an example that make sense: for that reason I
>>>>>         decided to go back to a binary deliverable (code) that
>>>>>         shows the problem, hope this helps!
>>>>>
>>>>>         This is my PreciousPool class, that handles Precious
>>>>>         resources:
>>>>>
>>>>>         import java.text.SimpleDateFormat;
>>>>>         import java.util.ArrayList;
>>>>>         import java.util.Date;
>>>>>         import java.util.List;
>>>>>         import java.util.concurrent.TimeUnit;
>>>>>         import java.util.concurrent.locks.Condition;
>>>>>         import java.util.concurrent.locks.Lock;
>>>>>         import java.util.concurrent.locks.ReentrantLock;
>>>>>
>>>>>         public class PreciousPool {
>>>>>
>>>>>             public static class Precious {
>>>>>                 private final int id;
>>>>>
>>>>>                 private Precious() {
>>>>>         this.id <http://this.id/> = 100+(int)(Math.random()*900.0);
>>>>>                 }
>>>>>
>>>>>                 public String toString() {
>>>>>                     return "Precious n."+id;
>>>>>                 }
>>>>>             }
>>>>>
>>>>>             private final Lock lock;
>>>>>             private final Condition ready;
>>>>>             private final long timeoutInMillis;
>>>>>
>>>>>             private final List<Precious> preciousLended;
>>>>>             private final List<Precious> preciousAvailable;
>>>>>
>>>>>             public PreciousPool(int size, long timeoutInSeconds) {
>>>>>                 this.lock = new ReentrantLock();
>>>>>                 this.ready = lock.newCondition();
>>>>>
>>>>>                 this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>>>                 this.preciousLended = new ArrayList<Precious>();
>>>>>                 this.preciousAvailable = new ArrayList<Precious>();
>>>>>
>>>>>                 for (int i = 0; i < size; i++) {
>>>>>         preciousAvailable.add(new Precious());
>>>>>                 }
>>>>>             }
>>>>>
>>>>>             public Precious obtain() {
>>>>>                 lock.lock();
>>>>>                 try {
>>>>>                     // if no precious are available we wait for
>>>>>         the specified timeout (releasing the lock so that others
>>>>>         can try)
>>>>>                     if (preciousAvailable.size() == 0) {
>>>>>                         try {
>>>>>         ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>>>                         } catch (InterruptedException e) {
>>>>>         Thread.currentThread().interrupt();
>>>>>                             throw new RuntimeException("Somebody
>>>>>         interrupted me!", e);
>>>>>                         }
>>>>>                     }
>>>>>
>>>>>                     // if a precious is available we unload it and
>>>>>         return to the caller, otherwise null
>>>>>                     if (preciousAvailable.size() > 0) {
>>>>>                         Precious value = preciousAvailable.remove(0);
>>>>>         preciousLended.add(value);
>>>>>                         return value;
>>>>>                     } else {
>>>>>                         return null;
>>>>>                     }
>>>>>                 } finally {
>>>>>                     lock.unlock();
>>>>>                 }
>>>>>             }
>>>>>
>>>>>             public void release(Precious value) {
>>>>>                 lock.lock();
>>>>>                 try {
>>>>>                     if (!preciousLended.remove(value))
>>>>>                         throw new RuntimeException("Element
>>>>>         "+value+" was not lended!");
>>>>>
>>>>>                     // if a precious is returned we put it back
>>>>>         and signal to anybody waiting
>>>>>         preciousAvailable.add(value);
>>>>>                     ready.signalAll();
>>>>>                 } finally {
>>>>>                     lock.unlock();
>>>>>                 }
>>>>>             }
>>>>>
>>>>>             public static void main(String args[]) {
>>>>>                 final int size = 3;
>>>>>                 final PreciousPool pool = new PreciousPool(size, 5);
>>>>>
>>>>>                 // let's exhaust the pool
>>>>>                 for (int i=0; i<size; i++)
>>>>>         dump(pool.obtain());
>>>>>
>>>>>                 // and as we are stubborn we continuosly ask for a
>>>>>         new one
>>>>>                 while(true) {
>>>>>         dump(pool.obtain());
>>>>>                 }
>>>>>             }
>>>>>
>>>>>             private static void dump(Precious precious) {
>>>>>                 if (precious == null)
>>>>>                     log("I did not get my precious :(");
>>>>>                 else
>>>>>                     log("I did get my precious! "+precious);
>>>>>             }
>>>>>
>>>>>             private static void log(String message) {
>>>>>                 final String now = new
>>>>>         SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>>>                 System.out.println(now + message);
>>>>>             }
>>>>>         }
>>>>>
>>>>>         So, the main is a single thread (no need for
>>>>>         multithreading here, let's keep it simple), that first
>>>>>         exhaust the whole pool and then keep asking, without
>>>>>         success, for a resource. Stubborn guy, I say, but it
>>>>>         happens. If you run this program everything works as
>>>>>         expected: you are greeted by a three successful Precious
>>>>>         and then an endless list of failures, that it continuously
>>>>>         grow. All good :)
>>>>>
>>>>>         02:34:40:0061 I did get my precious! Precious n.156
>>>>>         02:34:40:0062 I did get my precious! Precious n.991
>>>>>         02:34:40:0062 I did get my precious! Precious n.953
>>>>>         02:34:45:0064 I did not get my precious :(
>>>>>         02:34:50:0065 I did not get my precious :(
>>>>>         02:34:55:0066 I did not get my precious :(
>>>>>         02:35:00:0067 I did not get my precious :(
>>>>>         02:35:05:0068 I did not get my precious :(
>>>>>         [...]
>>>>>
>>>>>         But guess what happens when, while the program is running,
>>>>>         I change the date of my system back of one hour?
>>>>>         Everything stops,  it's simple as that. No prints,
>>>>>         nothing, zero, nada. Now, If it wasn't so late, I would
>>>>>         probably wait one hour in order to have my program
>>>>>         restored to his normal process, but as a customer I won't
>>>>>         be terribly happy :)
>>>>>
>>>>>         I hope my point is now clear.
>>>>>         Cheers,
>>>>>
>>>>>             Bruno
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>         On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>>>>         <oleksandr.otenko at oracle.com
>>>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>
>>>>>             n 04/09/2013 18:54, bruno bossola wrote:
>>>>>>             Hi Oleksandr,
>>>>>>
>>>>>>                 Where in the design of those systems is a
>>>>>>                 real-time timer? The one that delivers time
>>>>>>                 events uncompromised even by GC latency?
>>>>>>
>>>>>>             I don't think so :) If somebody needs a real time
>>>>>>             implementation he needs to go for a real time JVM,
>>>>>>             like Jean correctly pointed out.  The concurrency
>>>>>>             primitives are depending on
>>>>>>             LockSupport.parkNanos(...) to park a thread: if this
>>>>>>             for any reason is not working (like it is) then
>>>>>>             strange things may happen.
>>>>>             Your assumption is that it is not working, if the
>>>>>             elapsed time is longer. This is the flawed assumption.
>>>>>
>>>>>             Also, you need to read fine print on those "real time"
>>>>>             JVMs. The catch is in the definition of "real time".
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>>             Imagine, for example, that you are using a
>>>>>>             ReentrantLock to control a very precious resource
>>>>>>             used across the board (what about a database
>>>>>>             connection pool?) and you are unlucky enough to have
>>>>>>             a system time change (backwards) while you are
>>>>>>             locking: all the threads that want to use such
>>>>>>             resource will be progressively locked: not forever,
>>>>>>             but for the amount of time the clock went back.
>>>>>>             Probably most (all?) of your system freezes, and the
>>>>>>             only option you have is to wait, or restart.
>>>>>>             Now place this in a large application server, that
>>>>>>             provide services for hunreds (thousands) of users.
>>>>>>             How does it sound to you?
>>>>>             It sounds like you don't understand how the locks work.
>>>>>
>>>>>
>>>>>             Alex
>>>>>
>>>>>
>>>>>>
>>>>>>             BTW, at the moment we could have a watchdog (in
>>>>>>             Python :)) that restarts it, but, I dunno why, I
>>>>>>             don't like it a lot...
>>>>>>
>>>>>>             Cheers,
>>>>>>
>>>>>>                 Bruno
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>             On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>>>>             <oleksandr.otenko at oracle.com
>>>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>
>>>>>>                 You are missing the point.
>>>>>>
>>>>>>                 Where in the design of those systems is a
>>>>>>                 real-time timer? The one that delivers time
>>>>>>                 events uncompromised even by GC latency?
>>>>>>
>>>>>>                 The whole concurrency lot does not depend on the
>>>>>>                 timeout magnitude for correctness.
>>>>>>
>>>>>>                 Alex
>>>>>>
>>>>>>
>>>>>>                 On 04/09/2013 12:05, bruno bossola wrote:
>>>>>>>                 Hi David
>>>>>>>
>>>>>>>
>>>>>>>                     bugs.sun.com <http://bugs.sun.com/> is not a
>>>>>>>                     live reflection of the bug database but gets
>>>>>>>                     updated periodically (every 12 hours I think).
>>>>>>>
>>>>>>>
>>>>>>>                 Good to know :) I will be eagerly clicking on it
>>>>>>>                 to discover the new priority! Thanks for that, I
>>>>>>>                 really appreciate it.
>>>>>>>
>>>>>>>
>>>>>>>                     The issue arises on certain 64-bit linux
>>>>>>>                     kernel/glibc versions. If you have an older
>>>>>>>                     version this does not impact you.
>>>>>>>
>>>>>>>                 You saw my list: nobody will use an older
>>>>>>>                 Kernel/glibc version in production.
>>>>>>>
>>>>>>>
>>>>>>>                     As for the rest, show me real code in such
>>>>>>>                     systems that rely on sleep for correctness
>>>>>>>                     or performance/timeliness and I will show
>>>>>>>                     you broken code.
>>>>>>>
>>>>>>>                 You are still hitting about the sleep(), I
>>>>>>>                 understand and I agree about this. But here we
>>>>>>>                 are not talking about sleeps: we are talking
>>>>>>>                 about the whole concurrency lot. And yes, as I
>>>>>>>                 already said, we are talking about near time
>>>>>>>                 systems, like trading application, betting
>>>>>>>                 applications, air traffic control systems, car
>>>>>>>                 traffic control systems. Don't you think this
>>>>>>>                 bug might place Oracle JVM outside of these markets?
>>>>>>>
>>>>>>>
>>>>>>>                     If this was as dire as you make out do you
>>>>>>>                     not think that this issue would have been
>>>>>>>                     raised far more than it has? [....] prudent
>>>>>>>                     developers/companies trial platform upgrades
>>>>>>>                     to check for these kinds of issues before
>>>>>>>                     switching to them in production environments.
>>>>>>>
>>>>>>>                 I am waiting now for the part where you say that
>>>>>>>                 we should throw away Linux and use Oracle
>>>>>>>                 Solaris :)  In all seriousness, there's a lot of
>>>>>>>                 action "in the middle", and I think that Oracle
>>>>>>>                 cannot oversee that. For example a lot of
>>>>>>>                 trading software system can be installed on
>>>>>>>                 premises, where you usually have no control over
>>>>>>>                 the environment: what I would do is to put a
>>>>>>>                 native daemon in my app so that if I see the
>>>>>>>                 system clock change I would kill myself, just in
>>>>>>>                 case. And this is a solution that I know for a
>>>>>>>                 fact (sorry, I cannot make a reference) it's
>>>>>>>                 used in production in a very important trading
>>>>>>>                 application.
>>>>>>>
>>>>>>>                 Regarding that specific bug, it was not
>>>>>>>                 accessible to the external until two days ago,
>>>>>>>                 so I guess nobody really knew a lot about it,
>>>>>>>                 but I will make sure it will :) so that we can
>>>>>>>                 get more traction.
>>>>>>>
>>>>>>>                 Cheers,
>>>>>>>
>>>>>>>                     Bruno
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>                 On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>>>>                 <davidcholmes at aapt.net.au
>>>>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>
>>>>>>>                     Bruno,
>>>>>>>                     bugs.sun.com <http://bugs.sun.com/> is not a
>>>>>>>                     live reflection of the bug database but gets
>>>>>>>                     updated periodically (every 12 hours I think).
>>>>>>>                     The issue arises on certain 64-bit linux
>>>>>>>                     kernel/glibc versions. If you have an older
>>>>>>>                     version this does not impact you.
>>>>>>>                     As for the rest, show me real code in such
>>>>>>>                     systems that rely on sleep for correctness
>>>>>>>                     or performance/timelinessand I will show you
>>>>>>>                     broken code. We are not talking about
>>>>>>>                     real-time systemshere.
>>>>>>>                     park(nanos)/wait(millis) will only be
>>>>>>>                     affected by the backward time change if the
>>>>>>>                     real notification they are waiting for does
>>>>>>>                     not happen. Timeouts with these APIs are
>>>>>>>                     heuristics, they are defensive programming
>>>>>>>                     to cover the case "what if the notification
>>>>>>>                     I'm waiting for does not come". The code
>>>>>>>                     that would be affected by this issue is a
>>>>>>>                     very small % of the code that uses the API.
>>>>>>>                     If this was as dire as you make out do you
>>>>>>>                     not think that this issue would have been
>>>>>>>                     raised far more than it has? This issue does
>>>>>>>                     need addressing because the number of
>>>>>>>                     affected systems will grow as these newer
>>>>>>>                     linux systems are adopted, but prudent
>>>>>>>                     developers/companies trial platform upgrades
>>>>>>>                     to check for these kinds of issues before
>>>>>>>                     swicthing to them in production environments.
>>>>>>>                     Regards,
>>>>>>>                     David
>>>>>>>
>>>>>>>                         -----Original Message-----
>>>>>>>                         *From:* bruno bossola
>>>>>>>                         [mailto:bbossola at gmail.com
>>>>>>>                         <mailto:bbossola at gmail.com>]
>>>>>>>                         *Sent:* Wednesday, 4 September 2013 11:14 AM
>>>>>>>                         *To:* dholmes at ieee.org
>>>>>>>                         <mailto:dholmes at ieee.org>
>>>>>>>                         *Cc:* concurrency-interest at cs.oswego.edu
>>>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>>>                         Outstanding concurrency JVM issue -
>>>>>>>                         feedback?
>>>>>>>
>>>>>>>                         Hi David,
>>>>>>>
>>>>>>>                         thanks for following up.
>>>>>>>
>>>>>>>                             I have raised the priority on 6900441
>>>>>>>
>>>>>>>                         Thanks, but it looks still like a P4:
>>>>>>>                         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>>>                         See also the attached snapshot, just in
>>>>>>>                         case it changes :)
>>>>>>>
>>>>>>>                         Inline image 2
>>>>>>>
>>>>>>>                             [...] which to my knowledge [...]
>>>>>>>                             has never been a private bug
>>>>>>>
>>>>>>>                         It was not accessible using bugs.sun.com
>>>>>>>                         <http://bugs.sun.com/>, this was
>>>>>>>                         translated to private. I also received
>>>>>>>                         the same info indirectly from the 7u lead:
>>>>>>>                         "I'm not sure why 6900441 isn't public.
>>>>>>>                         (I'll follow up with owner of
>>>>>>>                         bugs.sun.com <http://bugs.sun.com/>)", I
>>>>>>>                         guess you can check with him.
>>>>>>>
>>>>>>>
>>>>>>>                             It doesn't affect "every JVM64
>>>>>>>                             running on Linux64".  A fix has been
>>>>>>>                             introduced into a specific glibc
>>>>>>>                             version...
>>>>>>>
>>>>>>>                         ...and apparently did not make it. I was
>>>>>>>                         able to reproduce this even with the IBM
>>>>>>>                         VM, so to speak. I tried JDK6, JDK7,
>>>>>>>                         JDK8 on Ubuntu 10, 11, 12, 13 + some
>>>>>>>                         random Debian. I did not have a JDK5, so
>>>>>>>                         I cannot say, but on JDK4 everything
>>>>>>>                         works (that's the reason why I call it a
>>>>>>>                         regression). (ah, if you look at the
>>>>>>>                         bug, it lists also JDK5, so I think we
>>>>>>>                         are pretty much covered here).
>>>>>>>                         If you still have doubts tough, please
>>>>>>>                         have also a look on stackoverflow to see
>>>>>>>                         how it was reproduced consistently on
>>>>>>>                         probably every 64bitJVM over 64bitLinux
>>>>>>>                         in the world.
>>>>>>>
>>>>>>>
>>>>>>>                             The effects of this is not that "all
>>>>>>>                             the threads parked will hang, with
>>>>>>>                             unpredictable/corrupted/useless"!
>>>>>>>                             The effects are very simple an quite
>>>>>>>                             predictable... [deletia]s.
>>>>>>>
>>>>>>>                         We have very different views, and I find
>>>>>>>                         quite difficult to accept yours. You are
>>>>>>>                         confusing my sample program which
>>>>>>>                         contains a single thread in a for loop
>>>>>>>                         with any other complex multi-threading
>>>>>>>                         concurrent system written in Java. For
>>>>>>>                         example, if you ever worked in a bank
>>>>>>>                         you surely know what I mean. You are
>>>>>>>                         comparing some random sleep() put into a
>>>>>>>                         program by some newbie, with the complex
>>>>>>>                         ecosystem of a concurrent platform
>>>>>>>                         written to manage trading information on
>>>>>>>                         very fast market. In that condition, I
>>>>>>>                         am sorry, statements such "...delayed
>>>>>>>                         timeout does not affect operation in a
>>>>>>>                         correctly functioning system..." and
>>>>>>>                         "...small time changes [...] are not a
>>>>>>>                         problem" are really not applicable. Let
>>>>>>>                         your system place an order three seconds
>>>>>>>                         late and your are out of the door so
>>>>>>>                         quickly you cannot even realize it.
>>>>>>>
>>>>>>>                         But let's not limit ourselves to banks:
>>>>>>>                         how do you think your previous
>>>>>>>                         statements stands in these scenarios?
>>>>>>>                         - air control systems
>>>>>>>                         <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>>>                         about a few seconds delay in control
>>>>>>>                         when fying planes?)
>>>>>>>                         - city traffic control systems
>>>>>>>                         <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>>>                         if just for a couple of seconds all
>>>>>>>                         traffic lights become green?)
>>>>>>>
>>>>>>>                         Not good enough.
>>>>>>>
>>>>>>>
>>>>>>>                             ...small time changes as typically
>>>>>>>                             done via NTP
>>>>>>>
>>>>>>>                         NTP is only one of the possible sources
>>>>>>>                         of this problem. The root of it is that
>>>>>>>                         the JVM is counting nanoseconds delays
>>>>>>>                         using absolute values based on a
>>>>>>>                         wallclock: I do not think it's that smart.
>>>>>>>
>>>>>>>
>>>>>>>                             So there is an issue that needs to
>>>>>>>                             be addressed but the situation is
>>>>>>>                             nowhere near as dire as you make out
>>>>>>>
>>>>>>>                         Let's try to put this in perspective,
>>>>>>>                         shall we? In case the clock run
>>>>>>>                         backwards LockSupport.park() will be
>>>>>>>                         waiting for the nanoseconds requested
>>>>>>>                         plus the amount of
>>>>>>>                         seconds/minute/hours/days requested to
>>>>>>>                         compensate. Now, this primitive is used
>>>>>>>                         by almost *every* concurrency construct
>>>>>>>                         available on the platform, such as
>>>>>>>                         AbstractQueuedSynchronizer (and
>>>>>>>                         subclasses), ReentrantLock (and
>>>>>>>                         subclasses), CyclicBarrier,
>>>>>>>                         BlockingQueue (and subclasses),
>>>>>>>                         Executors, FutureTask, .... (too long to
>>>>>>>                         list them all, but I think we have the
>>>>>>>                         picture) and also low levels
>>>>>>>                         synchronization primitives of the
>>>>>>>                         language itself, so Object::wait(:long)
>>>>>>>                         and the related sychronized blocks.
>>>>>>>
>>>>>>>                         I think it's pretty dire.
>>>>>>>
>>>>>>>
>>>>>>>                         Cheers,
>>>>>>>
>>>>>>>                             Bruno
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>                         On Wed, Sep 4, 2013 at 12:14 AM, David
>>>>>>>                         Holmes <davidcholmes at aapt.net.au
>>>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>
>>>>>>>                             Hi Bruno,
>>>>>>>                             I have raised the priority on
>>>>>>>                             6900441 (which to my knowledge - and
>>>>>>>                             I created it! - has never been a
>>>>>>>                             private bug).
>>>>>>>                             A few notes on the "very
>>>>>>>                             frightening" aspect of this:
>>>>>>>                             1. It doesn't affect "every JVM64
>>>>>>>                             running on Linux64". A fix has been
>>>>>>>                             introduced into a specific glibc
>>>>>>>                             version for the futex-wait code such
>>>>>>>                             that it now responds to changes in
>>>>>>>                             the system time for absolute waits,
>>>>>>>                             where for all the years previous it
>>>>>>>                             did not. The fix seems to have been
>>>>>>>                             applied in late 2011 or early 2012
>>>>>>>                             but I don't know the exact glibc
>>>>>>>                             version. There is also a 32-bit
>>>>>>>                             version of the fix that was proposed
>>>>>>>                             on Nov 27, 2012, so it will
>>>>>>>                             eventually make its way into 32-bit
>>>>>>>                             linux too.
>>>>>>>                             2. The effects of this is not that
>>>>>>>                             "all the threads parked will hang,
>>>>>>>                             with
>>>>>>>                             unpredictable/corrupted/useless"!
>>>>>>>                             The effects are very simple an quite
>>>>>>>                             predictable. If the system time goes
>>>>>>>                             forward then timed-waits
>>>>>>>                             (Object.wait,
>>>>>>>                             LockSupport.park) (which should be
>>>>>>>                             relative times) will return early as
>>>>>>>                             the absolute-time that the relative
>>>>>>>                             time was converted to will be seen
>>>>>>>                             to have been reached (Thread.sleep
>>>>>>>                             contains a guard against early
>>>>>>>                             returns). This is not actually a
>>>>>>>                             problem as you can not distinguish
>>>>>>>                             this case from a "spurious wakeup"
>>>>>>>                             which code is supposed to account
>>>>>>>                             for. If the time is changed
>>>>>>>                             backwards then these timed-waits &
>>>>>>>                             sleeps will not timeout when
>>>>>>>                             expected as the the for that is now
>>>>>>>                             further in the future, by the amount
>>>>>>>                             of the backward time change. Hence
>>>>>>>                             small time changes as typically done
>>>>>>>                             via NTP are NOT a problem.
>>>>>>>                             Timed-waits use timeouts as a
>>>>>>>                             heuristics for recovering when the
>>>>>>>                             expected real event notification
>>>>>>>                             does not occur - so a delayed
>>>>>>>                             timeout does not affect operation in
>>>>>>>                             a correctly functioning system.
>>>>>>>                             Early timeouts are indistinguishable
>>>>>>>                             from spurious wakeups, which code
>>>>>>>                             has to account for, so again not a
>>>>>>>                             problem for regular code. The only
>>>>>>>                             time a significant "hang" will occur
>>>>>>>                             is with Thread.sleep and a large
>>>>>>>                             backward time shift - but there is
>>>>>>>                             little real code that uses
>>>>>>>                             Thread.sleep in any critical way.
>>>>>>>                             So there is an issue that needs to
>>>>>>>                             be addressed but the situation is
>>>>>>>                             nowhere near as dire as you make out.
>>>>>>>                             David Holmes
>>>>>>>
>>>>>>>                                 -----Original Message-----
>>>>>>>                                 *From:*
>>>>>>>                                 concurrency-interest-bounces at cs.oswego.edu
>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>>                                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>>>>                                 Behalf Of *bruno bossola
>>>>>>>                                 *Sent:* Wednesday, 4 September
>>>>>>>                                 2013 1:56 AM
>>>>>>>                                 *To:*
>>>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>                                 *Subject:*
>>>>>>>                                 [concurrency-interest]
>>>>>>>                                 Outstanding concurrency JVM
>>>>>>>                                 issue - feedback?
>>>>>>>
>>>>>>>                                 Hi all,
>>>>>>>
>>>>>>>                                 I am writing here following a
>>>>>>>                                 suggestion by Ben Evans. I
>>>>>>>                                 wanted to check with you about
>>>>>>>                                 an issue that my teams found on
>>>>>>>                                 the JVM and that's very
>>>>>>>                                 frightening. I already started
>>>>>>>                                 the discussion with the
>>>>>>>                                 engineers of the hotspot VM team
>>>>>>>                                 but it looks like we need more
>>>>>>>                                 awareness to solve this one and
>>>>>>>                                 I'd really appreciate some help
>>>>>>>                                 and some push :)
>>>>>>>                                 It looks to me that this issue
>>>>>>>                                 is affecting every JVM64 running
>>>>>>>                                 on Linux64, so imho it's quite
>>>>>>>                                 important to be looked at.
>>>>>>>
>>>>>>>                                 *Executive summary
>>>>>>>                                 *The implementation of the
>>>>>>>                                 concurrency primitive
>>>>>>>                                 LockSupport.parkNanos(), the
>>>>>>>                                 function that controls most
>>>>>>>                                 concurrency primitive on the
>>>>>>>                                 JVM, is flawed, and any NTP
>>>>>>>                                 sync, or system time change, can
>>>>>>>                                 potentially break it with
>>>>>>>                                 unexpected results across the board.
>>>>>>>
>>>>>>>                                 *What we need to do?
>>>>>>>                                 *This is an old issue, and the
>>>>>>>                                 bug
>>>>>>>                                 <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>>>>                                 was declared private. I somehow
>>>>>>>                                 managed to have the bug reopened
>>>>>>>                                 to the public, but it's still a 
>>>>>>>                                 P4, that means that probably
>>>>>>>                                 won't be fixed. I think we need
>>>>>>>                                 to push for a resolution ASAP,
>>>>>>>                                 be sure that's in for JDK9, make
>>>>>>>                                 all the possible effort to make
>>>>>>>                                 this fix for JDK8 or, at least,
>>>>>>>                                 to include it in a later patch
>>>>>>>                                 release. In an ideal world it
>>>>>>>                                 would be nice to have a patch
>>>>>>>                                 for JDK7. As far as I understand
>>>>>>>                                 the hotspot engineering team
>>>>>>>                                 works based on priorities: being
>>>>>>>                                 this qualified as P4 means it
>>>>>>>                                 won't be probably worked on (if
>>>>>>>                                 you follow the breadcrumbs of
>>>>>>>                                 bugs and fixes you can go back
>>>>>>>                                 to 2002!) They acknowledge the
>>>>>>>                                 problem, it has been flagged to
>>>>>>>                                 management, but 1) it's low
>>>>>>>                                 priority 2) it's too risky to
>>>>>>>                                 fix for JDK8
>>>>>>>
>>>>>>>
>>>>>>>                                 *Why all this urgency?
>>>>>>>                                 *If a system time change happens
>>>>>>>                                 then all the threads parked will
>>>>>>>                                 hang, with
>>>>>>>                                 unpredictable/corrupted/useless
>>>>>>>                                 results to the end user. Same
>>>>>>>                                 applies to Future, Queue,
>>>>>>>                                 Executor, and (I guess) any
>>>>>>>                                 other construct that it's
>>>>>>>                                 somehow related to concurrency.
>>>>>>>                                 This is a big issue for us and
>>>>>>>                                 for any near time application:
>>>>>>>                                 please think about trading and
>>>>>>>                                 betting, where the JVM is
>>>>>>>                                 largely used, and  do not
>>>>>>>                                 restrain yourself to the Java
>>>>>>>                                 language: add Scala and any
>>>>>>>                                 other JVM-based language to the
>>>>>>>                                 picture (JRuby, Jython...)
>>>>>>>
>>>>>>>                                 *Tech details**
>>>>>>>                                 *To be more clear about the
>>>>>>>                                 issue, the extent of it and the
>>>>>>>                                 concurrency library, let me
>>>>>>>                                 introduce this very simple program:
>>>>>>>
>>>>>>>                                 import
>>>>>>>                                 java.util.concurrent.locks.LockSupport;
>>>>>>>
>>>>>>>                                 public class Main {
>>>>>>>
>>>>>>>                                     public static void
>>>>>>>                                 main(String[] args) {
>>>>>>>
>>>>>>>                                         for (int i=100; i>0; i--) {
>>>>>>>                                 System.out.println(i);
>>>>>>>                                 LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>>                                         }
>>>>>>>
>>>>>>>                                 System.out.println("Done!");
>>>>>>>                                     }
>>>>>>>                                 }
>>>>>>>
>>>>>>>                                 Run it with a 64bit 1.6+ JVM on
>>>>>>>                                 64bit Linux, turn the clock down
>>>>>>>                                 one hour and wait until the
>>>>>>>                                 counter stops... magic!  I
>>>>>>>                                 tested this on JDK6, JDK7 and
>>>>>>>                                 latest JDK8 beta running on
>>>>>>>                                 various Ubuntu distros. It's not
>>>>>>>                                 just a matter of (old?) sleep()
>>>>>>>                                 and wait() primitives, this
>>>>>>>                                 issue it affects the whole
>>>>>>>                                 concurrency library.
>>>>>>>
>>>>>>>                                 To prove that this is fixable, I
>>>>>>>                                 reimplemented the program above
>>>>>>>                                 above substituting
>>>>>>>                                 LockSupport.parkNanos() with  a
>>>>>>>                                 JNI call to
>>>>>>>                                 clock_nanosleep(CLOCK_MONOTONIC...):
>>>>>>>                                 works like a charm :(
>>>>>>>
>>>>>>>                                 This is due to the fact  that
>>>>>>>                                 the CPP code is calling the
>>>>>>>                                 pthread_cond_timedwait() using
>>>>>>>                                 its default clock
>>>>>>>                                 (CLOCK_REALTIME) which,
>>>>>>>                                 unfortunately is affected by
>>>>>>>                                 settime()/settimeofday() calls
>>>>>>>                                 (on Linux): for that reason it
>>>>>>>                                 cannot be used to measure
>>>>>>>                                 nanoseconds delays, which is
>>>>>>>                                 what the specification
>>>>>>>                                 <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>>>>                                 requires. CLOCK_REALTIME is not
>>>>>>>                                 guaranteed to monotonically
>>>>>>>                                 count as this is the actual
>>>>>>>                                 "system time": each time my
>>>>>>>                                 system syncs time using a NTP
>>>>>>>                                 server on the net, the time
>>>>>>>                                 might jump forward or backward.
>>>>>>>                                 The correct call (again on
>>>>>>>                                 Linux)  would require to use
>>>>>>>                                 CLOCK_MONOTONIC as clock id,
>>>>>>>                                 which are defined by POSIX specs
>>>>>>>                                 since 2002. (or better
>>>>>>>                                 CLOCK_MONOTONIC_RAW)
>>>>>>>
>>>>>>>                                 The POSIX spec
>>>>>>>                                 <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>>>>                                 is infact clear, as it states
>>>>>>>                                 "...setting the value of the
>>>>>>>                                 CLOCK_REALTIME clock via
>>>>>>>                                 clock_settime() shall have no
>>>>>>>                                 effect on threads that are
>>>>>>>                                 blocked waiting for a *relative*
>>>>>>>                                 time service based upon this
>>>>>>>                                 clock...": it definitely states
>>>>>>>                                 "relative". Having a look at the
>>>>>>>                                 hotspot code
>>>>>>>                                 <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>>>                                 it appears that the park() is
>>>>>>>                                 using compute_abstime() (which
>>>>>>>                                 uses timeofday) and then waits
>>>>>>>                                 on an absolute period: for that
>>>>>>>                                 reason it's influenced by the
>>>>>>>                                 system clock change. *Very wrong*.
>>>>>>>
>>>>>>>                                 I will be happy to know what you
>>>>>>>                                 think, and if you can help me to
>>>>>>>                                 escalate this issue I think that
>>>>>>>                                 the all Java community will
>>>>>>>                                 benefit from it.
>>>>>>>
>>>>>>>                                 Cheers,
>>>>>>>
>>>>>>>                                     Bruno
>>>>>>>
>>>>>>>
>>>>>>>                         No virus found in this message.
>>>>>>>                         Checked by AVG - www.avg.com
>>>>>>>                         <http://www.avg.com/>
>>>>>>>                         Version: 2013.0.3392 / Virus Database:
>>>>>>>                         3222/6633 - Release Date: 09/03/13
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>                 _______________________________________________
>>>>>>>                 Concurrency-interest mailing list
>>>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> -- 
>>> *Viktor Klang*
>>> /Director of Engineering/
>>> Typesafe <http://www.typesafe.com/>
>>>
>>> Twitter: @viktorklang
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> --
> [scala-debate on 2009/10/2]
> Viktor Klang: When will the days of numerical overflow be gone?
> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/b52ce4f0/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 14:47:27 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 19:47:27 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cA+pun+6ajyzpP9j8Zd=RfnU+5Gys-R5Qh8u4uuovCvUFw@mail.gmail.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228B960.6010305@oracle.com>
	<CAJU-cA+xn-8ONmTWu2Oa+R47-T+_Ws-4WqS+23K5VgYp_2=CLQ@mail.gmail.com>
	<5228C3DF.9050008@oracle.com>
	<CAJU-cA+pun+6ajyzpP9j8Zd=RfnU+5Gys-R5Qh8u4uuovCvUFw@mail.gmail.com>
Message-ID: <5228D1BF.1080607@oracle.com>

Will 10^9 be ok then? Will 10^6 be ok?

Alex

On 05/09/2013 19:20, bruno bossola wrote:
> Maybe because, if we pick the scenario presented in my example, we are 
> talking about an order of magnitude of 10^(-12)?
>
>
> On Thu, Sep 5, 2013 at 6:48 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     I don't know why you keep ignoring the point that the magnitude of
>     the negative time returned by awaitNanos is not required to be small.
>
>     Alex
>
>     On 05/09/2013 18:38, bruno bossola wrote:
>>     > You presented a design that relies on the magnitude of the
>>     negative value of awaitNanos...
>>     >
>>     No :) it's a very simple and legitimate example of usage of
>>     locking, that fails because the park(..) function is implemented
>>     using an absolute deadline based on a wall clock: that's what I
>>     call a design "not sound".
>>
>>     Cheers,
>>
>>         Bruno
>>
>>
>>
>>     On Thu, Sep 5, 2013 at 6:03 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         Quite the opposite. You presented a design that relies on the
>>         magnitude of the negative value of awaitNanos, which is not
>>         defined. I can't find a example of such algorithm in j.u.c,
>>         and I don't think your concurrent design is sound.
>>
>>         Alex
>>
>>         On 05/09/2013 17:50, bruno bossola wrote:
>>>         I am sorry but I really cannot spend more time creating more
>>>         samples and I am quite sure you could do a better work at
>>>         that! At the moment to me that matter is clear enough, but
>>>         feel free to ask, I will very happy to help! In the meantime
>>>         I prefer spend my time to work on a patch that I can apply
>>>         on my JVMs :)
>>>
>>>         Cheers,
>>>
>>>             Bruno
>>>
>>>
>>>
>>>         On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             This is far from reproducing the problem with arbitrary
>>>             j.u.c locks and queues hanging.
>>>
>>>             Condition.awaitNanos can return a negative value. If you
>>>             are expecting the negative value to be small, then how
>>>             small do you expect it to be?
>>>
>>>
>>>             Alex
>>>
>>>
>>>             On 05/09/2013 02:12, bruno bossola wrote:
>>>>             Hi Oaleksandr,
>>>>
>>>>             Please apologize me if my english was not good enough
>>>>             to provide you an example that make sense: for that
>>>>             reason I decided to go back to a binary deliverable
>>>>             (code) that shows the problem, hope this helps!
>>>>
>>>>             This is my PreciousPool class, that handles Precious
>>>>             resources:
>>>>
>>>>             import java.text.SimpleDateFormat;
>>>>             import java.util.ArrayList;
>>>>             import java.util.Date;
>>>>             import java.util.List;
>>>>             import java.util.concurrent.TimeUnit;
>>>>             import java.util.concurrent.locks.Condition;
>>>>             import java.util.concurrent.locks.Lock;
>>>>             import java.util.concurrent.locks.ReentrantLock;
>>>>
>>>>             public class PreciousPool {
>>>>
>>>>                 public static class Precious {
>>>>                     private final int id;
>>>>
>>>>                     private Precious() {
>>>>             this.id <http://this.id> = 100+(int)(Math.random()*900.0);
>>>>                     }
>>>>
>>>>                     public String toString() {
>>>>                         return "Precious n."+id;
>>>>                     }
>>>>                 }
>>>>
>>>>                 private final Lock lock;
>>>>                 private final Condition ready;
>>>>                 private final long timeoutInMillis;
>>>>
>>>>                 private final List<Precious> preciousLended;
>>>>                 private final List<Precious> preciousAvailable;
>>>>
>>>>                 public PreciousPool(int size, long timeoutInSeconds) {
>>>>                     this.lock = new ReentrantLock();
>>>>                     this.ready = lock.newCondition();
>>>>
>>>>                     this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>>                     this.preciousLended = new ArrayList<Precious>();
>>>>                     this.preciousAvailable = new ArrayList<Precious>();
>>>>
>>>>                     for (int i = 0; i < size; i++) {
>>>>             preciousAvailable.add(new Precious());
>>>>                     }
>>>>                 }
>>>>
>>>>                 public Precious obtain() {
>>>>                     lock.lock();
>>>>                     try {
>>>>                         // if no precious are available we wait for
>>>>             the specified timeout (releasing the lock so that
>>>>             others can try)
>>>>                         if (preciousAvailable.size() == 0) {
>>>>                             try {
>>>>             ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>>                             } catch (InterruptedException e) {
>>>>             Thread.currentThread().interrupt();
>>>>                                 throw new
>>>>             RuntimeException("Somebody interrupted me!", e);
>>>>                             }
>>>>                         }
>>>>
>>>>                         // if a precious is available we unload it
>>>>             and return to the caller, otherwise null
>>>>                         if (preciousAvailable.size() > 0) {
>>>>                             Precious value =
>>>>             preciousAvailable.remove(0);
>>>>             preciousLended.add(value);
>>>>                             return value;
>>>>                         } else {
>>>>                             return null;
>>>>                         }
>>>>                     } finally {
>>>>                         lock.unlock();
>>>>                     }
>>>>                 }
>>>>
>>>>                 public void release(Precious value) {
>>>>                     lock.lock();
>>>>                     try {
>>>>                         if (!preciousLended.remove(value))
>>>>                             throw new RuntimeException("Element
>>>>             "+value+" was not lended!");
>>>>
>>>>                         // if a precious is returned we put it back
>>>>             and signal to anybody waiting
>>>>             preciousAvailable.add(value);
>>>>                         ready.signalAll();
>>>>                     } finally {
>>>>                         lock.unlock();
>>>>                     }
>>>>                 }
>>>>
>>>>                 public static void main(String args[]) {
>>>>                     final int size = 3;
>>>>                     final PreciousPool pool = new
>>>>             PreciousPool(size, 5);
>>>>
>>>>                     // let's exhaust the pool
>>>>                     for (int i=0; i<size; i++)
>>>>             dump(pool.obtain());
>>>>
>>>>                     // and as we are stubborn we continuosly ask
>>>>             for a new one
>>>>                     while(true) {
>>>>             dump(pool.obtain());
>>>>                     }
>>>>                 }
>>>>
>>>>                 private static void dump(Precious precious) {
>>>>                     if (precious == null)
>>>>                         log("I did not get my precious :(");
>>>>                     else
>>>>                         log("I did get my precious! "+precious);
>>>>                 }
>>>>
>>>>                 private static void log(String message) {
>>>>                     final String now = new
>>>>             SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>>                     System.out.println(now + message);
>>>>                 }
>>>>             }
>>>>
>>>>             So, the main is a single thread (no need for
>>>>             multithreading here, let's keep it simple), that first
>>>>             exhaust the whole pool and then keep asking, without
>>>>             success, for a resource. Stubborn guy, I say, but it
>>>>             happens. If you run this program everything works as
>>>>             expected: you are greeted by a three successful
>>>>             Precious and then an endless list of failures, that it
>>>>             continuously grow. All good :)
>>>>
>>>>             02:34:40:0061 I did get my precious! Precious n.156
>>>>             02:34:40:0062 I did get my precious! Precious n.991
>>>>             02:34:40:0062 I did get my precious! Precious n.953
>>>>             02:34:45:0064 I did not get my precious :(
>>>>             02:34:50:0065 I did not get my precious :(
>>>>             02:34:55:0066 I did not get my precious :(
>>>>             02:35:00:0067 I did not get my precious :(
>>>>             02:35:05:0068 I did not get my precious :(
>>>>             [...]
>>>>
>>>>             But guess what happens when, while the program is
>>>>             running, I change the date of my system back of one
>>>>             hour? Everything stops,  it's simple as that. No
>>>>             prints, nothing, zero, nada. Now, If it wasn't so late,
>>>>             I would probably wait one hour in order to have my
>>>>             program restored to his normal process, but as a
>>>>             customer I won't be terribly happy :)
>>>>
>>>>             I hope my point is now clear.
>>>>             Cheers,
>>>>
>>>>                 Bruno
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>             On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>>>             <oleksandr.otenko at oracle.com
>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>
>>>>                 n 04/09/2013 18:54, bruno bossola wrote:
>>>>>                 Hi Oleksandr,
>>>>>
>>>>>                     Where in the design of those systems is a
>>>>>                     real-time timer? The one that delivers time
>>>>>                     events uncompromised even by GC latency?
>>>>>
>>>>>                 I don't think so :) If somebody needs a real time
>>>>>                 implementation he needs to go for a real time JVM,
>>>>>                 like Jean correctly pointed out.  The concurrency
>>>>>                 primitives are depending on
>>>>>                 LockSupport.parkNanos(...) to park a thread: if
>>>>>                 this for any reason is not working (like it is)
>>>>>                 then strange things may happen.
>>>>                 Your assumption is that it is not working, if the
>>>>                 elapsed time is longer. This is the flawed assumption.
>>>>
>>>>                 Also, you need to read fine print on those "real
>>>>                 time" JVMs. The catch is in the definition of "real
>>>>                 time".
>>>>
>>>>
>>>>
>>>>
>>>>>                 Imagine, for example, that you are using a
>>>>>                 ReentrantLock to control a very precious resource
>>>>>                 used across the board (what about a database
>>>>>                 connection pool?) and you are unlucky enough to
>>>>>                 have a system time change (backwards) while you
>>>>>                 are locking: all the threads that want to use such
>>>>>                 resource will be progressively locked: not
>>>>>                 forever, but for the amount of time the clock went
>>>>>                 back. Probably most (all?) of your system freezes,
>>>>>                 and the only option you have is to wait, or restart.
>>>>>                 Now place this in a large application server, that
>>>>>                 provide services for hunreds (thousands) of users.
>>>>>                 How does it sound to you?
>>>>                 It sounds like you don't understand how the locks work.
>>>>
>>>>
>>>>                 Alex
>>>>
>>>>
>>>>>
>>>>>                 BTW, at the moment we could have a watchdog (in
>>>>>                 Python :)) that restarts it, but, I dunno why, I
>>>>>                 don't like it a lot...
>>>>>
>>>>>                 Cheers,
>>>>>
>>>>>                     Bruno
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>                 On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>>>                 <oleksandr.otenko at oracle.com
>>>>>                 <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>
>>>>>                     You are missing the point.
>>>>>
>>>>>                     Where in the design of those systems is a
>>>>>                     real-time timer? The one that delivers time
>>>>>                     events uncompromised even by GC latency?
>>>>>
>>>>>                     The whole concurrency lot does not depend on
>>>>>                     the timeout magnitude for correctness.
>>>>>
>>>>>                     Alex
>>>>>
>>>>>
>>>>>                     On 04/09/2013 12:05, bruno bossola wrote:
>>>>>>                     Hi David
>>>>>>
>>>>>>
>>>>>>                         bugs.sun.com <http://bugs.sun.com> is not
>>>>>>                         a live reflection of the bug database but
>>>>>>                         gets updated periodically (every 12 hours
>>>>>>                         I think).
>>>>>>
>>>>>>
>>>>>>                     Good to know :) I will be eagerly clicking on
>>>>>>                     it to discover the new priority! Thanks for
>>>>>>                     that, I really appreciate it.
>>>>>>
>>>>>>
>>>>>>                         The issue arises on certain 64-bit linux
>>>>>>                         kernel/glibc versions. If you have an
>>>>>>                         older version this does not impact you.
>>>>>>
>>>>>>                     You saw my list: nobody will use an older
>>>>>>                     Kernel/glibc version in production.
>>>>>>
>>>>>>
>>>>>>                         As for the rest, show me real code in
>>>>>>                         such systems that rely on sleep for
>>>>>>                         correctness or performance/timeliness and
>>>>>>                         I will show you broken code.
>>>>>>
>>>>>>                     You are still hitting about the sleep(), I
>>>>>>                     understand and I agree about this. But here
>>>>>>                     we are not talking about sleeps: we are
>>>>>>                     talking about the whole concurrency lot. And
>>>>>>                     yes, as I already said, we are talking about
>>>>>>                     near time systems, like trading application,
>>>>>>                     betting applications, air traffic control
>>>>>>                     systems, car traffic control systems. Don't
>>>>>>                     you think this bug might place Oracle JVM
>>>>>>                     outside of these markets?
>>>>>>
>>>>>>
>>>>>>                         If this was as dire as you make out do
>>>>>>                         you not think that this issue would have
>>>>>>                         been raised far more than it has? [....]
>>>>>>                         prudent developers/companies trial
>>>>>>                         platform upgrades to check for these
>>>>>>                         kinds of issues before switching to them
>>>>>>                         in production environments.
>>>>>>
>>>>>>                     I am waiting now for the part where you say
>>>>>>                     that we should throw away Linux and use
>>>>>>                     Oracle Solaris :)  In all seriousness,
>>>>>>                     there's a lot of action "in the middle", and
>>>>>>                     I think that Oracle cannot oversee that. For
>>>>>>                     example a lot of trading software system can
>>>>>>                     be installed on premises, where you usually
>>>>>>                     have no control over the environment: what I
>>>>>>                     would do is to put a native daemon in my app
>>>>>>                     so that if I see the system clock change I
>>>>>>                     would kill myself, just in case. And this is
>>>>>>                     a solution that I know for a fact (sorry, I
>>>>>>                     cannot make a reference) it's used in
>>>>>>                     production in a very important trading
>>>>>>                     application.
>>>>>>
>>>>>>                     Regarding that specific bug, it was not
>>>>>>                     accessible to the external until two days
>>>>>>                     ago, so I guess nobody really knew a lot
>>>>>>                     about it, but I will make sure it will :) so
>>>>>>                     that we can get more traction.
>>>>>>
>>>>>>                     Cheers,
>>>>>>
>>>>>>                         Bruno
>>>>>>
>>>>>>
>>>>>>
>>>>>>                     On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>>>                     <davidcholmes at aapt.net.au
>>>>>>                     <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>
>>>>>>                         Bruno,
>>>>>>                         bugs.sun.com <http://bugs.sun.com> is not
>>>>>>                         a live reflection of the bug database but
>>>>>>                         gets updated periodically (every 12 hours
>>>>>>                         I think).
>>>>>>                         The issue arises on certain 64-bit linux
>>>>>>                         kernel/glibc versions. If you have an
>>>>>>                         older version this does not impact you.
>>>>>>                         As for the rest, show me real code in
>>>>>>                         such systems that rely on sleep for
>>>>>>                         correctness or performance/timelinessand
>>>>>>                         I will show you broken code. We are not
>>>>>>                         talking about real-time systemshere.
>>>>>>                         park(nanos)/wait(millis) will only be
>>>>>>                         affected by the backward time change if
>>>>>>                         the real notification they are waiting
>>>>>>                         for does not happen. Timeouts with these
>>>>>>                         APIs are heuristics, they are defensive
>>>>>>                         programming to cover the case "what if
>>>>>>                         the notification I'm waiting for does not
>>>>>>                         come". The code that would be affected by
>>>>>>                         this issue is a very small % of the code
>>>>>>                         that uses the API.
>>>>>>                         If this was as dire as you make out do
>>>>>>                         you not think that this issue would have
>>>>>>                         been raised far more than it has? This
>>>>>>                         issue does need addressing because the
>>>>>>                         number of affected systems will grow as
>>>>>>                         these newer linux systems are adopted,
>>>>>>                         but prudent developers/companies trial
>>>>>>                         platform upgrades to check for these
>>>>>>                         kinds of issues before swicthing to them
>>>>>>                         in production environments.
>>>>>>                         Regards,
>>>>>>                         David
>>>>>>
>>>>>>                             -----Original Message-----
>>>>>>                             *From:* bruno bossola
>>>>>>                             [mailto:bbossola at gmail.com
>>>>>>                             <mailto:bbossola at gmail.com>]
>>>>>>                             *Sent:* Wednesday, 4 September 2013
>>>>>>                             11:14 AM
>>>>>>                             *To:* dholmes at ieee.org
>>>>>>                             <mailto:dholmes at ieee.org>
>>>>>>                             *Cc:*
>>>>>>                             concurrency-interest at cs.oswego.edu
>>>>>>                             <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>                             *Subject:* Re: [concurrency-interest]
>>>>>>                             Outstanding concurrency JVM issue -
>>>>>>                             feedback?
>>>>>>
>>>>>>                             Hi David,
>>>>>>
>>>>>>                             thanks for following up.
>>>>>>
>>>>>>                                 I have raised the priority on 6900441
>>>>>>
>>>>>>                             Thanks, but it looks still like a P4:
>>>>>>                             http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>>                             See also the attached snapshot, just
>>>>>>                             in case it changes :)
>>>>>>
>>>>>>                             Inline image 2
>>>>>>
>>>>>>                                 [...] which to my knowledge [...]
>>>>>>                                 has never been a private bug
>>>>>>
>>>>>>                             It was not accessible using
>>>>>>                             bugs.sun.com <http://bugs.sun.com/>,
>>>>>>                             this was translated to private. I
>>>>>>                             also received the same info
>>>>>>                             indirectly from the 7u lead:
>>>>>>                             "I'm not sure why 6900441 isn't
>>>>>>                             public. (I'll follow up with owner of
>>>>>>                             bugs.sun.com
>>>>>>                             <http://bugs.sun.com/>)", I guess you
>>>>>>                             can check with him.
>>>>>>
>>>>>>
>>>>>>                                 It doesn't affect "every JVM64
>>>>>>                                 running on Linux64".  A fix has
>>>>>>                                 been introduced into a specific
>>>>>>                                 glibc version...
>>>>>>
>>>>>>                             ...and apparently did not make it. I
>>>>>>                             was able to reproduce this even with
>>>>>>                             the IBM VM, so to speak. I tried
>>>>>>                             JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>>>>                             12, 13 + some random Debian. I did
>>>>>>                             not have a JDK5, so I cannot say, but
>>>>>>                             on JDK4 everything works (that's the
>>>>>>                             reason why I call it a regression).
>>>>>>                             (ah, if you look at the bug, it lists
>>>>>>                             also JDK5, so I think we are pretty
>>>>>>                             much covered here).
>>>>>>                             If you still have doubts tough,
>>>>>>                             please have also a look on
>>>>>>                             stackoverflow to see how it was
>>>>>>                             reproduced consistently on probably
>>>>>>                             every 64bitJVM over 64bitLinux in the
>>>>>>                             world.
>>>>>>
>>>>>>
>>>>>>                                 The effects of this is not that
>>>>>>                                 "all the threads parked will
>>>>>>                                 hang, with
>>>>>>                                 unpredictable/corrupted/useless"!
>>>>>>                                 The effects are very simple an
>>>>>>                                 quite predictable... [deletia]s.
>>>>>>
>>>>>>                             We have very different views, and I
>>>>>>                             find quite difficult to accept yours.
>>>>>>                             You are confusing my sample program
>>>>>>                             which contains a single thread in a
>>>>>>                             for loop with any other complex
>>>>>>                             multi-threading concurrent system
>>>>>>                             written in Java. For example, if you
>>>>>>                             ever worked in a bank you surely know
>>>>>>                             what I mean. You are comparing some
>>>>>>                             random sleep() put into a program by
>>>>>>                             some newbie, with the complex
>>>>>>                             ecosystem of a concurrent platform
>>>>>>                             written to manage trading information
>>>>>>                             on very fast market. In that
>>>>>>                             condition, I am sorry, statements
>>>>>>                             such "...delayed timeout does not
>>>>>>                             affect operation in a correctly
>>>>>>                             functioning system..." and "...small
>>>>>>                             time changes [...] are not a problem"
>>>>>>                             are really not applicable. Let your
>>>>>>                             system place an order three seconds
>>>>>>                             late and your are out of the door so
>>>>>>                             quickly you cannot even realize it.
>>>>>>
>>>>>>                             But let's not limit ourselves to
>>>>>>                             banks: how do you think your previous
>>>>>>                             statements stands in these scenarios?
>>>>>>                             - air control systems
>>>>>>                             <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>>                             about a few seconds delay in control
>>>>>>                             when fying planes?)
>>>>>>                             - city traffic control systems
>>>>>>                             <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>>                             if just for a couple of seconds all
>>>>>>                             traffic lights become green?)
>>>>>>
>>>>>>                             Not good enough.
>>>>>>
>>>>>>
>>>>>>                                 ...small time changes as
>>>>>>                                 typically done via NTP
>>>>>>
>>>>>>                             NTP is only one of the possible
>>>>>>                             sources of this problem. The root of
>>>>>>                             it is that the JVM is counting
>>>>>>                             nanoseconds delays using absolute
>>>>>>                             values based on a wallclock: I do not
>>>>>>                             think it's that smart.
>>>>>>
>>>>>>
>>>>>>                                 So there is an issue that needs
>>>>>>                                 to be addressed but the situation
>>>>>>                                 is nowhere near as dire as you
>>>>>>                                 make out
>>>>>>
>>>>>>                             Let's try to put this in perspective,
>>>>>>                             shall we? In case the clock run
>>>>>>                             backwards LockSupport.park() will be
>>>>>>                             waiting for the nanoseconds requested
>>>>>>                             plus the amount of
>>>>>>                             seconds/minute/hours/days requested
>>>>>>                             to compensate. Now, this primitive is
>>>>>>                             used by almost *every* concurrency
>>>>>>                             construct available on the platform,
>>>>>>                             such as AbstractQueuedSynchronizer
>>>>>>                             (and subclasses), ReentrantLock (and
>>>>>>                             subclasses), CyclicBarrier,
>>>>>>                             BlockingQueue (and subclasses),
>>>>>>                             Executors, FutureTask, .... (too long
>>>>>>                             to list them all, but I think we have
>>>>>>                             the picture) and also low levels
>>>>>>                             synchronization primitives of the
>>>>>>                             language itself, so
>>>>>>                             Object::wait(:long) and the related
>>>>>>                             sychronized blocks.
>>>>>>
>>>>>>                             I think it's pretty dire.
>>>>>>
>>>>>>
>>>>>>                             Cheers,
>>>>>>
>>>>>>                                 Bruno
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>                             On Wed, Sep 4, 2013 at 12:14 AM,
>>>>>>                             David Holmes
>>>>>>                             <davidcholmes at aapt.net.au
>>>>>>                             <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>
>>>>>>                                 Hi Bruno,
>>>>>>                                 I have raised the priority on
>>>>>>                                 6900441 (which to my knowledge -
>>>>>>                                 and I created it! - has never
>>>>>>                                 been a private bug).
>>>>>>                                 A few notes on the "very
>>>>>>                                 frightening" aspect of this:
>>>>>>                                 1. It doesn't affect "every JVM64
>>>>>>                                 running on Linux64". A fix has
>>>>>>                                 been introduced into a specific
>>>>>>                                 glibc version for the futex-wait
>>>>>>                                 code such that it now responds to
>>>>>>                                 changes in the system time for
>>>>>>                                 absolute waits, where for all the
>>>>>>                                 years previous it did not. The
>>>>>>                                 fix seems to have been applied in
>>>>>>                                 late 2011 or early 2012 but I
>>>>>>                                 don't know the exact glibc
>>>>>>                                 version. There is also a 32-bit
>>>>>>                                 version of the fix that was
>>>>>>                                 proposed on Nov 27, 2012, so it
>>>>>>                                 will eventually make its way into
>>>>>>                                 32-bit linux too.
>>>>>>                                 2. The effects of this is not
>>>>>>                                 that "all the threads parked will
>>>>>>                                 hang, with
>>>>>>                                 unpredictable/corrupted/useless"!
>>>>>>                                 The effects are very simple an
>>>>>>                                 quite predictable. If the system
>>>>>>                                 time goes forward then
>>>>>>                                 timed-waits (Object.wait,
>>>>>>                                 LockSupport.park) (which should
>>>>>>                                 be relative times) will return
>>>>>>                                 early as the absolute-time that
>>>>>>                                 the relative time was converted
>>>>>>                                 to will be seen to have been
>>>>>>                                 reached (Thread.sleep contains a
>>>>>>                                 guard against early returns).
>>>>>>                                 This is not actually a problem as
>>>>>>                                 you can not distinguish this case
>>>>>>                                 from a "spurious wakeup" which
>>>>>>                                 code is supposed to account
>>>>>>                                 for. If the time is changed
>>>>>>                                 backwards then these timed-waits
>>>>>>                                 & sleeps will not timeout when
>>>>>>                                 expected as the the for that is
>>>>>>                                 now further in the future, by the
>>>>>>                                 amount of the backward time
>>>>>>                                 change. Hence small time changes
>>>>>>                                 as typically done via NTP are NOT
>>>>>>                                 a problem. Timed-waits use
>>>>>>                                 timeouts as a heuristics for
>>>>>>                                 recovering when the expected real
>>>>>>                                 event notification does not occur
>>>>>>                                 - so a delayed timeout does not
>>>>>>                                 affect operation in a correctly
>>>>>>                                 functioning system. Early
>>>>>>                                 timeouts are indistinguishable
>>>>>>                                 from spurious wakeups, which code
>>>>>>                                 has to account for, so again not
>>>>>>                                 a problem for regular code. The
>>>>>>                                 only time a significant "hang"
>>>>>>                                 will occur is with Thread.sleep
>>>>>>                                 and a large backward time shift -
>>>>>>                                 but there is little real code
>>>>>>                                 that uses Thread.sleep in any
>>>>>>                                 critical way.
>>>>>>                                 So there is an issue that needs
>>>>>>                                 to be addressed but the situation
>>>>>>                                 is nowhere near as dire as you
>>>>>>                                 make out.
>>>>>>                                 David Holmes
>>>>>>
>>>>>>                                     -----Original Message-----
>>>>>>                                     *From:*
>>>>>>                                     concurrency-interest-bounces at cs.oswego.edu
>>>>>>                                     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>                                     [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>                                     <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>>>                                     Behalf Of *bruno bossola
>>>>>>                                     *Sent:* Wednesday, 4
>>>>>>                                     September 2013 1:56 AM
>>>>>>                                     *To:*
>>>>>>                                     concurrency-interest at cs.oswego.edu
>>>>>>                                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>                                     *Subject:*
>>>>>>                                     [concurrency-interest]
>>>>>>                                     Outstanding concurrency JVM
>>>>>>                                     issue - feedback?
>>>>>>
>>>>>>                                     Hi all,
>>>>>>
>>>>>>                                     I am writing here following a
>>>>>>                                     suggestion by Ben Evans. I
>>>>>>                                     wanted to check with you
>>>>>>                                     about an issue that my teams
>>>>>>                                     found on the JVM and that's
>>>>>>                                     very frightening. I already
>>>>>>                                     started the discussion with
>>>>>>                                     the engineers of the hotspot
>>>>>>                                     VM team but it looks like we
>>>>>>                                     need more awareness to solve
>>>>>>                                     this one and I'd really
>>>>>>                                     appreciate some help and some
>>>>>>                                     push :)
>>>>>>                                     It looks to me that this
>>>>>>                                     issue is affecting every
>>>>>>                                     JVM64 running on Linux64, so
>>>>>>                                     imho it's quite important to
>>>>>>                                     be looked at.
>>>>>>
>>>>>>                                     *Executive summary
>>>>>>                                     *The implementation of the
>>>>>>                                     concurrency primitive
>>>>>>                                     LockSupport.parkNanos(), the
>>>>>>                                     function that controls most
>>>>>>                                     concurrency primitive on the
>>>>>>                                     JVM, is flawed, and any NTP
>>>>>>                                     sync, or system time change,
>>>>>>                                     can potentially break it with
>>>>>>                                     unexpected results across the
>>>>>>                                     board.
>>>>>>
>>>>>>                                     *What we need to do?
>>>>>>                                     *This is an old issue, and
>>>>>>                                     the bug
>>>>>>                                     <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>>>                                     was declared private. I
>>>>>>                                     somehow managed to have the
>>>>>>                                     bug reopened to the public,
>>>>>>                                     but it's still a  P4, that
>>>>>>                                     means that probably won't be
>>>>>>                                     fixed. I think we need to
>>>>>>                                     push for a resolution ASAP,
>>>>>>                                     be sure that's in for JDK9,
>>>>>>                                     make all the possible effort
>>>>>>                                     to make this fix for JDK8 or,
>>>>>>                                     at least, to include it in a
>>>>>>                                     later patch release. In an
>>>>>>                                     ideal world it would be nice
>>>>>>                                     to have a patch for JDK7. As
>>>>>>                                     far as I understand the
>>>>>>                                     hotspot engineering team
>>>>>>                                     works based on priorities:
>>>>>>                                     being this qualified as P4
>>>>>>                                     means it won't be probably
>>>>>>                                     worked on (if you follow the
>>>>>>                                     breadcrumbs of bugs and fixes
>>>>>>                                     you can go back to 2002!)
>>>>>>                                     They acknowledge the problem,
>>>>>>                                     it has been flagged to
>>>>>>                                     management, but 1) it's low
>>>>>>                                     priority 2) it's too risky to
>>>>>>                                     fix for JDK8
>>>>>>
>>>>>>
>>>>>>                                     *Why all this urgency?
>>>>>>                                     *If a system time change
>>>>>>                                     happens then all the threads
>>>>>>                                     parked will hang, with
>>>>>>                                     unpredictable/corrupted/useless
>>>>>>                                     results to the end user. Same
>>>>>>                                     applies to Future, Queue,
>>>>>>                                     Executor, and (I guess) any
>>>>>>                                     other construct that it's
>>>>>>                                     somehow related to
>>>>>>                                     concurrency. This is a big
>>>>>>                                     issue for us and for any near
>>>>>>                                     time application: please
>>>>>>                                     think about trading and
>>>>>>                                     betting, where the JVM is
>>>>>>                                     largely used, and  do not
>>>>>>                                     restrain yourself to the Java
>>>>>>                                     language: add Scala and any
>>>>>>                                     other JVM-based language to
>>>>>>                                     the picture (JRuby, Jython...)
>>>>>>
>>>>>>                                     *Tech details**
>>>>>>                                     *To be more clear about the
>>>>>>                                     issue, the extent of it and
>>>>>>                                     the concurrency library, let
>>>>>>                                     me introduce this very simple
>>>>>>                                     program:
>>>>>>
>>>>>>                                     import
>>>>>>                                     java.util.concurrent.locks.LockSupport;
>>>>>>
>>>>>>                                     public class Main {
>>>>>>
>>>>>>                                         public static void
>>>>>>                                     main(String[] args) {
>>>>>>
>>>>>>                                             for (int i=100; i>0;
>>>>>>                                     i--) {
>>>>>>                                     System.out.println(i);
>>>>>>                                     LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>                                             }
>>>>>>
>>>>>>                                     System.out.println("Done!");
>>>>>>                                         }
>>>>>>                                     }
>>>>>>
>>>>>>                                     Run it with a 64bit 1.6+ JVM
>>>>>>                                     on 64bit Linux, turn the
>>>>>>                                     clock down one hour and wait
>>>>>>                                     until the counter stops...
>>>>>>                                     magic!  I tested this on
>>>>>>                                     JDK6, JDK7 and latest JDK8
>>>>>>                                     beta running on various
>>>>>>                                     Ubuntu distros. It's not just
>>>>>>                                     a matter of (old?) sleep()
>>>>>>                                     and wait() primitives, this
>>>>>>                                     issue it affects the whole
>>>>>>                                     concurrency library.
>>>>>>
>>>>>>                                     To prove that this is
>>>>>>                                     fixable, I reimplemented the
>>>>>>                                     program above above
>>>>>>                                     substituting
>>>>>>                                     LockSupport.parkNanos() with 
>>>>>>                                     a JNI call to
>>>>>>                                     clock_nanosleep(CLOCK_MONOTONIC...):
>>>>>>                                     works like a charm :(
>>>>>>
>>>>>>                                     This is due to the fact  that
>>>>>>                                     the CPP code is calling the
>>>>>>                                     pthread_cond_timedwait()
>>>>>>                                     using its default clock
>>>>>>                                     (CLOCK_REALTIME) which,
>>>>>>                                     unfortunately is affected by
>>>>>>                                     settime()/settimeofday()
>>>>>>                                     calls (on Linux): for that
>>>>>>                                     reason it cannot be used to
>>>>>>                                     measure nanoseconds delays,
>>>>>>                                     which is what the
>>>>>>                                     specification
>>>>>>                                     <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>>>                                     requires. CLOCK_REALTIME is
>>>>>>                                     not guaranteed to
>>>>>>                                     monotonically count as this
>>>>>>                                     is the actual "system time":
>>>>>>                                     each time my system syncs
>>>>>>                                     time using a NTP server on
>>>>>>                                     the net, the time might jump
>>>>>>                                     forward or backward. The
>>>>>>                                     correct call (again on
>>>>>>                                     Linux)  would require to use
>>>>>>                                     CLOCK_MONOTONIC as clock id,
>>>>>>                                     which are defined by POSIX
>>>>>>                                     specs since 2002. (or better
>>>>>>                                     CLOCK_MONOTONIC_RAW)
>>>>>>
>>>>>>                                     The POSIX spec
>>>>>>                                     <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>>>                                     is infact clear, as it states
>>>>>>                                     "...setting the value of the
>>>>>>                                     CLOCK_REALTIME clock via
>>>>>>                                     clock_settime() shall have no
>>>>>>                                     effect on threads that are
>>>>>>                                     blocked waiting for a
>>>>>>                                     *relative* time service based
>>>>>>                                     upon this clock...": it
>>>>>>                                     definitely states "relative".
>>>>>>                                     Having a look at the hotspot
>>>>>>                                     code
>>>>>>                                     <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>>                                     it appears that the park() is
>>>>>>                                     using compute_abstime()
>>>>>>                                     (which uses timeofday) and
>>>>>>                                     then waits on an absolute
>>>>>>                                     period: for that reason it's
>>>>>>                                     influenced by the system
>>>>>>                                     clock change. *Very wrong*.
>>>>>>
>>>>>>                                     I will be happy to know what
>>>>>>                                     you think, and if you can
>>>>>>                                     help me to escalate this
>>>>>>                                     issue I think that the all
>>>>>>                                     Java community will benefit
>>>>>>                                     from it.
>>>>>>
>>>>>>                                     Cheers,
>>>>>>
>>>>>>                                         Bruno
>>>>>>
>>>>>>
>>>>>>                             No virus found in this message.
>>>>>>                             Checked by AVG - www.avg.com
>>>>>>                             <http://www.avg.com>
>>>>>>                             Version: 2013.0.3392 / Virus
>>>>>>                             Database: 3222/6633 - Release Date:
>>>>>>                             09/03/13
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>                     _______________________________________________
>>>>>>                     Concurrency-interest mailing list
>>>>>>                     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/865b3ad1/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 15:10:44 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 20:10:44 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5228D081.9040705@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
	<5228C351.4070009@oracle.com>
	<966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>
	<5228D081.9040705@oracle.com>
Message-ID: <5228D734.2050703@oracle.com>

The main point here is how to guarantee arrival of nanosecond resolution 
of events in a environment where we cannot guarantee reasonably-forward 
movement of time. Bruno showed a dummy case where he was moving the 
clock 1 hour away. Is this what he sees in his real environment? How 
does he justify the use of environment with such unreliable source of 
time? Do we know that environment will deliver nanosecond-time events 
reliably? Will they be spaced 1 ns from each other? (From what I recall, 
in some virtualization envs some JVMs reported the time go back, when it 
shouldn't. Yet, even the fix was only as perfect as the clock update 
delivery in that virtualization solution. If we are meant to catch up on 
200 microseconds, will it deliver in a salvo, or add a corrective 
microsecond on 200 subsequent seconds?)


If we talk about a different environment, eg VM with wall clock moving a 
few hundred ms back and forth, it becomes a problem of a very different 
magnitude. The question of timely arrival of events is still there, but 
even with that part unanswered, a few hundred ms drift in a pause will 
not be fine for banking or betting, nearly exclusively. Then the 
question is still why choose environments like that to run applications 
that are so sensitive?


Alex


On 05/09/2013 19:42, Oleksandr Otenko wrote:
> On 05/09/2013 19:15, Roland Kuhn wrote:
>>
>> 5 sep 2013 kl. 19:45 skrev Oleksandr Otenko:
>>
>>> Exactly my point.
>>>
>>> Now someone needs to take care of negative time returned, when the 
>>> clock goes back, even if the wait was shorter than timeout.
>>
>> Why would that lead to a negative return value?
>
> Depending on how you work out the elapsed time, of course.
>
>>> Or, if we report the actual time waited, then deal with the 
>>> inconsistency between apparent System.nanoTime() and the wait.
>>
>> There are two very different time sources in the JVM, and the one 
>> which has "nano" in its name is supposed to be monotonic and 
>> independent of the system's wall time clock. I share Bruno's view 
>> that a method called awaitNanos() should measure time using 
>> System.nanoTime and not with System.currentTimeMillis (conceptually). 
>> It is unfortunate that the API docs of awaitNanos() do not specify 
>> which of these choices was made.
>
> Conceptually awaitNanos() returns timeout-elapsedTime. How will 
> System.nanoTime() work out the elapsed time in nanoseconds after 
> suspend-modify wall clock-resume? Who tells it how many nanoseconds 
> were missed?
>
> Alex
>
>
>>
>> Regards,
>>
>> Roland
>>
>>>
>>> Alex
>>>
>>> On 05/09/2013 18:31, ?iktor ?lang wrote:
>>>> For Condition.awaitNanos it states:
>>>>
>>>> Returns:
>>>>     an estimate of the |nanosTimeout| value minus the time spent
>>>>     waiting upon return from this method. A positive value may be
>>>>     used as the argument to a subsequent call to this method to
>>>>     finish waiting out the desired time. *A value less than or
>>>>     equal to zero indicates that no time remains.*
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko 
>>>> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> 
>>>> wrote:
>>>>
>>>>     Oh, and now someone else is going to complain that awaitNanos
>>>>     returns a negative number, even though it waited for only 1 ms
>>>>     out of 100.
>>>>
>>>>     Alex
>>>>
>>>>     On 05/09/2013 17:50, bruno bossola wrote:
>>>>>     I am sorry but I really cannot spend more time creating more
>>>>>     samples and I am quite sure you could do a better work at
>>>>>     that! At the moment to me that matter is clear enough, but
>>>>>     feel free to ask, I will very happy to help! In the meantime I
>>>>>     prefer spend my time to work on a patch that I can apply on my
>>>>>     JVMs :)
>>>>>
>>>>>     Cheers,
>>>>>
>>>>>         Bruno
>>>>>
>>>>>
>>>>>
>>>>>     On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko
>>>>>     <oleksandr.otenko at oracle.com
>>>>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>
>>>>>         This is far from reproducing the problem with arbitrary
>>>>>         j.u.c locks and queues hanging.
>>>>>
>>>>>         Condition.awaitNanos can return a negative value. If you
>>>>>         are expecting the negative value to be small, then how
>>>>>         small do you expect it to be?
>>>>>
>>>>>
>>>>>         Alex
>>>>>
>>>>>
>>>>>         On 05/09/2013 02:12, bruno bossola wrote:
>>>>>>         Hi Oaleksandr,
>>>>>>
>>>>>>         Please apologize me if my english was not good enough to
>>>>>>         provide you an example that make sense: for that reason I
>>>>>>         decided to go back to a binary deliverable (code) that
>>>>>>         shows the problem, hope this helps!
>>>>>>
>>>>>>         This is my PreciousPool class, that handles Precious
>>>>>>         resources:
>>>>>>
>>>>>>         import java.text.SimpleDateFormat;
>>>>>>         import java.util.ArrayList;
>>>>>>         import java.util.Date;
>>>>>>         import java.util.List;
>>>>>>         import java.util.concurrent.TimeUnit;
>>>>>>         import java.util.concurrent.locks.Condition;
>>>>>>         import java.util.concurrent.locks.Lock;
>>>>>>         import java.util.concurrent.locks.ReentrantLock;
>>>>>>
>>>>>>         public class PreciousPool {
>>>>>>
>>>>>>             public static class Precious {
>>>>>>                 private final int id;
>>>>>>
>>>>>>                 private Precious() {
>>>>>>         this.id <http://this.id/> = 100+(int)(Math.random()*900.0);
>>>>>>                 }
>>>>>>
>>>>>>                 public String toString() {
>>>>>>                     return "Precious n."+id;
>>>>>>                 }
>>>>>>             }
>>>>>>
>>>>>>             private final Lock lock;
>>>>>>             private final Condition ready;
>>>>>>             private final long timeoutInMillis;
>>>>>>
>>>>>>             private final List<Precious> preciousLended;
>>>>>>             private final List<Precious> preciousAvailable;
>>>>>>
>>>>>>             public PreciousPool(int size, long timeoutInSeconds) {
>>>>>>                 this.lock = new ReentrantLock();
>>>>>>                 this.ready = lock.newCondition();
>>>>>>
>>>>>>                 this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>>>>                 this.preciousLended =  new ArrayList<Precious>();
>>>>>>         this.preciousAvailable = new ArrayList<Precious>();
>>>>>>
>>>>>>                 for (int i = 0; i < size; i++) {
>>>>>>         preciousAvailable.add(new Precious());
>>>>>>                 }
>>>>>>             }
>>>>>>
>>>>>>             public Precious obtain()  {
>>>>>>                 lock.lock();
>>>>>>                 try {
>>>>>>                     // if no precious are available we wait for
>>>>>>         the specified timeout (releasing the lock so that others
>>>>>>         can try)
>>>>>>                     if (preciousAvailable.size() == 0) {
>>>>>>                         try {
>>>>>>         ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>>>>                         } catch (InterruptedException e) {
>>>>>>         Thread.currentThread().interrupt();
>>>>>>                             throw new RuntimeException("Somebody
>>>>>>         interrupted me!", e);
>>>>>>                         }
>>>>>>                     }
>>>>>>
>>>>>>                     // if a precious is available we unload it
>>>>>>         and return to the caller, otherwise null
>>>>>>                     if (preciousAvailable.size() > 0) {
>>>>>>                         Precious value = preciousAvailable.remove(0);
>>>>>>         preciousLended.add(value);
>>>>>>                         return value;
>>>>>>                     } else {
>>>>>>                         return null;
>>>>>>                     }
>>>>>>                 } finally {
>>>>>>                     lock.unlock();
>>>>>>                 }
>>>>>>             }
>>>>>>
>>>>>>             public void release(Precious value) {
>>>>>>                 lock.lock();
>>>>>>                 try {
>>>>>>                     if (!preciousLended.remove(value))
>>>>>>                         throw new RuntimeException("Element
>>>>>>         "+value+" was not lended!");
>>>>>>
>>>>>>                     // if a precious is returned we put it back
>>>>>>         and signal to anybody waiting
>>>>>>         preciousAvailable.add(value);
>>>>>>         ready.signalAll();
>>>>>>                 } finally {
>>>>>>                     lock.unlock();
>>>>>>                 }
>>>>>>             }
>>>>>>
>>>>>>             public static void main(String args[]) {
>>>>>>                 final int size = 3;
>>>>>>                 final PreciousPool pool = new PreciousPool(size, 5);
>>>>>>
>>>>>>                 // let's exhaust the pool
>>>>>>                 for (int i=0; i<size; i++)
>>>>>>         dump(pool.obtain());
>>>>>>
>>>>>>                 // and as we are stubborn we continuosly ask for
>>>>>>         a new one
>>>>>>                 while(true) {
>>>>>>         dump(pool.obtain());
>>>>>>                 }
>>>>>>             }
>>>>>>
>>>>>>             private static void dump(Precious precious) {
>>>>>>                 if (precious == null)
>>>>>>                     log("I did not get my precious :(");
>>>>>>                 else
>>>>>>                     log("I did get my precious! "+precious);
>>>>>>             }
>>>>>>
>>>>>>             private static void log(String message) {
>>>>>>                 final String now = new
>>>>>>         SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>>>>         System.out.println(now + message);
>>>>>>             }
>>>>>>         }
>>>>>>
>>>>>>         So, the main is a single thread (no need for
>>>>>>         multithreading here, let's keep it simple), that first
>>>>>>         exhaust the whole pool and then keep asking, without
>>>>>>         success, for a resource. Stubborn guy, I say, but it
>>>>>>         happens. If you run this program everything works as
>>>>>>         expected: you are greeted by a three successful Precious
>>>>>>         and then an endless list of failures, that it
>>>>>>         continuously grow. All good :)
>>>>>>
>>>>>>         02:34:40:0061 I did get my precious! Precious n.156
>>>>>>         02:34:40:0062 I did get my precious! Precious n.991
>>>>>>         02:34:40:0062 I did get my precious! Precious n.953
>>>>>>         02:34:45:0064 I did not get my precious :(
>>>>>>         02:34:50:0065 I did not get my precious :(
>>>>>>         02:34:55:0066 I did not get my precious :(
>>>>>>         02:35:00:0067 I did not get my precious :(
>>>>>>         02:35:05:0068 I did not get my precious :(
>>>>>>         [...]
>>>>>>
>>>>>>         But guess what happens when, while the program is
>>>>>>         running, I change the date of my system back of one hour?
>>>>>>         Everything stops,  it's simple as that. No prints,
>>>>>>         nothing, zero, nada. Now, If it wasn't so late, I would
>>>>>>         probably wait one hour in order to have my program
>>>>>>         restored to his normal process, but as a customer I won't
>>>>>>         be terribly happy :)
>>>>>>
>>>>>>         I hope my point is now clear.
>>>>>>         Cheers,
>>>>>>
>>>>>>             Bruno
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>         On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>>>>>         <oleksandr.otenko at oracle.com
>>>>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>
>>>>>>             n 04/09/2013 18:54, bruno bossola wrote:
>>>>>>>             Hi Oleksandr,
>>>>>>>
>>>>>>>                 Where in the design of those systems is a
>>>>>>>                 real-time timer? The one that delivers time
>>>>>>>                 events uncompromised even by GC latency?
>>>>>>>
>>>>>>>             I don't think so :) If somebody needs a real time
>>>>>>>             implementation he needs to go for a real time JVM,
>>>>>>>             like Jean correctly pointed out. The concurrency
>>>>>>>             primitives are depending on
>>>>>>>             LockSupport.parkNanos(...) to park a thread: if this
>>>>>>>             for any reason is not working (like it is) then
>>>>>>>             strange things may happen.
>>>>>>             Your assumption is that it is not working, if the
>>>>>>             elapsed time is longer. This is the flawed assumption.
>>>>>>
>>>>>>             Also, you need to read fine print on those "real
>>>>>>             time" JVMs. The catch is in the definition of "real
>>>>>>             time".
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>>             Imagine, for example, that you are using a
>>>>>>>             ReentrantLock to control a very precious resource
>>>>>>>             used across the board (what about a database
>>>>>>>             connection pool?) and you are unlucky enough to have
>>>>>>>             a system time change (backwards) while you are
>>>>>>>             locking: all the threads that want to use such
>>>>>>>             resource will be progressively locked: not forever,
>>>>>>>             but for the amount of time the clock went back.
>>>>>>>             Probably most (all?) of your system freezes, and the
>>>>>>>             only option you have is to wait, or restart.
>>>>>>>             Now place this in a large application server, that
>>>>>>>             provide services for hunreds (thousands) of users.
>>>>>>>             How does it sound to you?
>>>>>>             It sounds like you don't understand how the locks work.
>>>>>>
>>>>>>
>>>>>>             Alex
>>>>>>
>>>>>>
>>>>>>>
>>>>>>>             BTW, at the moment we could have a watchdog (in
>>>>>>>             Python :)) that restarts it, but, I dunno why, I
>>>>>>>             don't like it a lot...
>>>>>>>
>>>>>>>             Cheers,
>>>>>>>
>>>>>>>                 Bruno
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>             On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>>>>>             <oleksandr.otenko at oracle.com
>>>>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>>
>>>>>>>                 You are missing the point.
>>>>>>>
>>>>>>>                 Where in the design of those systems is a
>>>>>>>                 real-time timer? The one that delivers time
>>>>>>>                 events uncompromised even by GC latency?
>>>>>>>
>>>>>>>                 The whole concurrency lot does not depend on the
>>>>>>>                 timeout magnitude for correctness.
>>>>>>>
>>>>>>>                 Alex
>>>>>>>
>>>>>>>
>>>>>>>                 On 04/09/2013 12:05, bruno bossola wrote:
>>>>>>>>                 Hi David
>>>>>>>>
>>>>>>>>
>>>>>>>>                     bugs.sun.com <http://bugs.sun.com/> is not
>>>>>>>>                     a live reflection of the bug database but
>>>>>>>>                     gets updated periodically (every 12 hours I
>>>>>>>>                     think).
>>>>>>>>
>>>>>>>>
>>>>>>>>                 Good to know :) I will be eagerly clicking on
>>>>>>>>                 it to discover the new priority! Thanks for
>>>>>>>>                 that, I really appreciate it.
>>>>>>>>
>>>>>>>>
>>>>>>>>                     The issue arises on certain 64-bit linux
>>>>>>>>                     kernel/glibc versions. If you have an older
>>>>>>>>                     version this does not impact you.
>>>>>>>>
>>>>>>>>                 You saw my list: nobody will use an older
>>>>>>>>                 Kernel/glibc version in production.
>>>>>>>>
>>>>>>>>
>>>>>>>>                     As for the rest, show me real code in such
>>>>>>>>                     systems that rely on sleep for correctness
>>>>>>>>                     or performance/timeliness and I will show
>>>>>>>>                     you broken code.
>>>>>>>>
>>>>>>>>                 You are still hitting about the sleep(), I
>>>>>>>>                 understand and I agree about this. But here we
>>>>>>>>                 are not talking about sleeps: we are talking
>>>>>>>>                 about the whole concurrency lot. And yes, as I
>>>>>>>>                 already said, we are talking about near time
>>>>>>>>                 systems, like trading application, betting
>>>>>>>>                 applications, air traffic control systems, car
>>>>>>>>                 traffic control systems. Don't you think this
>>>>>>>>                 bug might place Oracle JVM outside of these
>>>>>>>>                 markets?
>>>>>>>>
>>>>>>>>
>>>>>>>>                     If this was as dire as you make out do you
>>>>>>>>                     not think that this issue would have been
>>>>>>>>                     raised far more than it has? [....] prudent
>>>>>>>>                     developers/companies trial platform
>>>>>>>>                     upgrades to check for these kinds of issues
>>>>>>>>                     before switching to them in production
>>>>>>>>                     environments.
>>>>>>>>
>>>>>>>>                 I am waiting now for the part where you say
>>>>>>>>                 that we should throw away Linux and use Oracle
>>>>>>>>                 Solaris :)  In all seriousness, there's a lot
>>>>>>>>                 of action "in the middle", and I think that
>>>>>>>>                 Oracle cannot oversee that. For example a lot
>>>>>>>>                 of trading software system can be installed on
>>>>>>>>                 premises, where you usually have no control
>>>>>>>>                 over the environment: what I would do is to put
>>>>>>>>                 a native daemon in my app so that if I see the
>>>>>>>>                 system clock change I would kill myself, just
>>>>>>>>                 in case. And this is a solution that I know for
>>>>>>>>                 a fact (sorry, I cannot make a reference) it's
>>>>>>>>                 used in production in a very important trading
>>>>>>>>                 application.
>>>>>>>>
>>>>>>>>                 Regarding that specific bug, it was not
>>>>>>>>                 accessible to the external until two days ago,
>>>>>>>>                 so I guess nobody really knew a lot about it,
>>>>>>>>                 but I will make sure it will :) so that we can
>>>>>>>>                 get more traction.
>>>>>>>>
>>>>>>>>                 Cheers,
>>>>>>>>
>>>>>>>>                     Bruno
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>                 On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>>>>>                 <davidcholmes at aapt.net.au
>>>>>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>
>>>>>>>>                     Bruno,
>>>>>>>>                     bugs.sun.com <http://bugs.sun.com/> is not
>>>>>>>>                     a live reflection of the bug database but
>>>>>>>>                     gets updated periodically (every 12 hours I
>>>>>>>>                     think).
>>>>>>>>                     The issue arises on certain 64-bit linux
>>>>>>>>                     kernel/glibc versions. If you have an older
>>>>>>>>                     version this does not impact you.
>>>>>>>>                     As for the rest, show me real code in such
>>>>>>>>                     systems that rely on sleep for correctness
>>>>>>>>                     or performance/timelinessand I will show
>>>>>>>>                     you broken code. We are not talking about
>>>>>>>>                     real-time systemshere.
>>>>>>>>                     park(nanos)/wait(millis) will only be
>>>>>>>>                     affected by the backward time change if the
>>>>>>>>                     real notification they are waiting for does
>>>>>>>>                     not happen. Timeouts with these APIs are
>>>>>>>>                     heuristics, they are defensive programming
>>>>>>>>                     to cover the case "what if the notification
>>>>>>>>                     I'm waiting for does not come". The code
>>>>>>>>                     that would be affected by this issue is a
>>>>>>>>                     very small % of the code that uses the API.
>>>>>>>>                     If this was as dire as you make out do you
>>>>>>>>                     not think that this issue would have been
>>>>>>>>                     raised far more than it has? This issue
>>>>>>>>                     does need addressing because the number of
>>>>>>>>                     affected systems will grow as these newer
>>>>>>>>                     linux systems are adopted, but prudent
>>>>>>>>                     developers/companies trial platform
>>>>>>>>                     upgrades to check for these kinds of issues
>>>>>>>>                     before swicthing to them in production
>>>>>>>>                     environments.
>>>>>>>>                     Regards,
>>>>>>>>                     David
>>>>>>>>
>>>>>>>>                         -----Original Message-----
>>>>>>>>                         *From:* bruno bossola
>>>>>>>>                         [mailto:bbossola at gmail.com
>>>>>>>>                         <mailto:bbossola at gmail.com>]
>>>>>>>>                         *Sent:* Wednesday, 4 September 2013
>>>>>>>>                         11:14 AM
>>>>>>>>                         *To:* dholmes at ieee.org
>>>>>>>>                         <mailto:dholmes at ieee.org>
>>>>>>>>                         *Cc:*
>>>>>>>>                         concurrency-interest at cs.oswego.edu
>>>>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>>>>                         Outstanding concurrency JVM issue -
>>>>>>>>                         feedback?
>>>>>>>>
>>>>>>>>                         Hi David,
>>>>>>>>
>>>>>>>>                         thanks for following up.
>>>>>>>>
>>>>>>>>                             I have raised the priority on 6900441
>>>>>>>>
>>>>>>>>                         Thanks, but it looks still like a P4:
>>>>>>>>                         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>>>>                         See also the attached snapshot, just in
>>>>>>>>                         case it changes :)
>>>>>>>>
>>>>>>>>                         Inline image 2
>>>>>>>>
>>>>>>>>                             [...] which to my knowledge [...]
>>>>>>>>                             has never been a private bug
>>>>>>>>
>>>>>>>>                         It was not accessible using
>>>>>>>>                         bugs.sun.com <http://bugs.sun.com/>,
>>>>>>>>                         this was translated to private. I also
>>>>>>>>                         received the same info indirectly from
>>>>>>>>                         the 7u lead:
>>>>>>>>                         "I'm not sure why 6900441 isn't public.
>>>>>>>>                         (I'll follow up with owner of
>>>>>>>>                         bugs.sun.com <http://bugs.sun.com/>)",
>>>>>>>>                         I guess you can check with him.
>>>>>>>>
>>>>>>>>
>>>>>>>>                             It doesn't affect "every JVM64
>>>>>>>>                             running on Linux64".  A fix has
>>>>>>>>                             been introduced into a specific
>>>>>>>>                             glibc version...
>>>>>>>>
>>>>>>>>                         ...and apparently did not make it. I
>>>>>>>>                         was able to reproduce this even with
>>>>>>>>                         the IBM VM, so to speak. I tried JDK6,
>>>>>>>>                         JDK7, JDK8 on Ubuntu 10, 11, 12, 13 +
>>>>>>>>                         some random Debian. I did not have a
>>>>>>>>                         JDK5, so I cannot say, but on JDK4
>>>>>>>>                         everything works (that's the reason why
>>>>>>>>                         I call it a regression). (ah, if you
>>>>>>>>                         look at the bug, it lists also JDK5, so
>>>>>>>>                         I think we are pretty much covered here).
>>>>>>>>                         If you still have doubts tough, please
>>>>>>>>                         have also a look on stackoverflow to
>>>>>>>>                         see how it was reproduced consistently
>>>>>>>>                         on probably every 64bitJVM over
>>>>>>>>                         64bitLinux in the world.
>>>>>>>>
>>>>>>>>
>>>>>>>>                             The effects of this is not that
>>>>>>>>                             "all the threads parked will hang,
>>>>>>>>                             with
>>>>>>>>                             unpredictable/corrupted/useless"!
>>>>>>>>                             The effects are very simple an
>>>>>>>>                             quite predictable... [deletia]s.
>>>>>>>>
>>>>>>>>                         We have very different views, and I
>>>>>>>>                         find quite difficult to accept yours.
>>>>>>>>                         You are confusing my sample program
>>>>>>>>                         which contains a single thread in a for
>>>>>>>>                         loop with any other complex
>>>>>>>>                         multi-threading concurrent system
>>>>>>>>                         written in Java. For example, if you
>>>>>>>>                         ever worked in a bank you surely know
>>>>>>>>                         what I mean. You are comparing some
>>>>>>>>                         random sleep() put into a program by
>>>>>>>>                         some newbie, with the complex ecosystem
>>>>>>>>                         of a concurrent platform written to
>>>>>>>>                         manage trading information on very fast
>>>>>>>>                         market. In that condition, I am sorry,
>>>>>>>>                         statements such "...delayed timeout
>>>>>>>>                         does not affect operation in a
>>>>>>>>                         correctly functioning system..." and
>>>>>>>>                         "...small time changes [...] are not a
>>>>>>>>                         problem" are really not applicable. Let
>>>>>>>>                         your system place an order three
>>>>>>>>                         seconds late and your are out of the
>>>>>>>>                         door so quickly you cannot even realize it.
>>>>>>>>
>>>>>>>>                         But let's not limit ourselves to banks:
>>>>>>>>                         how do you think your previous
>>>>>>>>                         statements stands in these scenarios?
>>>>>>>>                         - air control systems
>>>>>>>>                         <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>>>>                         about a few seconds delay in control
>>>>>>>>                         when fying planes?)
>>>>>>>>                         - city traffic control systems
>>>>>>>>                         <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>>>>                         if just for a couple of seconds all
>>>>>>>>                         traffic lights become green?)
>>>>>>>>
>>>>>>>>                         Not good enough.
>>>>>>>>
>>>>>>>>
>>>>>>>>                             ...small time changes as typically
>>>>>>>>                             done via NTP
>>>>>>>>
>>>>>>>>                         NTP is only one of the possible sources
>>>>>>>>                         of this problem. The root of it is that
>>>>>>>>                         the JVM is counting nanoseconds delays
>>>>>>>>                         using absolute values based on a
>>>>>>>>                         wallclock: I do not think it's that smart.
>>>>>>>>
>>>>>>>>
>>>>>>>>                             So there is an issue that needs to
>>>>>>>>                             be addressed but the situation is
>>>>>>>>                             nowhere near as dire as you make out
>>>>>>>>
>>>>>>>>                         Let's try to put this in perspective,
>>>>>>>>                         shall we? In case the clock run
>>>>>>>>                         backwards LockSupport.park() will be
>>>>>>>>                         waiting for the nanoseconds requested
>>>>>>>>                         plus the amount of
>>>>>>>>                         seconds/minute/hours/days requested to
>>>>>>>>                         compensate. Now, this primitive is used
>>>>>>>>                         by almost *every* concurrency construct
>>>>>>>>                         available on the platform, such as
>>>>>>>>                         AbstractQueuedSynchronizer (and
>>>>>>>>                         subclasses), ReentrantLock (and
>>>>>>>>                         subclasses), CyclicBarrier,
>>>>>>>>                         BlockingQueue (and subclasses),
>>>>>>>>                         Executors, FutureTask, .... (too long
>>>>>>>>                         to list them all, but I think we have
>>>>>>>>                         the picture) and also low levels
>>>>>>>>                         synchronization primitives of the
>>>>>>>>                         language itself, so Object::wait(:long)
>>>>>>>>                         and the related sychronized blocks.
>>>>>>>>
>>>>>>>>                         I think it's pretty dire.
>>>>>>>>
>>>>>>>>
>>>>>>>>                         Cheers,
>>>>>>>>
>>>>>>>>                             Bruno
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>                         On Wed, Sep 4, 2013 at 12:14 AM, David
>>>>>>>>                         Holmes <davidcholmes at aapt.net.au
>>>>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>
>>>>>>>>                             Hi Bruno,
>>>>>>>>                             I have raised the priority on
>>>>>>>>                             6900441 (which to my knowledge -
>>>>>>>>                             and I created it! - has never been
>>>>>>>>                             a private bug).
>>>>>>>>                             A few notes on the "very
>>>>>>>>                             frightening" aspect of this:
>>>>>>>>                             1. It doesn't affect "every JVM64
>>>>>>>>                             running on Linux64". A fix has been
>>>>>>>>                             introduced into a specific glibc
>>>>>>>>                             version for the futex-wait code
>>>>>>>>                             such that it now responds to
>>>>>>>>                             changes in the system time for
>>>>>>>>                             absolute waits, where for all the
>>>>>>>>                             years previous it did not. The fix
>>>>>>>>                             seems to have been applied in late
>>>>>>>>                             2011 or early 2012 but I don't know
>>>>>>>>                             the exact glibc version. There is
>>>>>>>>                             also a 32-bit version of the fix
>>>>>>>>                             that was proposed on Nov 27, 2012,
>>>>>>>>                             so it will eventually make its way
>>>>>>>>                             into 32-bit linux too.
>>>>>>>>                             2. The effects of this is not that
>>>>>>>>                             "all the threads parked will hang,
>>>>>>>>                             with
>>>>>>>>                             unpredictable/corrupted/useless"!
>>>>>>>>                             The effects are very simple an
>>>>>>>>                             quite predictable. If the system
>>>>>>>>                             time goes forward then timed-waits
>>>>>>>>                             (Object.wait,
>>>>>>>>                             LockSupport.park) (which should be
>>>>>>>>                             relative times) will return early
>>>>>>>>                             as the absolute-time that the
>>>>>>>>                             relative time was converted to will
>>>>>>>>                             be seen to have been reached
>>>>>>>>                             (Thread.sleep contains a guard
>>>>>>>>                             against early returns). This is not
>>>>>>>>                             actually a problem as you can not
>>>>>>>>                             distinguish this case from a
>>>>>>>>                             "spurious wakeup" which code is
>>>>>>>>                             supposed to account for. If the
>>>>>>>>                             time is changed backwards then
>>>>>>>>                             these timed-waits & sleeps will not
>>>>>>>>                             timeout when expected as the the
>>>>>>>>                             for that is now further in the
>>>>>>>>                             future, by the amount of the
>>>>>>>>                             backward time change. Hence small
>>>>>>>>                             time changes as typically done via
>>>>>>>>                             NTP are NOT a problem. Timed-waits
>>>>>>>>                             use timeouts as a heuristics for
>>>>>>>>                             recovering when the expected real
>>>>>>>>                             event notification does not occur -
>>>>>>>>                             so a delayed timeout does not
>>>>>>>>                             affect operation in a correctly
>>>>>>>>                             functioning system. Early timeouts
>>>>>>>>                             are indistinguishable from spurious
>>>>>>>>                             wakeups, which code has to account
>>>>>>>>                             for, so again not a problem for
>>>>>>>>                             regular code. The only time a
>>>>>>>>                             significant "hang" will occur is
>>>>>>>>                             with Thread.sleep and a large
>>>>>>>>                             backward time shift - but there is
>>>>>>>>                             little real code that uses
>>>>>>>>                             Thread.sleep in any critical way.
>>>>>>>>                             So there is an issue that needs to
>>>>>>>>                             be addressed but the situation is
>>>>>>>>                             nowhere near as dire as you make out.
>>>>>>>>                             David Holmes
>>>>>>>>
>>>>>>>>                                 -----Original Message-----
>>>>>>>>                                 *From:*
>>>>>>>>                                 concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>>>                                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>>>>>                                 Behalf Of *bruno bossola
>>>>>>>>                                 *Sent:* Wednesday, 4 September
>>>>>>>>                                 2013 1:56 AM
>>>>>>>>                                 *To:*
>>>>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>                                 *Subject:*
>>>>>>>>                                 [concurrency-interest]
>>>>>>>>                                 Outstanding concurrency JVM
>>>>>>>>                                 issue - feedback?
>>>>>>>>
>>>>>>>>                                 Hi all,
>>>>>>>>
>>>>>>>>                                 I am writing here following a
>>>>>>>>                                 suggestion by Ben Evans. I
>>>>>>>>                                 wanted to check with you about
>>>>>>>>                                 an issue that my teams found on
>>>>>>>>                                 the JVM and that's very
>>>>>>>>                                 frightening. I already started
>>>>>>>>                                 the discussion with the
>>>>>>>>                                 engineers of the hotspot VM
>>>>>>>>                                 team but it looks like we need
>>>>>>>>                                 more awareness to solve this
>>>>>>>>                                 one and I'd really appreciate
>>>>>>>>                                 some help and some push :)
>>>>>>>>                                 It looks to me that this issue
>>>>>>>>                                 is affecting every JVM64
>>>>>>>>                                 running on Linux64, so imho
>>>>>>>>                                 it's quite important to be
>>>>>>>>                                 looked at.
>>>>>>>>
>>>>>>>>                                 *Executive summary
>>>>>>>>                                 *The implementation of the
>>>>>>>>                                 concurrency primitive
>>>>>>>>                                 LockSupport.parkNanos(), the
>>>>>>>>                                 function that controls most
>>>>>>>>                                 concurrency primitive on the
>>>>>>>>                                 JVM, is flawed, and any NTP
>>>>>>>>                                 sync, or system time change,
>>>>>>>>                                 can potentially break it with
>>>>>>>>                                 unexpected results across the
>>>>>>>>                                 board.
>>>>>>>>
>>>>>>>>                                 *What we need to do?
>>>>>>>>                                 *This is an old issue, and the
>>>>>>>>                                 bug
>>>>>>>>                                 <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>>>>>                                 was declared private. I somehow
>>>>>>>>                                 managed to have the bug
>>>>>>>>                                 reopened to the public, but
>>>>>>>>                                 it's still a  P4, that means
>>>>>>>>                                 that probably won't be fixed. I
>>>>>>>>                                 think we need to push for a
>>>>>>>>                                 resolution ASAP, be sure that's
>>>>>>>>                                 in for JDK9, make all the
>>>>>>>>                                 possible effort to make this
>>>>>>>>                                 fix for JDK8 or, at least, to
>>>>>>>>                                 include it in a later patch
>>>>>>>>                                 release. In an ideal world it
>>>>>>>>                                 would be nice to have a patch
>>>>>>>>                                 for JDK7. As far as I
>>>>>>>>                                 understand the hotspot
>>>>>>>>                                 engineering team works based on
>>>>>>>>                                 priorities: being this
>>>>>>>>                                 qualified as P4 means it won't
>>>>>>>>                                 be probably worked on (if you
>>>>>>>>                                 follow the breadcrumbs of bugs
>>>>>>>>                                 and fixes you can go back to
>>>>>>>>                                 2002!) They acknowledge the
>>>>>>>>                                 problem, it has been flagged to
>>>>>>>>                                 management, but 1) it's low
>>>>>>>>                                 priority 2) it's too risky to
>>>>>>>>                                 fix for JDK8
>>>>>>>>
>>>>>>>>
>>>>>>>>                                 *Why all this urgency?
>>>>>>>>                                 *If a system time change
>>>>>>>>                                 happens then all the threads
>>>>>>>>                                 parked will hang, with
>>>>>>>>                                 unpredictable/corrupted/useless
>>>>>>>>                                 results to the end user. Same
>>>>>>>>                                 applies to Future, Queue,
>>>>>>>>                                 Executor, and (I guess) any
>>>>>>>>                                 other construct that it's
>>>>>>>>                                 somehow related to concurrency.
>>>>>>>>                                 This is a big issue for us and
>>>>>>>>                                 for any near time application:
>>>>>>>>                                 please think about trading and
>>>>>>>>                                 betting, where the JVM is
>>>>>>>>                                 largely used, and  do not
>>>>>>>>                                 restrain yourself to the Java
>>>>>>>>                                 language: add Scala and any
>>>>>>>>                                 other JVM-based language to the
>>>>>>>>                                 picture (JRuby, Jython...)
>>>>>>>>
>>>>>>>>                                 *Tech details**
>>>>>>>>                                 *To be more clear about the
>>>>>>>>                                 issue, the extent of it and the
>>>>>>>>                                 concurrency library, let me
>>>>>>>>                                 introduce this very simple program:
>>>>>>>>
>>>>>>>>                                 import
>>>>>>>>                                 java.util.concurrent.locks.LockSupport;
>>>>>>>>
>>>>>>>>                                 public class Main {
>>>>>>>>
>>>>>>>>                                     public static void
>>>>>>>>                                 main(String[] args) {
>>>>>>>>
>>>>>>>>                                         for (int i=100; i>0; i--) {
>>>>>>>>                                 System.out.println(i);
>>>>>>>>                                 LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>>>                                         }
>>>>>>>>
>>>>>>>>                                 System.out.println("Done!");
>>>>>>>>                                     }
>>>>>>>>                                 }
>>>>>>>>
>>>>>>>>                                 Run it with a 64bit 1.6+ JVM on
>>>>>>>>                                 64bit Linux, turn the clock
>>>>>>>>                                 down one hour and wait until
>>>>>>>>                                 the counter stops... magic!  I
>>>>>>>>                                 tested this on JDK6, JDK7 and
>>>>>>>>                                 latest JDK8 beta running on
>>>>>>>>                                 various Ubuntu distros. It's
>>>>>>>>                                 not just a matter of (old?)
>>>>>>>>                                 sleep() and wait() primitives,
>>>>>>>>                                 this issue it affects the whole
>>>>>>>>                                 concurrency library.
>>>>>>>>
>>>>>>>>                                 To prove that this is fixable,
>>>>>>>>                                 I reimplemented the program
>>>>>>>>                                 above above substituting
>>>>>>>>                                 LockSupport.parkNanos() with  a
>>>>>>>>                                 JNI call to
>>>>>>>>                                 clock_nanosleep(CLOCK_MONOTONIC...):
>>>>>>>>                                 works like a charm :(
>>>>>>>>
>>>>>>>>                                 This is due to the fact  that
>>>>>>>>                                 the CPP code is calling the
>>>>>>>>                                 pthread_cond_timedwait() using
>>>>>>>>                                 its default clock
>>>>>>>>                                 (CLOCK_REALTIME) which,
>>>>>>>>                                 unfortunately is affected by
>>>>>>>>                                 settime()/settimeofday() calls
>>>>>>>>                                 (on Linux): for that reason it
>>>>>>>>                                 cannot be used to measure
>>>>>>>>                                 nanoseconds delays, which is
>>>>>>>>                                 what the specification
>>>>>>>>                                 <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>>>>>                                 requires. CLOCK_REALTIME is not
>>>>>>>>                                 guaranteed to monotonically
>>>>>>>>                                 count as this is the actual
>>>>>>>>                                 "system time": each time my
>>>>>>>>                                 system syncs time using a NTP
>>>>>>>>                                 server on the net, the time
>>>>>>>>                                 might jump forward or backward.
>>>>>>>>                                 The correct call (again on
>>>>>>>>                                 Linux)  would require to use
>>>>>>>>                                 CLOCK_MONOTONIC as clock id,
>>>>>>>>                                 which are defined by POSIX
>>>>>>>>                                 specs since 2002. (or better
>>>>>>>>                                 CLOCK_MONOTONIC_RAW)
>>>>>>>>
>>>>>>>>                                 The POSIX spec
>>>>>>>>                                 <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>>>>>                                 is infact clear, as it states
>>>>>>>>                                 "...setting the value of the
>>>>>>>>                                 CLOCK_REALTIME clock via
>>>>>>>>                                 clock_settime() shall have no
>>>>>>>>                                 effect on threads that are
>>>>>>>>                                 blocked waiting for a
>>>>>>>>                                 *relative* time service based
>>>>>>>>                                 upon this clock...": it
>>>>>>>>                                 definitely states "relative".
>>>>>>>>                                 Having a look at the hotspot
>>>>>>>>                                 code
>>>>>>>>                                 <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>>>>                                 it appears that the park() is
>>>>>>>>                                 using compute_abstime() (which
>>>>>>>>                                 uses timeofday) and then waits
>>>>>>>>                                 on an absolute period: for that
>>>>>>>>                                 reason it's influenced by the
>>>>>>>>                                 system clock change. *Very wrong*.
>>>>>>>>
>>>>>>>>                                 I will be happy to know what
>>>>>>>>                                 you think, and if you can help
>>>>>>>>                                 me to escalate this issue I
>>>>>>>>                                 think that the all Java
>>>>>>>>                                 community will benefit from it.
>>>>>>>>
>>>>>>>>                                 Cheers,
>>>>>>>>
>>>>>>>>                                     Bruno
>>>>>>>>
>>>>>>>>
>>>>>>>>                         No virus found in this message.
>>>>>>>>                         Checked by AVG - www.avg.com
>>>>>>>>                         <http://www.avg.com/>
>>>>>>>>                         Version: 2013.0.3392 / Virus Database:
>>>>>>>>                         3222/6633 - Release Date: 09/03/13
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>                 _______________________________________________
>>>>>>>>                 Concurrency-interest mailing list
>>>>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>>     _______________________________________________
>>>>     Concurrency-interest mailing list
>>>>     Concurrency-interest at cs.oswego.edu
>>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>
>>>> -- 
>>>> *Viktor Klang*
>>>> /Director of Engineering/
>>>> Typesafe <http://www.typesafe.com/>
>>>>
>>>> Twitter: @viktorklang
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu 
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> --
>> [scala-debate on 2009/10/2]
>> Viktor Klang: When will the days of numerical overflow be gone?
>> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/ec4bfc43/attachment-0001.html>

From rk at rkuhn.info  Thu Sep  5 15:41:39 2013
From: rk at rkuhn.info (Roland Kuhn)
Date: Thu, 5 Sep 2013 21:41:39 +0200
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <5228D734.2050703@oracle.com>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
	<5228C351.4070009@oracle.com>
	<966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>
	<5228D081.9040705@oracle.com> <5228D734.2050703@oracle.com>
Message-ID: <256C5E34-4581-411F-BA35-31FD8360AD2F@rkuhn.info>

Hi Alex,

I do not understand why you argue about time moving forwards and backwards: as I said this is not about wall time at all, it is about (idealized) cycle counts of the CPU (for example). And these always increase, they never go backwards (*). The discussion is also not about delivering events at nanosecond resolution on the JVM, everybody understands that that is never going to work. What is being discussed is the difference between arbitrary and reasonable behavior, where the former is allowed by the spec and the latter is expected implicitly of a high-quality piece of engineering. Today?s computers as used by end-users usually are responsive on the millisecond scale, with glitches ranging in the low seconds?that is what people are used to and what they expect. Delivering a wake-up 1h late?especially when the system itself is working fine?is definitely outside of the expected range on such systems.

Regards,

Roland

(*) yes, I know there were unsynchronized multi-socket systems where switching to a different CPU would have that effect, but those bugs have been fixed

5 sep 2013 kl. 21:10 skrev Oleksandr Otenko:

> The main point here is how to guarantee arrival of nanosecond resolution of events in a environment where we cannot guarantee reasonably-forward movement of time. Bruno showed a dummy case where he was moving the clock 1 hour away. Is this what he sees in his real environment? How does he justify the use of environment with such unreliable source of time? Do we know that environment will deliver nanosecond-time events reliably? Will they be spaced 1 ns from each other? (From what I recall, in some virtualization envs some JVMs reported the time go back, when it shouldn't. Yet, even the fix was only as perfect as the clock update delivery in that virtualization solution. If we are meant to catch up on 200 microseconds, will it deliver in a salvo, or add a corrective microsecond on 200 subsequent seconds?)
> 
> 
> If we talk about a different environment, eg VM with wall clock moving a few hundred ms back and forth, it becomes a problem of a very different magnitude. The question of timely arrival of events is still there, but even with that part unanswered, a few hundred ms drift in a pause will not be fine for banking or betting, nearly exclusively. Then the question is still why choose environments like that to run applications that are so sensitive?
> 
> 
> Alex
> 
> 
> On 05/09/2013 19:42, Oleksandr Otenko wrote:
>> On 05/09/2013 19:15, Roland Kuhn wrote:
>>> 
>>> 5 sep 2013 kl. 19:45 skrev Oleksandr Otenko:
>>> 
>>>> Exactly my point.
>>>> 
>>>> Now someone needs to take care of negative time returned, when the clock goes back, even if the wait was shorter than timeout.
>>> 
>>> Why would that lead to a negative return value?
>> 
>> Depending on how you work out the elapsed time, of course.
>> 
>>>> Or, if we report the actual time waited, then deal with the inconsistency between apparent System.nanoTime() and the wait.
>>> 
>>> There are two very different time sources in the JVM, and the one which has ?nano? in its name is supposed to be monotonic and independent of the system?s wall time clock. I share Bruno?s view that a method called awaitNanos() should measure time using System.nanoTime and not with System.currentTimeMillis (conceptually). It is unfortunate that the API docs of awaitNanos() do not specify which of these choices was made.
>> 
>> Conceptually awaitNanos() returns timeout-elapsedTime. How will System.nanoTime() work out the elapsed time in nanoseconds after suspend-modify wall clock-resume? Who tells it how many nanoseconds were missed?
>> 
>> Alex
>> 
>> 
>>> 
>>> Regards,
>>> 
>>> Roland
>>> 
>>>> 
>>>> Alex
>>>> 
>>>> On 05/09/2013 18:31, ?iktor ?lang wrote:
>>>>> For Condition.awaitNanos it states:
>>>>> 
>>>>> Returns:
>>>>> an estimate of the nanosTimeout value minus the time spent waiting upon return from this method. A positive value may be used as the argument to a subsequent call to this method to finish waiting out the desired time. A value less than or equal to zero indicates that no time remains.
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>>>> Oh, and now someone else is going to complain that awaitNanos returns a negative number, even though it waited for only 1 ms out of 100.
>>>>> 
>>>>> Alex
>>>>> 
>>>>> On 05/09/2013 17:50, bruno bossola wrote:
>>>>>> I am sorry but I really cannot spend more time creating more samples and I am quite sure you could do a better work at that! At the moment to me that matter is clear enough, but feel free to ask, I will very happy to help! In the meantime I prefer spend my time to work on a patch that I can apply on my JVMs :)
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>>     Bruno
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>>>>> This is far from reproducing the problem with arbitrary j.u.c locks and queues hanging.
>>>>>> 
>>>>>> Condition.awaitNanos can return a negative value. If you are expecting the negative value to be small, then how small do you expect it to be?
>>>>>> 
>>>>>> 
>>>>>> Alex
>>>>>> 
>>>>>> 
>>>>>> On 05/09/2013 02:12, bruno bossola wrote:
>>>>>>> Hi Oaleksandr,
>>>>>>> 
>>>>>>> Please apologize me if my english was not good enough to provide you an example that make sense: for that reason I decided to go back to a binary deliverable (code) that shows the problem, hope this helps!
>>>>>>> 
>>>>>>> This is my PreciousPool class, that handles Precious resources:
>>>>>>> 
>>>>>>> import java.text.SimpleDateFormat;
>>>>>>> import java.util.ArrayList;
>>>>>>> import java.util.Date;
>>>>>>> import java.util.List;
>>>>>>> import java.util.concurrent.TimeUnit;
>>>>>>> import java.util.concurrent.locks.Condition;
>>>>>>> import java.util.concurrent.locks.Lock;
>>>>>>> import java.util.concurrent.locks.ReentrantLock;
>>>>>>> 
>>>>>>> public class PreciousPool {
>>>>>>>     
>>>>>>>     public static class Precious {
>>>>>>>         private final int id;
>>>>>>> 
>>>>>>>         private Precious() {
>>>>>>>             this.id = 100+(int)(Math.random()*900.0);
>>>>>>>         }
>>>>>>> 
>>>>>>>         public String toString() {
>>>>>>>             return "Precious n."+id;
>>>>>>>         }
>>>>>>>     }
>>>>>>>     
>>>>>>>     private final Lock lock;
>>>>>>>     private final Condition ready;
>>>>>>>     private final long timeoutInMillis;
>>>>>>> 
>>>>>>>     private final List<Precious> preciousLended;
>>>>>>>     private final List<Precious> preciousAvailable;
>>>>>>>     
>>>>>>>     public PreciousPool(int size, long timeoutInSeconds) {
>>>>>>>         this.lock = new ReentrantLock();
>>>>>>>         this.ready = lock.newCondition();
>>>>>>> 
>>>>>>>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>>>>>         this.preciousLended =  new ArrayList<Precious>();
>>>>>>>         this.preciousAvailable = new ArrayList<Precious>();
>>>>>>> 
>>>>>>>         for (int i = 0; i < size; i++) {
>>>>>>>             preciousAvailable.add(new Precious());
>>>>>>>         }
>>>>>>>     }
>>>>>>>     
>>>>>>>     public Precious obtain()  {
>>>>>>>         lock.lock();
>>>>>>>         try {
>>>>>>>             // if no precious are available we wait for the specified timeout (releasing the lock so that others can try)
>>>>>>>             if (preciousAvailable.size() == 0) {
>>>>>>>                 try {
>>>>>>>                     ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>>>>>                 } catch (InterruptedException e) {
>>>>>>>                     Thread.currentThread().interrupt();
>>>>>>>                     throw new RuntimeException("Somebody interrupted me!", e);
>>>>>>>                 }
>>>>>>>             }
>>>>>>>             
>>>>>>>             // if a precious is available we unload it and return to the caller, otherwise null
>>>>>>>             if (preciousAvailable.size() > 0) {
>>>>>>>                 Precious value = preciousAvailable.remove(0);
>>>>>>>                 preciousLended.add(value);
>>>>>>>                 return value;
>>>>>>>             } else {
>>>>>>>                 return null;
>>>>>>>             }
>>>>>>>         } finally {
>>>>>>>             lock.unlock();
>>>>>>>         }
>>>>>>>     }
>>>>>>> 
>>>>>>>     public void release(Precious value) {
>>>>>>>         lock.lock();
>>>>>>>         try {
>>>>>>>             if (!preciousLended.remove(value))
>>>>>>>                 throw new RuntimeException("Element "+value+" was not lended!");
>>>>>>>             
>>>>>>>             // if a precious is returned we put it back and signal to anybody waiting
>>>>>>>             preciousAvailable.add(value);
>>>>>>>             ready.signalAll();
>>>>>>>         } finally {
>>>>>>>             lock.unlock();
>>>>>>>         }
>>>>>>>     }
>>>>>>>     
>>>>>>>     public static void main(String args[]) {
>>>>>>>         final int size = 3;
>>>>>>>         final PreciousPool pool = new PreciousPool(size, 5);
>>>>>>> 
>>>>>>>         // let's exhaust the pool
>>>>>>>         for (int i=0; i<size; i++)
>>>>>>>             dump(pool.obtain());
>>>>>>> 
>>>>>>>         // and as we are stubborn we continuosly ask for a new one
>>>>>>>         while(true) {
>>>>>>>             dump(pool.obtain());
>>>>>>>         }
>>>>>>>     }
>>>>>>> 
>>>>>>>     private static void dump(Precious precious) {
>>>>>>>         if (precious == null)
>>>>>>>             log("I did not get my precious :(");
>>>>>>>         else
>>>>>>>             log("I did get my precious! "+precious);
>>>>>>>     }
>>>>>>> 
>>>>>>>     private static void log(String message) {
>>>>>>>         final String now = new SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>>>>>         System.out.println(now + message);
>>>>>>>     }
>>>>>>> }
>>>>>>> 
>>>>>>> So, the main is a single thread (no need for multithreading here, let's keep it simple), that first exhaust the whole pool and then keep asking, without success, for a resource. Stubborn guy, I say, but it happens. If you run this program everything works as expected: you are greeted by a three successful Precious and then an endless list of failures, that it continuously grow. All good :) 
>>>>>>> 
>>>>>>> 02:34:40:0061 I did get my precious! Precious n.156
>>>>>>> 02:34:40:0062 I did get my precious! Precious n.991
>>>>>>> 02:34:40:0062 I did get my precious! Precious n.953
>>>>>>> 02:34:45:0064 I did not get my precious :(
>>>>>>> 02:34:50:0065 I did not get my precious :(
>>>>>>> 02:34:55:0066 I did not get my precious :(
>>>>>>> 02:35:00:0067 I did not get my precious :(
>>>>>>> 02:35:05:0068 I did not get my precious :(
>>>>>>> [...]
>>>>>>> 
>>>>>>> But guess what happens when, while the program is running, I change the date of my system back of one hour? Everything stops,  it's simple as that. No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably wait one hour in order to have my program restored to his normal process, but as a customer I won't be terribly happy :)
>>>>>>> 
>>>>>>> I hope my point is now clear.
>>>>>>> Cheers,
>>>>>>> 
>>>>>>>     Bruno
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>    
>>>>>>> 
>>>>>>> 
>>>>>>> On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>>>>>> n 04/09/2013 18:54, bruno bossola wrote:
>>>>>>>> Hi Oleksandr,
>>>>>>>> 
>>>>>>>> Where in the design of those systems is a real-time timer? The one that delivers time events uncompromised even by GC latency?
>>>>>>>>  
>>>>>>>> I don't think so :) If somebody needs a real time implementation he needs to go for a real time JVM, like Jean correctly pointed out.  The concurrency primitives are depending on LockSupport.parkNanos(...) to park a thread: if this for any reason is not working (like it is) then strange things may happen.
>>>>>>> Your assumption is that it is not working, if the elapsed time is longer. This is the flawed assumption.
>>>>>>> 
>>>>>>> Also, you need to read fine print on those "real time" JVMs. The catch is in the definition of "real time".
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>> Imagine, for example, that you are using a ReentrantLock to control a very precious resource used across the board (what about a database connection pool?) and you are unlucky enough to have a system time change (backwards) while you are locking: all the threads that want to use such resource will be progressively locked: not forever, but for the amount of time the clock went back. Probably most (all?) of your system freezes, and the only option you have is to wait, or restart. 
>>>>>>>> Now place this in a large application server, that provide services for hunreds (thousands) of users. How does it sound to you?
>>>>>>> It sounds like you don't understand how the locks work.
>>>>>>> 
>>>>>>> 
>>>>>>> Alex
>>>>>>> 
>>>>>>> 
>>>>>>>> 
>>>>>>>> BTW, at the moment we could have a watchdog (in Python :)) that restarts it, but, I dunno why, I don't like it a lot...
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> 
>>>>>>>>     Bruno
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
>>>>>>>> You are missing the point.
>>>>>>>> 
>>>>>>>> Where in the design of those systems is a real-time timer? The one that delivers time events uncompromised even by GC latency?
>>>>>>>> 
>>>>>>>> The whole concurrency lot does not depend on the timeout magnitude for correctness.
>>>>>>>> 
>>>>>>>> Alex
>>>>>>>> 
>>>>>>>> 
>>>>>>>> On 04/09/2013 12:05, bruno bossola wrote:
>>>>>>>>> Hi David
>>>>>>>>>  
>>>>>>>>> 
>>>>>>>>> bugs.sun.com is not a live reflection of the bug database but gets updated periodically (every 12 hours I think).
>>>>>>>>>   
>>>>>>>>> Good to know :) I will be eagerly clicking on it to discover the new priority! Thanks for that, I really appreciate it.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you have an older version this does not impact you.
>>>>>>>>>  
>>>>>>>>> You saw my list: nobody will use an older Kernel/glibc version in production.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> As for the rest, show me real code in such systems that rely on sleep for correctness or performance/timeliness and I will show you broken code.
>>>>>>>>>  
>>>>>>>>> You are still hitting about the sleep(), I understand and I agree about this. But here we are not talking about sleeps: we are talking about the whole concurrency lot. And yes, as I already said, we are talking about near time systems, like trading application, betting applications, air traffic control                                                           systems, car traffic control systems. Don't you think this bug might place Oracle JVM outside of these markets?
>>>>>>>>> 
>>>>>>>>>  
>>>>>>>>> If this was as dire as you make out do you not think that this issue would have been raised far more than it has? [....] prudent developers/companies trial platform upgrades to check for these kinds of issues before switching to them in production environments.
>>>>>>>>> 
>>>>>>>>> I am waiting now for the part where you say that we should throw away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of action "in the middle", and I think that Oracle cannot oversee that. For example a lot of trading software system can be installed on premises, where you usually have no control over the environment: what I would do is to put a native daemon in my app so that if I see the system clock change I would kill myself, just in case. And this is a solution that I know for a fact (sorry, I cannot make a reference) it's used in production in a very important trading application.
>>>>>>>>> 
>>>>>>>>> Regarding that specific bug, it was not accessible to the external until two days ago, so I guess nobody really knew a lot about it, but I will make sure it will :) so that we can get more traction.
>>>>>>>>> 
>>>>>>>>> Cheers,
>>>>>>>>> 
>>>>>>>>>     Bruno
>>>>>>>>>  
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On Wed, Sep 4, 2013 at 2:32 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>>>>>>> Bruno,
>>>>>>>>>  
>>>>>>>>> bugs.sun.com is not a live reflection of the bug database but gets updated periodically (every 12 hours I think).
>>>>>>>>>  
>>>>>>>>> The issue arises on certain 64-bit linux kernel/glibc versions. If you have an older version this does not impact you.
>>>>>>>>>  
>>>>>>>>> As for the rest, show me real code in such systems that rely on sleep for correctness or performance/timeliness and I will show you broken code. We are not talking about real-time systems here. park(nanos)/wait(millis) will only be affected by the backward time change if the real notification they are waiting for does not happen. Timeouts with these APIs are heuristics, they are defensive programming to cover the case "what if the notification I'm waiting for does not come". The code that would be affected by this issue is a very small % of the code that uses the API.
>>>>>>>>>  
>>>>>>>>> If this was as dire as you make out do you not think that this issue would have been raised far more than it has? This issue does need addressing because the number of affected systems will grow as these newer linux systems are adopted, but prudent developers/companies trial platform upgrades to check for these kinds of issues before swicthing to them in production environments.
>>>>>>>>>  
>>>>>>>>> Regards,
>>>>>>>>> David
>>>>>>>>> -----Original Message-----
>>>>>>>>> From: bruno bossola [mailto:bbossola at gmail.com]
>>>>>>>>> Sent: Wednesday, 4 September 2013 11:14 AM
>>>>>>>>> To: dholmes at ieee.org
>>>>>>>>> Cc: concurrency-interest at cs.oswego.edu
>>>>>>>>> Subject: Re: [concurrency-interest] Outstanding concurrency JVM issue - feedback?
>>>>>>>>> 
>>>>>>>>> Hi David,
>>>>>>>>> 
>>>>>>>>> thanks for following up.
>>>>>>>>> 
>>>>>>>>>  
>>>>>>>>> I have raised the priority on 6900441
>>>>>>>>>  
>>>>>>>>> Thanks, but it looks still like a P4:
>>>>>>>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>>>>> See also the attached snapshot, just in case it changes :) 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> [...] which to my knowledge [...] has never been a private bug
>>>>>>>>>  
>>>>>>>>> It was not accessible using bugs.sun.com, this was translated to private. I also received the same info indirectly from the 7u lead:
>>>>>>>>> "I'm not sure why 6900441 isn't public. (I'll follow up with owner of bugs.sun.com)", I guess you can check with him.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> It doesn't affect "every JVM64 running on Linux64".  A fix has been introduced into a specific glibc version...
>>>>>>>>>   
>>>>>>>>> ...and apparently did not make it. I was able to reproduce this even with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu 10, 11, 12, 13 + some random Debian. I did not have a JDK5, so I cannot say, but on JDK4 everything works (that's the reason why I call it a regression). (ah, if you look at the bug, it lists also JDK5, so I think we are pretty much covered                                                           here). 
>>>>>>>>> If you still have doubts tough, please have also a look on stackoverflow to see how it was reproduced consistently on probably every 64bitJVM over 64bitLinux in the world.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> The effects of this is not that "all the threads parked will hang, with unpredictable/corrupted/useless"! The effects are very simple an quite predictable... [deletia]s.
>>>>>>>>>  
>>>>>>>>> We have very different views, and I find quite difficult to accept yours. You are confusing my sample program which contains a single thread in a for loop with any other complex multi-threading concurrent system written in Java. For example, if you ever worked in a bank you surely know what I mean. You are comparing some random sleep() put into a program by some newbie, with the complex ecosystem of a concurrent platform written to manage trading information on very fast market. In that condition, I am sorry, statements such "...delayed timeout does not affect operation in a correctly functioning system..." and "...small time changes [...] are not a problem" are really not applicable. Let your system place an order three seconds late and your are out of the door so quickly you cannot even realize it.
>>>>>>>>> 
>>>>>>>>> But let's not limit ourselves to banks: how do you think your previous statements stands in these scenarios?
>>>>>>>>> - air control systems (what about a few seconds delay in control when fying planes?)
>>>>>>>>> - city traffic control systems (what if just for a couple of seconds all traffic lights become green?)
>>>>>>>>> 
>>>>>>>>> Not good enough.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> ...small time changes as typically done via NTP
>>>>>>>>>   
>>>>>>>>> NTP is only one of the possible sources of this problem. The root of it is that the JVM is counting nanoseconds delays using absolute values based on a wallclock: I do not think it's that smart. 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> So there is an issue that needs to be addressed but the situation is nowhere near as dire as you make out
>>>>>>>>>   
>>>>>>>>> Let's try to put this in perspective, shall we? In case the clock run backwards LockSupport.park() will be waiting for the nanoseconds requested plus the amount of seconds/minute/hours/days requested to compensate. Now, this primitive is used by almost *every* concurrency construct available on the platform, such as AbstractQueuedSynchronizer                                                           (and subclasses), ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue (and subclasses), Executors, FutureTask, .... (too long to list them all, but I think we have the picture) and also low levels synchronization primitives of the language itself, so Object::wait(:long) and the related sychronized blocks. 
>>>>>>>>> 
>>>>>>>>> I think it's pretty dire.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Cheers,
>>>>>>>>> 
>>>>>>>>>     Bruno
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On Wed, Sep 4, 2013 at 12:14 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>>>>>>> Hi Bruno,
>>>>>>>>>  
>>>>>>>>> I have raised the priority on 6900441 (which to my knowledge - and I created it! - has never been a private bug).
>>>>>>>>>  
>>>>>>>>> A few notes on the "very frightening" aspect of this:
>>>>>>>>>  
>>>>>>>>> 1. It doesn't affect "every JVM64 running on Linux64". A fix has been introduced                                                           into a specific glibc version for the futex-wait code such that it now responds to changes in the system time for absolute waits, where for all the years previous it did not. The fix seems to have been applied in late 2011 or early 2012 but I don't know the exact glibc version. There is also a 32-bit version of the fix that was proposed on Nov 27, 2012, so it will eventually make its way into 32-bit linux too.
>>>>>>>>>  
>>>>>>>>> 2. The effects of this is not that "all the threads parked will hang, with unpredictable/corrupted/useless"! The effects are very simple an quite predictable. If the system time goes forward then timed-waits (Object.wait, LockSupport.park) (which should be relative times) will return early as the absolute-time that the relative time was converted to will be seen to have been reached (Thread.sleep contains a guard against early returns). This is not actually a problem as you can not distinguish this case from a "spurious wakeup" which code is supposed to account for. If the time is changed backwards then these timed-waits & sleeps will not timeout when expected as the the for that is now further in the future, by the amount of the backward time change. Hence small time changes as typically done via NTP are NOT a problem. Timed-waits use timeouts as a heuristics for recovering when the expected real event notification does not occur - so a delayed timeout does not affect operation in a correctly functioning system. Early timeouts are indistinguishable from spurious wakeups, which code has to account for, so again not a problem for regular code. The only time a significant "hang" will occur is with Thread.sleep and a large backward time shift - but there is little real code that uses Thread.sleep in any critical way.
>>>>>>>>>  
>>>>>>>>> So there is an issue that needs to be addressed but the situation is nowhere near as dire as you make out.
>>>>>>>>>  
>>>>>>>>> David Holmes
>>>>>>>>> -----Original Message-----
>>>>>>>>> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno bossola
>>>>>>>>> Sent: Wednesday, 4 September 2013 1:56 AM
>>>>>>>>> To: concurrency-interest at cs.oswego.edu
>>>>>>>>> Subject: [concurrency-interest] Outstanding concurrency JVM issue - feedback?
>>>>>>>>> 
>>>>>>>>> Hi all,
>>>>>>>>> 
>>>>>>>>> I am writing here following a suggestion by Ben Evans. I wanted to check with you about an issue that my teams found on the JVM and that's very frightening. I already started the discussion with the engineers of the hotspot VM team but it looks like we need more awareness to solve this one and I'd really appreciate some help and some push :) 
>>>>>>>>> It looks to me that this issue is affecting every JVM64 running on Linux64, so imho it's quite important to be looked at.
>>>>>>>>> 
>>>>>>>>> Executive summary
>>>>>>>>> The implementation of the concurrency primitive LockSupport.parkNanos(),                                                           the function that controls most concurrency primitive on the JVM, is flawed, and any NTP sync, or system time change, can potentially break it with unexpected results across the board.
>>>>>>>>> 
>>>>>>>>> What we need to do?
>>>>>>>>> This is an old issue, and the bug was declared private. I somehow managed to have the bug reopened to the public, but it's still a  P4, that means that probably won't be fixed. I think we need to push for a resolution ASAP, be sure that's in for JDK9, make all the possible effort to make this fix for JDK8 or, at least, to include it in a later patch release. In an ideal world it would be nice to have a patch for JDK7. As far as I understand the hotspot engineering team works based on priorities: being this qualified as P4 means it won't be probably worked on (if you follow the breadcrumbs of bugs and fixes you can go back to 2002!) They acknowledge the problem, it has been flagged to management, but 1) it's low priority 2) it's too risky to fix for JDK8
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Why all this urgency?
>>>>>>>>> If a system time change happens then all the threads parked will hang, with unpredictable/corrupted/useless results to the end user. Same applies to Future, Queue, Executor, and (I guess) any other construct that it's somehow related to concurrency. This is a big issue for us and for any near time application: please think about trading and betting, where the JVM is largely used, and  do not restrain yourself to the Java language: add Scala and any other JVM-based language to the picture (JRuby, Jython...)
>>>>>>>>> 
>>>>>>>>> Tech details
>>>>>>>>> To be more clear about the issue, the extent of it and the concurrency library, let me introduce this very simple program:
>>>>>>>>> 
>>>>>>>>> import java.util.concurrent.locks.LockSupport;
>>>>>>>>> 
>>>>>>>>> public class Main {
>>>>>>>>> 
>>>>>>>>>     public static void main(String[] args) {
>>>>>>>>> 
>>>>>>>>>         for (int i=100; i>0; i--) {
>>>>>>>>>             System.out.println(i);
>>>>>>>>>             LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>>>>         }
>>>>>>>>> 
>>>>>>>>>         System.out.println("Done!");
>>>>>>>>>     }
>>>>>>>>> }
>>>>>>>>> 
>>>>>>>>> Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the clock down one hour and wait until the counter stops... magic!  I tested this on JDK6, JDK7 and latest JDK8 beta running on various Ubuntu distros. It's not just a matter of (old?) sleep() and wait() primitives, this issue it affects the whole concurrency library. 
>>>>>>>>> 
>>>>>>>>> To prove that this is fixable, I reimplemented the program above above substituting  LockSupport.parkNanos()  with  a JNI call to clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(
>>>>>>>>> 
>>>>>>>>> This is due to the fact  that the CPP code is calling the pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which, unfortunately is affected by settime()/settimeofday() calls (on Linux): for that reason it cannot be used to measure nanoseconds delays, which is what the specification requires. CLOCK_REALTIME is not                                                           guaranteed to monotonically count as this is the actual "system time": each time my system syncs time using a NTP server on the net, the time might jump forward or backward. The correct call (again on Linux)  would require to use CLOCK_MONOTONIC as clock id, which are defined by POSIX specs since 2002. (or better CLOCK_MONOTONIC_RAW)
>>>>>>>>> 
>>>>>>>>> The POSIX spec is infact clear, as it states "...setting the value of the CLOCK_REALTIME clock via clock_settime() shall have no effect on threads that are blocked waiting for a relative time service based upon this clock...": it definitely states "relative".  Having a look at the hotspot code, it appears that the park() is using compute_abstime() (which uses timeofday) and then waits on an absolute period: for that reason it's influenced by the system clock change. Very wrong.
>>>>>>>>> 
>>>>>>>>> I will be happy to know what you think, and if you can help me to escalate this issue I think that the all Java community will benefit from it.
>>>>>>>>> 
>>>>>>>>> Cheers,
>>>>>>>>> 
>>>>>>>>>     Bruno
>>>>>>>>> 
>>>>>>>>> No virus found in this message.
>>>>>>>>> Checked by AVG - www.avg.com
>>>>>>>>> Version: 2013.0.3392 / Virus Database: 3222/6633 - Release Date: 09/03/13
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> _______________________________________________
>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> -- 
>>>>> Viktor Klang
>>>>> Director of Engineering
>>>>> Typesafe
>>>>> 
>>>>> Twitter: @viktorklang
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>>> --
>>> [scala-debate on 2009/10/2]
>>> Viktor Klang: When will the days of numerical overflow be gone?
>>> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
>>> 
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/4393e479/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  5 16:16:34 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 05 Sep 2013 21:16:34 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <256C5E34-4581-411F-BA35-31FD8360AD2F@rkuhn.info>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
	<5228C351.4070009@oracle.com>
	<966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>
	<5228D081.9040705@oracle.com> <5228D734.2050703@oracle.com>
	<256C5E34-4581-411F-BA35-31FD8360AD2F@rkuhn.info>
Message-ID: <5228E6A2.6070807@oracle.com>

I am not arguing about the fix David said he'll do.

I am asking what is a reasonable expectation of a wake up? One can 
design an algorithm with optimistic wakeup timeout, but that's it - it 
remains a /optimistic/ wakeup. Deterministic wakeup must have very 
concrete guarantees all the way to hardware.


If we are looking at 1 hr backwards wall clock time shift, is this what 
happens in the cloud? That would be a weird cloud.


If we are looking at a few hundred ms backwards wall clock time shift, 
then how much of it will be rectified by the use of a new API? Bruno 
said the "fix" did work, but he didn't say if it was the "dummy" 
scenario with 1 hr moved manually (and where the timer events are 
delivered like clockwork), or the real env (where the clock drift occurs 
because of lack of precision of the timer events - how can you count the 
wakeup will be timely in such a env).


Alex


On 05/09/2013 20:41, Roland Kuhn wrote:
> Hi Alex,
>
> I do not understand why you argue about time moving forwards and 
> backwards: as I said this is not about wall time at all, it is about 
> (idealized) cycle counts of the CPU (for example). And these always 
> increase, they never go backwards (*). The discussion is also not 
> about delivering events at nanosecond resolution on the JVM, everybody 
> understands that that is never going to work. What is being discussed 
> is the difference between arbitrary and reasonable behavior, where the 
> former is allowed by the spec and the latter is expected implicitly of 
> a high-quality piece of engineering. Today?s computers as used by 
> end-users usually are responsive on the millisecond scale, with 
> glitches ranging in the low seconds?that is what people are used to 
> and what they expect. Delivering a wake-up 1h late?especially when the 
> system itself is working fine?is definitely outside of the expected 
> range on such systems.
>
> Regards,
>
> Roland
>
> (*) yes, I know there were unsynchronized multi-socket systems where 
> switching to a different CPU would have that effect, but those bugs 
> have been fixed
>
> 5 sep 2013 kl. 21:10 skrev Oleksandr Otenko:
>
>> The main point here is how to guarantee arrival of nanosecond 
>> resolution of events in a environment where we cannot guarantee 
>> reasonably-forward movement of time. Bruno showed a dummy case where 
>> he was moving the clock 1 hour away. Is this what he sees in his real 
>> environment? How does he justify the use of environment with such 
>> unreliable source of time? Do we know that environment will deliver 
>> nanosecond-time events reliably? Will they be spaced 1 ns from each 
>> other? (From what I recall, in some virtualization envs some JVMs 
>> reported the time go back, when it shouldn't. Yet, even the fix was 
>> only as perfect as the clock update delivery in that virtualization 
>> solution. If we are meant to catch up on 200 microseconds, will it 
>> deliver in a salvo, or add a corrective microsecond on 200 subsequent 
>> seconds?)
>>
>>
>> If we talk about a different environment, eg VM with wall clock 
>> moving a few hundred ms back and forth, it becomes a problem of a 
>> very different magnitude. The question of timely arrival of events is 
>> still there, but even with that part unanswered, a few hundred ms 
>> drift in a pause will not be fine for banking or betting, nearly 
>> exclusively. Then the question is still why choose environments like 
>> that to run applications that are so sensitive?
>>
>>
>> Alex
>>
>>
>> On 05/09/2013 19:42, Oleksandr Otenko wrote:
>>> On 05/09/2013 19:15, Roland Kuhn wrote:
>>>>
>>>> 5 sep 2013 kl. 19:45 skrev Oleksandr Otenko:
>>>>
>>>>> Exactly my point.
>>>>>
>>>>> Now someone needs to take care of negative time returned, when the 
>>>>> clock goes back, even if the wait was shorter than timeout.
>>>>
>>>> Why would that lead to a negative return value?
>>>
>>> Depending on how you work out the elapsed time, of course.
>>>
>>>>> Or, if we report the actual time waited, then deal with the 
>>>>> inconsistency between apparent System.nanoTime() and the wait.
>>>>
>>>> There are two very different time sources in the JVM, and the one 
>>>> which has ?nano? in its name is supposed to be monotonic and 
>>>> independent of the system?s wall time clock. I share Bruno?s view 
>>>> that a method called awaitNanos() should measure time using 
>>>> System.nanoTime and not with System.currentTimeMillis 
>>>> (conceptually). It is unfortunate that the API docs of awaitNanos() 
>>>> do not specify which of these choices was made.
>>>
>>> Conceptually awaitNanos() returns timeout-elapsedTime. How will 
>>> System.nanoTime() work out the elapsed time in nanoseconds after 
>>> suspend-modify wall clock-resume? Who tells it how many nanoseconds 
>>> were missed?
>>>
>>> Alex
>>>
>>>
>>>>
>>>> Regards,
>>>>
>>>> Roland
>>>>
>>>>>
>>>>> Alex
>>>>>
>>>>> On 05/09/2013 18:31, ?iktor ?lang wrote:
>>>>>> For Condition.awaitNanos it states:
>>>>>>
>>>>>> Returns:
>>>>>>     an estimate of the |nanosTimeout| value minus the time spent
>>>>>>     waiting upon return from this method. A positive value may be
>>>>>>     used as the argument to a subsequent call to this method to
>>>>>>     finish waiting out the desired time. *A value less than or
>>>>>>     equal to zero indicates that no time remains.*
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 5, 2013 at 1:06 PM, Oleksandr Otenko 
>>>>>> <oleksandr.otenko at oracle.com 
>>>>>> <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>
>>>>>>     Oh, and now someone else is going to complain that awaitNanos
>>>>>>     returns a negative number, even though it waited for only 1
>>>>>>     ms out of 100.
>>>>>>
>>>>>>     Alex
>>>>>>
>>>>>>     On 05/09/2013 17:50, bruno bossola wrote:
>>>>>>>     I am sorry but I really cannot spend more time creating more
>>>>>>>     samples and I am quite sure you could do a better work at
>>>>>>>     that! At the moment to me that matter is clear enough, but
>>>>>>>     feel free to ask, I will very happy to help! In the meantime
>>>>>>>     I prefer spend my time to work on a patch that I can apply
>>>>>>>     on my JVMs :)
>>>>>>>
>>>>>>>     Cheers,
>>>>>>>
>>>>>>>         Bruno
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>     On Thu, Sep 5, 2013 at 4:12 PM, Oleksandr Otenko
>>>>>>>     <oleksandr.otenko at oracle.com
>>>>>>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>>
>>>>>>>         This is far from reproducing the problem with arbitrary
>>>>>>>         j.u.c locks and queues hanging.
>>>>>>>
>>>>>>>         Condition.awaitNanos can return a negative value. If you
>>>>>>>         are expecting the negative value to be small, then how
>>>>>>>         small do you expect it to be?
>>>>>>>
>>>>>>>
>>>>>>>         Alex
>>>>>>>
>>>>>>>
>>>>>>>         On 05/09/2013 02:12, bruno bossola wrote:
>>>>>>>>         Hi Oaleksandr,
>>>>>>>>
>>>>>>>>         Please apologize me if my english was not good enough
>>>>>>>>         to provide you an example that make sense: for that
>>>>>>>>         reason I decided to go back to a binary deliverable
>>>>>>>>         (code) that shows the problem, hope this helps!
>>>>>>>>
>>>>>>>>         This is my PreciousPool class, that handles Precious
>>>>>>>>         resources:
>>>>>>>>
>>>>>>>>         import java.text.SimpleDateFormat;
>>>>>>>>         import java.util.ArrayList;
>>>>>>>>         import java.util.Date;
>>>>>>>>         import java.util.List;
>>>>>>>>         import java.util.concurrent.TimeUnit;
>>>>>>>>         import java.util.concurrent.locks.Condition;
>>>>>>>>         import java.util.concurrent.locks.Lock;
>>>>>>>>         import java.util.concurrent.locks.ReentrantLock;
>>>>>>>>
>>>>>>>>         public class PreciousPool {
>>>>>>>>
>>>>>>>>             public static class Precious {
>>>>>>>>                 private final int id;
>>>>>>>>
>>>>>>>>                 private Precious() {
>>>>>>>>         this.id <http://this.id/> = 100+(int)(Math.random()*900.0);
>>>>>>>>                 }
>>>>>>>>
>>>>>>>>                 public String toString() {
>>>>>>>>                     return "Precious n."+id;
>>>>>>>>                 }
>>>>>>>>             }
>>>>>>>>
>>>>>>>>             private final Lock lock;
>>>>>>>>             private final Condition ready;
>>>>>>>>             private final long timeoutInMillis;
>>>>>>>>
>>>>>>>>             private final List<Precious> preciousLended;
>>>>>>>>             private final List<Precious> preciousAvailable;
>>>>>>>>
>>>>>>>>             public PreciousPool(int size, long timeoutInSeconds) {
>>>>>>>>                 this.lock = new ReentrantLock();
>>>>>>>>                 this.ready = lock.newCondition();
>>>>>>>>
>>>>>>>>         this.timeoutInMillis = 1000L*timeoutInSeconds;
>>>>>>>>         this.preciousLended =  new ArrayList<Precious>();
>>>>>>>>         this.preciousAvailable = new ArrayList<Precious>();
>>>>>>>>
>>>>>>>>                 for (int i = 0; i < size; i++) {
>>>>>>>>         preciousAvailable.add(new Precious());
>>>>>>>>                 }
>>>>>>>>             }
>>>>>>>>
>>>>>>>>             public Precious obtain() {
>>>>>>>>         lock.lock();
>>>>>>>>                 try {
>>>>>>>>                     // if no precious are available we wait for
>>>>>>>>         the specified timeout (releasing the lock so that
>>>>>>>>         others can try)
>>>>>>>>                     if (preciousAvailable.size() == 0) {
>>>>>>>>         try {
>>>>>>>>         ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
>>>>>>>>                         } catch (InterruptedException e) {
>>>>>>>>         Thread.currentThread().interrupt();
>>>>>>>>         throw new RuntimeException("Somebody interrupted me!", e);
>>>>>>>>                         }
>>>>>>>>                     }
>>>>>>>>
>>>>>>>>                     // if a precious is available we unload it
>>>>>>>>         and return to the caller, otherwise null
>>>>>>>>                     if (preciousAvailable.size() > 0) {
>>>>>>>>         Precious value = preciousAvailable.remove(0);
>>>>>>>>         preciousLended.add(value);
>>>>>>>>         return value;
>>>>>>>>                     } else {
>>>>>>>>         return null;
>>>>>>>>                     }
>>>>>>>>                 } finally {
>>>>>>>>         lock.unlock();
>>>>>>>>                 }
>>>>>>>>             }
>>>>>>>>
>>>>>>>>             public void release(Precious value) {
>>>>>>>>         lock.lock();
>>>>>>>>                 try {
>>>>>>>>                     if (!preciousLended.remove(value))
>>>>>>>>         throw new RuntimeException("Element "+value+" was not
>>>>>>>>         lended!");
>>>>>>>>
>>>>>>>>                     // if a precious is returned we put it back
>>>>>>>>         and signal to anybody waiting
>>>>>>>>         preciousAvailable.add(value);
>>>>>>>>         ready.signalAll();
>>>>>>>>                 } finally {
>>>>>>>>         lock.unlock();
>>>>>>>>                 }
>>>>>>>>             }
>>>>>>>>
>>>>>>>>             public static void main(String args[]) {
>>>>>>>>                 final int size = 3;
>>>>>>>>                 final PreciousPool pool = new
>>>>>>>>         PreciousPool(size, 5);
>>>>>>>>
>>>>>>>>                 // let's exhaust the pool
>>>>>>>>                 for (int i=0; i<size; i++)
>>>>>>>>         dump(pool.obtain());
>>>>>>>>
>>>>>>>>                 // and as we are stubborn we continuosly ask
>>>>>>>>         for a new one
>>>>>>>>         while(true) {
>>>>>>>>         dump(pool.obtain());
>>>>>>>>                 }
>>>>>>>>             }
>>>>>>>>
>>>>>>>>             private static void dump(Precious precious) {
>>>>>>>>                 if (precious == null)
>>>>>>>>                     log("I did not get my precious :(");
>>>>>>>>                 else
>>>>>>>>                     log("I did get my precious! "+precious);
>>>>>>>>             }
>>>>>>>>
>>>>>>>>             private static void log(String message) {
>>>>>>>>                 final String now = new
>>>>>>>>         SimpleDateFormat("HH:mm:ss:SSSS ").format(new Date());
>>>>>>>>         System.out.println(now + message);
>>>>>>>>             }
>>>>>>>>         }
>>>>>>>>
>>>>>>>>         So, the main is a single thread (no need for
>>>>>>>>         multithreading here, let's keep it simple), that first
>>>>>>>>         exhaust the whole pool and then keep asking, without
>>>>>>>>         success, for a resource. Stubborn guy, I say, but it
>>>>>>>>         happens. If you run this program everything works as
>>>>>>>>         expected: you are greeted by a three successful
>>>>>>>>         Precious and then an endless list of failures, that it
>>>>>>>>         continuously grow. All good :)
>>>>>>>>
>>>>>>>>         02:34:40:0061 I did get my precious! Precious n.156
>>>>>>>>         02:34:40:0062 I did get my precious! Precious n.991
>>>>>>>>         02:34:40:0062 I did get my precious! Precious n.953
>>>>>>>>         02:34:45:0064 I did not get my precious :(
>>>>>>>>         02:34:50:0065 I did not get my precious :(
>>>>>>>>         02:34:55:0066 I did not get my precious :(
>>>>>>>>         02:35:00:0067 I did not get my precious :(
>>>>>>>>         02:35:05:0068 I did not get my precious :(
>>>>>>>>         [...]
>>>>>>>>
>>>>>>>>         But guess what happens when, while the program is
>>>>>>>>         running, I change the date of my system back of one
>>>>>>>>         hour? Everything stops,  it's simple as that. No
>>>>>>>>         prints, nothing, zero, nada. Now, If it wasn't so late,
>>>>>>>>         I would probably wait one hour in order to have my
>>>>>>>>         program restored to his normal process, but as a
>>>>>>>>         customer I won't be terribly happy :)
>>>>>>>>
>>>>>>>>         I hope my point is now clear.
>>>>>>>>         Cheers,
>>>>>>>>
>>>>>>>>             Bruno
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>         On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
>>>>>>>>         <oleksandr.otenko at oracle.com
>>>>>>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>>>
>>>>>>>>             n 04/09/2013 18:54, bruno bossola wrote:
>>>>>>>>>             Hi Oleksandr,
>>>>>>>>>
>>>>>>>>>                 Where in the design of those systems is a
>>>>>>>>>                 real-time timer? The one that delivers time
>>>>>>>>>                 events uncompromised even by GC latency?
>>>>>>>>>
>>>>>>>>>             I don't think so :) If somebody needs a real time
>>>>>>>>>             implementation he needs to go for a real time JVM,
>>>>>>>>>             like Jean correctly pointed out. The concurrency
>>>>>>>>>             primitives are depending on
>>>>>>>>>             LockSupport.parkNanos(...) to park a thread: if
>>>>>>>>>             this for any reason is not working (like it is)
>>>>>>>>>             then strange things may happen.
>>>>>>>>             Your assumption is that it is not working, if the
>>>>>>>>             elapsed time is longer. This is the flawed assumption.
>>>>>>>>
>>>>>>>>             Also, you need to read fine print on those "real
>>>>>>>>             time" JVMs. The catch is in the definition of "real
>>>>>>>>             time".
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>             Imagine, for example, that you are using a
>>>>>>>>>             ReentrantLock to control a very precious resource
>>>>>>>>>             used across the board (what about a database
>>>>>>>>>             connection pool?) and you are unlucky enough to
>>>>>>>>>             have a system time change (backwards) while you
>>>>>>>>>             are locking: all the threads that want to use such
>>>>>>>>>             resource will be progressively locked: not
>>>>>>>>>             forever, but for the amount of time the clock went
>>>>>>>>>             back. Probably most (all?) of your system freezes,
>>>>>>>>>             and the only option you have is to wait, or restart.
>>>>>>>>>             Now place this in a large application server, that
>>>>>>>>>             provide services for hunreds (thousands) of users.
>>>>>>>>>             How does it sound to you?
>>>>>>>>             It sounds like you don't understand how the locks work.
>>>>>>>>
>>>>>>>>
>>>>>>>>             Alex
>>>>>>>>
>>>>>>>>
>>>>>>>>>
>>>>>>>>>             BTW, at the moment we could have a watchdog (in
>>>>>>>>>             Python :)) that restarts it, but, I dunno why, I
>>>>>>>>>             don't like it a lot...
>>>>>>>>>
>>>>>>>>>             Cheers,
>>>>>>>>>
>>>>>>>>>                 Bruno
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>             On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
>>>>>>>>>             <oleksandr.otenko at oracle.com
>>>>>>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>>>>>
>>>>>>>>>                 You are missing the point.
>>>>>>>>>
>>>>>>>>>                 Where in the design of those systems is a
>>>>>>>>>                 real-time timer? The one that delivers time
>>>>>>>>>                 events uncompromised even by GC latency?
>>>>>>>>>
>>>>>>>>>                 The whole concurrency lot does not depend on
>>>>>>>>>                 the timeout magnitude for correctness.
>>>>>>>>>
>>>>>>>>>                 Alex
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>                 On 04/09/2013 12:05, bruno bossola wrote:
>>>>>>>>>>                 Hi David
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                     bugs.sun.com <http://bugs.sun.com/> is
>>>>>>>>>>                     not a live reflection of the bug database
>>>>>>>>>>                     but gets updated periodically (every 12
>>>>>>>>>>                     hours I think).
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                 Good to know :) I will be eagerly clicking on
>>>>>>>>>>                 it to discover the new priority! Thanks for
>>>>>>>>>>                 that, I really appreciate it.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                     The issue arises on certain 64-bit linux
>>>>>>>>>>                     kernel/glibc versions. If you have an
>>>>>>>>>>                     older version this does not impact you.
>>>>>>>>>>
>>>>>>>>>>                 You saw my list: nobody will use an older
>>>>>>>>>>                 Kernel/glibc version in production.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                     As for the rest, show me real code in
>>>>>>>>>>                     such systems that rely on sleep for
>>>>>>>>>>                     correctness or performance/timeliness and
>>>>>>>>>>                     I will show you broken code.
>>>>>>>>>>
>>>>>>>>>>                 You are still hitting about the sleep(), I
>>>>>>>>>>                 understand and I agree about this. But here
>>>>>>>>>>                 we are not talking about sleeps: we are
>>>>>>>>>>                 talking about the whole concurrency lot. And
>>>>>>>>>>                 yes, as I already said, we are talking about
>>>>>>>>>>                 near time systems, like trading application,
>>>>>>>>>>                 betting applications, air traffic control
>>>>>>>>>>                 systems, car traffic control systems. Don't
>>>>>>>>>>                 you think this bug might place Oracle JVM
>>>>>>>>>>                 outside of these markets?
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                     If this was as dire as you make out do
>>>>>>>>>>                     you not think that this issue would have
>>>>>>>>>>                     been raised far more than it has? [....]
>>>>>>>>>>                     prudent developers/companies trial
>>>>>>>>>>                     platform upgrades to check for these
>>>>>>>>>>                     kinds of issues before switching to them
>>>>>>>>>>                     in production environments.
>>>>>>>>>>
>>>>>>>>>>                 I am waiting now for the part where you say
>>>>>>>>>>                 that we should throw away Linux and use
>>>>>>>>>>                 Oracle Solaris :)  In all seriousness,
>>>>>>>>>>                 there's a lot of action "in the middle", and
>>>>>>>>>>                 I think that Oracle cannot oversee that. For
>>>>>>>>>>                 example a lot of trading software system can
>>>>>>>>>>                 be installed on premises, where you usually
>>>>>>>>>>                 have no control over the environment: what I
>>>>>>>>>>                 would do is to put a native daemon in my app
>>>>>>>>>>                 so that if I see the system clock change I
>>>>>>>>>>                 would kill myself, just in case. And this is
>>>>>>>>>>                 a solution that I know for a fact (sorry, I
>>>>>>>>>>                 cannot make a reference) it's used in
>>>>>>>>>>                 production in a very important trading
>>>>>>>>>>                 application.
>>>>>>>>>>
>>>>>>>>>>                 Regarding that specific bug, it was not
>>>>>>>>>>                 accessible to the external until two days
>>>>>>>>>>                 ago, so I guess nobody really knew a lot
>>>>>>>>>>                 about it, but I will make sure it will :) so
>>>>>>>>>>                 that we can get more traction.
>>>>>>>>>>
>>>>>>>>>>                 Cheers,
>>>>>>>>>>
>>>>>>>>>>                     Bruno
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                 On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
>>>>>>>>>>                 <davidcholmes at aapt.net.au
>>>>>>>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>>
>>>>>>>>>>                     Bruno,
>>>>>>>>>>                     bugs.sun.com <http://bugs.sun.com/> is
>>>>>>>>>>                     not a live reflection of the bug database
>>>>>>>>>>                     but gets updated periodically (every 12
>>>>>>>>>>                     hours I think).
>>>>>>>>>>                     The issue arises on certain 64-bit linux
>>>>>>>>>>                     kernel/glibc versions. If you have an
>>>>>>>>>>                     older version this does not impact you.
>>>>>>>>>>                     As for the rest, show me real code in
>>>>>>>>>>                     such systems that rely on sleep for
>>>>>>>>>>                     correctness or performance/timelinessand
>>>>>>>>>>                     I will show you broken code. We are not
>>>>>>>>>>                     talking about real-time systemshere.
>>>>>>>>>>                     park(nanos)/wait(millis) will only be
>>>>>>>>>>                     affected by the backward time change if
>>>>>>>>>>                     the real notification they are waiting
>>>>>>>>>>                     for does not happen. Timeouts with these
>>>>>>>>>>                     APIs are heuristics, they are defensive
>>>>>>>>>>                     programming to cover the case "what if
>>>>>>>>>>                     the notification I'm waiting for does not
>>>>>>>>>>                     come". The code that would be affected by
>>>>>>>>>>                     this issue is a very small % of the code
>>>>>>>>>>                     that uses the API.
>>>>>>>>>>                     If this was as dire as you make out do
>>>>>>>>>>                     you not think that this issue would have
>>>>>>>>>>                     been raised far more than it has? This
>>>>>>>>>>                     issue does need addressing because the
>>>>>>>>>>                     number of affected systems will grow as
>>>>>>>>>>                     these newer linux systems are adopted,
>>>>>>>>>>                     but prudent developers/companies trial
>>>>>>>>>>                     platform upgrades to check for these
>>>>>>>>>>                     kinds of issues before swicthing to them
>>>>>>>>>>                     in production environments.
>>>>>>>>>>                     Regards,
>>>>>>>>>>                     David
>>>>>>>>>>
>>>>>>>>>>                         -----Original Message-----
>>>>>>>>>>                         *From:* bruno bossola
>>>>>>>>>>                         [mailto:bbossola at gmail.com
>>>>>>>>>>                         <mailto:bbossola at gmail.com>]
>>>>>>>>>>                         *Sent:* Wednesday, 4 September 2013
>>>>>>>>>>                         11:14 AM
>>>>>>>>>>                         *To:* dholmes at ieee.org
>>>>>>>>>>                         <mailto:dholmes at ieee.org>
>>>>>>>>>>                         *Cc:*
>>>>>>>>>>                         concurrency-interest at cs.oswego.edu
>>>>>>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>>>>>>                         Outstanding concurrency JVM issue -
>>>>>>>>>>                         feedback?
>>>>>>>>>>
>>>>>>>>>>                         Hi David,
>>>>>>>>>>
>>>>>>>>>>                         thanks for following up.
>>>>>>>>>>
>>>>>>>>>>                             I have raised the priority on 6900441
>>>>>>>>>>
>>>>>>>>>>                         Thanks, but it looks still like a P4:
>>>>>>>>>>                         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
>>>>>>>>>>                         See also the attached snapshot, just
>>>>>>>>>>                         in case it changes :)
>>>>>>>>>>
>>>>>>>>>>                         Inline image 2
>>>>>>>>>>
>>>>>>>>>>                             [...] which to my knowledge [...]
>>>>>>>>>>                             has never been a private bug
>>>>>>>>>>
>>>>>>>>>>                         It was not accessible using
>>>>>>>>>>                         bugs.sun.com <http://bugs.sun.com/>,
>>>>>>>>>>                         this was translated to private. I
>>>>>>>>>>                         also received the same info
>>>>>>>>>>                         indirectly from the 7u lead:
>>>>>>>>>>                         "I'm not sure why 6900441 isn't
>>>>>>>>>>                         public. (I'll follow up with owner of
>>>>>>>>>>                         bugs.sun.com
>>>>>>>>>>                         <http://bugs.sun.com/>)", I guess you
>>>>>>>>>>                         can check with him.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                             It doesn't affect "every JVM64
>>>>>>>>>>                             running on Linux64".  A fix has
>>>>>>>>>>                             been introduced into a specific
>>>>>>>>>>                             glibc version...
>>>>>>>>>>
>>>>>>>>>>                         ...and apparently did not make it. I
>>>>>>>>>>                         was able to reproduce this even with
>>>>>>>>>>                         the IBM VM, so to speak. I tried
>>>>>>>>>>                         JDK6, JDK7, JDK8 on Ubuntu 10, 11,
>>>>>>>>>>                         12, 13 + some random Debian. I did
>>>>>>>>>>                         not have a JDK5, so I cannot say, but
>>>>>>>>>>                         on JDK4 everything works (that's the
>>>>>>>>>>                         reason why I call it a regression).
>>>>>>>>>>                         (ah, if you look at the bug, it lists
>>>>>>>>>>                         also JDK5, so I think we are pretty
>>>>>>>>>>                         much covered here).
>>>>>>>>>>                         If you still have doubts tough,
>>>>>>>>>>                         please have also a look on
>>>>>>>>>>                         stackoverflow to see how it was
>>>>>>>>>>                         reproduced consistently on probably
>>>>>>>>>>                         every 64bitJVM over 64bitLinux in the
>>>>>>>>>>                         world.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                             The effects of this is not that
>>>>>>>>>>                             "all the threads parked will
>>>>>>>>>>                             hang, with
>>>>>>>>>>                             unpredictable/corrupted/useless"!
>>>>>>>>>>                             The effects are very simple an
>>>>>>>>>>                             quite predictable... [deletia]s.
>>>>>>>>>>
>>>>>>>>>>                         We have very different views, and I
>>>>>>>>>>                         find quite difficult to accept yours.
>>>>>>>>>>                         You are confusing my sample program
>>>>>>>>>>                         which contains a single thread in a
>>>>>>>>>>                         for loop with any other complex
>>>>>>>>>>                         multi-threading concurrent system
>>>>>>>>>>                         written in Java. For example, if you
>>>>>>>>>>                         ever worked in a bank you surely know
>>>>>>>>>>                         what I mean. You are comparing some
>>>>>>>>>>                         random sleep() put into a program by
>>>>>>>>>>                         some newbie, with the complex
>>>>>>>>>>                         ecosystem of a concurrent platform
>>>>>>>>>>                         written to manage trading information
>>>>>>>>>>                         on very fast market. In that
>>>>>>>>>>                         condition, I am sorry, statements
>>>>>>>>>>                         such "...delayed timeout does not
>>>>>>>>>>                         affect operation in a correctly
>>>>>>>>>>                         functioning system..." and "...small
>>>>>>>>>>                         time changes [...] are not a problem"
>>>>>>>>>>                         are really not applicable. Let your
>>>>>>>>>>                         system place an order three seconds
>>>>>>>>>>                         late and your are out of the door so
>>>>>>>>>>                         quickly you cannot even realize it.
>>>>>>>>>>
>>>>>>>>>>                         But let's not limit ourselves to
>>>>>>>>>>                         banks: how do you think your previous
>>>>>>>>>>                         statements stands in these scenarios?
>>>>>>>>>>                         - air control systems
>>>>>>>>>>                         <http://www.zdnet.com/air-traffic-control-system-is-not-safe-say-uk-controllers-3040091970/> (what
>>>>>>>>>>                         about a few seconds delay in control
>>>>>>>>>>                         when fying planes?)
>>>>>>>>>>                         - city traffic control systems
>>>>>>>>>>                         <http://www.iisigroup.com/en/solutions/tra-city.html> (what
>>>>>>>>>>                         if just for a couple of seconds all
>>>>>>>>>>                         traffic lights become green?)
>>>>>>>>>>
>>>>>>>>>>                         Not good enough.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                             ...small time changes as
>>>>>>>>>>                             typically done via NTP
>>>>>>>>>>
>>>>>>>>>>                         NTP is only one of the possible
>>>>>>>>>>                         sources of this problem. The root of
>>>>>>>>>>                         it is that the JVM is counting
>>>>>>>>>>                         nanoseconds delays using absolute
>>>>>>>>>>                         values based on a wallclock: I do not
>>>>>>>>>>                         think it's that smart.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                             So there is an issue that needs
>>>>>>>>>>                             to be addressed but the situation
>>>>>>>>>>                             is nowhere near as dire as you
>>>>>>>>>>                             make out
>>>>>>>>>>
>>>>>>>>>>                         Let's try to put this in perspective,
>>>>>>>>>>                         shall we? In case the clock run
>>>>>>>>>>                         backwards LockSupport.park() will be
>>>>>>>>>>                         waiting for the nanoseconds requested
>>>>>>>>>>                         plus the amount of
>>>>>>>>>>                         seconds/minute/hours/days requested
>>>>>>>>>>                         to compensate. Now, this primitive is
>>>>>>>>>>                         used by almost *every* concurrency
>>>>>>>>>>                         construct available on the platform,
>>>>>>>>>>                         such as AbstractQueuedSynchronizer
>>>>>>>>>>                         (and subclasses), ReentrantLock (and
>>>>>>>>>>                         subclasses), CyclicBarrier,
>>>>>>>>>>                         BlockingQueue (and subclasses),
>>>>>>>>>>                         Executors, FutureTask, .... (too long
>>>>>>>>>>                         to list them all, but I think we have
>>>>>>>>>>                         the picture) and also low levels
>>>>>>>>>>                         synchronization primitives of the
>>>>>>>>>>                         language itself, so
>>>>>>>>>>                         Object::wait(:long) and the related
>>>>>>>>>>                         sychronized blocks.
>>>>>>>>>>
>>>>>>>>>>                         I think it's pretty dire.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                         Cheers,
>>>>>>>>>>
>>>>>>>>>>                             Bruno
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                         On Wed, Sep 4, 2013 at 12:14 AM,
>>>>>>>>>>                         David Holmes
>>>>>>>>>>                         <davidcholmes at aapt.net.au
>>>>>>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>>
>>>>>>>>>>                             Hi Bruno,
>>>>>>>>>>                             I have raised the priority on
>>>>>>>>>>                             6900441 (which to my knowledge -
>>>>>>>>>>                             and I created it! - has never
>>>>>>>>>>                             been a private bug).
>>>>>>>>>>                             A few notes on the "very
>>>>>>>>>>                             frightening" aspect of this:
>>>>>>>>>>                             1. It doesn't affect "every JVM64
>>>>>>>>>>                             running on Linux64". A fix has
>>>>>>>>>>                             been introduced into a specific
>>>>>>>>>>                             glibc version for the futex-wait
>>>>>>>>>>                             code such that it now responds to
>>>>>>>>>>                             changes in the system time for
>>>>>>>>>>                             absolute waits, where for all the
>>>>>>>>>>                             years previous it did not. The
>>>>>>>>>>                             fix seems to have been applied in
>>>>>>>>>>                             late 2011 or early 2012 but I
>>>>>>>>>>                             don't know the exact glibc
>>>>>>>>>>                             version. There is also a 32-bit
>>>>>>>>>>                             version of the fix that was
>>>>>>>>>>                             proposed on Nov 27, 2012, so it
>>>>>>>>>>                             will eventually make its way into
>>>>>>>>>>                             32-bit linux too.
>>>>>>>>>>                             2. The effects of this is not
>>>>>>>>>>                             that "all the threads parked will
>>>>>>>>>>                             hang, with
>>>>>>>>>>                             unpredictable/corrupted/useless"!
>>>>>>>>>>                             The effects are very simple an
>>>>>>>>>>                             quite predictable. If the system
>>>>>>>>>>                             time goes forward then
>>>>>>>>>>                             timed-waits (Object.wait,
>>>>>>>>>>                             LockSupport.park) (which should
>>>>>>>>>>                             be relative times) will return
>>>>>>>>>>                             early as the absolute-time that
>>>>>>>>>>                             the relative time was converted
>>>>>>>>>>                             to will be seen to have been
>>>>>>>>>>                             reached (Thread.sleep contains a
>>>>>>>>>>                             guard against early returns).
>>>>>>>>>>                             This is not actually a problem as
>>>>>>>>>>                             you can not distinguish this case
>>>>>>>>>>                             from a "spurious wakeup" which
>>>>>>>>>>                             code is supposed to account
>>>>>>>>>>                             for. If the time is changed
>>>>>>>>>>                             backwards then these timed-waits
>>>>>>>>>>                             & sleeps will not timeout when
>>>>>>>>>>                             expected as the the for that is
>>>>>>>>>>                             now further in the future, by the
>>>>>>>>>>                             amount of the backward time
>>>>>>>>>>                             change. Hence small time changes
>>>>>>>>>>                             as typically done via NTP are NOT
>>>>>>>>>>                             a problem. Timed-waits use
>>>>>>>>>>                             timeouts as a heuristics for
>>>>>>>>>>                             recovering when the expected real
>>>>>>>>>>                             event notification does not occur
>>>>>>>>>>                             - so a delayed timeout does not
>>>>>>>>>>                             affect operation in a correctly
>>>>>>>>>>                             functioning system. Early
>>>>>>>>>>                             timeouts are indistinguishable
>>>>>>>>>>                             from spurious wakeups, which code
>>>>>>>>>>                             has to account for, so again not
>>>>>>>>>>                             a problem for regular code. The
>>>>>>>>>>                             only time a significant "hang"
>>>>>>>>>>                             will occur is with Thread.sleep
>>>>>>>>>>                             and a large backward time shift -
>>>>>>>>>>                             but there is little real code
>>>>>>>>>>                             that uses Thread.sleep in any
>>>>>>>>>>                             critical way.
>>>>>>>>>>                             So there is an issue that needs
>>>>>>>>>>                             to be addressed but the situation
>>>>>>>>>>                             is nowhere near as dire as you
>>>>>>>>>>                             make out.
>>>>>>>>>>                             David Holmes
>>>>>>>>>>
>>>>>>>>>>                                 -----Original Message-----
>>>>>>>>>>                                 *From:*
>>>>>>>>>>                                 concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>>>>>                                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>>>>>>>>>                                 Behalf Of *bruno bossola
>>>>>>>>>>                                 *Sent:* Wednesday, 4
>>>>>>>>>>                                 September 2013 1:56 AM
>>>>>>>>>>                                 *To:*
>>>>>>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>>                                 *Subject:*
>>>>>>>>>>                                 [concurrency-interest]
>>>>>>>>>>                                 Outstanding concurrency JVM
>>>>>>>>>>                                 issue - feedback?
>>>>>>>>>>
>>>>>>>>>>                                 Hi all,
>>>>>>>>>>
>>>>>>>>>>                                 I am writing here following a
>>>>>>>>>>                                 suggestion by Ben Evans. I
>>>>>>>>>>                                 wanted to check with you
>>>>>>>>>>                                 about an issue that my teams
>>>>>>>>>>                                 found on the JVM and that's
>>>>>>>>>>                                 very frightening. I already
>>>>>>>>>>                                 started the discussion with
>>>>>>>>>>                                 the engineers of the hotspot
>>>>>>>>>>                                 VM team but it looks like we
>>>>>>>>>>                                 need more awareness to solve
>>>>>>>>>>                                 this one and I'd really
>>>>>>>>>>                                 appreciate some help and some
>>>>>>>>>>                                 push :)
>>>>>>>>>>                                 It looks to me that this
>>>>>>>>>>                                 issue is affecting every
>>>>>>>>>>                                 JVM64 running on Linux64, so
>>>>>>>>>>                                 imho it's quite important to
>>>>>>>>>>                                 be looked at.
>>>>>>>>>>
>>>>>>>>>>                                 *Executive summary
>>>>>>>>>>                                 *The implementation of the
>>>>>>>>>>                                 concurrency primitive
>>>>>>>>>>                                 LockSupport.parkNanos(), the
>>>>>>>>>>                                 function that controls most
>>>>>>>>>>                                 concurrency primitive on the
>>>>>>>>>>                                 JVM, is flawed, and any NTP
>>>>>>>>>>                                 sync, or system time change,
>>>>>>>>>>                                 can potentially break it with
>>>>>>>>>>                                 unexpected results across the
>>>>>>>>>>                                 board.
>>>>>>>>>>
>>>>>>>>>>                                 *What we need to do?
>>>>>>>>>>                                 *This is an old issue, and
>>>>>>>>>>                                 the bug
>>>>>>>>>>                                 <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441>
>>>>>>>>>>                                 was declared private. I
>>>>>>>>>>                                 somehow managed to have the
>>>>>>>>>>                                 bug reopened to the public,
>>>>>>>>>>                                 but it's still a  P4, that
>>>>>>>>>>                                 means that probably won't be
>>>>>>>>>>                                 fixed. I think we need to
>>>>>>>>>>                                 push for a resolution ASAP,
>>>>>>>>>>                                 be sure that's in for JDK9,
>>>>>>>>>>                                 make all the possible effort
>>>>>>>>>>                                 to make this fix for JDK8 or,
>>>>>>>>>>                                 at least, to include it in a
>>>>>>>>>>                                 later patch release. In an
>>>>>>>>>>                                 ideal world it would be nice
>>>>>>>>>>                                 to have a patch for JDK7. As
>>>>>>>>>>                                 far as I understand the
>>>>>>>>>>                                 hotspot engineering team
>>>>>>>>>>                                 works based on priorities:
>>>>>>>>>>                                 being this qualified as P4
>>>>>>>>>>                                 means it won't be probably
>>>>>>>>>>                                 worked on (if you follow the
>>>>>>>>>>                                 breadcrumbs of bugs and fixes
>>>>>>>>>>                                 you can go back to 2002!)
>>>>>>>>>>                                 They acknowledge the problem,
>>>>>>>>>>                                 it has been flagged to
>>>>>>>>>>                                 management, but 1) it's low
>>>>>>>>>>                                 priority 2) it's too risky to
>>>>>>>>>>                                 fix for JDK8
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                                 *Why all this urgency?
>>>>>>>>>>                                 *If a system time change
>>>>>>>>>>                                 happens then all the threads
>>>>>>>>>>                                 parked will hang, with
>>>>>>>>>>                                 unpredictable/corrupted/useless
>>>>>>>>>>                                 results to the end user. Same
>>>>>>>>>>                                 applies to Future, Queue,
>>>>>>>>>>                                 Executor, and (I guess) any
>>>>>>>>>>                                 other construct that it's
>>>>>>>>>>                                 somehow related to
>>>>>>>>>>                                 concurrency. This is a big
>>>>>>>>>>                                 issue for us and for any near
>>>>>>>>>>                                 time application: please
>>>>>>>>>>                                 think about trading and
>>>>>>>>>>                                 betting, where the JVM is
>>>>>>>>>>                                 largely used, and  do not
>>>>>>>>>>                                 restrain yourself to the Java
>>>>>>>>>>                                 language: add Scala and any
>>>>>>>>>>                                 other JVM-based language to
>>>>>>>>>>                                 the picture (JRuby, Jython...)
>>>>>>>>>>
>>>>>>>>>>                                 *Tech details**
>>>>>>>>>>                                 *To be more clear about the
>>>>>>>>>>                                 issue, the extent of it and
>>>>>>>>>>                                 the concurrency library, let
>>>>>>>>>>                                 me introduce this very simple
>>>>>>>>>>                                 program:
>>>>>>>>>>
>>>>>>>>>>                                 import
>>>>>>>>>>                                 java.util.concurrent.locks.LockSupport;
>>>>>>>>>>
>>>>>>>>>>                                 public class Main {
>>>>>>>>>>
>>>>>>>>>>                                     public static void
>>>>>>>>>>                                 main(String[] args) {
>>>>>>>>>>
>>>>>>>>>>                                         for (int i=100; i>0;
>>>>>>>>>>                                 i--) {
>>>>>>>>>>                                 System.out.println(i);
>>>>>>>>>>                                 LockSupport.parkNanos(1000L*1000L*1000L);
>>>>>>>>>>                                         }
>>>>>>>>>>
>>>>>>>>>>                                 System.out.println("Done!");
>>>>>>>>>>                                     }
>>>>>>>>>>                                 }
>>>>>>>>>>
>>>>>>>>>>                                 Run it with a 64bit 1.6+ JVM
>>>>>>>>>>                                 on 64bit Linux, turn the
>>>>>>>>>>                                 clock down one hour and wait
>>>>>>>>>>                                 until the counter stops...
>>>>>>>>>>                                 magic!  I tested this on
>>>>>>>>>>                                 JDK6, JDK7 and latest JDK8
>>>>>>>>>>                                 beta running on various
>>>>>>>>>>                                 Ubuntu distros. It's not just
>>>>>>>>>>                                 a matter of (old?) sleep()
>>>>>>>>>>                                 and wait() primitives, this
>>>>>>>>>>                                 issue it affects the whole
>>>>>>>>>>                                 concurrency library.
>>>>>>>>>>
>>>>>>>>>>                                 To prove that this is
>>>>>>>>>>                                 fixable, I reimplemented the
>>>>>>>>>>                                 program above above
>>>>>>>>>>                                 substituting
>>>>>>>>>>                                 LockSupport.parkNanos() with 
>>>>>>>>>>                                 a JNI call to
>>>>>>>>>>                                 clock_nanosleep(CLOCK_MONOTONIC...):
>>>>>>>>>>                                 works like a charm :(
>>>>>>>>>>
>>>>>>>>>>                                 This is due to the fact  that
>>>>>>>>>>                                 the CPP code is calling the
>>>>>>>>>>                                 pthread_cond_timedwait()
>>>>>>>>>>                                 using its default clock
>>>>>>>>>>                                 (CLOCK_REALTIME) which,
>>>>>>>>>>                                 unfortunately is affected by
>>>>>>>>>>                                 settime()/settimeofday()
>>>>>>>>>>                                 calls (on Linux): for that
>>>>>>>>>>                                 reason it cannot be used to
>>>>>>>>>>                                 measure nanoseconds delays,
>>>>>>>>>>                                 which is what the
>>>>>>>>>>                                 specification
>>>>>>>>>>                                 <http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos%28long%29>
>>>>>>>>>>                                 requires. CLOCK_REALTIME is
>>>>>>>>>>                                 not guaranteed to
>>>>>>>>>>                                 monotonically count as this
>>>>>>>>>>                                 is the actual "system time":
>>>>>>>>>>                                 each time my system syncs
>>>>>>>>>>                                 time using a NTP server on
>>>>>>>>>>                                 the net, the time might jump
>>>>>>>>>>                                 forward or backward. The
>>>>>>>>>>                                 correct call (again on
>>>>>>>>>>                                 Linux)  would require to use
>>>>>>>>>>                                 CLOCK_MONOTONIC as clock id,
>>>>>>>>>>                                 which are defined by POSIX
>>>>>>>>>>                                 specs since 2002. (or better
>>>>>>>>>>                                 CLOCK_MONOTONIC_RAW)
>>>>>>>>>>
>>>>>>>>>>                                 The POSIX spec
>>>>>>>>>>                                 <http://pubs.opengroup.org/onlinepubs/007904975/functions/clock_settime.html>
>>>>>>>>>>                                 is infact clear, as it states
>>>>>>>>>>                                 "...setting the value of the
>>>>>>>>>>                                 CLOCK_REALTIME clock via
>>>>>>>>>>                                 clock_settime() shall have no
>>>>>>>>>>                                 effect on threads that are
>>>>>>>>>>                                 blocked waiting for a
>>>>>>>>>>                                 *relative* time service based
>>>>>>>>>>                                 upon this clock...": it
>>>>>>>>>>                                 definitely states "relative".
>>>>>>>>>>                                 Having a look at the hotspot
>>>>>>>>>>                                 code
>>>>>>>>>>                                 <http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/9b0ca45cd756/src/os/linux/vm/os_linux.cpp>,
>>>>>>>>>>                                 it appears that the park() is
>>>>>>>>>>                                 using compute_abstime()
>>>>>>>>>>                                 (which uses timeofday) and
>>>>>>>>>>                                 then waits on an absolute
>>>>>>>>>>                                 period: for that reason it's
>>>>>>>>>>                                 influenced by the system
>>>>>>>>>>                                 clock change. *Very wrong*.
>>>>>>>>>>
>>>>>>>>>>                                 I will be happy to know what
>>>>>>>>>>                                 you think, and if you can
>>>>>>>>>>                                 help me to escalate this
>>>>>>>>>>                                 issue I think that the all
>>>>>>>>>>                                 Java community will benefit
>>>>>>>>>>                                 from it.
>>>>>>>>>>
>>>>>>>>>>                                 Cheers,
>>>>>>>>>>
>>>>>>>>>>                                     Bruno
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                         No virus found in this message.
>>>>>>>>>>                         Checked by AVG - www.avg.com
>>>>>>>>>>                         <http://www.avg.com/>
>>>>>>>>>>                         Version: 2013.0.3392 / Virus
>>>>>>>>>>                         Database: 3222/6633 - Release Date:
>>>>>>>>>>                         09/03/13
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>                 _______________________________________________
>>>>>>>>>>                 Concurrency-interest mailing list
>>>>>>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>     _______________________________________________
>>>>>>     Concurrency-interest mailing list
>>>>>>     Concurrency-interest at cs.oswego.edu
>>>>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> -- 
>>>>>> *Viktor Klang*
>>>>>> /Director of Engineering/
>>>>>> Typesafe <http://www.typesafe.com/>
>>>>>>
>>>>>> Twitter: @viktorklang
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu 
>>>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>> --
>>>> [scala-debate on 2009/10/2]
>>>> Viktor Klang: When will the days of numerical overflow be gone?
>>>> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 
>>>> January 2038
>>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> --
> Simplicity and elegance are unpopular because they require hard work 
> and discipline to achieve and education to be appreciated.
>   -- Dijkstra
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130905/34d14c6a/attachment-0001.html>

From howard.lovatt at gmail.com  Thu Sep  5 20:02:52 2013
From: howard.lovatt at gmail.com (Howard Lovatt)
Date: Fri, 6 Sep 2013 10:02:52 +1000
Subject: [concurrency-interest] Coordinated Runnables
In-Reply-To: <loom.20130905T130213-237@post.gmane.org>
References: <loom.20130829T134152-308@post.gmane.org>
	<CACuKZqESAPOuhU9Dw8uSDG=Dw8wR=HqtRGp1gQQdhZQsTzrmxA@mail.gmail.com>
	<CALCS1ZVfVMaqDO-EVF0b0jqiesmC+6B5_oFgDL6gK9qR2MJUQA@mail.gmail.com>
	<CANPzfU86zVgaE8hL5j+Jz1VWOJrzALv5Suy_vygvjw=Z7VoVQg@mail.gmail.com>
	<CALCS1ZV2sneM8Bd=Wa_DHPq8A+=MVJD=Ojh8JHxUgnTOvqUTQQ@mail.gmail.com>
	<17354802-F051-4A26-90B4-6B48B84707D4@rkuhn.info>
	<CACR_FB4G+7jr-Jb+-SyRgGBU=XAV2vqk2J=GNDzjshwryxdAmA@mail.gmail.com>
	<loom.20130905T130213-237@post.gmane.org>
Message-ID: <CACR_FB4OccFvZtjBwsDyDWR26sFu4C8gLvONGpHQYBPww9o7qQ@mail.gmail.com>

Yes the technique requires multiple threads to work. However techniques
that will run in a single threaded environment pay a throughput penalty (a
large one). See this discussion and microbenchmark for details:

http://cs.oswego.edu/pipermail/concurrency-interest/2013-August/011749.html

For me I wanted throughput, that was why I was writing parallel code!
Therefore it was the right compromise for me. If however you don't need
throughput then you could change the mechanism from that used, double check
locking, to something else (see microbenchmark for possibilities). You
would just have to change the body of the Vertex class methods that did the
actual locking, your application code would remain the same. You could even
have a safe and high throughput version of each of the Vertex classes to
enable either option.

I posted the code to give you some ideas of what might work for you, if its
not for you don't use it.

 -- Howard.


On 5 September 2013 21:10, Alexei Kaigorodov <alexei.kaigorodov at gmail.com>wrote:

> Howard Lovatt <howard.lovatt <at> gmail.com> writes:
>
> >
> >
> > Hi Alexei,
> > For this type of problem I use my own Graph library, works well for me.
> See below for an example. It might give you some ideas at least.
> >
> >  -- Howard.
> >
> >
>
> Are you serious? Your program falls in infinite loop when thread pool of
> fixed size 1 was used. Indeed, some methods (e.g. BufferingVertex.add())
> cycle while some value become not null, but because they occupy the single
> working thread, other tasks have no chance to set that value. This is not
> the way multithreading programs are designed.
>
> thanks,
> Alexei
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
  -- Howard.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130906/ba136ad2/attachment.html>

From aph at redhat.com  Fri Sep  6 04:56:51 2013
From: aph at redhat.com (Andrew Haley)
Date: Fri, 06 Sep 2013 09:56:51 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <256C5E34-4581-411F-BA35-31FD8360AD2F@rkuhn.info>
References: <CAJU-cALW3SVYjFqanZ8zcRD4bbYg2i-Xk4F0Umngr0720+aMOA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEDKAAA.davidcholmes@aapt.net.au>
	<CAJU-cAJO+S2SESSPwueejqrq9tUu977uoE2tKwAjT34fQ6LMtA@mail.gmail.com>
	<52276185.6070902@oracle.com>
	<CAJU-cAJ70KJQ1-L50+v2JZYX9VnwfjLB87598dr4RZYWqu0_Sw@mail.gmail.com>
	<5227759F.7060300@oracle.com>
	<CAJU-cAJzhx2Q7DBQyR3NzGdr5Sm02JOehVSMAuk1uw804ffkXw@mail.gmail.com>
	<52289F6B.7020405@oracle.com>
	<CAJU-cALR+ubdyqXxUwUtZJ-jc0XiJ_0G5VBboSMPbJLW7Frgog@mail.gmail.com>
	<5228BA0B.2050306@oracle.com>
	<CANPzfU-Gj5TXkT6MVogmec=z0hJw7iEouTRwHmd896en3hCAeg@mail.gmail.com>
	<5228C351.4070009@oracle.com>
	<966A34E3-3BB9-41CB-96C2-5A4A5B116233@rkuhn.info>
	<5228D081.9040705@oracle.com> <5228D734.2050703@oracle.com>
	<256C5E34-4581-411F-BA35-31FD8360AD2F@rkuhn.info>
Message-ID: <522998D3.20003@redhat.com>

On 09/05/2013 08:41 PM, Roland Kuhn wrote:

> Delivering a wake-up 1h late?especially when the system itself is
> working fine?is definitely outside of the expected range on such
> systems.

It's not outside the range of what *I* expect, and that's the point:
naive users should not have root passwords on important systems.  It's
not just about Java.  Java does not exist in a vacuum.  There will be
all manner of other programs running on that system.

So, fixing this problem in Java will not make such an action safe.
This is an education issue.

It's also what NTP was invented for.

Andrew.

From dl at cs.oswego.edu  Fri Sep  6 20:13:00 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 06 Sep 2013 20:13:00 -0400
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
Message-ID: <522A6F8C.8060307@cs.oswego.edu>


A few notes on this.

I was a co-developer (mainly with Dave Dice) of the original
JDK5 hotspot park/unpark support. We were painfully aware of
the fact that even a very weak spec was not always possible
to get exactly right on all Systems, that are full of quirks.
Among other issues, different libraries, OS calls, and hardware
level support can switch from absolute to relative time and back;
The millis and nanos clocks may or may not be the same;
different cores/cpus can have different views of time; the effects
of NTP on different clocks is not always knowable. And so on.
Despite all this, the base LockSupport API and the j.u.c components
using it were successful enough that oddities tended to show up
only in usages that were questionable to begin with.

Bruno's main complaint/suggestion, that on modern linux systems,
timed parks should use CLOCK_MONOTONIC is a good one. (This wan't
an option in initial versions). I'm happy to see David Holmes
taking on exploring this and providing a patch. But as
other posters have mentioned, it will only make a few anomalies
go away. It won't guarantee perfection.

-Doug



On 09/03/2013 11:55 AM, bruno bossola wrote:
> Hi all,
>
> I am writing here following a suggestion by Ben Evans. I wanted to check with
> you about an issue that my teams found on the JVM and that's very frightening. I
> already started the discussion with the engineers of the hotspot VM team but it
> looks like we need more awareness to solve this one and I'd really appreciate
> some help and some push :)
> It looks to me that this issue is affecting every JVM64 running on Linux64, so
> imho it's quite important to be looked at.
>
> *Executive summary
> *The implementation of the concurrency primitive LockSupport.parkNanos(), the
> function that controls most concurrency primitive on the JVM, is flawed, and any
> NTP sync, or system time change, can potentially break it with unexpected
> results across the board.
>

From martijnverburg at gmail.com  Sat Sep  7 02:47:21 2013
From: martijnverburg at gmail.com (Martijn Verburg)
Date: Sat, 7 Sep 2013 07:47:21 +0100
Subject: [concurrency-interest] Outstanding concurrency JVM issue -
	feedback?
In-Reply-To: <522A6F8C.8060307@cs.oswego.edu>
References: <CAJU-cALHAOCxZYNssqmfVTMoGeEsKOCV3MDL4ZMo06vQO-ZS6w@mail.gmail.com>
	<522A6F8C.8060307@cs.oswego.edu>
Message-ID: <CAP7YuARq-UuJWe4hBc78wim48LFAG8OwgZZ8-p-TFfkCZG46_A@mail.gmail.com>

+1 - We're starting to see an industry shift of folks trying out Java/JVM
in cloud / managed virtualised environments as a mainstream option.
Chipping away at anomalies like this (even if there is no perfect
answer/'fix') is actually surprisingly important for the JVM to be
accepted/chosen in this space. As Bruno pointed out, one of his initial
reactions was that he seriously considered having to drop Java and use a
different technology, which for his main use case he won't have to do now
and that's a good thing.


Cheers,
Martijn


On 7 September 2013 01:13, Doug Lea <dl at cs.oswego.edu> wrote:

>
> A few notes on this.
>
> I was a co-developer (mainly with Dave Dice) of the original
> JDK5 hotspot park/unpark support. We were painfully aware of
> the fact that even a very weak spec was not always possible
> to get exactly right on all Systems, that are full of quirks.
> Among other issues, different libraries, OS calls, and hardware
> level support can switch from absolute to relative time and back;
> The millis and nanos clocks may or may not be the same;
> different cores/cpus can have different views of time; the effects
> of NTP on different clocks is not always knowable. And so on.
> Despite all this, the base LockSupport API and the j.u.c components
> using it were successful enough that oddities tended to show up
> only in usages that were questionable to begin with.
>
> Bruno's main complaint/suggestion, that on modern linux systems,
> timed parks should use CLOCK_MONOTONIC is a good one. (This wan't
> an option in initial versions). I'm happy to see David Holmes
> taking on exploring this and providing a patch. But as
> other posters have mentioned, it will only make a few anomalies
> go away. It won't guarantee perfection.
>
> -Doug
>
>
>
> On 09/03/2013 11:55 AM, bruno bossola wrote:
>
>> Hi all,
>>
>> I am writing here following a suggestion by Ben Evans. I wanted to check
>> with
>> you about an issue that my teams found on the JVM and that's very
>> frightening. I
>> already started the discussion with the engineers of the hotspot VM team
>> but it
>> looks like we need more awareness to solve this one and I'd really
>> appreciate
>> some help and some push :)
>> It looks to me that this issue is affecting every JVM64 running on
>> Linux64, so
>> imho it's quite important to be looked at.
>>
>> *Executive summary
>> *The implementation of the concurrency primitive LockSupport.parkNanos(),
>> the
>> function that controls most concurrency primitive on the JVM, is flawed,
>> and any
>> NTP sync, or system time change, can potentially break it with unexpected
>> results across the board.
>>
>>  ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130907/ea553aea/attachment.html>

From hallorant at gmail.com  Mon Sep 16 17:10:58 2013
From: hallorant at gmail.com (Tim Halloran)
Date: Mon, 16 Sep 2013 17:10:58 -0400
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
	properly
Message-ID: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>

I've been trying out JEP 171 with Java 8, but have not found many
examples of its use.

So, I cooked up one (the complete code is at the bottom) that has two
nested classes access a "per-use volatile" static boolean field which
is declared as

  static boolean running = true;

One thread is a trivial "work until signaled" that does

  do {
    // stuff
    unsafe.loadFence();
  } while (running);

the second thread signals to stop, via the boolean field, after
(roughly) two seconds

  sleepTwoSeconds: try { Thread.sleep(2000); } catch
(InterruptedException ignore) {}
  running = false;
  unsafe.storeFence();

First, this example is wholly contrived and there is no reason to
implement this convoluted way except try try out JEP 171 on Java 8.

Second, if you comment out the unsafe.*Fence() calls the program hangs
forever -- as one would expect (at the worker.join() call in the full
code below because the first thread never sees the change in the
boolean).

Third, I'm not sure this code is correct -- in particular ONLY the
unsafe.loadFence() call seems to have any impact on program behavior
(put another way, you can comment out the unsafe.storeFence() in the
second thread and the boolean field's state change is still visible).
BUT I'm wondering if this is because I'm running Java 8 on a MacBook
Pro (Intel Core i5) and some of these calls are no-ops?  (per the JSR
133 cookbook)

This leads to my query if there are some examples of this JEP in use I
missed when searching. In particular where fullFence() and
storeFence() are used.

Thanks!

Best regards,
Tim Halloran


The complete example code listing:


import java.lang.reflect.*;
import java.util.concurrent.*;
import sun.misc.Unsafe;

class Fencer {

  static final CountDownLatch latch = new CountDownLatch(1);
  static final Unsafe unsafe;
  static {
    try {
      Field field = Unsafe.class.getDeclaredField("theUnsafe");
      field.setAccessible(true);
      unsafe = (Unsafe) field.get(null);
    } catch (Exception e) {
      throw new AssertionError(e);
    }
  }

  static boolean running = true;

  static class WorkUntilSignal extends Thread {
    public void run() {
       startTogether: try { latch.await(); } catch
(InterruptedException ignore) {}

       do {
         // stuff
         unsafe.loadFence();
       } while (running);
    }
  }

  static class Signaller extends Thread {
    public void run() {
       startTogether: try { latch.await(); } catch
(InterruptedException ignore) {}
       sleepTwoSeconds: try { Thread.sleep(2000); } catch
(InterruptedException ignore) {}
       running = false;
       unsafe.storeFence();
    }
  }

  public static void main(String[] args) throws InterruptedException {
    final WorkUntilSignal worker = new WorkUntilSignal();
    final Signaller signaller = new Signaller();

    worker.start();
    signaller.start();
    latch.countDown(); // start together

    signaller.join();
    System.out.println("Signaller finished...");
    worker.join();
    System.out.println("Worker finished...");
  }
}

From nathan.reynolds at oracle.com  Mon Sep 16 18:02:30 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 16 Sep 2013 15:02:30 -0700
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
 properly
In-Reply-To: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
References: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
Message-ID: <52377FF6.5070308@oracle.com>

x86 memory model forces stores to be completed in program order.  The 
storeFence() simply keeps JIT from rearranging the store with subsequent 
stores.  Because the signaller thread exits, this forces all stores to 
happen eventually.  So, the storeFence() isn't really needed in this 
example.  In order to show storeFence() as significant, you would need 
to have 2 stores where the order in which they are execute matters.

-Nathan

On 9/16/2013 2:10 PM, Tim Halloran wrote:
> I've been trying out JEP 171 with Java 8, but have not found many
> examples of its use.
>
> So, I cooked up one (the complete code is at the bottom) that has two
> nested classes access a "per-use volatile" static boolean field which
> is declared as
>
>    static boolean running = true;
>
> One thread is a trivial "work until signaled" that does
>
>    do {
>      // stuff
>      unsafe.loadFence();
>    } while (running);
>
> the second thread signals to stop, via the boolean field, after
> (roughly) two seconds
>
>    sleepTwoSeconds: try { Thread.sleep(2000); } catch
> (InterruptedException ignore) {}
>    running = false;
>    unsafe.storeFence();
>
> First, this example is wholly contrived and there is no reason to
> implement this convoluted way except try try out JEP 171 on Java 8.
>
> Second, if you comment out the unsafe.*Fence() calls the program hangs
> forever -- as one would expect (at the worker.join() call in the full
> code below because the first thread never sees the change in the
> boolean).
>
> Third, I'm not sure this code is correct -- in particular ONLY the
> unsafe.loadFence() call seems to have any impact on program behavior
> (put another way, you can comment out the unsafe.storeFence() in the
> second thread and the boolean field's state change is still visible).
> BUT I'm wondering if this is because I'm running Java 8 on a MacBook
> Pro (Intel Core i5) and some of these calls are no-ops?  (per the JSR
> 133 cookbook)
>
> This leads to my query if there are some examples of this JEP in use I
> missed when searching. In particular where fullFence() and
> storeFence() are used.
>
> Thanks!
>
> Best regards,
> Tim Halloran
>
>
> The complete example code listing:
>
>
> import java.lang.reflect.*;
> import java.util.concurrent.*;
> import sun.misc.Unsafe;
>
> class Fencer {
>
>    static final CountDownLatch latch = new CountDownLatch(1);
>    static final Unsafe unsafe;
>    static {
>      try {
>        Field field = Unsafe.class.getDeclaredField("theUnsafe");
>        field.setAccessible(true);
>        unsafe = (Unsafe) field.get(null);
>      } catch (Exception e) {
>        throw new AssertionError(e);
>      }
>    }
>
>    static boolean running = true;
>
>    static class WorkUntilSignal extends Thread {
>      public void run() {
>         startTogether: try { latch.await(); } catch
> (InterruptedException ignore) {}
>
>         do {
>           // stuff
>           unsafe.loadFence();
>         } while (running);
>      }
>    }
>
>    static class Signaller extends Thread {
>      public void run() {
>         startTogether: try { latch.await(); } catch
> (InterruptedException ignore) {}
>         sleepTwoSeconds: try { Thread.sleep(2000); } catch
> (InterruptedException ignore) {}
>         running = false;
>         unsafe.storeFence();
>      }
>    }
>
>    public static void main(String[] args) throws InterruptedException {
>      final WorkUntilSignal worker = new WorkUntilSignal();
>      final Signaller signaller = new Signaller();
>
>      worker.start();
>      signaller.start();
>      latch.countDown(); // start together
>
>      signaller.join();
>      System.out.println("Signaller finished...");
>      worker.join();
>      System.out.println("Worker finished...");
>    }
> }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130916/9e7ae7be/attachment.html>

From vitalyd at gmail.com  Mon Sep 16 20:19:57 2013
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 16 Sep 2013 20:19:57 -0400
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
	properly
In-Reply-To: <52377FF6.5070308@oracle.com>
References: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
	<52377FF6.5070308@oracle.com>
Message-ID: <CAHjP37FVSWU4nCPs1C1yFoDWfpsg_-5+RT_=pqmC0W+XkpJ49g@mail.gmail.com>

I'm not even sure the fact that signaller exits matters so long as it runs
at least one iteration that performs the write; eventually, the stores are
written out to cache, and reader picks them up.  The load fence just
prevents compiler from hoisting the read out of the loop (and thus causing
the infloop).

Sent from my phone
On Sep 16, 2013 6:09 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

>  x86 memory model forces stores to be completed in program order.  The
> storeFence() simply keeps JIT from rearranging the store with subsequent
> stores.  Because the signaller thread exits, this forces all stores to
> happen eventually.  So, the storeFence() isn't really needed in this
> example.  In order to show storeFence() as significant, you would need to
> have 2 stores where the order in which they are execute matters.
>
> -Nathan
>
> On 9/16/2013 2:10 PM, Tim Halloran wrote:
>
> I've been trying out JEP 171 with Java 8, but have not found many
> examples of its use.
>
> So, I cooked up one (the complete code is at the bottom) that has two
> nested classes access a "per-use volatile" static boolean field which
> is declared as
>
>   static boolean running = true;
>
> One thread is a trivial "work until signaled" that does
>
>   do {
>     // stuff
>     unsafe.loadFence();
>   } while (running);
>
> the second thread signals to stop, via the boolean field, after
> (roughly) two seconds
>
>   sleepTwoSeconds: try { Thread.sleep(2000); } catch
> (InterruptedException ignore) {}
>   running = false;
>   unsafe.storeFence();
>
> First, this example is wholly contrived and there is no reason to
> implement this convoluted way except try try out JEP 171 on Java 8.
>
> Second, if you comment out the unsafe.*Fence() calls the program hangs
> forever -- as one would expect (at the worker.join() call in the full
> code below because the first thread never sees the change in the
> boolean).
>
> Third, I'm not sure this code is correct -- in particular ONLY the
> unsafe.loadFence() call seems to have any impact on program behavior
> (put another way, you can comment out the unsafe.storeFence() in the
> second thread and the boolean field's state change is still visible).
> BUT I'm wondering if this is because I'm running Java 8 on a MacBook
> Pro (Intel Core i5) and some of these calls are no-ops?  (per the JSR
> 133 cookbook)
>
> This leads to my query if there are some examples of this JEP in use I
> missed when searching. In particular where fullFence() and
> storeFence() are used.
>
> Thanks!
>
> Best regards,
> Tim Halloran
>
>
> The complete example code listing:
>
>
> import java.lang.reflect.*;
> import java.util.concurrent.*;
> import sun.misc.Unsafe;
>
> class Fencer {
>
>   static final CountDownLatch latch = new CountDownLatch(1);
>   static final Unsafe unsafe;
>   static {
>     try {
>       Field field = Unsafe.class.getDeclaredField("theUnsafe");
>       field.setAccessible(true);
>       unsafe = (Unsafe) field.get(null);
>     } catch (Exception e) {
>       throw new AssertionError(e);
>     }
>   }
>
>   static boolean running = true;
>
>   static class WorkUntilSignal extends Thread {
>     public void run() {
>        startTogether: try { latch.await(); } catch
> (InterruptedException ignore) {}
>
>        do {
>          // stuff
>          unsafe.loadFence();
>        } while (running);
>     }
>   }
>
>   static class Signaller extends Thread {
>     public void run() {
>        startTogether: try { latch.await(); } catch
> (InterruptedException ignore) {}
>        sleepTwoSeconds: try { Thread.sleep(2000); } catch
> (InterruptedException ignore) {}
>        running = false;
>        unsafe.storeFence();
>     }
>   }
>
>   public static void main(String[] args) throws InterruptedException {
>     final WorkUntilSignal worker = new WorkUntilSignal();
>     final Signaller signaller = new Signaller();
>
>     worker.start();
>     signaller.start();
>     latch.countDown(); // start together
>
>     signaller.join();
>     System.out.println("Signaller finished...");
>     worker.join();
>     System.out.println("Worker finished...");
>   }
> }
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130916/e54e42a6/attachment.html>

From davidcholmes at aapt.net.au  Tue Sep 17 02:37:12 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 17 Sep 2013 16:37:12 +1000
Subject: [concurrency-interest] Outstanding concurrency JVM
	issue-feedback?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEELKAAA.davidcholmes@aapt.net.au>
Message-ID: <ABEHILABNFKEAJNKLENCEEDOCKAA.davidcholmes@aapt.net.au>

The fix for this has been pushed to hs25 repo for JDK 8. It should appear in
build b109.

Backports also in progress but I can't say when/where they will appear at
this time.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David Holmes
  Sent: Thursday, 5 September 2013 12:28 PM
  To: bruno bossola; Oleksandr Otenko
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Outstanding concurrency JVM
issue-feedback?


  Bruno,

  The issue is not that a problem can exist in some code - we already know
that is the case and we know exactly how it will manifest. The problem is
your claim "we are talking about the whole concurrency lot" and "all the
threads parked will hang, with unpredictable/corrupted/useless" - which is
simply untrue.

  Anyway I am working to get this fixed.

  David
    -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno
bossola
    Sent: Thursday, 5 September 2013 11:13 AM
    To: Oleksandr Otenko
    Cc: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] Outstanding concurrency JVM
issue -feedback?


    Hi Oaleksandr,


    Please apologize me if my english was not good enough to provide you an
example that make sense: for that reason I decided to go back to a binary
deliverable (code) that shows the problem, hope this helps!


    This is my PreciousPool class, that handles Precious resources:

    import java.text.SimpleDateFormat;
    import java.util.ArrayList;
    import java.util.Date;
    import java.util.List;
    import java.util.concurrent.TimeUnit;
    import java.util.concurrent.locks.Condition;
    import java.util.concurrent.locks.Lock;
    import java.util.concurrent.locks.ReentrantLock;

    public class PreciousPool {

        public static class Precious {
            private final int id;

            private Precious() {
                this.id = 100+(int)(Math.random()*900.0);
            }

            public String toString() {
                return "Precious n."+id;
            }
        }

        private final Lock lock;
        private final Condition ready;
        private final long timeoutInMillis;

        private final List<Precious> preciousLended;
        private final List<Precious> preciousAvailable;

        public PreciousPool(int size, long timeoutInSeconds) {
            this.lock = new ReentrantLock();
            this.ready = lock.newCondition();

            this.timeoutInMillis = 1000L*timeoutInSeconds;
            this.preciousLended =  new ArrayList<Precious>();
            this.preciousAvailable = new ArrayList<Precious>();

            for (int i = 0; i < size; i++) {
                preciousAvailable.add(new Precious());
            }
        }

        public Precious obtain()  {
            lock.lock();
            try {
                // if no precious are available we wait for the specified
timeout (releasing the lock so that others can try)
                if (preciousAvailable.size() == 0) {
                    try {
                        ready.await(timeoutInMillis, TimeUnit.MILLISECONDS);
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                        throw new RuntimeException("Somebody interrupted
me!", e);
                    }
                }

                // if a precious is available we unload it and return to the
caller, otherwise null
                if (preciousAvailable.size() > 0) {
                    Precious value = preciousAvailable.remove(0);
                    preciousLended.add(value);
                    return value;
                } else {
                    return null;
                }
            } finally {
                lock.unlock();
            }
        }

        public void release(Precious value) {
            lock.lock();
            try {
                if (!preciousLended.remove(value))
                    throw new RuntimeException("Element "+value+" was not
lended!");

                // if a precious is returned we put it back and signal to
anybody waiting
                preciousAvailable.add(value);
                ready.signalAll();
            } finally {
                lock.unlock();
            }
        }

        public static void main(String args[]) {
            final int size = 3;
            final PreciousPool pool = new PreciousPool(size, 5);

            // let's exhaust the pool
            for (int i=0; i<size; i++)
                dump(pool.obtain());

            // and as we are stubborn we continuosly ask for a new one
            while(true) {
                dump(pool.obtain());
            }
        }

        private static void dump(Precious precious) {
            if (precious == null)
                log("I did not get my precious :(");
            else
                log("I did get my precious! "+precious);
        }

        private static void log(String message) {
            final String now = new SimpleDateFormat("HH:mm:ss:SSSS
").format(new Date());
            System.out.println(now + message);
        }
    }


    So, the main is a single thread (no need for multithreading here, let's
keep it simple), that first exhaust the whole pool and then keep asking,
without success, for a resource. Stubborn guy, I say, but it happens. If you
run this program everything works as expected: you are greeted by a three
successful Precious and then an endless list of failures, that it
continuously grow. All good :)

    02:34:40:0061 I did get my precious! Precious n.156
    02:34:40:0062 I did get my precious! Precious n.991
    02:34:40:0062 I did get my precious! Precious n.953
    02:34:45:0064 I did not get my precious :(
    02:34:50:0065 I did not get my precious :(
    02:34:55:0066 I did not get my precious :(
    02:35:00:0067 I did not get my precious :(
    02:35:05:0068 I did not get my precious :(
    [...]


    But guess what happens when, while the program is running, I change the
date of my system back of one hour? Everything stops,  it's simple as that.
No prints, nothing, zero, nada. Now, If it wasn't so late, I would probably
wait one hour in order to have my program restored to his normal process,
but as a customer I won't be terribly happy :)


    I hope my point is now clear.

    Cheers,


        Bruno










    On Wed, Sep 4, 2013 at 7:02 PM, Oleksandr Otenko
<oleksandr.otenko at oracle.com> wrote:

      n 04/09/2013 18:54, bruno bossola wrote:

        Hi Oleksandr,


          Where in the design of those systems is a real-time timer? The one
that delivers time events uncompromised even by GC latency?


        I don't think so :) If somebody needs a real time implementation he
needs to go for a real time JVM, like Jean correctly pointed out.  The
concurrency primitives are depending on LockSupport.parkNanos(...) to park a
thread: if this for any reason is not working (like it is) then strange
things may happen.

      Your assumption is that it is not working, if the elapsed time is
longer. This is the flawed assumption.

      Also, you need to read fine print on those "real time" JVMs. The catch
is in the definition of "real time".





        Imagine, for example, that you are using a ReentrantLock to control
a very precious resource used across the board (what about a database
connection pool?) and you are unlucky enough to have a system time change
(backwards) while you are locking: all the threads that want to use such
resource will be progressively locked: not forever, but for the amount of
time the clock went back. Probably most (all?) of your system freezes, and
the only option you have is to wait, or restart.

        Now place this in a large application server, that provide services
for hunreds (thousands) of users. How does it sound to you?

      It sounds like you don't understand how the locks work.


      Alex





        BTW, at the moment we could have a watchdog (in Python :)) that
restarts it, but, I dunno why, I don't like it a lot...


        Cheers,


            Bruno









        On Wed, Sep 4, 2013 at 5:36 PM, Oleksandr Otenko
<oleksandr.otenko at oracle.com> wrote:

          You are missing the point.

          Where in the design of those systems is a real-time timer? The one
that delivers time events uncompromised even by GC latency?

          The whole concurrency lot does not depend on the timeout magnitude
for correctness.

          Alex



          On 04/09/2013 12:05, bruno bossola wrote:

            Hi David




              bugs.sun.com is not a live reflection of the bug database but
gets updated periodically (every 12 hours I think).



            Good to know :) I will be eagerly clicking on it to discover the
new priority! Thanks for that, I really appreciate it.



              The issue arises on certain 64-bit linux kernel/glibc
versions. If you have an older version this does not impact you.


            You saw my list: nobody will use an older Kernel/glibc version
in production.



              As for the rest, show me real code in such systems that rely
on sleep for correctness or performance/timeliness and I will show you
broken code.

            You are still hitting about the sleep(), I understand and I
agree about this. But here we are not talking about sleeps: we are talking
about the whole concurrency lot. And yes, as I already said, we are talking
about near time systems, like trading application, betting applications, air
traffic control systems, car traffic control systems. Don't you think this
bug might place Oracle JVM outside of these markets?



              If this was as dire as you make out do you not think that this
issue would have been raised far more than it has? [....] prudent
developers/companies trial platform upgrades to check for these kinds of
issues before switching to them in production environments.


            I am waiting now for the part where you say that we should throw
away Linux and use Oracle Solaris :)  In all seriousness, there's a lot of
action "in the middle", and I think that Oracle cannot oversee that. For
example a lot of trading software system can be installed on premises, where
you usually have no control over the environment: what I would do is to put
a native daemon in my app so that if I see the system clock change I would
kill myself, just in case. And this is a solution that I know for a fact
(sorry, I cannot make a reference) it's used in production in a very
important trading application.

            Regarding that specific bug, it was not accessible to the
external until two days ago, so I guess nobody really knew a lot about it,
but I will make sure it will :) so that we can get more traction.


            Cheers,


                Bruno





            On Wed, Sep 4, 2013 at 2:32 AM, David Holmes
<davidcholmes at aapt.net.au> wrote:

              Bruno,

              bugs.sun.com is not a live reflection of the bug database but
gets updated periodically (every 12 hours I think).

              The issue arises on certain 64-bit linux kernel/glibc
versions. If you have an older version this does not impact you.

              As for the rest, show me real code in such systems that rely
on sleep for correctness or performance/timeliness and I will show you
broken code. We are not talking about real-time systems here.
park(nanos)/wait(millis) will only be affected by the backward time change
if the real notification they are waiting for does not happen. Timeouts with
these APIs are heuristics, they are defensive programming to cover the case
"what if the notification I'm waiting for does not come". The code that
would be affected by this issue is a very small % of the code that uses the
API.

              If this was as dire as you make out do you not think that this
issue would have been raised far more than it has? This issue does need
addressing because the number of affected systems will grow as these newer
linux systems are adopted, but prudent developers/companies trial platform
upgrades to check for these kinds of issues before swicthing to them in
production environments.

              Regards,
              David
                -----Original Message-----
                From: bruno bossola [mailto:bbossola at gmail.com]
                Sent: Wednesday, 4 September 2013 11:14 AM
                To: dholmes at ieee.org
                Cc: concurrency-interest at cs.oswego.edu
                Subject: Re: [concurrency-interest] Outstanding concurrency
JVM issue - feedback?


                Hi David,


                thanks for following up.



                  I have raised the priority on 6900441


                Thanks, but it looks still like a P4:
                http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6900441
                See also the attached snapshot, just in case it changes :)






                  [...] which to my knowledge [...] has never been a private
bug

                It was not accessible using bugs.sun.com, this was
translated to private. I also received the same info indirectly from the 7u
lead:
                "I'm not sure why 6900441 isn't public. (I'll follow up with
owner of bugs.sun.com)", I guess you can check with him.




                  It doesn't affect "every JVM64 running on Linux64".  A fix
has been introduced into a specific glibc version...

                ...and apparently did not make it. I was able to reproduce
this even with the IBM VM, so to speak. I tried JDK6, JDK7, JDK8 on Ubuntu
10, 11, 12, 13 + some random Debian. I did not have a JDK5, so I cannot say,
but on JDK4 everything works (that's the reason why I call it a regression).
(ah, if you look at the bug, it lists also JDK5, so I think we are pretty
much covered here).
                If you still have doubts tough, please have also a look on
stackoverflow to see how it was reproduced consistently on probably every
64bitJVM over 64bitLinux in the world.




                  The effects of this is not that "all the threads parked
will hang, with unpredictable/corrupted/useless"! The effects are very
simple an quite predictable... [deletia]s.

                We have very different views, and I find quite difficult to
accept yours. You are confusing my sample program which contains a single
thread in a for loop with any other complex multi-threading concurrent
system written in Java. For example, if you ever worked in a bank you surely
know what I mean. You are comparing some random sleep() put into a program
by some newbie, with the complex ecosystem of a concurrent platform written
to manage trading information on very fast market. In that condition, I am
sorry, statements such "...delayed timeout does not affect operation in a
correctly functioning system..." and "...small time changes [...] are not a
problem" are really not applicable. Let your system place an order three
seconds late and your are out of the door so quickly you cannot even realize
it.


                But let's not limit ourselves to banks: how do you think
your previous statements stands in these scenarios?
                - air control systems (what about a few seconds delay in
control when fying planes?)
                - city traffic control systems (what if just for a couple of
seconds all traffic lights become green?)



                Not good enough.




                  ...small time changes as typically done via NTP

                NTP is only one of the possible sources of this problem. The
root of it is that the JVM is counting nanoseconds delays using absolute
values based on a wallclock: I do not think it's that smart.




                  So there is an issue that needs to be addressed but the
situation is nowhere near as dire as you make out


                Let's try to put this in perspective, shall we? In case the
clock run backwards LockSupport.park() will be waiting for the nanoseconds
requested plus the amount of seconds/minute/hours/days requested to
compensate. Now, this primitive is used by almost *every* concurrency
construct available on the platform, such as AbstractQueuedSynchronizer (and
subclasses), ReentrantLock (and subclasses), CyclicBarrier, BlockingQueue
(and subclasses), Executors, FutureTask, .... (too long to list them all,
but I think we have the picture) and also low levels synchronization
primitives of the language itself, so Object::wait(:long) and the related
sychronized blocks.


                I think it's pretty dire.




                Cheers,


                    Bruno









                On Wed, Sep 4, 2013 at 12:14 AM, David Holmes
<davidcholmes at aapt.net.au> wrote:

                  Hi Bruno,

                  I have raised the priority on 6900441 (which to my
knowledge - and I created it! - has never been a private bug).

                  A few notes on the "very frightening" aspect of this:

                  1. It doesn't affect "every JVM64 running on Linux64". A
fix has been introduced into a specific glibc version for the futex-wait
code such that it now responds to changes in the system time for absolute
waits, where for all the years previous it did not. The fix seems to have
been applied in late 2011 or early 2012 but I don't know the exact glibc
version. There is also a 32-bit version of the fix that was proposed on Nov
27, 2012, so it will eventually make its way into 32-bit linux too.

                  2. The effects of this is not that "all the threads parked
will hang, with unpredictable/corrupted/useless"! The effects are very
simple an quite predictable. If the system time goes forward then
timed-waits (Object.wait, LockSupport.park) (which should be relative times)
will return early as the absolute-time that the relative time was converted
to will be seen to have been reached (Thread.sleep contains a guard against
early returns). This is not actually a problem as you can not distinguish
this case from a "spurious wakeup" which code is supposed to account for. If
the time is changed backwards then these timed-waits & sleeps will not
timeout when expected as the the for that is now further in the future, by
the amount of the backward time change. Hence small time changes as
typically done via NTP are NOT a problem. Timed-waits use timeouts as a
heuristics for recovering when the expected real event notification does not
occur - so a delayed timeout does not affect operation in a correctly
functioning system. Early timeouts are indistinguishable from spurious
wakeups, which code has to account for, so again not a problem for regular
code. The only time a significant "hang" will occur is with Thread.sleep and
a large backward time shift - but there is little real code that uses
Thread.sleep in any critical way.

                  So there is an issue that needs to be addressed but the
situation is nowhere near as dire as you make out.

                  David Holmes
                    -----Original Message-----
                    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of bruno
bossola
                    Sent: Wednesday, 4 September 2013 1:56 AM
                    To: concurrency-interest at cs.oswego.edu
                    Subject: [concurrency-interest] Outstanding concurrency
JVM issue - feedback?


                    Hi all,

                    I am writing here following a suggestion by Ben Evans. I
wanted to check with you about an issue that my teams found on the JVM and
that's very frightening. I already started the discussion with the engineers
of the hotspot VM team but it looks like we need more awareness to solve
this one and I'd really appreciate some help and some push :)

                    It looks to me that this issue is affecting every JVM64
running on Linux64, so imho it's quite important to be looked at.

                    Executive summary
                    The implementation of the concurrency primitive
LockSupport.parkNanos(), the function that controls most concurrency
primitive on the JVM, is flawed, and any NTP sync, or system time change,
can potentially break it with unexpected results across the board.

                    What we need to do?
                    This is an old issue, and the bug was declared private.
I somehow managed to have the bug reopened to the public, but it's still a
P4, that means that probably won't be fixed. I think we need to push for a
resolution ASAP, be sure that's in for JDK9, make all the possible effort to
make this fix for JDK8 or, at least, to include it in a later patch release.
In an ideal world it would be nice to have a patch for JDK7. As far as I
understand the hotspot engineering team works based on priorities: being
this qualified as P4 means it won't be probably worked on (if you follow the
breadcrumbs of bugs and fixes you can go back to 2002!) They acknowledge the
problem, it has been flagged to management, but 1) it's low priority 2) it's
too risky to fix for JDK8


                    Why all this urgency?
                    If a system time change happens then all the threads
parked will hang, with unpredictable/corrupted/useless results to the end
user. Same applies to Future, Queue, Executor, and (I guess) any other
construct that it's somehow related to concurrency. This is a big issue for
us and for any near time application: please think about trading and
betting, where the JVM is largely used, and  do not restrain yourself to the
Java language: add Scala and any other JVM-based language to the picture
(JRuby, Jython...)

                    Tech details
                    To be more clear about the issue, the extent of it and
the concurrency library, let me introduce this very simple program:

                    import java.util.concurrent.locks.LockSupport;

                    public class Main {

                        public static void main(String[] args) {

                            for (int i=100; i>0; i--) {
                                System.out.println(i);
                                LockSupport.parkNanos(1000L*1000L*1000L);
                            }

                            System.out.println("Done!");
                        }
                    }

                    Run it with a 64bit 1.6+ JVM on 64bit Linux, turn the
clock down one hour and wait until the counter stops... magic!  I tested
this on JDK6, JDK7 and latest JDK8 beta running on various Ubuntu distros.
It's not just a matter of (old?) sleep() and wait() primitives, this issue
it affects the whole concurrency library.


                    To prove that this is fixable, I reimplemented the
program above above substituting  LockSupport.parkNanos()  with  a JNI call
to clock_nanosleep(CLOCK_MONOTONIC...): works like a charm :(



                    This is due to the fact  that the CPP code is calling
the pthread_cond_timedwait() using its default clock (CLOCK_REALTIME) which,
unfortunately is affected by settime()/settimeofday() calls (on Linux): for
that reason it cannot be used to measure nanoseconds delays, which is what
the specification requires. CLOCK_REALTIME is not guaranteed to
monotonically count as this is the actual "system time": each time my system
syncs time using a NTP server on the net, the time might jump forward or
backward. The correct call (again on Linux)  would require to use
CLOCK_MONOTONIC as clock id, which are defined by POSIX specs since 2002.
(or better CLOCK_MONOTONIC_RAW)

                    The POSIX spec is infact clear, as it states "...setting
the value of the CLOCK_REALTIME clock via clock_settime() shall have no
effect on threads that are blocked waiting for a relative time service based
upon this clock...": it definitely states "relative".  Having a look at the
hotspot code, it appears that the park() is using compute_abstime() (which
uses timeofday) and then waits on an absolute period: for that reason it's
influenced by the system clock change. Very wrong.


                    I will be happy to know what you think, and if you can
help me to escalate this issue I think that the all Java community will
benefit from it.

                    Cheers,


                        Bruno


                No virus found in this message.
                Checked by AVG - www.avg.com
                Version: 2013.0.3392 / Virus Database: 3222/6633 - Release
Date: 09/03/13






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130917/fb02cf0c/attachment-0001.html>

From cdracm at mail.ru  Thu Sep 19 09:45:54 2013
From: cdracm at mail.ru (=?UTF-8?B?QWxleGV5IEt1ZHJhdnRzZXY=?=)
Date: Thu, 19 Sep 2013 17:45:54 +0400
Subject: [concurrency-interest] =?utf-8?q?ForkJoinTask_leaks_exceptions=3F?=
Message-ID: <1379598354.786258950@f201.i.mail.ru>


I've?witnessed high memory consumption in my application and it seems that
it was ForkJoinPool which leaked memory.
Please run the following test which submits 10k tasks into the ForkJoinPool and terminates all of them abnormally by throwing an exception.
After each round of submitting/joining the memory consumption grows by (roughly)?4Mb.
Profiler shows that ForkJoinTask.ExceptionNode objects got created and (almost all) retained in ForkJoinTask.exceptionTable static field.
By the end of the fifth round of submitting/joining I have 48378 ForkJoinTask.ExceptionNode objects hanging there occupying 22Mb.
?
java version "1.8.0-ea"
Java(TM) SE Runtime Environment (build 1.8.0-ea-b106)
Java HotSpot(TM) Client VM (build 25.0-b48, mixed mode, sharing)
=====================================================
import java.util.concurrent.*;
?
import java.util.ArrayList;
import java.util.List;
?
public class Jsr166Exceptions {
? public static void main(String[] args) throws InterruptedException {
??? for (int k=0; k<5;k++) {
????? System.gc();
????? System.out.println("Running pass #" + k);
????? List<ForkJoinTask> tasks = new ArrayList<ForkJoinTask>();
????? for (int i = 0; i < 10000; i++) {
??????? ForkJoinTask task = new RecursiveTask() {
????????? @Override
????????? protected Object compute() {
??????????? throw new RuntimeException();
????????? }
??????? };
??????? tasks.add(task);
??????? ForkJoinPool.commonPool().execute(task);
????? }
????? for (ForkJoinTask task : tasks) {
??????? try {
????????? task.join();
??????? }
??????? catch (Exception e) {
??????? }
????? }
????? tasks.clear();
????? System.gc();
????? boolean success = ForkJoinPool.commonPool().awaitQuiescence(20, TimeUnit.SECONDS);
????? System.out.println("success = " + success);
????? Thread.sleep(30000);
??? }
? }
}
Alexey Kudravtsev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130919/e702ca5a/attachment.html>

From oleksandr.otenko at oracle.com  Thu Sep 19 15:24:36 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 19 Sep 2013 20:24:36 +0100
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
 properly
In-Reply-To: <CAHjP37FVSWU4nCPs1C1yFoDWfpsg_-5+RT_=pqmC0W+XkpJ49g@mail.gmail.com>
References: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
	<52377FF6.5070308@oracle.com>
	<CAHjP37FVSWU4nCPs1C1yFoDWfpsg_-5+RT_=pqmC0W+XkpJ49g@mail.gmail.com>
Message-ID: <523B4F74.7050900@oracle.com>

It matters when the store appears in the cache, too. Signaller exit is 
one such condition.

Alex

On 17/09/2013 01:19, Vitaly Davidovich wrote:
>
> I'm not even sure the fact that signaller exits matters so long as it 
> runs at least one iteration that performs the write; eventually, the 
> stores are written out to cache, and reader picks them up.  The load 
> fence just prevents compiler from hoisting the read out of the loop 
> (and thus causing the infloop).
>
> Sent from my phone
>
> On Sep 16, 2013 6:09 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com 
> <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     x86 memory model forces stores to be completed in program order. 
>     The storeFence() simply keeps JIT from rearranging the store with
>     subsequent stores.  Because the signaller thread exits, this
>     forces all stores to happen eventually.  So, the storeFence()
>     isn't really needed in this example.  In order to show
>     storeFence() as significant, you would need to have 2 stores where
>     the order in which they are execute matters.
>
>     -Nathan
>
>     On 9/16/2013 2:10 PM, Tim Halloran wrote:
>>     I've been trying out JEP 171 with Java 8, but have not found many
>>     examples of its use.
>>
>>     So, I cooked up one (the complete code is at the bottom) that has two
>>     nested classes access a "per-use volatile" static boolean field which
>>     is declared as
>>
>>        static boolean running = true;
>>
>>     One thread is a trivial "work until signaled" that does
>>
>>        do {
>>          // stuff
>>          unsafe.loadFence();
>>        } while (running);
>>
>>     the second thread signals to stop, via the boolean field, after
>>     (roughly) two seconds
>>
>>        sleepTwoSeconds: try { Thread.sleep(2000); } catch
>>     (InterruptedException ignore) {}
>>        running = false;
>>        unsafe.storeFence();
>>
>>     First, this example is wholly contrived and there is no reason to
>>     implement this convoluted way except try try out JEP 171 on Java 8.
>>
>>     Second, if you comment out the unsafe.*Fence() calls the program hangs
>>     forever -- as one would expect (at the worker.join() call in the full
>>     code below because the first thread never sees the change in the
>>     boolean).
>>
>>     Third, I'm not sure this code is correct -- in particular ONLY the
>>     unsafe.loadFence() call seems to have any impact on program behavior
>>     (put another way, you can comment out the unsafe.storeFence() in the
>>     second thread and the boolean field's state change is still visible).
>>     BUT I'm wondering if this is because I'm running Java 8 on a MacBook
>>     Pro (Intel Core i5) and some of these calls are no-ops?  (per the JSR
>>     133 cookbook)
>>
>>     This leads to my query if there are some examples of this JEP in use I
>>     missed when searching. In particular where fullFence() and
>>     storeFence() are used.
>>
>>     Thanks!
>>
>>     Best regards,
>>     Tim Halloran
>>
>>
>>     The complete example code listing:
>>
>>
>>     import java.lang.reflect.*;
>>     import java.util.concurrent.*;
>>     import sun.misc.Unsafe;
>>
>>     class Fencer {
>>
>>        static final CountDownLatch latch = new CountDownLatch(1);
>>        static final Unsafe unsafe;
>>        static {
>>          try {
>>            Field field = Unsafe.class.getDeclaredField("theUnsafe");
>>            field.setAccessible(true);
>>            unsafe = (Unsafe) field.get(null);
>>          } catch (Exception e) {
>>            throw new AssertionError(e);
>>          }
>>        }
>>
>>        static boolean running = true;
>>
>>        static class WorkUntilSignal extends Thread {
>>          public void run() {
>>             startTogether: try { latch.await(); } catch
>>     (InterruptedException ignore) {}
>>
>>             do {
>>               // stuff
>>               unsafe.loadFence();
>>             } while (running);
>>          }
>>        }
>>
>>        static class Signaller extends Thread {
>>          public void run() {
>>             startTogether: try { latch.await(); } catch
>>     (InterruptedException ignore) {}
>>             sleepTwoSeconds: try { Thread.sleep(2000); } catch
>>     (InterruptedException ignore) {}
>>             running = false;
>>             unsafe.storeFence();
>>          }
>>        }
>>
>>        public static void main(String[] args) throws InterruptedException {
>>          final WorkUntilSignal worker = new WorkUntilSignal();
>>          final Signaller signaller = new Signaller();
>>
>>          worker.start();
>>          signaller.start();
>>          latch.countDown(); // start together
>>
>>          signaller.join();
>>          System.out.println("Signaller finished...");
>>          worker.join();
>>          System.out.println("Worker finished...");
>>        }
>>     }
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130919/8912c910/attachment.html>

From dl at cs.oswego.edu  Thu Sep 19 16:43:22 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 19 Sep 2013 16:43:22 -0400
Subject: [concurrency-interest] ForkJoinTask leaks exceptions?
In-Reply-To: <1379598354.786258950@f201.i.mail.ru>
References: <1379598354.786258950@f201.i.mail.ru>
Message-ID: <523B61EA.7010903@cs.oswego.edu>

On 09/19/2013 09:45 AM, Alexey Kudravtsev wrote:
> I've witnessed high memory consumption in my application and it seems that
> it was ForkJoinPool which leaked memory.
> Please run the following test which submits 10k tasks into the ForkJoinPool and
> terminates all of them abnormally by throwing an exception.
> After each round of submitting/joining the memory consumption grows by
> (roughly) 4Mb.
> Profiler shows that ForkJoinTask.ExceptionNode objects got created and (almost
> all) retained in ForkJoinTask.exceptionTable static field.

The exception table is basically a specialized WeakHashMap,
and shares some of its advantages and disadvantages: Stale
(unreferenced) entries are checked (polling reference queue)
and expunged on each access. This means that they cannot
be killed until the GC says it is OK. Which in your test program
will not occur soon because all your tasks are live-referenced
while held in the array. If this is a snapshot of a more
serious use, you might try to find some way not to hold
references of dead aborted tasks for so long. Beyond that,
I'm not sure there is anything we could do to help.
I added some internal instrumentation to double-check that
all of the exception records are eventually reclaimed in your
test program.

-Doug



> By the end of the fifth round of submitting/joining I have 48378
> ForkJoinTask.ExceptionNode objects hanging there occupying 22Mb.
> java version "1.8.0-ea"
> Java(TM) SE Runtime Environment (build 1.8.0-ea-b106)
> Java HotSpot(TM) Client VM (build 25.0-b48, mixed mode, sharing)
> =====================================================
> import java.util.concurrent.*;
> import java.util.ArrayList;
> import java.util.List;
> public class Jsr166Exceptions {
>    public static void main(String[] args) throws InterruptedException {
>      for (int k=0; k<5;k++) {
>        System.gc();
>        System.out.println("Running pass #" + k);
>        List<ForkJoinTask> tasks = new ArrayList<ForkJoinTask>();
>        for (int i = 0; i < 10000; i++) {
>          ForkJoinTask task = new RecursiveTask() {
>            @Override
>            protected Object compute() {
>              throw new RuntimeException();
>            }
>          };
>          tasks.add(task);
>          ForkJoinPool.commonPool().execute(task);
>        }
>        for (ForkJoinTask task : tasks) {
>          try {
>            task.join();
>          }
>          catch (Exception e) {
>          }
>        }
>        tasks.clear();
>        System.gc();
>        boolean success = ForkJoinPool.commonPool().awaitQuiescence(20,
> TimeUnit.SECONDS);
>        System.out.println("success = " + success);
>        Thread.sleep(30000);
>      }
>    }
> }
> Alexey Kudravtsev
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From cdracm at mail.ru  Thu Sep 19 19:45:38 2013
From: cdracm at mail.ru (=?UTF-8?B?QWxleGV5IEt1ZHJhdnRzZXY=?=)
Date: Fri, 20 Sep 2013 03:45:38 +0400
Subject: [concurrency-interest]
 =?utf-8?q?ForkJoinTask_leaks_exceptions=3F?=
In-Reply-To: <523B61EA.7010903@cs.oswego.edu>
References: <1379598354.786258950@f201.i.mail.ru>
	<523B61EA.7010903@cs.oswego.edu>
Message-ID: <1379634338.163899508@f26.i.mail.ru>


I think the problem is in?jsr166e.ForkJoinTask#expungeStaleExceptions method.
The expression "ForkJoinTask<?> key = ((ExceptionNode)x).get();" always returns null because the reference is already dead.
Because of that, the weak hash map bucket index calculates to zero: "int i = System.identityHashCode(key) & (t.length - 1);"
and thus no exception gets removed.

I've put together a fix here:
https://gist.github.com/cdracm/6631269

(I was patching the FJTask version I downloaded from? http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/ )
Changes are minimal:??store weak hash map?exceptionTable?index inside ExceptionNode and use this index in expungeStaleExceptions method.
With this fix my test doesnt leak memory anymore.
Also I've tried to write a proper unit test for this but it turned out to be surprisingly difficult. I can send my attempts anyway if you want.

--regards, Alexey
>On 09/19/2013 09:45 AM, Alexey Kudravtsev wrote:
>> I've witnessed high memory consumption in my application and it seems that
>> it was ForkJoinPool which leaked memory.
>> Please run the following test which submits 10k tasks into the ForkJoinPool and
>> terminates all of them abnormally by throwing an exception.
>> After each round of submitting/joining the memory consumption grows by
>> (roughly) 4Mb.
>> Profiler shows that ForkJoinTask.ExceptionNode objects got created and (almost
>> all) retained in ForkJoinTask.exceptionTable static field.
>
>The exception table is basically a specialized WeakHashMap,
>and shares some of its advantages and disadvantages: Stale
>(unreferenced) entries are checked (polling reference queue)
>and expunged on each access. This means that they cannot
>be killed until the GC says it is OK. Which in your test program
>will not occur soon because all your tasks are live-referenced
>while held in the array. If this is a snapshot of a more
>serious use, you might try to find some way not to hold
>references of dead aborted tasks for so long. Beyond that,
>I'm not sure there is anything we could do to help.
>I added some internal instrumentation to double-check that
>all of the exception records are eventually reclaimed in your
>test program.
>
>-Doug
>
>
>
>> By the end of the fifth round of submitting/joining I have 48378
>> ForkJoinTask.ExceptionNode objects hanging there occupying 22Mb.
>> java version "1.8.0-ea"
>> Java(TM) SE Runtime Environment (build 1.8.0-ea-b106)
>> Java HotSpot(TM) Client VM (build 25.0-b48, mixed mode, sharing)
>> =====================================================
>> import java.util.concurrent.*;
>> import java.util.ArrayList;
>> import java.util.List;
>> public class Jsr166Exceptions {
>>    public static void main(String[] args) throws InterruptedException {
>>      for (int k=0; k<5;k++) {
>>        System.gc();
>>        System.out.println("Running pass #" + k);
>>        List<ForkJoinTask> tasks = new ArrayList<ForkJoinTask>();
>>        for (int i = 0; i < 10000; i++) {
>>          ForkJoinTask task = new RecursiveTask() {
>>            @Override
>>            protected Object compute() {
>>              throw new RuntimeException();
>>            }
>>          };
>>          tasks.add(task);
>>          ForkJoinPool.commonPool().execute(task);
>>        }
>>        for (ForkJoinTask task : tasks) {
>>          try {
>>            task.join();
>>          }
>>          catch (Exception e) {
>>          }
>>        }
>>        tasks.clear();
>>        System.gc();
>>        boolean success = ForkJoinPool.commonPool().awaitQuiescence(20,
>> TimeUnit.SECONDS);
>>        System.out.println("success = " + success);
>>        Thread.sleep(30000);
>>      }
>>    }
>> }
>> Alexey Kudravtsev
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>>  Concurrency-interest at cs.oswego.edu
>>  http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
a a
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130920/15b900f1/attachment-0001.html>

From dl at cs.oswego.edu  Fri Sep 20 06:59:18 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 20 Sep 2013 06:59:18 -0400
Subject: [concurrency-interest] ForkJoinTask leaks exceptions?
In-Reply-To: <1379634338.163899508@f26.i.mail.ru>
References: <1379598354.786258950@f201.i.mail.ru>
	<523B61EA.7010903@cs.oswego.edu>
	<1379634338.163899508@f26.i.mail.ru>
Message-ID: <523C2A86.3050506@cs.oswego.edu>

On 09/19/2013 07:45 PM, Alexey Kudravtsev wrote:
>
> The expression "ForkJoinTask<?> key = ((ExceptionNode)x).get();" always returns
> null because the reference is already dead.

Thanks for the extra prodding! Yes, even though processed, exception
records were not always being unlinked along that path. And storing the
hashCode on construction is the best remedy. I updated along the lines
of your suggestion, and will also post OpenJDK bug/fix.


> Also I've tried to write a proper unit test for this but it turned out to be
> surprisingly difficult.

The easiest way (and what we do for other leak tests) is to
create a test that will throw OOME (or related exceptions) when
run at known fixed -Xmx settings. As in:

import java.util.concurrent.*;

public class FJExceptionTableLeak {

     // Run with TASKS_PER_STEP * 40 < Xmx < STEPS * TASKS_PER_STEP * 40
     // These work for Xmx32m:
     static final int STEPS = 2000;
     static final int TASKS_PER_STEP = 1000;

     static class FailingTask extends RecursiveAction {
         public void compute() {
             throw new RuntimeException();
         }
     }

     public static void main(String[] args) throws InterruptedException {
         ForkJoinPool pool = new ForkJoinPool(4);
         FailingTask[] tasks = new FailingTask[TASKS_PER_STEP];
         for (int k = 0; k < STEPS; ++k) {
             for (int i = 0; i < tasks.length; ++i)
                 tasks[i] = new FailingTask();
             for (int i = 0; i < tasks.length; ++i)
                 pool.execute(tasks[i]);
             for (int i = 0; i < tasks.length; ++i) {
                 try {
                     tasks[i].join();
                 } catch (Exception e) {
                 }
             }
         }
     }
}



From hallorant at gmail.com  Fri Sep 20 11:09:27 2013
From: hallorant at gmail.com (Tim Halloran)
Date: Fri, 20 Sep 2013 11:09:27 -0400
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
	properly
In-Reply-To: <52377FF6.5070308@oracle.com>
References: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
	<52377FF6.5070308@oracle.com>
Message-ID: <CAMyLHFxzuiSmVSWzKrcSgECbfSNJcoAudEVJnD32wjjm0iyvLw@mail.gmail.com>

On Mon, Sep 16, 2013 at 6:02 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  x86 memory model forces stores to be completed in program order.  The
> storeFence() simply keeps JIT from rearranging the store with subsequent
> stores.  Because the signaller thread exits, this forces all stores to
> happen eventually.  So, the storeFence() isn't really needed in this
> example.  In order to show storeFence() as significant, you would need to
> have 2 stores where the order in which they are execute matters.
>
> -Nathan
>
> Thanks, this makes sense. So the "no reordering" goes all the way through
the javac -> jit -> cpu chain for this library method. It is not just
direction to the cpu. I understood from the JEP 171 writeup that the cpu
and the jit did not reorder, I was wondering a bit about javac.

Vitaly Davidovich wrote:

> I'm not even sure the fact that signaller exits matters so long as it runs
> at least one iteration that performs the write; eventually, the stores are
> written out to cache, and reader picks them up.  The load fence just
> prevents compiler from hoisting the read out of the loop (and thus causing
> the infloop).


Yes, but wouldn't the use of storeFence() force out the write "faster" or
does it simply ensure ordering -- not a flush.  This might be what Alex was
saying below.

It matters when the store appears in the cache, too. Signaller exit is one
> such condition.
> Alex


I'm still fuzzy when a *fullFence()* call would make sense. Is there any
examples where this would be required?

Also, perhaps asked above, but the relationship between ordering and
visibility is not crystal clear to me -- do all of these convey visibility.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130920/05018c4e/attachment.html>

From vitalyd at gmail.com  Fri Sep 20 13:40:04 2013
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 20 Sep 2013 13:40:04 -0400
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
	properly
In-Reply-To: <CAMyLHFxzuiSmVSWzKrcSgECbfSNJcoAudEVJnD32wjjm0iyvLw@mail.gmail.com>
References: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
	<52377FF6.5070308@oracle.com>
	<CAMyLHFxzuiSmVSWzKrcSgECbfSNJcoAudEVJnD32wjjm0iyvLw@mail.gmail.com>
Message-ID: <CAHjP37FB9he5W+1Q6MggfKQXNjqJnKW4LJXd7NAyLM9sY9CN1w@mail.gmail.com>

So there are two things at play here: (1) "immediacy" of the store being
visible to other CPUs and (2) order in which stores (loads too, but let's
focus on stores) appear to other CPUs.

Immediacy means: can the CPU proceed to next instruction (this is
simplified view because out of order/speculation makes this more complex)
before the store is globally visible.

Ordering means: when the stores *are* made visible (not necessarily before
next instruction executes) they need to appear in the specified order.

The machinery that makes "delayed" stores manifest itself is the store
buffer in the CPU.  Writes can go there first, and not be drained to the
coherent caches; if a pending store is sitting in the store buffer, no
other CPU can see it, but the CPU that issued the write *can* see it.  This
comes into play with store-forwarding: a CPU can read out its own store
from the buffer even though it's not globally visible.  Why can this be a
problem? Suppose you're writing a basic mutex.  Some CPU releases it by
doing a simple store with no full fence.  The store sits in the buffer; all
other CPUs still think mutex is locked.  The same CPU tries to acquire the
lock again before the store makes it out of the buffer.  Since it observes
it as free, it acquires the lock again.  This is an unfair advantage.

The second problem is that stores followed by loads can appear to reorder.
The store sits in the store buffer but the subsequent load can observe
coherent memory.  This can make it seem like the load came before the store
because the store operation was delayed, and other CPUs didn't see it yet.

This is just the CPU side of things; compiler can schedule operations
differently from program order as well.  So fences are usually at least a
compiler barrier, and depending on CPU memory model, also may include CPU
barrier instructions.

Sent from my phone
On Sep 20, 2013 11:16 AM, "Tim Halloran" <hallorant at gmail.com> wrote:

> On Mon, Sep 16, 2013 at 6:02 PM, Nathan Reynolds <
> nathan.reynolds at oracle.com> wrote:
>
>>  x86 memory model forces stores to be completed in program order.  The
>> storeFence() simply keeps JIT from rearranging the store with subsequent
>> stores.  Because the signaller thread exits, this forces all stores to
>> happen eventually.  So, the storeFence() isn't really needed in this
>> example.  In order to show storeFence() as significant, you would need to
>> have 2 stores where the order in which they are execute matters.
>>
>> -Nathan
>>
>> Thanks, this makes sense. So the "no reordering" goes all the way through
> the javac -> jit -> cpu chain for this library method. It is not just
> direction to the cpu. I understood from the JEP 171 writeup that the cpu
> and the jit did not reorder, I was wondering a bit about javac.
>
> Vitaly Davidovich wrote:
>
>> I'm not even sure the fact that signaller exits matters so long as it
>> runs at least one iteration that performs the write; eventually, the stores
>> are written out to cache, and reader picks them up.  The load fence just
>> prevents compiler from hoisting the read out of the loop (and thus causing
>> the infloop).
>
>
> Yes, but wouldn't the use of storeFence() force out the write "faster" or
> does it simply ensure ordering -- not a flush.  This might be what Alex was
> saying below.
>
> It matters when the store appears in the cache, too. Signaller exit is one
>> such condition.
>> Alex
>
>
> I'm still fuzzy when a *fullFence()* call would make sense. Is there any
> examples where this would be required?
>
> Also, perhaps asked above, but the relationship between ordering and
> visibility is not crystal clear to me -- do all of these convey visibility.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130920/0225e012/attachment.html>

From oleksandr.otenko at oracle.com  Fri Sep 20 14:30:11 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 20 Sep 2013 19:30:11 +0100
Subject: [concurrency-interest] JEP 171 using Unsafe.*Fence() methods
 properly
In-Reply-To: <CAMyLHFxzuiSmVSWzKrcSgECbfSNJcoAudEVJnD32wjjm0iyvLw@mail.gmail.com>
References: <CAMyLHFyUhwk9qmL9pgXHdPTVDo2QJAu0MZo6iRduqUOjWF9tHQ@mail.gmail.com>
	<52377FF6.5070308@oracle.com>
	<CAMyLHFxzuiSmVSWzKrcSgECbfSNJcoAudEVJnD32wjjm0iyvLw@mail.gmail.com>
Message-ID: <523C9433.2070303@oracle.com>

The fences only order thread-local events. Therefore, there is no such 
thing as "immediately" as observed by others. You can't, and you don't 
need to rely on their perception of "immediately" to devise a concurrent 
algorithm.

The fences permit to build causal chains. Irrespective of the total 
order of events observed by other threads, the order of events in this 
thread separated by fences, will be observed, or can be assumed to occur 
in that order, by the other threads. This permits to reason about 
correctness of the algorithm.

Suppose, one thread does this:

x=blah;
if (z.get()==null) z.compareAndSet(null, y == null? x: y);

The other does this:

y=blahblah;
if (x != null) while ((tmp=z.get()) != y && !z.compareAndSet(tmp, y));

Here they cooperatively set the value of z: set to x, if y has not been 
computed yet; set to y only if x has been computed. So to speak, a tiny 
two-shot queue, with z showing the last stored value.

1. If there is no fullFence() right after x=... and y=..., then loads 
for z.get() and x!=null can go ahead and the algorithm won't work.

2. If there is no loadLoad fence right after z.get()==null and x!=null, 
the loads for y == null and z.get() can go ahead and the algorithm won't 
work.

In the presence of fences warranted by the specification of Java 
volatile we can prove the correctness of the algorithm even without a 
loop in the first thread (which would usually be written). The absence 
of the loop permits the threads to resolve contention on z graciously.

Let's look at the statement "x != null". In the presence of fullFence 
and serialization of stores for volatile y *and* x, we can reason that 
if x == null, then the first thread didn't execute x=blah, and didn't 
execute y==null, therefore, this /will/ occur /in the future/, and we 
can go away, nothing needs doing in the second thread. On the other 
hand, if the fence was weaker than StoreLoad, or there was no 
serialization of stores right after x=blah, then we cannot reason about 
y==null test being in the future from the point where x!=null was false 
in the second thread. The case when x!=null is true, is not interesting 
- we cannot reason about the whereabouts of the first thread, so have to 
loop setting the value of z until successful.


Let's now look at the statement "y == null". In the presence of 
fullFence and serialization of stores for volatile y *and* x, we can 
reason that if y != null, we only need to attempt setting z to y once - 
either it was already set to y by the second thread after observing x != 
null (we can be sure it saw x != null, if it reached there), or the 
second thread left before x=blah finished and won't compete. A more 
revealing case is y == null, we only need to attempt setting z to x 
once, too - since the first thread observed y == null, then y=blahblah 
/will/ occur /in the future/ from that point, and the second thread 
/will/ observe x != null, because x=blah occurred before y==null test, 
hence the second thread will enter the loop to set z to y. Whether 
setting z to x succeeds or not, the second thread will eventually set z 
to y, possibly after a single retry. On the other hand, if the said 
fences were weaker than StoreLoad, or there was no serialization of 
stores right after y=blahblah, then we cannot reason about the y==null 
test indicating the whereabouts of the second thread.


See? There is no "immediate". We only need relative timing of events: 
observing y == null separates x=blah from y=blahblah in one order; 
similarly observing x == null separates y=blahblah from x=blah in the 
other order.

Alex


On 20/09/2013 16:09, Tim Halloran wrote:
> On Mon, Sep 16, 2013 at 6:02 PM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     x86 memory model forces stores to be completed in program order. 
>     The storeFence() simply keeps JIT from rearranging the store with
>     subsequent stores.  Because the signaller thread exits, this
>     forces all stores to happen eventually.  So, the storeFence()
>     isn't really needed in this example.  In order to show
>     storeFence() as significant, you would need to have 2 stores where
>     the order in which they are execute matters.
>
>     -Nathan
>
> Thanks, this makes sense. So the "no reordering" goes all the way 
> through the javac -> jit -> cpu chain for this library method. It is 
> not just direction to the cpu. I understood from the JEP 171 writeup 
> that the cpu and the jit did not reorder, I was wondering a bit about 
> javac.
>
> Vitaly Davidovich wrote:
>
>     I'm not even sure the fact that signaller exits matters so long as
>     it runs at least one iteration that performs the write;
>     eventually, the stores are written out to cache, and reader picks
>     them up.  The load fence just prevents compiler from hoisting the
>     read out of the loop (and thus causing the infloop).
>
>
> Yes, but wouldn't the use of storeFence() force out the write "faster" 
> or does it simply ensure ordering -- not a flush.  This might be what 
> Alex was saying below.
>
>     It matters when the store appears in the cache, too. Signaller
>     exit is one such condition.
>     Alex
>
>
> I'm still fuzzy when a *fullFence()* call would make sense. Is there 
> any examples where this would be required?
>
> Also, perhaps asked above, but the relationship between ordering and 
> visibility is not crystal clear to me -- do all of these convey 
> visibility.
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130920/ae50a314/attachment.html>

From cdracm at mail.ru  Mon Sep 23 16:55:05 2013
From: cdracm at mail.ru (=?UTF-8?B?QWxleGV5IEt1ZHJhdnRzZXY=?=)
Date: Tue, 24 Sep 2013 00:55:05 +0400
Subject: [concurrency-interest]
 =?utf-8?q?ForkJoinTask_leaks_exceptions=3F?=
In-Reply-To: <523C2A86.3050506@cs.oswego.edu>
References: <1379598354.786258950@f201.i.mail.ru>
	<1379634338.163899508@f26.i.mail.ru>
	<523C2A86.3050506@cs.oswego.edu>
Message-ID: <1379969705.846295317@f245.i.mail.ru>

 Regarding test:
I think that running test with specific -Xmx and waiting for it to throw OOM is a little harsh.
The following test will run faster and without any requirements (except to be located in jsr166e package to have access to ForkJoinTask fields)
https://gist.github.com/cdracm/6676496 ? Is there any chance to include something like this into the JDK test suite?
-- regards,
?Alexey Kudravtsev

???????, 20 ???????? 2013, 6:59 -04:00 ?? Doug Lea <dl at cs.oswego.edu>:
>On 09/19/2013 07:45 PM, Alexey Kudravtsev wrote:
>>
>> The expression "ForkJoinTask<?> key = ((ExceptionNode)x).get();" always returns
>> null because the reference is already dead.
>
>Thanks for the extra prodding! Yes, even though processed, exception
>records were not always being unlinked along that path. And storing the
>hashCode on construction is the best remedy. I updated along the lines
>of your suggestion, and will also post OpenJDK bug/fix.
>
>
>> Also I've tried to write a proper unit test for this but it turned out to be
>> surprisingly difficult.
>
>The easiest way (and what we do for other leak tests) is to
>create a test that will throw OOME (or related exceptions) when
>run at known fixed -Xmx settings. As in:
>
>import java.util.concurrent.*;
>
>public class FJExceptionTableLeak {
>
>?????// Run with TASKS_PER_STEP * 40 < Xmx < STEPS * TASKS_PER_STEP * 40
>?????// These work for Xmx32m:
>?????static final int STEPS = 2000;
>?????static final int TASKS_PER_STEP = 1000;
>
>?????static class FailingTask extends RecursiveAction {
>?????????public void compute() {
>?????????????throw new RuntimeException();
>?????????}
>?????}
>
>?????public static void main(String[] args) throws InterruptedException {
>?????????ForkJoinPool pool = new ForkJoinPool(4);
>?????????FailingTask[] tasks = new FailingTask[TASKS_PER_STEP];
>?????????for (int k = 0; k < STEPS; ++k) {
>?????????????for (int i = 0; i < tasks.length; ++i)
>?????????????????tasks[i] = new FailingTask();
>?????????????for (int i = 0; i < tasks.length; ++i)
>?????????????????pool.execute(tasks[i]);
>?????????????for (int i = 0; i < tasks.length; ++i) {
>?????????????????try {
>?????????????????????tasks[i].join();
>?????????????????} catch (Exception e) {
>?????????????????}
>?????????????}
>?????????}
>?????}
>}
>
>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
a a
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130924/c32d8479/attachment.html>

From dragonsinth at gmail.com  Tue Sep 24 11:24:02 2013
From: dragonsinth at gmail.com (Scott Blum)
Date: Tue, 24 Sep 2013 11:24:02 -0400
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade read->write
Message-ID: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>

I was a little surprised to discover that a lock upgrade is not possible.
 I read through this tutorial which suggests that supporting read->write
upgrade should be possible:

http://tutorials.jenkov.com/java-concurrency/read-write-locks.html

Was this a deliberate design decision for ReentrantReadWriteLock, or is
there something inherently unsafe about what he's doing in that article?

Thanks,
Scott
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130924/27e1b9cd/attachment.html>

From heinz at javaspecialists.eu  Tue Sep 24 11:37:20 2013
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 24 Sep 2013 17:37:20 +0200
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
Message-ID: <5241B1B0.7010801@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130924/f721aec6/attachment.html>

From oleksandr.otenko at oracle.com  Tue Sep 24 12:53:32 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 24 Sep 2013 17:53:32 +0100
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
Message-ID: <5241C38C.2020507@oracle.com>

It's possible, but nonsensical - the upgrade will be equivalent to 
release read, acquire write.

Also, it makes sense in designs with more than three states (0, R, 1). 
Eg when upgrade doesn't get the Write, but something in the middle 
between Read and Write.

Alex


On 24/09/2013 16:24, Scott Blum wrote:
> I was a little surprised to discover that a lock upgrade is not 
> possible.  I read through this tutorial which suggests that supporting 
> read->write upgrade should be possible:
>
> http://tutorials.jenkov.com/java-concurrency/read-write-locks.html
>
> Was this a deliberate design decision for ReentrantReadWriteLock, or 
> is there something inherently unsafe about what he's doing in that 
> article?
>
> Thanks,
> Scott
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130924/8c55c2da/attachment.html>

From david.lloyd at redhat.com  Tue Sep 24 14:24:46 2013
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 24 Sep 2013 13:24:46 -0500
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <5241C38C.2020507@oracle.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
	<5241C38C.2020507@oracle.com>
Message-ID: <5241D8EE.4040807@redhat.com>

This topic does come up quite a lot.

Upgradeable read-write locks are not nonsensical at all; in fact they're 
quite common in the wild.  The ReadWriteLock API doesn't really lend 
itself well to it though - the only way that API could support upgrades 
in any kind of sane way is if the owner of the read lock acquired the 
write lock and then released the read lock.  Unfortunately this doesn't 
align with any kind of simple way to support upgrading, which entails a 
reader performing an upgrade request, which would either block waiting 
for the write lock to become available (if the requester is the first), 
or would throw an exception of some sort.  After a successful upgrade, 
the reader would now be a writer.  But this doesn't map well to the API 
when there are distinct Lock objects for readers and writer.

My opinion is that in retrospect, making ReadWriteLock reuse the Lock 
interface in the way that it does turned out to be the wrong choice. 
There is probably very little generic code which could take advantage of 
this reuse, it makes lock downgrading clunky and easy to mess up, and it 
makes things like supporting upgrade fairly problematic.  A single 
instance with acquireRead(), acquireWrite(), and release() would have 
made more sense, and would have made upgrade (and downgrade) support 
pretty simple as you'd be able to request upgrade via acquireWrite() 
while holding read, and downgrade via acquireRead() while holding write, 
and a single release point makes cleanup much simpler (in fact using 
AutoCloseable would be a boon here).

Well, coding is 10% inspiration, 30% perspiration, and 60% regret. :)

On 09/24/2013 11:53 AM, Oleksandr Otenko wrote:
> It's possible, but nonsensical - the upgrade will be equivalent to
> release read, acquire write.
>
> Also, it makes sense in designs with more than three states (0, R, 1).
> Eg when upgrade doesn't get the Write, but something in the middle
> between Read and Write.
>
> Alex
>
>
> On 24/09/2013 16:24, Scott Blum wrote:
>> I was a little surprised to discover that a lock upgrade is not
>> possible.  I read through this tutorial which suggests that supporting
>> read->write upgrade should be possible:
>>
>> http://tutorials.jenkov.com/java-concurrency/read-write-locks.html
>>
>> Was this a deliberate design decision for ReentrantReadWriteLock, or
>> is there something inherently unsafe about what he's doing in that
>> article?
>>
>> Thanks,
>> Scott
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
- DML

From dragonsinth at gmail.com  Tue Sep 24 15:15:03 2013
From: dragonsinth at gmail.com (Scott Blum)
Date: Tue, 24 Sep 2013 15:15:03 -0400
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <5241D8EE.4040807@redhat.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
	<5241C38C.2020507@oracle.com> <5241D8EE.4040807@redhat.com>
Message-ID: <CALuNCphk7OSGVL2L22ZFzM6hA70uqQZ5syVGk0zFiQZGQFTZ1w@mail.gmail.com>

Thanks for the detailed analysis.  A coworker of mine did point out one
interesting note about lock upgrades:

BTW, I'm pretty sure the reason lock upgrades are not allowed is because it
is deadlock prone. Simple case: two threads both have the read lock and
then both request the write lock. Neither thread can acquire the write lock
until the other has released its read lock, which means deadlock.


How would one handle this scenario?  Is this what you had in mind when you
mentioned throwing an exception of some sort trying to upgrade?


On Tue, Sep 24, 2013 at 2:24 PM, David M. Lloyd <david.lloyd at redhat.com>wrote:

> This topic does come up quite a lot.
>
> Upgradeable read-write locks are not nonsensical at all; in fact they're
> quite common in the wild.  The ReadWriteLock API doesn't really lend itself
> well to it though - the only way that API could support upgrades in any
> kind of sane way is if the owner of the read lock acquired the write lock
> and then released the read lock.  Unfortunately this doesn't align with any
> kind of simple way to support upgrading, which entails a reader performing
> an upgrade request, which would either block waiting for the write lock to
> become available (if the requester is the first), or would throw an
> exception of some sort.  After a successful upgrade, the reader would now
> be a writer.  But this doesn't map well to the API when there are distinct
> Lock objects for readers and writer.
>
> My opinion is that in retrospect, making ReadWriteLock reuse the Lock
> interface in the way that it does turned out to be the wrong choice. There
> is probably very little generic code which could take advantage of this
> reuse, it makes lock downgrading clunky and easy to mess up, and it makes
> things like supporting upgrade fairly problematic.  A single instance with
> acquireRead(), acquireWrite(), and release() would have made more sense,
> and would have made upgrade (and downgrade) support pretty simple as you'd
> be able to request upgrade via acquireWrite() while holding read, and
> downgrade via acquireRead() while holding write, and a single release point
> makes cleanup much simpler (in fact using AutoCloseable would be a boon
> here).
>
> Well, coding is 10% inspiration, 30% perspiration, and 60% regret. :)
>
>
> On 09/24/2013 11:53 AM, Oleksandr Otenko wrote:
>
>> It's possible, but nonsensical - the upgrade will be equivalent to
>> release read, acquire write.
>>
>> Also, it makes sense in designs with more than three states (0, R, 1).
>> Eg when upgrade doesn't get the Write, but something in the middle
>> between Read and Write.
>>
>> Alex
>>
>>
>> On 24/09/2013 16:24, Scott Blum wrote:
>>
>>> I was a little surprised to discover that a lock upgrade is not
>>> possible.  I read through this tutorial which suggests that supporting
>>> read->write upgrade should be possible:
>>>
>>> http://tutorials.jenkov.com/**java-concurrency/read-write-**locks.html<http://tutorials.jenkov.com/java-concurrency/read-write-locks.html>
>>>
>>> Was this a deliberate design decision for ReentrantReadWriteLock, or
>>> is there something inherently unsafe about what he's doing in that
>>> article?
>>>
>>> Thanks,
>>> Scott
>>>
>>>
>>>
>>> ______________________________**_________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>
> --
> - DML
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130924/484a299a/attachment.html>

From david.lloyd at redhat.com  Tue Sep 24 15:23:49 2013
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 24 Sep 2013 14:23:49 -0500
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <CALuNCphk7OSGVL2L22ZFzM6hA70uqQZ5syVGk0zFiQZGQFTZ1w@mail.gmail.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
	<5241C38C.2020507@oracle.com> <5241D8EE.4040807@redhat.com>
	<CALuNCphk7OSGVL2L22ZFzM6hA70uqQZ5syVGk0zFiQZGQFTZ1w@mail.gmail.com>
Message-ID: <5241E6C5.8070002@redhat.com>

Yeah to make that scenario work you have to choose one "winner", and 
kill off the losers.  The easiest (but probably harshest) way to do that 
is simply to throw an exception.

In the hypothetical upgradable lock though, you could also have 
tryAcquireIntentToWrite() which would not block and would return true if 
you win the "intent to write" permit.  There are many ways to design 
this kind of lock but in a simple implementation, intent-to-write would 
block additional readers, and the owner of that lock would be allowed to 
call acquireWrite() without an exception.

On 09/24/2013 02:15 PM, Scott Blum wrote:
> Thanks for the detailed analysis.  A coworker of mine did point out one
> interesting note about lock upgrades:
>
>     BTW, I'm pretty sure the reason lock upgrades are not allowed is
>     because it is deadlock prone. Simple case: two threads both have the
>     read lock and then both request the write lock. Neither thread can
>     acquire the write lock until the other has released its read lock,
>     which means deadlock.
>
>
> How would one handle this scenario?  Is this what you had in mind when
> you mentioned throwing an exception of some sort trying to upgrade?
>
>
> On Tue, Sep 24, 2013 at 2:24 PM, David M. Lloyd <david.lloyd at redhat.com
> <mailto:david.lloyd at redhat.com>> wrote:
>
>     This topic does come up quite a lot.
>
>     Upgradeable read-write locks are not nonsensical at all; in fact
>     they're quite common in the wild.  The ReadWriteLock API doesn't
>     really lend itself well to it though - the only way that API could
>     support upgrades in any kind of sane way is if the owner of the read
>     lock acquired the write lock and then released the read lock.
>       Unfortunately this doesn't align with any kind of simple way to
>     support upgrading, which entails a reader performing an upgrade
>     request, which would either block waiting for the write lock to
>     become available (if the requester is the first), or would throw an
>     exception of some sort.  After a successful upgrade, the reader
>     would now be a writer.  But this doesn't map well to the API when
>     there are distinct Lock objects for readers and writer.
>
>     My opinion is that in retrospect, making ReadWriteLock reuse the
>     Lock interface in the way that it does turned out to be the wrong
>     choice. There is probably very little generic code which could take
>     advantage of this reuse, it makes lock downgrading clunky and easy
>     to mess up, and it makes things like supporting upgrade fairly
>     problematic.  A single instance with acquireRead(), acquireWrite(),
>     and release() would have made more sense, and would have made
>     upgrade (and downgrade) support pretty simple as you'd be able to
>     request upgrade via acquireWrite() while holding read, and downgrade
>     via acquireRead() while holding write, and a single release point
>     makes cleanup much simpler (in fact using AutoCloseable would be a
>     boon here).
>
>     Well, coding is 10% inspiration, 30% perspiration, and 60% regret. :)
>
>
>     On 09/24/2013 11:53 AM, Oleksandr Otenko wrote:
>
>         It's possible, but nonsensical - the upgrade will be equivalent to
>         release read, acquire write.
>
>         Also, it makes sense in designs with more than three states (0,
>         R, 1).
>         Eg when upgrade doesn't get the Write, but something in the middle
>         between Read and Write.
>
>         Alex
>
>
>         On 24/09/2013 16:24, Scott Blum wrote:
>
>             I was a little surprised to discover that a lock upgrade is not
>             possible.  I read through this tutorial which suggests that
>             supporting
>             read->write upgrade should be possible:
>
>             http://tutorials.jenkov.com/__java-concurrency/read-write-__locks.html
>             <http://tutorials.jenkov.com/java-concurrency/read-write-locks.html>
>
>             Was this a deliberate design decision for
>             ReentrantReadWriteLock, or
>             is there something inherently unsafe about what he's doing
>             in that
>             article?
>
>             Thanks,
>             Scott
>
>
>
>             _________________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.__oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>             <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
>         _________________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>     --
>     - DML
>
>     _________________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.__oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>


-- 
- DML

From oleksandr.otenko at oracle.com  Tue Sep 24 17:04:01 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 24 Sep 2013 22:04:01 +0100
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <5241D8EE.4040807@redhat.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
	<5241C38C.2020507@oracle.com> <5241D8EE.4040807@redhat.com>
Message-ID: <5241FE41.80300@oracle.com>

Everyone doing it is not a justification, because the way "it" is done 
can mean different things.

It all boils down to who / what accesses you want to exclude with a 
lock. For example, if you read X, and want to upgrade to only modify Y, 
whereas those who want a write lock from the start may modify X or Y, 
you have another level between R and W.


Throwing exception is a "rollback" with a possible outcome being "redo". 
This is the same as tryAcquire a write, then redo or forget it.

Blocking until a write lock is available requires revalidation of the 
data read while holding a read lock.


Alex

On 24/09/2013 19:24, David M. Lloyd wrote:
> This topic does come up quite a lot.
>
> Upgradeable read-write locks are not nonsensical at all; in fact 
> they're quite common in the wild.  The ReadWriteLock API doesn't 
> really lend itself well to it though - the only way that API could 
> support upgrades in any kind of sane way is if the owner of the read 
> lock acquired the write lock and then released the read lock.  
> Unfortunately this doesn't align with any kind of simple way to 
> support upgrading, which entails a reader performing an upgrade 
> request, which would either block waiting for the write lock to become 
> available (if the requester is the first), or would throw an exception 
> of some sort.  After a successful upgrade, the reader would now be a 
> writer.  But this doesn't map well to the API when there are distinct 
> Lock objects for readers and writer.
>
> My opinion is that in retrospect, making ReadWriteLock reuse the Lock 
> interface in the way that it does turned out to be the wrong choice. 
> There is probably very little generic code which could take advantage 
> of this reuse, it makes lock downgrading clunky and easy to mess up, 
> and it makes things like supporting upgrade fairly problematic.  A 
> single instance with acquireRead(), acquireWrite(), and release() 
> would have made more sense, and would have made upgrade (and 
> downgrade) support pretty simple as you'd be able to request upgrade 
> via acquireWrite() while holding read, and downgrade via acquireRead() 
> while holding write, and a single release point makes cleanup much 
> simpler (in fact using AutoCloseable would be a boon here).
>
> Well, coding is 10% inspiration, 30% perspiration, and 60% regret. :)
>
> On 09/24/2013 11:53 AM, Oleksandr Otenko wrote:
>> It's possible, but nonsensical - the upgrade will be equivalent to
>> release read, acquire write.
>>
>> Also, it makes sense in designs with more than three states (0, R, 1).
>> Eg when upgrade doesn't get the Write, but something in the middle
>> between Read and Write.
>>
>> Alex
>>
>>
>> On 24/09/2013 16:24, Scott Blum wrote:
>>> I was a little surprised to discover that a lock upgrade is not
>>> possible.  I read through this tutorial which suggests that supporting
>>> read->write upgrade should be possible:
>>>
>>> http://tutorials.jenkov.com/java-concurrency/read-write-locks.html
>>>
>>> Was this a deliberate design decision for ReentrantReadWriteLock, or
>>> is there something inherently unsafe about what he's doing in that
>>> article?
>>>
>>> Thanks,
>>> Scott
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>


From niall at npgall.com  Tue Sep 24 17:46:36 2013
From: niall at npgall.com (Niall Gallagher)
Date: Tue, 24 Sep 2013 22:46:36 +0100
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
Message-ID: <0A376514-82C0-45E5-915E-6E1CE8ABA570@npgall.com>

There was a related discussion on this list in July [1].

Long story short, there are a few options. It's not an accidental omission from ReentrantReadWriteLock in the JDK, as a classic readers-writer lock is susceptible to deadlock if two readers both block on an attempt to upgrade.

One alternative is a ReentrantReadWrite*Update*Lock [2]. This models the "right" to upgrade explicitly by introducing a separate "update" lock (so the option to upgrade can be reserved in advance, and exercised or not exercised later). It can be useful in some, but not all, use cases with read-before-write access patterns.

Another is the JDK 8 StampedLock[3] which also supports lock upgrade, however this does not guarantee the ability to upgrade, as it depends on the number of readers in the system when upgrade is attempted. So there are tradeoffs between the various approaches.

StampedLock = optimistic locking (acquire read lock, and you might be able to upgrade).
ReentrantReadWriteLock = pessimistic locking (must acquire write lock from the outset).
ReentrantReadWriteUpdateLock = sort of a middle ground (read locks and update lock coexist, update lock is upgradable) .

[1] http://cs.oswego.edu/pipermail/concurrency-interest/2013-July/011621.html
[2] http://code.google.com/p/concurrent-locks/
[3] http://download.java.net/jdk8/docs/api/java/util/concurrent/locks/StampedLock.html



From nathan.reynolds at oracle.com  Tue Sep 24 21:25:18 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 24 Sep 2013 18:25:18 -0700
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <0A376514-82C0-45E5-915E-6E1CE8ABA570@npgall.com>
References: <0A376514-82C0-45E5-915E-6E1CE8ABA570@npgall.com>
Message-ID: <52423B7E.20600@oracle.com>

Several years ago, I implemented ReentrantReadWriteLock and 
ReentrantReadWriteUpdateLock in a C++ server.  Adding update 
capabilities makes the logic in the lock more complex and hence less 
performant.  So, having two different locks depending upon whether 
updatability is needed is actually a good idea.  It allows the 
programmer to decide if they need the extra functionality and if it is 
worth the cost.  Most situations don't need updatability and to require 
everyone to pay for it would be a mistake.

-Nathan

On 9/24/2013 2:46 PM, Niall Gallagher wrote:
> There was a related discussion on this list in July [1].
>
> Long story short, there are a few options. It's not an accidental omission from ReentrantReadWriteLock in the JDK, as a classic readers-writer lock is susceptible to deadlock if two readers both block on an attempt to upgrade.
>
> One alternative is a ReentrantReadWrite*Update*Lock [2]. This models the "right" to upgrade explicitly by introducing a separate "update" lock (so the option to upgrade can be reserved in advance, and exercised or not exercised later). It can be useful in some, but not all, use cases with read-before-write access patterns.
>
> Another is the JDK 8 StampedLock[3] which also supports lock upgrade, however this does not guarantee the ability to upgrade, as it depends on the number of readers in the system when upgrade is attempted. So there are tradeoffs between the various approaches.
>
> StampedLock = optimistic locking (acquire read lock, and you might be able to upgrade).
> ReentrantReadWriteLock = pessimistic locking (must acquire write lock from the outset).
> ReentrantReadWriteUpdateLock = sort of a middle ground (read locks and update lock coexist, update lock is upgradable) .
>
> [1] http://cs.oswego.edu/pipermail/concurrency-interest/2013-July/011621.html
> [2] http://code.google.com/p/concurrent-locks/
> [3] http://download.java.net/jdk8/docs/api/java/util/concurrent/locks/StampedLock.html
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan


From david.lloyd at redhat.com  Tue Sep 24 23:27:37 2013
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 24 Sep 2013 22:27:37 -0500
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <5241FE41.80300@oracle.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
	<5241C38C.2020507@oracle.com> <5241D8EE.4040807@redhat.com>
	<5241FE41.80300@oracle.com>
Message-ID: <52425829.2090406@redhat.com>

The obvious implementation of an upgradeable RW lock would use an 
intent-to-write lock state granted to one upgrade requester; other 
upgrade requesters can fail-fast and know that they cannot upgrade and 
that the state will definitely change after they release the lock (I 
guess this is what you mean by rollback/redo though I don't think that 
terminology is quite applicable; working with transaction experts has 
taught me the peril of using transaction terminology lightly!).

The requester that successfully received the intent-to-write lock could 
freely block for a write lock, and when the lock was granted, she would 
be guaranteed to see the same state that she saw as a read lock holder. 
  Requsters who fail to receive the lock would have to be informed 
(either via aforementioned exception or a false return on a tryUpgrade 
sort of method) that they cannot be upgraded without releasing the read 
lock first.  Other waiting (non-upgrade) writers would block for the 
intent-to-write permit, thus preventing waiting writers from gaining 
priority over the upgrading reader.

Anyway I am describing a hypothetical implementation, not arguing about 
the validity of having a RW lock in the first place (in fact I would 
tend to argue against it for most use cases, as I know that several 
parties have demonstrated that RW locks do not generally scale well for 
various reasons).

On 09/24/2013 04:04 PM, Oleksandr Otenko wrote:
> Everyone doing it is not a justification, because the way "it" is done
> can mean different things.
>
> It all boils down to who / what accesses you want to exclude with a
> lock. For example, if you read X, and want to upgrade to only modify Y,
> whereas those who want a write lock from the start may modify X or Y,
> you have another level between R and W.
>
>
> Throwing exception is a "rollback" with a possible outcome being "redo".
> This is the same as tryAcquire a write, then redo or forget it.
>
> Blocking until a write lock is available requires revalidation of the
> data read while holding a read lock.
>
>
> Alex
>
> On 24/09/2013 19:24, David M. Lloyd wrote:
>> This topic does come up quite a lot.
>>
>> Upgradeable read-write locks are not nonsensical at all; in fact
>> they're quite common in the wild.  The ReadWriteLock API doesn't
>> really lend itself well to it though - the only way that API could
>> support upgrades in any kind of sane way is if the owner of the read
>> lock acquired the write lock and then released the read lock.
>> Unfortunately this doesn't align with any kind of simple way to
>> support upgrading, which entails a reader performing an upgrade
>> request, which would either block waiting for the write lock to become
>> available (if the requester is the first), or would throw an exception
>> of some sort.  After a successful upgrade, the reader would now be a
>> writer.  But this doesn't map well to the API when there are distinct
>> Lock objects for readers and writer.
>>
>> My opinion is that in retrospect, making ReadWriteLock reuse the Lock
>> interface in the way that it does turned out to be the wrong choice.
>> There is probably very little generic code which could take advantage
>> of this reuse, it makes lock downgrading clunky and easy to mess up,
>> and it makes things like supporting upgrade fairly problematic.  A
>> single instance with acquireRead(), acquireWrite(), and release()
>> would have made more sense, and would have made upgrade (and
>> downgrade) support pretty simple as you'd be able to request upgrade
>> via acquireWrite() while holding read, and downgrade via acquireRead()
>> while holding write, and a single release point makes cleanup much
>> simpler (in fact using AutoCloseable would be a boon here).
>>
>> Well, coding is 10% inspiration, 30% perspiration, and 60% regret. :)
>>
>> On 09/24/2013 11:53 AM, Oleksandr Otenko wrote:
>>> It's possible, but nonsensical - the upgrade will be equivalent to
>>> release read, acquire write.
>>>
>>> Also, it makes sense in designs with more than three states (0, R, 1).
>>> Eg when upgrade doesn't get the Write, but something in the middle
>>> between Read and Write.
>>>
>>> Alex
>>>
>>>
>>> On 24/09/2013 16:24, Scott Blum wrote:
>>>> I was a little surprised to discover that a lock upgrade is not
>>>> possible.  I read through this tutorial which suggests that supporting
>>>> read->write upgrade should be possible:
>>>>
>>>> http://tutorials.jenkov.com/java-concurrency/read-write-locks.html
>>>>
>>>> Was this a deliberate design decision for ReentrantReadWriteLock, or
>>>> is there something inherently unsafe about what he's doing in that
>>>> article?
>>>>
>>>> Thanks,
>>>> Scott
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>


-- 
- DML

From niall at npgall.com  Wed Sep 25 14:22:16 2013
From: niall at npgall.com (Niall Gallagher)
Date: Wed, 25 Sep 2013 19:22:16 +0100
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
Message-ID: <CABc862+ZGfY=tsMz5bKJUGKLHpDo1j3Fni+qPABcmvYghzjK0g@mail.gmail.com>

Actually that is not a hypothetical implementation :)

It's the approach taken in the read-write-update
lock implementation I mentioned [1], just our
terminology is different.

The "update" lock is an "intent-to-write" lock,
although more specifically I'd describe it as
an "option-to-write" lock, because exercising the
option to write is, er.. optional.

The code
    rwuLock.updateLock().tryLock()

allows fail-fast type of acquisition.

After successfully acquiring the update lock, the code
    rwuLock.updateLock().lock()

upgrades from the update lock to the write lock
(guaranteed to succeed without deadlock, when
any readers drain).

On failing to obtain the update lock, would-be requesters
would not be guaranteed to see state change however,
as the thread holding the update lock might choose not
to upgrade to a write lock after all.

If a thread tries to obtain the write lock without first
holding the update lock, the implementation is such that
acquiring the write lock implicitly (re-)acquires the update
lock, so the effect is the same as if it did already hold the
update lock. There are a few examples on the site.

[1] http://code.google.com/p/concurrent-locks/


On Tue Sep 24 23:27:37 EDT 2013, David M. Lloyd wrote:
> The obvious implementation of an upgradeable RW lock would use an
> intent-to-write lock state granted to one upgrade requester; other
> upgrade requesters can fail-fast and know that they cannot upgrade and
> that the state will definitely change after they release the lock (I
> guess this is what you mean by rollback/redo though I don't think that
> terminology is quite applicable; working with transaction experts has
> taught me the peril of using transaction terminology lightly!).
>
> The requester that successfully received the intent-to-write lock could
> freely block for a write lock, and when the lock was granted, she would
> be guaranteed to see the same state that she saw as a read lock holder.
>   Requsters who fail to receive the lock would have to be informed
> (either via aforementioned exception or a false return on a tryUpgrade
> sort of method) that they cannot be upgraded without releasing the read
> lock first.  Other waiting (non-upgrade) writers would block for the
> intent-to-write permit, thus preventing waiting writers from gaining
> priority over the upgrading reader.
>
> Anyway I am describing a hypothetical implementation, not arguing about
> the validity of having a RW lock in the first place (in fact I would
> tend to argue against it for most use cases, as I know that several
> parties have demonstrated that RW locks do not generally scale well for
> various reasons).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130925/6d70286a/attachment.html>

From niall at npgall.com  Wed Sep 25 14:29:38 2013
From: niall at npgall.com (Niall Gallagher)
Date: Wed, 25 Sep 2013 19:29:38 +0100
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <CABc862+ZGfY=tsMz5bKJUGKLHpDo1j3Fni+qPABcmvYghzjK0g@mail.gmail.com>
References: <CABc862+ZGfY=tsMz5bKJUGKLHpDo1j3Fni+qPABcmvYghzjK0g@mail.gmail.com>
Message-ID: <CABc862J5kY=Xxt7MQ9+UBkQOPoR3C6SuSKJzO1R4v0_2Tx0jkQ@mail.gmail.com>

Oops, I mean the code the code
    rwuLock.writeLock().lock()

upgrades from the update lock to the write lock.


On 25 September 2013 19:22, Niall Gallagher <niall at npgall.com> wrote:

> Actually that is not a hypothetical implementation :)
>
> It's the approach taken in the read-write-update
> lock implementation I mentioned [1], just our
> terminology is different.
>
> The "update" lock is an "intent-to-write" lock,
> although more specifically I'd describe it as
> an "option-to-write" lock, because exercising the
> option to write is, er.. optional.
>
> The code
>     rwuLock.updateLock().tryLock()
>
> allows fail-fast type of acquisition.
>
> After successfully acquiring the update lock, the code
>     rwuLock.updateLock().lock()
>
> upgrades from the update lock to the write lock
> (guaranteed to succeed without deadlock, when
> any readers drain).
>
> On failing to obtain the update lock, would-be requesters
> would not be guaranteed to see state change however,
> as the thread holding the update lock might choose not
> to upgrade to a write lock after all.
>
> If a thread tries to obtain the write lock without first
> holding the update lock, the implementation is such that
> acquiring the write lock implicitly (re-)acquires the update
> lock, so the effect is the same as if it did already hold the
> update lock. There are a few examples on the site.
>
> [1] http://code.google.com/p/concurrent-locks/
>
>
> On Tue Sep 24 23:27:37 EDT 2013, David M. Lloyd wrote:
> > The obvious implementation of an upgradeable RW lock would use an
> > intent-to-write lock state granted to one upgrade requester; other
> > upgrade requesters can fail-fast and know that they cannot upgrade and
> > that the state will definitely change after they release the lock (I
> > guess this is what you mean by rollback/redo though I don't think that
> > terminology is quite applicable; working with transaction experts has
> > taught me the peril of using transaction terminology lightly!).
> >
> > The requester that successfully received the intent-to-write lock could
> > freely block for a write lock, and when the lock was granted, she would
> > be guaranteed to see the same state that she saw as a read lock holder.
> >   Requsters who fail to receive the lock would have to be informed
> > (either via aforementioned exception or a false return on a tryUpgrade
> > sort of method) that they cannot be upgraded without releasing the read
> > lock first.  Other waiting (non-upgrade) writers would block for the
> > intent-to-write permit, thus preventing waiting writers from gaining
> > priority over the upgrading reader.
> >
> > Anyway I am describing a hypothetical implementation, not arguing about
> > the validity of having a RW lock in the first place (in fact I would
> > tend to argue against it for most use cases, as I know that several
> > parties have demonstrated that RW locks do not generally scale well for
> > various reasons).
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130925/3f7f92e5/attachment.html>

From vitalyd at gmail.com  Wed Sep 25 14:38:23 2013
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 25 Sep 2013 14:38:23 -0400
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <CABc862+ZGfY=tsMz5bKJUGKLHpDo1j3Fni+qPABcmvYghzjK0g@mail.gmail.com>
References: <CABc862+ZGfY=tsMz5bKJUGKLHpDo1j3Fni+qPABcmvYghzjK0g@mail.gmail.com>
Message-ID: <CAHjP37GRP6sEaH0Fq+TzmETMZzrrZypGaO3YbGUE6Wu1db0L_g@mail.gmail.com>

This is pretty much the same as the ReaderWriterLockSlim in .NET - you
enter/exit an upgradeable lock which has the "option to upgrade to write
lock" semantic.

Sent from my phone
On Sep 25, 2013 2:28 PM, "Niall Gallagher" <niall at npgall.com> wrote:

> Actually that is not a hypothetical implementation :)
>
> It's the approach taken in the read-write-update
> lock implementation I mentioned [1], just our
> terminology is different.
>
> The "update" lock is an "intent-to-write" lock,
> although more specifically I'd describe it as
> an "option-to-write" lock, because exercising the
> option to write is, er.. optional.
>
> The code
>     rwuLock.updateLock().tryLock()
>
> allows fail-fast type of acquisition.
>
> After successfully acquiring the update lock, the code
>     rwuLock.updateLock().lock()
>
> upgrades from the update lock to the write lock
> (guaranteed to succeed without deadlock, when
> any readers drain).
>
> On failing to obtain the update lock, would-be requesters
> would not be guaranteed to see state change however,
> as the thread holding the update lock might choose not
> to upgrade to a write lock after all.
>
> If a thread tries to obtain the write lock without first
> holding the update lock, the implementation is such that
> acquiring the write lock implicitly (re-)acquires the update
> lock, so the effect is the same as if it did already hold the
> update lock. There are a few examples on the site.
>
> [1] http://code.google.com/p/concurrent-locks/
>
>
> On Tue Sep 24 23:27:37 EDT 2013, David M. Lloyd wrote:
> > The obvious implementation of an upgradeable RW lock would use an
> > intent-to-write lock state granted to one upgrade requester; other
> > upgrade requesters can fail-fast and know that they cannot upgrade and
> > that the state will definitely change after they release the lock (I
> > guess this is what you mean by rollback/redo though I don't think that
> > terminology is quite applicable; working with transaction experts has
> > taught me the peril of using transaction terminology lightly!).
> >
> > The requester that successfully received the intent-to-write lock could
> > freely block for a write lock, and when the lock was granted, she would
> > be guaranteed to see the same state that she saw as a read lock holder.
> >   Requsters who fail to receive the lock would have to be informed
> > (either via aforementioned exception or a false return on a tryUpgrade
> > sort of method) that they cannot be upgraded without releasing the read
> > lock first.  Other waiting (non-upgrade) writers would block for the
> > intent-to-write permit, thus preventing waiting writers from gaining
> > priority over the upgrading reader.
> >
> > Anyway I am describing a hypothetical implementation, not arguing about
> > the validity of having a RW lock in the first place (in fact I would
> > tend to argue against it for most use cases, as I know that several
> > parties have demonstrated that RW locks do not generally scale well for
> > various reasons).
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130925/1dee4275/attachment.html>

From oleksandr.otenko at oracle.com  Wed Sep 25 15:23:22 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 25 Sep 2013 20:23:22 +0100
Subject: [concurrency-interest] ReentrantReadWriteLock upgrade
	read->write
In-Reply-To: <52425829.2090406@redhat.com>
References: <CALuNCpg5ajn46gRZ7yfR66fPTV=TEaxJ4qBagQxRFyAsbK6Wjw@mail.gmail.com>
	<5241C38C.2020507@oracle.com> <5241D8EE.4040807@redhat.com>
	<5241FE41.80300@oracle.com> <52425829.2090406@redhat.com>
Message-ID: <5243382A.8020408@oracle.com>

That's right. You have one more level. And Niall quoted one 
implementation (I think it was even discussed here earlier).

A lock excludes effects of a certain kind. We can assign different 
grades to effects.

Suppose we have a total order of grades of effects (possibly even a 
partial order might work): 0 < P < Q < R < 1. Each thread is associated 
with one grade of effects it is producing at the moment. The threads can 
transition from one grade to the other using Lattice.

Lattice captures the state of a synchronization point and can make 
decisions about transition of thread grade. Lattice can perform one 
action, await(p, q), with p == new grade of the caller's effects, and q 
== grade of effects to block. It blocks the caller until a proof is 
available that there are no threads that block grade p, that is, all 
threads that called await(-,y) p >= y modified their grade to a 
different level, and blocks all subsequent concurrent callers of 
await(x, -), if x >= q, until all threads change their grade to exclude 
a different grade.

Not sure how clear the above is, so let me give examples:

*Mutex**
*
Define total order 0 < 1.
lock.acquire() == lattice.await(1,0)
lock.release() == lattice.await(0,1) // this doesn't really await, 
because there is no concurrent threads demanding exclusion of grade 0

*RW lock**
*
Define total order 0 < R < W < 1.
read.acquire() == lattice.await(R,W) // proceed only if no thread 
excludes R, and by doing so, exclude threads that want W
read.release() == lattice.await(0,1) // not a wait really

write.acquire() == lattice.await(W,R) // proceed only if no thread 
excludes W or R (ie no concurrent R, and no concurrent W), and exclude 
threads that want R or W
write.release() == lattice.await(0,1)

*RWU lock*

Define total order 0 < R < P < W < 1.
read.acquire() == lattice.await(R,W) // like RW, but permits 
intermediate grade, P, to proceed concurrently
maybeWrite.acquire() == lattice.await(P,P) // wait till no one objects 
for P to enter, and forbid P and W -- this is what updateLock.acquire() 
is in that email
write.acquire() == lattice.await(W,R) // if called by the thread that 
already done lattice.await(P,P), will only wait for all R to leave; note 
that this will exclude maybeWrite.acquire(), too

Now because maybeWrite.acquire() mutually excludes other maybeWriters, 
we can make decisions based on excluded effects from maybeWriters.

Here write.release(), if done "inside" maybeWrite.acquire(), becomes a 
non-blocking lattice.await(P,P) (it doesn't block, because it is already 
at a wider exclusion scope).

This can be extended to sequencers.

Alex

On 25/09/2013 04:27, David M. Lloyd wrote:
> The obvious implementation of an upgradeable RW lock would use an 
> intent-to-write lock state granted to one upgrade requester; other 
> upgrade requesters can fail-fast and know that they cannot upgrade and 
> that the state will definitely change after they release the lock (I 
> guess this is what you mean by rollback/redo though I don't think that 
> terminology is quite applicable; working with transaction experts has 
> taught me the peril of using transaction terminology lightly!).
>
> The requester that successfully received the intent-to-write lock 
> could freely block for a write lock, and when the lock was granted, 
> she would be guaranteed to see the same state that she saw as a read 
> lock holder.  Requsters who fail to receive the lock would have to be 
> informed (either via aforementioned exception or a false return on a 
> tryUpgrade sort of method) that they cannot be upgraded without 
> releasing the read lock first.  Other waiting (non-upgrade) writers 
> would block for the intent-to-write permit, thus preventing waiting 
> writers from gaining priority over the upgrading reader.
>
> Anyway I am describing a hypothetical implementation, not arguing 
> about the validity of having a RW lock in the first place (in fact I 
> would tend to argue against it for most use cases, as I know that 
> several parties have demonstrated that RW locks do not generally scale 
> well for various reasons).
>
> On 09/24/2013 04:04 PM, Oleksandr Otenko wrote:
>> Everyone doing it is not a justification, because the way "it" is done
>> can mean different things.
>>
>> It all boils down to who / what accesses you want to exclude with a
>> lock. For example, if you read X, and want to upgrade to only modify Y,
>> whereas those who want a write lock from the start may modify X or Y,
>> you have another level between R and W.
>>
>>
>> Throwing exception is a "rollback" with a possible outcome being "redo".
>> This is the same as tryAcquire a write, then redo or forget it.
>>
>> Blocking until a write lock is available requires revalidation of the
>> data read while holding a read lock.
>>
>>
>> Alex
>>
>> On 24/09/2013 19:24, David M. Lloyd wrote:
>>> This topic does come up quite a lot.
>>>
>>> Upgradeable read-write locks are not nonsensical at all; in fact
>>> they're quite common in the wild.  The ReadWriteLock API doesn't
>>> really lend itself well to it though - the only way that API could
>>> support upgrades in any kind of sane way is if the owner of the read
>>> lock acquired the write lock and then released the read lock.
>>> Unfortunately this doesn't align with any kind of simple way to
>>> support upgrading, which entails a reader performing an upgrade
>>> request, which would either block waiting for the write lock to become
>>> available (if the requester is the first), or would throw an exception
>>> of some sort.  After a successful upgrade, the reader would now be a
>>> writer.  But this doesn't map well to the API when there are distinct
>>> Lock objects for readers and writer.
>>>
>>> My opinion is that in retrospect, making ReadWriteLock reuse the Lock
>>> interface in the way that it does turned out to be the wrong choice.
>>> There is probably very little generic code which could take advantage
>>> of this reuse, it makes lock downgrading clunky and easy to mess up,
>>> and it makes things like supporting upgrade fairly problematic.  A
>>> single instance with acquireRead(), acquireWrite(), and release()
>>> would have made more sense, and would have made upgrade (and
>>> downgrade) support pretty simple as you'd be able to request upgrade
>>> via acquireWrite() while holding read, and downgrade via acquireRead()
>>> while holding write, and a single release point makes cleanup much
>>> simpler (in fact using AutoCloseable would be a boon here).
>>>
>>> Well, coding is 10% inspiration, 30% perspiration, and 60% regret. :)
>>>
>>> On 09/24/2013 11:53 AM, Oleksandr Otenko wrote:
>>>> It's possible, but nonsensical - the upgrade will be equivalent to
>>>> release read, acquire write.
>>>>
>>>> Also, it makes sense in designs with more than three states (0, R, 1).
>>>> Eg when upgrade doesn't get the Write, but something in the middle
>>>> between Read and Write.
>>>>
>>>> Alex
>>>>
>>>>
>>>> On 24/09/2013 16:24, Scott Blum wrote:
>>>>> I was a little surprised to discover that a lock upgrade is not
>>>>> possible.  I read through this tutorial which suggests that 
>>>>> supporting
>>>>> read->write upgrade should be possible:
>>>>>
>>>>> http://tutorials.jenkov.com/java-concurrency/read-write-locks.html
>>>>>
>>>>> Was this a deliberate design decision for ReentrantReadWriteLock, or
>>>>> is there something inherently unsafe about what he's doing in that
>>>>> article?
>>>>>
>>>>> Thanks,
>>>>> Scott
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130925/2952bbe7/attachment-0001.html>

From pramalhe at gmail.com  Sun Sep 29 17:50:55 2013
From: pramalhe at gmail.com (Pedro Ramalhete)
Date: Sun, 29 Sep 2013 23:50:55 +0200
Subject: [concurrency-interest] Using LongAdder to make a Reader-Writer Lock
Message-ID: <CAAApjO075+VSDMKmVFPO0EwE=1v6Vwb+o3yFW_pnS8tf3HTRhg@mail.gmail.com>

Hello,

We've created a new RW-Lock, named LongAdderRWLock, by combining JDK 8's
LongAdder and StampedLock, using the C-RW-WP algorithm described in the
"NUMA-Aware Reader Writer Locks" paper. The technique with two counters
(ingress/egress, as described in the same paper) was used to make a
sequentially consistent logical counter to be used as readIndicator in the
C-RW-WP.
Unlike our previous implementations, this new RW-Lock does not need to use
ThreadLocals, CLQ, or finalize() methods, has a small memory footprint, and
its code is very simple because most of the complexity and sophistication
is "borrowed" from the StampedLock and LongAdder classes.

Here is a link to the source code, and as can be seen, the code is short
and simple:
https://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/locks/LongAdderRWLock.java/download

Andreia has created a variant that uses a single LongAdder instance instead
of two, thus consuming half the memory, requiring only a small change to
the LongAdder class. Code can be obtained here:
https://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/locks/LongAdderExtRWLock.java/download

More details and performance plots are available below:
http://concurrencyfreaks.blogspot.fr/2013/09/longadder-is-not-sequentially-consistent.html
http://concurrencyfreaks.blogspot.fr/2013/09/combining-stampedlock-and-longadder-to.html
http://concurrencyfreaks.blogspot.fr/2013/09/scalable-rw-lock-with-single-longadder.html


These and other variants are part of ConcurrencyFreaks Library 0.5:
https://sourceforge.net/projects/ccfreaks/files/

Thanks,
Pedro & Andreia
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20130929/113a855c/attachment.html>

