Subject: Re: [concurrency-interest] hb: potential causality; causal order: explicit causality?
From: Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-02, 22:20
To: alarmnummer <alarmnummer@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Shuyang Liu <sliu44@cs.ucla.edu>

Hello,

I cannot give an exact answer to the question but the definition of the term "causality" is quite ambiguous in weak memory models as it is very easy to raise to the out of thin air issue if not defined carefully. Perhaps a good reference is not a definition but a set of litmus tests showing how "causality" works in Java: http://www.cs.umd.edu/~pugh/java/memoryModel/CausalityTestCases.html

For Java, it can be hard to decided whether certain access "doesn't influence the value written" because of the compiler optimizations. Sometimes a compiler can even eliminate a control dependency between two events due to common sub-expressions so some of the explicit causal order at source code level may not be preserved by the compiler. On that front, I found this recent paper to be really close to formally define the dependencies: https://dl.acm.org/doi/10.1145/3498716

Best Regards,
Shuyang

From: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
To: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
Sent: Saturday, February 26, 2022 5:36:05 AM
Subject: [concurrency-interest] hb: potential causality; causal order: explicit causality?

Hi,

I'm trying to get a better understanding of the causal order. So I'm posting my understanding of the topic and would like to get feedback if I'm on the right track.

There are 2 flavors of causality in the space of memory models and distributed systems:
- potential causality
- explicit causality

In the "Time, clocks, and the ordering of events in a distributed system", where the happens-before relation is introduced, Leslie Lamport is talking about potential causality.

So if a->b then a might have affected b.

The happens-before relation from the JMM is about potential causality as well. E.g.

thread1:
  r1=a (1)
  a=1  (2)

They are ordered by the happens-before relation due to the program order rule. The happens-before has no clue if (1) and (2) are causally related or not;  so it just assumes that (1) might have affected (2).

Every execution that is allowed by the JMM has the following 2 constraints:
- (happens before) consistency.
- causality
The primary purpose of causality is to exclude executions with causal loops.

AFAIK this causal order is explicit causality. E.g.

thread1:
  r1=a   (1)
  a=1     (2)

The read (1) doesn't influence the value written at (2), so they are not ordered by the causal order.

But the following example is one with explicit causality:

thread1:
  r1=a      (1)
  a=r1+1  (2)

The value written is influenced by the value read, so (1) is ordered before (2) in the causal order.

Is my understanding correct?

PS: One of the papers I'm studying is the "JSR-133 Java Memory Model and Thread Specification".

Regards,

Peter.




_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: [concurrency-interest] ConcurrentHashMap and equality
From: Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-14, 00:51
To: "Concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Benjamin Manes <ben.manes@gmail.com>

The equality contract for Map is defined as having the same mappings in their entrySet views. The AbstractMap and AbstractSet implementations include a size() prescreen, which is typically an immediate operation. The concurrent maps don't, though, and I am wondering if this is a missed opportunity. The consistency property already dictates that the comparison is deterministic only if neither object or its parts are modified between invocations. Therefore the method's documentation that equality may be misleading in the face of concurrency is simply a reminder of that fact. Since the size check might be performed regardless by an AbstractMap-based implementation (e.g. HashMap), then by symmetry it would imply that adding this prescreen would be an acceptable optimization. Does that seem reasonable or is there an aspect that I am forgetting?

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] ConcurrentHashMap and equality
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-14, 04:47
To: Benjamin Manes <ben.manes@gmail.com>
CC: "Concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

If I remember right, ConcurrentHashMap.size() is a O(n) operation.  This means it traverses the entries in the Map.  So, instead of making 2 passes at the entries (i.e., size() and then entries equals()), it is probably cheaper to simply to just do entries equals().

I think size() is a O(n) operation because of too much contention from maintaining an atomic size.  Every put() and remove() will have to do an atomic operation on the size field.  This leads to cache contention and terrible performance.

However, my knowledge may be stale.  Perhaps, size() is now O(1).  If so, a size() precheck in equals() probably would make sense.

On Sun, Mar 13, 2022 at 4:54 PM Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    The equality contract for Map is defined as having the same mappings in their entrySet views. The AbstractMap and AbstractSet implementations include a size() prescreen, which is typically an immediate operation. The concurrent maps don't, though, and I am wondering if this is a missed opportunity. The consistency property already dictates that the comparison is deterministic only if neither object or its parts are modified between invocations. Therefore the method's documentation that equality may be misleading in the face of concurrency is simply a reminder of that fact. Since the size check might be performed regardless by an AbstractMap-based implementation (e.g. HashMap), then by symmetry it would imply that adding this prescreen would be an acceptable optimization. Does that seem reasonable or is there an aspect that I am forgetting?
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] ConcurrentHashMap and equality
From: Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-14, 05:04
To: Nathan Reynolds <numeralnathan@gmail.com>
CC: "Concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Benjamin Manes <ben.manes@gmail.com>

Thanks Nathan, I had forgotten about those details in the Java 5-7 implementations. If I recall correctly, those were O(concurrencyLevel) as the segment maintained a counter. However, some variants were more complex with retries and locking, whereas others were just a best-effort summation. The Java 8+ implementation embeds a variant of LongAdder which maintains its own array of lock-free counter cells. As the number of cells is based on the runtime cpu count, it is effectively O(1). This same approach was applied to ConcurrentSkipListMap which previously was O(n) and might be what you are recalling.

On Sun, Mar 13, 2022 at 7:47 PM Nathan Reynolds <numeralnathan@gmail.com> wrote:

    If I remember right, ConcurrentHashMap.size() is a O(n) operation.  This means it traverses the entries in the Map.  So, instead of making 2 passes at the entries (i.e., size() and then entries equals()), it is probably cheaper to simply to just do entries equals().

    I think size() is a O(n) operation because of too much contention from maintaining an atomic size.  Every put() and remove() will have to do an atomic operation on the size field.  This leads to cache contention and terrible performance.

    However, my knowledge may be stale.  Perhaps, size() is now O(1).  If so, a size() precheck in equals() probably would make sense.

    On Sun, Mar 13, 2022 at 4:54 PM Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

        The equality contract for Map is defined as having the same mappings in their entrySet views. The AbstractMap and AbstractSet implementations include a size() prescreen, which is typically an immediate operation. The concurrent maps don't, though, and I am wondering if this is a missed opportunity. The consistency property already dictates that the comparison is deterministic only if neither object or its parts are modified between invocations. Therefore the method's documentation that equality may be misleading in the face of concurrency is simply a reminder of that fact. Since the size check might be performed regardless by an AbstractMap-based implementation (e.g. HashMap), then by symmetry it would imply that adding this prescreen would be an acceptable optimization. Does that seem reasonable or is there an aspect that I am forgetting?
        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] 8 oooh ese era el ðŸ˜­ te TV etc etc r f er ðŸ˜­ fr tott ðŸ¤ž it t ðŸ˜­ you to the ðŸ¤žðŸ¤žoðŸ¤žðŸ¤žhouse ðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¤ž hou ðŸ”ª ðŸ¤žðŸ¤ž try and get to ðŸ¤ž Tory to your other tðŸ¤žy Housemate a la ðŸ”ª a y ðŸ¤žðŸ”ªðŸ¤žðŸ¤ž y try and get ðŸ¤ž a y ðŸ”ª yaðŸ”ª a ðŸ¤žðŸ˜­ðŸ¤žðŸ¤žðŸ¤žðŸ˜­ you ðŸ”ªðŸ”ª a y try yytoyyyy CopycatrecipeðŸ¤žyou ðŸ¤ž of yourðŸ”ªðŸ¤žðŸ–¤yyt note ðŸ¥³ to the you y ya ðŸ¥³ðŸ¥³ðŸ–¤ at to you and your family yyyyytðŸ¤žðŸ–¤ðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¥³ Hope you TT
From: Stephan Diestelhorst via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-14, 11:09
To: Benjamin Manes <ben.manes@gmail.com>
CC: "Concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Stephan Diestelhorst <stephan.diestelhorst@gmail.com>

Stephan Diestelhorst has sent you an email via Gmail confidential mode:

Gmail logoRe: [concurrency-interest] 8 oooh ese era el ðŸ˜­ te TV etc etc r f er ðŸ˜­ fr tott ðŸ¤ž it t ðŸ˜­ you to the ðŸ¤žðŸ¤žoðŸ¤žðŸ¤žhouse ðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¤ž hou ðŸ”ª ðŸ¤žðŸ¤ž try and get to ðŸ¤ž Tory to your other tðŸ¤žy Housemate a la ðŸ”ª a y ðŸ¤žðŸ”ªðŸ¤žðŸ¤ž y try and get ðŸ¤ž a y ðŸ”ª yaðŸ”ª a ðŸ¤žðŸ˜­ðŸ¤žðŸ¤žðŸ¤žðŸ˜­ you ðŸ”ªðŸ”ª a y try yytoyyyy CopycatrecipeðŸ¤žyou ðŸ¤ž of yourðŸ”ªðŸ¤žðŸ–¤yyt note ðŸ¥³ to the you y ya ðŸ¥³ðŸ¥³ðŸ–¤ at to you and your family yyyyytðŸ¤žðŸ–¤ðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¥³ Hope you TT

This message was sent on 14 Mar 2022 at 02:09:33 GMT-7
You can open it by clicking the link below. This link will only work for concurrency-interest@cs.oswego.edu.

View the email

Gmail confidential mode gives you more control over the messages that you send. The sender may have chosen to set an expiry time, disable printing or forwarding, or track access to this message. Learn more
Gmail: Email by Google
Use is subject to the Google Privacy Policy
Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA
You have received this message because someone sent you an email via Gmail confidential mode.
	Google logo

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] ConcurrentHashMap and equality
From: Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-19, 13:39
To: concurrency-interest@cs.oswego.edu
Reply-To: Doug Lea <dl@cs.oswego.edu>


On 3/13/22 18:51, Benjamin Manes via Concurrency-interest wrote:
> The equality contract for Map is defined as having the same mappings in their entrySet views. The AbstractMap and AbstractSet implementations include a size() prescreen, which is typically an immediate operation. The concurrent maps don't, though, and I am wondering if this is a missed opportunity. The consistency property already dictates that the comparison is deterministic only if neither object or its parts are modified between invocations. Therefore the method's documentation that equality may be misleading in the face of concurrency is simply a reminder of that fact. Since the size check might be performed regardless by an AbstractMap-based implementation (e.g. HashMap), then by symmetry it would imply that adding this prescreen would be an acceptable optimization. Does that seem reasonable or is there an aspect that I am forgetting?

This seems reasonable, but there is a tiny chance of incompatibility to make this change. The count is only quiescently accurate, and is updated after modifications. If there is a call while quiescing, then the elements may be stable before the count is. (Which was the original reason for not checking count first.) I'm not sure that the very rare possibility of a detectable difference matters, but CHM is used enough that someone might be unknowingly relying on this.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] ConcurrentHashMap and equality
From: Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-20, 13:06
To: Doug Lea <dl@cs.oswego.edu>
CC: "Concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Benjamin Manes <ben.manes@gmail.com>

It is unfortunate then that affected users might be dependent on the ordering of their equals statement due to a lack of symmetry. During quiescing the property is broken by causing CHM.equals(Map.of(a, b)) and Map.of(a, b).equals(CHM) to differ, since all non-concurrent JDK maps inherit the size() check. If unintentionally depending on this then a small refactoring would break behavior that might be hard to debug. Naively, I'd consider this an implementation detail equivalent to parsing an unspecified toString(), except less explicit in code as it is very sneaky. Of course the performance difference probably doesn't warrant making a change, but the possibility that someone might rely on this behavior is an uncomfortable consideration.

On Sat, Mar 19, 2022 at 4:40 AM Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:


    On 3/13/22 18:51, Benjamin Manes via Concurrency-interest wrote:
    > The equality contract for Map is defined as having the same mappings
    > in their entrySet views. The AbstractMap and AbstractSet
    > implementations include a size() prescreen, which is typically an
    > immediate operation. The concurrent maps don't, though, and I am
    > wondering if this is a missed opportunity. The consistency property
    > already dictates that the comparison is deterministic only if neither
    > object or its parts are modified between invocations. Therefore the
    > method's documentation that equality may be misleading in the face of
    > concurrency is simply a reminder of that fact. Since the size check
    > might be performed regardless by an AbstractMap-based implementation
    > (e.g. HashMap), then by symmetry it would imply that adding this
    > prescreen would be an acceptable optimization. Does that seem
    > reasonable or is there an aspect that I am forgetting?

    This seems reasonable, but there is a tiny chance of incompatibility to
    make this change. The count is only quiescently accurate, and is updated
    after modifications. If there is a call while quiescing, then the
    elements may be stable before the count is. (Which was the original
    reason for not checking count first.) I'm not sure that the very rare
    possibility of a detectable difference matters, but CHM is used enough
    that someone might be unknowingly relying on this.

    -Doug



    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: [concurrency-interest] ForkJoin updates
From: Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-25, 17:07
To: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Doug Lea <dl@cs.oswego.edu>

Upcoming updates for ForkJoin{Pool,Task} are mainly designed to make things better for loom (faster initialization, improved handling of async tasks, less memory and signal contention, a few nichy methods). They also include new method ForkJoinPool.setParallelism (see http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/ForkJoinPool.html) that allows dynamic changes in target parallelism. I had resisted this because of the uncertainty it adds (and internally structured code in a way that made it impossible without a lot of refactoring). But  now is the time to let go of this: Virtualized platforms now routinely give different answers at different times about available processors, and projects like crac (https://wiki.openjdk.java.net/display/crac) need to be able to dynamically update. There are no supported automated ways to do these, but allowing it makes it possible for others to explore them.

Comments and suggestions are welcome. You may be able to try these out now in jdk17+ by grabbing a jsr166.jar (http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar) and using: java --patch-module java.base="$DIR/jsr166.jar",

-Doug


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] ForkJoin updates
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-25, 17:11
To: Doug Lea <dl@cs.oswego.edu>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

I figure with Loom threads that ForkJoinPool would simply launch a new thread whenever there is work that can be done.  I am guessing that ForkJoinPool still limits threads.  Is this because ForkJoinPool is typically used for threads that don't block?

On Fri, Mar 25, 2022 at 9:09 AM Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    Upcoming updates for ForkJoin{Pool,Task} are mainly designed to make
    things better for loom (faster initialization, improved handling of
    async tasks, less memory and signal contention, a few nichy methods).
    They also include new method ForkJoinPool.setParallelism (see
    http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/ForkJoinPool.html)
    that allows dynamic changes in target parallelism. I had resisted this
    because of the uncertainty it adds (and internally structured code in a
    way that made it impossible without a lot of refactoring). But  now is
    the time to let go of this: Virtualized platforms now routinely give
    different answers at different times about available processors, and
    projects like crac (https://wiki.openjdk.java.net/display/crac) need to
    be able to dynamically update. There are no supported automated ways to
    do these, but allowing it makes it possible for others to explore them.

    Comments and suggestions are welcome. You may be able to try these out
    now in jdk17+ by grabbing a jsr166.jar
    (http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar) and using: java
    --patch-module java.base="$DIR/jsr166.jar",

    -Doug


    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] ForkJoin updates
From: Dmitry Zaslavsky via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2022-03-28, 04:33
To: Nathan Reynolds <numeralnathan@gmail.com>
CC: Doug Lea <dl@cs.oswego.edu>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Dmitry Zaslavsky <dmitry.zaslavsky@gmail.com>

FJP is still used a pool for carrier threads.
Loom/Virtual threads still need a carrier thread to execute on and FJP can/should be used for that.
As far as FJP is concerned a virtual thread is scheduled as a task.



> On Mar 25, 2022, at 11:11 AM, Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> I figure with Loom threads that ForkJoinPool would simply launch a new thread whenever there is work that can be done.  I am guessing that ForkJoinPool still limits threads.  Is this because ForkJoinPool is typically used for threads that don't block?
>
> On Fri, Mar 25, 2022 at 9:09 AM Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     Upcoming updates for ForkJoin{Pool,Task} are mainly designed to make
>     things better for loom (faster initialization, improved handling of
>     async tasks, less memory and signal contention, a few nichy methods).
>     They also include new method ForkJoinPool.setParallelism (see
>     http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/ForkJoinPool.html)
>     that allows dynamic changes in target parallelism. I had resisted this
>     because of the uncertainty it adds (and internally structured code in a
>     way that made it impossible without a lot of refactoring). But  now is
>     the time to let go of this: Virtualized platforms now routinely give
>     different answers at different times about available processors, and
>     projects like crac (https://wiki.openjdk.java.net/display/crac) need to
>     be able to dynamically update. There are no supported automated ways to
>     do these, but allowing it makes it possible for others to explore them.
>
>     Comments and suggestions are welcome. You may be able to try these out
>     now in jdk17+ by grabbing a jsr166.jar
>     (http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar) and using: java
>     --patch-module java.base="$DIR/jsr166.jar",
>
>     -Doug
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
