From peter.levart at gmail.com  Sun Sep  2 11:46:43 2018
From: peter.levart at gmail.com (Peter Levart)
Date: Sun, 2 Sep 2018 17:46:43 +0200
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
Message-ID: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>

Hello,

Recently I needed to code a completion stage that would asynchronously 
handle an exceptional completion of previous stage but in case of normal 
completion of previous stage didn't introduce another asynchronous step. 
I couldn't find a simple solution with CompletableFuture. Either of the 
following two methods were missing:

     public CompletableFuture<T> exceptionallyAsync(Function<Throwable, 
? extends T> fn)

...with an overload taking Executor. These would be the async 
counterparts of existing "exceptionaly" method.

Similar functionality could be achieved with the following method:

     public <U> CompletableFuture<U> handleCompose(BiFunction<? super T, 
Throwable, ? extends CompletionStage<U>> fn)

...which would be a combination of the following two existing methods:

     public <U> CompletableFuture<U> handle(BiFunction<? super T, 
Throwable, ? extends U> fn)
     public <U> CompletableFuture<U> thenCompose(Function<? super T, ? 
extends CompletionStage<U>> fn)


The with handleCompose method one could simulate exceptionallyAsync by 
returning a submitted but yet uncompleted CompletableFuture in case of 
exceptional completion of previous stage, while returning a completed 
CompletableFuture in case of normal completion.

The use case I'm trying to handle is using CompletionStage as a return 
type of an asynchronous web service endpoint method. The thread that 
completes the returned CF is a scarce resource (a single Kafka IO 
thread). In case of normal completion I can hand such CompletableFuture 
to web container as it dispatches the control from it to internal thread 
pool when handling the response. But in case of exceptional completion, 
I would like to employ special thread-pool to handle the exception as 
this involves additional external communication.

Currently I'm using the following trick:

someCompletableFuture

             // tunnel exception as the normal result
             .handle((result, exception) -> exception != null ? 
exception : result)

             .thenCompose(resultOrException -> {
                 if (resultOrException instanceof Throwable) {
                     return CompletableFuture.supplyAsync(() -> {
                         Throwable exc = (Throwable) resultOrException
                         // ...handle exc asynchronously...
                     });
                 } else {
                     // just pass return value synchronously
                     return CompletableFuture
                         .completedFuture((ReturnType) resultOrException);
                 }
             });


Has anyone else missed such method(s) on CompletableFuture too?

Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180902/deb3b851/attachment.html>

From alexei.kaigorodov at gmail.com  Sun Sep  2 13:41:28 2018
From: alexei.kaigorodov at gmail.com (Alexei Kaigorodov)
Date: Mon, 3 Sep 2018 00:41:28 +0700
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 163,
	Issue 1
In-Reply-To: <mailman.1.1535904002.23849.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1535904002.23849.concurrency-interest@cs.oswego.edu>
Message-ID: <CALCS1ZVFZ9Z5UKHzaSR33ekYmv6HffyRqVbZ_UMR7wShJLjtzQ@mail.gmail.com>

You can define such a function yourself:

public static CompletableFuture<ReturnType> exceptionallyAsync(
     CompletableFuture<ReturnType> cf,
     Function<Throwable, ReturnType> handleFunction,
     Executor executor
) {
    CompletableFuture<ReturnType> resFuture = new CompletableFuture<>();
    cf.whenComplete((result, exC) -> {
                if (exC != null) {
                    CompletableFuture.runAsync(() -> {
                        ReturnType valEx = handleFunction.apply(exC);
                        resFuture.complete(valEx);
                    }, executor);
                } else {
                    resFuture.complete(result);
                }
            });
    return resFuture;
}

Usage:

CompletableFuture<ReturnType> resFuture =
exceptionallyAsync(someCompletableFuture, exc->new ReturnType(exc),
ForkJoinPool.commonPool());


thanks,
Alexei


On Sun, 2 Sep 2018 at 23:01, <concurrency-interest-request at cs.oswego.edu>
wrote:

> Send Concurrency-interest mailing list submissions to
>         concurrency-interest at cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
>         concurrency-interest-request at cs.oswego.edu
>
> You can reach the person managing the list at
>         concurrency-interest-owner at cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
>
> Today's Topics:
>
>    1. CompletableFuture.exceptionallyAsync or   handleCompose
>       (Peter Levart)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 2 Sep 2018 17:46:43 +0200
> From: Peter Levart <peter.levart at gmail.com>
> To: concurrency-interest <Concurrency-interest at cs.oswego.edu>
> Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync
>         or      handleCompose
> Message-ID: <879230aa-df47-1279-d78f-cf72c41a0de9 at gmail.com>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
> Hello,
>
> Recently I needed to code a completion stage that would asynchronously
> handle an exceptional completion of previous stage but in case of normal
> completion of previous stage didn't introduce another asynchronous step.
> I couldn't find a simple solution with CompletableFuture. Either of the
> following two methods were missing:
>
>      public CompletableFuture<T> exceptionallyAsync(Function<Throwable,
> ? extends T> fn)
>
> ...with an overload taking Executor. These would be the async
> counterparts of existing "exceptionaly" method.
>
> Similar functionality could be achieved with the following method:
>
>      public <U> CompletableFuture<U> handleCompose(BiFunction<? super T,
> Throwable, ? extends CompletionStage<U>> fn)
>
> ...which would be a combination of the following two existing methods:
>
>      public <U> CompletableFuture<U> handle(BiFunction<? super T,
> Throwable, ? extends U> fn)
>      public <U> CompletableFuture<U> thenCompose(Function<? super T, ?
> extends CompletionStage<U>> fn)
>
>
> The with handleCompose method one could simulate exceptionallyAsync by
> returning a submitted but yet uncompleted CompletableFuture in case of
> exceptional completion of previous stage, while returning a completed
> CompletableFuture in case of normal completion.
>
> The use case I'm trying to handle is using CompletionStage as a return
> type of an asynchronous web service endpoint method. The thread that
> completes the returned CF is a scarce resource (a single Kafka IO
> thread). In case of normal completion I can hand such CompletableFuture
> to web container as it dispatches the control from it to internal thread
> pool when handling the response. But in case of exceptional completion,
> I would like to employ special thread-pool to handle the exception as
> this involves additional external communication.
>
> Currently I'm using the following trick:
>
> someCompletableFuture
>
>              // tunnel exception as the normal result
>              .handle((result, exception) -> exception != null ?
> exception : result)
>
>              .thenCompose(resultOrException -> {
>                  if (resultOrException instanceof Throwable) {
>                      return CompletableFuture.supplyAsync(() -> {
>                          Throwable exc = (Throwable) resultOrException
>                          // ...handle exc asynchronously...
>                      });
>                  } else {
>                      // just pass return value synchronously
>                      return CompletableFuture
>                          .completedFuture((ReturnType) resultOrException);
>                  }
>              });
>
>
> Has anyone else missed such method(s) on CompletableFuture too?
>
> Regards, Peter
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180902/deb3b851/attachment-0001.html
> >
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> ------------------------------
>
> End of Concurrency-interest Digest, Vol 163, Issue 1
> ****************************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/17782b57/attachment.html>

From chris.hegarty at oracle.com  Mon Sep  3 07:13:17 2018
From: chris.hegarty at oracle.com (Chris Hegarty)
Date: Mon, 3 Sep 2018 12:13:17 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
Message-ID: <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>


On 02/09/18 16:46, Peter Levart via Concurrency-interest wrote:
> ...
> Has anyone else missed such method(s) on CompletableFuture too?

Similar, but not quite the same: "CompletionStage.exceptionallyCompose"

 
http://cs.oswego.edu/pipermail/concurrency-interest/2018-March/016340.html

-Chris.

From dl at cs.oswego.edu  Mon Sep  3 07:42:15 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 3 Sep 2018 07:42:15 -0400
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
Message-ID: <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>

On 09/03/2018 07:13 AM, Chris Hegarty via Concurrency-interest wrote:
> 
> On 02/09/18 16:46, Peter Levart via Concurrency-interest wrote:
>> ...
>> Has anyone else missed such method(s) on CompletableFuture too?
> 
> Similar, but not quite the same: "CompletionStage.exceptionallyCompose"
> 
> 
> http://cs.oswego.edu/pipermail/concurrency-interest/2018-March/016340.html
> 

Yes, the last time we discussed related issues, we were left stalled in
indecision. Adding exceptionallyCompose seems to be the best single
method to add, but still might not cover enough cases that arise in
practice; for example those that inspect the exception type, and
different async usages.

On the one hand, people can write their own methods for such cases using
whenComplete and/or handle. On the other hand, the constructions are not
at all obvious, and cannot easily be written in a way that allows them
to be used in fluent style. Any further thoughts would be welcome.

-Doug



From martinrb at google.com  Mon Sep  3 11:48:42 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 3 Sep 2018 08:48:42 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
Message-ID: <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>

On Mon, Sep 3, 2018 at 4:42 AM, Doug Lea via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

>
> On the one hand, people can write their own methods for such cases using
> whenComplete and/or handle. On the other hand, the constructions are not
> at all obvious, and cannot easily be written in a way that allows them
> to be used in fluent style. Any further thoughts would be welcome.
>

People keep looking at the methods in CompletableFuture and rediscovering
the 2 missing exceptionallyAsync methods.  And there's no hint in the
sources as to why they were omitted (even I don't know - I've probably
forgotten).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/7a23e2c2/attachment-0001.html>

From blake.meike at gmail.com  Mon Sep  3 11:55:18 2018
From: blake.meike at gmail.com (G. Blake Meike)
Date: Mon, 3 Sep 2018 08:55:18 -0700
Subject: [concurrency-interest] Double-check locking
Message-ID: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>

I beg your indulgence: I realize that this post is quite off-topic.  It is, none the less, something that I think that people on this list might find of interest:

I’ve done some empirical testing of the behaviors of a couple of lazy initialization idioms. While this experiment is entirely on an Android runtime, I would be interested in re-running it on a JVM.

https://medium.com/@blake.meike/fast-locking-in-android-with-kotlin-5de656351563

-blake


From martinrb at google.com  Mon Sep  3 12:07:10 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 3 Sep 2018 09:07:10 -0700
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 163,
 Issue 1
In-Reply-To: <CALCS1ZVFZ9Z5UKHzaSR33ekYmv6HffyRqVbZ_UMR7wShJLjtzQ@mail.gmail.com>
References: <mailman.1.1535904002.23849.concurrency-interest@cs.oswego.edu>
 <CALCS1ZVFZ9Z5UKHzaSR33ekYmv6HffyRqVbZ_UMR7wShJLjtzQ@mail.gmail.com>
Message-ID: <CA+kOe08CTnPEshQnF_NOk_+AscyagtSk3ixYRoeE34PEs+avCw@mail.gmail.com>

A production-quality version of exceptionallyAsync would have more error
handling for the cases where runAsync or handleFunction threw, creating
typically messy method bodies - a good reason for why exceptionallyAsync
should be provided by CompletableFuture.

On Sun, Sep 2, 2018 at 10:41 AM, Alexei Kaigorodov via Concurrency-interest
<concurrency-interest at cs.oswego.edu> wrote:

> You can define such a function yourself:
>
> public static CompletableFuture<ReturnType> exceptionallyAsync(
>      CompletableFuture<ReturnType> cf,
>      Function<Throwable, ReturnType> handleFunction,
>      Executor executor
> ) {
>     CompletableFuture<ReturnType> resFuture = new CompletableFuture<>();
>     cf.whenComplete((result, exC) -> {
>                 if (exC != null) {
>                     CompletableFuture.runAsync(() -> {
>                         ReturnType valEx = handleFunction.apply(exC);
>                         resFuture.complete(valEx);
>                     }, executor);
>                 } else {
>                     resFuture.complete(result);
>                 }
>             });
>     return resFuture;
> }
>
> Usage:
>
> CompletableFuture<ReturnType> resFuture = exceptionallyAsync(someCompletableFuture, exc->new ReturnType(exc), ForkJoinPool.commonPool());
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/3b7e1057/attachment.html>

From Sebastian.Millies at softwareag.com  Mon Sep  3 15:03:53 2018
From: Sebastian.Millies at softwareag.com (Millies, Sebastian)
Date: Mon, 3 Sep 2018 19:03:53 +0000
Subject: [concurrency-interest] Double-check locking
Message-ID: <32F15738E8E5524DA4F01A0FA4A8E4900156FE137C@daeexmbx1.eur.ad.sag>

I'd be interested as well, especially in the Spin lock performance in Java. According to Aleksey Shipilev's well-known article
https://shipilev.net/blog/2014/safe-public-construction/
the  SafeDCLFactory performs best on x64 and ARMv7, but the article, although it mentions "exchanging the reference ... via the AtomicX classes"
actually does not contain a comparison with the Spin lock method. I guess the Java code would go like this:

private final AtomicReference<T> instance = new AtomicReference<>();

public T getInstance(Supplier<T> s) {
  while (true) {
    T v1 = instance.get();
    if (v1 != null) {
      return v1;
    }
    T v2 = s.get();
    if (instance.compareAndSet(null, v2)) {
      return v2;
    }
  }
}

(Aside: For the purpose of producing a singleton, I like this API (with the object factory  as a parameter to the getInstance() method) better than
spending another reference to hold the Supplier in a member.)

-- Sebastian

-----Original Message-----
From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of G. Blake Meike via Concurrency-interest
Sent: Monday, September 03, 2018 5:55 PM
To: concurrency-interest at cs.oswego.edu
Subject: [Spam]: [concurrency-interest] Double-check locking

I beg your indulgence: I realize that this post is quite off-topic.  It is, none the less, something that I think that people on this list might find of interest:

I’ve done some empirical testing of the behaviors of a couple of lazy initialization idioms. While this experiment is entirely on an Android runtime, I would be interested in re-running it on a JVM.

https://medium.com/@blake.meike/fast-locking-in-android-with-kotlin-5de656351563

-blake

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

Software AG – Sitz/Registered office: Uhlandstraße 12, 64297 Darmstadt, Germany – Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Sanjay Brahmawar (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt, Dr. Stefan Sigg; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com


From oleksandr.otenko at gmail.com  Mon Sep  3 18:18:26 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 3 Sep 2018 23:18:26 +0100
Subject: [concurrency-interest] Double-check locking
In-Reply-To: <32F15738E8E5524DA4F01A0FA4A8E4900156FE137C@daeexmbx1.eur.ad.sag>
References: <32F15738E8E5524DA4F01A0FA4A8E4900156FE137C@daeexmbx1.eur.ad.sag>
Message-ID: <D4B2F32D-DC87-495C-90AC-9CC1A1649D46@gmail.com>

Do you save anything by having a conditional?

It should work:

public T getInstance(Supplier<T> s) {
  T v1 = instance.get();
  if (v1 != null) return v1;
  instance.compareAndSet(null, s.get());
  return instance.get();
}

On the surface of it, you get an unnecessary read on a successful compareAndSet, but is that slower than a condition check?

Alex

> On 3 Sep 2018, at 20:03, Millies, Sebastian via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> I'd be interested as well, especially in the Spin lock performance in Java. According to Aleksey Shipilev's well-known article
> https://shipilev.net/blog/2014/safe-public-construction/
> the  SafeDCLFactory performs best on x64 and ARMv7, but the article, although it mentions "exchanging the reference ... via the AtomicX classes"
> actually does not contain a comparison with the Spin lock method. I guess the Java code would go like this:
> 
> private final AtomicReference<T> instance = new AtomicReference<>();
> 
> public T getInstance(Supplier<T> s) {
>  while (true) {
>    T v1 = instance.get();
>    if (v1 != null) {
>      return v1;
>    }
>    T v2 = s.get();
>    if (instance.compareAndSet(null, v2)) {
>      return v2;
>    }
>  }
> }
> 
> (Aside: For the purpose of producing a singleton, I like this API (with the object factory  as a parameter to the getInstance() method) better than
> spending another reference to hold the Supplier in a member.)
> 
> -- Sebastian
> 
> -----Original Message-----
> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of G. Blake Meike via Concurrency-interest
> Sent: Monday, September 03, 2018 5:55 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [Spam]: [concurrency-interest] Double-check locking
> 
> I beg your indulgence: I realize that this post is quite off-topic.  It is, none the less, something that I think that people on this list might find of interest:
> 
> I’ve done some empirical testing of the behaviors of a couple of lazy initialization idioms. While this experiment is entirely on an Android runtime, I would be interested in re-running it on a JVM.
> 
> https://medium.com/@blake.meike/fast-locking-in-android-with-kotlin-5de656351563
> 
> -blake
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> Software AG – Sitz/Registered office: Uhlandstraße 12, 64297 Darmstadt, Germany – Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Sanjay Brahmawar (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt, Dr. Stefan Sigg; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From martinrb at google.com  Mon Sep  3 19:12:36 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 3 Sep 2018 16:12:36 -0700
Subject: [concurrency-interest] Double-check locking
In-Reply-To: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
References: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
Message-ID: <CA+kOe09bkQ=9FtowD6rbAOGy9u8NfzbEe+7R+LWcfMujD_gtHg@mail.gmail.com>

This looks like a copy-paste typo:

      if (v1 === newVal) {
        return v2
      }

... which looks like a trick preparing us to buy some Kotlin-style
syntactic sugar:


class DoubleCheckedLocking () {
    @Volatile private var field : Int? = null

    private final val lock = Object()

    fun lazyGet() : Int = field ?:
        synchronized (lock) { field ?: computeValue().also { field = it } }

    fun computeValue() : Int { return 42 }
}

fun main(args: Array<String>) {
     DoubleCheckedLocking().let {
        println(it.lazyGet())
        println(it.lazyGet())
    }


very concise, but still rather tricky (trickier? than plain java)


On Mon, Sep 3, 2018 at 8:55 AM, G. Blake Meike via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> I beg your indulgence: I realize that this post is quite off-topic.  It
> is, none the less, something that I think that people on this list might
> find of interest:
>
> I’ve done some empirical testing of the behaviors of a couple of lazy
> initialization idioms. While this experiment is entirely on an Android
> runtime, I would be interested in re-running it on a JVM.
>
> https://medium.com/@blake.meike/fast-locking-in-android-
> with-kotlin-5de656351563
>
> -blake
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/3b779829/attachment.html>

From martinrb at google.com  Mon Sep  3 19:20:38 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 3 Sep 2018 16:20:38 -0700
Subject: [concurrency-interest] Double-check locking
In-Reply-To: <CA+kOe09bkQ=9FtowD6rbAOGy9u8NfzbEe+7R+LWcfMujD_gtHg@mail.gmail.com>
References: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
 <CA+kOe09bkQ=9FtowD6rbAOGy9u8NfzbEe+7R+LWcfMujD_gtHg@mail.gmail.com>
Message-ID: <CA+kOe0_UZrsTN+zy_bbVj5KcAPdTPs+F-S+p6NyYAFE-riin0w@mail.gmail.com>

What is testAndSet?

Did you read
https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java
The Internet Elves have recently updated it.
Should you add a Kotlin section?

Why haven't the Kotlin folk added even sweeter syntactic sugar to
lazy-once-init a field?


On Mon, Sep 3, 2018 at 4:12 PM, Martin Buchholz <martinrb at google.com> wrote:

> This looks like a copy-paste typo:
>
>       if (v1 === newVal) {
>         return v2
>       }
>
> ... which looks like a trick preparing us to buy some Kotlin-style
> syntactic sugar:
>
>
> class DoubleCheckedLocking () {
>     @Volatile private var field : Int? = null
>
>     private final val lock = Object()
>
>     fun lazyGet() : Int = field ?:
>         synchronized (lock) { field ?: computeValue().also { field = it } }
>
>     fun computeValue() : Int { return 42 }
> }
>
> fun main(args: Array<String>) {
>      DoubleCheckedLocking().let {
>         println(it.lazyGet())
>         println(it.lazyGet())
>     }
>
>
> very concise, but still rather tricky (trickier? than plain java)
>
>
> On Mon, Sep 3, 2018 at 8:55 AM, G. Blake Meike via Concurrency-interest <
> concurrency-interest at cs.oswego.edu> wrote:
>
>> I beg your indulgence: I realize that this post is quite off-topic.  It
>> is, none the less, something that I think that people on this list might
>> find of interest:
>>
>> I’ve done some empirical testing of the behaviors of a couple of lazy
>> initialization idioms. While this experiment is entirely on an Android
>> runtime, I would be interested in re-running it on a JVM.
>>
>> https://medium.com/@blake.meike/fast-locking-in-android-with
>> -kotlin-5de656351563
>>
>> -blake
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/92ebb732/attachment-0001.html>

From blake.meike at gmail.com  Mon Sep  3 20:19:13 2018
From: blake.meike at gmail.com (G. Blake Meike)
Date: Mon, 3 Sep 2018 17:19:13 -0700
Subject: [concurrency-interest] Double-check locking
In-Reply-To: <CA+kOe0_UZrsTN+zy_bbVj5KcAPdTPs+F-S+p6NyYAFE-riin0w@mail.gmail.com>
References: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
 <CA+kOe09bkQ=9FtowD6rbAOGy9u8NfzbEe+7R+LWcfMujD_gtHg@mail.gmail.com>
 <CA+kOe0_UZrsTN+zy_bbVj5KcAPdTPs+F-S+p6NyYAFE-riin0w@mail.gmail.com>
Message-ID: <AAD6FFB4-FD5C-4AA8-9D4B-E6BCD2901B36@gmail.com>


On Sep 3, 2018, at 16:12, Martin Buchholz <martinrb at google.com> wrote:

> This looks like a copy-paste typo:
> 
>       if (v1 === newVal) {
>         return v2
>       }

It is.

> On Sep 3, 2018, at 16:20, Martin Buchholz <martinrb at google.com> wrote:
> 
> What is testAndSet?

Jebuz, Martin.  I cannot believe neither I nor any of the other people that read this, have noticed either of those two glaring bugs in the text.  I certainly owe you a beer.

> Did you read
> https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java
> The Internet Elves have recently updated it.
> Should you add a Kotlin section?

Yes.  Will do.  Thanks.

-blake

From martinrb at google.com  Mon Sep  3 22:05:57 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 3 Sep 2018 19:05:57 -0700
Subject: [concurrency-interest] Double-check locking
In-Reply-To: <AAD6FFB4-FD5C-4AA8-9D4B-E6BCD2901B36@gmail.com>
References: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
 <CA+kOe09bkQ=9FtowD6rbAOGy9u8NfzbEe+7R+LWcfMujD_gtHg@mail.gmail.com>
 <CA+kOe0_UZrsTN+zy_bbVj5KcAPdTPs+F-S+p6NyYAFE-riin0w@mail.gmail.com>
 <AAD6FFB4-FD5C-4AA8-9D4B-E6BCD2901B36@gmail.com>
Message-ID: <CA+kOe08Ksx27fa4RYXRnp96VeeWSQsWa7e5izKhZ=O0oKmeQpA@mail.gmail.com>

It's a pet peeve of mine when double checked locking code reads the
volatile field more times than necessary.  The programmer should introduce
locals (unless they're lucky enough to be programming in kotlin).  (Fix
DoubleCheckedProvider)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/601915a2/attachment.html>

From notcarl at google.com  Mon Sep  3 22:09:28 2018
From: notcarl at google.com (Carl Mastrangelo)
Date: Mon, 3 Sep 2018 19:09:28 -0700
Subject: [concurrency-interest] Double-check locking
In-Reply-To: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
References: <F1419AE2-7A3C-4E93-BE28-F684166F5A50@gmail.com>
Message-ID: <CAAcqB+vLreutbo9ZaMNHWGUDrkLZMS9WOupmJ5dN4w3h9FZjOQ@mail.gmail.com>

Your section labelled "Spin Test"  is not quite lazy (I didn't read the
whole article, but I didn't see mention of it.)   For example, if the line:

val v2 = provider.get()

has side effects (such as initiating a database connection, or opening a
file), then you could still have two threads succeed.


On Mon, Sep 3, 2018 at 9:02 AM G. Blake Meike via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> I beg your indulgence: I realize that this post is quite off-topic.  It
> is, none the less, something that I think that people on this list might
> find of interest:
>
> I’ve done some empirical testing of the behaviors of a couple of lazy
> initialization idioms. While this experiment is entirely on an Android
> runtime, I would be interested in re-running it on a JVM.
>
>
> https://medium.com/@blake.meike/fast-locking-in-android-with-kotlin-5de656351563
>
> -blake
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180903/f5c53719/attachment.html>

From leventov.ru at gmail.com  Wed Sep 12 06:08:26 2018
From: leventov.ru at gmail.com (Roman Leventov)
Date: Wed, 12 Sep 2018 13:08:26 +0300
Subject: [concurrency-interest] Write barrier in ArrayList.grow()
Message-ID: <CAAMLo=bMsO-KE+aOszPWyJO2hDGuw5=k6sk4egaZU8atTretnw@mail.gmail.com>

Why wouldn't ArrayList add a write barrier in it's grow() method between
the new elementData array population and the assignment of the elementData
field? It would cost almost nothing, but exclude an important class of
races, when one thread adds elements into an ArrayList, and other threads
read elements at small indexes.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180912/124955f2/attachment.html>

From oleksandr.otenko at gmail.com  Wed Sep 12 06:16:25 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Wed, 12 Sep 2018 11:16:25 +0100
Subject: [concurrency-interest] Write barrier in ArrayList.grow()
In-Reply-To: <CAAMLo=bMsO-KE+aOszPWyJO2hDGuw5=k6sk4egaZU8atTretnw@mail.gmail.com>
References: <CAAMLo=bMsO-KE+aOszPWyJO2hDGuw5=k6sk4egaZU8atTretnw@mail.gmail.com>
Message-ID: <243CA47F-7091-42A2-8805-5AB79A6E63BA@gmail.com>

Because a write barrier means nothing without a read barrier (which would need doing always). Then need a specification of which read synchronizes-with which write.


Alex

> On 12 Sep 2018, at 11:08, Roman Leventov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> Why wouldn't ArrayList add a write barrier in it's grow() method between the new elementData array population and the assignment of the elementData field? It would cost almost nothing, but exclude an important class of races, when one thread adds elements into an ArrayList, and other threads read elements at small indexes.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From leventov.ru at gmail.com  Wed Sep 12 06:27:23 2018
From: leventov.ru at gmail.com (Roman Leventov)
Date: Wed, 12 Sep 2018 13:27:23 +0300
Subject: [concurrency-interest] Write barrier in ArrayList.grow()
In-Reply-To: <243CA47F-7091-42A2-8805-5AB79A6E63BA@gmail.com>
References: <CAAMLo=bMsO-KE+aOszPWyJO2hDGuw5=k6sk4egaZU8atTretnw@mail.gmail.com>
 <243CA47F-7091-42A2-8805-5AB79A6E63BA@gmail.com>
Message-ID: <CAAMLo=bj2hYs=69aJMF3r9dDtQN9q8e+EgKxS4AFh=jB5gJ2OA@mail.gmail.com>

I don't understand, why read barriers are needed there? Constructors of
classes with final fields don't require it, as far as I know. What I talk
about, equivalently, is Arrays.copyOf() having safe publication semantics.

On Wed, 12 Sep 2018, 13:16 Alex Otenko, <oleksandr.otenko at gmail.com> wrote:

> Because a write barrier means nothing without a read barrier (which would
> need doing always). Then need a specification of which read
> synchronizes-with which write.
>
>
> Alex
>
> > On 12 Sep 2018, at 11:08, Roman Leventov via Concurrency-interest <
> concurrency-interest at cs.oswego.edu> wrote:
> >
> > Why wouldn't ArrayList add a write barrier in it's grow() method between
> the new elementData array population and the assignment of the elementData
> field? It would cost almost nothing, but exclude an important class of
> races, when one thread adds elements into an ArrayList, and other threads
> read elements at small indexes.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180912/8d4395dd/attachment.html>

From dl at cs.oswego.edu  Mon Sep 17 12:06:02 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 17 Sep 2018 12:06:02 -0400
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
Message-ID: <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>

On 09/03/2018 11:48 AM, Martin Buchholz wrote:
> People keep looking at the methods in CompletableFuture and
> rediscovering the 2 missing exceptionallyAsync methods. 
I added methods to cover all variants of exceptionally{Compose}{Async}:

 exceptionally(Function<Throwable, ? extends T> f) // already exists
 exceptionallyAsync(Function<Throwable, ? extends T> f);
 exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
 exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>> f);
 exceptionallyComposeAsync(Function<Throwable, ? extends
CompletionStage<T>> f);
 exceptionallyComposeAsync(Function<Throwable, ? extends
CompletionStage<T>> f, Executor e);

These target the next jdk release (12; too late for 11). For javadocs,
see
http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html

These are all declared in the CompletionStage interface. They are
directly implemented in CompletableFuture. They are default-implemented
in CompletionStage in terms of toCompletableFuture, because a concrete
CompletionStage instance is required. If some  CompletionStage
implementation class chooses not to implement toCompletableFuture to
actually return one, and also chooses not to implement these new
methods, the default implementation will fail. However, this is
presumably what anyone designing such an implementation would want.

Comments welcome as always.

-Doug

From martinrb at google.com  Mon Sep 17 14:48:14 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 17 Sep 2018 11:48:14 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
Message-ID: <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>

We don't have any infrastructure for testing default methods on
CompletionStage - all concrete tests are for CompletableFuture.  But,
you say, those methods do nothing but delegate ...

Since exceptionally is less general than handle, It seems possible to
implement the former in terms of the latter, without
toCompletableFuture getting in the way, but I haven't tried it.  (That
is, can exceptionally be implemented as a pure convenience method?)
But then we'd have to test it.

On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
<concurrency-interest at cs.oswego.edu> wrote:
> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>> People keep looking at the methods in CompletableFuture and
>> rediscovering the 2 missing exceptionallyAsync methods.
> I added methods to cover all variants of exceptionally{Compose}{Async}:
>
>  exceptionally(Function<Throwable, ? extends T> f) // already exists
>  exceptionallyAsync(Function<Throwable, ? extends T> f);
>  exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>  exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>> f);
>  exceptionallyComposeAsync(Function<Throwable, ? extends
> CompletionStage<T>> f);
>  exceptionallyComposeAsync(Function<Throwable, ? extends
> CompletionStage<T>> f, Executor e);
>
> These target the next jdk release (12; too late for 11). For javadocs,
> see
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>
> These are all declared in the CompletionStage interface. They are
> directly implemented in CompletableFuture. They are default-implemented
> in CompletionStage in terms of toCompletableFuture, because a concrete
> CompletionStage instance is required. If some  CompletionStage
> implementation class chooses not to implement toCompletableFuture to
> actually return one, and also chooses not to implement these new
> methods, the default implementation will fail. However, this is
> presumably what anyone designing such an implementation would want.
>
> Comments welcome as always.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From martinrb at google.com  Mon Sep 17 21:42:19 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 17 Sep 2018 18:42:19 -0700
Subject: [concurrency-interest] Sleep time consistency compared to
	System.currentTimeMillis
In-Reply-To: <CAAcqB+tyMpCsAsNYAhtz=kdMj4Nymc==d4hyP5k44WSgp5vaag@mail.gmail.com>
References: <ffbde00d-268c-7ff5-ab1a-cd2499cadd36@freigmbh.de>
 <0593feb8-924f-9e99-dc0e-a31ced2370a0@cs.oswego.edu>
 <b1e44afb-59a2-5fc1-181c-b13b08c03021@freigmbh.de>
 <CACLL95oU9=dfQ2isB14u8r9EuC7ug0qjxJEJVE9rSa4Ad4D_KQ@mail.gmail.com>
 <CA+kOe0-1CLPK9bYfbSGvw3VzgZ6m1NzD2v5yGP9rY9oWnOzYQg@mail.gmail.com>
 <CAAcqB+tyMpCsAsNYAhtz=kdMj4Nymc==d4hyP5k44WSgp5vaag@mail.gmail.com>
Message-ID: <CA+kOe0-HbsZGaGgGJEOvLGYMBK2b8unax1tUOL-PgO+AZi=gYA@mail.gmail.com>

https://bugs.openjdk.java.net/browse/JDK-8210004
http://hg.openjdk.java.net/jdk/jdk/rev/13d6be5fbfa5

On Mon, Aug 27, 2018 at 10:23 AM, Carl Mastrangelo <notcarl at google.com> wrote:
> That's good to hear it was a bug.  I had asked about in on Stack Overflow* a
> while ago, and no one seemed to recognize it should be fixed.
>
>
> *
> https://stackoverflow.com/questions/42544387/why-does-thread-join-use-currenttimemillis
>
> On Mon, Aug 27, 2018 at 7:06 AM Martin Buchholz via Concurrency-interest
> <concurrency-interest at cs.oswego.edu> wrote:
>>
>> Thread.jjoin(long) should be fixed to use nanoTime instead of
>> currentTimeMillis.
>>
>> Thread.wait's spec should be fixed to remove the "more or less" (although
>> spurious wakeup remains possible).
>>
>> Thread.sleep should be fixed to not wake up early due to rounding of nanos
>> (as Object.wait was fixed).
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From peter.levart at gmail.com  Tue Sep 18 12:06:29 2018
From: peter.levart at gmail.com (Peter Levart)
Date: Tue, 18 Sep 2018 18:06:29 +0200
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
Message-ID: <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>

Hi Martin,

On 09/17/2018 08:48 PM, Martin Buchholz via Concurrency-interest wrote:
> We don't have any infrastructure for testing default methods on
> CompletionStage - all concrete tests are for CompletableFuture.  But,
> you say, those methods do nothing but delegate ...
>
> Since exceptionally is less general than handle, It seems possible to
> implement the former in terms of the latter, without
> toCompletableFuture getting in the way, but I haven't tried it.  (That
> is, can exceptionally be implemented as a pure convenience method?)
> But then we'd have to test it.

The problem with handle[Async] is that you choose synchronous vs. 
asynchronous variant regardless of the type of completion of previous 
stage (normal vs. exceptional). So you can't implement 
exceptionallyAsync exactly with handleAsync. If you simply do:

default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? 
extends T> function) {
     return handleAsync((result, exception) -> {
         if (exception != null) {
             return function.apply(exception);
         } else {
             return result;
         }
     });
}

...then you have introduced an asynchronous stage even for normal 
completion of previous stage. You may not want to usually do that as 
this introduces latency to normal path.

Regards, Peter

>
> On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
> <concurrency-interest at cs.oswego.edu> wrote:
>> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>>> People keep looking at the methods in CompletableFuture and
>>> rediscovering the 2 missing exceptionallyAsync methods.
>> I added methods to cover all variants of exceptionally{Compose}{Async}:
>>
>>   exceptionally(Function<Throwable, ? extends T> f) // already exists
>>   exceptionallyAsync(Function<Throwable, ? extends T> f);
>>   exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>>   exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>> f);
>>   exceptionallyComposeAsync(Function<Throwable, ? extends
>> CompletionStage<T>> f);
>>   exceptionallyComposeAsync(Function<Throwable, ? extends
>> CompletionStage<T>> f, Executor e);
>>
>> These target the next jdk release (12; too late for 11). For javadocs,
>> see
>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>>
>> These are all declared in the CompletionStage interface. They are
>> directly implemented in CompletableFuture. They are default-implemented
>> in CompletionStage in terms of toCompletableFuture, because a concrete
>> CompletionStage instance is required. If some  CompletionStage
>> implementation class chooses not to implement toCompletableFuture to
>> actually return one, and also chooses not to implement these new
>> methods, the default implementation will fail. However, this is
>> presumably what anyone designing such an implementation would want.
>>
>> Comments welcome as always.
>>
>> -Doug
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From martinrb at google.com  Tue Sep 18 13:27:58 2018
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 18 Sep 2018 10:27:58 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
Message-ID: <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>

Thanks, Peter, I see your point.  Maybe the unconditional async is a
lesser evil than calling toCompletableFuture (all serious
implementations of CompletionStage will override).

Maybe a missing piece of low-level infrastructure is something that
combines handle and compose

return handleCompose((r, ex) -> (ex == null) ? this :
this.handleAsync((r, ex) -> fn.apply(ex))

Is there a monad theorist in the audience?

On Tue, Sep 18, 2018 at 9:06 AM, Peter Levart <peter.levart at gmail.com> wrote:
> Hi Martin,
>
> On 09/17/2018 08:48 PM, Martin Buchholz via Concurrency-interest wrote:
>>
>> We don't have any infrastructure for testing default methods on
>> CompletionStage - all concrete tests are for CompletableFuture.  But,
>> you say, those methods do nothing but delegate ...
>>
>> Since exceptionally is less general than handle, It seems possible to
>> implement the former in terms of the latter, without
>> toCompletableFuture getting in the way, but I haven't tried it.  (That
>> is, can exceptionally be implemented as a pure convenience method?)
>> But then we'd have to test it.
>
>
> The problem with handle[Async] is that you choose synchronous vs.
> asynchronous variant regardless of the type of completion of previous stage
> (normal vs. exceptional). So you can't implement exceptionallyAsync exactly
> with handleAsync. If you simply do:
>
> default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? extends
> T> function) {
>     return handleAsync((result, exception) -> {
>         if (exception != null) {
>             return function.apply(exception);
>         } else {
>             return result;
>         }
>     });
> }
>
> ...then you have introduced an asynchronous stage even for normal completion
> of previous stage. You may not want to usually do that as this introduces
> latency to normal path.
>
> Regards, Peter
>
>
>>
>> On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
>> <concurrency-interest at cs.oswego.edu> wrote:
>>>
>>> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>>>>
>>>> People keep looking at the methods in CompletableFuture and
>>>> rediscovering the 2 missing exceptionallyAsync methods.
>>>
>>> I added methods to cover all variants of exceptionally{Compose}{Async}:
>>>
>>>   exceptionally(Function<Throwable, ? extends T> f) // already exists
>>>   exceptionallyAsync(Function<Throwable, ? extends T> f);
>>>   exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>>>   exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>>
>>> f);
>>>   exceptionallyComposeAsync(Function<Throwable, ? extends
>>> CompletionStage<T>> f);
>>>   exceptionallyComposeAsync(Function<Throwable, ? extends
>>> CompletionStage<T>> f, Executor e);
>>>
>>> These target the next jdk release (12; too late for 11). For javadocs,
>>> see
>>>
>>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>>>
>>> These are all declared in the CompletionStage interface. They are
>>> directly implemented in CompletableFuture. They are default-implemented
>>> in CompletionStage in terms of toCompletableFuture, because a concrete
>>> CompletionStage instance is required. If some  CompletionStage
>>> implementation class chooses not to implement toCompletableFuture to
>>> actually return one, and also chooses not to implement these new
>>> methods, the default implementation will fail. However, this is
>>> presumably what anyone designing such an implementation would want.
>>>
>>> Comments welcome as always.
>>>
>>> -Doug
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From oleksandr.otenko at gmail.com  Tue Sep 18 17:31:16 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 18 Sep 2018 22:31:16 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
Message-ID: <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>

  public static <T> CompletionStage<? extends T> exceptionallyAsync(CompletionStage<T> cs, Function<Throwable, ? extends T> fn) {
    return cs.handle((r, e) -> e == null ?
                                  cs:
                                  cs.handleAsync((_r, ex) -> fn.apply(ex))
                    ).thenCompose(r -> r);
  }

Alex


> On 18 Sep 2018, at 18:27, Martin Buchholz via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> Thanks, Peter, I see your point.  Maybe the unconditional async is a
> lesser evil than calling toCompletableFuture (all serious
> implementations of CompletionStage will override).
> 
> Maybe a missing piece of low-level infrastructure is something that
> combines handle and compose
> 
> return handleCompose((r, ex) -> (ex == null) ? this :
> this.handleAsync((r, ex) -> fn.apply(ex))
> 
> Is there a monad theorist in the audience?
> 
> On Tue, Sep 18, 2018 at 9:06 AM, Peter Levart <peter.levart at gmail.com> wrote:
>> Hi Martin,
>> 
>> On 09/17/2018 08:48 PM, Martin Buchholz via Concurrency-interest wrote:
>>> 
>>> We don't have any infrastructure for testing default methods on
>>> CompletionStage - all concrete tests are for CompletableFuture.  But,
>>> you say, those methods do nothing but delegate ...
>>> 
>>> Since exceptionally is less general than handle, It seems possible to
>>> implement the former in terms of the latter, without
>>> toCompletableFuture getting in the way, but I haven't tried it.  (That
>>> is, can exceptionally be implemented as a pure convenience method?)
>>> But then we'd have to test it.
>> 
>> 
>> The problem with handle[Async] is that you choose synchronous vs.
>> asynchronous variant regardless of the type of completion of previous stage
>> (normal vs. exceptional). So you can't implement exceptionallyAsync exactly
>> with handleAsync. If you simply do:
>> 
>> default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? extends
>> T> function) {
>>    return handleAsync((result, exception) -> {
>>        if (exception != null) {
>>            return function.apply(exception);
>>        } else {
>>            return result;
>>        }
>>    });
>> }
>> 
>> ...then you have introduced an asynchronous stage even for normal completion
>> of previous stage. You may not want to usually do that as this introduces
>> latency to normal path.
>> 
>> Regards, Peter
>> 
>> 
>>> 
>>> On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
>>> <concurrency-interest at cs.oswego.edu> wrote:
>>>> 
>>>> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>>>>> 
>>>>> People keep looking at the methods in CompletableFuture and
>>>>> rediscovering the 2 missing exceptionallyAsync methods.
>>>> 
>>>> I added methods to cover all variants of exceptionally{Compose}{Async}:
>>>> 
>>>>  exceptionally(Function<Throwable, ? extends T> f) // already exists
>>>>  exceptionallyAsync(Function<Throwable, ? extends T> f);
>>>>  exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>>>>  exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>>
>>>> f);
>>>>  exceptionallyComposeAsync(Function<Throwable, ? extends
>>>> CompletionStage<T>> f);
>>>>  exceptionallyComposeAsync(Function<Throwable, ? extends
>>>> CompletionStage<T>> f, Executor e);
>>>> 
>>>> These target the next jdk release (12; too late for 11). For javadocs,
>>>> see
>>>> 
>>>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>>>> 
>>>> These are all declared in the CompletionStage interface. They are
>>>> directly implemented in CompletableFuture. They are default-implemented
>>>> in CompletionStage in terms of toCompletableFuture, because a concrete
>>>> CompletionStage instance is required. If some  CompletionStage
>>>> implementation class chooses not to implement toCompletableFuture to
>>>> actually return one, and also chooses not to implement these new
>>>> methods, the default implementation will fail. However, this is
>>>> presumably what anyone designing such an implementation would want.
>>>> 
>>>> Comments welcome as always.
>>>> 
>>>> -Doug
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180918/9abfa97e/attachment-0001.html>

From martinrb at google.com  Tue Sep 18 19:45:13 2018
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 18 Sep 2018 16:45:13 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
Message-ID: <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>

Alex: Thanks for being  our official monad theorist.  To port that to
CompletableFuture without @SuppressWarnings, I came up with:

    public CompletableFuture<T> exceptionallyAsync(
        Function<Throwable, ? extends T> fn) {
        return handle(
            (r, ex) -> (ex == null)
            ? this
            : handleAsync((r1, ex1) -> { T t = fn.apply(ex1); return t; }))
            .thenCompose(stage -> stage);
    }

which can be reused without changes for the CompletionStage version

    public default CompletionStage<T> exceptionallyAsync
        (Function<Throwable, ? extends T> fn) {
        return handle(
            (r, ex) -> (ex == null)
            ? this
            : handleAsync((r1, ex1) -> { T t = fn.apply(ex1); return t; }))
            .thenCompose(stage -> stage);


On Tue, Sep 18, 2018 at 2:31 PM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>   public static <T> CompletionStage<? extends T>
> exceptionallyAsync(CompletionStage<T> cs, Function<Throwable, ? extends T>
> fn) {
>     return cs.handle((r, e) -> e == null ?
>                                   cs:
>                                   cs.handleAsync((_r, ex) -> fn.apply(ex))
>                     ).thenCompose(r -> r);
>   }
>
> Alex
>
>
> On 18 Sep 2018, at 18:27, Martin Buchholz via Concurrency-interest
> <concurrency-interest at cs.oswego.edu> wrote:
>
> Thanks, Peter, I see your point.  Maybe the unconditional async is a
> lesser evil than calling toCompletableFuture (all serious
> implementations of CompletionStage will override).
>
> Maybe a missing piece of low-level infrastructure is something that
> combines handle and compose
>
> return handleCompose((r, ex) -> (ex == null) ? this :
> this.handleAsync((r, ex) -> fn.apply(ex))
>
> Is there a monad theorist in the audience?
>
> On Tue, Sep 18, 2018 at 9:06 AM, Peter Levart <peter.levart at gmail.com>
> wrote:
>
> Hi Martin,
>
> On 09/17/2018 08:48 PM, Martin Buchholz via Concurrency-interest wrote:
>
>
> We don't have any infrastructure for testing default methods on
> CompletionStage - all concrete tests are for CompletableFuture.  But,
> you say, those methods do nothing but delegate ...
>
> Since exceptionally is less general than handle, It seems possible to
> implement the former in terms of the latter, without
> toCompletableFuture getting in the way, but I haven't tried it.  (That
> is, can exceptionally be implemented as a pure convenience method?)
> But then we'd have to test it.
>
>
>
> The problem with handle[Async] is that you choose synchronous vs.
> asynchronous variant regardless of the type of completion of previous stage
> (normal vs. exceptional). So you can't implement exceptionallyAsync exactly
> with handleAsync. If you simply do:
>
> default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? extends
> T> function) {
>    return handleAsync((result, exception) -> {
>        if (exception != null) {
>            return function.apply(exception);
>        } else {
>            return result;
>        }
>    });
> }
>
> ...then you have introduced an asynchronous stage even for normal completion
> of previous stage. You may not want to usually do that as this introduces
> latency to normal path.
>
> Regards, Peter
>
>
>
> On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
> <concurrency-interest at cs.oswego.edu> wrote:
>
>
> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>
>
> People keep looking at the methods in CompletableFuture and
> rediscovering the 2 missing exceptionallyAsync methods.
>
>
> I added methods to cover all variants of exceptionally{Compose}{Async}:
>
>  exceptionally(Function<Throwable, ? extends T> f) // already exists
>  exceptionallyAsync(Function<Throwable, ? extends T> f);
>  exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>  exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>>
> f);
>  exceptionallyComposeAsync(Function<Throwable, ? extends
> CompletionStage<T>> f);
>  exceptionallyComposeAsync(Function<Throwable, ? extends
> CompletionStage<T>> f, Executor e);
>
> These target the next jdk release (12; too late for 11). For javadocs,
> see
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>
> These are all declared in the CompletionStage interface. They are
> directly implemented in CompletableFuture. They are default-implemented
> in CompletionStage in terms of toCompletableFuture, because a concrete
> CompletionStage instance is required. If some  CompletionStage
> implementation class chooses not to implement toCompletableFuture to
> actually return one, and also chooses not to implement these new
> methods, the default implementation will fail. However, this is
> presumably what anyone designing such an implementation would want.
>
> Comments welcome as always.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From oleksandr.otenko at gmail.com  Wed Sep 19 04:20:35 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Wed, 19 Sep 2018 09:20:35 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
Message-ID: <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>

“monad theorist” is too much of a title for me. I can’t bear it :-)

Then possibly you could just cast to T?

…handleAsync((r1, ex1) -> (T)fn.apply(ex1))

Alex

> On 19 Sep 2018, at 00:45, Martin Buchholz <martinrb at google.com> wrote:
> 
> Alex: Thanks for being  our official monad theorist.  To port that to
> CompletableFuture without @SuppressWarnings, I came up with:
> 
>    public CompletableFuture<T> exceptionallyAsync(
>        Function<Throwable, ? extends T> fn) {
>        return handle(
>            (r, ex) -> (ex == null)
>            ? this
>            : handleAsync((r1, ex1) -> { T t = fn.apply(ex1); return t; }))
>            .thenCompose(stage -> stage);
>    }
> 
> which can be reused without changes for the CompletionStage version
> 
>    public default CompletionStage<T> exceptionallyAsync
>        (Function<Throwable, ? extends T> fn) {
>        return handle(
>            (r, ex) -> (ex == null)
>            ? this
>            : handleAsync((r1, ex1) -> { T t = fn.apply(ex1); return t; }))
>            .thenCompose(stage -> stage);
> 
> 
> On Tue, Sep 18, 2018 at 2:31 PM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>  public static <T> CompletionStage<? extends T>
>> exceptionallyAsync(CompletionStage<T> cs, Function<Throwable, ? extends T>
>> fn) {
>>    return cs.handle((r, e) -> e == null ?
>>                                  cs:
>>                                  cs.handleAsync((_r, ex) -> fn.apply(ex))
>>                    ).thenCompose(r -> r);
>>  }
>> 
>> Alex
>> 
>> 
>> On 18 Sep 2018, at 18:27, Martin Buchholz via Concurrency-interest
>> <concurrency-interest at cs.oswego.edu> wrote:
>> 
>> Thanks, Peter, I see your point.  Maybe the unconditional async is a
>> lesser evil than calling toCompletableFuture (all serious
>> implementations of CompletionStage will override).
>> 
>> Maybe a missing piece of low-level infrastructure is something that
>> combines handle and compose
>> 
>> return handleCompose((r, ex) -> (ex == null) ? this :
>> this.handleAsync((r, ex) -> fn.apply(ex))
>> 
>> Is there a monad theorist in the audience?
>> 
>> On Tue, Sep 18, 2018 at 9:06 AM, Peter Levart <peter.levart at gmail.com>
>> wrote:
>> 
>> Hi Martin,
>> 
>> On 09/17/2018 08:48 PM, Martin Buchholz via Concurrency-interest wrote:
>> 
>> 
>> We don't have any infrastructure for testing default methods on
>> CompletionStage - all concrete tests are for CompletableFuture.  But,
>> you say, those methods do nothing but delegate ...
>> 
>> Since exceptionally is less general than handle, It seems possible to
>> implement the former in terms of the latter, without
>> toCompletableFuture getting in the way, but I haven't tried it.  (That
>> is, can exceptionally be implemented as a pure convenience method?)
>> But then we'd have to test it.
>> 
>> 
>> 
>> The problem with handle[Async] is that you choose synchronous vs.
>> asynchronous variant regardless of the type of completion of previous stage
>> (normal vs. exceptional). So you can't implement exceptionallyAsync exactly
>> with handleAsync. If you simply do:
>> 
>> default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? extends
>> T> function) {
>>   return handleAsync((result, exception) -> {
>>       if (exception != null) {
>>           return function.apply(exception);
>>       } else {
>>           return result;
>>       }
>>   });
>> }
>> 
>> ...then you have introduced an asynchronous stage even for normal completion
>> of previous stage. You may not want to usually do that as this introduces
>> latency to normal path.
>> 
>> Regards, Peter
>> 
>> 
>> 
>> On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
>> <concurrency-interest at cs.oswego.edu> wrote:
>> 
>> 
>> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>> 
>> 
>> People keep looking at the methods in CompletableFuture and
>> rediscovering the 2 missing exceptionallyAsync methods.
>> 
>> 
>> I added methods to cover all variants of exceptionally{Compose}{Async}:
>> 
>> exceptionally(Function<Throwable, ? extends T> f) // already exists
>> exceptionallyAsync(Function<Throwable, ? extends T> f);
>> exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>> exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>>
>> f);
>> exceptionallyComposeAsync(Function<Throwable, ? extends
>> CompletionStage<T>> f);
>> exceptionallyComposeAsync(Function<Throwable, ? extends
>> CompletionStage<T>> f, Executor e);
>> 
>> These target the next jdk release (12; too late for 11). For javadocs,
>> see
>> 
>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>> 
>> These are all declared in the CompletionStage interface. They are
>> directly implemented in CompletableFuture. They are default-implemented
>> in CompletionStage in terms of toCompletableFuture, because a concrete
>> CompletionStage instance is required. If some  CompletionStage
>> implementation class chooses not to implement toCompletableFuture to
>> actually return one, and also chooses not to implement these new
>> methods, the default implementation will fail. However, this is
>> presumably what anyone designing such an implementation would want.
>> 
>> Comments welcome as always.
>> 
>> -Doug
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 


From peter.levart at gmail.com  Wed Sep 19 04:49:20 2018
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 19 Sep 2018 10:49:20 +0200
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
Message-ID: <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>

Hi,

This is a very nice solution.

On 09/19/2018 10:20 AM, Alex Otenko wrote:
> “monad theorist” is too much of a title for me. I can’t bear it :-)
>
> Then possibly you could just cast to T?
>
> …handleAsync((r1, ex1) -> (T)fn.apply(ex1))
>
> Alex

...or help the type inference in the following way:

     default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? 
extends T> fn) {
         return handle(
             (r, ex) -> (ex == null)
                        ? this
                        : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
         ).thenCompose(Function.identity());
     }

Regards, Peter

>
>> On 19 Sep 2018, at 00:45, Martin Buchholz <martinrb at google.com> wrote:
>>
>> Alex: Thanks for being  our official monad theorist.  To port that to
>> CompletableFuture without @SuppressWarnings, I came up with:
>>
>>     public CompletableFuture<T> exceptionallyAsync(
>>         Function<Throwable, ? extends T> fn) {
>>         return handle(
>>             (r, ex) -> (ex == null)
>>             ? this
>>             : handleAsync((r1, ex1) -> { T t = fn.apply(ex1); return t; }))
>>             .thenCompose(stage -> stage);
>>     }
>>
>> which can be reused without changes for the CompletionStage version
>>
>>     public default CompletionStage<T> exceptionallyAsync
>>         (Function<Throwable, ? extends T> fn) {
>>         return handle(
>>             (r, ex) -> (ex == null)
>>             ? this
>>             : handleAsync((r1, ex1) -> { T t = fn.apply(ex1); return t; }))
>>             .thenCompose(stage -> stage);
>>
>>
>> On Tue, Sep 18, 2018 at 2:31 PM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>>   public static <T> CompletionStage<? extends T>
>>> exceptionallyAsync(CompletionStage<T> cs, Function<Throwable, ? extends T>
>>> fn) {
>>>     return cs.handle((r, e) -> e == null ?
>>>                                   cs:
>>>                                   cs.handleAsync((_r, ex) -> fn.apply(ex))
>>>                     ).thenCompose(r -> r);
>>>   }
>>>
>>> Alex
>>>
>>>
>>> On 18 Sep 2018, at 18:27, Martin Buchholz via Concurrency-interest
>>> <concurrency-interest at cs.oswego.edu> wrote:
>>>
>>> Thanks, Peter, I see your point.  Maybe the unconditional async is a
>>> lesser evil than calling toCompletableFuture (all serious
>>> implementations of CompletionStage will override).
>>>
>>> Maybe a missing piece of low-level infrastructure is something that
>>> combines handle and compose
>>>
>>> return handleCompose((r, ex) -> (ex == null) ? this :
>>> this.handleAsync((r, ex) -> fn.apply(ex))
>>>
>>> Is there a monad theorist in the audience?
>>>
>>> On Tue, Sep 18, 2018 at 9:06 AM, Peter Levart <peter.levart at gmail.com>
>>> wrote:
>>>
>>> Hi Martin,
>>>
>>> On 09/17/2018 08:48 PM, Martin Buchholz via Concurrency-interest wrote:
>>>
>>>
>>> We don't have any infrastructure for testing default methods on
>>> CompletionStage - all concrete tests are for CompletableFuture.  But,
>>> you say, those methods do nothing but delegate ...
>>>
>>> Since exceptionally is less general than handle, It seems possible to
>>> implement the former in terms of the latter, without
>>> toCompletableFuture getting in the way, but I haven't tried it.  (That
>>> is, can exceptionally be implemented as a pure convenience method?)
>>> But then we'd have to test it.
>>>
>>>
>>>
>>> The problem with handle[Async] is that you choose synchronous vs.
>>> asynchronous variant regardless of the type of completion of previous stage
>>> (normal vs. exceptional). So you can't implement exceptionallyAsync exactly
>>> with handleAsync. If you simply do:
>>>
>>> default CompletionStage<T> exceptionallyAsync(Function<Throwable, ? extends
>>> T> function) {
>>>    return handleAsync((result, exception) -> {
>>>        if (exception != null) {
>>>            return function.apply(exception);
>>>        } else {
>>>            return result;
>>>        }
>>>    });
>>> }
>>>
>>> ...then you have introduced an asynchronous stage even for normal completion
>>> of previous stage. You may not want to usually do that as this introduces
>>> latency to normal path.
>>>
>>> Regards, Peter
>>>
>>>
>>>
>>> On Mon, Sep 17, 2018 at 9:06 AM, Doug Lea via Concurrency-interest
>>> <concurrency-interest at cs.oswego.edu> wrote:
>>>
>>>
>>> On 09/03/2018 11:48 AM, Martin Buchholz wrote:
>>>
>>>
>>> People keep looking at the methods in CompletableFuture and
>>> rediscovering the 2 missing exceptionallyAsync methods.
>>>
>>>
>>> I added methods to cover all variants of exceptionally{Compose}{Async}:
>>>
>>> exceptionally(Function<Throwable, ? extends T> f) // already exists
>>> exceptionallyAsync(Function<Throwable, ? extends T> f);
>>> exceptionallyAsync(Function<Throwable, ? extends T> f, Executor e);
>>> exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>>
>>> f);
>>> exceptionallyComposeAsync(Function<Throwable, ? extends
>>> CompletionStage<T>> f);
>>> exceptionallyComposeAsync(Function<Throwable, ? extends
>>> CompletionStage<T>> f, Executor e);
>>>
>>> These target the next jdk release (12; too late for 11). For javadocs,
>>> see
>>>
>>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java.base/java/util/concurrent/CompletionStage.html
>>>
>>> These are all declared in the CompletionStage interface. They are
>>> directly implemented in CompletableFuture. They are default-implemented
>>> in CompletionStage in terms of toCompletableFuture, because a concrete
>>> CompletionStage instance is required. If some  CompletionStage
>>> implementation class chooses not to implement toCompletableFuture to
>>> actually return one, and also chooses not to implement these new
>>> methods, the default implementation will fail. However, this is
>>> presumably what anyone designing such an implementation would want.
>>>
>>> Comments welcome as always.
>>>
>>> -Doug
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>


From martinrb at google.com  Wed Sep 19 10:27:14 2018
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 Sep 2018 07:27:14 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
Message-ID: <CA+kOe0-dsb2234URa9=gGvEe+adQVs2BwiKwEHTDPwv+MzFXuw@mail.gmail.com>

On Wed, Sep 19, 2018 at 1:20 AM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> “monad theorist” is too much of a title for me. I can’t bear it :-)

I'll try to adjust my worship rites!

> Then possibly you could just cast to T?
>
> …handleAsync((r1, ex1) -> (T)fn.apply(ex1))

We try hard to avoid casts and the ugly @SuppressWarning that goes with them.

From martinrb at google.com  Wed Sep 19 10:29:38 2018
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 Sep 2018 07:29:38 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
Message-ID: <CA+kOe0-qMgqTTrqn=2OPuHsHwOSWL3A-FbRBaFte0D7Dz+5ayw@mail.gmail.com>

On Wed, Sep 19, 2018 at 1:49 AM, Peter Levart <peter.levart at gmail.com> wrote:

>
> ...or help the type inference in the following way:
>
>     default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
> extends T> fn) {
>         return handle(
>             (r, ex) -> (ex == null)
>                        ? this
>                        : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>         ).thenCompose(Function.identity());
>     }

Thanks!  This one's a winner!

From dl at cs.oswego.edu  Wed Sep 19 10:40:37 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 19 Sep 2018 10:40:37 -0400
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
Message-ID: <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>

On 09/19/2018 04:49 AM, Peter Levart wrote:
> ...or help the type inference in the following way:
> 
>     default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
> extends T> fn) {
>         return handle(
>             (r, ex) -> (ex == null)
>                        ? this
>                        : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>         ).thenCompose(Function.identity());
>     }
> 

This is a handy trick. I had mistaken inability to infer type as a need
for using a concrete type. Further simplifying using thenApplyAsync:

        return handle((r, ex) -> (ex == null) ? this
                      : this.<T>thenApplyAsync(x -> fn.apply(ex)))
            .thenCompose(Function.identity());

Something similar works with exceptionallyCompose:

     public default CompletionStage<T> exceptionallyCompose
        (Function<Throwable, ? extends CompletionStage<T>> fn) {
        return handle((r, ex) -> (ex == null) ? this : fn.apply(ex))
            .thenCompose(Function.identity());
    }

I haven't found a nice way yet to do so with exceptionallyComposeAsync.
Assuming we do, these would all make for less surprising default
implementations, but add enough overhead vs direct implementations that
CompletionStage authors would be motivated to override.

We'll also need to add separate default-implementation tests to TCK,
which will take some work.

-Doug


From oleksandr.otenko at gmail.com  Wed Sep 19 11:14:09 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Wed, 19 Sep 2018 16:14:09 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
Message-ID: <55A152F5-EF07-4542-8CAC-C203085E0F41@gmail.com>


> On 19 Sep 2018, at 15:40, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> On 09/19/2018 04:49 AM, Peter Levart wrote:
>> ...or help the type inference in the following way:
>> 
>>     default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
>> extends T> fn) {
>>         return handle(
>>             (r, ex) -> (ex == null)
>>                        ? this
>>                        : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>>         ).thenCompose(Function.identity());
>>     }
>> 
> 
> This is a handy trick. I had mistaken inability to infer type as a need
> for using a concrete type. Further simplifying using thenApplyAsync:
> 
>        return handle((r, ex) -> (ex == null) ? this
>                      : this.<T>thenApplyAsync(x -> fn.apply(ex)))
>            .thenCompose(Function.identity());
> 

Will thenApplyAsync apply in exceptional case? I don’t think it will?


Alex



> Something similar works with exceptionallyCompose:
> 
>     public default CompletionStage<T> exceptionallyCompose
>        (Function<Throwable, ? extends CompletionStage<T>> fn) {
>        return handle((r, ex) -> (ex == null) ? this : fn.apply(ex))
>            .thenCompose(Function.identity());
>    }
> 
> I haven't found a nice way yet to do so with exceptionallyComposeAsync.
> Assuming we do, these would all make for less surprising default
> implementations, but add enough overhead vs direct implementations that
> CompletionStage authors would be motivated to override.
> 
> We'll also need to add separate default-implementation tests to TCK,
> which will take some work.
> 
> -Doug
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From peter.levart at gmail.com  Wed Sep 19 11:18:25 2018
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 19 Sep 2018 17:18:25 +0200
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
Message-ID: <a88d7bd1-b400-a893-8629-c26eafa57e34@gmail.com>



On 09/19/2018 04:40 PM, Doug Lea wrote:
> On 09/19/2018 04:49 AM, Peter Levart wrote:
>> ...or help the type inference in the following way:
>>
>>      default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
>> extends T> fn) {
>>          return handle(
>>              (r, ex) -> (ex == null)
>>                         ? this
>>                         : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>>          ).thenCompose(Function.identity());
>>      }
>>
> This is a handy trick. I had mistaken inability to infer type as a need
> for using a concrete type. Further simplifying using thenApplyAsync:
>
>          return handle((r, ex) -> (ex == null) ? this
>                        : this.<T>thenApplyAsync(x -> fn.apply(ex)))
>              .thenCompose(Function.identity());
>
> Something similar works with exceptionallyCompose:
>
>       public default CompletionStage<T> exceptionallyCompose
>          (Function<Throwable, ? extends CompletionStage<T>> fn) {
>          return handle((r, ex) -> (ex == null) ? this : fn.apply(ex))
>              .thenCompose(Function.identity());
>      }
>
> I haven't found a nice way yet to do so with exceptionallyComposeAsync.

What about continuing with the nesting fashion:

     default CompletionStage<T> 
exceptionallyComposeAsync(Function<Throwable, ? extends 
CompletionStage<T>> fn) {
         return handle(
             (r, ex) -> (ex == null)
                        ? this
                        : this.handleAsync((r1, ex1) -> fn.apply(ex1))
                              .thenCompose(Function.identity())
         ).thenCompose(Function.identity());
     }


Regards, Peter

> Assuming we do, these would all make for less surprising default
> implementations, but add enough overhead vs direct implementations that
> CompletionStage authors would be motivated to override.
>
> We'll also need to add separate default-implementation tests to TCK,
> which will take some work.
>
> -Doug
>


From dl at cs.oswego.edu  Wed Sep 19 11:38:59 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 19 Sep 2018 11:38:59 -0400
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <55A152F5-EF07-4542-8CAC-C203085E0F41@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <55A152F5-EF07-4542-8CAC-C203085E0F41@gmail.com>
Message-ID: <a96c8cfe-270c-dd8a-cdce-7e90f1d4d58a@cs.oswego.edu>

On 09/19/2018 11:14 AM, Alex Otenko wrote:
> 
>> On 19 Sep 2018, at 15:40, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>>
>> On 09/19/2018 04:49 AM, Peter Levart wrote:
>>> ...or help the type inference in the following way:
>>>
>>>     default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
>>> extends T> fn) {
>>>         return handle(
>>>             (r, ex) -> (ex == null)
>>>                        ? this
>>>                        : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>>>         ).thenCompose(Function.identity());
>>>     }
>>>
>>
>> This is a handy trick. I had mistaken inability to infer type as a need
>> for using a concrete type. Further simplifying using thenApplyAsync:
>>
>>        return handle((r, ex) -> (ex == null) ? this
>>                      : this.<T>thenApplyAsync(x -> fn.apply(ex)))
>>            .thenCompose(Function.identity());
>>
> 
> Will thenApplyAsync apply in exceptional case? I don’t think it will?

Good point. The specs don't require it, so Peter's version is a better
choice.

-Doug


From dl at cs.oswego.edu  Wed Sep 19 11:40:35 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 19 Sep 2018 11:40:35 -0400
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <a88d7bd1-b400-a893-8629-c26eafa57e34@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <a88d7bd1-b400-a893-8629-c26eafa57e34@gmail.com>
Message-ID: <c3f8628e-adc9-0767-1b0f-e1200af5b796@cs.oswego.edu>

On 09/19/2018 11:18 AM, Peter Levart wrote:

>> I haven't found a nice way yet to do so with exceptionallyComposeAsync.
> 
> What about continuing with the nesting fashion:
> 
>     default CompletionStage<T>
> exceptionallyComposeAsync(Function<Throwable, ? extends
> CompletionStage<T>> fn) {
>         return handle(
>             (r, ex) -> (ex == null)
>                        ? this
>                        : this.handleAsync((r1, ex1) -> fn.apply(ex1))
>                              .thenCompose(Function.identity())
>         ).thenCompose(Function.identity());
>     }
> 

Thanks. Yet another layer of wrapping, but at least it compiles!

-Doug



From oleksandr.otenko at gmail.com  Wed Sep 19 12:33:20 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Wed, 19 Sep 2018 17:33:20 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <c3f8628e-adc9-0767-1b0f-e1200af5b796@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <a88d7bd1-b400-a893-8629-c26eafa57e34@gmail.com>
 <c3f8628e-adc9-0767-1b0f-e1200af5b796@cs.oswego.edu>
Message-ID: <61A0B17A-E6A5-4915-841D-1F49274E14CF@gmail.com>

It’s a common strategy to reduce CompletionStage<CompletionStage<T>> to CompletionStage<T>

Alex

> On 19 Sep 2018, at 16:40, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> On 09/19/2018 11:18 AM, Peter Levart wrote:
> 
>>> I haven't found a nice way yet to do so with exceptionallyComposeAsync.
>> 
>> What about continuing with the nesting fashion:
>> 
>>     default CompletionStage<T>
>> exceptionallyComposeAsync(Function<Throwable, ? extends
>> CompletionStage<T>> fn) {
>>         return handle(
>>             (r, ex) -> (ex == null)
>>                        ? this
>>                        : this.handleAsync((r1, ex1) -> fn.apply(ex1))
>>                              .thenCompose(Function.identity())
>>         ).thenCompose(Function.identity());
>>     }
>> 
> 
> Thanks. Yet another layer of wrapping, but at least it compiles!
> 
> -Doug
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From peter.levart at gmail.com  Wed Sep 19 18:19:35 2018
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 20 Sep 2018 00:19:35 +0200
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
Message-ID: <58b81af4-4ded-d672-a7c1-3cbfb9e8d8a9@gmail.com>

Regarding testing of default methods on CompletionStage...

If you produce tests for new methods in CompletableFuture, then the same 
tests can be used to test CompletionStage default methods simply by 
passing a subclass of CompletableFuture, overriding the new methods and 
delegating to CompletionStage methods. This can't be perfomed in Java, 
but can be performed using MethodHandle(s). For example:

/**
  * A CompletableFuture subclass that delegates execution of methods that
  * have defaults in {@link CompletionStage} to the default implementations.
  */
public class CompletableFutureUsingDefaults<T> extends 
CompletableFuture<T> {
     private static final MethodHandle exceptionallyAsync;
     private static final MethodHandle exceptionallyAsyncEx;
     private static final MethodHandle exceptionallyCompose;
     private static final MethodHandle exceptionallyComposeAsync;
     private static final MethodHandle exceptionallyComposeAsyncEx;

     static {
         try {
             MethodHandles.Lookup lookup = MethodHandles
                 .privateLookupIn(CompletionStage.class, 
MethodHandles.lookup());
             exceptionallyAsync = lookup.findSpecial(
                 CompletionStage.class, "exceptionallyAsync",
                 MethodType.methodType(CompletionStage.class, 
Function.class),
                 CompletableFuture.class);
             exceptionallyAsyncEx = lookup.findSpecial(
                 CompletionStage.class, "exceptionallyAsync",
                 MethodType.methodType(CompletionStage.class, 
Function.class, Executor.class),
                 CompletableFuture.class);
             exceptionallyCompose = lookup.findSpecial(
                 CompletionStage.class, "exceptionallyCompose",
                 MethodType.methodType(CompletionStage.class, 
Function.class),
                 CompletableFuture.class);
             exceptionallyComposeAsync = lookup.findSpecial(
                 CompletionStage.class, "exceptionallyComposeAsync",
                 MethodType.methodType(CompletionStage.class, 
Function.class),
                 CompletableFuture.class);
             exceptionallyComposeAsyncEx = lookup.findSpecial(
                 CompletionStage.class, "exceptionallyComposeAsync",
                 MethodType.methodType(CompletionStage.class, 
Function.class, Executor.class),
                 CompletableFuture.class);
         } catch (IllegalAccessException e) {
             throw (Error) new 
IllegalAccessError(e.getMessage()).initCause(e);
         } catch (NoSuchMethodException e) {
             throw (Error) new 
NoSuchMethodError(e.getMessage()).initCause(e);
         }

     }

     private static RuntimeException unchecked(Throwable exception) {
         if (exception instanceof RuntimeException) {
             return (RuntimeException) exception;
         } else if (exception instanceof Error) {
             throw (Error) exception;
         } else {
             return new RuntimeException(exception);
         }
     }

     @Override
     public <U> CompletableFuture<U> newIncompleteFuture() {
         return new CompletableFutureUsingDefaults<>();
     }

     @SuppressWarnings("unchecked")
     public CompletableFuture<T> exceptionallyAsync(Function<Throwable, 
? extends T> fn) {
         try {
             return (CompletableFuture<T>) (CompletionStage<T>)
exceptionallyAsync.invokeExact((CompletableFuture<T>) this, fn);
         } catch (Throwable ex) {
             throw unchecked(ex);
         }
     }

     @SuppressWarnings("unchecked")
     public CompletableFuture<T> exceptionallyAsync(Function<Throwable, 
? extends T> fn, Executor executor) {
         try {
             return (CompletableFuture<T>) (CompletionStage<T>)
exceptionallyAsyncEx.invokeExact((CompletableFuture<T>) this, fn, executor);
         } catch (Throwable ex) {
             throw unchecked(ex);
         }
     }

     @SuppressWarnings("unchecked")
     public CompletableFuture<T> 
exceptionallyCompose(Function<Throwable, ? extends CompletionStage<T>> fn) {
         try {
             return (CompletableFuture<T>) (CompletionStage<T>)
exceptionallyCompose.invokeExact((CompletableFuture<T>) this, fn);
         } catch (Throwable ex) {
             throw unchecked(ex);
         }
     }

     @SuppressWarnings("unchecked")
     public CompletableFuture<T> 
exceptionallyComposeAsync(Function<Throwable, ? extends 
CompletionStage<T>> fn) {
         try {
             return (CompletableFuture<T>) (CompletionStage<T>)
exceptionallyComposeAsync.invokeExact((CompletableFuture<T>) this, fn);
         } catch (Throwable ex) {
             throw unchecked(ex);
         }
     }

     @SuppressWarnings("unchecked")
     public CompletableFuture<T> 
exceptionallyComposeAsync(Function<Throwable, ? extends 
CompletionStage<T>> fn, Executor executor) {
         try {
             return (CompletableFuture<T>) (CompletionStage<T>)
exceptionallyComposeAsyncEx.invokeExact((CompletableFuture<T>) this, fn, 
executor);
         } catch (Throwable ex) {
             throw unchecked(ex);
         }
     }
}


If a test with such class is on class-path, then it must be invoked with 
an additional java option:

     --add-opens java.base/java.util.concurrent=ALL-UNNAMED


The effects of testing such class should be the same as the effects of 
testing a CompletableFuture that didn't override the default methods.

Regards, Peter


On 09/19/2018 04:40 PM, Doug Lea wrote:
> On 09/19/2018 04:49 AM, Peter Levart wrote:
>> ...or help the type inference in the following way:
>>
>>      default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
>> extends T> fn) {
>>          return handle(
>>              (r, ex) -> (ex == null)
>>                         ? this
>>                         : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>>          ).thenCompose(Function.identity());
>>      }
>>
> This is a handy trick. I had mistaken inability to infer type as a need
> for using a concrete type. Further simplifying using thenApplyAsync:
>
>          return handle((r, ex) -> (ex == null) ? this
>                        : this.<T>thenApplyAsync(x -> fn.apply(ex)))
>              .thenCompose(Function.identity());
>
> Something similar works with exceptionallyCompose:
>
>       public default CompletionStage<T> exceptionallyCompose
>          (Function<Throwable, ? extends CompletionStage<T>> fn) {
>          return handle((r, ex) -> (ex == null) ? this : fn.apply(ex))
>              .thenCompose(Function.identity());
>      }
>
> I haven't found a nice way yet to do so with exceptionallyComposeAsync.
> Assuming we do, these would all make for less surprising default
> implementations, but add enough overhead vs direct implementations that
> CompletionStage authors would be motivated to override.
>
> We'll also need to add separate default-implementation tests to TCK,
> which will take some work.
>
> -Doug
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180920/392362e9/attachment.html>

From martinrb at google.com  Wed Sep 19 20:46:35 2018
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 Sep 2018 17:46:35 -0700
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
	handleCompose
In-Reply-To: <58b81af4-4ded-d672-a7c1-3cbfb9e8d8a9@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <58b81af4-4ded-d672-a7c1-3cbfb9e8d8a9@gmail.com>
Message-ID: <CA+kOe09v4kr7=DXNswuQ9=RNimLk3X-GKxkpWNF2ZmU48bU40g@mail.gmail.com>

Thanks, Peter - we may end up parameterizing tests with a
CompletableFutureFactory

We already use --add-opens java.base/java.util.concurrent=ALL-UNNAMED

On Wed, Sep 19, 2018 at 3:19 PM, Peter Levart via Concurrency-interest
<concurrency-interest at cs.oswego.edu> wrote:
> Regarding testing of default methods on CompletionStage...
>
> If you produce tests for new methods in CompletableFuture, then the same
> tests can be used to test CompletionStage default methods simply by passing
> a subclass of CompletableFuture, overriding the new methods and delegating
> to CompletionStage methods. This can't be perfomed in Java, but can be
> performed using MethodHandle(s). For example:
>
> /**
>  * A CompletableFuture subclass that delegates execution of methods that
>  * have defaults in {@link CompletionStage} to the default implementations.
>  */
> public class CompletableFutureUsingDefaults<T> extends CompletableFuture<T>
> {
>     private static final MethodHandle exceptionallyAsync;
>     private static final MethodHandle exceptionallyAsyncEx;
>     private static final MethodHandle exceptionallyCompose;
>     private static final MethodHandle exceptionallyComposeAsync;
>     private static final MethodHandle exceptionallyComposeAsyncEx;
>
>     static {
>         try {
>             MethodHandles.Lookup lookup = MethodHandles
>                 .privateLookupIn(CompletionStage.class,
> MethodHandles.lookup());
>             exceptionallyAsync = lookup.findSpecial(
>                 CompletionStage.class, "exceptionallyAsync",
>                 MethodType.methodType(CompletionStage.class,
> Function.class),
>                 CompletableFuture.class);
>             exceptionallyAsyncEx = lookup.findSpecial(
>                 CompletionStage.class, "exceptionallyAsync",
>                 MethodType.methodType(CompletionStage.class, Function.class,
> Executor.class),
>                 CompletableFuture.class);
>             exceptionallyCompose = lookup.findSpecial(
>                 CompletionStage.class, "exceptionallyCompose",
>                 MethodType.methodType(CompletionStage.class,
> Function.class),
>                 CompletableFuture.class);
>             exceptionallyComposeAsync = lookup.findSpecial(
>                 CompletionStage.class, "exceptionallyComposeAsync",
>                 MethodType.methodType(CompletionStage.class,
> Function.class),
>                 CompletableFuture.class);
>             exceptionallyComposeAsyncEx = lookup.findSpecial(
>                 CompletionStage.class, "exceptionallyComposeAsync",
>                 MethodType.methodType(CompletionStage.class, Function.class,
> Executor.class),
>                 CompletableFuture.class);
>         } catch (IllegalAccessException e) {
>             throw (Error) new
> IllegalAccessError(e.getMessage()).initCause(e);
>         } catch (NoSuchMethodException e) {
>             throw (Error) new
> NoSuchMethodError(e.getMessage()).initCause(e);
>         }
>
>     }
>
>     private static RuntimeException unchecked(Throwable exception) {
>         if (exception instanceof RuntimeException) {
>             return (RuntimeException) exception;
>         } else if (exception instanceof Error) {
>             throw (Error) exception;
>         } else {
>             return new RuntimeException(exception);
>         }
>     }
>
>     @Override
>     public <U> CompletableFuture<U> newIncompleteFuture() {
>         return new CompletableFutureUsingDefaults<>();
>     }
>
>     @SuppressWarnings("unchecked")
>     public CompletableFuture<T> exceptionallyAsync(Function<Throwable, ?
> extends T> fn) {
>         try {
>             return (CompletableFuture<T>) (CompletionStage<T>)
>                 exceptionallyAsync.invokeExact((CompletableFuture<T>) this,
> fn);
>         } catch (Throwable ex) {
>             throw unchecked(ex);
>         }
>     }
>
>     @SuppressWarnings("unchecked")
>     public CompletableFuture<T> exceptionallyAsync(Function<Throwable, ?
> extends T> fn, Executor executor) {
>         try {
>             return (CompletableFuture<T>) (CompletionStage<T>)
>                 exceptionallyAsyncEx.invokeExact((CompletableFuture<T>)
> this, fn, executor);
>         } catch (Throwable ex) {
>             throw unchecked(ex);
>         }
>     }
>
>     @SuppressWarnings("unchecked")
>     public CompletableFuture<T> exceptionallyCompose(Function<Throwable, ?
> extends CompletionStage<T>> fn) {
>         try {
>             return (CompletableFuture<T>) (CompletionStage<T>)
>                 exceptionallyCompose.invokeExact((CompletableFuture<T>)
> this, fn);
>         } catch (Throwable ex) {
>             throw unchecked(ex);
>         }
>     }
>
>     @SuppressWarnings("unchecked")
>     public CompletableFuture<T>
> exceptionallyComposeAsync(Function<Throwable, ? extends CompletionStage<T>>
> fn) {
>         try {
>             return (CompletableFuture<T>) (CompletionStage<T>)
>                 exceptionallyComposeAsync.invokeExact((CompletableFuture<T>)
> this, fn);
>         } catch (Throwable ex) {
>             throw unchecked(ex);
>         }
>     }
>
>     @SuppressWarnings("unchecked")
>     public CompletableFuture<T>
> exceptionallyComposeAsync(Function<Throwable, ? extends CompletionStage<T>>
> fn, Executor executor) {
>         try {
>             return (CompletableFuture<T>) (CompletionStage<T>)
>
> exceptionallyComposeAsyncEx.invokeExact((CompletableFuture<T>) this, fn,
> executor);
>         } catch (Throwable ex) {
>             throw unchecked(ex);
>         }
>     }
> }
>
>
> If a test with such class is on class-path, then it must be invoked with an
> additional java option:
>
>     --add-opens java.base/java.util.concurrent=ALL-UNNAMED
>
>
> The effects of testing such class should be the same as the effects of
> testing a CompletableFuture that didn't override the default methods.
>
> Regards, Peter
>
>
> On 09/19/2018 04:40 PM, Doug Lea wrote:
>
> On 09/19/2018 04:49 AM, Peter Levart wrote:
>
> ...or help the type inference in the following way:
>
>     default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
> extends T> fn) {
>         return handle(
>             (r, ex) -> (ex == null)
>                        ? this
>                        : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>         ).thenCompose(Function.identity());
>     }
>
> This is a handy trick. I had mistaken inability to infer type as a need
> for using a concrete type. Further simplifying using thenApplyAsync:
>
>         return handle((r, ex) -> (ex == null) ? this
>                       : this.<T>thenApplyAsync(x -> fn.apply(ex)))
>             .thenCompose(Function.identity());
>
> Something similar works with exceptionallyCompose:
>
>      public default CompletionStage<T> exceptionallyCompose
>         (Function<Throwable, ? extends CompletionStage<T>> fn) {
>         return handle((r, ex) -> (ex == null) ? this : fn.apply(ex))
>             .thenCompose(Function.identity());
>     }
>
> I haven't found a nice way yet to do so with exceptionallyComposeAsync.
> Assuming we do, these would all make for less surprising default
> implementations, but add enough overhead vs direct implementations that
> CompletionStage authors would be motivated to override.
>
> We'll also need to add separate default-implementation tests to TCK,
> which will take some work.
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From oleksandr.otenko at gmail.com  Thu Sep 20 03:05:11 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 20 Sep 2018 08:05:11 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <a96c8cfe-270c-dd8a-cdce-7e90f1d4d58a@cs.oswego.edu>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <55A152F5-EF07-4542-8CAC-C203085E0F41@gmail.com>
 <a96c8cfe-270c-dd8a-cdce-7e90f1d4d58a@cs.oswego.edu>
Message-ID: <898FAD61-183B-4EE3-BB8F-6060E29CD38A@gmail.com>

I am not sure what “the specs don’t require it” means.

It would be very surprising, if not utterly wrong, if anyone implemented then* for CompletionStage that ended exceptionally.

Alex

> On 19 Sep 2018, at 16:38, Doug Lea <dl at cs.oswego.edu> wrote:
> 
> On 09/19/2018 11:14 AM, Alex Otenko wrote:
>> 
>>> On 19 Sep 2018, at 15:40, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>>> 
>>> On 09/19/2018 04:49 AM, Peter Levart wrote:
>>>> ...or help the type inference in the following way:
>>>> 
>>>>    default CompletionStage<T> exceptionallyAsync(Function<Throwable, ?
>>>> extends T> fn) {
>>>>        return handle(
>>>>            (r, ex) -> (ex == null)
>>>>                       ? this
>>>>                       : this.<T>handleAsync((r1, ex1) -> fn.apply(ex1))
>>>>        ).thenCompose(Function.identity());
>>>>    }
>>>> 
>>> 
>>> This is a handy trick. I had mistaken inability to infer type as a need
>>> for using a concrete type. Further simplifying using thenApplyAsync:
>>> 
>>>       return handle((r, ex) -> (ex == null) ? this
>>>                     : this.<T>thenApplyAsync(x -> fn.apply(ex)))
>>>           .thenCompose(Function.identity());
>>> 
>> 
>> Will thenApplyAsync apply in exceptional case? I don’t think it will?
> 
> Good point. The specs don't require it, so Peter's version is a better
> choice.
> 
> -Doug

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180920/d5de4846/attachment.html>

From oleksandr.otenko at gmail.com  Thu Sep 20 03:21:46 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 20 Sep 2018 08:21:46 +0100
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <61A0B17A-E6A5-4915-841D-1F49274E14CF@gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <a88d7bd1-b400-a893-8629-c26eafa57e34@gmail.com>
 <c3f8628e-adc9-0767-1b0f-e1200af5b796@cs.oswego.edu>
 <61A0B17A-E6A5-4915-841D-1F49274E14CF@gmail.com>
Message-ID: <1A93AD87-59B9-4D3C-AD56-C513357CB315@gmail.com>

For example,

   default CompletionStage<T> exceptionallyComposeAsync(Function<Throwable, ? extends CompletionStage<T>> fn) {
       return thenApply(_r -> this).<CompletionStage<T>>exceptionallyAsync(fn).thenCompose(r -> r);
   }

is an alternative.

I am not competing for clarity (although to me that’s much clearer), but trying to demonstrate the expected behaviour to be compatible with this.

Because thenApply(_r -> this).thenCompose(r -> r) is expected to be Function.identity().

Alex

> On 19 Sep 2018, at 17:33, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> It’s a common strategy to reduce CompletionStage<CompletionStage<T>> to CompletionStage<T>
> 
> Alex
> 
>> On 19 Sep 2018, at 16:40, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>> 
>> On 09/19/2018 11:18 AM, Peter Levart wrote:
>> 
>>>> I haven't found a nice way yet to do so with exceptionallyComposeAsync.
>>> 
>>> What about continuing with the nesting fashion:
>>> 
>>>    default CompletionStage<T>
>>> exceptionallyComposeAsync(Function<Throwable, ? extends
>>> CompletionStage<T>> fn) {
>>>        return handle(
>>>            (r, ex) -> (ex == null)
>>>                       ? this
>>>                       : this.handleAsync((r1, ex1) -> fn.apply(ex1))
>>>                             .thenCompose(Function.identity())
>>>        ).thenCompose(Function.identity());
>>>    }
>>> 
>> 
>> Thanks. Yet another layer of wrapping, but at least it compiles!
>> 
>> -Doug
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From heinz at javaspecialists.eu  Thu Sep 20 11:32:35 2018
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 20 Sep 2018 18:32:35 +0300
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
Message-ID: <5BA3BD93.7020204@javaspecialists.eu>

Most likely too basic for this audience ... :-)

Abstract: ConcurrentLinkedQueue's size() method is not very useful in a 
multi-threaded environment, because it counts the number of elements in 
the queue, rather than relying on a "hot field" to store the size. The 
result might be completely incorrect, or in strange situations, never 
return.

Full article: https://www.javaspecialists.eu/archive/Issue261.html

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java™ Specialists' Newsletter" - www.javaspecialists.eu
Java Champion - www.javachampions.org
Oracle Developer Champion - www.twitter.com/dev_champions
JavaOne Rock Star - www.oracle.com/javaone/rock-star-wall-of-fame.html
Tel: +30 69 75 595 262
Skype: kabutz



From martinrb at google.com  Sat Sep 22 16:32:20 2018
From: martinrb at google.com (Martin Buchholz)
Date: Sat, 22 Sep 2018 13:32:20 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <5BA3BD93.7020204@javaspecialists.eu>
References: <5BA3BD93.7020204@javaspecialists.eu>
Message-ID: <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>

Hi Heinz,

Thanks for the article.  How can we do better?  The problem affects
all methods that iterate over a concurrent queue, so not just size()
but also contains(), toArray().  We surely want all these methods to
return the correct result when the queue is quiescent.  The semantics
of the current implementation  "traverse all elements from head until
the end is found" are pretty intuitive.  It wouldn't work to first
find the last node, then traverse from head until the last node is
encountered, because there is no guarantee this node will remain in
the queue.

If it was important to fix, we can probably do it with heroic effort
and a tax on the dequeue methods.  First enqueue a special end marker
node that will only be unlinked by the traversing method.  (harder
than it sounds!)

Users can work-around by creating a subclass maintaining a count in a LongAdder.

On Thu, Sep 20, 2018 at 8:32 AM, Dr Heinz M. Kabutz via
Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> Most likely too basic for this audience ... :-)
>
> Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
> multi-threaded environment, because it counts the number of elements in the
> queue, rather than relying on a "hot field" to store the size. The result
> might be completely incorrect, or in strange situations, never return.
>
> Full article: https://www.javaspecialists.eu/archive/Issue261.html
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java™ Specialists' Newsletter" - www.javaspecialists.eu
> Java Champion - www.javachampions.org
> Oracle Developer Champion - www.twitter.com/dev_champions
> JavaOne Rock Star - www.oracle.com/javaone/rock-star-wall-of-fame.html
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From dl at cs.oswego.edu  Sat Sep 22 16:35:38 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 22 Sep 2018 16:35:38 -0400
Subject: [concurrency-interest] CompletableFuture.exceptionallyAsync or
 handleCompose
In-Reply-To: <CA+kOe09v4kr7=DXNswuQ9=RNimLk3X-GKxkpWNF2ZmU48bU40g@mail.gmail.com>
References: <879230aa-df47-1279-d78f-cf72c41a0de9@gmail.com>
 <dc93a323-262a-2d10-b35f-c1a999dc26e9@oracle.com>
 <e6285bbe-5805-0342-7c50-7d097b8768dd@cs.oswego.edu>
 <CA+kOe08Ye-WnpyXj=UPc0hS=3Q3td-N3uRy3fVdhL+QSQOnGyA@mail.gmail.com>
 <70408aa3-66f6-a1dc-230e-717cfeb18d81@cs.oswego.edu>
 <CA+kOe08=1zfR+GAfe8gEjXET+Pctj3vtfkv1kROHD3=im6NWGA@mail.gmail.com>
 <92b6ca96-80fb-3ec3-dda2-1f898b4c74d6@gmail.com>
 <CA+kOe0-CnhX=Hi7TgZn4hTo-0LHKdUnayafRTH3SCrdGbvF+kA@mail.gmail.com>
 <3946079A-6889-49A3-8916-6EE17A8C155C@gmail.com>
 <CA+kOe0-kjbX2LQymtoX7r1qPMj+6aw-pU7xAnp4d=8KX4dYa6w@mail.gmail.com>
 <2E9FF45B-ABB6-47BE-AC68-D200CE3F78A6@gmail.com>
 <34b52220-6aa7-a0fc-bc00-9548f3ed100a@gmail.com>
 <90e1326a-24e3-0919-a28e-b5a529d22532@cs.oswego.edu>
 <58b81af4-4ded-d672-a7c1-3cbfb9e8d8a9@gmail.com>
 <CA+kOe09v4kr7=DXNswuQ9=RNimLk3X-GKxkpWNF2ZmU48bU40g@mail.gmail.com>
Message-ID: <b2f8fd05-77a2-6aa4-cdf8-b77972dfc842@cs.oswego.edu>


Thanks all for the prods and help. This is now an openjdk CR and CSR,
heading for jdk12:
  https://bugs.openjdk.java.net/browse/JDK-8211010
  https://bugs.openjdk.java.net/browse/JDK-8210971

Also, thanks Peter for the MethodHandle approach (that we'll probably
someday somehow use) but the tck tests just use a
DelegatedCompletionStage that leaves out relays for new defaut methods.

And thanks Alex for posts about formulating defaults. We went with the
version Peter posted based on your initial suggestions. We could have
made some a little more concise, but these choices seem to create fewer
(or at least no more) intermediary objects of overhead.

-Doug


From oleksandr.otenko at gmail.com  Sat Sep 22 17:53:23 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sat, 22 Sep 2018 22:53:23 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
Message-ID: <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>

I am baffled by the suggestions both to use size() in any circumstances, and to use LongAdder.

What use is the size() in a concurrent setting? It can only be an estimate, and any implementation on top of the current ConcurrentLinkedQueue will permit invalid values, including negative size, unless the queue updates the count atomically with adding or removing an element.

Alex

> On 22 Sep 2018, at 21:32, Martin Buchholz via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> Hi Heinz,
> 
> Thanks for the article.  How can we do better?  The problem affects
> all methods that iterate over a concurrent queue, so not just size()
> but also contains(), toArray().  We surely want all these methods to
> return the correct result when the queue is quiescent.  The semantics
> of the current implementation  "traverse all elements from head until
> the end is found" are pretty intuitive.  It wouldn't work to first
> find the last node, then traverse from head until the last node is
> encountered, because there is no guarantee this node will remain in
> the queue.
> 
> If it was important to fix, we can probably do it with heroic effort
> and a tax on the dequeue methods.  First enqueue a special end marker
> node that will only be unlinked by the traversing method.  (harder
> than it sounds!)
> 
> Users can work-around by creating a subclass maintaining a count in a LongAdder.
> 
> On Thu, Sep 20, 2018 at 8:32 AM, Dr Heinz M. Kabutz via
> Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>> Most likely too basic for this audience ... :-)
>> 
>> Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
>> multi-threaded environment, because it counts the number of elements in the
>> queue, rather than relying on a "hot field" to store the size. The result
>> might be completely incorrect, or in strange situations, never return.
>> 
>> Full article: https://www.javaspecialists.eu/archive/Issue261.html
>> 
>> Regards
>> 
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java™ Specialists' Newsletter" - www.javaspecialists.eu
>> Java Champion - www.javachampions.org
>> Oracle Developer Champion - www.twitter.com/dev_champions
>> JavaOne Rock Star - www.oracle.com/javaone/rock-star-wall-of-fame.html
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180922/9bf2a829/attachment.html>

From martinrb at google.com  Sat Sep 22 18:12:17 2018
From: martinrb at google.com (Martin Buchholz)
Date: Sat, 22 Sep 2018 15:12:17 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
Message-ID: <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>

On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> What use is the size() in a concurrent setting? It can only be an estimate

Some library methods call size(), in the hope that it might optimize
some other code.

Even when size() is only an estimate, it may be useful.

Surely we would want size() to never return a negative value (we
probably have buglets where size overflows 32-bit).

From oleksandr.otenko at gmail.com  Sat Sep 22 18:48:39 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sat, 22 Sep 2018 23:48:39 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
Message-ID: <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>

Right.

If the counter update is not atomic with the adding/removing of the elements, then you may get to add an element, then remove the element, then reduce the count as part of removing, then read a negative size(), and only then increment the count as part of the adding.


Alex

> On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
> 
> On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>> What use is the size() in a concurrent setting? It can only be an estimate
> 
> Some library methods call size(), in the hope that it might optimize
> some other code.
> 
> Even when size() is only an estimate, it may be useful.
> 
> Surely we would want size() to never return a negative value (we
> probably have buglets where size overflows 32-bit).


From heinz at javaspecialists.eu  Sat Sep 22 23:13:44 2018
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Sun, 23 Sep 2018 06:13:44 +0300
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
Message-ID: <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>

We could increment before actually adding.  Both queues where this would
apply are unbounded so we can assume it will add eventually. For remove we
could decrement only if it was successfully removed.

To avoid one hot field, Nathan suggested to me to use two AtomicLongs, one
for adds and one for removes.  Size would return the difference.

Heinz

On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> Right.
>
> If the counter update is not atomic with the adding/removing of the
> elements, then you may get to add an element, then remove the element, then
> reduce the count as part of removing, then read a negative size(), and only
> then increment the count as part of the adding.
>
>
> Alex
>
> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
> >
> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
> >> What use is the size() in a concurrent setting? It can only be an
> estimate
> >
> > Some library methods call size(), in the hope that it might optimize
> > some other code.
> >
> > Even when size() is only an estimate, it may be useful.
> >
> > Surely we would want size() to never return a negative value (we
> > probably have buglets where size overflows 32-bit).
>
> --
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion
JavaOne Rockstar Speaker
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/0b839bde/attachment-0001.html>

From joe.bowbeer at gmail.com  Sun Sep 23 00:04:03 2018
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 22 Sep 2018 21:04:03 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
 <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
Message-ID: <CAHzJPEow3Y-KrmxTypkM6HottqoQp7EHT1=zyRTFu6kkaN0kyg@mail.gmail.com>

The impl. hasn't changed in 15 years, right? Since Java 5.

Likewise, the warning has existed for 15 years:

Beware that, unlike in most collections, this method is *NOT* a
constant-time operation. Because of the asynchronous nature of these
queues, determining the current number of elements requires an O(n)
traversal. Additionally, if elements are added or removed during execution
of this method, the returned result may be inaccurate. Thus, this method is
typically not very useful in concurrent applications.

What's the benefit in changing this now?

I claim the current impl. is by design.

On Sat, Sep 22, 2018 at 8:37 PM Dr Heinz M. Kabutz via Concurrency-interest
<concurrency-interest at cs.oswego.edu> wrote:

> We could increment before actually adding.  Both queues where this would
> apply are unbounded so we can assume it will add eventually. For remove we
> could decrement only if it was successfully removed.
>
> To avoid one hot field, Nathan suggested to me to use two AtomicLongs, one
> for adds and one for removes.  Size would return the difference.
>
> Heinz
>
> On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
>
>> Right.
>>
>> If the counter update is not atomic with the adding/removing of the
>> elements, then you may get to add an element, then remove the element, then
>> reduce the count as part of removing, then read a negative size(), and only
>> then increment the count as part of the adding.
>>
>>
>> Alex
>>
>> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
>> >
>> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <
>> oleksandr.otenko at gmail.com> wrote:
>> >> What use is the size() in a concurrent setting? It can only be an
>> estimate
>> >
>> > Some library methods call size(), in the hope that it might optimize
>> > some other code.
>> >
>> > Even when size() is only an estimate, it may be useful.
>> >
>> > Surely we would want size() to never return a negative value (we
>> > probably have buglets where size overflows 32-bit).
>>
>> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu
>
> Tel: +30 69 75 595 262
> Skype: kabutz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180922/f1e839a3/attachment.html>

From heinz at javaspecialists.eu  Sun Sep 23 00:11:37 2018
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Sun, 23 Sep 2018 07:11:37 +0300
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CAHzJPEow3Y-KrmxTypkM6HottqoQp7EHT1=zyRTFu6kkaN0kyg@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
 <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
 <CAHzJPEow3Y-KrmxTypkM6HottqoQp7EHT1=zyRTFu6kkaN0kyg@mail.gmail.com>
Message-ID: <CACLL95oHPALgbKCO2Q5OrdzA8Z6uW5jWDBTB_k52GmJFsm+EMg@mail.gmail.com>

It is giving incorrect answers by design.

And ConcurrentLinkedQueue has been revised and improved several times in
the last 15 years.

It is the one thing that programmers get most surprised by in my
concurrency classes, especially how incorrect the answer can be.  And it is
trivial to fix or at least improve.

Heinz

On Sun, 23 Sep 2018 at 07:04, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> The impl. hasn't changed in 15 years, right? Since Java 5.
>
> Likewise, the warning has existed for 15 years:
>
> Beware that, unlike in most collections, this method is *NOT* a
> constant-time operation. Because of the asynchronous nature of these
> queues, determining the current number of elements requires an O(n)
> traversal. Additionally, if elements are added or removed during execution
> of this method, the returned result may be inaccurate. Thus, this method is
> typically not very useful in concurrent applications.
>
> What's the benefit in changing this now?
>
> I claim the current impl. is by design.
>
> On Sat, Sep 22, 2018 at 8:37 PM Dr Heinz M. Kabutz via
> Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>
>> We could increment before actually adding.  Both queues where this would
>> apply are unbounded so we can assume it will add eventually. For remove we
>> could decrement only if it was successfully removed.
>>
>> To avoid one hot field, Nathan suggested to me to use two AtomicLongs,
>> one for adds and one for removes.  Size would return the difference.
>>
>> Heinz
>>
>> On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com>
>> wrote:
>>
>>> Right.
>>>
>>> If the counter update is not atomic with the adding/removing of the
>>> elements, then you may get to add an element, then remove the element, then
>>> reduce the count as part of removing, then read a negative size(), and only
>>> then increment the count as part of the adding.
>>>
>>>
>>> Alex
>>>
>>> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
>>> >
>>> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <
>>> oleksandr.otenko at gmail.com> wrote:
>>> >> What use is the size() in a concurrent setting? It can only be an
>>> estimate
>>> >
>>> > Some library methods call size(), in the hope that it might optimize
>>> > some other code.
>>> >
>>> > Even when size() is only an estimate, it may be useful.
>>> >
>>> > Surely we would want size() to never return a negative value (we
>>> > probably have buglets where size overflows 32-bit).
>>>
>>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun/Oracle Java Champion
>> JavaOne Rockstar Speaker
>> http://www.javaspecialists.eu
>>
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> --
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion
JavaOne Rockstar Speaker
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/9479457b/attachment.html>

From nigro.fra at gmail.com  Sun Sep 23 03:57:24 2018
From: nigro.fra at gmail.com (Francesco Nigro)
Date: Sun, 23 Sep 2018 09:57:24 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
 <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
Message-ID: <CAKxGtTUnNVY=qxFpQKPubcj-SHrrx-Xx7EtMbc1Fv1my5Vw6Pg@mail.gmail.com>

Hi guys!

To echo what Dr. Heinz suggested, on JCTools queues is being used a similar
method
https://github.com/JCTools/JCTools/blob/master/jctools-core/src/main/java/org/jctools/queues/IndexedQueueSizeUtil.java#L21
The only downside I see is that both producer/consumer sequences (given the
multi producer/consumer nature) would fall into some perf penalty with both
LongAdder (due to the many pointer chasing indirections) or
incrementAndAdd-ish operations (due to the sequential consistent semantic).
Only measuring would say the truth...

Cheers,
Francesco


Il 23 set 2018 05:37, "Dr Heinz M. Kabutz via Concurrency-interest" <
concurrency-interest at cs.oswego.edu> ha scritto:

We could increment before actually adding.  Both queues where this would
apply are unbounded so we can assume it will add eventually. For remove we
could decrement only if it was successfully removed.

To avoid one hot field, Nathan suggested to me to use two AtomicLongs, one
for adds and one for removes.  Size would return the difference.

Heinz

On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> Right.
>
> If the counter update is not atomic with the adding/removing of the
> elements, then you may get to add an element, then remove the element, then
> reduce the count as part of removing, then read a negative size(), and only
> then increment the count as part of the adding.
>
>
> Alex
>
> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
> >
> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
> >> What use is the size() in a concurrent setting? It can only be an
> estimate
> >
> > Some library methods call size(), in the hope that it might optimize
> > some other code.
> >
> > Even when size() is only an estimate, it may be useful.
> >
> > Surely we would want size() to never return a negative value (we
> > probably have buglets where size overflows 32-bit).
>
> --
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion
JavaOne Rockstar Speaker
http://www.javaspecialists.eu

Tel: +30 69 75 595 262
Skype: kabutz
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/b591df4a/attachment-0001.html>

From heinz at javaspecialists.eu  Sun Sep 23 04:50:20 2018
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Sun, 23 Sep 2018 10:50:20 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CAKxGtTUnNVY=qxFpQKPubcj-SHrrx-Xx7EtMbc1Fv1my5Vw6Pg@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
 <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
 <CAKxGtTUnNVY=qxFpQKPubcj-SHrrx-Xx7EtMbc1Fv1my5Vw6Pg@mail.gmail.com>
Message-ID: <CACLL95oFvJMnLApz24Wd84h5=aifvF44mDh4fDzR7cQT3W9bUA@mail.gmail.com>

I ran some basic tests to see under what circumstances a LongAdder or
AtomicInteger would show up as a bottleneck and came up empty.   CLQ is a
good general unbounded MPMC implementation, but there are faster approaches
in JCTools when we can restrict the use case somewhat.  Or maybe my tests
were just a bit too basic.

LongAdder can use a lot of memory if there is contention, so I’d probably
use two long fields with VarHandle access.

Heinz

On Sun, 23 Sep 2018 at 09:57, Francesco Nigro <nigro.fra at gmail.com> wrote:

> Hi guys!
>
> To echo what Dr. Heinz suggested, on JCTools queues is being used a
> similar method
> https://github.com/JCTools/JCTools/blob/master/jctools-core/src/main/java/org/jctools/queues/IndexedQueueSizeUtil.java#L21
> The only downside I see is that both producer/consumer sequences (given
> the multi producer/consumer nature) would fall into some perf penalty with
> both LongAdder (due to the many pointer chasing indirections) or
> incrementAndAdd-ish operations (due to the sequential consistent semantic).
> Only measuring would say the truth...
>
> Cheers,
> Francesco
>
>
> Il 23 set 2018 05:37, "Dr Heinz M. Kabutz via Concurrency-interest" <
> concurrency-interest at cs.oswego.edu> ha scritto:
>
> We could increment before actually adding.  Both queues where this would
> apply are unbounded so we can assume it will add eventually. For remove we
> could decrement only if it was successfully removed.
>
> To avoid one hot field, Nathan suggested to me to use two AtomicLongs, one
> for adds and one for removes.  Size would return the difference.
>
> Heinz
>
> On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
>
>> Right.
>>
>> If the counter update is not atomic with the adding/removing of the
>> elements, then you may get to add an element, then remove the element, then
>> reduce the count as part of removing, then read a negative size(), and only
>> then increment the count as part of the adding.
>>
>>
>> Alex
>>
>> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
>> >
>> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <
>> oleksandr.otenko at gmail.com> wrote:
>> >> What use is the size() in a concurrent setting? It can only be an
>> estimate
>> >
>> > Some library methods call size(), in the hope that it might optimize
>> > some other code.
>> >
>> > Even when size() is only an estimate, it may be useful.
>> >
>> > Surely we would want size() to never return a negative value (we
>> > probably have buglets where size overflows 32-bit).
>>
>> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu
>
> Tel: +30 69 75 595 262
> Skype: kabutz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> --
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion
JavaOne Rockstar Speaker
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/db5d142a/attachment.html>

From oleksandr.otenko at gmail.com  Sun Sep 23 04:52:34 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 23 Sep 2018 09:52:34 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
 <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
Message-ID: <56735F18-8B57-44BC-BEB3-79BCC02F8E5E@gmail.com>

It is possible to round negative sizes to zero, too. Counting “accurately” is not the point. The point is whether the consumer is capable of coping with overestimated or underestimated queue size.

Alex

> On 23 Sep 2018, at 04:13, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:
> 
> We could increment before actually adding.  Both queues where this would apply are unbounded so we can assume it will add eventually. For remove we could decrement only if it was successfully removed. 
> 
> To avoid one hot field, Nathan suggested to me to use two AtomicLongs, one for adds and one for removes.  Size would return the difference. 
> 
> Heinz
> 
> On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> Right.
> 
> If the counter update is not atomic with the adding/removing of the elements, then you may get to add an element, then remove the element, then reduce the count as part of removing, then read a negative size(), and only then increment the count as part of the adding.
> 
> 
> Alex
> 
> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com <mailto:martinrb at google.com>> wrote:
> > 
> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> >> What use is the size() in a concurrent setting? It can only be an estimate
> > 
> > Some library methods call size(), in the hope that it might optimize
> > some other code.
> > 
> > Even when size() is only an estimate, it may be useful.
> > 
> > Surely we would want size() to never return a negative value (we
> > probably have buglets where size overflows 32-bit).
> 
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu <http://www.javaspecialists.eu/>
> Tel: +30 69 75 595 262
> Skype: kabutz

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/79422334/attachment.html>

From nigro.fra at gmail.com  Sun Sep 23 05:51:02 2018
From: nigro.fra at gmail.com (Francesco Nigro)
Date: Sun, 23 Sep 2018 11:51:02 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95oFvJMnLApz24Wd84h5=aifvF44mDh4fDzR7cQT3W9bUA@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <CA+kOe0-202JMLS1LZK6gNo0np7FWEzgPDB+g9+djU6XZTx2wcQ@mail.gmail.com>
 <09C3D08B-6A65-417F-90F3-CEEDF3A81250@gmail.com>
 <CA+kOe0_tFLs_4qvivB+oZQE_E9K=Wv6A0v7LqimhHO_qUiaYMQ@mail.gmail.com>
 <5D850A8D-76A4-487D-8C35-C647DCA3A9D6@gmail.com>
 <CACLL95q8dhyYzgd6o3=kswZ5a2F9K5nnA3+kT8pVkwtkuzxxJA@mail.gmail.com>
 <CAKxGtTUnNVY=qxFpQKPubcj-SHrrx-Xx7EtMbc1Fv1my5Vw6Pg@mail.gmail.com>
 <CACLL95oFvJMnLApz24Wd84h5=aifvF44mDh4fDzR7cQT3W9bUA@mail.gmail.com>
Message-ID: <CAKxGtTUSvzH9wybbe_4_AJ8E9XPDNfJixVrZjMNB0XKc-Up=Hw@mail.gmail.com>

> LongAdder can use a lot of memory if there is contention, so I’d probably
use two long fields with VarHandle access.

+100
Given that there isn't any indication on the CLQ doc to not use in an
highly concurrent scenario I suspect that incrementAndGet (on jdk >= 8 and
properly padded) woudn't be the bottleneck if compared to CLQ's cas:
a LongAdder instead will add stealthy effects without adding any real value.




Il dom 23 set 2018, 10:50 Dr Heinz M. Kabutz <heinz at javaspecialists.eu> ha
scritto:

> I ran some basic tests to see under what circumstances a LongAdder or
> AtomicInteger would show up as a bottleneck and came up empty.   CLQ is a
> good general unbounded MPMC implementation, but there are faster approaches
> in JCTools when we can restrict the use case somewhat.  Or maybe my tests
> were just a bit too basic.
>
> LongAdder can use a lot of memory if there is contention, so I’d probably
> use two long fields with VarHandle access.
>
> Heinz
>
> On Sun, 23 Sep 2018 at 09:57, Francesco Nigro <nigro.fra at gmail.com> wrote:
>
>> Hi guys!
>>
>> To echo what Dr. Heinz suggested, on JCTools queues is being used a
>> similar method
>> https://github.com/JCTools/JCTools/blob/master/jctools-core/src/main/java/org/jctools/queues/IndexedQueueSizeUtil.java#L21
>> The only downside I see is that both producer/consumer sequences (given
>> the multi producer/consumer nature) would fall into some perf penalty with
>> both LongAdder (due to the many pointer chasing indirections) or
>> incrementAndAdd-ish operations (due to the sequential consistent semantic).
>> Only measuring would say the truth...
>>
>> Cheers,
>> Francesco
>>
>>
>> Il 23 set 2018 05:37, "Dr Heinz M. Kabutz via Concurrency-interest" <
>> concurrency-interest at cs.oswego.edu> ha scritto:
>>
>> We could increment before actually adding.  Both queues where this would
>> apply are unbounded so we can assume it will add eventually. For remove we
>> could decrement only if it was successfully removed.
>>
>> To avoid one hot field, Nathan suggested to me to use two AtomicLongs,
>> one for adds and one for removes.  Size would return the difference.
>>
>> Heinz
>>
>> On Sun, 23 Sep 2018 at 01:48, Alex Otenko <oleksandr.otenko at gmail.com>
>> wrote:
>>
>>> Right.
>>>
>>> If the counter update is not atomic with the adding/removing of the
>>> elements, then you may get to add an element, then remove the element, then
>>> reduce the count as part of removing, then read a negative size(), and only
>>> then increment the count as part of the adding.
>>>
>>>
>>> Alex
>>>
>>> > On 22 Sep 2018, at 23:12, Martin Buchholz <martinrb at google.com> wrote:
>>> >
>>> > On Sat, Sep 22, 2018 at 2:53 PM, Alex Otenko <
>>> oleksandr.otenko at gmail.com> wrote:
>>> >> What use is the size() in a concurrent setting? It can only be an
>>> estimate
>>> >
>>> > Some library methods call size(), in the hope that it might optimize
>>> > some other code.
>>> >
>>> > Even when size() is only an estimate, it may be useful.
>>> >
>>> > Surely we would want size() to never return a negative value (we
>>> > probably have buglets where size overflows 32-bit).
>>>
>>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun/Oracle Java Champion
>> JavaOne Rockstar Speaker
>> http://www.javaspecialists.eu
>>
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/2df75a6e/attachment-0001.html>

From dl at cs.oswego.edu  Sun Sep 23 07:07:52 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 23 Sep 2018 07:07:52 -0400
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <5BA3BD93.7020204@javaspecialists.eu>
References: <5BA3BD93.7020204@javaspecialists.eu>
Message-ID: <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>

On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest wrote:
> Most likely too basic for this audience ... :-)
> 
> Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
> multi-threaded environment, because it counts the number of elements in
> the queue, rather than relying on a "hot field" to store the size. The
> result might be completely incorrect, or in strange situations, never
> return.
> 
> Full article: https://www.javaspecialists.eu/archive/Issue261.html
> 

This was one of the very first API design issues in j.u.c (some of the
discussions are probably in old concurrency-interest
archives): Should concurrent queues be forced to implement Collection?
Because supporting both the size() and remove(x) methods are
problematic, the initial versions included unrelated interface
"Channel". But people successfully argued for integrating with
Collections via Queue interface, even though it forces choice among bad
implementation options. For size(), the simplest is to add a sequence
field to each node, ensuring that it is one greater than predecessor
when CASing in. This leads to fast and accurate size(), at the expense
of a 25% increase in space. Another is to add an atomic counter, which
adds contention and still presents before-vs-after increment
inaccuracies. The third, which we adopted, is to traverse, with all the
disadvantages mentioned in the article. As others have mentioned, the
main rationale is that people should not be calling size for any kind of
synchronization control anyway; for occasional uses in monitoring etc,
the slow and inaccurate version is normally OK. We now have a few more
options available (LongAdder or variants), but the same arguments for
the status quo still seem to apply.


-Doug



From heinz at javaspecialists.eu  Sun Sep 23 08:28:28 2018
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Sun, 23 Sep 2018 14:28:28 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
Message-ID: <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>

On Sun, 23 Sep 2018 at 14:05, Doug Lea via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest wrote:
> > Most likely too basic for this audience ... :-)
> >
> > Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
> > multi-threaded environment, because it counts the number of elements in
> > the queue, rather than relying on a "hot field" to store the size. The
> > result might be completely incorrect, or in strange situations, never
> > return.
> >
> > Full article: https://www.javaspecialists.eu/archive/Issue261.html
> >
>
> This was one of the very first API design issues in j.u.c (some of the
> discussions are probably in old concurrency-interest
> archives): Should concurrent queues be forced to implement Collection?
> Because supporting both the size() and remove(x) methods are
> problematic, the initial versions included unrelated interface
> "Channel". But people successfully argued for integrating with
> Collections via Queue interface, even though it forces choice among bad
> implementation options. For size(), the simplest is to add a sequence
> field to each node, ensuring that it is one greater than predecessor
> when CASing in. This leads to fast and accurate size(), at the expense
> of a 25% increase in space.


On 64-bit with compressed oops, each node is 12+4+4 bytes, which is rounded
up to 24 bytes.  Thus in terms of memory usage the extra int would be free
on that architecture.

That said, I think the case of removal in the middle would then also give
us wrong results.

Another is to add an atomic counter, which
> adds contention and still presents before-vs-after increment
> inaccuracies. The third, which we adopted, is to traverse, with all the
> disadvantages mentioned in the article. As others have mentioned, the
> main rationale is that people should not be calling size for any kind of
> synchronization control anyway; for occasional uses in monitoring etc,
> the slow and inaccurate version is normally OK. We now have a few more
> options available (LongAdder or variants), but the same arguments for
> the status quo still seem to apply.


In my newsletter i was mainly pointing out the behavior, rather than
suggesting ways to fix it, because I’ve seen a lot of puzzled faces from
experienced Java programmers over the years.



>
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion
JavaOne Rockstar Speaker
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/e3bc2e32/attachment.html>

From dl at cs.oswego.edu  Sun Sep 23 08:38:39 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 23 Sep 2018 08:38:39 -0400
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
Message-ID: <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>

On 09/23/2018 08:28 AM, Dr Heinz M. Kabutz wrote:

>     Collections via Queue interface, even though it forces choice among bad
>     implementation options. For size(), the simplest is to add a sequence
>     field to each node, ensuring that it is one greater than predecessor
>     when CASing in. This leads to fast and accurate size(), at the expense
>     of a 25% increase in space. 
> 
> 
> On 64-bit with compressed oops, each node is 12+4+4 bytes, which is
> rounded up to 24 bytes.  Thus in terms of memory usage the extra int
> would be free on that architecture.
> 
> That said, I think the case of removal in the middle would then also
> give us wrong results.   

Now "wrong", but internal remove(x) would be even slower: the method
would need to retraverse and atomically increment each sequence number
of each predecessor.

-Doug




> 
>     Another is to add an atomic counter, which
>     adds contention and still presents before-vs-after increment
>     inaccuracies. The third, which we adopted, is to traverse, with all the
>     disadvantages mentioned in the article. As others have mentioned, the
>     main rationale is that people should not be calling size for any kind of
>     synchronization control anyway; for occasional uses in monitoring etc,
>     the slow and inaccurate version is normally OK. We now have a few more
>     options available (LongAdder or variants), but the same arguments for
>     the status quo still seem to apply.
> 
> 
> In my newsletter i was mainly pointing out the behavior, rather than
> suggesting ways to fix it, because I’ve seen a lot of puzzled faces from
> experienced Java programmers over the years. 
> 
> 
> 
> 
> 
>     -Doug
> 
> 
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz



From oleksandr.otenko at gmail.com  Sun Sep 23 09:14:44 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 23 Sep 2018 14:14:44 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
Message-ID: <9D4681EB-C4CD-4889-A669-04AB8D6252ED@gmail.com>

I think you need to start with what a “correct result” means.

First the queue is forced to be a Collection, then we find that the methods cannot be implemented “correctly” :-) Maybe it isn’t a Collection?


Alex

> On 23 Sep 2018, at 13:28, Dr Heinz M. Kabutz via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> 
> 
> On Sun, 23 Sep 2018 at 14:05, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>> wrote:
> On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest wrote:
> > Most likely too basic for this audience ... :-)
> > 
> > Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
> > multi-threaded environment, because it counts the number of elements in
> > the queue, rather than relying on a "hot field" to store the size. The
> > result might be completely incorrect, or in strange situations, never
> > return.
> > 
> > Full article: https://www.javaspecialists.eu/archive/Issue261.html <https://www.javaspecialists.eu/archive/Issue261.html>
> > 
> 
> This was one of the very first API design issues in j.u.c (some of the
> discussions are probably in old concurrency-interest
> archives): Should concurrent queues be forced to implement Collection?
> Because supporting both the size() and remove(x) methods are
> problematic, the initial versions included unrelated interface
> "Channel". But people successfully argued for integrating with
> Collections via Queue interface, even though it forces choice among bad
> implementation options. For size(), the simplest is to add a sequence
> field to each node, ensuring that it is one greater than predecessor
> when CASing in. This leads to fast and accurate size(), at the expense
> of a 25% increase in space. 
> 
> On 64-bit with compressed oops, each node is 12+4+4 bytes, which is rounded up to 24 bytes.  Thus in terms of memory usage the extra int would be free on that architecture.
> 
> That said, I think the case of removal in the middle would then also give us wrong results.   
> 
> Another is to add an atomic counter, which
> adds contention and still presents before-vs-after increment
> inaccuracies. The third, which we adopted, is to traverse, with all the
> disadvantages mentioned in the article. As others have mentioned, the
> main rationale is that people should not be calling size for any kind of
> synchronization control anyway; for occasional uses in monitoring etc,
> the slow and inaccurate version is normally OK. We now have a few more
> options available (LongAdder or variants), but the same arguments for
> the status quo still seem to apply.
> 
> In my newsletter i was mainly pointing out the behavior, rather than suggesting ways to fix it, because I’ve seen a lot of puzzled faces from experienced Java programmers over the years. 
> 
> 
> 
> 
> 
> -Doug
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu <http://www.javaspecialists.eu/>
> Tel: +30 69 75 595 262
> Skype: kabutz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/3b744023/attachment-0001.html>

From oleksandr.otenko at gmail.com  Sun Sep 23 09:18:02 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 23 Sep 2018 14:18:02 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
Message-ID: <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>

I don’t think you can do that reliably. In the end, who’s faster: a consumer removing elements, or remove(x) incrementing the sequence numbers? There will be subtle races showing up as weird values for size().

Alex

> On 23 Sep 2018, at 13:38, Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> On 09/23/2018 08:28 AM, Dr Heinz M. Kabutz wrote:
> 
>>    Collections via Queue interface, even though it forces choice among bad
>>    implementation options. For size(), the simplest is to add a sequence
>>    field to each node, ensuring that it is one greater than predecessor
>>    when CASing in. This leads to fast and accurate size(), at the expense
>>    of a 25% increase in space. 
>> 
>> 
>> On 64-bit with compressed oops, each node is 12+4+4 bytes, which is
>> rounded up to 24 bytes.  Thus in terms of memory usage the extra int
>> would be free on that architecture.
>> 
>> That said, I think the case of removal in the middle would then also
>> give us wrong results.   
> 
> Now "wrong", but internal remove(x) would be even slower: the method
> would need to retraverse and atomically increment each sequence number
> of each predecessor.
> 
> -Doug
> 
> 
> 
> 
>> 
>>    Another is to add an atomic counter, which
>>    adds contention and still presents before-vs-after increment
>>    inaccuracies. The third, which we adopted, is to traverse, with all the
>>    disadvantages mentioned in the article. As others have mentioned, the
>>    main rationale is that people should not be calling size for any kind of
>>    synchronization control anyway; for occasional uses in monitoring etc,
>>    the slow and inaccurate version is normally OK. We now have a few more
>>    options available (LongAdder or variants), but the same arguments for
>>    the status quo still seem to apply.
>> 
>> 
>> In my newsletter i was mainly pointing out the behavior, rather than
>> suggesting ways to fix it, because I’ve seen a lot of puzzled faces from
>> experienced Java programmers over the years. 
>> 
>> 
>> 
>> 
>> 
>>    -Doug
>> 
>> 
>>    _______________________________________________
>>    Concurrency-interest mailing list
>>    Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>    <mailto:Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>>
>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> -- 
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun/Oracle Java Champion
>> JavaOne Rockstar Speaker
>> http://www.javaspecialists.eu
>> Tel: +30 69 75 595 262
>> Skype: kabutz
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/5f073a93/attachment.html>

From dl at cs.oswego.edu  Sun Sep 23 09:38:42 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 23 Sep 2018 09:38:42 -0400
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
Message-ID: <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>

On 09/23/2018 09:18 AM, Alex Otenko wrote:
> I don’t think you can do that reliably. In the end, who’s faster: a 
> consumer removing elements, or remove(x) incrementing the sequence 
> numbers? There will be subtle races showing up as weird values for
> size().

To first answer:

> I think you need to start with what a “correct result” means.
> 
> First the queue is forced to be a Collection, then we find that the
> methods cannot be implemented “correctly” :-) Maybe it isn’t a
> Collection?
> 

I initially resisted integrating with Collection on these grounds. But
one argument in favor is that implementations can at least preserve
quiescent consistency: results for one thread meet specs if no other
threads execute. This is the notion underlying all j.u.c methods that
contain "not for use in synchronization control" disclaimers.  Also, all
j.u.c queues, being Collections, are iterable, so already have defined
weak consistency properties on these grounds. So any solution based on
traversal is no worse than what people could do themselves; and some
surely would do so if we did not supply the method.

Given all this, using sequence numbers could provide stronger guarantees
(but with an unattractive time/space tradeoff) in the absence of
internal remove, but no better than now in their presence.

-Doug


> 
> Alex
> 
>> On 23 Sep 2018, at 13:38, Doug Lea via Concurrency-interest 
>> <concurrency-interest at cs.oswego.edu 
>> <mailto:concurrency-interest at cs.oswego.edu>> wrote:
>> 
>> On 09/23/2018 08:28 AM, Dr Heinz M. Kabutz wrote:
>> 
>>> Collections via Queue interface, even though it forces choice 
>>> among bad implementation options. For size(), the simplest is to
>>> add a sequence field to each node, ensuring that it is one
>>> greater than predecessor when CASing in. This leads to fast and
>>> accurate size(), at the expense of a 25% increase in space.
>>> 
>>> 
>>> On 64-bit with compressed oops, each node is 12+4+4 bytes, which
>>> is rounded up to 24 bytes.  Thus in terms of memory usage the
>>> extra int would be free on that architecture.
>>> 
>>> That said, I think the case of removal in the middle would then
>>> also give us wrong results.
>> 
>> Now "wrong", but internal remove(x) would be even slower: the
>> method would need to retraverse and atomically increment each
>> sequence number of each predecessor.
>> 
>> -Doug
>> 
>> 
>> 
>> 
>>> 
>>> Another is to add an atomic counter, which adds contention and
>>> still presents before-vs-after increment inaccuracies. The third,
>>> which we adopted, is to traverse, with all the disadvantages
>>> mentioned in the article. As others have mentioned, the main
>>> rationale is that people should not be calling size for any kind
>>> of synchronization control anyway; for occasional uses in
>>> monitoring etc, the slow and inaccurate version is normally OK.
>>> We now have a few more options available (LongAdder or variants),
>>> but the same arguments for the status quo still seem to apply.
>>> 
>>> 
>>> In my newsletter i was mainly pointing out the behavior, rather
>>> than suggesting ways to fix it, because I’ve seen a lot of
>>> puzzled faces from experienced Java programmers over the years.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> -Doug
>>> 
>>> 
>>> _______________________________________________ 
>>> Concurrency-interest mailing list 
>>> Concurrency-interest at cs.oswego.edu 
>>> <mailto:Concurrency-interest at cs.oswego.edu> 
>>> <mailto:Concurrency-interest at cs.oswego.edu> 
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>>> -- Dr Heinz M. Kabutz (PhD CompSci) Author of "The Java(tm)
>>> Specialists' Newsletter" Sun/Oracle Java Champion JavaOne
>>> Rockstar Speaker http://www.javaspecialists.eu Tel: +30 69 75 595
>>> 262 Skype: kabutz
>> 
>> 
>> _______________________________________________ 
>> Concurrency-interest mailing list 
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu> 
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 



From viktor.klang at gmail.com  Sun Sep 23 09:45:49 2018
From: viktor.klang at gmail.com (Viktor Klang)
Date: Sun, 23 Sep 2018 15:45:49 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <9D4681EB-C4CD-4889-A669-04AB8D6252ED@gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9D4681EB-C4CD-4889-A669-04AB8D6252ED@gmail.com>
Message-ID: <CANPzfU-ANRkeZXcVBAK1B6Y8eDqG6_VXCDzU7hSze2uHCXn-jA@mail.gmail.com>

If it is used as a Collection then it will give expected results ;)

On Sun, 23 Sep 2018 at 15:42, Alex Otenko via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> I think you need to start with what a “correct result” means.
>
> First the queue is forced to be a Collection, then we find that the
> methods cannot be implemented “correctly” :-) Maybe it isn’t a Collection?
>
>
> Alex
>
> On 23 Sep 2018, at 13:28, Dr Heinz M. Kabutz via Concurrency-interest <
> concurrency-interest at cs.oswego.edu> wrote:
>
>
>
> On Sun, 23 Sep 2018 at 14:05, Doug Lea via Concurrency-interest <
> concurrency-interest at cs.oswego.edu> wrote:
>
>> On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest wrote:
>> > Most likely too basic for this audience ... :-)
>> >
>> > Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
>> > multi-threaded environment, because it counts the number of elements in
>> > the queue, rather than relying on a "hot field" to store the size. The
>> > result might be completely incorrect, or in strange situations, never
>> > return.
>> >
>> > Full article: https://www.javaspecialists.eu/archive/Issue261.html
>> >
>>
>> This was one of the very first API design issues in j.u.c (some of the
>> discussions are probably in old concurrency-interest
>> archives): Should concurrent queues be forced to implement Collection?
>> Because supporting both the size() and remove(x) methods are
>> problematic, the initial versions included unrelated interface
>> "Channel". But people successfully argued for integrating with
>> Collections via Queue interface, even though it forces choice among bad
>> implementation options. For size(), the simplest is to add a sequence
>> field to each node, ensuring that it is one greater than predecessor
>> when CASing in. This leads to fast and accurate size(), at the expense
>> of a 25% increase in space.
>
>
> On 64-bit with compressed oops, each node is 12+4+4 bytes, which is
> rounded up to 24 bytes.  Thus in terms of memory usage the extra int would
> be free on that architecture.
>
> That said, I think the case of removal in the middle would then also give
> us wrong results.
>
> Another is to add an atomic counter, which
>> adds contention and still presents before-vs-after increment
>> inaccuracies. The third, which we adopted, is to traverse, with all the
>> disadvantages mentioned in the article. As others have mentioned, the
>> main rationale is that people should not be calling size for any kind of
>> synchronization control anyway; for occasional uses in monitoring etc,
>> the slow and inaccurate version is normally OK. We now have a few more
>> options available (LongAdder or variants), but the same arguments for
>> the status quo still seem to apply.
>
>
> In my newsletter i was mainly pointing out the behavior, rather than
> suggesting ways to fix it, because I’ve seen a lot of puzzled faces from
> experienced Java programmers over the years.
>
>
>
>>
>>
>> -Doug
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/6f473550/attachment-0001.html>

From nigro.fra at gmail.com  Sun Sep 23 10:16:12 2018
From: nigro.fra at gmail.com (Francesco Nigro)
Date: Sun, 23 Sep 2018 16:16:12 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
Message-ID: <CAKxGtTV==e++gOny0MvBRY5_573Decdrs88BOUqW4k28r9bpUw@mail.gmail.com>

Sorry to be OT but now I'm curious about the original Channel API proposal
:)

Il dom 23 set 2018, 14:01 Doug Lea via Concurrency-interest <
concurrency-interest at cs.oswego.edu> ha scritto:

> On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest wrote:
> > Most likely too basic for this audience ... :-)
> >
> > Abstract: ConcurrentLinkedQueue's size() method is not very useful in a
> > multi-threaded environment, because it counts the number of elements in
> > the queue, rather than relying on a "hot field" to store the size. The
> > result might be completely incorrect, or in strange situations, never
> > return.
> >
> > Full article: https://www.javaspecialists.eu/archive/Issue261.html
> >
>
> This was one of the very first API design issues in j.u.c (some of the
> discussions are probably in old concurrency-interest
> archives): Should concurrent queues be forced to implement Collection?
> Because supporting both the size() and remove(x) methods are
> problematic, the initial versions included unrelated interface
> "Channel". But people successfully argued for integrating with
> Collections via Queue interface, even though it forces choice among bad
> implementation options. For size(), the simplest is to add a sequence
> field to each node, ensuring that it is one greater than predecessor
> when CASing in. This leads to fast and accurate size(), at the expense
> of a 25% increase in space. Another is to add an atomic counter, which
> adds contention and still presents before-vs-after increment
> inaccuracies. The third, which we adopted, is to traverse, with all the
> disadvantages mentioned in the article. As others have mentioned, the
> main rationale is that people should not be calling size for any kind of
> synchronization control anyway; for occasional uses in monitoring etc,
> the slow and inaccurate version is normally OK. We now have a few more
> options available (LongAdder or variants), but the same arguments for
> the status quo still seem to apply.
>
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/40c09094/attachment.html>

From dl at cs.oswego.edu  Sun Sep 23 10:25:54 2018
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 23 Sep 2018 10:25:54 -0400
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CAKxGtTV==e++gOny0MvBRY5_573Decdrs88BOUqW4k28r9bpUw@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CAKxGtTV==e++gOny0MvBRY5_573Decdrs88BOUqW4k28r9bpUw@mail.gmail.com>
Message-ID: <dc3f25be-0378-9658-efb6-224d0759b343@cs.oswego.edu>

On 09/23/2018 10:16 AM, Francesco Nigro wrote:
> Sorry to be OT but now I'm curious about the original Channel API
> proposal :)

Basically, the methods introduced in Queue, but not extending
Collection. Candidates were based mainly on my pre-j.u.c package
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
; in particular,
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Channel.html

-Doug



> 
> Il dom 23 set 2018, 14:01 Doug Lea via Concurrency-interest
> <concurrency-interest at cs.oswego.edu
> <mailto:concurrency-interest at cs.oswego.edu>> ha scritto:
> 
>     On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest
>     wrote:
>     > Most likely too basic for this audience ... :-)
>     >
>     > Abstract: ConcurrentLinkedQueue's size() method is not very useful
>     in a
>     > multi-threaded environment, because it counts the number of
>     elements in
>     > the queue, rather than relying on a "hot field" to store the size. The
>     > result might be completely incorrect, or in strange situations, never
>     > return.
>     >
>     > Full article: https://www.javaspecialists.eu/archive/Issue261.html
>     >
> 
>     This was one of the very first API design issues in j.u.c (some of the
>     discussions are probably in old concurrency-interest
>     archives): Should concurrent queues be forced to implement Collection?
>     Because supporting both the size() and remove(x) methods are
>     problematic, the initial versions included unrelated interface
>     "Channel". But people successfully argued for integrating with
>     Collections via Queue interface, even though it forces choice among bad
>     implementation options. For size(), the simplest is to add a sequence
>     field to each node, ensuring that it is one greater than predecessor
>     when CASing in. This leads to fast and accurate size(), at the expense
>     of a 25% increase in space. Another is to add an atomic counter, which
>     adds contention and still presents before-vs-after increment
>     inaccuracies. The third, which we adopted, is to traverse, with all the
>     disadvantages mentioned in the article. As others have mentioned, the
>     main rationale is that people should not be calling size for any kind of
>     synchronization control anyway; for occasional uses in monitoring etc,
>     the slow and inaccurate version is normally OK. We now have a few more
>     options available (LongAdder or variants), but the same arguments for
>     the status quo still seem to apply.
> 
> 
>     -Doug
> 
> 
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From nigro.fra at gmail.com  Sun Sep 23 11:56:45 2018
From: nigro.fra at gmail.com (Francesco Nigro)
Date: Sun, 23 Sep 2018 17:56:45 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <dc3f25be-0378-9658-efb6-224d0759b343@cs.oswego.edu>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CAKxGtTV==e++gOny0MvBRY5_573Decdrs88BOUqW4k28r9bpUw@mail.gmail.com>
 <dc3f25be-0378-9658-efb6-224d0759b343@cs.oswego.edu>
Message-ID: <CAKxGtTWLwGZvr7pBhzs86yLeBps3ixRZ_DD=dJGXpdi2No1qQA@mail.gmail.com>

Many thanks, nice one!

Il dom 23 set 2018, 16:25 Doug Lea <dl at cs.oswego.edu> ha scritto:

> On 09/23/2018 10:16 AM, Francesco Nigro wrote:
> > Sorry to be OT but now I'm curious about the original Channel API
> > proposal :)
>
> Basically, the methods introduced in Queue, but not extending
> Collection. Candidates were based mainly on my pre-j.u.c package
>
> http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
> ; in particular,
>
> http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Channel.html
>
> -Doug
>
>
>
> >
> > Il dom 23 set 2018, 14:01 Doug Lea via Concurrency-interest
> > <concurrency-interest at cs.oswego.edu
> > <mailto:concurrency-interest at cs.oswego.edu>> ha scritto:
> >
> >     On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest
> >     wrote:
> >     > Most likely too basic for this audience ... :-)
> >     >
> >     > Abstract: ConcurrentLinkedQueue's size() method is not very useful
> >     in a
> >     > multi-threaded environment, because it counts the number of
> >     elements in
> >     > the queue, rather than relying on a "hot field" to store the size.
> The
> >     > result might be completely incorrect, or in strange situations,
> never
> >     > return.
> >     >
> >     > Full article: https://www.javaspecialists.eu/archive/Issue261.html
> >     >
> >
> >     This was one of the very first API design issues in j.u.c (some of
> the
> >     discussions are probably in old concurrency-interest
> >     archives): Should concurrent queues be forced to implement
> Collection?
> >     Because supporting both the size() and remove(x) methods are
> >     problematic, the initial versions included unrelated interface
> >     "Channel". But people successfully argued for integrating with
> >     Collections via Queue interface, even though it forces choice among
> bad
> >     implementation options. For size(), the simplest is to add a sequence
> >     field to each node, ensuring that it is one greater than predecessor
> >     when CASing in. This leads to fast and accurate size(), at the
> expense
> >     of a 25% increase in space. Another is to add an atomic counter,
> which
> >     adds contention and still presents before-vs-after increment
> >     inaccuracies. The third, which we adopted, is to traverse, with all
> the
> >     disadvantages mentioned in the article. As others have mentioned, the
> >     main rationale is that people should not be calling size for any
> kind of
> >     synchronization control anyway; for occasional uses in monitoring
> etc,
> >     the slow and inaccurate version is normally OK. We now have a few
> more
> >     options available (LongAdder or variants), but the same arguments for
> >     the status quo still seem to apply.
> >
> >
> >     -Doug
> >
> >
> >     _______________________________________________
> >     Concurrency-interest mailing list
> >     Concurrency-interest at cs.oswego.edu
> >     <mailto:Concurrency-interest at cs.oswego.edu>
> >     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
Il 23 set 2018 4:25 PM, "Doug Lea" <dl at cs.oswego.edu> ha scritto:

On 09/23/2018 10:16 AM, Francesco Nigro wrote:
> Sorry to be OT but now I'm curious about the original Channel API
> proposal :)

Basically, the methods introduced in Queue, but not extending
Collection. Candidates were based mainly on my pre-j.u.c package
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
; in particular,
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Channel.html

-Doug




>
> Il dom 23 set 2018, 14:01 Doug Lea via Concurrency-interest
> <concurrency-interest at cs.oswego.edu
> <mailto:concurrency-interest at cs.oswego.edu>> ha scritto:

>
>     On 09/20/2018 11:32 AM, Dr Heinz M. Kabutz via Concurrency-interest
>     wrote:
>     > Most likely too basic for this audience ... :-)
>     >
>     > Abstract: ConcurrentLinkedQueue's size() method is not very useful
>     in a
>     > multi-threaded environment, because it counts the number of
>     elements in
>     > the queue, rather than relying on a "hot field" to store the size.
The
>     > result might be completely incorrect, or in strange situations,
never
>     > return.
>     >
>     > Full article: https://www.javaspecialists.eu/archive/Issue261.html
>     >
>
>     This was one of the very first API design issues in j.u.c (some of the
>     discussions are probably in old concurrency-interest
>     archives): Should concurrent queues be forced to implement Collection?
>     Because supporting both the size() and remove(x) methods are
>     problematic, the initial versions included unrelated interface
>     "Channel". But people successfully argued for integrating with
>     Collections via Queue interface, even though it forces choice among
bad
>     implementation options. For size(), the simplest is to add a sequence
>     field to each node, ensuring that it is one greater than predecessor
>     when CASing in. This leads to fast and accurate size(), at the expense
>     of a 25% increase in space. Another is to add an atomic counter, which
>     adds contention and still presents before-vs-after increment
>     inaccuracies. The third, which we adopted, is to traverse, with all
the
>     disadvantages mentioned in the article. As others have mentioned, the
>     main rationale is that people should not be calling size for any kind
of
>     synchronization control anyway; for occasional uses in monitoring etc,
>     the slow and inaccurate version is normally OK. We now have a few more
>     options available (LongAdder or variants), but the same arguments for
>     the status quo still seem to apply.
>
>
>     -Doug
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/c6ca518b/attachment-0001.html>

From jbloch at gmail.com  Sun Sep 23 16:53:57 2018
From: jbloch at gmail.com (Joshua Bloch)
Date: Sun, 23 Sep 2018 16:53:57 -0400
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
Message-ID: <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>

Collection and friends have always been intentionally permissive in their
semantics, to permit atypical implementations. That said, the only reason
to implement it is because it's useful to programmers to do so. In this
case, I suspect the primary use is that it ensures that standard methods
have the correct names and signatures. That's not to be sneezed at, and the
disadvantages seem small, right? Sequence numbers feel like overkill.

On Sun, Sep 23, 2018 at 10:20 AM Doug Lea via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> On 09/23/2018 09:18 AM, Alex Otenko wrote:
> > I don’t think you can do that reliably. In the end, who’s faster: a
> > consumer removing elements, or remove(x) incrementing the sequence
> > numbers? There will be subtle races showing up as weird values for
> > size().
>
> To first answer:
>
> > I think you need to start with what a “correct result” means.
> >
> > First the queue is forced to be a Collection, then we find that the
> > methods cannot be implemented “correctly” :-) Maybe it isn’t a
> > Collection?
> >
>
> I initially resisted integrating with Collection on these grounds. But
> one argument in favor is that implementations can at least preserve
> quiescent consistency: results for one thread meet specs if no other
> threads execute. This is the notion underlying all j.u.c methods that
> contain "not for use in synchronization control" disclaimers.  Also, all
> j.u.c queues, being Collections, are iterable, so already have defined
> weak consistency properties on these grounds. So any solution based on
> traversal is no worse than what people could do themselves; and some
> surely would do so if we did not supply the method.
>
> Given all this, using sequence numbers could provide stronger guarantees
> (but with an unattractive time/space tradeoff) in the absence of
> internal remove, but no better than now in their presence.
>
> -Doug
>
>
> >
> > Alex
> >
> >> On 23 Sep 2018, at 13:38, Doug Lea via Concurrency-interest
> >> <concurrency-interest at cs.oswego.edu
> >> <mailto:concurrency-interest at cs.oswego.edu>> wrote:
> >>
> >> On 09/23/2018 08:28 AM, Dr Heinz M. Kabutz wrote:
> >>
> >>> Collections via Queue interface, even though it forces choice
> >>> among bad implementation options. For size(), the simplest is to
> >>> add a sequence field to each node, ensuring that it is one
> >>> greater than predecessor when CASing in. This leads to fast and
> >>> accurate size(), at the expense of a 25% increase in space.
> >>>
> >>>
> >>> On 64-bit with compressed oops, each node is 12+4+4 bytes, which
> >>> is rounded up to 24 bytes.  Thus in terms of memory usage the
> >>> extra int would be free on that architecture.
> >>>
> >>> That said, I think the case of removal in the middle would then
> >>> also give us wrong results.
> >>
> >> Now "wrong", but internal remove(x) would be even slower: the
> >> method would need to retraverse and atomically increment each
> >> sequence number of each predecessor.
> >>
> >> -Doug
> >>
> >>
> >>
> >>
> >>>
> >>> Another is to add an atomic counter, which adds contention and
> >>> still presents before-vs-after increment inaccuracies. The third,
> >>> which we adopted, is to traverse, with all the disadvantages
> >>> mentioned in the article. As others have mentioned, the main
> >>> rationale is that people should not be calling size for any kind
> >>> of synchronization control anyway; for occasional uses in
> >>> monitoring etc, the slow and inaccurate version is normally OK.
> >>> We now have a few more options available (LongAdder or variants),
> >>> but the same arguments for the status quo still seem to apply.
> >>>
> >>>
> >>> In my newsletter i was mainly pointing out the behavior, rather
> >>> than suggesting ways to fix it, because I’ve seen a lot of
> >>> puzzled faces from experienced Java programmers over the years.
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> -Doug
> >>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> <mailto:Concurrency-interest at cs.oswego.edu>
> >>> <mailto:Concurrency-interest at cs.oswego.edu>
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>> -- Dr Heinz M. Kabutz (PhD CompSci) Author of "The Java(tm)
> >>> Specialists' Newsletter" Sun/Oracle Java Champion JavaOne
> >>> Rockstar Speaker http://www.javaspecialists.eu Tel: +30 69 75 595
> >>> 262 Skype: kabutz
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> <mailto:Concurrency-interest at cs.oswego.edu>
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/a26299b6/attachment.html>

From oleksandr.otenko at gmail.com  Sun Sep 23 17:25:25 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 23 Sep 2018 22:25:25 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
Message-ID: <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>

No, it is sequence numbers that you set up non-atomically at creation time, and only update atomically in rare and unlikely circumstances, and likely with no overhead, if Dr Kabutz’s working out is right, vs extra atomic operations for every single put or take to keep the counters for the method that has no use in concurrent scenarios (that only have use for contrived use cases).


Alex

> On 23 Sep 2018, at 21:53, Joshua Bloch <jbloch at gmail.com> wrote:
> 
> Collection and friends have always been intentionally permissive in their semantics, to permit atypical implementations. That said, the only reason to implement it is because it's useful to programmers to do so. In this case, I suspect the primary use is that it ensures that standard methods have the correct names and signatures. That's not to be sneezed at, and the disadvantages seem small, right? Sequence numbers feel like overkill.
> 
> On Sun, Sep 23, 2018 at 10:20 AM Doug Lea via Concurrency-interest <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>> wrote:
> On 09/23/2018 09:18 AM, Alex Otenko wrote:
> > I don’t think you can do that reliably. In the end, who’s faster: a 
> > consumer removing elements, or remove(x) incrementing the sequence 
> > numbers? There will be subtle races showing up as weird values for
> > size().
> 
> To first answer:
> 
> > I think you need to start with what a “correct result” means.
> > 
> > First the queue is forced to be a Collection, then we find that the
> > methods cannot be implemented “correctly” :-) Maybe it isn’t a
> > Collection?
> > 
> 
> I initially resisted integrating with Collection on these grounds. But
> one argument in favor is that implementations can at least preserve
> quiescent consistency: results for one thread meet specs if no other
> threads execute. This is the notion underlying all j.u.c methods that
> contain "not for use in synchronization control" disclaimers.  Also, all
> j.u.c queues, being Collections, are iterable, so already have defined
> weak consistency properties on these grounds. So any solution based on
> traversal is no worse than what people could do themselves; and some
> surely would do so if we did not supply the method.
> 
> Given all this, using sequence numbers could provide stronger guarantees
> (but with an unattractive time/space tradeoff) in the absence of
> internal remove, but no better than now in their presence.
> 
> -Doug
> 
> 
> > 
> > Alex
> > 
> >> On 23 Sep 2018, at 13:38, Doug Lea via Concurrency-interest 
> >> <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> 
> >> <mailto:concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>>> wrote:
> >> 
> >> On 09/23/2018 08:28 AM, Dr Heinz M. Kabutz wrote:
> >> 
> >>> Collections via Queue interface, even though it forces choice 
> >>> among bad implementation options. For size(), the simplest is to
> >>> add a sequence field to each node, ensuring that it is one
> >>> greater than predecessor when CASing in. This leads to fast and
> >>> accurate size(), at the expense of a 25% increase in space.
> >>> 
> >>> 
> >>> On 64-bit with compressed oops, each node is 12+4+4 bytes, which
> >>> is rounded up to 24 bytes.  Thus in terms of memory usage the
> >>> extra int would be free on that architecture.
> >>> 
> >>> That said, I think the case of removal in the middle would then
> >>> also give us wrong results.
> >> 
> >> Now "wrong", but internal remove(x) would be even slower: the
> >> method would need to retraverse and atomically increment each
> >> sequence number of each predecessor.
> >> 
> >> -Doug
> >> 
> >> 
> >> 
> >> 
> >>> 
> >>> Another is to add an atomic counter, which adds contention and
> >>> still presents before-vs-after increment inaccuracies. The third,
> >>> which we adopted, is to traverse, with all the disadvantages
> >>> mentioned in the article. As others have mentioned, the main
> >>> rationale is that people should not be calling size for any kind
> >>> of synchronization control anyway; for occasional uses in
> >>> monitoring etc, the slow and inaccurate version is normally OK.
> >>> We now have a few more options available (LongAdder or variants),
> >>> but the same arguments for the status quo still seem to apply.
> >>> 
> >>> 
> >>> In my newsletter i was mainly pointing out the behavior, rather
> >>> than suggesting ways to fix it, because I’ve seen a lot of
> >>> puzzled faces from experienced Java programmers over the years.
> >>> 
> >>> 
> >>> 
> >>> 
> >>> 
> >>> -Doug
> >>> 
> >>> 
> >>> _______________________________________________ 
> >>> Concurrency-interest mailing list 
> >>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
> >>> <mailto:Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>> 
> >>> <mailto:Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>> 
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> >>> 
> >>> -- Dr Heinz M. Kabutz (PhD CompSci) Author of "The Java(tm)
> >>> Specialists' Newsletter" Sun/Oracle Java Champion JavaOne
> >>> Rockstar Speaker http://www.javaspecialists.eu <http://www.javaspecialists.eu/> Tel: +30 69 75 595
> >>> 262 Skype: kabutz
> >> 
> >> 
> >> _______________________________________________ 
> >> Concurrency-interest mailing list 
> >> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
> >> <mailto:Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>> 
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> > 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180923/6a82b95d/attachment-0001.html>

From martinrb at google.com  Mon Sep 24 17:14:14 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 24 Sep 2018 14:14:14 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
Message-ID: <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>

The conservative maintainers of the concurrent queues are unlikely to
change the implementation.  The behavior of the queues when quiescent
is correct and useful.  Any fix for size() would be unsatisfying if it
did not also apply to toArray().  It might be good to add scare
javadocs about how traversal may end up visiting many more elements
than the high water mark size of the queue (but that "leaks"
implementation details into the javadoc).

From heinz at javaspecialists.eu  Mon Sep 24 19:12:31 2018
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 25 Sep 2018 01:12:31 +0200
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
 <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
Message-ID: <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>

And that in rare circumstances it might never return at all, even for a
queue of essentially fixed length.

On Tue, 25 Sep 2018 at 00:16, Martin Buchholz via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> The conservative maintainers of the concurrent queues are unlikely to
> change the implementation.  The behavior of the queues when quiescent
> is correct and useful.  Any fix for size() would be unsatisfying if it
> did not also apply to toArray().  It might be good to add scare
> javadocs about how traversal may end up visiting many more elements
> than the high water mark size of the queue (but that "leaks"
> implementation details into the javadoc).
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion
JavaOne Rockstar Speaker
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180925/10458ecd/attachment.html>

From martinrb at google.com  Mon Sep 24 20:47:50 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 24 Sep 2018 17:47:50 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
 <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
 <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
Message-ID: <CA+kOe0_1-_oWdJtdGxyPhLZx-LLP+Mv5-Y_QotFt0ZH7JDrp1g@mail.gmail.com>

On Mon, Sep 24, 2018 at 4:12 PM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> And that in rare circumstances it might never return at all, even for a
> queue of essentially fixed length.

Think of it like this - never reaching the end of a traversal is a
problem with many (most?) mutable data structures.  Even iterating
single-threaded over LinkedList could take forever if an element is
enqueued and dequeued at every step.  it's a treadmill.

From notcarl at google.com  Tue Sep 25 00:33:30 2018
From: notcarl at google.com (Carl Mastrangelo)
Date: Mon, 24 Sep 2018 21:33:30 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CA+kOe0_1-_oWdJtdGxyPhLZx-LLP+Mv5-Y_QotFt0ZH7JDrp1g@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
 <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
 <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
 <CA+kOe0_1-_oWdJtdGxyPhLZx-LLP+Mv5-Y_QotFt0ZH7JDrp1g@mail.gmail.com>
Message-ID: <CAAcqB+u7Ym-8LYkzVUwGBqrcK1s1LBjAPtC7xjZNDCWMDUuyDg@mail.gmail.com>

Out of curiosity, suppose that Java had access to 2word atomics
(like CMPXCHG16B on x64).  It might be possible to align the head pointer
with a counter word, and update them both at the same time.  With the tail
pointer, a similar counter could also be updated when offer()ing.   That
would allow size() to be wait free, though likely still inaccurate.

On Mon, Sep 24, 2018 at 6:43 PM Martin Buchholz via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> On Mon, Sep 24, 2018 at 4:12 PM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
> > And that in rare circumstances it might never return at all, even for a
> > queue of essentially fixed length.
>
> Think of it like this - never reaching the end of a traversal is a
> problem with many (most?) mutable data structures.  Even iterating
> single-threaded over LinkedList could take forever if an element is
> enqueued and dequeued at every step.  it's a treadmill.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180924/b6fd9623/attachment.html>

From martinrb at google.com  Tue Sep 25 02:44:35 2018
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 24 Sep 2018 23:44:35 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CAAcqB+u7Ym-8LYkzVUwGBqrcK1s1LBjAPtC7xjZNDCWMDUuyDg@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
 <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
 <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
 <CA+kOe0_1-_oWdJtdGxyPhLZx-LLP+Mv5-Y_QotFt0ZH7JDrp1g@mail.gmail.com>
 <CAAcqB+u7Ym-8LYkzVUwGBqrcK1s1LBjAPtC7xjZNDCWMDUuyDg@mail.gmail.com>
Message-ID: <CA+kOe08=aH2Tj9LNFTkg_aDgaqG=S1HD6w1Czh9+=t1YjvUY8w@mail.gmail.com>

On Mon, Sep 24, 2018 at 9:33 PM, Carl Mastrangelo <notcarl at google.com> wrote:
> Out of curiosity, suppose that Java had access to 2word atomics (like
> CMPXCHG16B on x64).  It might be possible to align the head pointer with a
> counter word, and update them both at the same time.  With the tail pointer,
> a similar counter could also be updated when offer()ing.   That would allow
> size() to be wait free, though likely still inaccurate.

There's interior remove to deal with.

ConcurrentLinkedQueue does not necessarily update head and tail for
each enqueue and dequeue.

There's toArray to deal with, although it could give up after
encountering size() elements.

I don't know whether double-width CAS would be faster or slower than
two single-width CASes.

From oleksandr.otenko at gmail.com  Tue Sep 25 03:40:52 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 25 Sep 2018 08:40:52 +0100
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
 <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
 <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
Message-ID: <22F9D7D5-BDA2-4765-82D9-89EBCD1AD256@gmail.com>

In a concurrent setting non-termination could also be a suspension, too. No one said size() is meant to be lock-free. :-)

Once it is not lock-free, you cannot guarantee the progress of any thread, once some chosen single thread is suspended. This requirement is so weak, that it allows to not guarantee the progress of more than one thread at any time.


Alex

> On 25 Sep 2018, at 00:12, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:
> 
> And that in rare circumstances it might never return at all, even for a queue of essentially fixed length. 
> 
> On Tue, 25 Sep 2018 at 00:16, Martin Buchholz via Concurrency-interest <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>> wrote:
> The conservative maintainers of the concurrent queues are unlikely to
> change the implementation.  The behavior of the queues when quiescent
> is correct and useful.  Any fix for size() would be unsatisfying if it
> did not also apply to toArray().  It might be good to add scare
> javadocs about how traversal may end up visiting many more elements
> than the high water mark size of the queue (but that "leaks"
> implementation details into the javadoc).
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion
> JavaOne Rockstar Speaker
> http://www.javaspecialists.eu <http://www.javaspecialists.eu/>
> Tel: +30 69 75 595 262
> Skype: kabutz

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180925/bc808d22/attachment-0001.html>

From martinrb at google.com  Tue Sep 25 11:09:46 2018
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 25 Sep 2018 08:09:46 -0700
Subject: [concurrency-interest] Concurrent Queue Sizes and Hot Fields
In-Reply-To: <22F9D7D5-BDA2-4765-82D9-89EBCD1AD256@gmail.com>
References: <5BA3BD93.7020204@javaspecialists.eu>
 <756a7906-3c34-57a0-598b-e6232539d8d7@cs.oswego.edu>
 <CACLL95rMx86Fve9++V-_674Gf3+6zY5dShYwmpquH_8n6a1_6Q@mail.gmail.com>
 <9d44ee26-f0fe-b98e-2243-f3eecdb45205@cs.oswego.edu>
 <18C841BA-7D95-44FA-B949-2F19B799C1B7@gmail.com>
 <0e67e98e-f75c-b55d-3abd-bcb712808145@cs.oswego.edu>
 <CAP0L=UQD9swDcr6v3r5Ep3mVyHJB57pQL7CDFtaNHJzq8Hfjtw@mail.gmail.com>
 <4489AEC7-4136-4305-9FD8-9123F434F029@gmail.com>
 <CA+kOe09_FNeCkEPqSCsut8-dCJ8vv0uWOXY=sF6Bxm6xWcBVEQ@mail.gmail.com>
 <CACLL95rN9UW0CO2a=Qe8XOfRm1BBmkQNCVP+N+2JVK-ToTp6hw@mail.gmail.com>
 <22F9D7D5-BDA2-4765-82D9-89EBCD1AD256@gmail.com>
Message-ID: <CA+kOe0-YPAwDSC1yiHQbH1Sx+xdKh86tMt3zbbOTbRemZjig+A@mail.gmail.com>

Maybe a better "other" method to think about is contains(Object).
Here there's no choice but to traverse the collection.  If you are
consistently slow, you will keep falling off the front of the
treadmill and have to get back on.  A plausible implementation
strategy would fall back to a more expensive but more terminating
traversal after the first fall off the treadmill.

(but these concurrent queue traversal methods are already pretty
complicated and hard to test)

From alarmnummer at gmail.com  Wed Sep 26 00:34:03 2018
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 26 Sep 2018 07:34:03 +0300
Subject: [concurrency-interest] initialization safety questions
Message-ID: <CAGuAWdC+5A1CQ=QvHruBKWxo5iX=eAZ0GDnnX9DMQ2viHVQruA@mail.gmail.com>

I'm studying the topic of initialization safety and want to make sure my
understanding is correct.

The following object doesn't provide initialization safety since none of
the fields are final

    class Foo_1{
        private int f1;
        private int f2;

        public Foo_1(){
            f1=1;
            f2=2;
        }
    }

Foo_2 will provide initialization safety because all the fields are final.

    class Foo_2{
        private final int f1;
        private final int f2;

        public Foo_2(){
            f2=2;
            f1=1;
        }
    }

Also Foo_3 is broken. f1 has no issues, but f2 is not final therefor
another thread could observe a Foo_3 instance with f2 not being initialized.

    class Foo_3{
        private final int f1;
        private int f2;

        public Foo_3(){
            f1=1;
            f2=2;
        }
    }

The broken nature of the Foo_3 example is mentioned here:
https://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#finalRight

The question is about the following:

class Foo_4{
        private int f1;
        private final int f2;

        public Foo_4(){
            f1=1;
            f2=2;
        }
    }

If I understand the JMM correctly then this example is broken as well.
Initially I got confused by a excellent post from Shiplev:
https://shipilev.net/blog/2014/safe-public-construction/#_safe_initialization
where he states that if any field is final (and the reference doesn't
escape), safe initialization works. But he is referring to how it actually
is implemented; not about the specification.

So is it correct to say that Foo_4 is doesn't support safe initialization?

If f2 would be made volatile, then the object is supporting safe
initialization because in this case the f1=1 can't jump after the f2=2.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180926/706aeb09/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Sep 26 16:18:52 2018
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 26 Sep 2018 14:18:52 -0600
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 163,
	Issue 21
In-Reply-To: <mailman.3.1537977602.27195.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1537977602.27195.concurrency-interest@cs.oswego.edu>
Message-ID: <CAO-wXwLvs9XT5vfy6AsKT2xEULz=YJ6JMHiByYtHBMnYmU9ykw@mail.gmail.com>

Hi Peter,

Yes, according to the specification, there is no guarantee of what you are
calling safe initialization in example 4.

You may want to take a look at this presentation:
https://sites.google.com/site/aboutmale/techblog/javafinal (there is also a
link to a talk by my former colleague Vladimir Sitnikov, but that talk is
in Russian language).

Regards,
Valentin


On Wed, Sep 26, 2018, 10:56 <concurrency-interest-request at cs.oswego.edu>
wrote:

> Send Concurrency-interest mailing list submissions to
>         concurrency-interest at cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
>         concurrency-interest-request at cs.oswego.edu
>
> You can reach the person managing the list at
>         concurrency-interest-owner at cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
>
> Today's Topics:
>
>    1. initialization safety questions (Peter Veentjer)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 26 Sep 2018 07:34:03 +0300
> From: Peter Veentjer <alarmnummer at gmail.com>
> To: "concurrency-interest at cs.oswego.edu"
>         <concurrency-interest at cs.oswego.edu>
> Subject: [concurrency-interest] initialization safety questions
> Message-ID:
>         <CAGuAWdC+5A1CQ=QvHruBKWxo5iX=
> eAZ0GDnnX9DMQ2viHVQruA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> I'm studying the topic of initialization safety and want to make sure my
> understanding is correct.
>
> The following object doesn't provide initialization safety since none of
> the fields are final
>
>     class Foo_1{
>         private int f1;
>         private int f2;
>
>         public Foo_1(){
>             f1=1;
>             f2=2;
>         }
>     }
>
> Foo_2 will provide initialization safety because all the fields are final.
>
>     class Foo_2{
>         private final int f1;
>         private final int f2;
>
>         public Foo_2(){
>             f2=2;
>             f1=1;
>         }
>     }
>
> Also Foo_3 is broken. f1 has no issues, but f2 is not final therefor
> another thread could observe a Foo_3 instance with f2 not being
> initialized.
>
>     class Foo_3{
>         private final int f1;
>         private int f2;
>
>         public Foo_3(){
>             f1=1;
>             f2=2;
>         }
>     }
>
> The broken nature of the Foo_3 example is mentioned here:
> https://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#finalRight
>
> The question is about the following:
>
> class Foo_4{
>         private int f1;
>         private final int f2;
>
>         public Foo_4(){
>             f1=1;
>             f2=2;
>         }
>     }
>
> If I understand the JMM correctly then this example is broken as well.
> Initially I got confused by a excellent post from Shiplev:
>
> https://shipilev.net/blog/2014/safe-public-construction/#_safe_initialization
> where he states that if any field is final (and the reference doesn't
> escape), safe initialization works. But he is referring to how it actually
> is implemented; not about the specification.
>
> So is it correct to say that Foo_4 is doesn't support safe initialization?
>
> If f2 would be made volatile, then the object is supporting safe
> initialization because in this case the f1=1 can't jump after the f2=2.
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180926/706aeb09/attachment-0001.html
> >
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> ------------------------------
>
> End of Concurrency-interest Digest, Vol 163, Issue 21
> *****************************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180926/7835a70c/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Sep 26 16:30:44 2018
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 26 Sep 2018 14:30:44 -0600
Subject: [concurrency-interest] initialization safety questions
Message-ID: <CAO-wXw+a8SO1ZNaq5CiPPM74Rebe6Zq7hN+d5iFQUJ+t2GDASQ@mail.gmail.com>

>If f2 would be made volatile, then the object is supporting safe
initialization because in this case the f1=1 can't jump after the f2=2

No, that would not save the day. You would lose "safety initialization" for
both fields in that case because non of them would be final. And volatile
store in a constructor does not prevent reading the default value in case
of unsafe publication. This has already been discussed:

question
http://cs.oswego.edu/pipermail/concurrency-interest/2013-November/011951.html
correct answer
http://cs.oswego.edu/pipermail/concurrency-interest/2013-November/011954.html
Dug Lee's thoughts
http://cs.oswego.edu/pipermail/concurrency-interest/2013-November/011966.html

Regards,
Valentin

On Wed, Sep 26, 2018, 14:18 Valentin Kovalenko <
valentin.male.kovalenko at gmail.com> wrote:

> Hi Peter,
>
> Yes, according to the specification, there is no guarantee of what you are
> calling safe initialization in example 4.
>
> You may want to take a look at this presentation:
> https://sites.google.com/site/aboutmale/techblog/javafinal (there is also
> a link to a talk by my former colleague Vladimir Sitnikov, but that talk is
> in Russian language).
>
> Regards,
> Valentin
>
>
> On Wed, Sep 26, 2018, 10:56 <concurrency-interest-request at cs.oswego.edu>
> wrote:
>
>> Send Concurrency-interest mailing list submissions to
>>         concurrency-interest at cs.oswego.edu
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> or, via email, send a message with subject or body 'help' to
>>         concurrency-interest-request at cs.oswego.edu
>>
>> You can reach the person managing the list at
>>         concurrency-interest-owner at cs.oswego.edu
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of Concurrency-interest digest..."
>>
>>
>> Today's Topics:
>>
>>    1. initialization safety questions (Peter Veentjer)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Wed, 26 Sep 2018 07:34:03 +0300
>> From: Peter Veentjer <alarmnummer at gmail.com>
>> To: "concurrency-interest at cs.oswego.edu"
>>         <concurrency-interest at cs.oswego.edu>
>> Subject: [concurrency-interest] initialization safety questions
>> Message-ID:
>>         <CAGuAWdC+5A1CQ=QvHruBKWxo5iX=
>> eAZ0GDnnX9DMQ2viHVQruA at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> I'm studying the topic of initialization safety and want to make sure my
>> understanding is correct.
>>
>> The following object doesn't provide initialization safety since none of
>> the fields are final
>>
>>     class Foo_1{
>>         private int f1;
>>         private int f2;
>>
>>         public Foo_1(){
>>             f1=1;
>>             f2=2;
>>         }
>>     }
>>
>> Foo_2 will provide initialization safety because all the fields are final.
>>
>>     class Foo_2{
>>         private final int f1;
>>         private final int f2;
>>
>>         public Foo_2(){
>>             f2=2;
>>             f1=1;
>>         }
>>     }
>>
>> Also Foo_3 is broken. f1 has no issues, but f2 is not final therefor
>> another thread could observe a Foo_3 instance with f2 not being
>> initialized.
>>
>>     class Foo_3{
>>         private final int f1;
>>         private int f2;
>>
>>         public Foo_3(){
>>             f1=1;
>>             f2=2;
>>         }
>>     }
>>
>> The broken nature of the Foo_3 example is mentioned here:
>> https://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#finalRight
>>
>> The question is about the following:
>>
>> class Foo_4{
>>         private int f1;
>>         private final int f2;
>>
>>         public Foo_4(){
>>             f1=1;
>>             f2=2;
>>         }
>>     }
>>
>> If I understand the JMM correctly then this example is broken as well.
>> Initially I got confused by a excellent post from Shiplev:
>>
>> https://shipilev.net/blog/2014/safe-public-construction/#_safe_initialization
>> where he states that if any field is final (and the reference doesn't
>> escape), safe initialization works. But he is referring to how it actually
>> is implemented; not about the specification.
>>
>> So is it correct to say that Foo_4 is doesn't support safe initialization?
>>
>> If f2 would be made volatile, then the object is supporting safe
>> initialization because in this case the f1=1 can't jump after the f2=2.
>> -------------- next part --------------
>> An HTML attachment was scrubbed...
>> URL: <
>> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180926/706aeb09/attachment-0001.html
>> >
>>
>> ------------------------------
>>
>> Subject: Digest Footer
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> ------------------------------
>>
>> End of Concurrency-interest Digest, Vol 163, Issue 21
>> *****************************************************
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180926/ae691d36/attachment-0001.html>

From boehm at acm.org  Wed Sep 26 20:27:03 2018
From: boehm at acm.org (Hans Boehm)
Date: Wed, 26 Sep 2018 17:27:03 -0700
Subject: [concurrency-interest] initialization safety questions
In-Reply-To: <CAGuAWdC+5A1CQ=QvHruBKWxo5iX=eAZ0GDnnX9DMQ2viHVQruA@mail.gmail.com>
References: <CAGuAWdC+5A1CQ=QvHruBKWxo5iX=eAZ0GDnnX9DMQ2viHVQruA@mail.gmail.com>
Message-ID: <CAPUmR1ZV_mG16aqQUOfZh5Bn3G6td-_M27wdLZAx+cjM8zLRag@mail.gmail.com>

On Tue, Sep 25, 2018 at 10:02 PM Peter Veentjer via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> ...
> The question is about the following:
>
> class Foo_4{
>         private int f1;
>         private final int f2;
>
>         public Foo_4(){
>             f1=1;
>             f2=2;
>         }
>     }
>
> If I understand the JMM correctly then this example is broken as well.
> Initially I got confused by a excellent post from Shiplev:
> https://shipilev.net/blog/2014/safe-public-construction/#_safe_initialization
> where he states that if any field is final (and the reference doesn't
> escape), safe initialization works. But he is referring to how it actually
> is implemented; not about the specification.
>
> So is it correct to say that Foo_4 is doesn't support safe initialization?
>
> Yes. And there's a fundamental reason I think you would not want to rely
on the generated fence for non-final fields, even if the spec somehow
guaranteed it's there.

On some architectures, it really is only a StoreStore fence. This means the
fence, given the standard implementation with a fence after the
constructor, will ensure that  a Foo_4 user will see f1 initialized.
However the assert in the following slightly modified example can still
fail if the client modifies f1:

class Foo_4{
        private int f1;
        private final int f2;

        public Foo_4(){
            f1=1;
            assert f1 == 1; // read can be reordered with end of
constructor; may see later write
            f2=2;
        }
  }

In the final field case, f1 can't change, and this all makes a lot more
sense.

Hans
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180926/4bb091df/attachment.html>

From felix.riemann at andrena.de  Fri Sep 28 08:27:41 2018
From: felix.riemann at andrena.de (Felix Riemann)
Date: Fri, 28 Sep 2018 14:27:41 +0200
Subject: [concurrency-interest] JLS 17.5 Examples
Message-ID: <mailman.0.1538137702.1912.concurrency-interest@cs.oswego.edu>

Hi,

about the two examples in JLS 17.5 https://docs.oracle.com/javase/specs/jls/se11/html/jls-17.html#jls-17.5

- In Example 17.5-1, wouldn't it be more accurate to replace "guaranteed to see 3" with "cannot see 0"? Because it could still throw a NullPointerException. As access to f is (deliberately) not synchronized, the second dereference of f could return null. In fact, one could get rid of the non-null check altogether.
- Example 17.5-2 seems to refer to previous implementations of String which still had an offset field.

Is that accurate?

Greets,
Felix


-- 
andrena objects ag
Albert-Nestler-Str. 9
76131 Karlsruhe

t: +49 (0) 721 6105 122
f: +49 (0) 721 6105 140

http://www.andrena.de

Vorstand: Hagen Buchwald, Dr. Dieter Kuhn, Stefan Schürle
Aufsichtsratsvorsitzender: Rolf Hetzelberger

Sitz der Gesellschaft: Karlsruhe
Amtsgericht Mannheim, HRB 109694
USt-IdNr. DE174314824
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180928/b8dda99f/attachment.html>

From pavel.rappo at gmail.com  Fri Sep 28 08:51:58 2018
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 28 Sep 2018 13:51:58 +0100
Subject: [concurrency-interest] Synchronization primitives in Reactive
	Streams implementations
Message-ID: <9B8CD5A4-9259-478F-B35E-06CE87CFE008@gmail.com>

Hello,

Let me start this discussion as a branch of the "Reactive Streams utility API" 
thread here:

  http://mail.openjdk.java.net/pipermail/core-libs-dev/2018-September/055671.html

I would like to talk about a particular synchronization primitive I find to be
repeatedly reinvented in Reactive Streams implementations. I hope that we could
discuss different incarnations of this primitive and maybe extract it into a 
reusable component.

The primitive in question assists a number of parties in executing tasks in a
sequential and non-blocking fashion without having to use a dedicated thread of
execution. Though specifics may vary, the core of the primitive consists of a
tiny protocol for bidirectional communication between parties, a backlog of
tasks and an executor to execute the tasks in. All this is packed into a single
method for a party to invoke. When a party invokes the method, the method adds
the passed task to the backlog and then checks whether the method must handle
the task or the method may simply return. If the method must handle the task,
then the method executes a special service task in the executor and returns.
From that moment and up until the service task has finished all tasks that are
added to the backlog are handled by this service task. The service task finishes
when the backlog becomes empty.

In other words, parties are busy with dumping their tasks on each other. Either
a party gets lucky and can rest assured the task it has just added will be
looked after, or it ends up with executing its task and, possibly, many others 
dumped on it by its luckier peers. In an extreme case where the underlying 
executor is a "calling thread executor" (`Executor executor = Runnable::run`), 
an unlucky party can get really buried itself in work. A metaphor for this
strategy could be "work dumping" (or "work foisting").

Without diving further into too much detail here are 2 components I would like 
to start with:

  1. MutexExecutor
  https://github.com/lightbend/microprofile-reactive-streams/blob/master/zerodep/src/main/java/com/lightbend/microprofile/reactive/streams/zerodep/MutexExecutor.java
  2. SequentialScheduler[^1]
  http://hg.openjdk.java.net/jdk/jdk11/file/ee6f7a61f3a5/src/java.net.http/share/classes/jdk/internal/net/http/common/SequentialScheduler.java

I believe that a similar (though a bit more sophisticated) primitive was implemented
in `java.util.concurrent.SubmissionPublisher`.

Do you think they fit into the idea described above? Could there be some common
mechanics extracted? Is there any potentially reusable component? Are there any
other contexts in which this can be used?

Thanks,
-Pavel

[^1]: `SequentialScheduler` evolved from a much simpler `CooperativeHandler` http://hg.openjdk.java.net/jdk9/sandbox/jdk/file/7c7a3c48196e/src/jdk.incubator.httpclient/share/classes/jdk/incubator/http/internal/websocket/CooperativeHandler.java 
adding asynchronous tasks and an underlying executor.


From akarnokd at gmail.com  Fri Sep 28 10:25:21 2018
From: akarnokd at gmail.com (=?UTF-8?Q?D=C3=A1vid_Karnok?=)
Date: Fri, 28 Sep 2018 16:25:21 +0200
Subject: [concurrency-interest] Synchronization primitives in Reactive
 Streams implementations
In-Reply-To: <9B8CD5A4-9259-478F-B35E-06CE87CFE008@gmail.com>
References: <9B8CD5A4-9259-478F-B35E-06CE87CFE008@gmail.com>
Message-ID: <CAAWwtm-vfa41Vq+8JBygi2dvKkEqDXu-Oze0OvH42Rht51Fr-A@mail.gmail.com>

We call this trampolining or queue-drain in ReactiveX and the concept was
already invented by the time we switched to such lock-free coordination.

There are two typical implementations. The first reuses one of the involved
threads to do as much work as possible:

concurrentQueue.offer(ThingsToDo);
if (wip.getAndIncrement() == 0) {
   do {
      var todo =  concurrentQueue.poll();
      handle(todo);
   } while (wip.decrementAndGet() != 0);
}

Another one uses a dedicated executor (scheduler, worker, actor, etc.) to
perform the loop body:

concurrentQueue.offer(ThingsToDo);
if (wip.getAndIncrement() == 0) {
   executor.execute(() -> {
      do {
         var todo =  concurrentQueue.poll();
         handle(todo);
      } while (wip.decrementAndGet() != 0);
   });
}

The latter has the benefit that the handle() method will run
non-overlappingly even if the executor is multi-threaded; it will occupy
one of its threads as long as possible and the atomic operation on wip
makes sure the do-loop body gets executed exclusively as well. Also unlike
the first one, this variant could be made fair by allowing it to get
interleaved by other tasks on the same executor.

The reason we don't have one abstraction for these in general is the
inlining of other features/behavior of reactive operators while making them
more concise and performant.

Pavel Rappo via Concurrency-interest <concurrency-interest at cs.oswego.edu>
ezt írta (időpont: 2018. szept. 28., P, 15:24):

> Hello,
>
> Let me start this discussion as a branch of the "Reactive Streams utility
> API"
> thread here:
>
>
> http://mail.openjdk.java.net/pipermail/core-libs-dev/2018-September/055671.html
>
> I would like to talk about a particular synchronization primitive I find
> to be
> repeatedly reinvented in Reactive Streams implementations. I hope that we
> could
> discuss different incarnations of this primitive and maybe extract it into
> a
> reusable component.
>
> The primitive in question assists a number of parties in executing tasks
> in a
> sequential and non-blocking fashion without having to use a dedicated
> thread of
> execution. Though specifics may vary, the core of the primitive consists
> of a
> tiny protocol for bidirectional communication between parties, a backlog of
> tasks and an executor to execute the tasks in. All this is packed into a
> single
> method for a party to invoke. When a party invokes the method, the method
> adds
> the passed task to the backlog and then checks whether the method must
> handle
> the task or the method may simply return. If the method must handle the
> task,
> then the method executes a special service task in the executor and
> returns.
> From that moment and up until the service task has finished all tasks that
> are
> added to the backlog are handled by this service task. The service task
> finishes
> when the backlog becomes empty.
>
> In other words, parties are busy with dumping their tasks on each other.
> Either
> a party gets lucky and can rest assured the task it has just added will be
> looked after, or it ends up with executing its task and, possibly, many
> others
> dumped on it by its luckier peers. In an extreme case where the underlying
> executor is a "calling thread executor" (`Executor executor =
> Runnable::run`),
> an unlucky party can get really buried itself in work. A metaphor for this
> strategy could be "work dumping" (or "work foisting").
>
> Without diving further into too much detail here are 2 components I would
> like
> to start with:
>
>   1. MutexExecutor
>
> https://github.com/lightbend/microprofile-reactive-streams/blob/master/zerodep/src/main/java/com/lightbend/microprofile/reactive/streams/zerodep/MutexExecutor.java
>   2. SequentialScheduler[^1]
>
> http://hg.openjdk.java.net/jdk/jdk11/file/ee6f7a61f3a5/src/java.net.http/share/classes/jdk/internal/net/http/common/SequentialScheduler.java
>
> I believe that a similar (though a bit more sophisticated) primitive was
> implemented
> in `java.util.concurrent.SubmissionPublisher`.
>
> Do you think they fit into the idea described above? Could there be some
> common
> mechanics extracted? Is there any potentially reusable component? Are
> there any
> other contexts in which this can be used?
>
> Thanks,
> -Pavel
>
> [^1]: `SequentialScheduler` evolved from a much simpler
> `CooperativeHandler`
> http://hg.openjdk.java.net/jdk9/sandbox/jdk/file/7c7a3c48196e/src/jdk.incubator.httpclient/share/classes/jdk/incubator/http/internal/websocket/CooperativeHandler.java
> adding asynchronous tasks and an underlying executor.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Best regards,
David Karnok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180928/ac79a17b/attachment.html>

From andrershov at gmail.com  Fri Sep 28 11:30:20 2018
From: andrershov at gmail.com (Andrew Ershov)
Date: Fri, 28 Sep 2018 17:30:20 +0200
Subject: [concurrency-interest] Linearizability of synchronization actions
Message-ID: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>

The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
1) T1 q.enq(x)
2) T2 q.enq(y)
3) T3 q.deq(y)

This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.

Any ideas on that?

Andrey

From oleksandr.otenko at gmail.com  Fri Sep 28 11:47:12 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 28 Sep 2018 16:47:12 +0100
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
References: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
Message-ID: <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>

Time is an illusion.

Alex

> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
> 
> The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
> In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
> 1) T1 q.enq(x)
> 2) T2 q.enq(y)
> 3) T3 q.deq(y)
> 
> This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.
> 
> Any ideas on that?
> 
> Andrey
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at gmail.com  Fri Sep 28 11:53:10 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 28 Sep 2018 16:53:10 +0100
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>
References: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
 <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>
Message-ID: <EB55F396-C00B-42C0-A5DD-135713A4F337@gmail.com>

On a serious note, there needs to be some clarity what time is meant in the definition of linearizability you are looking at.

There is no physical global time line in the real world. The models may assume an even weaker notion of time. (Hence a reference to happens-before and total orders - that’s a way to get out of the “what is time?” conundrum and at the same time specify what it means that they are atomic, and that everyone agrees on the order. Such a definition also allows for weaker-than-real-world time.)

Alex

> On 28 Sep 2018, at 16:47, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> Time is an illusion.
> 
> Alex
> 
>> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>> 
>> The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
>> In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
>> 1) T1 q.enq(x)
>> 2) T2 q.enq(y)
>> 3) T3 q.deq(y)
>> 
>> This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.
>> 
>> Any ideas on that?
>> 
>> Andrey
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From andrershov at gmail.com  Fri Sep 28 12:41:57 2018
From: andrershov at gmail.com (Andrew Ershov)
Date: Fri, 28 Sep 2018 18:41:57 +0200
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <EB55F396-C00B-42C0-A5DD-135713A4F337@gmail.com>
References: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
 <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>
 <EB55F396-C00B-42C0-A5DD-135713A4F337@gmail.com>
Message-ID: <6EFB1ADF-22CE-4AD4-BC65-4B26A2B565A3@gmail.com>

If there is no global time, does it make sense to talk about linearizability?
For humans time is mostly about causality.
What if we enrich my previous example with external actions (socket read/write) like this:
T1
q.enq(x)
writeToSocket1()

T2
readFromSocket2()
q.enq(y)
q.deq(y)

And there is an external actor, that receives message from socket1 as soon as enqueuing in the first thread is done and immediately writes to socket2 to unblock thread T2.
What in JMM prohibits such execution?

> On 28 Sep 2018, at 17:53, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> On a serious note, there needs to be some clarity what time is meant in the definition of linearizability you are looking at.
> 
> There is no physical global time line in the real world. The models may assume an even weaker notion of time. (Hence a reference to happens-before and total orders - that’s a way to get out of the “what is time?” conundrum and at the same time specify what it means that they are atomic, and that everyone agrees on the order. Such a definition also allows for weaker-than-real-world time.)
> 
> Alex
> 
>> On 28 Sep 2018, at 16:47, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>> 
>> Time is an illusion.
>> 
>> Alex
>> 
>>> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>>> 
>>> The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
>>> In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
>>> 1) T1 q.enq(x)
>>> 2) T2 q.enq(y)
>>> 3) T3 q.deq(y)
>>> 
>>> This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.
>>> 
>>> Any ideas on that?
>>> 
>>> Andrey
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
> 

From oleksandr.otenko at gmail.com  Fri Sep 28 13:17:00 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 28 Sep 2018 18:17:00 +0100
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <6EFB1ADF-22CE-4AD4-BC65-4B26A2B565A3@gmail.com>
References: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
 <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>
 <EB55F396-C00B-42C0-A5DD-135713A4F337@gmail.com>
 <6EFB1ADF-22CE-4AD4-BC65-4B26A2B565A3@gmail.com>
Message-ID: <6B279585-73BF-491C-ADFA-6746B4C5D04E@gmail.com>


> On 28 Sep 2018, at 17:41, Andrew Ershov <andrershov at gmail.com> wrote:
> 
> If there is no global time, does it make sense to talk about linearizability?

Yes. By defining a total order of synchronization events which all the threads agree on.

Global time is more than that. Global time is about agreeing on the time elapsed between any two events in such an order. But this is not a necessary condition for linearizability.

> For humans time is mostly about causality.

Happens-before captures that.

> What if we enrich my previous example with external actions (socket read/write) like this:
> T1
> q.enq(x)
> writeToSocket1()
> 
> T2
> readFromSocket2()
> q.enq(y)
> q.deq(y)
> 
> And there is an external actor, that receives message from socket1 as soon as enqueuing in the first thread is done and immediately writes to socket2 to unblock thread T2.
> What in JMM prohibits such execution?

For JMM to prohibit such execution, you need a synchronizes-with edge that from which absurd follows.


Alex


>> On 28 Sep 2018, at 17:53, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>> 
>> On a serious note, there needs to be some clarity what time is meant in the definition of linearizability you are looking at.
>> 
>> There is no physical global time line in the real world. The models may assume an even weaker notion of time. (Hence a reference to happens-before and total orders - that’s a way to get out of the “what is time?” conundrum and at the same time specify what it means that they are atomic, and that everyone agrees on the order. Such a definition also allows for weaker-than-real-world time.)
>> 
>> Alex
>> 
>>> On 28 Sep 2018, at 16:47, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>> 
>>> Time is an illusion.
>>> 
>>> Alex
>>> 
>>>> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>>>> 
>>>> The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
>>>> In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
>>>> 1) T1 q.enq(x)
>>>> 2) T2 q.enq(y)
>>>> 3) T3 q.deq(y)
>>>> 
>>>> This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.
>>>> 
>>>> Any ideas on that?
>>>> 
>>>> Andrey
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>> 


From andrershov at gmail.com  Fri Sep 28 13:26:33 2018
From: andrershov at gmail.com (Andrew Ershov)
Date: Fri, 28 Sep 2018 19:26:33 +0200
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <6B279585-73BF-491C-ADFA-6746B4C5D04E@gmail.com>
References: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
 <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>
 <EB55F396-C00B-42C0-A5DD-135713A4F337@gmail.com>
 <6EFB1ADF-22CE-4AD4-BC65-4B26A2B565A3@gmail.com>
 <6B279585-73BF-491C-ADFA-6746B4C5D04E@gmail.com>
Message-ID: <5A64A994-05C0-4010-82D6-1FC745E826E5@gmail.com>


Thanks for your reply.
Regarding your third answer: do you mean synchronizes-with edge between writeToSocket and readFromSocket? I don’t see in the spec, that external actions could form synchronizes-with edge.

> On 28 Sep 2018, at 19:17, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> 
>> On 28 Sep 2018, at 17:41, Andrew Ershov <andrershov at gmail.com> wrote:
>> 
>> If there is no global time, does it make sense to talk about linearizability?
> 
> Yes. By defining a total order of synchronization events which all the threads agree on.
> 
> Global time is more than that. Global time is about agreeing on the time elapsed between any two events in such an order. But this is not a necessary condition for linearizability.
> 
>> For humans time is mostly about causality.
> 
> Happens-before captures that.
> 
>> What if we enrich my previous example with external actions (socket read/write) like this:
>> T1
>> q.enq(x)
>> writeToSocket1()
>> 
>> T2
>> readFromSocket2()
>> q.enq(y)
>> q.deq(y)
>> 
>> And there is an external actor, that receives message from socket1 as soon as enqueuing in the first thread is done and immediately writes to socket2 to unblock thread T2.
>> What in JMM prohibits such execution?
> 
> For JMM to prohibit such execution, you need a synchronizes-with edge that from which absurd follows.
> 
> 
> Alex
> 
> 
>>> On 28 Sep 2018, at 17:53, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>> 
>>> On a serious note, there needs to be some clarity what time is meant in the definition of linearizability you are looking at.
>>> 
>>> There is no physical global time line in the real world. The models may assume an even weaker notion of time. (Hence a reference to happens-before and total orders - that’s a way to get out of the “what is time?” conundrum and at the same time specify what it means that they are atomic, and that everyone agrees on the order. Such a definition also allows for weaker-than-real-world time.)
>>> 
>>> Alex
>>> 
>>>> On 28 Sep 2018, at 16:47, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>>> 
>>>> Time is an illusion.
>>>> 
>>>> Alex
>>>> 
>>>>> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>>>>> 
>>>>> The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
>>>>> In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
>>>>> 1) T1 q.enq(x)
>>>>> 2) T2 q.enq(y)
>>>>> 3) T3 q.deq(y)
>>>>> 
>>>>> This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.
>>>>> 
>>>>> Any ideas on that?
>>>>> 
>>>>> Andrey
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
>>> 
> 

From valentin.male.kovalenko at gmail.com  Fri Sep 28 18:24:57 2018
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Fri, 28 Sep 2018 16:24:57 -0600
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <mailman.3.1538150402.30854.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1538150402.30854.concurrency-interest@cs.oswego.edu>
Message-ID: <CAO-wXw+LJWgyd9rboecEfp5+8a8vat30ZigdjM+aEMu-MyDfeA@mail.gmail.com>

Andrey,

>JMM also agrees that there is a total order of synchronization actions,
but linearizability assumes also time ordering, JMM says nothing that
synchronization actions order is consistent with time.

As Alex mentioned, there is no concept of physical global time and what is
considered as "time" in the definition of linearizability (see
https://www.ics.forth.gr/tech-reports/2013/2013.TR439_Survey_on_Consistency_Conditions.pdf
or the original https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf) is
just a partial order of actions (I hate this terrible choice to use word
"time"). Our "time"-order is the happens-before order.

Regards,
Valentin
[image: LinkedIn] <https://www.linkedin.com/in/stIncMale>   [image: GitHub]
<https://github.com/stIncMale>   [image: YouTube]
<https://www.youtube.com/user/stIncMale>


On Fri, 28 Sep 2018 at 10:25, <concurrency-interest-request at cs.oswego.edu>
wrote:

> Send Concurrency-interest mailing list submissions to
>         concurrency-interest at cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
>         concurrency-interest-request at cs.oswego.edu
>
> You can reach the person managing the list at
>         concurrency-interest-owner at cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
>
> Today's Topics:
>
>    1. Re: Linearizability of synchronization    actions (Alex Otenko)
>    2. Re: Linearizability of synchronization    actions (Alex Otenko)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 28 Sep 2018 16:47:12 +0100
> From: Alex Otenko <oleksandr.otenko at gmail.com>
> To: Andrew Ershov <andrershov at gmail.com>
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Linearizability of synchronization
>         actions
> Message-ID: <A1D91EEA-D8C1-449F-BF16-EA972A434EBE at gmail.com>
> Content-Type: text/plain;       charset=utf-8
>
> Time is an illusion.
>
> Alex
>
> > On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <
> concurrency-interest at cs.oswego.edu> wrote:
> >
> > The “Art of Multiprocessor programming” claims that “synchronization
> events are linearizable: they are totally ordered, and all threads agree on
> the ordering”. JMM also agrees that there is a total order of
> synchronization actions, but linearizability assumes also time ordering,
> JMM says nothing that synchronization actions order is consistent with time.
> > In other words, if there is a queue q (protected by lock) and two
> threads T1 and T1. In the time order (assuming no method invocations
> overlap):
> > 1) T1 q.enq(x)
> > 2) T2 q.enq(y)
> > 3) T3 q.deq(y)
> >
> > This execution is sequentially consistent, but it’s not linearizable.
> The total order of synchronization actions that allows this execution is 2
> lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not
> consistent with time.
> >
> > Any ideas on that?
> >
> > Andrey
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> ------------------------------
>
> Message: 2
> Date: Fri, 28 Sep 2018 16:53:10 +0100
> From: Alex Otenko <oleksandr.otenko at gmail.com>
> To: Andrew Ershov <andrershov at gmail.com>
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Linearizability of synchronization
>         actions
> Message-ID: <EB55F396-C00B-42C0-A5DD-135713A4F337 at gmail.com>
> Content-Type: text/plain;       charset=utf-8
>
> On a serious note, there needs to be some clarity what time is meant in
> the definition of linearizability you are looking at.
>
> There is no physical global time line in the real world. The models may
> assume an even weaker notion of time. (Hence a reference to happens-before
> and total orders - that’s a way to get out of the “what is time?” conundrum
> and at the same time specify what it means that they are atomic, and that
> everyone agrees on the order. Such a definition also allows for
> weaker-than-real-world time.)
>
> Alex
>
> > On 28 Sep 2018, at 16:47, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
> >
> > Time is an illusion.
> >
> > Alex
> >
> >> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <
> concurrency-interest at cs.oswego.edu> wrote:
> >>
> >> The “Art of Multiprocessor programming” claims that “synchronization
> events are linearizable: they are totally ordered, and all threads agree on
> the ordering”. JMM also agrees that there is a total order of
> synchronization actions, but linearizability assumes also time ordering,
> JMM says nothing that synchronization actions order is consistent with time.
> >> In other words, if there is a queue q (protected by lock) and two
> threads T1 and T1. In the time order (assuming no method invocations
> overlap):
> >> 1) T1 q.enq(x)
> >> 2) T2 q.enq(y)
> >> 3) T3 q.deq(y)
> >>
> >> This execution is sequentially consistent, but it’s not linearizable.
> The total order of synchronization actions that allows this execution is 2
> lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not
> consistent with time.
> >>
> >> Any ideas on that?
> >>
> >> Andrey
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> ------------------------------
>
> End of Concurrency-interest Digest, Vol 163, Issue 25
> *****************************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180928/049bbb26/attachment-0001.html>

From oleksandr.otenko at gmail.com  Fri Sep 28 18:27:12 2018
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 28 Sep 2018 23:27:12 +0100
Subject: [concurrency-interest] Linearizability of synchronization
	actions
In-Reply-To: <5A64A994-05C0-4010-82D6-1FC745E826E5@gmail.com>
References: <996621C8-40C3-485C-A4FF-9FE38A0BA59B@gmail.com>
 <A1D91EEA-D8C1-449F-BF16-EA972A434EBE@gmail.com>
 <EB55F396-C00B-42C0-A5DD-135713A4F337@gmail.com>
 <6EFB1ADF-22CE-4AD4-BC65-4B26A2B565A3@gmail.com>
 <6B279585-73BF-491C-ADFA-6746B4C5D04E@gmail.com>
 <5A64A994-05C0-4010-82D6-1FC745E826E5@gmail.com>
Message-ID: <79803A65-DA4B-43CE-9E72-0267442E554E@gmail.com>

I am not sure what you are getting at. You asked about JMM. JMM needs a synchronizes-with edge that makes the sequence you are enquiring about absurd. If there is no such edge, then JMM doesn’t forbid it.

It doesn’t mean it’s possible. It only means it is not JMM that can make it impossible.

Alex

> On 28 Sep 2018, at 18:26, Andrew Ershov <andrershov at gmail.com> wrote:
> 
> 
> Thanks for your reply.
> Regarding your third answer: do you mean synchronizes-with edge between writeToSocket and readFromSocket? I don’t see in the spec, that external actions could form synchronizes-with edge.
> 
>> On 28 Sep 2018, at 19:17, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>> 
>> 
>>> On 28 Sep 2018, at 17:41, Andrew Ershov <andrershov at gmail.com> wrote:
>>> 
>>> If there is no global time, does it make sense to talk about linearizability?
>> 
>> Yes. By defining a total order of synchronization events which all the threads agree on.
>> 
>> Global time is more than that. Global time is about agreeing on the time elapsed between any two events in such an order. But this is not a necessary condition for linearizability.
>> 
>>> For humans time is mostly about causality.
>> 
>> Happens-before captures that.
>> 
>>> What if we enrich my previous example with external actions (socket read/write) like this:
>>> T1
>>> q.enq(x)
>>> writeToSocket1()
>>> 
>>> T2
>>> readFromSocket2()
>>> q.enq(y)
>>> q.deq(y)
>>> 
>>> And there is an external actor, that receives message from socket1 as soon as enqueuing in the first thread is done and immediately writes to socket2 to unblock thread T2.
>>> What in JMM prohibits such execution?
>> 
>> For JMM to prohibit such execution, you need a synchronizes-with edge that from which absurd follows.
>> 
>> 
>> Alex
>> 
>> 
>>>> On 28 Sep 2018, at 17:53, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>>> 
>>>> On a serious note, there needs to be some clarity what time is meant in the definition of linearizability you are looking at.
>>>> 
>>>> There is no physical global time line in the real world. The models may assume an even weaker notion of time. (Hence a reference to happens-before and total orders - that’s a way to get out of the “what is time?” conundrum and at the same time specify what it means that they are atomic, and that everyone agrees on the order. Such a definition also allows for weaker-than-real-world time.)
>>>> 
>>>> Alex
>>>> 
>>>>> On 28 Sep 2018, at 16:47, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>>>> 
>>>>> Time is an illusion.
>>>>> 
>>>>> Alex
>>>>> 
>>>>>> On 28 Sep 2018, at 16:30, Andrew Ershov via Concurrency-interest <concurrency-interest at cs.oswego.edu> wrote:
>>>>>> 
>>>>>> The “Art of Multiprocessor programming” claims that “synchronization events are linearizable: they are totally ordered, and all threads agree on the ordering”. JMM also agrees that there is a total order of synchronization actions, but linearizability assumes also time ordering, JMM says nothing that synchronization actions order is consistent with time.
>>>>>> In other words, if there is a queue q (protected by lock) and two threads T1 and T1. In the time order (assuming no method invocations overlap):
>>>>>> 1) T1 q.enq(x)
>>>>>> 2) T2 q.enq(y)
>>>>>> 3) T3 q.deq(y)
>>>>>> 
>>>>>> This execution is sequentially consistent, but it’s not linearizable. The total order of synchronization actions that allows this execution is 2 lock - 2 unlock - 3 lock - 3 unlock - 1 lock - 1 unlock. But it’s not consistent with time.
>>>>>> 
>>>>>> Any ideas on that?
>>>>>> 
>>>>>> Andrey
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>> 
>> 


From boehm at acm.org  Sat Sep 29 12:36:19 2018
From: boehm at acm.org (Hans Boehm)
Date: Sat, 29 Sep 2018 09:36:19 -0700
Subject: [concurrency-interest] JLS 17.5 Examples
In-Reply-To: <20180928130211.31FDF1600181@altair.cs.oswego.edu>
References: <20180928130211.31FDF1600181@altair.cs.oswego.edu>
Message-ID: <CAPUmR1ZRs0HP=6Xo=T5Lu1vEmiAgvMRPfANj0BNZ-Uh+MEqKPw@mail.gmail.com>

On Fri, Sep 28, 2018 at 6:03 AM Felix Riemann via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:
>
> Hi,
>
> about the two examples in JLS 17.5
https://docs.oracle.com/javase/specs/jls/se11/html/jls-17.html#jls-17.5
>
> - In Example 17.5-1, wouldn't it be more accurate to replace "guaranteed
to see 3" with "cannot see 0"? Because it could still throw a
NullPointerException. As access to f is (deliberately) not synchronized,
the second dereference of f could return null. In fact, one could get rid
of the non-null check altogether.

Agreed. It might be better to instead have the example just read f once.

Hans
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20180929/b3cfe335/attachment.html>

From viktor.klang at gmail.com  Sun Sep 30 18:30:06 2018
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 1 Oct 2018 00:30:06 +0200
Subject: [concurrency-interest] Synchronization primitives in Reactive
 Streams implementations
In-Reply-To: <9B8CD5A4-9259-478F-B35E-06CE87CFE008@gmail.com>
References: <9B8CD5A4-9259-478F-B35E-06CE87CFE008@gmail.com>
Message-ID: <CANPzfU8Z0cSOn4KArpNGiJccUyvCt9_Wx-scEHQX+CR9eLZ=9w@mail.gmail.com>

Hi Pavel,

It's an interesting problem.
Come to think about it, besides the MutexExecutor, I've also got this
<https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/util/SerializedSuspendableExecutionContext.scala>
and that
<https://github.com/scala/scala/blob/2.13.x/src/library/scala/concurrent/BatchingExecutor.scala>
.

On Fri, Sep 28, 2018 at 3:24 PM Pavel Rappo via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> Hello,
>
> Let me start this discussion as a branch of the "Reactive Streams utility
> API"
> thread here:
>
>
> http://mail.openjdk.java.net/pipermail/core-libs-dev/2018-September/055671.html
>
> I would like to talk about a particular synchronization primitive I find
> to be
> repeatedly reinvented in Reactive Streams implementations. I hope that we
> could
> discuss different incarnations of this primitive and maybe extract it into
> a
> reusable component.
>
> The primitive in question assists a number of parties in executing tasks
> in a
> sequential and non-blocking fashion without having to use a dedicated
> thread of
> execution. Though specifics may vary, the core of the primitive consists
> of a
> tiny protocol for bidirectional communication between parties, a backlog of
> tasks and an executor to execute the tasks in. All this is packed into a
> single
> method for a party to invoke. When a party invokes the method, the method
> adds
> the passed task to the backlog and then checks whether the method must
> handle
> the task or the method may simply return. If the method must handle the
> task,
> then the method executes a special service task in the executor and
> returns.
> From that moment and up until the service task has finished all tasks that
> are
> added to the backlog are handled by this service task. The service task
> finishes
> when the backlog becomes empty.
>
> In other words, parties are busy with dumping their tasks on each other.
> Either
> a party gets lucky and can rest assured the task it has just added will be
> looked after, or it ends up with executing its task and, possibly, many
> others
> dumped on it by its luckier peers. In an extreme case where the underlying
> executor is a "calling thread executor" (`Executor executor =
> Runnable::run`),
> an unlucky party can get really buried itself in work. A metaphor for this
> strategy could be "work dumping" (or "work foisting").
>
> Without diving further into too much detail here are 2 components I would
> like
> to start with:
>
>   1. MutexExecutor
>
> https://github.com/lightbend/microprofile-reactive-streams/blob/master/zerodep/src/main/java/com/lightbend/microprofile/reactive/streams/zerodep/MutexExecutor.java
>   2. SequentialScheduler[^1]
>
> http://hg.openjdk.java.net/jdk/jdk11/file/ee6f7a61f3a5/src/java.net.http/share/classes/jdk/internal/net/http/common/SequentialScheduler.java
>
> I believe that a similar (though a bit more sophisticated) primitive was
> implemented
> in `java.util.concurrent.SubmissionPublisher`.
>
> Do you think they fit into the idea described above? Could there be some
> common
> mechanics extracted? Is there any potentially reusable component? Are
> there any
> other contexts in which this can be used?
>
> Thanks,
> -Pavel
>
> [^1]: `SequentialScheduler` evolved from a much simpler
> `CooperativeHandler`
> http://hg.openjdk.java.net/jdk9/sandbox/jdk/file/7c7a3c48196e/src/jdk.incubator.httpclient/share/classes/jdk/incubator/http/internal/websocket/CooperativeHandler.java
> adding asynchronous tasks and an underlying executor.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20181001/b034badb/attachment.html>

