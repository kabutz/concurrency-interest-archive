From nader at aeinehchi.com  Wed Nov  3 05:07:13 2010
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Wed, 03 Nov 2010 10:07:13 +0100
Subject: [concurrency-interest] How to implement a self populating memoizer
	cache?
Message-ID: <4CD12641.3010306@aeinehchi.com>

Hello

How can a self populating cache be implemented?

Requirements:

1. the put(key,value) operation will be a memoizer (value = 
computer(computable)) where computable==key.
2. how can a remove operation be implemented?
3. the cache will be thread safe
4. the cache will have a good performance for up to upper medium 
contention (i.e. very high contention is not required)
5. preferrably a non-blocking algorithm
6. no need for timers,....

In advance, thank you very much.


From wangfabo1986 at gmail.com  Wed Nov  3 05:40:01 2010
From: wangfabo1986 at gmail.com (fabo wang)
Date: Wed, 3 Nov 2010 17:40:01 +0800
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <4CD12641.3010306@aeinehchi.com>
References: <4CD12641.3010306@aeinehchi.com>
Message-ID: <AANLkTikJOoarR2hX7X521DAzGdVxteUQM_LbmYncvqKs@mail.gmail.com>

the book?Java Concurrency in Practice?give a simple solution.



2010/11/3 Nader Aeinehchi <nader at aeinehchi.com>

> Hello
>
> How can a self populating cache be implemented?
>
> Requirements:
>
> 1. the put(key,value) operation will be a memoizer (value =
> computer(computable)) where computable==key.
> 2. how can a remove operation be implemented?
> 3. the cache will be thread safe
> 4. the cache will have a good performance for up to upper medium contention
> (i.e. very high contention is not required)
> 5. preferrably a non-blocking algorithm
> 6. no need for timers,....
>
> In advance, thank you very much.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
computer science???
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/12275990/attachment.html>

From nader at aeinehchi.com  Wed Nov  3 07:31:57 2010
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Wed, 03 Nov 2010 12:31:57 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTikJOoarR2hX7X521DAzGdVxteUQM_LbmYncvqKs@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTikJOoarR2hX7X521DAzGdVxteUQM_LbmYncvqKs@mail.gmail.com>
Message-ID: <4CD1482D.40906@aeinehchi.com>

Would you kindly refer more specifically to which part of the book?

Thanks

Nader Aeinehchi



On 11/03/2010 10:40 AM, fabo wang wrote:
> the book?Java Concurrency in Practice?give a simple solution.
>
>
>
> 2010/11/3 Nader Aeinehchi <nader at aeinehchi.com
> <mailto:nader at aeinehchi.com>>
>
>     Hello
>
>     How can a self populating cache be implemented?
>
>     Requirements:
>
>     1. the put(key,value) operation will be a memoizer (value =
>     computer(computable)) where computable==key.
>     2. how can a remove operation be implemented?
>     3. the cache will be thread safe
>     4. the cache will have a good performance for up to upper medium
>     contention (i.e. very high contention is not required)
>     5. preferrably a non-blocking algorithm
>     6. no need for timers,....
>
>     In advance, thank you very much.
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> computer science???
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/ac296647/attachment.html>

From karmazilla at gmail.com  Wed Nov  3 07:48:05 2010
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Wed, 3 Nov 2010 12:48:05 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <4CD12641.3010306@aeinehchi.com>
References: <4CD12641.3010306@aeinehchi.com>
Message-ID: <AANLkTi=A1FdZPrwarhge1kZkCZC8RwWgUKXivG0+Vidd@mail.gmail.com>

Here's a simple algorithm based on ConcurrentHashMap:

Try .get'ing the value by the key.
 * If the value is a CountDownLatch, then wait on the latch, then get
again and return that value.
 * If the value is otherwise something non-null, then return it.
 * If the value is null, then create a new CountDownLatch with count
1, and putIfAbsent on the key.
 ** If the value returned by putIfAbsent is null, then create our real
value, put it, and count the latch down.
 ** If the value is a latch, wait on it and return the result of getting again.
 ** Otherwise return whatever you got.

Note that this algorithm does not support nulls as values, so you'd
have to use a Null Object if you need to support nulls.

On Wed, Nov 3, 2010 at 10:07, Nader Aeinehchi <nader at aeinehchi.com> wrote:
> Hello
>
> How can a self populating cache be implemented?
>
> Requirements:
>
> 1. the put(key,value) operation will be a memoizer (value =
> computer(computable)) where computable==key.
> 2. how can a remove operation be implemented?
> 3. the cache will be thread safe
> 4. the cache will have a good performance for up to upper medium contention
> (i.e. very high contention is not required)
> 5. preferrably a non-blocking algorithm
> 6. no need for timers,....
>
> In advance, thank you very much.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.

From dhanji at gmail.com  Wed Nov  3 08:18:48 2010
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 3 Nov 2010 23:18:48 +1100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <4CD12641.3010306@aeinehchi.com>
References: <4CD12641.3010306@aeinehchi.com>
Message-ID: <AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>

Take a look at the implementation of MapMaker from guava libraries. That
should give you some ideas too.

Dhanji.

On Wed, Nov 3, 2010 at 8:07 PM, Nader Aeinehchi <nader at aeinehchi.com> wrote:

> Hello
>
> How can a self populating cache be implemented?
>
> Requirements:
>
> 1. the put(key,value) operation will be a memoizer (value =
> computer(computable)) where computable==key.
> 2. how can a remove operation be implemented?
> 3. the cache will be thread safe
> 4. the cache will have a good performance for up to upper medium contention
> (i.e. very high contention is not required)
> 5. preferrably a non-blocking algorithm
> 6. no need for timers,....
>
> In advance, thank you very much.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/5801f6b0/attachment.html>

From viktor.klang at gmail.com  Wed Nov  3 08:26:03 2010
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3IgS2xhbmc=?=)
Date: Wed, 3 Nov 2010 13:26:03 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTi=A1FdZPrwarhge1kZkCZC8RwWgUKXivG0+Vidd@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTi=A1FdZPrwarhge1kZkCZC8RwWgUKXivG0+Vidd@mail.gmail.com>
Message-ID: <AANLkTinUC4-c00B==Hwq3O4e+rKzAkFUesNGJ21OTQnH@mail.gmail.com>

How do you do cache evictions/invalidations on top of that? Storing
SoftRefs?

On Wed, Nov 3, 2010 at 12:48 PM, Christian Vest Hansen <karmazilla at gmail.com
> wrote:

> Here's a simple algorithm based on ConcurrentHashMap:
>
> Try .get'ing the value by the key.
>  * If the value is a CountDownLatch, then wait on the latch, then get
> again and return that value.
>  * If the value is otherwise something non-null, then return it.
>  * If the value is null, then create a new CountDownLatch with count
> 1, and putIfAbsent on the key.
>  ** If the value returned by putIfAbsent is null, then create our real
> value, put it, and count the latch down.
>  ** If the value is a latch, wait on it and return the result of getting
> again.
>  ** Otherwise return whatever you got.
>
> Note that this algorithm does not support nulls as values, so you'd
> have to use a Null Object if you need to support nulls.
>
> On Wed, Nov 3, 2010 at 10:07, Nader Aeinehchi <nader at aeinehchi.com> wrote:
> > Hello
> >
> > How can a self populating cache be implemented?
> >
> > Requirements:
> >
> > 1. the put(key,value) operation will be a memoizer (value =
> > computer(computable)) where computable==key.
> > 2. how can a remove operation be implemented?
> > 3. the cache will be thread safe
> > 4. the cache will have a good performance for up to upper medium
> contention
> > (i.e. very high contention is not required)
> > 5. preferrably a non-blocking algorithm
> > 6. no need for timers,....
> >
> > In advance, thank you very much.
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
> --
> Venlig hilsen / Kind regards,
> Christian Vest Hansen.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang,
Code Connoisseur
Work:   akka.io
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/6638d1e3/attachment.html>

From nader at aeinehchi.com  Wed Nov  3 08:31:11 2010
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Wed, 03 Nov 2010 13:31:11 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
Message-ID: <4CD1560F.5080004@aeinehchi.com>

When I investigate the code in ExpiringComputingMap in MapMaker, I find 
blocks of code that seem to be compound operations (read-modify-write as 
stated on page 22 of JCiP book).

1. Please forgive me for my ignorance, but ExpiringComputingMap does not 
guarantee that a computable to be calculated only once for concurrent 
threads?
2. However, if we relax the requirement "only once" and allow a 
computable to be calculated few times, ExpiringComputingMap will work fine?




On 11/03/2010 01:18 PM, Dhanji R. Prasanna wrote:
> Take a look at the implementation of MapMaker from guava libraries. 
> That should give you some ideas too.
>
> Dhanji.
>
> On Wed, Nov 3, 2010 at 8:07 PM, Nader Aeinehchi <nader at aeinehchi.com 
> <mailto:nader at aeinehchi.com>> wrote:
>
>     Hello
>
>     How can a self populating cache be implemented?
>
>     Requirements:
>
>     1. the put(key,value) operation will be a memoizer (value =
>     computer(computable)) where computable==key.
>     2. how can a remove operation be implemented?
>     3. the cache will be thread safe
>     4. the cache will have a good performance for up to upper medium
>     contention (i.e. very high contention is not required)
>     5. preferrably a non-blocking algorithm
>     6. no need for timers,....
>
>     In advance, thank you very much.
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/e890df7e/attachment-0001.html>

From karmazilla at gmail.com  Wed Nov  3 08:44:16 2010
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Wed, 3 Nov 2010 13:44:16 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTinUC4-c00B==Hwq3O4e+rKzAkFUesNGJ21OTQnH@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTi=A1FdZPrwarhge1kZkCZC8RwWgUKXivG0+Vidd@mail.gmail.com>
	<AANLkTinUC4-c00B==Hwq3O4e+rKzAkFUesNGJ21OTQnH@mail.gmail.com>
Message-ID: <AANLkTinOa5wEASsF_XRQd1WzUDogKjRHSc0gOuxv=AjG@mail.gmail.com>

Oh, didn't spot that requirement at first.

If you wrap the get-code in a retry-if-we-got-null loop, then you just
remove the mapping if you think you no longer need it.

On Wed, Nov 3, 2010 at 13:26, ?iktor Klang <viktor.klang at gmail.com> wrote:
> How do you do cache evictions/invalidations on top of that? Storing
> SoftRefs?
>
> On Wed, Nov 3, 2010 at 12:48 PM, Christian Vest Hansen
> <karmazilla at gmail.com> wrote:
>>
>> Here's a simple algorithm based on ConcurrentHashMap:
>>
>> Try .get'ing the value by the key.
>> ?* If the value is a CountDownLatch, then wait on the latch, then get
>> again and return that value.
>> ?* If the value is otherwise something non-null, then return it.
>> ?* If the value is null, then create a new CountDownLatch with count
>> 1, and putIfAbsent on the key.
>> ?** If the value returned by putIfAbsent is null, then create our real
>> value, put it, and count the latch down.
>> ?** If the value is a latch, wait on it and return the result of getting
>> again.
>> ?** Otherwise return whatever you got.
>>
>> Note that this algorithm does not support nulls as values, so you'd
>> have to use a Null Object if you need to support nulls.
>>
>> On Wed, Nov 3, 2010 at 10:07, Nader Aeinehchi <nader at aeinehchi.com> wrote:
>> > Hello
>> >
>> > How can a self populating cache be implemented?
>> >
>> > Requirements:
>> >
>> > 1. the put(key,value) operation will be a memoizer (value =
>> > computer(computable)) where computable==key.
>> > 2. how can a remove operation be implemented?
>> > 3. the cache will be thread safe
>> > 4. the cache will have a good performance for up to upper medium
>> > contention
>> > (i.e. very high contention is not required)
>> > 5. preferrably a non-blocking algorithm
>> > 6. no need for timers,....
>> >
>> > In advance, thank you very much.
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>>
>>
>>
>> --
>> Venlig hilsen / Kind regards,
>> Christian Vest Hansen.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> --
> Viktor Klang,
> Code Connoisseur
> Work:?? akka.io
> Code:?? github.com/viktorklang
> Follow: twitter.com/viktorklang
> Read:?? klangism.tumblr.com
>
>



-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.


From kevinb at google.com  Wed Nov  3 10:15:02 2010
From: kevinb at google.com (Kevin Bourrillion)
Date: Wed, 3 Nov 2010 07:15:02 -0700
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <4CD1560F.5080004@aeinehchi.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
Message-ID: <AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>

On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi <nader at aeinehchi.com> wrote:

1. Please forgive me for my ignorance, but ExpiringComputingMap does not
> guarantee that a computable to be calculated only once for concurrent
> threads?
>

"Map.get(java.lang.Object)<http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get(java.lang.Object)>
 either returns an already-computed value for the given key, atomically
computes it using the supplied function, or, if another thread is currently
computing the value for this key, simply waits for that thread to finish and
returns its computed value. Note that the function may be executed
concurrently by multiple threads, but only for distinct keys."


-- 
Kevin Bourrillion @ Google
http://guava-libraries.googlecode.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/5ece6b66/attachment.html>

From nader at aeinehchi.com  Wed Nov  3 16:47:49 2010
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Wed, 03 Nov 2010 21:47:49 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
	<AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
Message-ID: <4CD1CA75.3030609@aeinehchi.com>

Dear Kevin,

If I understand you correctly, MapMaker.ExpiringComputingMap (which I 
believe you are referring to) is thread safe.  Furthermore, it 
guarantees that threads will wait until the first thread computes for a 
given key.

Following is an excerpt of MapMaker.ExpiringComputingMap.  Here, if the 
result is null, the compute method is called and the calculated value is 
put.  How is it guaranteed that another thread does not concurrently 
perform the latter (calculation and put operations)?  Is not this a 
read-modify-write scheme which according to JCiP book is a compound (not 
atomic) operation?

In advance, thank you very much.


     @Override
     public V get(Object k) {
       // from CustomConcurrentHashMap
       V result = super.get(k);
       if (result == null && computer != null) {
         /*
          * This cast isn't safe, but we can rely on the fact that K is 
almost
          * always passed to Map.get(), and tools like IDEs and Findbugs can
          * catch situations where this isn't the case.
          *
          * The alternative is to add an overloaded method, but the 
chances of
          * a user calling get() instead of the new API and the risks 
inherent
          * in adding a new API outweigh this little hole.
          */
         @SuppressWarnings("unchecked")
         K key = (K) k;
         result = compute(key);
       }
       return result;
     }

     private V compute(K key) {
       // from MapMaker
       V value;
       try {
         value = computer.apply(key);
       } catch (Throwable t) {
         throw new ComputationException(t);
       }

       if (value == null) {
         String message = computer + " returned null for key " + key + ".";
         throw new NullPointerException(message);
       }
       put(key, value);
       return value;
     }



On 11/03/2010 03:15 PM, Kevin Bourrillion wrote:
> On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi <nader at aeinehchi.com 
> <mailto:nader at aeinehchi.com>> wrote:
>
>     1. Please forgive me for my ignorance, but ExpiringComputingMap
>     does not guarantee that a computable to be calculated only once
>     for concurrent threads?
>
>
> "|Map.get(java.lang.Object)| 
> <http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get%28java.lang.Object%29> 
> either returns an already-computed value for the given key, atomically 
> computes it using the supplied function, or, if another thread is 
> currently computing the value for this key, simply waits for that 
> thread to finish and returns its computed value. Note that the 
> function may be executed concurrently by multiple threads, but only 
> for distinct keys."
>
>
> -- 
> Kevin Bourrillion @ Google
> http://guava-libraries.googlecode.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/d72fd3b7/attachment.html>

From fry at google.com  Wed Nov  3 16:59:23 2010
From: fry at google.com (Charles Fry)
Date: Wed, 3 Nov 2010 16:59:23 -0400
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <4CD1CA75.3030609@aeinehchi.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
	<AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
	<4CD1CA75.3030609@aeinehchi.com>
Message-ID: <AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>

It looks like you're looking at an old version of MapMaker. Check out the
version in the guava project:


http://code.google.com/p/guava-libraries/source/browse/trunk/src/com/google/common/collect/ComputingConcurrentHashMap.java#76

Charles

On Wed, Nov 3, 2010 at 16:47, Nader Aeinehchi <nader at aeinehchi.com> wrote:

>  Dear Kevin,
>
> If I understand you correctly, MapMaker.ExpiringComputingMap (which I
> believe you are referring to) is thread safe.  Furthermore, it guarantees
> that threads will wait until the first thread computes for a given key.
>
> Following is an excerpt of MapMaker.ExpiringComputingMap.  Here, if the
> result is null, the compute method is called and the calculated value is
> put.  How is it guaranteed that another thread does not concurrently perform
> the latter (calculation and put operations)?  Is not this a
> read-modify-write scheme which according to JCiP book is a compound (not
> atomic) operation?
>
>
> In advance, thank you very much.
>
>
>     @Override
>     public V get(Object k) {
>       // from CustomConcurrentHashMap
>       V result = super.get(k);
>       if (result == null && computer != null) {
>         /*
>          * This cast isn't safe, but we can rely on the fact that K is
> almost
>          * always passed to Map.get(), and tools like IDEs and Findbugs can
>          * catch situations where this isn't the case.
>          *
>          * The alternative is to add an overloaded method, but the chances
> of
>          * a user calling get() instead of the new API and the risks
> inherent
>          * in adding a new API outweigh this little hole.
>          */
>         @SuppressWarnings("unchecked")
>         K key = (K) k;
>         result = compute(key);
>       }
>       return result;
>     }
>
>     private V compute(K key) {
>       // from MapMaker
>       V value;
>       try {
>         value = computer.apply(key);
>       } catch (Throwable t) {
>         throw new ComputationException(t);
>       }
>
>       if (value == null) {
>         String message = computer + " returned null for key " + key + ".";
>         throw new NullPointerException(message);
>       }
>       put(key, value);
>       return value;
>
>     }
>
>
>
> On 11/03/2010 03:15 PM, Kevin Bourrillion wrote:
>
> On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi <nader at aeinehchi.com>wrote:
>
>  1. Please forgive me for my ignorance, but ExpiringComputingMap does not
>> guarantee that a computable to be calculated only once for concurrent
>> threads?
>>
>
>  "Map.get(java.lang.Object)<http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get%28java.lang.Object%29>
>  either returns an already-computed value for the given key, atomically
> computes it using the supplied function, or, if another thread is currently
> computing the value for this key, simply waits for that thread to finish and
> returns its computed value. Note that the function may be executed
> concurrently by multiple threads, but only for distinct keys."
>
>
>  --
> Kevin Bourrillion @ Google
> http://guava-libraries.googlecode.com
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/f1c8fdfb/attachment.html>

From nader at aeinehchi.com  Wed Nov  3 17:02:29 2010
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Wed, 03 Nov 2010 22:02:29 +0100
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
	<AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
	<4CD1CA75.3030609@aeinehchi.com>
	<AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>
Message-ID: <4CD1CDE5.10505@aeinehchi.com>

Dear Charles

Thank you very much for the link.  It explains a lot!  I was looking at 
the old code and it simply seemed wrong.  Many thanks.



On 11/03/2010 09:59 PM, Charles Fry wrote:
> It looks like you're looking at an old version of MapMaker. Check out 
> the version in the guava project:
>
> http://code.google.com/p/guava-libraries/source/browse/trunk/src/com/google/common/collect/ComputingConcurrentHashMap.java#76
>
> Charles
>
> On Wed, Nov 3, 2010 at 16:47, Nader Aeinehchi <nader at aeinehchi.com 
> <mailto:nader at aeinehchi.com>> wrote:
>
>     Dear Kevin,
>
>     If I understand you correctly, MapMaker.ExpiringComputingMap
>     (which I believe you are referring to) is thread safe. 
>     Furthermore, it guarantees that threads will wait until the first
>     thread computes for a given key.
>
>     Following is an excerpt of MapMaker.ExpiringComputingMap.  Here,
>     if the result is null, the compute method is called and the
>     calculated value is put.  How is it guaranteed that another thread
>     does not concurrently perform the latter (calculation and put
>     operations)?  Is not this a read-modify-write scheme which
>     according to JCiP book is a compound (not atomic) operation?
>
>
>     In advance, thank you very much.
>
>
>         @Override
>         public V get(Object k) {
>           // from CustomConcurrentHashMap
>           V result = super.get(k);
>           if (result == null && computer != null) {
>             /*
>              * This cast isn't safe, but we can rely on the fact that
>     K is almost
>              * always passed to Map.get(), and tools like IDEs and
>     Findbugs can
>              * catch situations where this isn't the case.
>              *
>              * The alternative is to add an overloaded method, but the
>     chances of
>              * a user calling get() instead of the new API and the
>     risks inherent
>              * in adding a new API outweigh this little hole.
>              */
>             @SuppressWarnings("unchecked")
>             K key = (K) k;
>             result = compute(key);
>           }
>           return result;
>         }
>
>         private V compute(K key) {
>           // from MapMaker
>           V value;
>           try {
>             value = computer.apply(key);
>           } catch (Throwable t) {
>             throw new ComputationException(t);
>           }
>
>           if (value == null) {
>             String message = computer + " returned null for key " +
>     key + ".";
>             throw new NullPointerException(message);
>           }
>           put(key, value);
>           return value;
>
>         }
>
>
>
>     On 11/03/2010 03:15 PM, Kevin Bourrillion wrote:
>>     On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi
>>     <nader at aeinehchi.com <mailto:nader at aeinehchi.com>> wrote:
>>
>>         1. Please forgive me for my ignorance, but
>>         ExpiringComputingMap does not guarantee that a computable to
>>         be calculated only once for concurrent threads?
>>
>>
>>     "|Map.get(java.lang.Object)|
>>     <http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get%28java.lang.Object%29>
>>     either returns an already-computed value for the given key,
>>     atomically computes it using the supplied function, or, if
>>     another thread is currently computing the value for this key,
>>     simply waits for that thread to finish and returns its computed
>>     value. Note that the function may be executed concurrently by
>>     multiple threads, but only for distinct keys."
>>
>>
>>     -- 
>>     Kevin Bourrillion @ Google
>>     http://guava-libraries.googlecode.com
>>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/8bf018bf/attachment-0001.html>

From kevinb at google.com  Wed Nov  3 18:14:49 2010
From: kevinb at google.com (Kevin Bourrillion)
Date: Wed, 3 Nov 2010 15:14:49 -0700
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
	<AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
	<4CD1CA75.3030609@aeinehchi.com>
	<AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>
Message-ID: <AANLkTimRRFibpxtYt_Y6sYKcdpz+GiiROnmvFeeTWZtE@mail.gmail.com>

Actually, I think he's looking at the GWT version of MapMaker, which is Java
code that is meant to be converted to Javascript and run -- single-threaded!
-- in the browser.  Confusing, I know.



On Wed, Nov 3, 2010 at 1:59 PM, Charles Fry <fry at google.com> wrote:

> It looks like you're looking at an old version of MapMaker. Check out the
> version in the guava project:
>
>
> http://code.google.com/p/guava-libraries/source/browse/trunk/src/com/google/common/collect/ComputingConcurrentHashMap.java#76
>
> Charles
>
> On Wed, Nov 3, 2010 at 16:47, Nader Aeinehchi <nader at aeinehchi.com> wrote:
>
>>  Dear Kevin,
>>
>> If I understand you correctly, MapMaker.ExpiringComputingMap (which I
>> believe you are referring to) is thread safe.  Furthermore, it guarantees
>> that threads will wait until the first thread computes for a given key.
>>
>> Following is an excerpt of MapMaker.ExpiringComputingMap.  Here, if the
>> result is null, the compute method is called and the calculated value is
>> put.  How is it guaranteed that another thread does not concurrently perform
>> the latter (calculation and put operations)?  Is not this a
>> read-modify-write scheme which according to JCiP book is a compound (not
>> atomic) operation?
>>
>>
>> In advance, thank you very much.
>>
>>
>>     @Override
>>     public V get(Object k) {
>>       // from CustomConcurrentHashMap
>>       V result = super.get(k);
>>       if (result == null && computer != null) {
>>         /*
>>          * This cast isn't safe, but we can rely on the fact that K is
>> almost
>>          * always passed to Map.get(), and tools like IDEs and Findbugs
>> can
>>          * catch situations where this isn't the case.
>>          *
>>          * The alternative is to add an overloaded method, but the chances
>> of
>>          * a user calling get() instead of the new API and the risks
>> inherent
>>          * in adding a new API outweigh this little hole.
>>          */
>>         @SuppressWarnings("unchecked")
>>         K key = (K) k;
>>         result = compute(key);
>>       }
>>       return result;
>>     }
>>
>>     private V compute(K key) {
>>       // from MapMaker
>>       V value;
>>       try {
>>         value = computer.apply(key);
>>       } catch (Throwable t) {
>>         throw new ComputationException(t);
>>       }
>>
>>       if (value == null) {
>>         String message = computer + " returned null for key " + key + ".";
>>         throw new NullPointerException(message);
>>       }
>>       put(key, value);
>>       return value;
>>
>>     }
>>
>>
>>
>> On 11/03/2010 03:15 PM, Kevin Bourrillion wrote:
>>
>> On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi <nader at aeinehchi.com>wrote:
>>
>>  1. Please forgive me for my ignorance, but ExpiringComputingMap does not
>>> guarantee that a computable to be calculated only once for concurrent
>>> threads?
>>>
>>
>>  "Map.get(java.lang.Object)<http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get%28java.lang.Object%29>
>>  either returns an already-computed value for the given key, atomically
>> computes it using the supplied function, or, if another thread is currently
>> computing the value for this key, simply waits for that thread to finish and
>> returns its computed value. Note that the function may be executed
>> concurrently by multiple threads, but only for distinct keys."
>>
>>
>>  --
>> Kevin Bourrillion @ Google
>> http://guava-libraries.googlecode.com
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Kevin Bourrillion @ Google
http://guava-libraries.googlecode.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/18f51791/attachment.html>

From wangfabo1986 at gmail.com  Wed Nov  3 21:10:20 2010
From: wangfabo1986 at gmail.com (fabo wang)
Date: Thu, 4 Nov 2010 09:10:20 +0800
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTimRRFibpxtYt_Y6sYKcdpz+GiiROnmvFeeTWZtE@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
	<AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
	<4CD1CA75.3030609@aeinehchi.com>
	<AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>
	<AANLkTimRRFibpxtYt_Y6sYKcdpz+GiiROnmvFeeTWZtE@mail.gmail.com>
Message-ID: <AANLkTikZ=XuxFuvecT9oPrgWs-KHzN6q-xtcW2W_YMEY@mail.gmail.com>

Chapter 5,section 6.the book ?java concurrency in practic?

2010/11/4 Kevin Bourrillion <kevinb at google.com>

> Actually, I think he's looking at the GWT version of MapMaker, which is
> Java code that is meant to be converted to Javascript and run --
> single-threaded! -- in the browser.  Confusing, I know.
>
>
>
> On Wed, Nov 3, 2010 at 1:59 PM, Charles Fry <fry at google.com> wrote:
>
>> It looks like you're looking at an old version of MapMaker. Check out the
>> version in the guava project:
>>
>>
>> http://code.google.com/p/guava-libraries/source/browse/trunk/src/com/google/common/collect/ComputingConcurrentHashMap.java#76
>>
>> Charles
>>
>> On Wed, Nov 3, 2010 at 16:47, Nader Aeinehchi <nader at aeinehchi.com>wrote:
>>
>>>  Dear Kevin,
>>>
>>> If I understand you correctly, MapMaker.ExpiringComputingMap (which I
>>> believe you are referring to) is thread safe.  Furthermore, it guarantees
>>> that threads will wait until the first thread computes for a given key.
>>>
>>> Following is an excerpt of MapMaker.ExpiringComputingMap.  Here, if the
>>> result is null, the compute method is called and the calculated value is
>>> put.  How is it guaranteed that another thread does not concurrently perform
>>> the latter (calculation and put operations)?  Is not this a
>>> read-modify-write scheme which according to JCiP book is a compound (not
>>> atomic) operation?
>>>
>>>
>>> In advance, thank you very much.
>>>
>>>
>>>     @Override
>>>     public V get(Object k) {
>>>       // from CustomConcurrentHashMap
>>>       V result = super.get(k);
>>>       if (result == null && computer != null) {
>>>         /*
>>>          * This cast isn't safe, but we can rely on the fact that K is
>>> almost
>>>          * always passed to Map.get(), and tools like IDEs and Findbugs
>>> can
>>>          * catch situations where this isn't the case.
>>>          *
>>>          * The alternative is to add an overloaded method, but the
>>> chances of
>>>          * a user calling get() instead of the new API and the risks
>>> inherent
>>>          * in adding a new API outweigh this little hole.
>>>          */
>>>         @SuppressWarnings("unchecked")
>>>         K key = (K) k;
>>>         result = compute(key);
>>>       }
>>>       return result;
>>>     }
>>>
>>>     private V compute(K key) {
>>>       // from MapMaker
>>>       V value;
>>>       try {
>>>         value = computer.apply(key);
>>>       } catch (Throwable t) {
>>>         throw new ComputationException(t);
>>>       }
>>>
>>>       if (value == null) {
>>>         String message = computer + " returned null for key " + key +
>>> ".";
>>>         throw new NullPointerException(message);
>>>       }
>>>       put(key, value);
>>>       return value;
>>>
>>>     }
>>>
>>>
>>>
>>> On 11/03/2010 03:15 PM, Kevin Bourrillion wrote:
>>>
>>> On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi <nader at aeinehchi.com>wrote:
>>>
>>>  1. Please forgive me for my ignorance, but ExpiringComputingMap does
>>>> not guarantee that a computable to be calculated only once for concurrent
>>>> threads?
>>>>
>>>
>>>  "Map.get(java.lang.Object)<http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get%28java.lang.Object%29>
>>>  either returns an already-computed value for the given key, atomically
>>> computes it using the supplied function, or, if another thread is currently
>>> computing the value for this key, simply waits for that thread to finish and
>>> returns its computed value. Note that the function may be executed
>>> concurrently by multiple threads, but only for distinct keys."
>>>
>>>
>>>  --
>>> Kevin Bourrillion @ Google
>>> http://guava-libraries.googlecode.com
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Kevin Bourrillion @ Google
> http://guava-libraries.googlecode.com
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
computer science???
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101104/8272ce68/attachment-0001.html>

From tim at peierls.net  Wed Nov  3 21:36:36 2010
From: tim at peierls.net (Tim Peierls)
Date: Wed, 3 Nov 2010 21:36:36 -0400
Subject: [concurrency-interest] How to implement a self populating
 memoizer cache?
In-Reply-To: <AANLkTikZ=XuxFuvecT9oPrgWs-KHzN6q-xtcW2W_YMEY@mail.gmail.com>
References: <4CD12641.3010306@aeinehchi.com>
	<AANLkTinaZ4eboYn0QLr=f5Z9D1bd-W-LSX+fgQ6cSH+x@mail.gmail.com>
	<4CD1560F.5080004@aeinehchi.com>
	<AANLkTinu=eSu8_LZ=WNqvCwvmg38OSPNGOygmj6cuKAt@mail.gmail.com>
	<4CD1CA75.3030609@aeinehchi.com>
	<AANLkTine0E=fipOOh=+To-SU7z0wpuFXy+_-gaGQj8pE@mail.gmail.com>
	<AANLkTimRRFibpxtYt_Y6sYKcdpz+GiiROnmvFeeTWZtE@mail.gmail.com>
	<AANLkTikZ=XuxFuvecT9oPrgWs-KHzN6q-xtcW2W_YMEY@mail.gmail.com>
Message-ID: <AANLkTikW7xh-GimwCgYSLFdmaw_P9QEH-rS5NFgzwBqm@mail.gmail.com>

The Memoizer class presented in that section is only to illustrate a
technique. It lacks a number of useful features, and it is nowhere near
production-ready.

Use MapMaker anywhere you might have been tempted to use or adapt Memoizer.

--tim

2010/11/3 fabo wang <wangfabo1986 at gmail.com>

> Chapter 5,section 6.the book ?java concurrency in practic?
>
> 2010/11/4 Kevin Bourrillion <kevinb at google.com>
>
> Actually, I think he's looking at the GWT version of MapMaker, which is
>> Java code that is meant to be converted to Javascript and run --
>> single-threaded! -- in the browser.  Confusing, I know.
>>
>>
>>
>> On Wed, Nov 3, 2010 at 1:59 PM, Charles Fry <fry at google.com> wrote:
>>
>>> It looks like you're looking at an old version of MapMaker. Check out the
>>> version in the guava project:
>>>
>>>
>>> http://code.google.com/p/guava-libraries/source/browse/trunk/src/com/google/common/collect/ComputingConcurrentHashMap.java#76
>>>
>>> Charles
>>>
>>> On Wed, Nov 3, 2010 at 16:47, Nader Aeinehchi <nader at aeinehchi.com>wrote:
>>>
>>>>  Dear Kevin,
>>>>
>>>> If I understand you correctly, MapMaker.ExpiringComputingMap (which I
>>>> believe you are referring to) is thread safe.  Furthermore, it guarantees
>>>> that threads will wait until the first thread computes for a given key.
>>>>
>>>> Following is an excerpt of MapMaker.ExpiringComputingMap.  Here, if the
>>>> result is null, the compute method is called and the calculated value is
>>>> put.  How is it guaranteed that another thread does not concurrently perform
>>>> the latter (calculation and put operations)?  Is not this a
>>>> read-modify-write scheme which according to JCiP book is a compound (not
>>>> atomic) operation?
>>>>
>>>>
>>>> In advance, thank you very much.
>>>>
>>>>
>>>>     @Override
>>>>     public V get(Object k) {
>>>>       // from CustomConcurrentHashMap
>>>>       V result = super.get(k);
>>>>       if (result == null && computer != null) {
>>>>         /*
>>>>          * This cast isn't safe, but we can rely on the fact that K is
>>>> almost
>>>>          * always passed to Map.get(), and tools like IDEs and Findbugs
>>>> can
>>>>          * catch situations where this isn't the case.
>>>>          *
>>>>          * The alternative is to add an overloaded method, but the
>>>> chances of
>>>>          * a user calling get() instead of the new API and the risks
>>>> inherent
>>>>          * in adding a new API outweigh this little hole.
>>>>          */
>>>>         @SuppressWarnings("unchecked")
>>>>         K key = (K) k;
>>>>         result = compute(key);
>>>>       }
>>>>       return result;
>>>>     }
>>>>
>>>>     private V compute(K key) {
>>>>       // from MapMaker
>>>>       V value;
>>>>       try {
>>>>         value = computer.apply(key);
>>>>       } catch (Throwable t) {
>>>>         throw new ComputationException(t);
>>>>       }
>>>>
>>>>       if (value == null) {
>>>>         String message = computer + " returned null for key " + key +
>>>> ".";
>>>>         throw new NullPointerException(message);
>>>>       }
>>>>       put(key, value);
>>>>       return value;
>>>>
>>>>     }
>>>>
>>>>
>>>>
>>>> On 11/03/2010 03:15 PM, Kevin Bourrillion wrote:
>>>>
>>>> On Wed, Nov 3, 2010 at 5:31 AM, Nader Aeinehchi <nader at aeinehchi.com>wrote:
>>>>
>>>>  1. Please forgive me for my ignorance, but ExpiringComputingMap does
>>>>> not guarantee that a computable to be calculated only once for concurrent
>>>>> threads?
>>>>>
>>>>
>>>>  "Map.get(java.lang.Object)<http://java.sun.com/javase/6/docs/api/java/util/Map.html?is-external=true#get%28java.lang.Object%29>
>>>>  either returns an already-computed value for the given key, atomically
>>>> computes it using the supplied function, or, if another thread is currently
>>>> computing the value for this key, simply waits for that thread to finish and
>>>> returns its computed value. Note that the function may be executed
>>>> concurrently by multiple threads, but only for distinct keys."
>>>>
>>>>
>>>>  --
>>>> Kevin Bourrillion @ Google
>>>> http://guava-libraries.googlecode.com
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> --
>> Kevin Bourrillion @ Google
>> http://guava-libraries.googlecode.com
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> computer science???
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101103/c6dee983/attachment.html>

From mydevgroup at gmail.com  Sat Nov  6 09:19:31 2010
From: mydevgroup at gmail.com (George)
Date: Sat, 06 Nov 2010 14:19:31 +0100
Subject: [concurrency-interest] Scheduling tasks using TimerTask
Message-ID: <C8FB1473.6003%mydevgroup@gmail.com>

Hi,

I am using java.util.Timer to schedule TimerTask at an interval of 24hours,
so for example, if I set a  timer task using Timer.schedule(TimerTask task,
Date tomorrow at 8am), then the actual execution takes place only after 6 to 7
seconds past the set time.

This observation is made on a linux box running jvm 1.6, with ntpd running.
Basically, longer the duration of scheduling more deviation is found. It is
found that the deviation increases linearly. (deviation is measured by using
System.currentTimeMillis- scheduledExecutionTime )
 
But on a standalone system with no ntp synchronization using similar JVM
version (1.6),  the scheduling works on second precision. It just deviates
by 20 to 30 milliseconds and deviation is constant.

I would be very grateful to know if there is any solution in Java to
maintain second precision on systems with ntp time synchronization enabled
(linux). In other words, If I schedule a task to be executed after 24hours ,
it should be executed on the second without any deviation of seconds from
the set time. Will it help if I make the wait time in millisecond to be a
multiple of 10/15ms, based on the systems timer interrupts.

Any suggestions would be highly appreciated. Please let me know if I need to
provide more details on the observation, such as the ntp drift .


Thanks,
George



Hello,
I am using java.util.Timer to schedule TimerTask at an interval of 24hours,
so for example, if I set a  timer task using Timer.schedule(TimerTask task,
Date tomorrow at 8am), then the actual execution takes place only after 6 to 7
seconds past the set time.

This observation is made on a linux box running jvm 1.6, with ntpd running.
Basically, longer the duration of scheduling more deviation is found. It is
found that the deviation increases linearly. (deviation is measured by using
scheduledExecutionTime() - System.currentTimeMillis())
 
But on a standalone system with no ntp synchronization using similar JVM
version (1.6),  the scheduling works on second precision. It just deviates
by 20 to 30 milliseconds and deviation is constant.

I would be very grateful to know if is there any solution in Java to
maintain second precision on systems with ntp time synchronization enabled
(linux). In other words, If I schedule a task to be executed after 24hours ,
it should be executed on the second without any deviation of seconds from
the set time.
Any suggestions would be highly appreciated. Please let me know if I need to
provide more details on the observation, such as the ntp drift .


Thanks,
George






From tim at peierls.net  Sat Nov  6 12:06:48 2010
From: tim at peierls.net (Tim Peierls)
Date: Sat, 6 Nov 2010 12:06:48 -0400
Subject: [concurrency-interest] Scheduling tasks using TimerTask
In-Reply-To: <C8FB1473.6003%mydevgroup@gmail.com>
References: <C8FB1473.6003%mydevgroup@gmail.com>
Message-ID: <AANLkTimq-PQEb++7bm6CwxFXYo7v7P5Rd4TTOR+6jxqQ@mail.gmail.com>

You could try ScheduledExecutorService.scheduleAtFixedRate<http://download.oracle.com/javase/6/docs/api/java/util/concurrent/ScheduledExecutorService.html#scheduleAtFixedRate(java.lang.Runnable,
long, long, java.util.concurrent.TimeUnit)>, but it sounds like what you
really want is some kind of cron facility, such as the one provided by
Google App Engine:

http://code.google.com/appengine/docs/java/config/cron.html

<http://code.google.com/appengine/docs/java/config/cron.html>--tim

On Sat, Nov 6, 2010 at 9:19 AM, George <mydevgroup at gmail.com> wrote:

> Hi,
>
> I am using java.util.Timer to schedule TimerTask at an interval of 24hours,
> so for example, if I set a  timer task using Timer.schedule(TimerTask task,
> Date tomorrow at 8am), then the actual execution takes place only after 6 to
> 7
> seconds past the set time.
>
> This observation is made on a linux box running jvm 1.6, with ntpd running.
> Basically, longer the duration of scheduling more deviation is found. It is
> found that the deviation increases linearly. (deviation is measured by
> using
> System.currentTimeMillis- scheduledExecutionTime )
>
> But on a standalone system with no ntp synchronization using similar JVM
> version (1.6),  the scheduling works on second precision. It just deviates
> by 20 to 30 milliseconds and deviation is constant.
>
> I would be very grateful to know if there is any solution in Java to
> maintain second precision on systems with ntp time synchronization enabled
> (linux). In other words, If I schedule a task to be executed after 24hours
> ,
> it should be executed on the second without any deviation of seconds from
> the set time. Will it help if I make the wait time in millisecond to be a
> multiple of 10/15ms, based on the systems timer interrupts.
>
> Any suggestions would be highly appreciated. Please let me know if I need
> to
> provide more details on the observation, such as the ntp drift .
>
>
> Thanks,
> George
>
>
>
> Hello,
> I am using java.util.Timer to schedule TimerTask at an interval of 24hours,
> so for example, if I set a  timer task using Timer.schedule(TimerTask task,
> Date tomorrow at 8am), then the actual execution takes place only after 6 to
> 7
> seconds past the set time.
>
> This observation is made on a linux box running jvm 1.6, with ntpd running.
> Basically, longer the duration of scheduling more deviation is found. It is
> found that the deviation increases linearly. (deviation is measured by
> using
> scheduledExecutionTime() - System.currentTimeMillis())
>
> But on a standalone system with no ntp synchronization using similar JVM
> version (1.6),  the scheduling works on second precision. It just deviates
> by 20 to 30 milliseconds and deviation is constant.
>
> I would be very grateful to know if is there any solution in Java to
> maintain second precision on systems with ntp time synchronization enabled
> (linux). In other words, If I schedule a task to be executed after 24hours
> ,
> it should be executed on the second without any deviation of seconds from
> the set time.
> Any suggestions would be highly appreciated. Please let me know if I need
> to
> provide more details on the observation, such as the ntp drift .
>
>
> Thanks,
> George
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101106/35b12166/attachment.html>

From dl at cs.oswego.edu  Sat Nov  6 12:43:23 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 06 Nov 2010 12:43:23 -0400
Subject: [concurrency-interest] Scheduling tasks using TimerTask
In-Reply-To: <C8FB1473.6003%mydevgroup@gmail.com>
References: <C8FB1473.6003%mydevgroup@gmail.com>
Message-ID: <4CD585AB.3030309@cs.oswego.edu>

On 11/06/10 09:19, George wrote:
>
> I would be very grateful to know if there is any solution in Java to
> maintain second precision on systems with ntp time synchronization enabled
> (linux). In other words, If I schedule a task to be executed after 24hours ,
> it should be executed on the second without any deviation of seconds from
> the set time.


If you are on a system with an unreliable system clock that undergoes
frequent ntp adjustment, you can, instead of requesting a
delay until a given time 24hrs from now, just ask for delay
of a few minutes. Then check deadline yourself --
if you've hit it, trigger action, else recalculate the
next few minutes interval based on current system time and delay again.
This is a little messy, but not hard.

-Doug

From mydevgroup at gmail.com  Sat Nov  6 20:39:22 2010
From: mydevgroup at gmail.com (George)
Date: Sun, 07 Nov 2010 00:39:22 +0000
Subject: [concurrency-interest] Scheduling tasks using TimerTask
In-Reply-To: <4CD585AB.3030309@cs.oswego.edu>
Message-ID: <C8FBA5BA.6012%mydevgroup@gmail.com>

Thanks very much for the suggestion, it is very informative,
I have tried scheduling the task few seconds before the actual deadline and
rescheduling it again for the target time with the recalculated time in
milli seconds. However, this approach doesn't work with frequent ntp
synchronization. It may be that the initial scheduling might have
accumulated error and the second rescheduling only occurs after the target
time has lapsed

As you suggested, if I reschedule the task recursively, say every 5 minutes
till I reach the target time (considering the target time to be 24hours from
a given time). Would there be any significant performance issue that could
be caused by repeated scheduling of TimerTask?


Thanks
George


On 06/11/2010 17:43, "Doug Lea" <dl at cs.oswego.edu> wrote:

> On 11/06/10 09:19, George wrote:
>> 
>> I would be very grateful to know if there is any solution in Java to
>> maintain second precision on systems with ntp time synchronization enabled
>> (linux). In other words, If I schedule a task to be executed after 24hours ,
>> it should be executed on the second without any deviation of seconds from
>> the set time.
> 
> 
> If you are on a system with an unreliable system clock that undergoes
> frequent ntp adjustment, you can, instead of requesting a
> delay until a given time 24hrs from now, just ask for delay
> of a few minutes. Then check deadline yourself --
> if you've hit it, trigger action, else recalculate the
> next few minutes interval based on current system time and delay again.
> This is a little messy, but not hard.
> 
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From jdmitchell at gmail.com  Sat Nov  6 23:10:41 2010
From: jdmitchell at gmail.com (John D. Mitchell)
Date: Sat, 6 Nov 2010 20:10:41 -0700
Subject: [concurrency-interest] Scheduling tasks using TimerTask
In-Reply-To: <C8FBA5BA.6012%mydevgroup@gmail.com>
References: <C8FBA5BA.6012%mydevgroup@gmail.com>
Message-ID: <CEE54AC3-098F-4E09-9828-354A17FBFAE2@gmail.com>


On Nov 6, 2010, at 17:39 , George wrote:
[...]
> Thanks very much for the suggestion, it is very informative,
> I have tried scheduling the task few seconds before the actual  
> deadline and
> rescheduling it again for the target time with the recalculated time  
> in
> milli seconds. However, this approach doesn't work with frequent ntp
> synchronization. It may be that the initial scheduling might have
> accumulated error and the second rescheduling only occurs after the  
> target
> time has lapsed

You might want to switch from using ntp to clockspeed, http://cr.yp.to/clockspeed.html 
.  Clockspeed's approach is much smoother than the random seeming  
changes due to ntp.

Have fun,
John




From jeffhain at rocketmail.com  Sun Nov  7 07:47:56 2010
From: jeffhain at rocketmail.com (Jeff Hain)
Date: Sun, 7 Nov 2010 12:47:56 +0000 (GMT)
Subject: [concurrency-interest] takeOrWake() method for a LinkedBlockingQueue
Message-ID: <83263.45030.qm@web29212.mail.ird.yahoo.com>

Hello.

I'm currently optimizing some scheduler (or Executor) implementation:
for ASAP schedules, it was using a LinkedList with synchronization, then
I switched to a LinkedBlockingQueue, using add(E) and take() methods.

The scheduler has start()/stop() methods, so I need to be able to tell worker
threads in take() method to stop waiting for an ASAP schedule, and wait for
being allowed to work again.
(pending schedules need to be reachable any time, for there is a 
cancelSchedules()
method, so if take() returns a schedule and work status is false, I can't just 
wait for
it to be true again, since after take() returns the schedule is no longer 
reachable)

The simplest way I found to have a take() that can stop waiting was to extend
LinkedBlockingQueue, and add a takeOrWake() method, which is basically
take() with
>while (count.get() == 0) {
>   notEmpty.await();
>}
replaced with
>if (count.get() == 0) {
>   notEmpty.await();
>   if (count.get() == 0) {
>      // signal or spurious wake-up
>      return null;
>   }
>}
(I also removed the call to signalNotFull(), which breaks put(E) and
offer(E,long,TimeUnit) methods, but I don't use them.)

I had to use reflection to access some private fields and dequeue()
method used in take() method.

My concern is, I don't really like this solution, for reflection is a bit
hacky and might have some performance hit.

On the other hand, I don't really want to copy-paste-modify the whole
LinkedBlockingQueue class, and calling dequeue() through reflection
does not seem to have a noticeable performance hit in my benches.

If anyone has a nicer solution to this problem, or can confirm that
reflection should not hurt in that case, I would be pleased to hear it.

Regards,

Jeff


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101107/943ad0da/attachment.html>

From martinrb at google.com  Sun Nov  7 17:58:12 2010
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 7 Nov 2010 14:58:12 -0800
Subject: [concurrency-interest] takeOrWake() method for a
	LinkedBlockingQueue
In-Reply-To: <83263.45030.qm@web29212.mail.ird.yahoo.com>
References: <83263.45030.qm@web29212.mail.ird.yahoo.com>
Message-ID: <AANLkTi=z7kKnmAmt9w4o7wz-YuFm6_gcOR1w5Gg6gQta@mail.gmail.com>

Writing a thread pool is non-trivial.

ThreadPoolExecutor tackles some of the same sort of issues, e.g. need
to notify waiting threads on shutdown.

The most obvious thing to do is to interrupt waiting threads, have
them catch InterruptedException, and then reexamine the state of the
executor.  See TPE.interruptIdleWorkers for inspiration.

Martin

On Sun, Nov 7, 2010 at 04:47, Jeff Hain <jeffhain at rocketmail.com> wrote:
> Hello.
>
> I'm currently optimizing some scheduler (or Executor) implementation:
> for ASAP schedules, it was using a LinkedList with synchronization, then
> I switched to a LinkedBlockingQueue, using add(E) and take() methods.
>
> The scheduler has start()/stop() methods, so I need to be able to tell
> worker
> threads in take() method to stop waiting for an ASAP schedule, and wait for
> being allowed to work again.
> (pending schedules need to be reachable any time, for there is a
> cancelSchedules()
> method, so if take() returns a schedule and work status is false, I can't
> just wait for
> it to be true again, since after take() returns the schedule is no longer
> reachable)
>
> The simplest way I found to have a take() that can stop waiting was to
> extend
> LinkedBlockingQueue, and add a takeOrWake() method, which is basically
> take() with
>>while (count.get() == 0) {
>>?? notEmpty.await();
>>}
> replaced with
>>if (count.get() == 0) {
>>?? notEmpty.await();
>>?? if (count.get() == 0) {
>>????? // signal or spurious wake-up
>>????? return null;
>>?? }
>>}
> (I also removed the call to signalNotFull(), which breaks put(E) and
> offer(E,long,TimeUnit) methods, but I don't use them.)
>
> I had to use reflection to access some private fields and dequeue()
> method used in take() method.
>
> My concern is, I don't really like this solution, for reflection is a bit
> hacky and might have some performance hit.
>
> On the other hand, I don't really want to copy-paste-modify the whole
> LinkedBlockingQueue class, and calling dequeue() through reflection
> does not seem to have a noticeable performance hit in my benches.
>
> If anyone has a nicer solution to this problem, or can confirm that
> reflection should not hurt in that case, I would be pleased to hear it.
>
> Regards,
>
> Jeff
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From jeffhain at rocketmail.com  Sun Nov  7 20:19:29 2010
From: jeffhain at rocketmail.com (Jeff Hain)
Date: Mon, 8 Nov 2010 01:19:29 +0000 (GMT)
Subject: [concurrency-interest] Re : takeOrWake() method for a
	LinkedBlockingQueue
In-Reply-To: <AANLkTi=z7kKnmAmt9w4o7wz-YuFm6_gcOR1w5Gg6gQta@mail.gmail.com>
References: <83263.45030.qm@web29212.mail.ird.yahoo.com>
	<AANLkTi=z7kKnmAmt9w4o7wz-YuFm6_gcOR1w5Gg6gQta@mail.gmail.com>
Message-ID: <598031.81914.qm@web29212.mail.ird.yahoo.com>


Thanks, I didn't (want to) think of interrupt as a way to stop the wait
(looked too brutal to me, but indeed it has its use cases!).

Regards,

Jeff



________________________________
De : Martin Buchholz <martinrb at google.com>
? : Jeff Hain <jeffhain at rocketmail.com>
Cc : concurrency-interest at cs.oswego.edu
Envoy? le : Dim 7 novembre 2010, 23h 58min 12s
Objet : Re: [concurrency-interest] takeOrWake() method for a LinkedBlockingQueue

Writing a thread pool is non-trivial.

ThreadPoolExecutor tackles some of the same sort of issues, e.g. need
to notify waiting threads on shutdown.

The most obvious thing to do is to interrupt waiting threads, have
them catch InterruptedException, and then reexamine the state of the
executor.  See TPE.interruptIdleWorkers for inspiration.

Martin


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101108/b4979483/attachment.html>

From andrew.trick at gmail.com  Fri Nov 12 15:59:04 2010
From: andrew.trick at gmail.com (Andrew Trick)
Date: Fri, 12 Nov 2010 12:59:04 -0800
Subject: [concurrency-interest] Unsafe publication of new objects
	question
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJIIIAA.davidcholmes@aapt.net.au>
References: <4CAC562F.4020301@xemaps.com>
	<NFBBKALFDCPFIDBNKAPCAEJIIIAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTi=32P7E_cDhVGV1PPE-uUcVrT6RYuP2R+3dcx10@mail.gmail.com>

The JVM needs an effective store-store memory barrier between all
stores that initialize a new object and any store that may publish a
pointer to it. Not easy to do efficiently on all architectures.
-Andy

On Wed, Oct 6, 2010 at 4:06 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Joseph Seigh writes:
>>
>> ? How did the JVM get around to fixing the unsafe publication
>> problem of new object state, ?i.e. basic type safety for
>> primative types? ? Exploiting load dependency perhaps?
>
> Primitive types are type safe by definition. The only guarantee you have
> regarding unsafe publication is that you can never see uninitialized state -
> at a minimum you must see the default initialization values (which is easily
> achieved by allocating out of pre-zeroed memory).
>
> David Holmes
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From ashwin.jayaprakash at gmail.com  Fri Nov 12 16:43:41 2010
From: ashwin.jayaprakash at gmail.com (Ashwin Jayaprakash)
Date: Fri, 12 Nov 2010 13:43:41 -0800
Subject: [concurrency-interest] Is it still ok to use synchronized after all
	these years?
Message-ID: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>

I was wondering if it is still ok to use the "synchronized" keyword instead
of ReentrantLock where it is convenient.

Or is it thought of as an anachronism?

Does synchronized still have a better internal implementation over
j.u.c.Lock as this old blog entry says -
http://blogs.sun.com/dave/entry/java_util_concurrent_reentrantlock_vs ?


Thanks,
Ashwin Jayaprakash.

PS: Doug Lea - if you are reading this, I hope you will continue to make
your awesome contributions to the JDK! I can't imagine what it would be like
without the j.u.c code.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101112/0769d212/attachment.html>

From tim at peierls.net  Fri Nov 12 16:56:56 2010
From: tim at peierls.net (Tim Peierls)
Date: Fri, 12 Nov 2010 16:56:56 -0500
Subject: [concurrency-interest] Is it still ok to use synchronized after
 all these years?
In-Reply-To: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>
References: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>
Message-ID: <AANLkTinwmEQJRH1h4XvpjE+Q+yxQqj0LUwTVf7fdmTrz@mail.gmail.com>

On Fri, Nov 12, 2010 at 4:43 PM, Ashwin Jayaprakash <
ashwin.jayaprakash at gmail.com> wrote:

> I was wondering if it is still ok to use the "synchronized" keyword instead
> of ReentrantLock where it is convenient.
>

The main reason to use Lock is for these capabilities:

   - Non-nested locking
   - Lock.newCondition
   - Lock.tryLock (timed/untimed)
   - Lock.lockInterruptibly

If you don't need any of these, go ahead and use 'synchronized'.



> Or is it thought of as an anachronism?
>

Nope. It's much easier to read, and there's no danger of forgetting to
release the lock.



> Does synchronized still have a better internal implementation over
> j.u.c.Lock as this old blog entry says -
> http://blogs.sun.com/dave/entry/java_util_concurrent_reentrantlock_vs ?
>

The scales have shifted back and forth, but it's not something to worry
about at this point.


PS: Doug Lea - if you are reading this, I hope you will continue to make
> your awesome contributions to the JDK! I can't imagine what it would be like
> without the j.u.c code.
>

I'm sure Doug _is_ reading this!

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101112/0b59e677/attachment.html>

From davidcholmes at aapt.net.au  Fri Nov 12 17:16:12 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 13 Nov 2010 08:16:12 +1000
Subject: [concurrency-interest] Unsafe publication of new objects
	question
In-Reply-To: <AANLkTi=32P7E_cDhVGV1PPE-uUcVrT6RYuP2R+3dcx10@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEHHIJAA.davidcholmes@aapt.net.au>

Andy,

Andrew Trick writes:
>
> The JVM needs an effective store-store memory barrier between all
> stores that initialize a new object and any store that may publish a
> pointer to it. Not easy to do efficiently on all architectures.
> -Andy

The JVM would need this if it were to guarantee safe-publication, but it
doesn't guarantee that.

David Holmes

>
> On Wed, Oct 6, 2010 at 4:06 AM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Joseph Seigh writes:
> >>
> >> ? How did the JVM get around to fixing the unsafe publication
> >> problem of new object state, ?i.e. basic type safety for
> >> primative types? ? Exploiting load dependency perhaps?
> >
> > Primitive types are type safe by definition. The only guarantee you have
> > regarding unsafe publication is that you can never see
> uninitialized state -
> > at a minimum you must see the default initialization values
> (which is easily
> > achieved by allocating out of pre-zeroed memory).
> >
> > David Holmes
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>



From qiyaoltc at gmail.com  Fri Nov 12 21:19:17 2010
From: qiyaoltc at gmail.com (Yao Qi)
Date: Sat, 13 Nov 2010 10:19:17 +0800
Subject: [concurrency-interest] Is it still ok to use synchronized after
 all these years?
In-Reply-To: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>
References: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>
Message-ID: <AANLkTintU4Fi2CDJyznSA4ZP5o9bP9EzQRtV0o=O-yjW@mail.gmail.com>

On Sat, Nov 13, 2010 at 5:43 AM, Ashwin Jayaprakash
<ashwin.jayaprakash at gmail.com> wrote:
> I was wondering if it is still ok to use the "synchronized" keyword instead
> of ReentrantLock where it is convenient.
>

Yes, of course.

> Or is it thought of as an anachronism?
>

No.

> Does synchronized still have a better internal implementation over
> j.u.c.Lock as this old blog entry says -
> http://blogs.sun.com/dave/entry/java_util_concurrent_reentrantlock_vs ?
>
>

The choice between "synchronized" and j.u.c.Lock depends on your application
or workload.  If your application is a heavy concurrent code, and suffered by
lock contention, you could try j.u.c.Lock, otherwise, "synchronize" is
still pretty
good if you are aware of the scope of it.

> Thanks,
> Ashwin Jayaprakash.
>
> PS: Doug Lea - if you are reading this, I hope you will continue to make
> your awesome contributions to the JDK! I can't imagine what it would be like
> without the j.u.c code.


-- 
Yao Qi <qiyaoltc AT gmail DOT com>
http://sites.google.com/site/duewayqi/

From justin at krasama.com  Fri Nov 12 21:28:23 2010
From: justin at krasama.com (Justin T. Sampson)
Date: Fri, 12 Nov 2010 18:28:23 -0800
Subject: [concurrency-interest] Unsafe publication of new objects
	question
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEHHIJAA.davidcholmes@aapt.net.au>
References: <AANLkTi=32P7E_cDhVGV1PPE-uUcVrT6RYuP2R+3dcx10@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEHHIJAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTimA1jWkd3JNFeSKG9NcD4vRwsRxiq4Yo-KVs0H2@mail.gmail.com>

On Fri, Nov 12, 2010 at 2:16 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:
> Andrew Trick writes:
> > The JVM needs an effective store-store memory barrier between all
> > stores that initialize a new object and any store that may publish a
> > pointer to it. Not easy to do efficiently on all architectures.
> > -Andy
>
> The JVM would need this if it were to guarantee safe-publication, but it
> doesn't guarantee that.

It does for final fields, right? Or is that a different concept?

Cheers,
Justin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101112/630c26ea/attachment.html>

From fslzdd at gmail.com  Fri Nov 12 21:42:46 2010
From: fslzdd at gmail.com (=?GB2312?B?tO/X0w==?=)
Date: Sat, 13 Nov 2010 10:42:46 +0800
Subject: [concurrency-interest] Is it still ok to use synchronized after
 all these years?
In-Reply-To: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>
References: <AANLkTimGC0kcSQLqa=W87TMk-q7YCnNYCjBTrm5-oSv1@mail.gmail.com>
Message-ID: <AANLkTin9dqWNSjAGvKn3F3zu_WwYVy4+XZmFG9PR7SaB@mail.gmail.com>

I thought Tim and Yao shared good points. Brian Goetz summarizes the usage
of ReentrantLock here:
http://www.ibm.com/developerworks/java/library/j-jtp10264/.

"Use it when you need something it provides that synchronized doesn't, like
timed lock waits, interruptible lock waits, non-block-structured locks,
multiple condition variables, or lock polling. ReentrantLock also has
scalability benefits."

Thanks!

2010/11/13 Ashwin Jayaprakash <ashwin.jayaprakash at gmail.com>

> I was wondering if it is still ok to use the "synchronized" keyword instead
> of ReentrantLock where it is convenient.
>
> Or is it thought of as an anachronism?
>
> Does synchronized still have a better internal implementation over
> j.u.c.Lock as this old blog entry says -
> http://blogs.sun.com/dave/entry/java_util_concurrent_reentrantlock_vs ?
>
>
> Thanks,
> Ashwin Jayaprakash.
>
> PS: Doug Lea - if you are reading this, I hope you will continue to make
> your awesome contributions to the JDK! I can't imagine what it would be like
> without the j.u.c code.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101113/291722bc/attachment.html>

From davidcholmes at aapt.net.au  Fri Nov 12 22:12:47 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 13 Nov 2010 13:12:47 +1000
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTimA1jWkd3JNFeSKG9NcD4vRwsRxiq4Yo-KVs0H2@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEHIIJAA.davidcholmes@aapt.net.au>

Justin T. Sampson writes:
> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:
>> Andrew Trick writes:
>> > The JVM needs an effective store-store memory barrier between all
>> > stores that initialize a new object and any store that may publish a
>> > pointer to it. Not easy to do efficiently on all architectures.
>>
>> The JVM would need this if it were to guarantee safe-publication, but it
>> doesn't guarantee that.
>
>
> It does for final fields, right? Or is that a different concept?

There are additional guarantees regarding the initialization of final
fields. I suggest reading Section 17.5 of the Java Language Specification
for the details, but for a simple formulation see the "Final Fields" section
of the JMM Cookbook:

http://gee.cs.oswego.edu/dl/jmm/cookbook.html

Cheers,
David Holmes


From andrew.trick at gmail.com  Fri Nov 12 22:34:19 2010
From: andrew.trick at gmail.com (Andrew Trick)
Date: Fri, 12 Nov 2010 19:34:19 -0800
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEHIIJAA.davidcholmes@aapt.net.au>
References: <AANLkTimA1jWkd3JNFeSKG9NcD4vRwsRxiq4Yo-KVs0H2@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEHIIJAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTi=5hXAmvWq7ECHJt_HyF3YQfyyd9cpDRv3Hi0RU@mail.gmail.com>

I thought the original question referred to object instantiation, not
the call to <init>. Setting up the object header and zeroing fields
obviously requires a barrier.
-Andy

On Fri, Nov 12, 2010 at 7:12 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Justin T. Sampson writes:
>> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>>> Andrew Trick writes:
>>> > The JVM needs an effective store-store memory barrier between all
>>> > stores that initialize a new object and any store that may publish a
>>> > pointer to it. Not easy to do efficiently on all architectures.
>>>
>>> The JVM would need this if it were to guarantee safe-publication, but it
>>> doesn't guarantee that.
>>
>>
>> It does for final fields, right? Or is that a different concept?
>
> There are additional guarantees regarding the initialization of final
> fields. I suggest reading Section 17.5 of the Java Language Specification
> for the details, but for a simple formulation see the "Final Fields" section
> of the JMM Cookbook:
>
> http://gee.cs.oswego.edu/dl/jmm/cookbook.html
>
> Cheers,
> David Holmes
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From davidcholmes at aapt.net.au  Sat Nov 13 00:02:36 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 13 Nov 2010 15:02:36 +1000
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTi=5hXAmvWq7ECHJt_HyF3YQfyyd9cpDRv3Hi0RU@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEHJIJAA.davidcholmes@aapt.net.au>

Andrew Trick writes:
>
> I thought the original question referred to object instantiation, not
> the call to <init>. Setting up the object header and zeroing fields
> obviously requires a barrier.

The original question was somewhat vague.

The JMM requires that you always see at worst a default initialized object,
so yes there are some implicit barriers in there, but the details depend on
the VM implementation. Pre-zeroing the heap avoids the need for explicit
zeroing at object allocation. Thread transitions to/from Java/VM code
provide implicit (and sometimes explicit) barrier effects that avoid the
need for an explicit barrier as part of the object allocation and
initialization sequence.

On some architectures the theoretical problem of being able to see a
reference to the object before seeing the initialized fields can't happen
anyway (at the hardware level) due to dependent-loads (as Joe Seigh alluded
to in the original post).

Cheers,
David

> -Andy
>
> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Justin T. Sampson writes:
> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
> <davidcholmes at aapt.net.au>
> > wrote:
> >>> Andrew Trick writes:
> >>> > The JVM needs an effective store-store memory barrier between all
> >>> > stores that initialize a new object and any store that may publish a
> >>> > pointer to it. Not easy to do efficiently on all architectures.
> >>>
> >>> The JVM would need this if it were to guarantee
> safe-publication, but it
> >>> doesn't guarantee that.
> >>
> >>
> >> It does for final fields, right? Or is that a different concept?
> >
> > There are additional guarantees regarding the initialization of final
> > fields. I suggest reading Section 17.5 of the Java Language
> Specification
> > for the details, but for a simple formulation see the "Final
> Fields" section
> > of the JMM Cookbook:
> >
> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
> >
> > Cheers,
> > David Holmes
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dl at cs.oswego.edu  Sat Nov 13 12:45:22 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 13 Nov 2010 12:45:22 -0500
Subject: [concurrency-interest] plans
Message-ID: <4CDECEB2.7010700@cs.oswego.edu>


As you all probably know, as of November 15, I will no longer
be on the Executive Committee for the JCP. But this has nothing
to do with plans for java.util.concurrent, which include:
soon (this week or so) resyncing minor updates to OpenJDK;
developing new library components for parallel operations on
aggregates (collections and arrays) for JDK8  (based
on proposed language support for lambdas); some related
support targeted for other languages running on JVMs;
plus continuing improvements and occasional additions to
our synchronizers, concurrent collections, and execution
services.

-Doug


From Philip.Lee at smartstream-stp.com  Mon Nov 15 07:00:58 2010
From: Philip.Lee at smartstream-stp.com (Philip Lee)
Date: Mon, 15 Nov 2010 12:00:58 +0000
Subject: [concurrency-interest] Demonstrating the need for correct partial
	ordering
Message-ID: <62EC155DFFC99A4EB1D3BBC6CD0A395D7235DB68@briexch0002.sst.stp>

It can be difficult to persuade developers of the need to ensure correct partial ordering when many programs appear to work without it.

I was wondering if there are any example programs that demonstrate failures due to unsafe publication etc? Any such concrete examples would be very helpful in demonstrating that these problems are more than just theoretical. ( I appreciate that programs may only fail on certain multi-core architectures .)

Thanks,

    Phil.

________________________________
 The information in this email is confidential and may be legally privileged. It is intended solely for the addressee. Access to this email by anyone else is unauthorised. If you are not the intended recipient, any disclosure, copying, distribution or any action taken or omitted to be taken in reliance on it, is prohibited and may be unlawful.
SmartStream Technologies Ltd. is a company incorporated in England and Wales. Registered office: St Helen's, 1 Undershaft, London, EC3A 8EE. Registration No. 2285524


From andrew.trick at gmail.com  Mon Nov 15 13:20:22 2010
From: andrew.trick at gmail.com (Andrew Trick)
Date: Mon, 15 Nov 2010 10:20:22 -0800
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEHJIJAA.davidcholmes@aapt.net.au>
References: <AANLkTi=5hXAmvWq7ECHJt_HyF3YQfyyd9cpDRv3Hi0RU@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHJIJAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTi=5Xvpa7uPaBB5o7Z4x7TLRnjG1ySzAtiVRwMxc@mail.gmail.com>

Not arguing at all. But I don't want JVM implementers and
microarchitects to completely ignore the issue...  optimized object
allocation will not involve thread transitions. Pre-zeroing is also
not efficient, but moot because the JVM will likely need to do
type-specific initialization of the object header (exposing a zero
header == crash). Furthermore, the allocating thread need not do any
loads to publish a newly instantiated object. It just needs to store
the pointer in a field, not necessarily declared volatile. Any pointer
store between instantiation and the next barrier may be a publisher
(considering only the first publisher is insufficient). So an explicit
barrier is needed, resulting in some type of fence on non-TSO
machines. Hardware support for a reasonably efficient store-store
fence is great to have for this purpose.
-Andy

On Fri, Nov 12, 2010 at 9:02 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Andrew Trick writes:
>>
>> I thought the original question referred to object instantiation, not
>> the call to <init>. Setting up the object header and zeroing fields
>> obviously requires a barrier.
>
> The original question was somewhat vague.
>
> The JMM requires that you always see at worst a default initialized object,
> so yes there are some implicit barriers in there, but the details depend on
> the VM implementation. Pre-zeroing the heap avoids the need for explicit
> zeroing at object allocation. Thread transitions to/from Java/VM code
> provide implicit (and sometimes explicit) barrier effects that avoid the
> need for an explicit barrier as part of the object allocation and
> initialization sequence.
>
> On some architectures the theoretical problem of being able to see a
> reference to the object before seeing the initialized fields can't happen
> anyway (at the hardware level) due to dependent-loads (as Joe Seigh alluded
> to in the original post).
>
> Cheers,
> David
>
>> -Andy
>>
>> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
>> <davidcholmes at aapt.net.au> wrote:
>> > Justin T. Sampson writes:
>> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
>> <davidcholmes at aapt.net.au>
>> > wrote:
>> >>> Andrew Trick writes:
>> >>> > The JVM needs an effective store-store memory barrier between all
>> >>> > stores that initialize a new object and any store that may publish a
>> >>> > pointer to it. Not easy to do efficiently on all architectures.
>> >>>
>> >>> The JVM would need this if it were to guarantee
>> safe-publication, but it
>> >>> doesn't guarantee that.
>> >>
>> >>
>> >> It does for final fields, right? Or is that a different concept?
>> >
>> > There are additional guarantees regarding the initialization of final
>> > fields. I suggest reading Section 17.5 of the Java Language
>> Specification
>> > for the details, but for a simple formulation see the "Final
>> Fields" section
>> > of the JMM Cookbook:
>> >
>> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
>> >
>> > Cheers,
>> > David Holmes
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>

From niko at alum.mit.edu  Mon Nov 15 13:38:31 2010
From: niko at alum.mit.edu (Niko Matsakis)
Date: Mon, 15 Nov 2010 19:38:31 +0100
Subject: [concurrency-interest] Handling DAGs with JSR166
Message-ID: <4CE17E27.6060803@alum.mit.edu>

Hello,

I am attempting to use the jsr166y ForkJoinPool to handle a parallel 
task computation (in fact, as the underlying thread pool for the 
Intervals parallel task framework [1]).  The idea is that each task 
represents a node in the DAG.  I don't know the DAG before hand, so I 
need to run the tasks to find out who will join which other tasks.  I've 
found that this is very prone to deadlocks, generally because of a stack 
like:

1. Tasks X,  Y, and Z are forked.
2. Task X joins Task Z.
3. In the meantime, the worker thread tries to run Task Y.
4. Task Y joins Task X.

Clearly I am violating some assumption. A preliminary reading of the 
code suggests that while blocked on a join(), a ForkJoinWorkerThread 
will execute arbitrary tasks from the local queue.  This is not safe in 
this case, since all tasks are forked to begin with, and may in fact 
have dependencies on the joining task.

Is there a better way to handle encode such a problem with jsr166y?


regards,
Niko

[1] http://intervals.inf.ethz.ch

From davidcholmes at aapt.net.au  Mon Nov 15 15:08:55 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 16 Nov 2010 06:08:55 +1000
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTi=5Xvpa7uPaBB5o7Z4x7TLRnjG1ySzAtiVRwMxc@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEIIIJAA.davidcholmes@aapt.net.au>

Andy,

The VM is required to "do the right thing" here. Only by examining an actual
VM implementation can you determine how it achieves this, and ensure that it
does achieve it.

David

> -----Original Message-----
> From: Andrew Trick [mailto:andrew.trick at gmail.com]
> Sent: Tuesday, 16 November 2010 4:20 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Unsafe publication of new
> objectsquestion
>
>
> Not arguing at all. But I don't want JVM implementers and
> microarchitects to completely ignore the issue...  optimized object
> allocation will not involve thread transitions. Pre-zeroing is also
> not efficient, but moot because the JVM will likely need to do
> type-specific initialization of the object header (exposing a zero
> header == crash). Furthermore, the allocating thread need not do any
> loads to publish a newly instantiated object. It just needs to store
> the pointer in a field, not necessarily declared volatile. Any pointer
> store between instantiation and the next barrier may be a publisher
> (considering only the first publisher is insufficient). So an explicit
> barrier is needed, resulting in some type of fence on non-TSO
> machines. Hardware support for a reasonably efficient store-store
> fence is great to have for this purpose.
> -Andy
>
> On Fri, Nov 12, 2010 at 9:02 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Andrew Trick writes:
> >>
> >> I thought the original question referred to object instantiation, not
> >> the call to <init>. Setting up the object header and zeroing fields
> >> obviously requires a barrier.
> >
> > The original question was somewhat vague.
> >
> > The JMM requires that you always see at worst a default
> initialized object,
> > so yes there are some implicit barriers in there, but the
> details depend on
> > the VM implementation. Pre-zeroing the heap avoids the need for explicit
> > zeroing at object allocation. Thread transitions to/from Java/VM code
> > provide implicit (and sometimes explicit) barrier effects that avoid the
> > need for an explicit barrier as part of the object allocation and
> > initialization sequence.
> >
> > On some architectures the theoretical problem of being able to see a
> > reference to the object before seeing the initialized fields
> can't happen
> > anyway (at the hardware level) due to dependent-loads (as Joe
> Seigh alluded
> > to in the original post).
> >
> > Cheers,
> > David
> >
> >> -Andy
> >>
> >> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
> >> <davidcholmes at aapt.net.au> wrote:
> >> > Justin T. Sampson writes:
> >> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
> >> <davidcholmes at aapt.net.au>
> >> > wrote:
> >> >>> Andrew Trick writes:
> >> >>> > The JVM needs an effective store-store memory barrier between all
> >> >>> > stores that initialize a new object and any store that
> may publish a
> >> >>> > pointer to it. Not easy to do efficiently on all architectures.
> >> >>>
> >> >>> The JVM would need this if it were to guarantee
> >> safe-publication, but it
> >> >>> doesn't guarantee that.
> >> >>
> >> >>
> >> >> It does for final fields, right? Or is that a different concept?
> >> >
> >> > There are additional guarantees regarding the initialization of final
> >> > fields. I suggest reading Section 17.5 of the Java Language
> >> Specification
> >> > for the details, but for a simple formulation see the "Final
> >> Fields" section
> >> > of the JMM Cookbook:
> >> >
> >> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
> >> >
> >> > Cheers,
> >> > David Holmes
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
>


From dl at cs.oswego.edu  Mon Nov 15 19:01:57 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 15 Nov 2010 19:01:57 -0500
Subject: [concurrency-interest] Handling DAGs with JSR166
In-Reply-To: <4CE17E27.6060803@alum.mit.edu>
References: <4CE17E27.6060803@alum.mit.edu>
Message-ID: <4CE1C9F5.8080407@cs.oswego.edu>

On 11/15/10 13:38, Niko Matsakis wrote:
> The idea is that each task represents a node in the DAG. I
> don't know the DAG before hand, so I need to run the tasks to find out who will
> join which other tasks. ...
>
> Clearly I am violating some assumption.
> Is there a better way to handle encode such a problem with jsr166y?
>

The provided Recursive{Action,Task} subclasses of ForkJoinTask deal
with strict nesting, but you can use others for arbitrary
DAGS. Two such classes (BinaryAsyncAction and LinkedAsyncAction),
along with a few usage examples can be found in our CVS at
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/

We initially planned to include these and others in the main
package, but found that whenever people were tempted
to use them, they ended up making custom ForkJoinTask classes
using some combination of join counts, parent links,
phasers, and/or quiescence detection. One of these days we should
put together a tutorial about these kinds of mechanics.

-Doug




From niko at alum.mit.edu  Tue Nov 16 01:45:27 2010
From: niko at alum.mit.edu (Niko Matsakis)
Date: Tue, 16 Nov 2010 07:45:27 +0100
Subject: [concurrency-interest] Handling DAGs with JSR166
In-Reply-To: <4CE1C9F5.8080407@cs.oswego.edu>
References: <4CE17E27.6060803@alum.mit.edu> <4CE1C9F5.8080407@cs.oswego.edu>
Message-ID: <4CE22887.3090600@alum.mit.edu>


> The provided Recursive{Action,Task} subclasses of ForkJoinTask deal
> with strict nesting, but you can use others for arbitrary
> DAGS. Two such classes (BinaryAsyncAction and LinkedAsyncAction),
> along with a few usage examples can be found in our CVS at
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
Thanks.  I'll take a look!


regards,
Niko


From niko at alum.mit.edu  Tue Nov 16 07:20:45 2010
From: niko at alum.mit.edu (Niko Matsakis)
Date: Tue, 16 Nov 2010 13:20:45 +0100
Subject: [concurrency-interest] Handling DAGs with JSR166
In-Reply-To: <4CE1C9F5.8080407@cs.oswego.edu>
References: <4CE17E27.6060803@alum.mit.edu> <4CE1C9F5.8080407@cs.oswego.edu>
Message-ID: <4CE2771D.50501@alum.mit.edu>

>
> The provided Recursive{Action,Task} subclasses of ForkJoinTask deal
> with strict nesting, but you can use others for arbitrary
> DAGS. Two such classes (BinaryAsyncAction and LinkedAsyncAction),
> along with a few usage examples can be found in our CVS at
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/ 
So, I did a bit more reading into the code and in particular looked at 
those examples actions you gave.  Am I correct that 
{Binary,Linked}AsyncAction still don't allow "lateral" joins? By a 
lateral join, I mean a case like I outlined previously, where one node 
joins its siblings in the "fork tree" (i.e., the tree formed by 
considering which task forked every other task).  I believe this is true 
because the join() behavior seems to be fixed in ForkJoinTask and the 
ForkJoinWorkerThread using a combination of final / package-only 
methods.  I guess that lateral joins would best be accomplished using 
the point-to-point synchronization capabilities of Phasers or some other 
construct?


thanks,

Niko

From dl at cs.oswego.edu  Tue Nov 16 07:37:29 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 16 Nov 2010 07:37:29 -0500
Subject: [concurrency-interest] Handling DAGs with JSR166
In-Reply-To: <4CE2771D.50501@alum.mit.edu>
References: <4CE17E27.6060803@alum.mit.edu> <4CE1C9F5.8080407@cs.oswego.edu>
	<4CE2771D.50501@alum.mit.edu>
Message-ID: <4CE27B09.4070108@cs.oswego.edu>

On 11/16/10 07:20, Niko Matsakis wrote:

> So, I did a bit more reading into the code and in particular looked at those
> examples actions you gave. Am I correct that {Binary,Linked}AsyncAction still
> don't allow "lateral" joins? By a lateral join, I mean a case like I outlined
> previously, where one node joins its siblings in the "fork tree" (i.e., the tree
> formed by considering which task forked every other task).

Right. These classes maintain parent pointers only. It is possible
to maintain arbitrary links and use them in conjunction with
join counts or phasers. (An example slightly
closer to what you want is "FJSums" demo; see also
"TorusSpanningTree", both in src/test/loops in our CVS).
In general, when you have data structures that are not
statically shaped as trees/dags, you need to mix the
data-structure maintenance with execution control,
normally using something other than ForkJoinTask.join.
Which can get messy. This should be better documented.
We'll work on it.

-Doug

From viktor.klang at gmail.com  Tue Nov 16 08:59:33 2010
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3IgS2xhbmc=?=)
Date: Tue, 16 Nov 2010 14:59:33 +0100
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEIIIJAA.davidcholmes@aapt.net.au>
References: <AANLkTi=5Xvpa7uPaBB5o7Z4x7TLRnjG1ySzAtiVRwMxc@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEIIIJAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTikyYVTVyXmioCUqPdi6cwpR4+K1n9hLQ8Pkzr9a@mail.gmail.com>

>From my point of view the problem is allowing logic in the constructor.

On Mon, Nov 15, 2010 at 9:08 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> Andy,
>
> The VM is required to "do the right thing" here. Only by examining an
> actual
> VM implementation can you determine how it achieves this, and ensure that
> it
> does achieve it.
>
> David
>
> > -----Original Message-----
> > From: Andrew Trick [mailto:andrew.trick at gmail.com]
> > Sent: Tuesday, 16 November 2010 4:20 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Unsafe publication of new
> > objectsquestion
> >
> >
> > Not arguing at all. But I don't want JVM implementers and
> > microarchitects to completely ignore the issue...  optimized object
> > allocation will not involve thread transitions. Pre-zeroing is also
> > not efficient, but moot because the JVM will likely need to do
> > type-specific initialization of the object header (exposing a zero
> > header == crash). Furthermore, the allocating thread need not do any
> > loads to publish a newly instantiated object. It just needs to store
> > the pointer in a field, not necessarily declared volatile. Any pointer
> > store between instantiation and the next barrier may be a publisher
> > (considering only the first publisher is insufficient). So an explicit
> > barrier is needed, resulting in some type of fence on non-TSO
> > machines. Hardware support for a reasonably efficient store-store
> > fence is great to have for this purpose.
> > -Andy
> >
> > On Fri, Nov 12, 2010 at 9:02 PM, David Holmes
> > <davidcholmes at aapt.net.au> wrote:
> > > Andrew Trick writes:
> > >>
> > >> I thought the original question referred to object instantiation, not
> > >> the call to <init>. Setting up the object header and zeroing fields
> > >> obviously requires a barrier.
> > >
> > > The original question was somewhat vague.
> > >
> > > The JMM requires that you always see at worst a default
> > initialized object,
> > > so yes there are some implicit barriers in there, but the
> > details depend on
> > > the VM implementation. Pre-zeroing the heap avoids the need for
> explicit
> > > zeroing at object allocation. Thread transitions to/from Java/VM code
> > > provide implicit (and sometimes explicit) barrier effects that avoid
> the
> > > need for an explicit barrier as part of the object allocation and
> > > initialization sequence.
> > >
> > > On some architectures the theoretical problem of being able to see a
> > > reference to the object before seeing the initialized fields
> > can't happen
> > > anyway (at the hardware level) due to dependent-loads (as Joe
> > Seigh alluded
> > > to in the original post).
> > >
> > > Cheers,
> > > David
> > >
> > >> -Andy
> > >>
> > >> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
> > >> <davidcholmes at aapt.net.au> wrote:
> > >> > Justin T. Sampson writes:
> > >> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
> > >> <davidcholmes at aapt.net.au>
> > >> > wrote:
> > >> >>> Andrew Trick writes:
> > >> >>> > The JVM needs an effective store-store memory barrier between
> all
> > >> >>> > stores that initialize a new object and any store that
> > may publish a
> > >> >>> > pointer to it. Not easy to do efficiently on all architectures.
> > >> >>>
> > >> >>> The JVM would need this if it were to guarantee
> > >> safe-publication, but it
> > >> >>> doesn't guarantee that.
> > >> >>
> > >> >>
> > >> >> It does for final fields, right? Or is that a different concept?
> > >> >
> > >> > There are additional guarantees regarding the initialization of
> final
> > >> > fields. I suggest reading Section 17.5 of the Java Language
> > >> Specification
> > >> > for the details, but for a simple formulation see the "Final
> > >> Fields" section
> > >> > of the JMM Cookbook:
> > >> >
> > >> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
> > >> >
> > >> > Cheers,
> > >> > David Holmes
> > >> >
> > >> > _______________________________________________
> > >> > Concurrency-interest mailing list
> > >> > Concurrency-interest at cs.oswego.edu
> > >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >> >
> > >> _______________________________________________
> > >> Concurrency-interest mailing list
> > >> Concurrency-interest at cs.oswego.edu
> > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >>
> > >
> > >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang,
Code Connoisseur
Work:   Scalable Solutions <http://www.scalablesolutions.se>
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101116/34c46f04/attachment-0001.html>

From andrew.trick at gmail.com  Tue Nov 16 13:38:11 2010
From: andrew.trick at gmail.com (Andrew Trick)
Date: Tue, 16 Nov 2010 10:38:11 -0800
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTikyYVTVyXmioCUqPdi6cwpR4+K1n9hLQ8Pkzr9a@mail.gmail.com>
References: <AANLkTi=5Xvpa7uPaBB5o7Z4x7TLRnjG1ySzAtiVRwMxc@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEIIIJAA.davidcholmes@aapt.net.au>
	<AANLkTikyYVTVyXmioCUqPdi6cwpR4+K1n9hLQ8Pkzr9a@mail.gmail.com>
Message-ID: <AANLkTikCNBWERnM5b05x70wVEgf9fVjcdZY-c4QUB0vN@mail.gmail.com>

I read Joseph's question as "how does one implement a JVM that meets
the JVM spec". Maybe this wasn't the best forum for that discussion?

I think David answered your question to the effect that it's the
programmer's responsibility to synchronize constructors in general,
but final fields have some implied synchronization.

-Andy

On Tue, Nov 16, 2010 at 5:59 AM, ?iktor Klang <viktor.klang at gmail.com> wrote:
> From my point of view the problem is allowing logic in the constructor.
>
> On Mon, Nov 15, 2010 at 9:08 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>>
>> Andy,
>>
>> The VM is required to "do the right thing" here. Only by examining an
>> actual
>> VM implementation can you determine how it achieves this, and ensure that
>> it
>> does achieve it.
>>
>> David
>>
>> > -----Original Message-----
>> > From: Andrew Trick [mailto:andrew.trick at gmail.com]
>> > Sent: Tuesday, 16 November 2010 4:20 AM
>> > To: dholmes at ieee.org
>> > Cc: concurrency-interest at cs.oswego.edu
>> > Subject: Re: [concurrency-interest] Unsafe publication of new
>> > objectsquestion
>> >
>> >
>> > Not arguing at all. But I don't want JVM implementers and
>> > microarchitects to completely ignore the issue... ?optimized object
>> > allocation will not involve thread transitions. Pre-zeroing is also
>> > not efficient, but moot because the JVM will likely need to do
>> > type-specific initialization of the object header (exposing a zero
>> > header == crash). Furthermore, the allocating thread need not do any
>> > loads to publish a newly instantiated object. It just needs to store
>> > the pointer in a field, not necessarily declared volatile. Any pointer
>> > store between instantiation and the next barrier may be a publisher
>> > (considering only the first publisher is insufficient). So an explicit
>> > barrier is needed, resulting in some type of fence on non-TSO
>> > machines. Hardware support for a reasonably efficient store-store
>> > fence is great to have for this purpose.
>> > -Andy
>> >
>> > On Fri, Nov 12, 2010 at 9:02 PM, David Holmes
>> > <davidcholmes at aapt.net.au> wrote:
>> > > Andrew Trick writes:
>> > >>
>> > >> I thought the original question referred to object instantiation, not
>> > >> the call to <init>. Setting up the object header and zeroing fields
>> > >> obviously requires a barrier.
>> > >
>> > > The original question was somewhat vague.
>> > >
>> > > The JMM requires that you always see at worst a default
>> > initialized object,
>> > > so yes there are some implicit barriers in there, but the
>> > details depend on
>> > > the VM implementation. Pre-zeroing the heap avoids the need for
>> > > explicit
>> > > zeroing at object allocation. Thread transitions to/from Java/VM code
>> > > provide implicit (and sometimes explicit) barrier effects that avoid
>> > > the
>> > > need for an explicit barrier as part of the object allocation and
>> > > initialization sequence.
>> > >
>> > > On some architectures the theoretical problem of being able to see a
>> > > reference to the object before seeing the initialized fields
>> > can't happen
>> > > anyway (at the hardware level) due to dependent-loads (as Joe
>> > Seigh alluded
>> > > to in the original post).
>> > >
>> > > Cheers,
>> > > David
>> > >
>> > >> -Andy
>> > >>
>> > >> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
>> > >> <davidcholmes at aapt.net.au> wrote:
>> > >> > Justin T. Sampson writes:
>> > >> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
>> > >> <davidcholmes at aapt.net.au>
>> > >> > wrote:
>> > >> >>> Andrew Trick writes:
>> > >> >>> > The JVM needs an effective store-store memory barrier between
>> > >> >>> > all
>> > >> >>> > stores that initialize a new object and any store that
>> > may publish a
>> > >> >>> > pointer to it. Not easy to do efficiently on all architectures.
>> > >> >>>
>> > >> >>> The JVM would need this if it were to guarantee
>> > >> safe-publication, but it
>> > >> >>> doesn't guarantee that.
>> > >> >>
>> > >> >>
>> > >> >> It does for final fields, right? Or is that a different concept?
>> > >> >
>> > >> > There are additional guarantees regarding the initialization of
>> > >> > final
>> > >> > fields. I suggest reading Section 17.5 of the Java Language
>> > >> Specification
>> > >> > for the details, but for a simple formulation see the "Final
>> > >> Fields" section
>> > >> > of the JMM Cookbook:
>> > >> >
>> > >> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
>> > >> >
>> > >> > Cheers,
>> > >> > David Holmes
>> > >> >
>> > >> > _______________________________________________
>> > >> > Concurrency-interest mailing list
>> > >> > Concurrency-interest at cs.oswego.edu
>> > >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> > >> >
>> > >> _______________________________________________
>> > >> Concurrency-interest mailing list
>> > >> Concurrency-interest at cs.oswego.edu
>> > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> > >>
>> > >
>> > >
>> >
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> --
> Viktor Klang,
> Code Connoisseur
> Work:?? Scalable Solutions
> Code:?? github.com/viktorklang
> Follow: twitter.com/viktorklang
> Read:?? klangism.tumblr.com
>
>


From viktor.klang at gmail.com  Tue Nov 16 13:57:43 2010
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3IgS2xhbmc=?=)
Date: Tue, 16 Nov 2010 19:57:43 +0100
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTikCNBWERnM5b05x70wVEgf9fVjcdZY-c4QUB0vN@mail.gmail.com>
References: <AANLkTi=5Xvpa7uPaBB5o7Z4x7TLRnjG1ySzAtiVRwMxc@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEIIIJAA.davidcholmes@aapt.net.au>
	<AANLkTikyYVTVyXmioCUqPdi6cwpR4+K1n9hLQ8Pkzr9a@mail.gmail.com>
	<AANLkTikCNBWERnM5b05x70wVEgf9fVjcdZY-c4QUB0vN@mail.gmail.com>
Message-ID: <AANLkTi=i_-_YidOAc_t=atCOh4ZnvjNr64xKzvHop4+3@mail.gmail.com>

On Tue, Nov 16, 2010 at 7:38 PM, Andrew Trick <andrew.trick at gmail.com>wrote:

> I read Joseph's question as "how does one implement a JVM that meets
> the JVM spec". Maybe this wasn't the best forum for that discussion?
>
> I think David answered your question to the effect that it's the
> programmer's responsibility to synchronize constructors in general,
> but final fields have some implied synchronization.
>

What I'm saying is that if there was no logic in the constructor, all values
for all fields would have to be allocated before the call, and you would be
sure that references to the object was not exposed before it was fully
constructed.


>
> -Andy
>
> On Tue, Nov 16, 2010 at 5:59 AM, ?iktor Klang <viktor.klang at gmail.com>
> wrote:
> > From my point of view the problem is allowing logic in the constructor.
> >
> > On Mon, Nov 15, 2010 at 9:08 PM, David Holmes <davidcholmes at aapt.net.au>
> > wrote:
> >>
> >> Andy,
> >>
> >> The VM is required to "do the right thing" here. Only by examining an
> >> actual
> >> VM implementation can you determine how it achieves this, and ensure
> that
> >> it
> >> does achieve it.
> >>
> >> David
> >>
> >> > -----Original Message-----
> >> > From: Andrew Trick [mailto:andrew.trick at gmail.com]
> >> > Sent: Tuesday, 16 November 2010 4:20 AM
> >> > To: dholmes at ieee.org
> >> > Cc: concurrency-interest at cs.oswego.edu
> >> > Subject: Re: [concurrency-interest] Unsafe publication of new
> >> > objectsquestion
> >> >
> >> >
> >> > Not arguing at all. But I don't want JVM implementers and
> >> > microarchitects to completely ignore the issue...  optimized object
> >> > allocation will not involve thread transitions. Pre-zeroing is also
> >> > not efficient, but moot because the JVM will likely need to do
> >> > type-specific initialization of the object header (exposing a zero
> >> > header == crash). Furthermore, the allocating thread need not do any
> >> > loads to publish a newly instantiated object. It just needs to store
> >> > the pointer in a field, not necessarily declared volatile. Any pointer
> >> > store between instantiation and the next barrier may be a publisher
> >> > (considering only the first publisher is insufficient). So an explicit
> >> > barrier is needed, resulting in some type of fence on non-TSO
> >> > machines. Hardware support for a reasonably efficient store-store
> >> > fence is great to have for this purpose.
> >> > -Andy
> >> >
> >> > On Fri, Nov 12, 2010 at 9:02 PM, David Holmes
> >> > <davidcholmes at aapt.net.au> wrote:
> >> > > Andrew Trick writes:
> >> > >>
> >> > >> I thought the original question referred to object instantiation,
> not
> >> > >> the call to <init>. Setting up the object header and zeroing fields
> >> > >> obviously requires a barrier.
> >> > >
> >> > > The original question was somewhat vague.
> >> > >
> >> > > The JMM requires that you always see at worst a default
> >> > initialized object,
> >> > > so yes there are some implicit barriers in there, but the
> >> > details depend on
> >> > > the VM implementation. Pre-zeroing the heap avoids the need for
> >> > > explicit
> >> > > zeroing at object allocation. Thread transitions to/from Java/VM
> code
> >> > > provide implicit (and sometimes explicit) barrier effects that avoid
> >> > > the
> >> > > need for an explicit barrier as part of the object allocation and
> >> > > initialization sequence.
> >> > >
> >> > > On some architectures the theoretical problem of being able to see a
> >> > > reference to the object before seeing the initialized fields
> >> > can't happen
> >> > > anyway (at the hardware level) due to dependent-loads (as Joe
> >> > Seigh alluded
> >> > > to in the original post).
> >> > >
> >> > > Cheers,
> >> > > David
> >> > >
> >> > >> -Andy
> >> > >>
> >> > >> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
> >> > >> <davidcholmes at aapt.net.au> wrote:
> >> > >> > Justin T. Sampson writes:
> >> > >> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
> >> > >> <davidcholmes at aapt.net.au>
> >> > >> > wrote:
> >> > >> >>> Andrew Trick writes:
> >> > >> >>> > The JVM needs an effective store-store memory barrier between
> >> > >> >>> > all
> >> > >> >>> > stores that initialize a new object and any store that
> >> > may publish a
> >> > >> >>> > pointer to it. Not easy to do efficiently on all
> architectures.
> >> > >> >>>
> >> > >> >>> The JVM would need this if it were to guarantee
> >> > >> safe-publication, but it
> >> > >> >>> doesn't guarantee that.
> >> > >> >>
> >> > >> >>
> >> > >> >> It does for final fields, right? Or is that a different concept?
> >> > >> >
> >> > >> > There are additional guarantees regarding the initialization of
> >> > >> > final
> >> > >> > fields. I suggest reading Section 17.5 of the Java Language
> >> > >> Specification
> >> > >> > for the details, but for a simple formulation see the "Final
> >> > >> Fields" section
> >> > >> > of the JMM Cookbook:
> >> > >> >
> >> > >> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
> >> > >> >
> >> > >> > Cheers,
> >> > >> > David Holmes
> >> > >> >
> >> > >> > _______________________________________________
> >> > >> > Concurrency-interest mailing list
> >> > >> > Concurrency-interest at cs.oswego.edu
> >> > >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> > >> >
> >> > >> _______________________________________________
> >> > >> Concurrency-interest mailing list
> >> > >> Concurrency-interest at cs.oswego.edu
> >> > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> > >>
> >> > >
> >> > >
> >> >
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> > --
> > Viktor Klang,
> > Code Connoisseur
> > Work:   Scalable Solutions
> > Code:   github.com/viktorklang
> > Follow: twitter.com/viktorklang
> > Read:   klangism.tumblr.com
> >
> >
>



-- 
Viktor Klang,
Code Connoisseur
Work:   Scalable Solutions <http://www.scalablesolutions.se>
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101116/2c03ee49/attachment.html>

From gregg at cytetech.com  Tue Nov 16 14:44:01 2010
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 16 Nov 2010 13:44:01 -0600
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTi=i_-_YidOAc_t=atCOh4ZnvjNr64xKzvHop4+3@mail.gmail.com>
References: <AANLkTi=5Xvpa7uPaBB5o7Z4x7TLRnjG1ySzAtiVRwMxc@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEIIIJAA.davidcholmes@aapt.net.au>
	<AANLkTikyYVTVyXmioCUqPdi6cwpR4+K1n9hLQ8Pkzr9a@mail.gmail.com>
	<AANLkTikCNBWERnM5b05x70wVEgf9fVjcdZY-c4QUB0vN@mail.gmail.com>
	<AANLkTi=i_-_YidOAc_t=atCOh4ZnvjNr64xKzvHop4+3@mail.gmail.com>
Message-ID: <4CE2DF01.8080500@cytetech.com>

On 11/16/2010 12:57 PM, ?iktor Klang wrote:
>
>
> On Tue, Nov 16, 2010 at 7:38 PM, Andrew Trick <andrew.trick at gmail.com
> <mailto:andrew.trick at gmail.com>> wrote:
>
>     I read Joseph's question as "how does one implement a JVM that meets
>     the JVM spec". Maybe this wasn't the best forum for that discussion?
>
>     I think David answered your question to the effect that it's the
>     programmer's responsibility to synchronize constructors in general,
>     but final fields have some implied synchronization.
>
>
> What I'm saying is that if there was no logic in the constructor, all values for
> all fields would have to be allocated before the call, and you would be sure
> that references to the object was not exposed before it was fully constructed.

This is a developer/engineer choice on object lifecycle and initialization.  One 
can create every class instance with a noargs constructor that will thus have to 
create every value it assigns to some internal field.  Or you can pass those 
into constructor.

But in the end, it is the fact that you can create a reference to "this" within 
the construct of <init> being invoked that creates the larger issue.

I know that in some cases where I have leaked "this" into a "callback" mechanism 
during construction, and had the callback method invoked before construction 
completed, that "this" has been referenced in an anonymous method and resulted 
in a NPE.

Lots of things about <init> are important to get right.  Unfortunately, not all 
JVMs do all things (set 'this' for example) in the same order it seems.

These kinds of "ordering" issues are what make "programming in a concurrent 
environment" difficult.  We are all still largely content to look at APIs and 
say "when you use it in this way, with this ordering, it works thusly", instead 
of looking at APIs and saying "I can't guarantee the same results in all 
circumstances, maybe I need to rethink how to do this".

Gregg Wonderly

>
>     -Andy
>
>     On Tue, Nov 16, 2010 at 5:59 AM, ?iktor Klang <viktor.klang at gmail.com
>     <mailto:viktor.klang at gmail.com>> wrote:
>      > From my point of view the problem is allowing logic in the constructor.
>      >
>      > On Mon, Nov 15, 2010 at 9:08 PM, David Holmes <davidcholmes at aapt.net.au
>     <mailto:davidcholmes at aapt.net.au>>
>      > wrote:
>      >>
>      >> Andy,
>      >>
>      >> The VM is required to "do the right thing" here. Only by examining an
>      >> actual
>      >> VM implementation can you determine how it achieves this, and ensure that
>      >> it
>      >> does achieve it.
>      >>
>      >> David
>      >>
>      >> > -----Original Message-----
>      >> > From: Andrew Trick [mailto:andrew.trick at gmail.com
>     <mailto:andrew.trick at gmail.com>]
>      >> > Sent: Tuesday, 16 November 2010 4:20 AM
>      >> > To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>      >> > Cc: concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>      >> > Subject: Re: [concurrency-interest] Unsafe publication of new
>      >> > objectsquestion
>      >> >
>      >> >
>      >> > Not arguing at all. But I don't want JVM implementers and
>      >> > microarchitects to completely ignore the issue...  optimized object
>      >> > allocation will not involve thread transitions. Pre-zeroing is also
>      >> > not efficient, but moot because the JVM will likely need to do
>      >> > type-specific initialization of the object header (exposing a zero
>      >> > header == crash). Furthermore, the allocating thread need not do any
>      >> > loads to publish a newly instantiated object. It just needs to store
>      >> > the pointer in a field, not necessarily declared volatile. Any pointer
>      >> > store between instantiation and the next barrier may be a publisher
>      >> > (considering only the first publisher is insufficient). So an explicit
>      >> > barrier is needed, resulting in some type of fence on non-TSO
>      >> > machines. Hardware support for a reasonably efficient store-store
>      >> > fence is great to have for this purpose.
>      >> > -Andy
>      >> >
>      >> > On Fri, Nov 12, 2010 at 9:02 PM, David Holmes
>      >> > <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>      >> > > Andrew Trick writes:
>      >> > >>
>      >> > >> I thought the original question referred to object instantiation, not
>      >> > >> the call to <init>. Setting up the object header and zeroing fields
>      >> > >> obviously requires a barrier.
>      >> > >
>      >> > > The original question was somewhat vague.
>      >> > >
>      >> > > The JMM requires that you always see at worst a default
>      >> > initialized object,
>      >> > > so yes there are some implicit barriers in there, but the
>      >> > details depend on
>      >> > > the VM implementation. Pre-zeroing the heap avoids the need for
>      >> > > explicit
>      >> > > zeroing at object allocation. Thread transitions to/from Java/VM code
>      >> > > provide implicit (and sometimes explicit) barrier effects that avoid
>      >> > > the
>      >> > > need for an explicit barrier as part of the object allocation and
>      >> > > initialization sequence.
>      >> > >
>      >> > > On some architectures the theoretical problem of being able to see a
>      >> > > reference to the object before seeing the initialized fields
>      >> > can't happen
>      >> > > anyway (at the hardware level) due to dependent-loads (as Joe
>      >> > Seigh alluded
>      >> > > to in the original post).
>      >> > >
>      >> > > Cheers,
>      >> > > David
>      >> > >
>      >> > >> -Andy
>      >> > >>
>      >> > >> On Fri, Nov 12, 2010 at 7:12 PM, David Holmes
>      >> > >> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>      >> > >> > Justin T. Sampson writes:
>      >> > >> >> On Fri, Nov 12, 2010 at 2:16 PM, David Holmes
>      >> > >> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>>
>      >> > >> > wrote:
>      >> > >> >>> Andrew Trick writes:
>      >> > >> >>> > The JVM needs an effective store-store memory barrier between
>      >> > >> >>> > all
>      >> > >> >>> > stores that initialize a new object and any store that
>      >> > may publish a
>      >> > >> >>> > pointer to it. Not easy to do efficiently on all architectures.
>      >> > >> >>>
>      >> > >> >>> The JVM would need this if it were to guarantee
>      >> > >> safe-publication, but it
>      >> > >> >>> doesn't guarantee that.
>      >> > >> >>
>      >> > >> >>
>      >> > >> >> It does for final fields, right? Or is that a different concept?
>      >> > >> >
>      >> > >> > There are additional guarantees regarding the initialization of
>      >> > >> > final
>      >> > >> > fields. I suggest reading Section 17.5 of the Java Language
>      >> > >> Specification
>      >> > >> > for the details, but for a simple formulation see the "Final
>      >> > >> Fields" section
>      >> > >> > of the JMM Cookbook:
>      >> > >> >
>      >> > >> > http://gee.cs.oswego.edu/dl/jmm/cookbook.html
>      >> > >> >
>      >> > >> > Cheers,
>      >> > >> > David Holmes
>      >> > >> >
>      >> > >> > _______________________________________________
>      >> > >> > Concurrency-interest mailing list
>      >> > >> > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>      >> > >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>      >> > >> >
>      >> > >> _______________________________________________
>      >> > >> Concurrency-interest mailing list
>      >> > >> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>      >> > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>      >> > >>
>      >> > >
>      >> > >
>      >> >
>      >>
>      >> _______________________________________________
>      >> Concurrency-interest mailing list
>      >> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>      >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>      >
>      >
>      >
>      > --
>      > Viktor Klang,
>      > Code Connoisseur
>      > Work:   Scalable Solutions
>      > Code: github.com/viktorklang <http://github.com/viktorklang>
>      > Follow: twitter.com/viktorklang <http://twitter.com/viktorklang>
>      > Read: klangism.tumblr.com <http://klangism.tumblr.com>
>      >
>      >
>
>
>
>
> --
> Viktor Klang,
> Code Connoisseur
> Work: Scalable Solutions <http://www.scalablesolutions.se>
> Code: github.com/viktorklang <http://github.com/viktorklang>
> Follow: twitter.com/viktorklang <http://twitter.com/viktorklang>
> Read: klangism.tumblr.com <http://klangism.tumblr.com>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From davidcholmes at aapt.net.au  Tue Nov 16 17:32:16 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 17 Nov 2010 08:32:16 +1000
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <AANLkTi=i_-_YidOAc_t=atCOh4ZnvjNr64xKzvHop4+3@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEJBIJAA.davidcholmes@aapt.net.au>

Viktor Klang writes:
> On Tue, Nov 16, 2010 at 7:38 PM, Andrew Trick <andrew.trick at gmail.com> wrote:
>
>> I read Joseph's question as "how does one implement a JVM that meets
>> the JVM spec". Maybe this wasn't the best forum for that discussion?
>
>> I think David answered your question to the effect that it's the
>> programmer's responsibility to synchronize constructors in general,
>> but final fields have some implied synchronization.
>
>
> What I'm saying is that if there was no logic in the constructor, all values for all fields 
> would have to be allocated before the call, and you would be sure that references to the object 
> was not exposed before it was fully constructed. 

Premature exposing of 'this' in only one kind of issue that can arise. The broader unsafe-publication issue simply requires creation of an object that is assigned to a non-volatile static field. In such as case there is no guarantee that the stores to the object's fields will be visible before the store of the object reference to the static field. The only required safety-guarantees are that the object itself must be "valid" (correct header, vtable etc) and the fields must be seen to at least have their default-initialized valuses ie no out-of-thin-air values are allowed.

What a VM has to do to meet these requirements depends on how the VM implements a whole bunch of things.

David Holmes
   



From hans.boehm at hp.com  Tue Nov 16 19:06:35 2010
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 17 Nov 2010 00:06:35 +0000
Subject: [concurrency-interest] Unsafe publication of new objectsquestion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJBIJAA.davidcholmes@aapt.net.au>
References: <AANLkTi=i_-_YidOAc_t=atCOh4ZnvjNr64xKzvHop4+3@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJBIJAA.davidcholmes@aapt.net.au>
Message-ID: <238A96A773B3934685A7269CC8A8D0426F253C800A@GVW0436EXB.americas.hpqcorp.net>

> From: David Holmes
> 
> Viktor Klang writes:
> > On Tue, Nov 16, 2010 at 7:38 PM, Andrew Trick
> <andrew.trick at gmail.com> wrote:
> >
> >> I read Joseph's question as "how does one implement a JVM that meets
> >> the JVM spec". Maybe this wasn't the best forum for that discussion?
> >
> >> I think David answered your question to the effect that it's the
> >> programmer's responsibility to synchronize constructors in general,
> >> but final fields have some implied synchronization.
> >
> >
> > What I'm saying is that if there was no logic in the constructor, all
> values for all fields
> > would have to be allocated before the call, and you would be sure
> that references to the object
> > was not exposed before it was fully constructed.
> 
> Premature exposing of 'this' in only one kind of issue that can arise.
> The broader unsafe-publication issue simply requires creation of an
> object that is assigned to a non-volatile static field. In such as case
> there is no guarantee that the stores to the object's fields will be
> visible before the store of the object reference to the static field.
> The only required safety-guarantees are that the object itself must be
> "valid" (correct header, vtable etc) and the fields must be seen to at
> least have their default-initialized valuses ie no out-of-thin-air
> values are allowed.
> 
> What a VM has to do to meet these requirements depends on how the VM
> implements a whole bunch of things.
> 
> David Holmes
> 
Yes.  But at the risk of repetition, it's also worth remembering that none of
these problems can occur unless you first introduce a data race.  In this case, you
must store the this pointer and read it back in another thread without
proper synchronization, i.e. with nothing to prevent the store and the read
from occurring at the same time.  So long as you don't do that, and there
is no untrusted code that can do it, you're fine.  No data races, no problems.

Hans


From dl at cs.oswego.edu  Wed Nov 17 08:30:17 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 17 Nov 2010 08:30:17 -0500
Subject: [concurrency-interest] Handling DAGs with JSR166
In-Reply-To: <4CE1C9F5.8080407@cs.oswego.edu>
References: <4CE17E27.6060803@alum.mit.edu> <4CE1C9F5.8080407@cs.oswego.edu>
Message-ID: <4CE3D8E9.7040904@cs.oswego.edu>

> On 11/15/10 13:38, Niko Matsakis wrote:
>> The idea is that each task represents a node in the DAG. I
>> don't know the DAG before hand, so I need to run the tasks to find out who will
>> join which other tasks. ...
>>
>> Clearly I am violating some assumption.

Revisiting this: The undocumented assumption in
one FJ component was that any joinable task heads a DAG
(rather than is part of a DAG), which was too strict.
Rather than trying to explain this away, it is better
to relax the restriction/assumption, which we did
in updated version.

Thanks to Niko for some offlist checks on this.

-Doug


From nader at aeinehchi.com  Wed Nov 17 09:32:51 2010
From: nader at aeinehchi.com (nader at aeinehchi.com)
Date: Wed, 17 Nov 2010 09:32:51 -0500
Subject: [concurrency-interest] How to order the external calls?
Message-ID: <0fc9ca0135251f88f0d907f009d6cfa2.squirrel@www.aeinehchi.com>

Suppose you have two methods initialize and terminate.  Both methods call
some external code that results in some state transition in the external
component.

Now, I want to ensure that terminate is not called while initialize is
running, and vice versa.  How can it be achieved effectively.

Thank you very much.


From nader at aeinehchi.com  Wed Nov 17 10:02:45 2010
From: nader at aeinehchi.com (nader at aeinehchi.com)
Date: Wed, 17 Nov 2010 10:02:45 -0500
Subject: [concurrency-interest] How to order the external calls?
In-Reply-To: <AANLkTikTj-UB8H0WjLZXLCRpPE6LDwUbeUUOrfeJ+hzi@mail.gmail.com>
References: <0fc9ca0135251f88f0d907f009d6cfa2.squirrel@www.aeinehchi.com>
	<AANLkTikTj-UB8H0WjLZXLCRpPE6LDwUbeUUOrfeJ+hzi@mail.gmail.com>
Message-ID: <dab7c69cacb89f7d510e4b69a52308cb.squirrel@www.aeinehchi.com>

Hi

According to JCiP, one must not lock the call to external code.  Question
remains how to enforce a locking or non-blocking algorithm?

Thanks.

> With a single lock perhaps?
>
> On Wed, Nov 17, 2010 at 6:32 AM, <nader at aeinehchi.com> wrote:
>
>> Suppose you have two methods initialize and terminate.  Both methods
>> call
>> some external code that results in some state transition in the external
>> component.
>>
>> Now, I want to ensure that terminate is not called while initialize is
>> running, and vice versa.  How can it be achieved effectively.
>>
>> Thank you very much.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>



From gregg at cytetech.com  Wed Nov 17 10:24:50 2010
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 17 Nov 2010 09:24:50 -0600
Subject: [concurrency-interest] How to order the external calls?
In-Reply-To: <0fc9ca0135251f88f0d907f009d6cfa2.squirrel@www.aeinehchi.com>
References: <0fc9ca0135251f88f0d907f009d6cfa2.squirrel@www.aeinehchi.com>
Message-ID: <4CE3F3C2.7060207@cytetech.com>

On 11/17/2010 8:32 AM, nader at aeinehchi.com wrote:
> Suppose you have two methods initialize and terminate.  Both methods call
> some external code that results in some state transition in the external
> component.
>
> Now, I want to ensure that terminate is not called while initialize is
> running, and vice versa.  How can it be achieved effectively.

The ultimate answer depends on a number of factors.  If there is no other use of 
"synchronized" on methods in the class, you could simply put "synchronized" on 
the method declaration.

If, on the other hand, there is already unrelated use of 'synchronized' on 
methods, or synchronized(X) where X is the class name, then you can simply 
create another "object" to synchronize on.  What I typically do is.

	Object singleUseLock = new Object();

	public void method1() {
		synchronized( singleUseLock ) {
			unlockedMethod1();
		}
	}

	public void method2() {
		synchronized( singleUseLock ) {
			unlockedMethod2();
		}
	}

	private void unlockedMethod1() {}
	private void unlockedMethod2() {}

But, if you don't want threads to block if someone is already calling one of the 
other methods, then it gets more complicated and you need to put in the use of a 
Lock object and call tryLock() and return when it is appropriate to skip the 
call.  In that case, you might use a boolean return value to say that you did, 
or did not take the appropriate actions.  Doing this kind of thing can make an 
application more fragile from the perspective that you don't always take the 
actions requested.

But, if your application has some pretty explicit control of logic using state 
based transitions or other similar techniques then you can do this kind of thing.

Gregg Wonderly

From nader at aeinehchi.com  Wed Nov 17 11:38:26 2010
From: nader at aeinehchi.com (nader at aeinehchi.com)
Date: Wed, 17 Nov 2010 11:38:26 -0500
Subject: [concurrency-interest] How to order the external calls?
In-Reply-To: <4CE3F3C2.7060207@cytetech.com>
References: <0fc9ca0135251f88f0d907f009d6cfa2.squirrel@www.aeinehchi.com>
	<4CE3F3C2.7060207@cytetech.com>
Message-ID: <677cf090df21b7b6a63b49f972d71447.squirrel@www.aeinehchi.com>

Thanks Gregg for a comprehensive response.

For instance, I have a Module Manager with a certain life-cycle
(initialize, ... and terminate).  Each method (e.g. initialize) calls a
set of Modules, e.g.

// Based on the state, initialize and terminate are called
private State state;

void initialize(){
   foreach (module in modules){
      module.doSomething;
   }
}
void terminate(){
   foreach (module in modules){
      module.doSomethingElse;
   }
}

Now, I do not have control over the modules as a module may or may not
make external calls,e.g. a JMS server.  I do not have (and do not want)
control the locking mecahnism that each module has.

1. The "synchronized" locking mechanism that you mention here may
potentially lead to dead-locks?
2. Perhaps a ReentrantLock with some time-out would be a better solution?
3. Is there any better alternative than 1. & 2. ?

thanks.

> On 11/17/2010 8:32 AM, nader at aeinehchi.com wrote:
>> Suppose you have two methods initialize and terminate.  Both methods
>> call
>> some external code that results in some state transition in the external
>> component.
>>
>> Now, I want to ensure that terminate is not called while initialize is
>> running, and vice versa.  How can it be achieved effectively.
>
> The ultimate answer depends on a number of factors.  If there is no other
> use of
> "synchronized" on methods in the class, you could simply put
> "synchronized" on
> the method declaration.
>
> If, on the other hand, there is already unrelated use of 'synchronized' on
> methods, or synchronized(X) where X is the class name, then you can simply
> create another "object" to synchronize on.  What I typically do is.
>
> 	Object singleUseLock = new Object();
>
> 	public void method1() {
> 		synchronized( singleUseLock ) {
> 			unlockedMethod1();
> 		}
> 	}
>
> 	public void method2() {
> 		synchronized( singleUseLock ) {
> 			unlockedMethod2();
> 		}
> 	}
>
> 	private void unlockedMethod1() {}
> 	private void unlockedMethod2() {}
>
> But, if you don't want threads to block if someone is already calling one
> of the
> other methods, then it gets more complicated and you need to put in the
> use of a
> Lock object and call tryLock() and return when it is appropriate to skip
> the
> call.  In that case, you might use a boolean return value to say that you
> did,
> or did not take the appropriate actions.  Doing this kind of thing can
> make an
> application more fragile from the perspective that you don't always take
> the
> actions requested.
>
> But, if your application has some pretty explicit control of logic using
> state
> based transitions or other similar techniques then you can do this kind of
> thing.
>
> Gregg Wonderly
>



From ganeshrvce at gmail.com  Tue Nov 23 22:47:03 2010
From: ganeshrvce at gmail.com (Ganesha Upadhyaya Belle)
Date: Tue, 23 Nov 2010 21:47:03 -0600
Subject: [concurrency-interest] Graph search examples
Message-ID: <AANLkTikGQqnJ2fgHpXvLnNhX25F02LbbFSa7_E-95NAD@mail.gmail.com>

Hi All,

I would like to know, is there any implementation for graph search
algorithms such as depth-first, breadth-first, a-star etc using JSR166 or
concurrent framework?
I would really appreciate any help.

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101123/a78f78ae/attachment.html>

From john_platts at hotmail.com  Fri Nov 26 14:34:49 2010
From: john_platts at hotmail.com (John Platts)
Date: Fri, 26 Nov 2010 13:34:49 -0600
Subject: [concurrency-interest] New field accessor APIs
Message-ID: <SNT116-W152B93E371C6E489D78ACA9D210@phx.gbl>


Here are reasons why new field accessor APIs are needed:
- To improve portability, correctness, and thread safety of code using the improved field accessor APIs. Writes to reference fields through methods in sun.misc.Unsafe are not type safe. The sun.misc.Unsafe class is not part of the Java SE specification and is not guaranteed to be available in a Java SE implementation.
- To allow volatile reads, volatile writes, lazy volatile writes, and atomic operations to be performed on non-volatile fields. These operations are often useful on non-volatile fields as they enable thread-safe initialization of non-volatile fields, while allowing subsequent accesses to be optimized. Supporting volatile writes of non-volatile fields also allows inversion of control and dependency control containers to ensure that non-volatile fields are properly initialized and written to in a thread-safe manner.
- To allow field updaters to be created through lookup classes (similar to the java.dyn.MethodHandles.Lookup class in Java SE 7 and later). This is useful in dynamic programming languages, as it provides capabilities that are not yet available in JSR 292. MethodHandle objects can be used to read from or write to a field. However, field updaters can perform atomic operations, write to non-volatile fields using volatile writes, perform lazy volatile writes, and read to non-volatile fields using volatile reads, things that MethodHandles cannot do directly.
- To facilitate the implementation of JVM programming languages whose field access semantics differ from the Java Programming Language.

The new field accessor APIs provide the following guarantees:
- Static final fields are never written to through the new field accessor APIs
- Writes to final instance fields through the new field accessors are not enabled by default
- Security checks and immutability of final fields are enforced by default
- Callers must have permission to disable security checks and final field immutability checks
- Volatile and final fields are never written to through a non-volatile write
- Reads to volatile fields through the new field accessor API's are normal volatile reads by default

 		 	   		  

From forax at univ-mlv.fr  Fri Nov 26 16:46:10 2010
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Fri, 26 Nov 2010 22:46:10 +0100
Subject: [concurrency-interest] New field accessor APIs
In-Reply-To: <SNT116-W152B93E371C6E489D78ACA9D210@phx.gbl>
References: <SNT116-W152B93E371C6E489D78ACA9D210@phx.gbl>
Message-ID: <4CF02AA2.1020309@univ-mlv.fr>

On 11/26/2010 08:34 PM, John Platts wrote:
> Here are reasons why new field accessor APIs are needed:
> - To improve portability, correctness, and thread safety of code using the improved field accessor APIs. Writes to reference fields through methods in sun.misc.Unsafe are not type safe. The sun.misc.Unsafe class is not part of the Java SE specification and is not guaranteed to be available in a Java SE implementation.
> - To allow volatile reads, volatile writes, lazy volatile writes, and atomic operations to be performed on non-volatile fields. These operations are often useful on non-volatile fields as they enable thread-safe initialization of non-volatile fields, while allowing subsequent accesses to be optimized. Supporting volatile writes of non-volatile fields also allows inversion of control and dependency control containers to ensure that non-volatile fields are properly initialized and written to in a thread-safe manner.

You can use invokedynamic and its bootstrap method mechanism to 
implement a lazy initialization.
see 
http://weblogs.java.net/blog/forax/archive/2010/11/04/jsr-292-goodness-singleton-pattern 


> - To allow field updaters to be created through lookup classes (similar to the java.dyn.MethodHandles.Lookup class in Java SE 7 and later). This is useful in dynamic programming languages, as it provides capabilities that are not yet available in JSR 292. MethodHandle objects can be used to read from or write to a field. However, field updaters can perform atomic operations, write to non-volatile fields using volatile writes, perform lazy volatile writes, and read to non-volatile fields using volatile reads, things that MethodHandles cannot do directly.

You can create a MethodHandle on FieldUpdater.compareAndSet.
The only advantage I see to create a new API is to avoid the runtime 
check that is done each time compareAndSet is called.

> - To facilitate the implementation of JVM programming languages whose field access semantics differ from the Java Programming Language.
>
> The new field accessor APIs provide the following guarantees:
> - Static final fields are never written to through the new field accessor APIs
> - Writes to final instance fields through the new field accessors are not enabled by default
> - Security checks and immutability of final fields are enforced by default
> - Callers must have permission to disable security checks and final field immutability checks
> - Volatile and final fields are never written to through a non-volatile write
> - Reads to volatile fields through the new field accessor API's are normal volatile reads by default

Also note that you can use MethodHandle API to change the value of a 
final field.
Create a java.lang.reflect.Field, call setAccessible(true) and then use 
Lookup.unreflectField().

R?mi

From sg at sgurjar.com  Mon Nov 29 12:02:49 2010
From: sg at sgurjar.com (Satyendra Gurjar)
Date: Mon, 29 Nov 2010 12:02:49 -0500
Subject: [concurrency-interest] producer-consumer POISON msg
Message-ID: <AANLkTi=KL_Xy1t0w0s5t82wiqbyaUpkP-pHUSqhpQUY2@mail.gmail.com>

Hello, I'm trying producer-consumer pattern as described in jcip 5.3
I'm putting POISON MSG for consumers to stop after finish consuming real msgs.
But what I'm seeing is consumers consumes POISON MSG before real msgs and
stops. Following is my code, please help me understand the behavior.

Thanks.


static final File POISON_MSG = new File("");

static void main(String[] args) throws Exception {

 int N_CONSUMERS = 10, BOUND = 1000;
 BlockingQueue<File> blockingqueue = new LinkedBlockingQueue<File>(BOUND);

 ArrayList<Thread> producers = new ArrayList<Thread>();
 for(String[] file : logfiles) { // producer threads
     Thread t = new Thread(new Producer(file[0], file[1], blockingqueue));
     t.start();
     producers.add(t);
 }

 Crawler crawler = new Crawler(); // Crawler is immutable

 for(int i=0; i < N_CONSUMERS; i++) { // consumer threads
     new Thread(new Consumer(blockingqueue, crawler)).start();
 }

 // wait for all producers to finish
 for(Thread p : producers) p.join();

 // then put N_CONSUMERS POISON_MSG for consumers to stop
 for(int i=0; i < N_CONSUMERS; i++) blockingqueue.put(POISON_MSG);

}

From hanson.char at gmail.com  Tue Nov 30 17:49:55 2010
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 30 Nov 2010 14:49:55 -0800
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEGIIGAA.davidcholmes@aapt.net.au>
References: <AANLkTikXfnnpcHPR5bwYebF_KsRAGGa9RjF5ZVpTA4Wn@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEGIIGAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTimKd2LZcgNTWqO4+Oem7xVvrDFa1bV7goC-ALkb@mail.gmail.com>

Turns out there is something in jdk 1.6 that can find out the default thread
stack size of a running JVM:

  jinfo -flag ThreadStackSize <PID>

Regards,
Hanson

On Thu, May 13, 2010 at 3:01 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> Hanson,
>
> Hanson Char writes:
> > Any recommended way to find out:
> > a) the default thread stack size used in a running JVM
> > b) the actual thread stack size of a thread (after it is created with
> > a requested stack size)
>
> There are no APIs to retrieve either of those pieces of information that I
> am aware of.
>
> David
>
> > Thanks,
> > Hanson
> >
> > On Tue, Mar 23, 2010 at 3:32 PM, David Holmes
> > <davidcholmes at aapt.net.au> wrote:
> > > Hi Ramesh,
> > >
> > > The default Java thread stack size is platform specific but can
> > be set with
> > > -Xss parameter on JVM startup (or can be set for individual threads via
> > > their constructor). This stack size is not related to that seen
> > in ulimit
> > > because the VM explicitly sets the stack size when native threads are
> > > created.
> > >
> > > As for "Thread Local Data" I'm not sure exactly what you mean by that.
> > >
> > > HTH
> > >
> > > David Holmes
> > >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101130/f7f7b4ca/attachment.html>

