Subject: [concurrency-interest] coherence litmus test and data race.
From: Peter Veentjer via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-13, 10:16
To: "concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Peter Veentjer <alarmnummer@gmail.com>

Hi,

Imagine the following program:

int a,b=0

thread1:
   a=1
   [storestore]
   a=2

thread2:
    r1=a
    r2=a

It is obvious that there is a data race since the loads/stores are plain loads and stores. My question is about the allowed behaviors in this particular case. Do the 2 plain loads to the same address need to be executed in order, or will any order be fine?

In terms of litmus tests: is it allowed that code with a data race can violate the coherence litmus test.

int a,b=0

thread1:
   a=1

thread2:
   a=2

thread3:
  r1=a
  r2=a

thread4:
   r3=a
   r4=a

So could it be that we end up with r1=1, r2=2, r3=2 and r4=1.

https://repository.upenn.edu/cgi/viewcontent.cgi?article=1980&context=cis_reports

My guess at this is allowed behavior because it doesn't change the 'within thread as if serial semantics'.

Regards,

Peter.



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] coherence litmus test and data race.
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-13, 17:07
To: Peter Veentjer <alarmnummer@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think the only requirement for plain loads in a concurrent setting is that there are no out-of-thin-air values.

That is, you can read only values that some thread stores.

The coherence does not come into picture, because there is a compiler (which is allowed to produce code that violates any assumptions you want to make about hardware)

Alex

On Tue, 13 Jul 2021, 08:18 Peter Veentjer via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    Hi,

    Imagine the following program:

    int a,b=0

    thread1:
       a=1
       [storestore]
       a=2

    thread2:
        r1=a
        r2=a

    It is obvious that there is a data race since the loads/stores are plain loads and stores. My question is about the allowed behaviors in this particular case. Do the 2 plain loads to the same address need to be executed in order, or will any order be fine?

    In terms of litmus tests: is it allowed that code with a data race can violate the coherence litmus test.

    int a,b=0

    thread1:
       a=1

    thread2:
       a=2

    thread3:
      r1=a
      r2=a

    thread4:
       r3=a
       r4=a

    So could it be that we end up with r1=1, r2=2, r3=2 and r4=1.

    https://repository.upenn.edu/cgi/viewcontent.cgi?article=1980&context=cis_reports

    My guess at this is allowed behavior because it doesn't change the 'within thread as if serial semantics'.

    Regards,

    Peter.


    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] coherence litmus test and data race.
From: Peter Veentjer via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-13, 17:52
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Peter Veentjer <alarmnummer@gmail.com>

Hi Alex,

Thanks for your response.

I know cache-coherence doesn't come into play since caches on modern CPUs are always coherent. But this test is called the coherence litmus test and checks if it is allowed that loads to the same address get reordered independent of the level this happens.

On Tue, Jul 13, 2021 at 5:08 PM Alex Otenko <oleksandr.otenko@gmail.com> wrote:

    I think the only requirement for plain loads in a concurrent setting is that there are no out-of-thin-air values.

    That is, you can read only values that some thread stores.

    The coherence does not come into picture, because there is a compiler (which is allowed to produce code that violates any assumptions you want to make about hardware)

    Alex

    On Tue, 13 Jul 2021, 08:18 Peter Veentjer via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

        Hi,

        Imagine the following program:

        int a,b=0

        thread1:
           a=1
           [storestore]
           a=2

        thread2:
            r1=a
            r2=a

        It is obvious that there is a data race since the loads/stores are plain loads and stores. My question is about the allowed behaviors in this particular case. Do the 2 plain loads to the same address need to be executed in order, or will any order be fine?

        In terms of litmus tests: is it allowed that code with a data race can violate the coherence litmus test.

        int a,b=0

        thread1:
           a=1

        thread2:
           a=2

        thread3:
          r1=a
          r2=a

        thread4:
           r3=a
           r4=a

        So could it be that we end up with r1=1, r2=2, r3=2 and r4=1.

        https://repository.upenn.edu/cgi/viewcontent.cgi?article=1980&context=cis_reports

        My guess at this is allowed behavior because it doesn't change the 'within thread as if serial semantics'.

        Regards,

        Peter.


        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: [concurrency-interest] [Reply] coherence litmus test and data race.
From: Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-13, 19:36
To: concurrency-interest@cs.oswego.edu, alarmnummer@gmail.com
Reply-To: Shuyang Liu <sliu44@cs.ucla.edu>

Hello,

According to the current definitions in JAM [1] for Java 9, the execution in the litmus test is forbidden. In particular, there is a CORR rule saying that if there are two consecutive reads to the same location reading from two writes, then there is a coherence order between the two writes in the same order. So the two writes have to be executed in the same order as observed and all threads in the program have to agree on the same coherence order.

In addition, the same execution is forbidden by RC11 [2], too (with non-atomics). In particular, there is a reflexive hb;eco order from (r3=a) -hb-> (r4=a) -eco-> (r3=a), which is forbidden by the coherence rule in RC11. RC11 assumes a single total coherence order on writes to the same location, like hardware memory models. 

Interestingly, this blog post [3] by Russ Cox says otherwise because the compiler can reorder the reads. If this is true in the compilers, then the formal model is too strong for the language. 

I'm not sure if this is the correct format to reply to a post in the mailing list. Apologize if not. 

Best Regards,
Shuyang Liu

[1] John Bender and Jens Palsberg. 2019. A formalization of Java’s concurrent access modes. Proc. ACM Program. Lang. 3, OOPSLA, Article 142 (October 2019), 28 pages. DOI:https://doi.org/10.1145/3360568

[2] Ori Lahav, Viktor Vafeiadis, Jeehoon Kang, Chung-Kil Hur, and Derek Dreyer. 2017. Repairing Sequential Consistency in C/C++11. In Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2017). ACM, New York, NY, USA, 618–632

[3] Programming Language Memory Models  https://research.swtch.com/plmm
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] [Reply] coherence litmus test and data race.
From: Peter Veentjer via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-13, 20:26
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: "concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Peter Veentjer <alarmnummer@gmail.com>

Hi Shuyang,

Thanks for your excellent reply. I'll study the links you send. 

I read the article of Russ Cox as well and it is the reason I'm asking this question.

Regards,

Peter


On Tue, Jul 13, 2021, 19:36 Shuyang Liu <sliu44@cs.ucla.edu> wrote:

    Hello,

    According to the current definitions in JAM [1] for Java 9, the execution in the litmus test is forbidden. In particular, there is a CORR rule saying that if there are two consecutive reads to the same location reading from two writes, then there is a coherence order between the two writes in the same order. So the two writes have to be executed in the same order as observed and all threads in the program have to agree on the same coherence order.

    In addition, the same execution is forbidden by RC11 [2], too (with non-atomics). In particular, there is a reflexive hb;eco order from (r3=a) -hb-> (r4=a) -eco-> (r3=a), which is forbidden by the coherence rule in RC11. RC11 assumes a single total coherence order on writes to the same location, like hardware memory models.

    Interestingly, this blog post [3] by Russ Cox says otherwise because the compiler can reorder the reads. If this is true in the compilers, then the formal model is too strong for the language.

    I'm not sure if this is the correct format to reply to a post in the mailing list. Apologize if not.

    Best Regards,
    Shuyang Liu

    [1] John Bender and Jens Palsberg. 2019. A formalization of Java’s concurrent access modes. Proc. ACM Program. Lang. 3, OOPSLA, Article 142 (October 2019), 28 pages. DOI:https://doi.org/10.1145/3360568

    [2] Ori Lahav, Viktor Vafeiadis, Jeehoon Kang, Chung-Kil Hur, and Derek Dreyer. 2017. Repairing Sequential Consistency in C/C++11. In Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2017). ACM, New York, NY, USA, 618–632

    [3] Programming Language Memory Models  https://research.swtch.com/plmm


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] coherence litmus test and data race.
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-13, 20:54
To: Peter Veentjer <alarmnummer@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

What I am getting at, is that there is a compiler, which is allowed to reorder things.

So your test doesn't test coherence as a system-wide property.

In simple words - a program that is not sequentially consistent cannot be expected to have coherent reads as your test defines them.

Your test is not sequentially consistent. So it is allowed to observe anything.

Alex

On Tue, 13 Jul 2021, 15:52 Peter Veentjer, <alarmnummer@gmail.com> wrote:

    Hi Alex,

    Thanks for your response.

    I know cache-coherence doesn't come into play since caches on modern CPUs are always coherent. But this test is called the coherence litmus test and checks if it is allowed that loads to the same address get reordered independent of the level this happens.

    On Tue, Jul 13, 2021 at 5:08 PM Alex Otenko <oleksandr.otenko@gmail.com> wrote:

        I think the only requirement for plain loads in a concurrent setting is that there are no out-of-thin-air values.

        That is, you can read only values that some thread stores.

        The coherence does not come into picture, because there is a compiler (which is allowed to produce code that violates any assumptions you want to make about hardware)

        Alex

        On Tue, 13 Jul 2021, 08:18 Peter Veentjer via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

            Hi,

            Imagine the following program:

            int a,b=0

            thread1:
               a=1
               [storestore]
               a=2

            thread2:
                r1=a
                r2=a

            It is obvious that there is a data race since the loads/stores are plain loads and stores. My question is about the allowed behaviors in this particular case. Do the 2 plain loads to the same address need to be executed in order, or will any order be fine?

            In terms of litmus tests: is it allowed that code with a data race can violate the coherence litmus test.

            int a,b=0

            thread1:
               a=1

            thread2:
               a=2

            thread3:
              r1=a
              r2=a

            thread4:
               r3=a
               r4=a

            So could it be that we end up with r1=1, r2=2, r3=2 and r4=1.

            https://repository.upenn.edu/cgi/viewcontent.cgi?article=1980&context=cis_reports

            My guess at this is allowed behavior because it doesn't change the 'within thread as if serial semantics'.

            Regards,

            Peter.


            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] [Reply] coherence litmus test and data race.
From: Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-14, 15:08
To: concurrency-interest@cs.oswego.edu
Reply-To: Doug Lea <dl@cs.oswego.edu>

Background: Shuyang and colleagues are working on a formal model ("JAM") that accounts for jdk9+ VarHandle modes (http://gee.cs.oswego.edu/dl/html/j9mm.html), C++ interoperability (modulo intrinsic differences), updated processor mappings, and JSR133 JMM bugfixes, that could become a basis for revised JLS spec.

On 7/13/21 12:36 PM, Shuyang Liu via Concurrency-interest wrote:
> Hello,
>
> According to the current definitions in JAM [1] for Java 9, the execution in the litmus test is forbidden. In particular, there is a CORR rule saying that if there are two consecutive reads to the same location reading from two writes, then there is a coherence order between the two writes in the same order. So the two writes have to be executed in the same order as observed and all threads in the program have to agree on the same coherence order.
>
> In addition, the same execution is forbidden by RC11 [2], too (with non-atomics). In particular, there is a reflexive hb;eco order from (r3=a) -hb-> (r4=a) -eco-> (r3=a), which is forbidden by the coherence rule in RC11. RC11 assumes a single total coherence order on writes to the same location, like hardware memory models.
>
> Interestingly, this blog post [3] by Russ Cox says otherwise because the compiler can reorder the reads. If this is true in the compilers, then the formal model is too strong for the language.
>
> I'm not sure if this is the correct format to reply to a post in the mailing list. Apologize if not.
>
> Best Regards,
> Shuyang Liu
>
> [1] John Bender and Jens Palsberg. 2019. A formalization of Java’s concurrent access modes. Proc. ACM Program. Lang. 3, OOPSLA, Article 142 (October 2019), 28 pages. DOI:https://doi.org/10.1145/3360568
>
> [2] Ori Lahav, Viktor Vafeiadis, Jeehoon Kang, Chung-Kil Hur, and Derek Dreyer. 2017. Repairing Sequential Consistency in C/C++11. In Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2017). ACM, New York, NY, USA, 618–632
>
> [3] Programming Language Memory Models  https://research.swtch.com/plmm
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: [concurrency-interest] Are there real use cases with the Java access modes?
From: Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-17, 23:29
To: concurrency-interest@cs.oswego.edu
Reply-To: Shuyang Liu <sliu44@cs.ucla.edu>

Hello,

My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

Thanks you,
Shuyang Liu

[1]. Using JDK 9 Memory Order Modes  
http://gee.cs.oswego.edu/dl/html/j9mm.html

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-17, 23:45
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Gregg Wonderly <gergg@cox.net>

One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 

while( nonVolatileRefExpr ) {}

Into 

if( nonVolatileRefExpr ) { while( true ) {} }

Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.

Gregg Wonderly

Sent from my iPhone

> On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> ﻿
> Hello,
>
> My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>
> Thanks you,
> Shuyang Liu
>
> [1]. Using JDK 9 Memory Order Modes  
> http://gee.cs.oswego.edu/dl/html/j9mm.html
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 00:05
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Shuyang Liu <sliu44@cs.ucla.edu>

Thanks you!

 I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 

Best Regards,
Shuyang

> On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>
> ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>
> while( nonVolatileRefExpr ) {}
>
> Into 
>
> if( nonVolatileRefExpr ) { while( true ) {} }
>
> Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>
> Gregg Wonderly
>
> Sent from my iPhone
>
>> On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>> ﻿
>> Hello,
>>
>> My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>
>> Thanks you,
>> Shuyang Liu
>>
>> [1]. Using JDK 9 Memory Order Modes  
>> http://gee.cs.oswego.edu/dl/html/j9mm.html
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest@cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 01:09
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think one important case is an atomic increment that does not introduce full barriers (choose opaque, if you are just counting; acquire, if you are acquiring a semaphore; release, when releasing; or rel-acquire). I know of a few like things achievable in other languages, which probably are beneficial on many non-tso architectures.

Another important clarification needed is what barriers are enforced on failure of CAS. I think there was a discussion about this on this list, but I don't recall if that resulted in a definitive answer about what it should be. 

Alex

On Sat, 17 Jul 2021, 21:33 Shuyang Liu via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    Hello,

    My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

    Thanks you,
    Shuyang Liu

    [1]. Using JDK 9 Memory Order Modes  
    http://gee.cs.oswego.edu/dl/html/j9mm.html
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 01:14
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think it is easy to test what happens, if you don't allow that to happen.

To do that, declare everything volatile. You can use byte code instrumentation to achieve that.

You can see at least two things:

a. How slow everything becomes
b. How it doesn't improve correctness.

Alex

On Sat, 17 Jul 2021, 21:46 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 

    while( nonVolatileRefExpr ) {}

    Into 

    if( nonVolatileRefExpr ) { while( true ) {} }

    Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.

    Gregg Wonderly

    Sent from my iPhone

>     On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     ﻿
>     Hello,
>
>     My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>
>     Thanks you,
>     Shuyang Liu
>
>     [1]. Using JDK 9 Memory Order Modes  
>     http://gee.cs.oswego.edu/dl/html/j9mm.html
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 01:18
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: "Concurrency-interest@cs.oswego.edu" <concurrency-interest@cs.oswego.edu>
Reply-To: Benjamin Manes <ben.manes@gmail.com>

There is one usage of acquire / release in Caffeine for a weak / soft values cache. It looks something like the below snippet. It has the following characteristics:

1. During construction, a plain set is used as the entry is not yet visible to other threads. That can piggyback on the lock release.
2. Reading the value can usually use a plain read to piggyback on the map's volatile read of the entry, of which this class is the entry's value object.
3. When the referent is null, it may either be due to the garbage collector or a cache.put(k,v) setting a new reference and nulling out the old one. An acquire is used to check for a stale read.
4. When writing, a release is used to ensure that clearing the reference is ordered after the value is set. This way an intermediate null is not read due to a compiler reordering.

In general, though, most developers would prefer to use stronger orderings than necessary as simpler to reason about with equivalent performance. There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.

----

static final VarHandle VALUE;

Node(Object keyReference, V value, ReferenceQueue<V> referenceQueue) {
  VALUE.set(this, new WeakValueReference<V>(keyReference, value, referenceQueue));
}

public final V getValue() {
  for (;;) {
    Reference<V> ref = (Reference<V>) VALUE.get(this);
    V referent = ref.get();
    if ((referent != null) || (ref == VALUE.getAcquire(this))) {
      return referent;
    }
  }
}

public final void setValue(V value, ReferenceQueue<V> referenceQueue) {
  Reference<V> ref = (Reference<V>) VALUE.get(this);
  VALUE.setRelease(this, new WeakValueReference<V>(getKeyReference(), value, referenceQueue));
  ref.clear();
}
 

On Sat, Jul 17, 2021 at 1:32 PM Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    Hello,

    My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

    Thanks you,
    Shuyang Liu

    [1]. Using JDK 9 Memory Order Modes  
    http://gee.cs.oswego.edu/dl/html/j9mm.html
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 02:33
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Shuyang Liu <sliu44@cs.ucla.edu>

Thank you!

> I know of a few like things achievable in other languages

Is there an example of this?

> Another important clarification needed is what barriers are enforced on failure of CAS

Currently in our Herd implementation with Java, on a failed CAS, it treated equivalently as a read with its access mode specified. But I agree that it needs further confirmations on whether it is correct. So if it is `compareAndExchangeRelease`, then no barrier is enforced because the read in this case is a plain read. If it is `compareAndSet​`on a failure branch, then it is the same as a volatile read with a full barrier inserted either before or after depends on the compilation scheme. C11 does something slightly different (according to their Herd implementation). In addition to the read (with its specified memory order), it also performs a non-atomic write to `*expected` following that read if the compare fails. Since it is non-atomic, there is no extra barriers inserted for the write.

I'll look for that email thread that you mentioned. It seems there might be something more to it.

Best,
Shuyang

From: "Alex Otenko" <oleksandr.otenko@gmail.com>
To: "Shuyang Liu" <sliu44@cs.ucla.edu>
Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
Sent: Saturday, July 17, 2021 3:09:49 PM
Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

I think one important case is an atomic increment that does not introduce full barriers (choose opaque, if you are just counting; acquire, if you are acquiring a semaphore; release, when releasing; or rel-acquire). I know of a few like things achievable in other languages, which probably are beneficial on many non-tso architectures.

Another important clarification needed is what barriers are enforced on failure of CAS. I think there was a discussion about this on this list, but I don't recall if that resulted in a definitive answer about what it should be. 

Alex

On Sat, 17 Jul 2021, 21:33 Shuyang Liu via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    Hello,

    My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

    Thanks you,
    Shuyang Liu

    [1]. Using JDK 9 Memory Order Modes  
    http://gee.cs.oswego.edu/dl/html/j9mm.html
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 02:50
To: Benjamin Manes <ben.manes@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Shuyang Liu <sliu44@cs.ucla.edu>

Thank you for the detailed explanation! I'll take a look at the code in Caffine.

> There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.
This is why we are asking for help here :) We couldn't find many interesting use cases after a basic search. Your example is a good one. I'll look into how JDK uses it.

Best,
Shuyang

From: "Benjamin Manes" <ben.manes@gmail.com>
To: "Shuyang Liu" <sliu44@cs.ucla.edu>
Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
Sent: Saturday, July 17, 2021 3:18:22 PM
Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

There is one usage of acquire / release in Caffeine for a weak / soft values cache. It looks something like the below snippet. It has the following characteristics:

1. During construction, a plain set is used as the entry is not yet visible to other threads. That can piggyback on the lock release.
2. Reading the value can usually use a plain read to piggyback on the map's volatile read of the entry, of which this class is the entry's value object.
3. When the referent is null, it may either be due to the garbage collector or a cache.put(k,v) setting a new reference and nulling out the old one. An acquire is used to check for a stale read.
4. When writing, a release is used to ensure that clearing the reference is ordered after the value is set. This way an intermediate null is not read due to a compiler reordering.

In general, though, most developers would prefer to use stronger orderings than necessary as simpler to reason about with equivalent performance. There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.

----

static final VarHandle VALUE;

Node(Object keyReference, V value, ReferenceQueue<V> referenceQueue) {
  VALUE.set(this, new WeakValueReference<V>(keyReference, value, referenceQueue));
}

public final V getValue() {
  for (;;) {
    Reference<V> ref = (Reference<V>) VALUE.get(this);
    V referent = ref.get();
    if ((referent != null) || (ref == VALUE.getAcquire(this))) {
      return referent;
    }
  }
}

public final void setValue(V value, ReferenceQueue<V> referenceQueue) {
  Reference<V> ref = (Reference<V>) VALUE.get(this);
  VALUE.setRelease(this, new WeakValueReference<V>(getKeyReference(), value, referenceQueue));
  ref.clear();
}
 

On Sat, Jul 17, 2021 at 1:32 PM Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    Hello,

    My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

    Thanks you,
    Shuyang Liu

    [1]. Using JDK 9 Memory Order Modes  
    http://gee.cs.oswego.edu/dl/html/j9mm.html
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 07:10
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Gregg Wonderly <gergg@cox.net>

Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  

While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!

The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.

Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!

Gregg Wonderly

Sent from my iPhone

> On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>
> ﻿Thanks you!
>
>  I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>
> Best Regards,
> Shuyang
>
>> On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>
>> ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>
>> while( nonVolatileRefExpr ) {}
>>
>> Into 
>>
>> if( nonVolatileRefExpr ) { while( true ) {} }
>>
>> Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>
>> Gregg Wonderly
>>
>> Sent from my iPhone
>>
>>> On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>> ﻿
>>> Hello,
>>>
>>> My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>
>>> Thanks you,
>>> Shuyang Liu
>>>
>>> [1]. Using JDK 9 Memory Order Modes  
>>> http://gee.cs.oswego.edu/dl/html/j9mm.html
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest@cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 07:13
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

You still assume that everyone trying to use a Java is a well educated, trained and knowledgeable software engineer.  That’s just not the reality that exists.

Gregg

Sent from my iPhone

> On Jul 17, 2021, at 6:15 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> ﻿
> I think it is easy to test what happens, if you don't allow that to happen.
>
> To do that, declare everything volatile. You can use byte code instrumentation to achieve that.
>
> You can see at least two things:
>
> a. How slow everything becomes
> b. How it doesn't improve correctness.
>
> Alex
>
> On Sat, 17 Jul 2021, 21:46 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>
>     One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>
>     while( nonVolatileRefExpr ) {}
>
>     Into 
>
>     if( nonVolatileRefExpr ) { while( true ) {} }
>
>     Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>
>     Gregg Wonderly
>
>     Sent from my iPhone
>
>>     On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>     ﻿
>>     Hello,
>>
>>     My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>
>>     Thanks you,
>>     Shuyang Liu
>>
>>     [1]. Using JDK 9 Memory Order Modes  
>>     http://gee.cs.oswego.edu/dl/html/j9mm.html
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest@cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 09:08
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

The example for fetch_add with memory order parameter is available in Rust and C.

The different examples of code would be: counting watermark. Here the loads and releases done by fetch-add I presume are not "normal", but opaque.

A case with release semantics is the common serialization routine: if fetch-add with release ordering returns zero, you enter the critical section; if non-zero, then you can assume your changes to shared data structure will be observed by the contender that observed 0 for this fetch-add. Then before exiting the critical section it suffices to do fetch-add with acquire ordering. If this fetch-add results in non-zero, some contender attempted to enter.

if (contenders.getAndIncrement() >0) return; // release ordering

for(int c=1; c>0; c=contenders.addAndGet(-c)) // acquire ordering
// process changes to shared data structure, and, say, write to socket


Of course, there are some assumptions about shared state modified outside this loop, and shared state accessible inside the loop.

Alex

On Sun, 18 Jul 2021, 00:33 Shuyang Liu, <sliu44@cs.ucla.edu> wrote:

    Thank you!

    > I know of a few like things achievable in other languages

    Is there an example of this?

    > Another important clarification needed is what barriers are enforced on failure of CAS

    Currently in our Herd implementation with Java, on a failed CAS, it treated equivalently as a read with its access mode specified. But I agree that it needs further confirmations on whether it is correct. So if it is `compareAndExchangeRelease`, then no barrier is enforced because the read in this case is a plain read. If it is `compareAndSet​`on a failure branch, then it is the same as a volatile read with a full barrier inserted either before or after depends on the compilation scheme. C11 does something slightly different (according to their Herd implementation). In addition to the read (with its specified memory order), it also performs a non-atomic write to `*expected` following that read if the compare fails. Since it is non-atomic, there is no extra barriers inserted for the write.

    I'll look for that email thread that you mentioned. It seems there might be something more to it.

    Best,
    Shuyang

    From: "Alex Otenko" <oleksandr.otenko@gmail.com>
    To: "Shuyang Liu" <sliu44@cs.ucla.edu>
    Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
    Sent: Saturday, July 17, 2021 3:09:49 PM
    Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

    I think one important case is an atomic increment that does not introduce full barriers (choose opaque, if you are just counting; acquire, if you are acquiring a semaphore; release, when releasing; or rel-acquire). I know of a few like things achievable in other languages, which probably are beneficial on many non-tso architectures.

    Another important clarification needed is what barriers are enforced on failure of CAS. I think there was a discussion about this on this list, but I don't recall if that resulted in a definitive answer about what it should be. 

    Alex

    On Sat, 17 Jul 2021, 21:33 Shuyang Liu via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

        Hello,

        My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

        Thanks you,
        Shuyang Liu

        [1]. Using JDK 9 Memory Order Modes  
        http://gee.cs.oswego.edu/dl/html/j9mm.html
        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 09:25
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Ok, I meant

if (...getAndIncrement...) // acquire ordering

for(....addAndGet...) // release ordering 

Alex

On Sun, 18 Jul 2021, 07:08 Alex Otenko, <oleksandr.otenko@gmail.com> wrote:

    The example for fetch_add with memory order parameter is available in Rust and C.

    The different examples of code would be: counting watermark. Here the loads and releases done by fetch-add I presume are not "normal", but opaque.

    A case with release semantics is the common serialization routine: if fetch-add with release ordering returns zero, you enter the critical section; if non-zero, then you can assume your changes to shared data structure will be observed by the contender that observed 0 for this fetch-add. Then before exiting the critical section it suffices to do fetch-add with acquire ordering. If this fetch-add results in non-zero, some contender attempted to enter.

    if (contenders.getAndIncrement() >0) return; // release ordering

    for(int c=1; c>0; c=contenders.addAndGet(-c)) // acquire ordering
    // process changes to shared data structure, and, say, write to socket


    Of course, there are some assumptions about shared state modified outside this loop, and shared state accessible inside the loop.

    Alex

    On Sun, 18 Jul 2021, 00:33 Shuyang Liu, <sliu44@cs.ucla.edu> wrote:

        Thank you!

        > I know of a few like things achievable in other languages

        Is there an example of this?

        > Another important clarification needed is what barriers are enforced on failure of CAS

        Currently in our Herd implementation with Java, on a failed CAS, it treated equivalently as a read with its access mode specified. But I agree that it needs further confirmations on whether it is correct. So if it is `compareAndExchangeRelease`, then no barrier is enforced because the read in this case is a plain read. If it is `compareAndSet​`on a failure branch, then it is the same as a volatile read with a full barrier inserted either before or after depends on the compilation scheme. C11 does something slightly different (according to their Herd implementation). In addition to the read (with its specified memory order), it also performs a non-atomic write to `*expected` following that read if the compare fails. Since it is non-atomic, there is no extra barriers inserted for the write.

        I'll look for that email thread that you mentioned. It seems there might be something more to it.

        Best,
        Shuyang

        From: "Alex Otenko" <oleksandr.otenko@gmail.com>
        To: "Shuyang Liu" <sliu44@cs.ucla.edu>
        Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
        Sent: Saturday, July 17, 2021 3:09:49 PM
        Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

        I think one important case is an atomic increment that does not introduce full barriers (choose opaque, if you are just counting; acquire, if you are acquiring a semaphore; release, when releasing; or rel-acquire). I know of a few like things achievable in other languages, which probably are beneficial on many non-tso architectures.

        Another important clarification needed is what barriers are enforced on failure of CAS. I think there was a discussion about this on this list, but I don't recall if that resulted in a definitive answer about what it should be. 

        Alex

        On Sat, 17 Jul 2021, 21:33 Shuyang Liu via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

            Hello,

            My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

            Thanks you,
            Shuyang Liu

            [1]. Using JDK 9 Memory Order Modes  
            http://gee.cs.oswego.edu/dl/html/j9mm.html
            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 09:34
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.

And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.

There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.

Alex

On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  

    While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!

    The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.

    Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!

    Gregg Wonderly

    Sent from my iPhone

>     On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>
>     ﻿Thanks you!
>
>      I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>
>     Best Regards,
>     Shuyang
>
>>     On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>
>>     ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>
>>     while( nonVolatileRefExpr ) {}
>>
>>     Into 
>>
>>     if( nonVolatileRefExpr ) { while( true ) {} }
>>
>>     Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>
>>     Gregg Wonderly
>>
>>     Sent from my iPhone
>>
>>>     On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>>     ﻿
>>>     Hello,
>>>
>>>     My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>
>>>     Thanks you,
>>>     Shuyang Liu
>>>
>>>     [1]. Using JDK 9 Memory Order Modes  
>>>     http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest@cs.oswego.edu
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 20:54
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.

Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.

Gregg Wonderly

Sent from my iPhone

> On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
> ﻿
> The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>
> And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>
> There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>
> Alex
>
> On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>
>     Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>
>     While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>
>     The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>
>     Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>
>     Gregg Wonderly
>
>     Sent from my iPhone
>
>>     On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>
>>     ﻿Thanks you!
>>
>>      I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>
>>     Best Regards,
>>     Shuyang
>>
>>>     On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>
>>>     ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>
>>>     while( nonVolatileRefExpr ) {}
>>>
>>>     Into 
>>>
>>>     if( nonVolatileRefExpr ) { while( true ) {} }
>>>
>>>     Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>
>>>     Gregg Wonderly
>>>
>>>     Sent from my iPhone
>>>
>>>>     On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>
>>>>     ﻿
>>>>     Hello,
>>>>
>>>>     My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>
>>>>     Thanks you,
>>>>     Shuyang Liu
>>>>
>>>>     [1]. Using JDK 9 Memory Order Modes  
>>>>     http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>     _______________________________________________
>>>>     Concurrency-interest mailing list
>>>>     Concurrency-interest@cs.oswego.edu
>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-18, 23:47
To: concurrency-interest@cs.oswego.edu
Reply-To: Brian S O'Neill <bronee@gmail.com>

Consider for a moment if Java was originally designed with the current memory model, and that all fields were effectively volatile by default. This would mean that the loop problem that you identified would never surface, which is a good thing.

One problem is now solved, but perhaps new problems would emerge? The first problem that I can think of is that this doesn't magically make code thread-safe. The cost is performance, and there's no real benefit except in a few cases. The bigger problem is "premature optimization".

As soon as someone discovers that declaring fields as non-volatile offers performance benefits, then this ends up becoming best practice, and new thread safety issues emerge that never should have.

The best practice these days is for most programmers to never declare volatile fields in the first place, because it implies that they're doing magic stuff with threads and they might not do it correctly. Unlike Java 1.0, there's plenty of frameworks that take care of thread safety nicely without having to declare fields as volatile or make methods synchronized. Work queues fall into this category, for example.

Your concern seems to be with regard to Java desktop apps, and this is fair. The Java desktop API (AWT/Swing) was designed without proper consideration for threads, and it's quite a mess as a result. A lot has been learned since then, and the desktop API is in need of a major refresh. That is, it needs to be completely redesigned to incorporate the lessons learned over the past 25 years. If a new design requires that fields need to always be volatile, then it's a failure too.

By the way, I suspect that most people on this mailing list (including me) usually write server-side code, and so we don't have a proper understanding of how the desktop API can sometimes be a burden. So when we hear someone suggesting that fields behave as volatile by default, we wonder if this would solve any of the problems we've ever encountered. I can't really think of any, but then this is probably because the server-side has a richer set of frameworks to use.


On 2021-07-18 10:54 AM, Gregg Wonderly via Concurrency-interest wrote:
> Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>
> Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>
> Gregg Wonderly
>
> Sent from my iPhone
>
>> On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>
>> ﻿
>> The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>
>> And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>
>> There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>
>> Alex
>>
>> On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu <mailto:concurrency-interest@cs.oswego.edu>> wrote:
>>
>>     Yes this was changed at the sane time the JMM defined  and caused
>>     implementation of volatile to happen.
>>
>>     While this is legal because of the JMM, it causes broken code to
>>     happen without the user really understanding why it could happen
>>     and that it will happen.  It’s different in significant ways from
>>     cache coherency, and it worked prior to JDK1.5.  I still believe
>>     that volatile creates a giant surprise.  This is an optimization
>>     behavior that “breaks” code without the user electing to have such
>>     an optimization performed!
>>
>>     The default variable declaration should be volatile and a
>>     different mechanism should be necessary to get non-volatile
>>     optimizations to happen.  A user should never, ever, be able to
>>     write non-working code using default language constructs.
>>
>>     Look at the past examples in C-Language and C++ etc.  Things like
>>     Register optimizations and many other constructs required the user
>>     to break their code, rather than that being the default behavior!
>>
>>     Gregg Wonderly
>>
>>     Sent from my iPhone
>>
>>>     On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu
>>>     <mailto:sliu44@cs.ucla.edu>> wrote:
>>>
>>>     ﻿Thanks you!
>>>
>>>      I guess this is before Java 9? So I think “nonVolatileRefExpr”
>>>     is equivalent to a plain access in this case. The compiler
>>>     probably identified it as a local access since it is not marked
>>>     as volatile (then its indeed equivalent to an infinite loop,
>>>     which makes the transformation valid). Do you know if there’s any
>>>     applications/bug report with this pattern?
>>>
>>>     Best Regards,
>>>     Shuyang
>>>
>>>>     On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net
>>>>     <mailto:gergg@cox.net>> wrote:
>>>>
>>>>     ﻿One of the standing problems I have is optimizations around
>>>>     non-volatile value references.  Currently, there are visibility
>>>>     optimizations that turn
>>>>
>>>>     while( nonVolatileRefExpr ) {}
>>>>
>>>>     Into
>>>>
>>>>     if( nonVolatileRefExpr ) { while( true ) {} }
>>>>
>>>>     Which creates infinite loops.  This makes one of the most common
>>>>     types of applications written in Swing to fail to work as the
>>>>     code is written.
>>>>
>>>>     Gregg Wonderly
>>>>
>>>>     Sent from my iPhone
>>>>
>>>>>     On Jul 17, 2021, at 4:33 PM, Shuyang Liu via
>>>>>     Concurrency-interest <concurrency-interest@cs.oswego.edu
>>>>>     <mailto:concurrency-interest@cs.oswego.edu>> wrote:
>>>>>
>>>>>     ﻿
>>>>>     Hello,
>>>>>
>>>>>     My colleagues and I have been working on a formal model for the
>>>>>     Java access modes that is added since Java 9 [1]. Are there any
>>>>>     popular use cases of access modes in real world
>>>>>     applications/frameworks/libraries? We would like to see how our
>>>>>     current formal model works in real examples.
>>>>>
>>>>>     Thanks you,
>>>>>     Shuyang Liu
>>>>>
>>>>>     [1]. Using JDK 9 Memory Order Modes
>>>>>     http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>     <http://gee.cs.oswego.edu/dl/html/j9mm.html>
>>>>>     _______________________________________________
>>>>>     Concurrency-interest mailing list
>>>>>     Concurrency-interest@cs.oswego.edu
>>>>>     <mailto:Concurrency-interest@cs.oswego.edu>
>>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest@cs.oswego.edu
>>     <mailto:Concurrency-interest@cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 00:28
To: Brian S O'Neill <bronee@gmail.com>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Gregg Wonderly <gergg@cox.net>

Brian, you are saying what I feel.  The issue is simply that non-volatile compiler optimization behavior breaks a simple construct that requires adding volatile declaration to fix.  We can discuss how much is missing from the Swing/AWT multi-threading support.  Many people have engineered something using SwingWorkerThread and shared data structure exchanges.  That works from a trivial level of knowledge, because you can read about it.

The use of volatile as a solution to simple one reader and one writer exchanges, as you say, is not really a solution, but rather a wrenching into the system to disable a problem that occurs in logic, broken by inaction by the developer.

Everything else involving data sharing happens through frameworks and APIs with JavaDoc, examples online, and books even!  I am just one voice calling this out.  I was the one voice first demanding that Java 9 not be released with introspection disabled.  It took quite some time for server only developers to understand how separate Java jar file software releases from Java version management for desktop users.  There is never a combined release of anything in the desktop environment for most users that I interact with. Forever forward compatibility is what you have to do, to develop Java for the Desktop, and that is impossible, but the best thing to aim for.

Oracles change in licensing is now pushing many companies to openJDK and that push compatibility requirements back to JDK 1.8 and the risk is that there’s now no path forward with modularity “always”.  Thus means two releases if not code bases and that implies that Java is no longer write once, run everywhere.  Microsoft is eliminating barriers and python is sucking inexperienced service developers into a non-scalable platform down the road.

The Java community needs to be heavily focused on all barriers to entry and first experiences and inexperienced developers have to be part of that audience.  Sun showed Java’s target audience as the 1,000,000 and up developers, not the 10,000 experts in big tech.  It would appear that Java is carving itself into a very vertical market space instead of being the write once run anywhere software system that was changing software for the better.  

The JVM has been heavily leveraged!  We need Java to continue to be a beneficial software system, or what have the past 25years of work been about?

Gregg Wonderly

> > On Jul 18, 2021, at 4:48 PM, Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > ﻿Consider for a moment if Java was originally designed with the current memory model, and that all fields were effectively volatile by default. This would mean that the loop problem that you identified would never surface, which is a good thing.
> > 
> > One problem is now solved, but perhaps new problems would emerge? The first problem that I can think of is that this doesn't magically make code thread-safe. The cost is performance, and there's no real benefit except in a few cases. The bigger problem is "premature optimization".
> > 
> > As soon as someone discovers that declaring fields as non-volatile offers performance benefits, then this ends up becoming best practice, and new thread safety issues emerge that never should have.
> > 
> > The best practice these days is for most programmers to never declare volatile fields in the first place, because it implies that they're doing magic stuff with threads and they might not do it correctly. Unlike Java 1.0, there's plenty of frameworks that take care of thread safety nicely without having to declare fields as volatile or make methods synchronized. Work queues fall into this category, for example.
> > 
> > Your concern seems to be with regard to Java desktop apps, and this is fair. The Java desktop API (AWT/Swing) was designed without proper consideration for threads, and it's quite a mess as a result. A lot has been learned since then, and the desktop API is in need of a major refresh. That is, it needs to be completely redesigned to incorporate the lessons learned over the past 25 years. If a new design requires that fields need to always be volatile, then it's a failure too.
> > 
> > By the way, I suspect that most people on this mailing list (including me) usually write server-side code, and so we don't have a proper understanding of how the desktop API can sometimes be a burden. So when we hear someone suggesting that fields behave as volatile by default, we wonder if this would solve any of the problems we've ever encountered. I can't really think of any, but then this is probably because the server-side has a richer set of frameworks to use.
> > 
> > 
>> >> On 2021-07-18 10:54 AM, Gregg Wonderly via Concurrency-interest wrote:
>> >> Good software design always includes the notion of least surprise.  In which ot

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 02:06
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.

I'd like to see such code.

Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.

Alex

On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:

    Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.

    Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.

    Gregg Wonderly

    Sent from my iPhone

>     On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
>     ﻿
>     The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>
>     And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>
>     There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>
>     Alex
>
>     On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>
>         Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>
>         While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>
>         The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>
>         Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>
>         Gregg Wonderly
>
>         Sent from my iPhone
>
>>         On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>
>>         ﻿Thanks you!
>>
>>          I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>
>>         Best Regards,
>>         Shuyang
>>
>>>         On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>
>>>         ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>
>>>         while( nonVolatileRefExpr ) {}
>>>
>>>         Into 
>>>
>>>         if( nonVolatileRefExpr ) { while( true ) {} }
>>>
>>>         Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>
>>>         Gregg Wonderly
>>>
>>>         Sent from my iPhone
>>>
>>>>         On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>
>>>>         ﻿
>>>>         Hello,
>>>>
>>>>         My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>
>>>>         Thanks you,
>>>>         Shuyang Liu
>>>>
>>>>         [1]. Using JDK 9 Memory Order Modes  
>>>>         http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest@cs.oswego.edu
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest@cs.oswego.edu
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 05:32
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

You are misunderstanding my assertion.  I am only stating that the code is changed from could work under some circumstances, to unexplainably never working.  In other words, a debugger would make non volatile code work, because all of its code running, would cause processor instructions that would likely make cache line isolation impossible to experience.

This then becomes documentable side effects of data races.  But realistically, as Brian stated, any mult-threaded behaviors in desktop apps are not very obvious, and data races are often not experienced because of how the app thread and the awt event queue interact.

Gregg

Sent from my iPhone

> On Jul 18, 2021, at 6:09 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> ﻿
> I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.
>
> I'd like to see such code.
>
> Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.
>
> Alex
>
> On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:
>
>     Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>
>     Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>
>     Gregg Wonderly
>
>     Sent from my iPhone
>
>>     On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>
>>     ﻿
>>     The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>
>>     And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>
>>     There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>
>>     Alex
>>
>>     On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>>
>>         Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>>
>>         While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>>
>>         The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>>
>>         Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>>
>>         Gregg Wonderly
>>
>>         Sent from my iPhone
>>
>>>         On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>>
>>>         ﻿Thanks you!
>>>
>>>          I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>>
>>>         Best Regards,
>>>         Shuyang
>>>
>>>>         On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>>
>>>>         ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>>
>>>>         while( nonVolatileRefExpr ) {}
>>>>
>>>>         Into 
>>>>
>>>>         if( nonVolatileRefExpr ) { while( true ) {} }
>>>>
>>>>         Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>>
>>>>         Gregg Wonderly
>>>>
>>>>         Sent from my iPhone
>>>>
>>>>>         On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>>
>>>>>         ﻿
>>>>>         Hello,
>>>>>
>>>>>         My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>>
>>>>>         Thanks you,
>>>>>         Shuyang Liu
>>>>>
>>>>>         [1]. Using JDK 9 Memory Order Modes  
>>>>>         http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>         _______________________________________________
>>>>>         Concurrency-interest mailing list
>>>>>         Concurrency-interest@cs.oswego.edu
>>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest@cs.oswego.edu
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 10:40
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think a piece of code would move this discussion from handwaving to something concrete. If there is some interaction with AWT, the variable you complain about cannot be hoisted. If there is no interaction, then the complaint reduces from "perfectly good code is perfectly broken" to "perfectly broken code is perfectly broken".

Without an example everyone is left guessing why anyone would attempt to use a debugger to diagnose a race condition. 

Alex

On Mon, 19 Jul 2021, 03:32 Gregg Wonderly, <gergg@cox.net> wrote:

    You are misunderstanding my assertion.  I am only stating that the code is changed from could work under some circumstances, to unexplainably never working.  In other words, a debugger would make non volatile code work, because all of its code running, would cause processor instructions that would likely make cache line isolation impossible to experience.

    This then becomes documentable side effects of data races.  But realistically, as Brian stated, any mult-threaded behaviors in desktop apps are not very obvious, and data races are often not experienced because of how the app thread and the awt event queue interact.

    Gregg

    Sent from my iPhone

>     On Jul 18, 2021, at 6:09 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     ﻿
>     I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.
>
>     I'd like to see such code.
>
>     Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.
>
>     Alex
>
>     On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:
>
>         Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>
>         Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>
>         Gregg Wonderly
>
>         Sent from my iPhone
>
>>         On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>
>>         ﻿
>>         The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>
>>         And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>
>>         There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>
>>         Alex
>>
>>         On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>>
>>             Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>>
>>             While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>>
>>             The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>>
>>             Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>>
>>             Gregg Wonderly
>>
>>             Sent from my iPhone
>>
>>>             On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>>
>>>             ﻿Thanks you!
>>>
>>>              I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>>
>>>             Best Regards,
>>>             Shuyang
>>>
>>>>             On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>>
>>>>             ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>>
>>>>             while( nonVolatileRefExpr ) {}
>>>>
>>>>             Into 
>>>>
>>>>             if( nonVolatileRefExpr ) { while( true ) {} }
>>>>
>>>>             Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>>
>>>>             Gregg Wonderly
>>>>
>>>>             Sent from my iPhone
>>>>
>>>>>             On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>>
>>>>>             ﻿
>>>>>             Hello,
>>>>>
>>>>>             My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>>
>>>>>             Thanks you,
>>>>>             Shuyang Liu
>>>>>
>>>>>             [1]. Using JDK 9 Memory Order Modes  
>>>>>             http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>             _______________________________________________
>>>>>             Concurrency-interest mailing list
>>>>>             Concurrency-interest@cs.oswego.edu
>>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>             _______________________________________________
>>             Concurrency-interest mailing list
>>             Concurrency-interest@cs.oswego.edu
>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 10:56
To: Shuyang Liu <sliu44@cs.ucla.edu>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Benjamin Manes <ben.manes@gmail.com>

Another avenue to explore are usages of the older Unsafe's putOrdered and Atomic's delegate of lazySet. While these were introduced in JDK5, the naming and meaning was confusing and are not widely used. It is now explicitly acquire/release ordering in JDK9. JCTools is a good example of such usages.

When reviewing Caffeine, there are more cases that I had forgotten about which use weaker ordering, such as when populating an element in an MPSC ring buffer. Similarly, it seems that LMAX disruptor is also using acquire/release for its ring buffer logic.

On Sat, Jul 17, 2021 at 4:50 PM Shuyang Liu <sliu44@cs.ucla.edu> wrote:

    Thank you for the detailed explanation! I'll take a look at the code in Caffine.

    > There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.
    This is why we are asking for help here :) We couldn't find many interesting use cases after a basic search. Your example is a good one. I'll look into how JDK uses it.

    Best,
    Shuyang

    From: "Benjamin Manes" <ben.manes@gmail.com>
    To: "Shuyang Liu" <sliu44@cs.ucla.edu>
    Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
    Sent: Saturday, July 17, 2021 3:18:22 PM
    Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

    There is one usage of acquire / release in Caffeine for a weak / soft values cache. It looks something like the below snippet. It has the following characteristics:

    1. During construction, a plain set is used as the entry is not yet visible to other threads. That can piggyback on the lock release.
    2. Reading the value can usually use a plain read to piggyback on the map's volatile read of the entry, of which this class is the entry's value object.
    3. When the referent is null, it may either be due to the garbage collector or a cache.put(k,v) setting a new reference and nulling out the old one. An acquire is used to check for a stale read.
    4. When writing, a release is used to ensure that clearing the reference is ordered after the value is set. This way an intermediate null is not read due to a compiler reordering.

    In general, though, most developers would prefer to use stronger orderings than necessary as simpler to reason about with equivalent performance. There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.

    ----

    static final VarHandle VALUE;

    Node(Object keyReference, V value, ReferenceQueue<V> referenceQueue) {
      VALUE.set(this, new WeakValueReference<V>(keyReference, value, referenceQueue));
    }

    public final V getValue() {
      for (;;) {
        Reference<V> ref = (Reference<V>) VALUE.get(this);
        V referent = ref.get();
        if ((referent != null) || (ref == VALUE.getAcquire(this))) {
          return referent;
        }
      }
    }

    public final void setValue(V value, ReferenceQueue<V> referenceQueue) {
      Reference<V> ref = (Reference<V>) VALUE.get(this);
      VALUE.setRelease(this, new WeakValueReference<V>(getKeyReference(), value, referenceQueue));
      ref.clear();
    }
     

    On Sat, Jul 17, 2021 at 1:32 PM Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

        Hello,

        My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

        Thanks you,
        Shuyang Liu

        [1]. Using JDK 9 Memory Order Modes  
        http://gee.cs.oswego.edu/dl/html/j9mm.html
        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Francesco Nigro via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 11:09
To: Benjamin Manes <ben.manes@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Francesco Nigro <nigro.fra@gmail.com>

All good points @Benjamin Manes: just for reference this is the related article of Nitsan Wakart (main author of JCTools) on the subject http://psy-lob-saw.blogspot.com/2016/12/what-is-lazyset-putordered.html

IIRC some time later on JCTools Nitsan switched to the fast flow queue model using "lazySet" aka store-release semantic for the q slot values.


Il lun 19 lug 2021, 09:58 Benjamin Manes via Concurrency-interest <concurrency-interest@cs.oswego.edu> ha scritto:

    Another avenue to explore are usages of the older Unsafe's putOrdered and Atomic's delegate of lazySet. While these were introduced in JDK5, the naming and meaning was confusing and are not widely used. It is now explicitly acquire/release ordering in JDK9. JCTools is a good example of such usages.

    When reviewing Caffeine, there are more cases that I had forgotten about which use weaker ordering, such as when populating an element in an MPSC ring buffer. Similarly, it seems that LMAX disruptor is also using acquire/release for its ring buffer logic.

    On Sat, Jul 17, 2021 at 4:50 PM Shuyang Liu <sliu44@cs.ucla.edu> wrote:

        Thank you for the detailed explanation! I'll take a look at the code in Caffine.

        > There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.
        This is why we are asking for help here :) We couldn't find many interesting use cases after a basic search. Your example is a good one. I'll look into how JDK uses it.

        Best,
        Shuyang

        From: "Benjamin Manes" <ben.manes@gmail.com>
        To: "Shuyang Liu" <sliu44@cs.ucla.edu>
        Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
        Sent: Saturday, July 17, 2021 3:18:22 PM
        Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

        There is one usage of acquire / release in Caffeine for a weak / soft values cache. It looks something like the below snippet. It has the following characteristics:

        1. During construction, a plain set is used as the entry is not yet visible to other threads. That can piggyback on the lock release.
        2. Reading the value can usually use a plain read to piggyback on the map's volatile read of the entry, of which this class is the entry's value object.
        3. When the referent is null, it may either be due to the garbage collector or a cache.put(k,v) setting a new reference and nulling out the old one. An acquire is used to check for a stale read.
        4. When writing, a release is used to ensure that clearing the reference is ordered after the value is set. This way an intermediate null is not read due to a compiler reordering.

        In general, though, most developers would prefer to use stronger orderings than necessary as simpler to reason about with equivalent performance. There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.

        ----

        static final VarHandle VALUE;

        Node(Object keyReference, V value, ReferenceQueue<V> referenceQueue) {
          VALUE.set(this, new WeakValueReference<V>(keyReference, value, referenceQueue));
        }

        public final V getValue() {
          for (;;) {
            Reference<V> ref = (Reference<V>) VALUE.get(this);
            V referent = ref.get();
            if ((referent != null) || (ref == VALUE.getAcquire(this))) {
              return referent;
            }
          }
        }

        public final void setValue(V value, ReferenceQueue<V> referenceQueue) {
          Reference<V> ref = (Reference<V>) VALUE.get(this);
          VALUE.setRelease(this, new WeakValueReference<V>(getKeyReference(), value, referenceQueue));
          ref.clear();
        }
         

        On Sat, Jul 17, 2021 at 1:32 PM Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

            Hello,

            My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

            Thanks you,
            Shuyang Liu

            [1]. Using JDK 9 Memory Order Modes  
            http://gee.cs.oswego.edu/dl/html/j9mm.html
            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest


    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 12:26
To: Gregg Wonderly <gergg@cox.net>, Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Andrew Dinn <adinn@redhat.com>

On 18/07/2021 05:13, Gregg Wonderly via Concurrency-interest wrote:
> You still assume that everyone trying to use a Java is a well educated, trained and knowledgeable software engineer.  That’s just not the reality that exists.
So, essentially, your argument is that we should significantly damage the performance of Java in order to make a relatively common example of ignorantly and badly written multi-threaded code (but not all such code) work correctly because that will allow people who don't know how to write multi-threaded code correctly to continue to produce more of it?

I believe you are fixing the wrong problem here.

regards,


Andrew Dinn
-----------

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 17:06
To: Andrew Dinn <adinn@redhat.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.

But, overall, least surprise is the real detail.  The non-volatile behavior, of data sharing not working, is fine, because that’s already documented.  You can search about all kinds of things to find the data sharing conversations.  But this single optimization is a problem that doesn’t need to happen behind the users back.  If you are trying to optimize a loop to avoid a memory reference in a loop that you know is controlled by a non-volatile reference that you know is not mutated by some other thread, then you can write that code explicitly, and all is good, because the logic that one reads in the source, is the logic that the JVM executes for you.   When you run a debugger, or review the code logic, it’s entirely clear what is happening.

Gregg Wonderly

> > On Jul 19, 2021, at 4:26 AM, Andrew Dinn <adinn@redhat.com> wrote:
> > 
> > On 18/07/2021 05:13, Gregg Wonderly via Concurrency-interest wrote:
>> >> You still assume that everyone trying to use a Java is a well educated, trained and knowledgeable software engineer.  That’s just not the reality that exists.
> > So, essentially, your argument is that we should significantly damage the performance of Java in order to make a relatively common example of ignorantly and badly written multi-threaded code (but not all such code) work correctly because that will allow people who don't know how to write multi-threaded code correctly to continue to produce more of it?
> > 
> > I believe you are fixing the wrong problem here.
> > 
> > regards,
> > 
> > 
> > Andrew Dinn
> > -----------
> > 

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 17:17
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.

Gregg Wonderly

import java.awt.*;
import java.awt.event.*;
import javax.swing.*;
import javax.swing.event.*;
import java.util.logging.*;

public class Example2 extends JFrame {

        JTextField tm;
        JButton btn;
        boolean done;
        public static void main( String args[] ) {
                new Example2(args).open();
                System.exit(0);
        }

        public Example2(String args[] ) {
                JPanel p = new JPanel();
                p.setLayout( new FlowLayout() );
                p.add( btn = new JButton("Press to Exit") );
                p.add( tm = new JTextField(20) );
                this.add(p);
                btn.addActionListener( new ActionListener() {
                        public void actionPerformed( ActionEvent ev ) {
                                Logger.getLogger(Example2.class.getName()).info("done...");
                                done = true;
                        }
                });
                done = false;
        }

        public void open() {
                pack();
                setLocationRelativeTo(null);
                setVisible(true);

// Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
                while( !done ) {
                        tm.setText(""+new java.util.Date() );
                        try {
                                Thread.sleep(500);
                        } catch( Exception ex ) {
                                Logger.getLogger(Example2.class.getName())
                                        .log( Level.SEVERE, ex.getMessage(), ex );
                        }
                }
        }
}

> On Jul 19, 2021, at 2:40 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> I think a piece of code would move this discussion from handwaving to something concrete. If there is some interaction with AWT, the variable you complain about cannot be hoisted. If there is no interaction, then the complaint reduces from "perfectly good code is perfectly broken" to "perfectly broken code is perfectly broken".
>
> Without an example everyone is left guessing why anyone would attempt to use a debugger to diagnose a race condition. 
>
> Alex
>
> On Mon, 19 Jul 2021, 03:32 Gregg Wonderly, <gergg@cox.net> wrote:
>
>     You are misunderstanding my assertion.  I am only stating that the code is changed from could work under some circumstances, to unexplainably never working.  In other words, a debugger would make non volatile code work, because all of its code running, would cause processor instructions that would likely make cache line isolation impossible to experience.
>
>     This then becomes documentable side effects of data races.  But realistically, as Brian stated, any mult-threaded behaviors in desktop apps are not very obvious, and data races are often not experienced because of how the app thread and the awt event queue interact.
>
>     Gregg
>
>     Sent from my iPhone
>
>>     On Jul 18, 2021, at 6:09 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>     ﻿
>>     I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.
>>
>>     I'd like to see such code.
>>
>>     Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.
>>
>>     Alex
>>
>>     On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:
>>
>>         Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>>
>>         Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>>
>>         Gregg Wonderly
>>
>>         Sent from my iPhone
>>
>>>         On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>>
>>>         ﻿
>>>         The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>>
>>>         And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>>
>>>         There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>>
>>>         Alex
>>>
>>>         On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>>             Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>>>
>>>             While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>>>
>>>             The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>>>
>>>             Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>>>
>>>             Gregg Wonderly
>>>
>>>             Sent from my iPhone
>>>
>>>>             On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>>>
>>>>             ﻿Thanks you!
>>>>
>>>>              I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>>>
>>>>             Best Regards,
>>>>             Shuyang
>>>>
>>>>>             On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>>>
>>>>>             ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>>>
>>>>>             while( nonVolatileRefExpr ) {}
>>>>>
>>>>>             Into 
>>>>>
>>>>>             if( nonVolatileRefExpr ) { while( true ) {} }
>>>>>
>>>>>             Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>>>
>>>>>             Gregg Wonderly
>>>>>
>>>>>             Sent from my iPhone
>>>>>
>>>>>>             On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>>>
>>>>>>             ﻿
>>>>>>             Hello,
>>>>>>
>>>>>>             My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>>>
>>>>>>             Thanks you,
>>>>>>             Shuyang Liu
>>>>>>
>>>>>>             [1]. Using JDK 9 Memory Order Modes  
>>>>>>             http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>>             _______________________________________________
>>>>>>             Concurrency-interest mailing list
>>>>>>             Concurrency-interest@cs.oswego.edu
>>>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest@cs.oswego.edu
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest@cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 17:25
To: concurrency-interest@cs.oswego.edu
Reply-To: Andrew Haley <aph@redhat.com>

On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
> > I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.

That single optimization is no more than hoisting a memory load. It's
one of the most common optimizations there is. It probably happens
many times in every moderately complex method. It's not some kind of
weird "let's turn this into an infinite loop" optimization.

For every non-volatile field load, in the absence of synchronization
actions, it is entirely correct and proper to hoist the result of that
load into a register, or propagate its value some other way. This is
common in many programming language implementations, and is not going
to change. It is a very important optimization.

-- Andrew Haley (he/him) Java Platform Lead Engineer Red Hat UK Ltd. <https://www.redhat.com> https://keybase.io/andrewhaley EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671 _______________________________________________ Concurrency-interest mailing list Concurrency-interest@cs.oswego.edu http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Viktor Klang via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 18:14
To: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Viktor Klang <viktor.klang@gmail.com>

In my experience,
once developers are offered dedicated APIs for thread-safe communication and concurrency, many of the issues we're talking about here sort of disappear. After 12+ years of experience of both developing, maintaining, and observing users use things like Akka Actors, visibility/reording issues tend to be a non-problem—as the concurrency model itself handles the safe publication, and the access to state is never done in parallel.
What remains is instead having to think about protocols—in the sense of communication patterns.

An application developer should, in my current view of the world, not ever have to deal with things such as Atomic*, s.m.Unsafe, volatile, etc.
Not only because they are difficult to *prove that their use is 100% correct*, but also because they are completely, 100%, unrelated to writing application logic.

So ideally (IMO) such tools should be reserved for JDK & library writers, to be able to offer constructs to developers where they no longer need to worry about correctness-in-the-face-of-parallelism. It is also a situation where more experience and knowledge is to be expected of the developer-user.

Long rant, and I realize that everything above is a bit of a "yes that would be nice but it's not realistic".

And I second the opinion that even if "dangerous" optimizations would be turned off by default, if those optimizations would lead to significant performance benefits (they will), they'd become de-facto defaults, eseentially turning the entire exercise into a bit of a moot point.

On Mon, Jul 19, 2021 at 4:26 PM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
    > I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.

    That single optimization is no more than hoisting a memory load. It's
    one of the most common optimizations there is. It probably happens
    many times in every moderately complex method. It's not some kind of
    weird "let's turn this into an infinite loop" optimization.

    For every non-volatile field load, in the absence of synchronization
    actions, it is entirely correct and proper to hoist the result of that
    load into a register, or propagate its value some other way. This is
    common in many programming language implementations, and is not going
    to change. It is a very important optimization.

    -- 
    Andrew Haley  (he/him)
    Java Platform Lead Engineer
    Red Hat UK Ltd. <https://www.redhat.com>
    https://keybase.io/andrewhaley
    EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-- 
Cheers,
√

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 18:43
To: Andrew Haley <aph@redhat.com>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 19, 2021, at 9:25 AM, Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
>> >> I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.
> > 
> > That single optimization is no more than hoisting a memory load. It's
> > one of the most common optimizations there is. It probably happens
> > many times in every moderately complex method. It's not some kind of
> > weird "let's turn this into an infinite loop" optimization.

Because it's in logic control code, it becomes quite visible as “unknown” behavior that the explicit code elements don’t illustrate, in any way, as the desired behavior.  If volatile was the default, and the user had to instead declare non-volatile desires with @nonvolatile or some other declaration (no new keywords is a problem), then this optimization would be documented by the code structure and keyword/feature use.  I get that no-one really wants to be faced with this, yet, when the JMM was released, everyone was faced with it.

> > For every non-volatile field load, in the absence of synchronization
> > actions, it is entirely correct and proper to hoist the result of that
> > load into a register, or propagate its value some other way. This is
> > common in many programming language implementations, and is not going
> > to change. It is a very important optimization.

There are countless data sharing APIs that suggest that non-volatile should never be something a user experiences, implicitly.  These APIs have to exist to “fix” problems with non-volatile being a default element of the language operations by explicitly controlling the moment that “volatile” data sharing occurs.  It’s an interesting history of concurrency design/development.   When java was released with just Vector and HashMap, we of course were all unexcited by the fact that there wasn’t ’non-volatile’ storage implementations that would make single user (thread) access fast and efficient.  Java “servers" suffered scaling pain from all kinds of things not “finished”.
 
Why would a user write conditional logic, intending that the control be with a non-volatile value?  A warning to the user on compilation would be the most helpful thing that could occur.  But we don’t have that to help people understand that their software logic is not being executed as expected.

I completely understand that this is now history, unfortunately.   But I still feel that this single thing about the Java language provides one of the most fragile elements of multi-threaded application behavior because it happens implicitly.

Gregg Wonderly

> > 
> > -- 
> > Andrew Haley  (he/him)
> > Java Platform Lead Engineer
> > Red Hat UK Ltd. <https://www.redhat.com>
> > https://keybase.io/andrewhaley
> > EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Valentin Kovalenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 19:01
To: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>

Hi Gregg,

> There is no explicit indication of Thread usage

There is only one explanation I can think of with regard to how the code in the listener added via `addActionListener` can be run: by a `java.lang.Thread` different from the one running `main` and blocked in `open` (this statement remains true even if one thinks about the project Loom). If an engineer writing the code like that does not even question himself about how can this application in principle be run in a single thread (that's the assumption in the example), then eliminating some optimizations that clearly do not violate JMM helps nothing. That same engineer can then pass between threads not a single `boolean`, but a more complex piece of data the same way with the same assumption (that there is only one thread), and be surprised to the same extent to observe not the piece of data that was shared. In fact, I think that the more often incorrectly synchronized code fails, the more likely it is that the author will discover and fix the bug, potentially improving his understanding along the way.

Regards,
Valentin www.kovalenko.link



    Message: 4
    Date: Mon, 19 Jul 2021 09:17:05 -0500
    From: Gregg Wonderly <gergg@cox.net>
    To: Alex Otenko <oleksandr.otenko@gmail.com>
    Cc: concurrency-interest <concurrency-interest@cs.oswego.edu>
    Subject: Re: [concurrency-interest] Are there real use cases with the
            Java access modes?
    Message-ID: <A527F64F-4F4E-4A91-9B34-C63D15AF71FD@cox.net>
    Content-Type: text/plain; charset="utf-8"

    Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.

    Gregg Wonderly

    import java.awt.*;
    import java.awt.event.*;
    import javax.swing.*;
    import javax.swing.event.*;
    import java.util.logging.*;

    public class Example2 extends JFrame {

            JTextField tm;
            JButton btn;
            boolean done;
            public static void main( String args[] ) {
                    new Example2(args).open();
                    System.exit(0);
            }

            public Example2(String args[] ) {
                    JPanel p = new JPanel();
                    p.setLayout( new FlowLayout() );
                    p.add( btn = new JButton("Press to Exit") );
                    p.add( tm = new JTextField(20) );
                    this.add(p);
                    btn.addActionListener( new ActionListener() {
                            public void actionPerformed( ActionEvent ev ) {
                                    Logger.getLogger(Example2.class.getName()).info("done...");
                                    done = true;
                            }
                    });
                    done = false;
            }

            public void open() {
                    pack();
                    setLocationRelativeTo(null);
                    setVisible(true);

                    // Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
                    while( !done ) {
                            tm.setText(""+new java.util.Date() );
                            try {
                                    Thread.sleep(500);
                            } catch( Exception ex ) {
                                    Logger.getLogger(Example2.class.getName())
                                            .log( Level.SEVERE, ex.getMessage(), ex );
                            }
                    }
            }
    }


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol 196, Issue 11
From: J E via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 19:32
To: concurrency-interest@cs.oswego.edu
Reply-To: J E <jellisnwb@yahoo.com>

Fuuuuuccccccckkkk offfffffff



> > On Jul 19, 2021, at 12:02, concurrency-interest-request@cs.oswego.edu wrote:
> > 
> > ﻿Send Concurrency-interest mailing list submissions to
> >    concurrency-interest@cs.oswego.edu
> > 
> > To subscribe or unsubscribe via the World Wide Web, visit
> >    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > or, via email, send a message with subject or body 'help' to
> >    concurrency-interest-request@cs.oswego.edu
> > 
> > You can reach the person managing the list at
> >    concurrency-interest-owner@cs.oswego.edu
> > 
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of Concurrency-interest digest..."
> > 
> > 
> > Today's Topics:
> > 
> >   1. Re: Are there real use cases with the Java access modes?
> >      (Andrew Haley)
> >   2. Re: Are there real use cases with the Java access modes?
> >      (Viktor Klang)
> >   3. Re: Are there real use cases with the Java access modes?
> >      (Gregg Wonderly)
> > 
> > 
> > ----------------------------------------------------------------------
> > 
> > Message: 1
> > Date: Mon, 19 Jul 2021 15:25:25 +0100
> > From: Andrew Haley <aph@redhat.com>
> > To: concurrency-interest@cs.oswego.edu
> > Subject: Re: [concurrency-interest] Are there real use cases with the
> >    Java access modes?
> > Message-ID: <b01c7e61-4c82-dc4a-d827-9aa11aa51b2e@redhat.com>
> > Content-Type: text/plain; charset=utf-8
> > 
>> >> On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
>> >> I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.
> > 
> > That single optimization is no more than hoisting a memory load. It's
> > one of the most common optimizations there is. It probably happens
> > many times in every moderately complex method. It's not some kind of
> > weird "let's turn this into an infinite loop" optimization.
> > 
> > For every non-volatile field load, in the absence of synchronization
> > actions, it is entirely correct and proper to hoist the result of that
> > load into a register, or propagate its value some other way. This is
> > common in many programming language implementations, and is not going
> > to change. It is a very important optimization.
> > 
> > -- 
> > Andrew Haley  (he/him)
> > Java Platform Lead Engineer
> > Red Hat UK Ltd. <https://www.redhat.com>
> > https://keybase.io/andrewhaley
> > EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> > 
> > 
> > 
> > ------------------------------
> > 
> > Message: 2
> > Date: Mon, 19 Jul 2021 17:14:50 +0200
> > From: Viktor Klang <viktor.klang@gmail.com>
> > To: concurrency-interest <concurrency-interest@cs.oswego.edu>
> > Subject: Re: [concurrency-interest] Are there real use cases with the
> >    Java access modes?
> > Message-ID:
> >    <CANPzfU9JA-A38RnpwjDOgBsNhqOn=LfBCX3h4EPtxKZmo4LkFQ@mail.gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> > 
> > In my experience,
> > once developers are offered dedicated APIs for thread-safe communication
> > and concurrency, many of the issues we're talking about here sort of
> > disappear. After 12+ years of experience of both developing, maintaining,
> > and observing users use things like Akka Actors, visibility/reording issues
> > tend to be a non-problem—as the concurrency model itself handles the safe
> > publication, and the access to state is never done in parallel.
> > What remains is instead having to think about protocols—in the sense of
> > communication patterns.
> > 
> > An application developer should, in my current view of the world, not ever
> > have to deal with things such as Atomic*, s.m.Unsafe, volatile, etc.
> > Not only because they are difficult to *prove that their use is 100%
> > correct*, but also because they are completely, 100%, unrelated to writing
> > application logic.
> > 
> > So ideally (IMO) such tools should be reserved for JDK & library writers,
> > to be able to offer constructs to developers where they no longer need to
> > worry about correctness-in-the-face-of-parallelism. It is also a situation
> > where more experience and knowledge is to be expected of the developer-user.
> > 
> > Long rant, and I realize that everything above is a bit of a "yes that
> > would be nice but it's not realistic".
> > 
> > And I second the opinion that even if "dangerous" optimizations would be
> > turned off by default, if those optimizations would lead to significant
> > performance benefits (they will), they'd become de-facto defaults,
> > eseentially turning the entire exercise into a bit of a moot point.
> > 
> > On Mon, Jul 19, 2021 at 4:26 PM Andrew Haley via Concurrency-interest <
> > concurrency-interest@cs.oswego.edu> wrote:
> > 
>>> >>> On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
>>> >>> I am specifically against the single optimization I illustrated that
>> >> rewrites code to be non-logically executed, without the user being aware of
>> >> this happening and not being warned that an optimization has potentially
>> >> made the logic of the application not work as expected.
>> >> 
>> >> That single optimization is no more than hoisting a memory load. It's
>> >> one of the most common optimizations there is. It probably happens
>> >> many times in every moderately complex method. It's not some kind of
>> >> weird "let's turn this into an infinite loop" optimization.
>> >> 
>> >> For every non-volatile field load, in the absence of synchronization
>> >> actions, it is entirely correct and proper to hoist the result of that
>> >> load into a register, or propagate its value some other way. This is
>> >> common in many programming language implementations, and is not going
>> >> to change. It is a very important optimization.
>> >> 
>> >> --
>> >> Andrew Haley  (he/him)
>> >> Java Platform Lead Engineer
>> >> Red Hat UK Ltd. <https://www.redhat.com>
>> >> https://keybase.io/andrewhaley
>> >> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
>> >> 
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest@cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> 
> > 
> > 
> > -- 
> > Cheers,
> > √
> > -------------- next part --------------
> > An HTML attachment was scrubbed...
> > URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20210719/989f8ca3/attachment-0001.htm>
> > 
> > ------------------------------
> > 
> > Message: 3
> > Date: Mon, 19 Jul 2021 10:43:29 -0500
> > From: Gregg Wonderly <gergg@cox.net>
> > To: Andrew Haley <aph@redhat.com>
> > Cc: concurrency-interest@cs.oswego.edu
> > Subject: Re: [concurrency-interest] Are there real use cases with the
> >    Java access modes?
> > Message-ID: <08E72E0A-9FBF-4660-A203-8BD838D97DE1@cox.net>
> > Content-Type: text/plain;    charset=utf-8
> > 
> > 
> > 
>> >> On Jul 19, 2021, at 9:25 AM, Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>> >> 
>> >> On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
>>> >>> I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.
>> >> 
>> >> That single optimization is no more than hoisting a memory load. It's
>> >> one of the most common optimizations there is. It probably happens
>> >> many times in every moderately complex method. It's not some kind of
>> >> weird "let's turn this into an infinite loop" optimization.
> > 
> > Because it's in logic control code, it becomes quite visible as “unknown” behavior that the explicit code elements don’t illustrate, in any way, as the desired behavior.  If volatile was the default, and the user had to instead declare non-volatile desires with @nonvolatile or some other declaration (no new keywords is a problem), then this optimization would be documented by the code structure and keyword/feature use.  I get that no-one really wants to be faced with this, yet, when the JMM was released, everyone was faced with it.
> > 
>> >> For every non-volatile field load, in the absence of synchronization
>> >> actions, it is entirely correct and proper to hoist the result of that
>> >> load into a register, or propagate its value some other way. This is
>> >> common in many programming language implementations, and is not going
>> >> to change. It is a very important optimization.
> > 
> > There are countless data sharing APIs that suggest that non-volatile should never be something a user experiences, implicitly.  These APIs have to exist to “fix” problems with non-volatile being a default element of the language operations by explicitly controlling the moment that “volatile” data sharing occurs.  It’s an interesting history of concurrency design/development.   When java was released with just Vector and HashMap, we of course were all unexcited by the fact that there wasn’t ’non-volatile’ storage implementations that would make single user (thread) access fast and efficient.  Java “servers" suffered scaling pain from all kinds of things not “finished”.
> > 
> > Why would a user write conditional logic, intending that the control be with a non-volatile value?  A warning to the user on compilation would be the most helpful thing that could occur.  But we don’t have that to help people understand that their software logic is not being executed as expected.
> > 
> > I completely understand that this is now history, unfortunately.   But I still feel that this single thing about the Java language provides one of the most fragile elements of multi-threaded application behavior because it happens implicitly.
> > 
> > Gregg Wonderly
> > 
>> >> 
>> >> -- 
>> >> Andrew Haley  (he/him)
>> >> Java Platform Lead Engineer
>> >> Red Hat UK Ltd. <https://www.redhat.com>
>> >> https://keybase.io/andrewhaley
>> >> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
>> >> 
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest@cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > 
> > 
> > 
> > ------------------------------
> > 
> > Subject: Digest Footer
> > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > 
> > 
> > ------------------------------
> > 
> > End of Concurrency-interest Digest, Vol 196, Issue 11
> > *****************************************************

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: SHUYANG LIU via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 19:34
To: Benjamin Manes <ben.manes@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: SHUYANG LIU <sliu44@cs.ucla.edu>

Thank you! I’ll take a look at them.

Best,
Shuyang

On Mon, Jul 19, 2021 at 12:57 AM Benjamin Manes <ben.manes@gmail.com> wrote:

    Another avenue to explore are usages of the older Unsafe's putOrdered and Atomic's delegate of lazySet. While these were introduced in JDK5, the naming and meaning was confusing and are not widely used. It is now explicitly acquire/release ordering in JDK9. JCTools is a good example of such usages.

    When reviewing Caffeine, there are more cases that I had forgotten about which use weaker ordering, such as when populating an element in an MPSC ring buffer. Similarly, it seems that LMAX disruptor is also using acquire/release for its ring buffer logic.

    On Sat, Jul 17, 2021 at 4:50 PM Shuyang Liu <sliu44@cs.ucla.edu> wrote:

        Thank you for the detailed explanation! I'll take a look at the code in Caffine.

        > There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.
        This is why we are asking for help here :) We couldn't find many interesting use cases after a basic search. Your example is a good one. I'll look into how JDK uses it.

        Best,
        Shuyang

        From: "Benjamin Manes" <ben.manes@gmail.com>
        To: "Shuyang Liu" <sliu44@cs.ucla.edu>
        Cc: "concurrency-interest" <concurrency-interest@cs.oswego.edu>
        Sent: Saturday, July 17, 2021 3:18:22 PM
        Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?

        There is one usage of acquire / release in Caffeine for a weak / soft values cache. It looks something like the below snippet. It has the following characteristics:

        1. During construction, a plain set is used as the entry is not yet visible to other threads. That can piggyback on the lock release.
        2. Reading the value can usually use a plain read to piggyback on the map's volatile read of the entry, of which this class is the entry's value object.
        3. When the referent is null, it may either be due to the garbage collector or a cache.put(k,v) setting a new reference and nulling out the old one. An acquire is used to check for a stale read.
        4. When writing, a release is used to ensure that clearing the reference is ordered after the value is set. This way an intermediate null is not read due to a compiler reordering.

        In general, though, most developers would prefer to use stronger orderings than necessary as simpler to reason about with equivalent performance. There probably are not many valid use-cases outside of the JDK, and all others (including below) should probably be considered suspect.

        ----

        static final VarHandle VALUE;

        Node(Object keyReference, V value, ReferenceQueue<V> referenceQueue) {
          VALUE.set(this, new WeakValueReference<V>(keyReference, value, referenceQueue));
        }

        public final V getValue() {
          for (;;) {
            Reference<V> ref = (Reference<V>) VALUE.get(this);
            V referent = ref.get();
            if ((referent != null) || (ref == VALUE.getAcquire(this))) {
              return referent;
            }
          }
        }

        public final void setValue(V value, ReferenceQueue<V> referenceQueue) {
          Reference<V> ref = (Reference<V>) VALUE.get(this);
          VALUE.setRelease(this, new WeakValueReference<V>(getKeyReference(), value, referenceQueue));
          ref.clear();
        }
         

        On Sat, Jul 17, 2021 at 1:32 PM Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

            Hello,

            My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 

            Thanks you,
            Shuyang Liu

            [1]. Using JDK 9 Memory Order Modes  
            http://gee.cs.oswego.edu/dl/html/j9mm.html
            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 19:55
To: Andrew Haley <aph@redhat.com>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

Program Mistake Detector (PMD) is an awesome tool for finding many mistakes.  It can be easily improved with new rules.  There are other similar tools out there as well but I am not sure of their capabilities.

Consider this simple case...

private boolean m_quit;   // not volatile

while (!m_quit)
{
   // do some things
}

If the loop body does not modify m_quit, then we can write a PMD rule to flag this as an unintended infinite loop (i.e. a mistake).  If the while loop has no method calls, then this simple case can be done with a very simple PMD rule.  If the while loop calls other methods, then the PMD rule will need to explore the call tree to see if m_quit is modified.  This will be more complex to write.

With such a rule in place, when a programmer writes an unintended infinite loop, then PMD will flag the problem.  The programmer can then fix the problem and the bug will only exist for a few minutes on the programmer's machine.

With such a simple solution (e.g. create a PMD rule), I would rather improve linters to catch programmer's mistakes than make a change to Java that could hurt performance.

On Mon, Jul 19, 2021 at 8:26 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    On 7/19/21 3:06 PM, Gregg Wonderly via Concurrency-interest wrote:
    > I am specifically against the single optimization I illustrated that rewrites code to be non-logically executed, without the user being aware of this happening and not being warned that an optimization has potentially made the logic of the application not work as expected.

    That single optimization is no more than hoisting a memory load. It's
    one of the most common optimizations there is. It probably happens
    many times in every moderately complex method. It's not some kind of
    weird "let's turn this into an infinite loop" optimization.

    For every non-volatile field load, in the absence of synchronization
    actions, it is entirely correct and proper to hoist the result of that
    load into a register, or propagate its value some other way. This is
    common in many programming language implementations, and is not going
    to change. It is a very important optimization.

    -- 
    Andrew Haley  (he/him)
    Java Platform Lead Engineer
    Red Hat UK Ltd. <https://www.redhat.com>
    https://keybase.io/andrewhaley
    EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-19, 21:25
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Does this even get hoisted? setText in the loop is thread safe, and the mutation goes through a lock, so no level of inlining should be able to allow the elimination of the read that you are concerned about. (And certainly no one hoists the read without proving the absence of volatile loads in the loop body)

Alex

On Mon, 19 Jul 2021, 15:17 Gregg Wonderly, <gergg@cox.net> wrote:

    Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.

    Gregg Wonderly

    import java.awt.*;
    import java.awt.event.*;
    import javax.swing.*;
    import javax.swing.event.*;
    import java.util.logging.*;

    public class Example2 extends JFrame {

            JTextField tm;
            JButton btn;
            boolean done;
            public static void main( String args[] ) {
                    new Example2(args).open();
                    System.exit(0);
            }

            public Example2(String args[] ) {
                    JPanel p = new JPanel();
                    p.setLayout( new FlowLayout() );
                    p.add( btn = new JButton("Press to Exit") );
                    p.add( tm = new JTextField(20) );
                    this.add(p);
                    btn.addActionListener( new ActionListener() {
                            public void actionPerformed( ActionEvent ev ) {
                                    Logger.getLogger(Example2.class.getName()).info("done...");
                                    done = true;
                            }
                    });
                    done = false;
            }

            public void open() {
                    pack();
                    setLocationRelativeTo(null);
                    setVisible(true);

    // Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
                    while( !done ) {
                            tm.setText(""+new java.util.Date() );
                            try {
                                    Thread.sleep(500);
                            } catch( Exception ex ) {
                                    Logger.getLogger(Example2.class.getName())
                                            .log( Level.SEVERE, ex.getMessage(), ex );
                            }
                    }
            }
    }

>     On Jul 19, 2021, at 2:40 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     I think a piece of code would move this discussion from handwaving to something concrete. If there is some interaction with AWT, the variable you complain about cannot be hoisted. If there is no interaction, then the complaint reduces from "perfectly good code is perfectly broken" to "perfectly broken code is perfectly broken".
>
>     Without an example everyone is left guessing why anyone would attempt to use a debugger to diagnose a race condition. 
>
>     Alex
>
>     On Mon, 19 Jul 2021, 03:32 Gregg Wonderly, <gergg@cox.net> wrote:
>
>         You are misunderstanding my assertion.  I am only stating that the code is changed from could work under some circumstances, to unexplainably never working.  In other words, a debugger would make non volatile code work, because all of its code running, would cause processor instructions that would likely make cache line isolation impossible to experience.
>
>         This then becomes documentable side effects of data races.  But realistically, as Brian stated, any mult-threaded behaviors in desktop apps are not very obvious, and data races are often not experienced because of how the app thread and the awt event queue interact.
>
>         Gregg
>
>         Sent from my iPhone
>
>>         On Jul 18, 2021, at 6:09 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>         ﻿
>>         I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.
>>
>>         I'd like to see such code.
>>
>>         Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.
>>
>>         Alex
>>
>>         On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:
>>
>>             Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>>
>>             Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>>
>>             Gregg Wonderly
>>
>>             Sent from my iPhone
>>
>>>             On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>>
>>>             ﻿
>>>             The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>>
>>>             And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>>
>>>             There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>>
>>>             Alex
>>>
>>>             On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>>                 Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>>>
>>>                 While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>>>
>>>                 The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>>>
>>>                 Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>>>
>>>                 Gregg Wonderly
>>>
>>>                 Sent from my iPhone
>>>
>>>>                 On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>>>
>>>>                 ﻿Thanks you!
>>>>
>>>>                  I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>>>
>>>>                 Best Regards,
>>>>                 Shuyang
>>>>
>>>>>                 On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>>>
>>>>>                 ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>>>
>>>>>                 while( nonVolatileRefExpr ) {}
>>>>>
>>>>>                 Into 
>>>>>
>>>>>                 if( nonVolatileRefExpr ) { while( true ) {} }
>>>>>
>>>>>                 Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>>>
>>>>>                 Gregg Wonderly
>>>>>
>>>>>                 Sent from my iPhone
>>>>>
>>>>>>                 On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>>>
>>>>>>                 ﻿
>>>>>>                 Hello,
>>>>>>
>>>>>>                 My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>>>
>>>>>>                 Thanks you,
>>>>>>                 Shuyang Liu
>>>>>>
>>>>>>                 [1]. Using JDK 9 Memory Order Modes  
>>>>>>                 http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>>                 _______________________________________________
>>>>>>                 Concurrency-interest mailing list
>>>>>>                 Concurrency-interest@cs.oswego.edu
>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>                 _______________________________________________
>>>                 Concurrency-interest mailing list
>>>                 Concurrency-interest@cs.oswego.edu
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest@cs.oswego.edu
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 00:39
To: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.

I think my perspective may be something I assume everyone sees too.   In the 1990s, as Java rolled out and Mosaic “was” the web browser, we had “HTML authors” deployed en-masse to construct the web.  There were all the “software engineers” trying to solve the web server problems and create J2EE and lots of server side things by real software systems engineers.  Yet, 90% of people creating the web, were HTML authors, or later because Javascript codes (because Java was too big for the 32mb-128mb client/desktop PCs where applets where being attempted, but which couldn’t survive because they caused HUGE paging loads on under equipped PCs.   Later, these coders learned all kinds things like PHP, and 10’s if not 100’s of JavaScript platforms and libraries to do things on their HTML pages.

Then, there's the hobbiests that do technical things with small bits of software that they get from other people.  They try to “add” stuff, and “fix” stuff and contribute to all kinds of small communities of people using little Java desktop applications to facilitate portability to multiple computer platforms because many have PCs, some have Macs and some have Linux machines, and they want to all be able to do the same things, like use their home automation or other simple uProcessor control things etc.  These people have no idea how processors work in many cases.  They know nothing about caches, coherency, fences, etc.  Threads are something they’ve probably heard about, but they think of those as “server” things that make it possible to do a lot of things at once.   They are trying to create applications that don’t have “busy” things to do.  They write loops, like I did here, that just use timers, because some of them used to write MSDOS code with such timing loops for animations etc.  It’s this type of person that I am trying to highlight here.

I participate in several different technical communities like Amateur Radio where I’ve wanted to get the community to adopt Java as the preferred platform for lots of desktop application things.  I’ve written and shared lots of “jar-based” apps that would help people do interesting things in such communities.  But, the uptake has just been a huge hill, because Java is just too hard for them to comprehend all the details to get started.  There’s lots of details and things that I don’t really want to inject into this conversation.  But, I just want to point out that there are things like this particular issue, which “break” code by default.

Just 20mins ago I was having a discussion with a fairly new developer who had some questions about creating a “timing” class that would let him observe a count of operations over time, and then use the starting and ending time to show a “bandwidth” figure.  We talked about volatile and sharing related to the class fields and whether he should leave them non-volatile, use volatile or atomic references, synchronized methods etc.  And then he went right to another recent problem he had solved where this EXACT example had been encountered.  This was not in a desktop app but a Kafka based server app.  He had spent some period of time to workout that he need to make the boolean volatile to get the callback that changed the value of the boolean to be observed by the thread using the boolean for the loop control.

I still contend this is a surprise to many people.  They probably figure it out if they don’t have a choice to “move on” from solving the problem.  And once they figure out the volatile declaration, they have a keyword to look up and read about etc.  The default behavior of not having a designation for the default non-volatile “hoist” is really a problematic implicit behavior that is not the first thought process for many in my experience.  It’s the choice to “move on” that I feel drives people away from Java in some cases, because they really don’t now how to search for this problem because it’s by default.  There are lots of examples of “my loop doesn’t exit” for lots of other languages for countless reasons.  But not really anything on places like stackoverflow.com unless you know to include volatile and java.  Then you see this example:

https://stackoverflow.com/questions/55322624/why-is-this-code-not-going-into-an-infinite-loop-as-suggested-by-jsr133

which illustrates that the hoist starts happening if there are no call outs in the loop that the compiler can’t trace completely through, then the hoist doesn’t happen.  It’s this irregular behavior that just adds further to the frustration.

Gregg Wonderly

> On Jul 19, 2021, at 11:01 AM, Valentin Kovalenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> Hi Gregg,
>
> > There is no explicit indication of Thread usage
>
> There is only one explanation I can think of with regard to how the code in the listener added via `addActionListener` can be run: by a `java.lang.Thread` different from the one running `main` and blocked in `open` (this statement remains true even if one thinks about the project Loom). If an engineer writing the code like that does not even question himself about how can this application in principle be run in a single thread (that's the assumption in the example), then eliminating some optimizations that clearly do not violate JMM helps nothing. That same engineer can then pass between threads not a single `boolean`, but a more complex piece of data the same way with the same assumption (that there is only one thread), and be surprised to the same extent to observe not the piece of data that was shared. In fact, I think that the more often incorrectly synchronized code fails, the more likely it is that the author will discover and fix the bug, potentially improving his understanding along the way.
>
> Regards,
> Valentin www.kovalenko.link
>
>
>
>     Message: 4
>     Date: Mon, 19 Jul 2021 09:17:05 -0500
>     From: Gregg Wonderly <gergg@cox.net>
>     To: Alex Otenko <oleksandr.otenko@gmail.com>
>     Cc: concurrency-interest <concurrency-interest@cs.oswego.edu>
>     Subject: Re: [concurrency-interest] Are there real use cases with the
>             Java access modes?
>     Message-ID: <A527F64F-4F4E-4A91-9B34-C63D15AF71FD@cox.net>
>     Content-Type: text/plain; charset="utf-8"
>
>     Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.
>
>     Gregg Wonderly
>
>     import java.awt.*;
>     import java.awt.event.*;
>     import javax.swing.*;
>     import javax.swing.event.*;
>     import java.util.logging.*;
>
>     public class Example2 extends JFrame {
>
>             JTextField tm;
>             JButton btn;
>             boolean done;
>             public static void main( String args[] ) {
>                     new Example2(args).open();
>                     System.exit(0);
>             }
>
>             public Example2(String args[] ) {
>                     JPanel p = new JPanel();
>                     p.setLayout( new FlowLayout() );
>                     p.add( btn = new JButton("Press to Exit") );
>                     p.add( tm = new JTextField(20) );
>                     this.add(p);
>                     btn.addActionListener( new ActionListener() {
>                             public void actionPerformed( ActionEvent ev ) {
>                                     Logger.getLogger(Example2.class.getName()).info("done...");
>                                     done = true;
>                             }
>                     });
>                     done = false;
>             }
>
>             public void open() {
>                     pack();
>                     setLocationRelativeTo(null);
>                     setVisible(true);
>
>                     // Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
>                     while( !done ) {
>                             tm.setText(""+new java.util.Date() );
>                             try {
>                                     Thread.sleep(500);
>                             } catch( Exception ex ) {
>                                     Logger.getLogger(Example2.class.getName())
>                                             .log( Level.SEVERE, ex.getMessage(), ex );
>                             }
>                     }
>             }
>     }
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 00:41
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

With the logging in there, it’s not happening, because then the compiler can’t determine what the end state is, so it doesn’t hoist the read.   But, if there are no such things happening, then it’s going to hoist it.  Those subtle “conditions” of the hoist make it even more frustrating, because you can sprinkle in logging like this and see it work, but then take the stuff back out and it stops working…

Gregg Wonderly

> On Jul 19, 2021, at 1:25 PM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
> Does this even get hoisted? setText in the loop is thread safe, and the mutation goes through a lock, so no level of inlining should be able to allow the elimination of the read that you are concerned about. (And certainly no one hoists the read without proving the absence of volatile loads in the loop body)
>
> Alex
>
> On Mon, 19 Jul 2021, 15:17 Gregg Wonderly, <gergg@cox.net> wrote:
>
>     Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.
>
>     Gregg Wonderly
>
>     import java.awt.*;
>     import java.awt.event.*;
>     import javax.swing.*;
>     import javax.swing.event.*;
>     import java.util.logging.*;
>
>     public class Example2 extends JFrame {
>
>             JTextField tm;
>             JButton btn;
>             boolean done;
>             public static void main( String args[] ) {
>                     new Example2(args).open();
>                     System.exit(0);
>             }
>
>             public Example2(String args[] ) {
>                     JPanel p = new JPanel();
>                     p.setLayout( new FlowLayout() );
>                     p.add( btn = new JButton("Press to Exit") );
>                     p.add( tm = new JTextField(20) );
>                     this.add(p);
>                     btn.addActionListener( new ActionListener() {
>                             public void actionPerformed( ActionEvent ev ) {
>                                     Logger.getLogger(Example2.class.getName()).info("done...");
>                                     done = true;
>                             }
>                     });
>                     done = false;
>             }
>
>             public void open() {
>                     pack();
>                     setLocationRelativeTo(null);
>                     setVisible(true);
>
>     // Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
>                     while( !done ) {
>                             tm.setText(""+new java.util.Date() );
>                             try {
>                                     Thread.sleep(500);
>                             } catch( Exception ex ) {
>                                     Logger.getLogger(Example2.class.getName())
>                                             .log( Level.SEVERE, ex.getMessage(), ex );
>                             }
>                     }
>             }
>     }
>
>>     On Jul 19, 2021, at 2:40 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>     I think a piece of code would move this discussion from handwaving to something concrete. If there is some interaction with AWT, the variable you complain about cannot be hoisted. If there is no interaction, then the complaint reduces from "perfectly good code is perfectly broken" to "perfectly broken code is perfectly broken".
>>
>>     Without an example everyone is left guessing why anyone would attempt to use a debugger to diagnose a race condition. 
>>
>>     Alex
>>
>>     On Mon, 19 Jul 2021, 03:32 Gregg Wonderly, <gergg@cox.net> wrote:
>>
>>         You are misunderstanding my assertion.  I am only stating that the code is changed from could work under some circumstances, to unexplainably never working.  In other words, a debugger would make non volatile code work, because all of its code running, would cause processor instructions that would likely make cache line isolation impossible to experience.
>>
>>         This then becomes documentable side effects of data races.  But realistically, as Brian stated, any mult-threaded behaviors in desktop apps are not very obvious, and data races are often not experienced because of how the app thread and the awt event queue interact.
>>
>>         Gregg
>>
>>         Sent from my iPhone
>>
>>>         On Jul 18, 2021, at 6:09 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>>         ﻿
>>>         I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.
>>>
>>>         I'd like to see such code.
>>>
>>>         Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.
>>>
>>>         Alex
>>>
>>>         On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:
>>>
>>>             Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>>>
>>>             Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>>>
>>>             Gregg Wonderly
>>>
>>>             Sent from my iPhone
>>>
>>>>             On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>>>
>>>>             ﻿
>>>>             The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>>>
>>>>             And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>>>
>>>>             There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>>>
>>>>             Alex
>>>>
>>>>             On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>>>>
>>>>                 Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>>>>
>>>>                 While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>>>>
>>>>                 The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>>>>
>>>>                 Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>>>>
>>>>                 Gregg Wonderly
>>>>
>>>>                 Sent from my iPhone
>>>>
>>>>>                 On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>>>>
>>>>>                 ﻿Thanks you!
>>>>>
>>>>>                  I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>>>>
>>>>>                 Best Regards,
>>>>>                 Shuyang
>>>>>
>>>>>>                 On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>>>>
>>>>>>                 ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>>>>
>>>>>>                 while( nonVolatileRefExpr ) {}
>>>>>>
>>>>>>                 Into 
>>>>>>
>>>>>>                 if( nonVolatileRefExpr ) { while( true ) {} }
>>>>>>
>>>>>>                 Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>>>>
>>>>>>                 Gregg Wonderly
>>>>>>
>>>>>>                 Sent from my iPhone
>>>>>>
>>>>>>>                 On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>>>>
>>>>>>>                 ﻿
>>>>>>>                 Hello,
>>>>>>>
>>>>>>>                 My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>>>>
>>>>>>>                 Thanks you,
>>>>>>>                 Shuyang Liu
>>>>>>>
>>>>>>>                 [1]. Using JDK 9 Memory Order Modes  
>>>>>>>                 http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>>>                 _______________________________________________
>>>>>>>                 Concurrency-interest mailing list
>>>>>>>                 Concurrency-interest@cs.oswego.edu
>>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>                 _______________________________________________
>>>>                 Concurrency-interest mailing list
>>>>                 Concurrency-interest@cs.oswego.edu
>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest@cs.oswego.edu
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest@cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 11:49
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Well, no. Your claim was that the thread may interact with AWT, and still get the loop variable hoisted. You did not show an example of that happening.


Alex

On Mon, 19 Jul 2021, 22:41 Gregg Wonderly, <gergg@cox.net> wrote:

    With the logging in there, it’s not happening, because then the compiler can’t determine what the end state is, so it doesn’t hoist the read.   But, if there are no such things happening, then it’s going to hoist it.  Those subtle “conditions” of the hoist make it even more frustrating, because you can sprinkle in logging like this and see it work, but then take the stuff back out and it stops working…

    Gregg Wonderly

>     On Jul 19, 2021, at 1:25 PM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
>     Does this even get hoisted? setText in the loop is thread safe, and the mutation goes through a lock, so no level of inlining should be able to allow the elimination of the read that you are concerned about. (And certainly no one hoists the read without proving the absence of volatile loads in the loop body)
>
>     Alex
>
>     On Mon, 19 Jul 2021, 15:17 Gregg Wonderly, <gergg@cox.net> wrote:
>
>         Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.
>
>         Gregg Wonderly
>
>         import java.awt.*;
>         import java.awt.event.*;
>         import javax.swing.*;
>         import javax.swing.event.*;
>         import java.util.logging.*;
>
>         public class Example2 extends JFrame {
>
>                 JTextField tm;
>                 JButton btn;
>                 boolean done;
>                 public static void main( String args[] ) {
>                         new Example2(args).open();
>                         System.exit(0);
>                 }
>
>                 public Example2(String args[] ) {
>                         JPanel p = new JPanel();
>                         p.setLayout( new FlowLayout() );
>                         p.add( btn = new JButton("Press to Exit") );
>                         p.add( tm = new JTextField(20) );
>                         this.add(p);
>                         btn.addActionListener( new ActionListener() {
>                                 public void actionPerformed( ActionEvent ev ) {
>                                         Logger.getLogger(Example2.class.getName()).info("done...");
>                                         done = true;
>                                 }
>                         });
>                         done = false;
>                 }
>
>                 public void open() {
>                         pack();
>                         setLocationRelativeTo(null);
>                         setVisible(true);
>
>         // Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
>                         while( !done ) {
>                                 tm.setText(""+new java.util.Date() );
>                                 try {
>                                         Thread.sleep(500);
>                                 } catch( Exception ex ) {
>                                         Logger.getLogger(Example2.class.getName())
>                                                 .log( Level.SEVERE, ex.getMessage(), ex );
>                                 }
>                         }
>                 }
>         }
>
>>         On Jul 19, 2021, at 2:40 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>         I think a piece of code would move this discussion from handwaving to something concrete. If there is some interaction with AWT, the variable you complain about cannot be hoisted. If there is no interaction, then the complaint reduces from "perfectly good code is perfectly broken" to "perfectly broken code is perfectly broken".
>>
>>         Without an example everyone is left guessing why anyone would attempt to use a debugger to diagnose a race condition. 
>>
>>         Alex
>>
>>         On Mon, 19 Jul 2021, 03:32 Gregg Wonderly, <gergg@cox.net> wrote:
>>
>>             You are misunderstanding my assertion.  I am only stating that the code is changed from could work under some circumstances, to unexplainably never working.  In other words, a debugger would make non volatile code work, because all of its code running, would cause processor instructions that would likely make cache line isolation impossible to experience.
>>
>>             This then becomes documentable side effects of data races.  But realistically, as Brian stated, any mult-threaded behaviors in desktop apps are not very obvious, and data races are often not experienced because of how the app thread and the awt event queue interact.
>>
>>             Gregg
>>
>>             Sent from my iPhone
>>
>>>             On Jul 18, 2021, at 6:09 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>>             ﻿
>>>             I think it is a worthwhile challenge to claim that there is real code that is free from races, if only all the variables were volatile.
>>>
>>>             I'd like to see such code.
>>>
>>>             Somehow I doubt that there is a lot of correct code routinely produced without consideration of happens-before and the whole memory model shebang.
>>>
>>>             Alex
>>>
>>>             On Sun, 18 Jul 2021, 18:54 Gregg Wonderly, <gergg@cox.net> wrote:
>>>
>>>                 Good software design always includes the notion of least surprise.  In which other languages are there examples of Volatile or other optimizations that rewrite code to be incorrect based on what the code reads?  There is literally no advantage to this rewrite.  Developers can write this code exactly if they believe it is beneficial to them.  But having it done by default, is a giant surprise and in fact drives people away from Java because this looks like a bug, and the compiler still contains zero warnings about volatile optimizations that may change logic to not be what the code reads.
>>>
>>>                 Literally every single volatile read escape optimization should be issuing warnings to the user that their code will not be executed more than once.  You continue to insist that this is rare code while it is the single most common mechanism for controlling UI actions.  Whether it’s a boolean or an object reference, this optimization is a huge detriment to new developers trying out Java desktop apps.
>>>
>>>                 Gregg Wonderly
>>>
>>>                 Sent from my iPhone
>>>
>>>>                 On Jul 18, 2021, at 2:35 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>>>>
>>>>                 ﻿
>>>>                 The simple truth is that there are more ways to write incorrect code than there are ways to write correct code. Complex state changes cannot be assumed to work correctly, when done concurrently.
>>>>
>>>>                 And the things that count for "complex" - anything beyond a single bit flip 0->1, and never back 1->0, is complex.
>>>>
>>>>                 There is no point in forbidding one optimisation for the sake of one type of system where that's the only problem.
>>>>
>>>>                 Alex
>>>>
>>>>                 On Sun, 18 Jul 2021, 05:13 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>>>>
>>>>                     Yes this was changed at the sane time the JMM defined  and caused implementation of volatile to happen.  
>>>>
>>>>                     While this is legal because of the JMM, it causes broken code to happen without the user really understanding why it could happen and that it will happen.  It’s different in significant ways from cache coherency, and it worked prior to JDK1.5.  I still believe that volatile creates a giant surprise.  This is an optimization behavior that “breaks” code without the user electing to have such an optimization performed!
>>>>
>>>>                     The default variable declaration should be volatile and a different mechanism should be necessary to get non-volatile optimizations to happen.  A user should never, ever, be able to write non-working code using default language constructs.
>>>>
>>>>                     Look at the past examples in C-Language and C++ etc.  Things like Register optimizations and many other constructs required the user to break their code, rather than that being the default behavior!
>>>>
>>>>                     Gregg Wonderly
>>>>
>>>>                     Sent from my iPhone
>>>>
>>>>>                     On Jul 17, 2021, at 5:05 PM, Shuyang Liu <sliu44@cs.ucla.edu> wrote:
>>>>>
>>>>>                     ﻿Thanks you!
>>>>>
>>>>>                      I guess this is before Java 9? So I think “nonVolatileRefExpr” is equivalent to a plain access in this case. The compiler probably identified it as a local access since it is not marked as volatile (then its indeed equivalent to an infinite loop, which makes the transformation valid). Do you know if there’s any applications/bug report with this pattern? 
>>>>>
>>>>>                     Best Regards,
>>>>>                     Shuyang
>>>>>
>>>>>>                     On Jul 17, 2021, at 1:46 PM, Gregg Wonderly <gergg@cox.net> wrote:
>>>>>>
>>>>>>                     ﻿One of the standing problems I have is optimizations around non-volatile value references.  Currently, there are visibility optimizations that turn 
>>>>>>
>>>>>>                     while( nonVolatileRefExpr ) {}
>>>>>>
>>>>>>                     Into 
>>>>>>
>>>>>>                     if( nonVolatileRefExpr ) { while( true ) {} }
>>>>>>
>>>>>>                     Which creates infinite loops.  This makes one of the most common types of applications written in Swing to fail to work as the code is written.
>>>>>>
>>>>>>                     Gregg Wonderly
>>>>>>
>>>>>>                     Sent from my iPhone
>>>>>>
>>>>>>>                     On Jul 17, 2021, at 4:33 PM, Shuyang Liu via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>>>>>
>>>>>>>                     ﻿
>>>>>>>                     Hello,
>>>>>>>
>>>>>>>                     My colleagues and I have been working on a formal model for the Java access modes that is added since Java 9 [1]. Are there any popular use cases of access modes in real world applications/frameworks/libraries? We would like to see how our current formal model works in real examples. 
>>>>>>>
>>>>>>>                     Thanks you,
>>>>>>>                     Shuyang Liu
>>>>>>>
>>>>>>>                     [1]. Using JDK 9 Memory Order Modes  
>>>>>>>                     http://gee.cs.oswego.edu/dl/html/j9mm.html
>>>>>>>                     _______________________________________________
>>>>>>>                     Concurrency-interest mailing list
>>>>>>>                     Concurrency-interest@cs.oswego.edu
>>>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>                     _______________________________________________
>>>>                     Concurrency-interest mailing list
>>>>                     Concurrency-interest@cs.oswego.edu
>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest@cs.oswego.edu
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest@cs.oswego.edu
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 12:46
To: Gregg Wonderly <gergg@cox.net>
CC: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Maybe java is the wrong tool for introducing people to programming. Maybe hobbyists will be fine with Python.

As for the claim about Kafka server app - I find it extraordinary that there be a loop with the thread-safe body that interacts with other threads, and yet experiences the hoisting that you complain about.

I've seen a lot of incorrect double-checked locking, which stems from the same "issue" of having non-volatile by default - and have never seen any impact from that. Which is to say that I find it surprising that you encounter hoisting happening so frequently.

Alex

On Mon, 19 Jul 2021, 22:54 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.

    I think my perspective may be something I assume everyone sees too.   In the 1990s, as Java rolled out and Mosaic “was” the web browser, we had “HTML authors” deployed en-masse to construct the web.  There were all the “software engineers” trying to solve the web server problems and create J2EE and lots of server side things by real software systems engineers.  Yet, 90% of people creating the web, were HTML authors, or later because Javascript codes (because Java was too big for the 32mb-128mb client/desktop PCs where applets where being attempted, but which couldn’t survive because they caused HUGE paging loads on under equipped PCs.   Later, these coders learned all kinds things like PHP, and 10’s if not 100’s of JavaScript platforms and libraries to do things on their HTML pages.

    Then, there's the hobbiests that do technical things with small bits of software that they get from other people.  They try to “add” stuff, and “fix” stuff and contribute to all kinds of small communities of people using little Java desktop applications to facilitate portability to multiple computer platforms because many have PCs, some have Macs and some have Linux machines, and they want to all be able to do the same things, like use their home automation or other simple uProcessor control things etc.  These people have no idea how processors work in many cases.  They know nothing about caches, coherency, fences, etc.  Threads are something they’ve probably heard about, but they think of those as “server” things that make it possible to do a lot of things at once.   They are trying to create applications that don’t have “busy” things to do.  They write loops, like I did here, that just use timers, because some of them used to write MSDOS code with such timing loops for animations etc.  It’s this type of person that I am trying to highlight here.

    I participate in several different technical communities like Amateur Radio where I’ve wanted to get the community to adopt Java as the preferred platform for lots of desktop application things.  I’ve written and shared lots of “jar-based” apps that would help people do interesting things in such communities.  But, the uptake has just been a huge hill, because Java is just too hard for them to comprehend all the details to get started.  There’s lots of details and things that I don’t really want to inject into this conversation.  But, I just want to point out that there are things like this particular issue, which “break” code by default.

    Just 20mins ago I was having a discussion with a fairly new developer who had some questions about creating a “timing” class that would let him observe a count of operations over time, and then use the starting and ending time to show a “bandwidth” figure.  We talked about volatile and sharing related to the class fields and whether he should leave them non-volatile, use volatile or atomic references, synchronized methods etc.  And then he went right to another recent problem he had solved where this EXACT example had been encountered.  This was not in a desktop app but a Kafka based server app.  He had spent some period of time to workout that he need to make the boolean volatile to get the callback that changed the value of the boolean to be observed by the thread using the boolean for the loop control.

    I still contend this is a surprise to many people.  They probably figure it out if they don’t have a choice to “move on” from solving the problem.  And once they figure out the volatile declaration, they have a keyword to look up and read about etc.  The default behavior of not having a designation for the default non-volatile “hoist” is really a problematic implicit behavior that is not the first thought process for many in my experience.  It’s the choice to “move on” that I feel drives people away from Java in some cases, because they really don’t now how to search for this problem because it’s by default.  There are lots of examples of “my loop doesn’t exit” for lots of other languages for countless reasons.  But not really anything on places like stackoverflow.com unless you know to include volatile and java.  Then you see this example:

    https://stackoverflow.com/questions/55322624/why-is-this-code-not-going-into-an-infinite-loop-as-suggested-by-jsr133

    which illustrates that the hoist starts happening if there are no call outs in the loop that the compiler can’t trace completely through, then the hoist doesn’t happen.  It’s this irregular behavior that just adds further to the frustration.

    Gregg Wonderly

>     On Jul 19, 2021, at 11:01 AM, Valentin Kovalenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     Hi Gregg,
>
>     > There is no explicit indication of Thread usage
>
>     There is only one explanation I can think of with regard to how the code in the listener added via `addActionListener` can be run: by a `java.lang.Thread` different from the one running `main` and blocked in `open` (this statement remains true even if one thinks about the project Loom). If an engineer writing the code like that does not even question himself about how can this application in principle be run in a single thread (that's the assumption in the example), then eliminating some optimizations that clearly do not violate JMM helps nothing. That same engineer can then pass between threads not a single `boolean`, but a more complex piece of data the same way with the same assumption (that there is only one thread), and be surprised to the same extent to observe not the piece of data that was shared. In fact, I think that the more often incorrectly synchronized code fails, the more likely it is that the author will discover and fix the bug, potentially improving his understanding along the way.
>
>     Regards,
>     Valentin www.kovalenko.link
>
>
>
>         Message: 4
>         Date: Mon, 19 Jul 2021 09:17:05 -0500
>         From: Gregg Wonderly <gergg@cox.net>
>         To: Alex Otenko <oleksandr.otenko@gmail.com>
>         Cc: concurrency-interest <concurrency-interest@cs.oswego.edu>
>         Subject: Re: [concurrency-interest] Are there real use cases with the
>                 Java access modes?
>         Message-ID: <A527F64F-4F4E-4A91-9B34-C63D15AF71FD@cox.net>
>         Content-Type: text/plain; charset="utf-8"
>
>         Here’s what I’ve repeatedly shown in these conversations in the past.  There is no explicit indication of Thread usage.  This is just a plain and simple swing application that would be the kind of framework that the first Swing application would be written using.  But even some of the things I am doing here are a bit more than what I would expect to see in someones first swing app.
>
>         Gregg Wonderly
>
>         import java.awt.*;
>         import java.awt.event.*;
>         import javax.swing.*;
>         import javax.swing.event.*;
>         import java.util.logging.*;
>
>         public class Example2 extends JFrame {
>
>                 JTextField tm;
>                 JButton btn;
>                 boolean done;
>                 public static void main( String args[] ) {
>                         new Example2(args).open();
>                         System.exit(0);
>                 }
>
>                 public Example2(String args[] ) {
>                         JPanel p = new JPanel();
>                         p.setLayout( new FlowLayout() );
>                         p.add( btn = new JButton("Press to Exit") );
>                         p.add( tm = new JTextField(20) );
>                         this.add(p);
>                         btn.addActionListener( new ActionListener() {
>                                 public void actionPerformed( ActionEvent ev ) {
>                                         Logger.getLogger(Example2.class.getName()).info("done...");
>                                         done = true;
>                                 }
>                         });
>                         done = false;
>                 }
>
>                 public void open() {
>                         pack();
>                         setLocationRelativeTo(null);
>                         setVisible(true);
>
>                         // Does your JVM convert this statement to if( !done ) { while( true ){ ...  } }?
>                         while( !done ) {
>                                 tm.setText(""+new java.util.Date() );
>                                 try {
>                                         Thread.sleep(500);
>                                 } catch( Exception ex ) {
>                                         Logger.getLogger(Example2.class.getName())
>                                                 .log( Level.SEVERE, ex.getMessage(), ex );
>                                 }
>                         }
>                 }
>         }
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 13:41
To: Gregg Wonderly <gergg@cox.net>, Valentin Kovalenko <valentin.male.kovalenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Andrew Dinn <adinn@redhat.com>

On 19/07/2021 22:39, Gregg Wonderly via Concurrency-interest wrote:
> Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.

And I am still trying to assert that we should not hobble the language implementation to cater for that category of 'programmer' (rabbit ears de rigeur). Java has been specified and implemented for use by skilled and knowledgeable professionals. That includes knowing about and having the skill to deal with the presence of multi-threading as a core element of the language, with all its attendant complexities.

Of course, as a Java implementor I make no assumption that all those who use Java will be skilled, knowledgeable professionals. What I do assume is that I don't have to take the concerns or failings of unskilled or ignorant 'would-be' coders into account.

By the way, I believe you are having your cake and eating it in the way you present your arguments here. You cited an example program as simple to understand and behaving as expected until you remove some logging code to simplify it and suddenly ... oh,. how surprising, a non-volatile access gets hoisted! At which point this simple to understand code becomes incomprehensible to the average reader.

In truth, if you know how to read the different versions of this code with an awareness that Java is a multi-threaded language the complexity is never absent. The surprise you describe is prima facie evidence that your posited average reader is not reading the code correctly, whether in the original or reduced version. They just think they understand it.

regards,


Andrew Dinn
-----------
Red Hat Distinguished Engineer
Red Hat UK Ltd
Registered in England and Wales under Company Registration No. 03798903
Directors: Michael Cunningham, Michael ("Mike") O'Neill

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Doug Lea via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 13:42
To: concurrency-interest@cs.oswego.edu
Reply-To: Doug Lea <dl@cs.oswego.edu>

On 7/17/21 6:09 PM, Alex Otenko via Concurrency-interest wrote:
> I think one important case is an atomic increment that does not introduce full barriers (choose opaque, if you are just counting; acquire, if you are acquiring a semaphore; release, when releasing; or rel-acquire). I know of a few like things achievable in other languages, which probably are beneficial on many non-tso architectures.

I agree that there is a case for adding weaker "RMW" methods getAndAddOpaque, getAndSetOpaque, getAndBitwiseAndOpaque, and getAndBitwiseOrOpaque. There are now processors that support this directly, and others can fall back to heavier variants.  And usage can speed up some operations on some processors enough to be worthwhile. I'll look into it.

>
> Another important clarification needed is what barriers are enforced on failure of CAS. I think there was a discussion about this on this list, but I don't recall if that resulted in a definitive answer about what it should be.

I don't think there is any ambiguity in the spec (because it doesn't distinguish the cases). Variants that allow weaker ordering on CAS failure were triaged out mainly because they would cause an API explosion: Up to 16 (vs 4) versions each of compareAndSet, weakCompareAndSet, without compelling use cases.

-Doug


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 22:27
To: Andrew Dinn <adinn@redhat.com>
CC: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

Andrew, I appreciate all of the details you enumerate below about the design of Java and how concurrency with multi-threading is a primary design element.  The reference hoist has nothing to do with that though.  It has to do with optimizing the execution time of a block of code.  Yes, the analysis takes all the details of concurrent access into consideration around code paths of this thread, able to reach back into the class in some form.  But that analysis is totally based on the ‘volatile’ nature of the value, not simply on the fact that we are in a language that provides APIs that allow multi-threading to work.

I understand that the specifics seem integrated.  But my perspective is still that this reference hoist is assuming something that is so difficult to prove and variable based on what can be proved, that it’s an alarming side effect that is a surprise, more than it is a discernible behavior without extensive knowledge to all the implementation details which control when the hoist can actually occur.  Yes, that is what optimization is about, but the reality is that this optimization breaks the logic of the application and this is observable even in a debugger because of the logic change due to the hoisted read.  Other language compilers have over decades of development broken code due to mis-architected optimizations and we’ve not left them in.

The contention I am sensing revolves around the fact that this single optimization would appear to be something that everyone is relying on to solve lots of performance problems.  In days gone by of C and C++ programming, block-level, copy-of-value declarations were used as a moment to copy needed immutable references into block level values as a form of optimization of reference.  Things like

SomeType val;
if( ( val = externVal) != null ) {
…lots of references to val...
}

As a general non-locking mutation scheme, copy and replace (via CAS) reference strategies are ever present in concurrent systems, to avoid locks.  There’s just so many things that are done explicitly and provide such better documentation than a compiler optimization does.

The recurring counter point over the years, has been that experienced software developers can know why this occurs and will be able to readily fix the problem.  Really, believing that as a precursor to inaction, I feel, is a pretentious attitude that has caused a lot of people to not participate in many discussions.  It speaks to the belief that one can and does know everything, and that’s the only way to be a real software developer.  I’ve tried to have this discussion for years in a productive way.  But repeatedly, we arrive at “those are not real developers and so we don’t care about their problems” or “this is not a big problem, only some ignorant want-to-be programmers have this problem” so why should anyone care about them.

It’s really a privilege for all who spend time on this level of software construction and have the knowledge to understand all the details that are discussed in this group and amongst people of this caliber of knowledge.  Declaring it somehow required and achievable by all, is problematic, and that’s what I am continuing to stress.  Software doesn’t have to appear to be magic.  The notion of least surprise (https://en.wikipedia.org/wiki/Principle_of_least_astonishment) is an old principle that has books written about it to try and illuminate the ideals of how we should consider system design for the users of those systems.

There are countless examples of how “training” is a requirement before performing lots of tasks in jobs and in life in general.  It’s not the training that I am complaining about.  It’s the notion that this single optimization is something that breaks software systems in non-predictable ways because it’s a large scale software system inspection, not a local, recognizable optimization that the user somehow knows they purposefully requested.  

I am go to once again cease here because I appear to be pushing buttons with my conversation mode and I am really not trying to make people made or defensive.  At some level these are hard discussions to have, I get that, but I just really sense to much defensive posturing and so I really don’t believe that the discussion can happen without creating even more walls to have to figure out how to talk through.

Gregg

> On Jul 20, 2021, at 5:41 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> On 19/07/2021 22:39, Gregg Wonderly via Concurrency-interest wrote:
>> Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.
>
> And I am still trying to assert that we should not hobble the language implementation to cater for that category of 'programmer' (rabbit ears de rigeur). Java has been specified and implemented for use by skilled and knowledgeable professionals. That includes knowing about and having the skill to deal with the presence of multi-threading as a core element of the language, with all its attendant complexities.
>
> Of course, as a Java implementor I make no assumption that all those who use Java will be skilled, knowledgeable professionals. What I do assume is that I don't have to take the concerns or failings of unskilled or ignorant 'would-be' coders into account.
>
> By the way, I believe you are having your cake and eating it in the way you present your arguments here. You cited an example program as simple to understand and behaving as expected until you remove some logging code to simplify it and suddenly ... oh,. how surprising, a non-volatile access gets hoisted! At which point this simple to understand code becomes incomprehensible to the average reader.
>
> In truth, if you know how to read the different versions of this code with an awareness that Java is a multi-threaded language the complexity is never absent. The surprise you describe is prima facie evidence that your posited average reader is not reading the code correctly, whether in the original or reduced version. They just think they understand it.
>
> regards,
>
>
> Andrew Dinn
> -----------
> Red Hat Distinguished Engineer
> Red Hat UK Ltd
> Registered in England and Wales under Company Registration No. 03798903
> Directors: Michael Cunningham, Michael ("Mike") O'Neill
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: [concurrency-interest] Swing/AWT concurrency
From: Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-20, 23:45
To: concurrency-interest@cs.oswego.edu
Reply-To: Brian S O'Neill <bronee@gmail.com>

This is a continuation of the "Are there real use cases with the Java access modes?", but in a separate discussion thread to maintain focus on what I feel is the crux of the matter.

Gregg pointed out a potential problem that can affect new Java users when writing desktop applications. In particular, one thread can set a shared "isDone" field, and another thread might never observe this. In practice, the specific example which was provided wouldn't actually have a problem, but knowing why this is the case isn't something that a new Java user would have any knowledge of. In other languages/frameworks, users don't need to understand concurrency except as an advanced topic.

The suggested solution is to require that all fields be volatile as default. This naturally causes a knee-jerk reaction to anyone who wants the Java platform to be concurrent and highly efficient. And for those of us who mostly write server-side applications, we don't understand why this change is needed at all. After all, there's a bunch of modern async/task scheduling frameworks available that allow new users to write safe, efficient, and completely non-surprising programs.

New users of Swing/AWT don't have this luxury. And to them, Java == Swing, and so any problems in Swing are equivalent to problems in Java itself.

Would declaring all fields as volatile actually fix Swing? Not really. Consider the case in which one thread does this:

 isDone = true;
 doneMessage = "all done!";

Both fields are volatile, and both are thus visible to other threads. Except what I did is wrong, and it's not obvious to a new user. In their head, they think, "this task is done, and the message is 'all done'". So naturally the code should be written the same way. In almost all cases, this works just fine. Randomly it fails, and now you have to explain to the new user the concepts of concurrency, sequential consistency, etc.

If Swing/AWT was designed around a "pure" event loop, then all tasks run atomically, and so the order in which fields are assigned isn't relevant. They don't need to be volatile either. If the event loop implementation wants to use multiple threads, then it's responsible for using the correct thread-safe constructs and memory barriers to prevent strange issues from cropping up.

Modern frameworks exist on the server side to do just this, but have they been adapted for writing desktop apps? Is there an alternative to Swing/AWT? If not, my hope is that someone reading this becomes inspired to write such a thing. In the past, this seemed quite scary because it would likely involve a bunch of JNI coding. Hopefully the Panama project will take the sting out of this.

By the way, I know very little about "real world" Swing applications. My understanding of the issues might be wrong, so please be nice!
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 00:38
To: "Brian S O'Neill" <bronee@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think the problem is totally made up. You can't be using Swing, and not know about threads. Thread safety clauses are all over documentation for components. The hoist that Gregg has an issue with can happen only if non-thread-safe methods are used. Other methods are likely using locks inside, so even though not synchronized properly, the hoisting in question simply cannot happen.

I was hoping to see a working example that shows otherwise.

Alex

On Tue, 20 Jul 2021, 21:47 Brian S O'Neill via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    This is a continuation of the "Are there real use cases with the Java
    access modes?", but in a separate discussion thread to maintain focus on
    what I feel is the crux of the matter.

    Gregg pointed out a potential problem that can affect new Java users
    when writing desktop applications. In particular, one thread can set a
    shared "isDone" field, and another thread might never observe this. In
    practice, the specific example which was provided wouldn't actually have
    a problem, but knowing why this is the case isn't something that a new
    Java user would have any knowledge of. In other languages/frameworks,
    users don't need to understand concurrency except as an advanced topic.

    The suggested solution is to require that all fields be volatile as
    default. This naturally causes a knee-jerk reaction to anyone who wants
    the Java platform to be concurrent and highly efficient. And for those
    of us who mostly write server-side applications, we don't understand why
    this change is needed at all. After all, there's a bunch of modern
    async/task scheduling frameworks available that allow new users to write
    safe, efficient, and completely non-surprising programs.

    New users of Swing/AWT don't have this luxury. And to them, Java ==
    Swing, and so any problems in Swing are equivalent to problems in Java
    itself.

    Would declaring all fields as volatile actually fix Swing? Not really.
    Consider the case in which one thread does this:

      isDone = true;
      doneMessage = "all done!";

    Both fields are volatile, and both are thus visible to other threads.
    Except what I did is wrong, and it's not obvious to a new user. In their
    head, they think, "this task is done, and the message is 'all done'". So
    naturally the code should be written the same way. In almost all cases,
    this works just fine. Randomly it fails, and now you have to explain to
    the new user the concepts of concurrency, sequential consistency, etc.

    If Swing/AWT was designed around a "pure" event loop, then all tasks run
    atomically, and so the order in which fields are assigned isn't
    relevant. They don't need to be volatile either. If the event loop
    implementation wants to use multiple threads, then it's responsible for
    using the correct thread-safe constructs and memory barriers to prevent
    strange issues from cropping up.

    Modern frameworks exist on the server side to do just this, but have
    they been adapted for writing desktop apps? Is there an alternative to
    Swing/AWT? If not, my hope is that someone reading this becomes inspired
    to write such a thing. In the past, this seemed quite scary because it
    would likely involve a bunch of JNI coding. Hopefully the Panama project
    will take the sting out of this.

    By the way, I know very little about "real world" Swing applications. My
    understanding of the issues might be wrong, so please be nice!
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 02:18
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Brian S O'Neill <bronee@gmail.com>

I was able to reproduce the problem by changing the example code to have an empty loop body. It now looks like this:

  while (!done) {}
  tm.setText("" + new java.util.Date());

A new user might not understand the benefit of adding the sleep in the loop, but adding that back in does prevent hoisting.

I don't think the problem is totally made up. I've worked with new and experienced programmers who make mistakes like this, and it's not at all obvious why this is a problem.


On 2021-07-20 02:38 PM, Alex Otenko wrote:
> I think the problem is totally made up. You can't be using Swing, and not know about threads. Thread safety clauses are all over documentation for components. The hoist that Gregg has an issue with can happen only if non-thread-safe methods are used. Other methods are likely using locks inside, so even though not synchronized properly, the hoisting in question simply cannot happen.
>
> I was hoping to see a working example that shows otherwise.
>
> Alex
>
> On Tue, 20 Jul 2021, 21:47 Brian S O'Neill via Concurrency-interest, <concurrency-interest@cs.oswego.edu <mailto:concurrency-interest@cs.oswego.edu>> wrote:
>
>     This is a continuation of the "Are there real use cases with the Java
>     access modes?", but in a separate discussion thread to maintain
>     focus on
>     what I feel is the crux of the matter.
>
>     Gregg pointed out a potential problem that can affect new Java users
>     when writing desktop applications. In particular, one thread can set a
>     shared "isDone" field, and another thread might never observe this. In
>     practice, the specific example which was provided wouldn't actually
>     have
>     a problem, but knowing why this is the case isn't something that a new
>     Java user would have any knowledge of. In other languages/frameworks,
>     users don't need to understand concurrency except as an advanced topic.
>
>     The suggested solution is to require that all fields be volatile as
>     default. This naturally causes a knee-jerk reaction to anyone who wants
>     the Java platform to be concurrent and highly efficient. And for those
>     of us who mostly write server-side applications, we don't understand
>     why
>     this change is needed at all. After all, there's a bunch of modern
>     async/task scheduling frameworks available that allow new users to
>     write
>     safe, efficient, and completely non-surprising programs.
>
>     New users of Swing/AWT don't have this luxury. And to them, Java ==
>     Swing, and so any problems in Swing are equivalent to problems in Java
>     itself.
>
>     Would declaring all fields as volatile actually fix Swing? Not really.
>     Consider the case in which one thread does this:
>
>        isDone = true;
>        doneMessage = "all done!";
>
>     Both fields are volatile, and both are thus visible to other threads.
>     Except what I did is wrong, and it's not obvious to a new user. In
>     their
>     head, they think, "this task is done, and the message is 'all
>     done'". So
>     naturally the code should be written the same way. In almost all cases,
>     this works just fine. Randomly it fails, and now you have to explain to
>     the new user the concepts of concurrency, sequential consistency, etc.
>
>     If Swing/AWT was designed around a "pure" event loop, then all tasks
>     run
>     atomically, and so the order in which fields are assigned isn't
>     relevant. They don't need to be volatile either. If the event loop
>     implementation wants to use multiple threads, then it's responsible for
>     using the correct thread-safe constructs and memory barriers to prevent
>     strange issues from cropping up.
>
>     Modern frameworks exist on the server side to do just this, but have
>     they been adapted for writing desktop apps? Is there an alternative to
>     Swing/AWT? If not, my hope is that someone reading this becomes
>     inspired
>     to write such a thing. In the past, this seemed quite scary because it
>     would likely involve a bunch of JNI coding. Hopefully the Panama
>     project
>     will take the sting out of this.
>
>     By the way, I know very little about "real world" Swing
>     applications. My
>     understanding of the issues might be wrong, so please be nice!
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     <mailto:Concurrency-interest@cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Joe Bowbeer via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 04:39
To: Gregg Wonderly <gergg@cox.net>
CC: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Joe Bowbeer <joe.bowbeer@gmail.com>

Gregg,

You've been involved off-and-on in the concurrency and JMM discussions for over 20 years, if I recall correctly.

Are you proposing that an existing optimization now be disallowed? Is this a new proposal (from you), or has your argument changed? 

(For example, now you are arguing that our understanding of Java's intended audience is different than it was 20+ years ago?)


On Tue, Jul 20, 2021, 12:29 PM Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    Andrew, I appreciate all of the details you enumerate below about the design of Java and how concurrency with multi-threading is a primary design element.  The reference hoist has nothing to do with that though.  It has to do with optimizing the execution time of a block of code.  Yes, the analysis takes all the details of concurrent access into consideration around code paths of this thread, able to reach back into the class in some form.  But that analysis is totally based on the ‘volatile’ nature of the value, not simply on the fact that we are in a language that provides APIs that allow multi-threading to work.

    I understand that the specifics seem integrated.  But my perspective is still that this reference hoist is assuming something that is so difficult to prove and variable based on what can be proved, that it’s an alarming side effect that is a surprise, more than it is a discernible behavior without extensive knowledge to all the implementation details which control when the hoist can actually occur.  Yes, that is what optimization is about, but the reality is that this optimization breaks the logic of the application and this is observable even in a debugger because of the logic change due to the hoisted read.  Other language compilers have over decades of development broken code due to mis-architected optimizations and we’ve not left them in.

    The contention I am sensing revolves around the fact that this single optimization would appear to be something that everyone is relying on to solve lots of performance problems.  In days gone by of C and C++ programming, block-level, copy-of-value declarations were used as a moment to copy needed immutable references into block level values as a form of optimization of reference.  Things like

    SomeType val;
    if( ( val = externVal) != null ) {
    …lots of references to val...
    }

    As a general non-locking mutation scheme, copy and replace (via CAS) reference strategies are ever present in concurrent systems, to avoid locks.  There’s just so many things that are done explicitly and provide such better documentation than a compiler optimization does.

    The recurring counter point over the years, has been that experienced software developers can know why this occurs and will be able to readily fix the problem.  Really, believing that as a precursor to inaction, I feel, is a pretentious attitude that has caused a lot of people to not participate in many discussions.  It speaks to the belief that one can and does know everything, and that’s the only way to be a real software developer.  I’ve tried to have this discussion for years in a productive way.  But repeatedly, we arrive at “those are not real developers and so we don’t care about their problems” or “this is not a big problem, only some ignorant want-to-be programmers have this problem” so why should anyone care about them.

    It’s really a privilege for all who spend time on this level of software construction and have the knowledge to understand all the details that are discussed in this group and amongst people of this caliber of knowledge.  Declaring it somehow required and achievable by all, is problematic, and that’s what I am continuing to stress.  Software doesn’t have to appear to be magic.  The notion of least surprise (https://en.wikipedia.org/wiki/Principle_of_least_astonishment) is an old principle that has books written about it to try and illuminate the ideals of how we should consider system design for the users of those systems.

    There are countless examples of how “training” is a requirement before performing lots of tasks in jobs and in life in general.  It’s not the training that I am complaining about.  It’s the notion that this single optimization is something that breaks software systems in non-predictable ways because it’s a large scale software system inspection, not a local, recognizable optimization that the user somehow knows they purposefully requested.  

    I am go to once again cease here because I appear to be pushing buttons with my conversation mode and I am really not trying to make people made or defensive.  At some level these are hard discussions to have, I get that, but I just really sense to much defensive posturing and so I really don’t believe that the discussion can happen without creating even more walls to have to figure out how to talk through.

    Gregg

>     On Jul 20, 2021, at 5:41 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     On 19/07/2021 22:39, Gregg Wonderly via Concurrency-interest wrote:
>>     Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.
>
>     And I am still trying to assert that we should not hobble the language implementation to cater for that category of 'programmer' (rabbit ears de rigeur). Java has been specified and implemented for use by skilled and knowledgeable professionals. That includes knowing about and having the skill to deal with the presence of multi-threading as a core element of the language, with all its attendant complexities.
>
>     Of course, as a Java implementor I make no assumption that all those who use Java will be skilled, knowledgeable professionals. What I do assume is that I don't have to take the concerns or failings of unskilled or ignorant 'would-be' coders into account.
>
>     By the way, I believe you are having your cake and eating it in the way you present your arguments here. You cited an example program as simple to understand and behaving as expected until you remove some logging code to simplify it and suddenly ... oh,. how surprising, a non-volatile access gets hoisted! At which point this simple to understand code becomes incomprehensible to the average reader.
>
>     In truth, if you know how to read the different versions of this code with an awareness that Java is a multi-threaded language the complexity is never absent. The surprise you describe is prima facie evidence that your posited average reader is not reading the code correctly, whether in the original or reduced version. They just think they understand it.
>
>     regards,
>
>
>     Andrew Dinn
>     -----------
>     Red Hat Distinguished Engineer
>     Red Hat UK Ltd
>     Registered in England and Wales under Company Registration No. 03798903
>     Directors: Michael Cunningham, Michael ("Mike") O'Neill
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 07:03
To: Joe Bowbeer <joe.bowbeer@gmail.com>
CC: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

I have suggested that the default of non-volatile was a problematic choice, because it creates surprise behavior out of compiler optimization of non-volatile references for even simple applications.  We all can agree that we used to write C and C++ code like the following, and having an optimizer do this for us, seems awesome.

{ 
register cpyA = A;
register cpyB = B;

… do something as fast as possible with cpyA and cpyB values…
}

My experience with this hoist optimization, early on, was a problem that I didn’t enjoy.  There were all kinds of circumstances that made it extremely difficult for me to fix my applications to work with JDK 1.5 and get the updates to all the unknown users since my jar files had been circulated without any formal distribution system.  So, I have a raw feeling about this particular “optimization” that wasn’t something I elected to use.  The JLS already described volatile keyword use, it wasn’t something that had used because I hadn’t encounter any such optimization prior to JDK 1.5 and the JMM clarifications of all the things that were underspecified before that.

I am bring this up again, because if there are new language and JVM features happening, I’d like to see if there is some kind of solution for this particular issue that would at least allow inexperienced developers as well as experienced developers maintaining broken code that they haven’t seen a problem with yet.  Because this is a pretty silent optimization and because it’s so conditional on the code around it, my simple observation is that it’s a large surprise when the status of the hoist changes when you change code around the hoist.  Logic control statements in particular that have the hoist conditionally happen creates the surprise moment for people who don’t really understand that volatile is required to make swing applications that have listener callbacks manipulating data that the main thread is using.

I have a class that I wrote a long time ago to make the AWT-only vs external-data creator details easier.  Here’s how a listener would use it to cause an action to occur when a button is pressed or menu item selected etc.

public void ActionPerformed( ActionEvent ev ) {
new ComponentUpdateThread<DataValues>( btn1, btn2, lbl1, lbl2, lbl3, txt1, txt2, pnlA ) {
public void setup() { // on AWT event thread
super.setup();   // disable all controls in cons
txt1.setText( “” );
txt2.setText(“”);
}
public DataValues construct() {  // Executes on random pool thread
try {
DataValues v = NetworkAPI_to_getData();
return v;
} catch( Exception ex ) {
reportException(ex);
}
return null;
}
public void finish() {  // on AWT event thread
DataValues v = getResults();
txt1.setText(v.data1);
txt2.setText(v.data2);
super.finish();  // Enable all components
}
}.start();
}

This covers the exchange of data values between threads.  It also manages the access to the AWT component hierarchy so that it’s done with only an AWT event queue thread.  However, it still doesn’t cover the issue of non-volatile vs volatile value references between threads like my loop control example.  That’s why I am talking about this again and again.  There is literally no way that simple value references can be passed between threads without eliminating the hoist.  You just cannot pass the value between threads, and this means that everyone has to understand exactly how the AWT event queue threads work and that anything that one of those “listener bits” reads or writes, which is also read or written by the main threads has to be volatile.  I am not claiming that just completely eliminating the hoist from the compiler is the only solution.   I am just trying to describe all the details that I see and have experience about this one particular language feature and how swing in particular has a common code design that can happen to developers of new applications, early in the development, that is frustrating to figure out.  And I also mentioned that the bigger issue is that this optimization is based on code structure that is far more reaching analysis than most optimizations and that implies further surprise when the optimization changes what’s executed.

Yes I’ve been around Java from the beginning of it hitting the internet. I went to the NYC meeting where we saw applets in Mosaic.  I was on the Sun developer advisory council so I got to meet a lot of different people in Sun and in the Java community who were also participating there, such as Doug.  But I am not trying to say that makes me an expert.  I still have a whole lot less knowledge that the people on this list.

I brought this up in the past and Alex and I have gone back and forth about it and he’s constantly contended that this is either not a problem or that it’s such a rare thing that it doesn’t matter.   As a long time Java proponent, I am frustrated about various things that have happened around the “Java is a server platform” mantra that many of the people pulling strings in this community and others.  I write code from the bottom to the top of the software stack.  I do nothing on the web, because I prefer native apps better and I feel like Swing had the opportunity to solve a lot of portability problems and allow UNIXish OSes to have an easy to use GUI environment.  But there were all kinds of problems around missing APIs to simplify things.  There were too many ways to get screwed over by the threading mode because there wasn’t anything explicit, like the API I showed above.  Even in code like netbeans, people were using the AWT even thread to make network connections specifically because of the non-volatile data sharing problem.  It’s really everywhere, and I don’t know how else to illustrate that this creates a really large difficulty in places where ’small’ data exchanges are frequent and everywhere.  People just don’t create large data structures and wrapper APIs that can solve this simple issue of hoisting references, because you can’t solve it simply by an API, because you still need both threads to know about some reference or use some rendezvous mechanism to exchange a value through a class wrapped reference that is managed appropriate in declaration and happens before.

Gregg


> On Jul 20, 2021, at 8:39 PM, Joe Bowbeer via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> Gregg,
>
> You've been involved off-and-on in the concurrency and JMM discussions for over 20 years, if I recall correctly.
>
> Are you proposing that an existing optimization now be disallowed? Is this a new proposal (from you), or has your argument changed? 
>
> (For example, now you are arguing that our understanding of Java's intended audience is different than it was 20+ years ago?)
>
>
> On Tue, Jul 20, 2021, 12:29 PM Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     Andrew, I appreciate all of the details you enumerate below about the design of Java and how concurrency with multi-threading is a primary design element.  The reference hoist has nothing to do with that though.  It has to do with optimizing the execution time of a block of code.  Yes, the analysis takes all the details of concurrent access into consideration around code paths of this thread, able to reach back into the class in some form.  But that analysis is totally based on the ‘volatile’ nature of the value, not simply on the fact that we are in a language that provides APIs that allow multi-threading to work.
>
>     I understand that the specifics seem integrated.  But my perspective is still that this reference hoist is assuming something that is so difficult to prove and variable based on what can be proved, that it’s an alarming side effect that is a surprise, more than it is a discernible behavior without extensive knowledge to all the implementation details which control when the hoist can actually occur.  Yes, that is what optimization is about, but the reality is that this optimization breaks the logic of the application and this is observable even in a debugger because of the logic change due to the hoisted read.  Other language compilers have over decades of development broken code due to mis-architected optimizations and we’ve not left them in.
>
>     The contention I am sensing revolves around the fact that this single optimization would appear to be something that everyone is relying on to solve lots of performance problems.  In days gone by of C and C++ programming, block-level, copy-of-value declarations were used as a moment to copy needed immutable references into block level values as a form of optimization of reference.  Things like
>
>     SomeType val;
>     if( ( val = externVal) != null ) {
>     …lots of references to val...
>     }
>
>     As a general non-locking mutation scheme, copy and replace (via CAS) reference strategies are ever present in concurrent systems, to avoid locks.  There’s just so many things that are done explicitly and provide such better documentation than a compiler optimization does.
>
>     The recurring counter point over the years, has been that experienced software developers can know why this occurs and will be able to readily fix the problem.  Really, believing that as a precursor to inaction, I feel, is a pretentious attitude that has caused a lot of people to not participate in many discussions.  It speaks to the belief that one can and does know everything, and that’s the only way to be a real software developer.  I’ve tried to have this discussion for years in a productive way.  But repeatedly, we arrive at “those are not real developers and so we don’t care about their problems” or “this is not a big problem, only some ignorant want-to-be programmers have this problem” so why should anyone care about them.
>
>     It’s really a privilege for all who spend time on this level of software construction and have the knowledge to understand all the details that are discussed in this group and amongst people of this caliber of knowledge.  Declaring it somehow required and achievable by all, is problematic, and that’s what I am continuing to stress.  Software doesn’t have to appear to be magic.  The notion of least surprise (https://en.wikipedia.org/wiki/Principle_of_least_astonishment) is an old principle that has books written about it to try and illuminate the ideals of how we should consider system design for the users of those systems.
>
>     There are countless examples of how “training” is a requirement before performing lots of tasks in jobs and in life in general.  It’s not the training that I am complaining about.  It’s the notion that this single optimization is something that breaks software systems in non-predictable ways because it’s a large scale software system inspection, not a local, recognizable optimization that the user somehow knows they purposefully requested.  
>
>     I am go to once again cease here because I appear to be pushing buttons with my conversation mode and I am really not trying to make people made or defensive.  At some level these are hard discussions to have, I get that, but I just really sense to much defensive posturing and so I really don’t believe that the discussion can happen without creating even more walls to have to figure out how to talk through.
>
>     Gregg
>
>>     On Jul 20, 2021, at 5:41 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>     On 19/07/2021 22:39, Gregg Wonderly via Concurrency-interest wrote:
>>>     Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.
>>
>>     And I am still trying to assert that we should not hobble the language implementation to cater for that category of 'programmer' (rabbit ears de rigeur). Java has been specified and implemented for use by skilled and knowledgeable professionals. That includes knowing about and having the skill to deal with the presence of multi-threading as a core element of the language, with all its attendant complexities.
>>
>>     Of course, as a Java implementor I make no assumption that all those who use Java will be skilled, knowledgeable professionals. What I do assume is that I don't have to take the concerns or failings of unskilled or ignorant 'would-be' coders into account.
>>
>>     By the way, I believe you are having your cake and eating it in the way you present your arguments here. You cited an example program as simple to understand and behaving as expected until you remove some logging code to simplify it and suddenly ... oh,. how surprising, a non-volatile access gets hoisted! At which point this simple to understand code becomes incomprehensible to the average reader.
>>
>>     In truth, if you know how to read the different versions of this code with an awareness that Java is a multi-threaded language the complexity is never absent. The surprise you describe is prima facie evidence that your posited average reader is not reading the code correctly, whether in the original or reduced version. They just think they understand it.
>>
>>     regards,
>>
>>
>>     Andrew Dinn
>>     -----------
>>     Red Hat Distinguished Engineer
>>     Red Hat UK Ltd
>>     Registered in England and Wales under Company Registration No. 03798903
>>     Directors: Michael Cunningham, Michael ("Mike") O'Neill
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest@cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 09:02
To: "Brian S O'Neill" <bronee@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Correct, that can hang.

I was waiting when we will start reducing a big claim of a variety of situations that confuse experts, to a simple claim of a broken condition wait.

I suppose the experienced programmers understand "condition wait" concept?

Alex

On Wed, 21 Jul 2021, 00:18 Brian S O'Neill, <bronee@gmail.com> wrote:

    I was able to reproduce the problem by changing the example code to have
    an empty loop body. It now looks like this:

       while (!done) {}
       tm.setText("" + new java.util.Date());

    A new user might not understand the benefit of adding the sleep in the
    loop, but adding that back in does prevent hoisting.

    I don't think the problem is totally made up. I've worked with new and
    experienced programmers who make mistakes like this, and it's not at all
    obvious why this is a problem.


    On 2021-07-20 02:38 PM, Alex Otenko wrote:
    > I think the problem is totally made up. You can't be using Swing, and
    > not know about threads. Thread safety clauses are all over documentation
    > for components. The hoist that Gregg has an issue with can happen only
    > if non-thread-safe methods are used. Other methods are likely using
    > locks inside, so even though not synchronized properly, the hoisting in
    > question simply cannot happen.
    >
    > I was hoping to see a working example that shows otherwise.
    >
    > Alex
    >
    > On Tue, 20 Jul 2021, 21:47 Brian S O'Neill via Concurrency-interest,
    > <concurrency-interest@cs.oswego.edu
    > <mailto:concurrency-interest@cs.oswego.edu>> wrote:
    >
    >     This is a continuation of the "Are there real use cases with the Java
    >     access modes?", but in a separate discussion thread to maintain
    >     focus on
    >     what I feel is the crux of the matter.
    >
    >     Gregg pointed out a potential problem that can affect new Java users
    >     when writing desktop applications. In particular, one thread can set a
    >     shared "isDone" field, and another thread might never observe this. In
    >     practice, the specific example which was provided wouldn't actually
    >     have
    >     a problem, but knowing why this is the case isn't something that a new
    >     Java user would have any knowledge of. In other languages/frameworks,
    >     users don't need to understand concurrency except as an advanced topic.
    >
    >     The suggested solution is to require that all fields be volatile as
    >     default. This naturally causes a knee-jerk reaction to anyone who wants
    >     the Java platform to be concurrent and highly efficient. And for those
    >     of us who mostly write server-side applications, we don't understand
    >     why
    >     this change is needed at all. After all, there's a bunch of modern
    >     async/task scheduling frameworks available that allow new users to
    >     write
    >     safe, efficient, and completely non-surprising programs.
    >
    >     New users of Swing/AWT don't have this luxury. And to them, Java ==
    >     Swing, and so any problems in Swing are equivalent to problems in Java
    >     itself.
    >
    >     Would declaring all fields as volatile actually fix Swing? Not really.
    >     Consider the case in which one thread does this:
    >
    >        isDone = true;
    >        doneMessage = "all done!";
    >
    >     Both fields are volatile, and both are thus visible to other threads.
    >     Except what I did is wrong, and it's not obvious to a new user. In
    >     their
    >     head, they think, "this task is done, and the message is 'all
    >     done'". So
    >     naturally the code should be written the same way. In almost all cases,
    >     this works just fine. Randomly it fails, and now you have to explain to
    >     the new user the concepts of concurrency, sequential consistency, etc.
    >
    >     If Swing/AWT was designed around a "pure" event loop, then all tasks
    >     run
    >     atomically, and so the order in which fields are assigned isn't
    >     relevant. They don't need to be volatile either. If the event loop
    >     implementation wants to use multiple threads, then it's responsible for
    >     using the correct thread-safe constructs and memory barriers to prevent
    >     strange issues from cropping up.
    >
    >     Modern frameworks exist on the server side to do just this, but have
    >     they been adapted for writing desktop apps? Is there an alternative to
    >     Swing/AWT? If not, my hope is that someone reading this becomes
    >     inspired
    >     to write such a thing. In the past, this seemed quite scary because it
    >     would likely involve a bunch of JNI coding. Hopefully the Panama
    >     project
    >     will take the sting out of this.
    >
    >     By the way, I know very little about "real world" Swing
    >     applications. My
    >     understanding of the issues might be wrong, so please be nice!
    >     _______________________________________________
    >     Concurrency-interest mailing list
    >     Concurrency-interest@cs.oswego.edu
    >     <mailto:Concurrency-interest@cs.oswego.edu>
    >     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    >     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
    >


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Peter via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 09:25
To: Alex Otenko <oleksandr.otenko@gmail.com>, Brian S O'Neill <bronee@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: jini@zeus.net.au

It has been my experience that this type of synchronization leads to brittle code, which breaks unexpectedly when changes are made, which creates fear of change among developers.

Just my 2 cents.

-- 
Regards,
 
Peter

>
>     On 2021-07-20 02:38 PM, Alex Otenko wrote:
>       Other methods are likely using
>     > locks inside, so even though not synchronized properly
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Thorsten via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 12:01
To: concurrency-interest@cs.oswego.edu
Reply-To: Thorsten <tg@freigmbh.de>

Hello,

My Experience as a real world swing developer: I know that I have to respect multithreading, and if I see a race condition, I change it. Usually using SwingUtililities.inokeLater()/ Executer.execute()/Future.cancel(), volatile/atomics are almost never needed.

The curent state can be simplified for the average developer (me) as: If it is shared between Threads, it needs some sort of synchronization. Always. If the jvm would prevent "hoisting" it would make judging the "correctness" of a code become a mess. I would have to use way to much of my limited brain to tell if the race condition is covered by "hoisting-prevention" or if its an other race condition that is not covered. And/Or I still have to tell everyone to make their fields volatile, even if it doesn't do anything anymore and everyone becomes even more confused about how multithreading works.

So the usecase Greg presented looks like this: theres a loop, and the condition is changed from another thread. That is indeed a real world scenario. But in your example there is only one field "done" for which you want protection. But in any real usecase there will be more fields. So protecting "done", even if possible would just cause more confusion later on: is "paused" safe to acess in this way? is "input"? If yes/no why? it worked with done before.

while(!done){

if (!paused){

 evaluate(input)

}

}

So in conclusion multithreading simply requires some extra work from the developer. Java and also Swing/AWT do a good job providing usefull tools. Adding some training wheels seems like a miss to me, because its not transparent when the training wheels are on/off and how much they actually do.

Best regards,

Thorsten


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 12:04
To: concurrency-interest@cs.oswego.edu
Reply-To: Andrew Haley <aph@redhat.com>

On 7/20/21 8:27 PM, Gregg Wonderly via Concurrency-interest wrote:

> > I am go to once again cease here because I appear to be pushing
> > buttons with my conversation mode and I am really not trying to make
> > people made or defensive.  At some level these are hard discussions
> > to have, I get that, but I just really sense to much defensive
> > posturing and so I really don’t believe that the discussion can
> > happen without creating even more walls to have to figure out how to
> > talk through.

Gregg, really. Please have some respect.

People are giving you time and explaining their reasons to you. We are
not "defensively posturing". In my case, it's sheer amazement that
something like hosting a value into a register, one of the most common
and powerful optimizations we have, is in some way weird.

It's like this: operations in a CPU act on registers. There is near-
zero cost for accessing them, so the basic arithmetic and logical
operations can deliver their results in a single cycle. Memory, on the
other hand, even cache memory, has a latency of four or five cycles,
and costs more energy too. So this optimization is a really big deal
on the billions (probably?) of computers running Java.

I'll try an analogy. Imagine someone came up with a way to make
internal combustion engines run 10% better, consume less fuel, and
produce less emissions. (It's not hard to imagine: it happens.) Then
someone else comes along and says it's terribly complicated, and Bono
in the repair shop on the corner will not be able to maintain it, so
we shouldn't do it.

This is, almost exactly, the same as your argument.

-- Andrew Haley (he/him) Java Platform Lead Engineer Red Hat UK Ltd. <https://www.redhat.com> https://keybase.io/andrewhaley EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671 _______________________________________________ Concurrency-interest mailing list Concurrency-interest@cs.oswego.edu http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 12:11
To: Gregg Wonderly <gergg@cox.net>
CC: Joe Bowbeer <joe.bowbeer@gmail.com>, Valentin Kovalenko <valentin.male.kovalenko@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I don't think I have ever said that it is not a problem. I think I have been clear that if there is misunderstanding of what non-volatile accesses do, there is a bigger problem, so "solving" the "unexpected" hoist is not going to make the program correct.

For one, non-volatile accesses are allowed to happen in any order. The example you gave just waits for a flag to be flipped, then do nothing exciting. Try to read some variables instead. Even in pre-1.5 reorderings happened.

I am particularly amazed at some claims about interactions with AWT and even Kafka. How can one program for these, and not think of threads? Ok, I know, many will learn Java from stackoverflow. But once you open documentation about AWT or Swing, thread-(un)safety clauses are all over it.

The principle of least astonishment is misapplied, too. Astonishment to whom? In C all loops terminate, so a C programmer may be astonished that the loop you gave as an example does anything at all, if we throw away everything out of the loop body. A Python or Javascript programmer may be astonished that that loop ever terminates, because it never yields control to a routine that mutates the flag. A Rust programmer may be surprised that it compiles - mutability is not a given.


Alex

On Wed, 21 Jul 2021, 05:05 Gregg Wonderly via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    I have suggested that the default of non-volatile was a problematic choice, because it creates surprise behavior out of compiler optimization of non-volatile references for even simple applications.  We all can agree that we used to write C and C++ code like the following, and having an optimizer do this for us, seems awesome.

    { 
    register cpyA = A;
    register cpyB = B;

    … do something as fast as possible with cpyA and cpyB values…
    }

    My experience with this hoist optimization, early on, was a problem that I didn’t enjoy.  There were all kinds of circumstances that made it extremely difficult for me to fix my applications to work with JDK 1.5 and get the updates to all the unknown users since my jar files had been circulated without any formal distribution system.  So, I have a raw feeling about this particular “optimization” that wasn’t something I elected to use.  The JLS already described volatile keyword use, it wasn’t something that had used because I hadn’t encounter any such optimization prior to JDK 1.5 and the JMM clarifications of all the things that were underspecified before that.

    I am bring this up again, because if there are new language and JVM features happening, I’d like to see if there is some kind of solution for this particular issue that would at least allow inexperienced developers as well as experienced developers maintaining broken code that they haven’t seen a problem with yet.  Because this is a pretty silent optimization and because it’s so conditional on the code around it, my simple observation is that it’s a large surprise when the status of the hoist changes when you change code around the hoist.  Logic control statements in particular that have the hoist conditionally happen creates the surprise moment for people who don’t really understand that volatile is required to make swing applications that have listener callbacks manipulating data that the main thread is using.

    I have a class that I wrote a long time ago to make the AWT-only vs external-data creator details easier.  Here’s how a listener would use it to cause an action to occur when a button is pressed or menu item selected etc.

    public void ActionPerformed( ActionEvent ev ) {
    new ComponentUpdateThread<DataValues>( btn1, btn2, lbl1, lbl2, lbl3, txt1, txt2, pnlA ) {
    public void setup() { // on AWT event thread
    super.setup();   // disable all controls in cons
    txt1.setText( “” );
    txt2.setText(“”);
    }
    public DataValues construct() {  // Executes on random pool thread
    try {
    DataValues v = NetworkAPI_to_getData();
    return v;
    } catch( Exception ex ) {
    reportException(ex);
    }
    return null;
    }
    public void finish() {  // on AWT event thread
    DataValues v = getResults();
    txt1.setText(v.data1);
    txt2.setText(v.data2);
    super.finish();  // Enable all components
    }
    }.start();
    }

    This covers the exchange of data values between threads.  It also manages the access to the AWT component hierarchy so that it’s done with only an AWT event queue thread.  However, it still doesn’t cover the issue of non-volatile vs volatile value references between threads like my loop control example.  That’s why I am talking about this again and again.  There is literally no way that simple value references can be passed between threads without eliminating the hoist.  You just cannot pass the value between threads, and this means that everyone has to understand exactly how the AWT event queue threads work and that anything that one of those “listener bits” reads or writes, which is also read or written by the main threads has to be volatile.  I am not claiming that just completely eliminating the hoist from the compiler is the only solution.   I am just trying to describe all the details that I see and have experience about this one particular language feature and how swing in particular has a common code design that can happen to developers of new applications, early in the development, that is frustrating to figure out.  And I also mentioned that the bigger issue is that this optimization is based on code structure that is far more reaching analysis than most optimizations and that implies further surprise when the optimization changes what’s executed.

    Yes I’ve been around Java from the beginning of it hitting the internet. I went to the NYC meeting where we saw applets in Mosaic.  I was on the Sun developer advisory council so I got to meet a lot of different people in Sun and in the Java community who were also participating there, such as Doug.  But I am not trying to say that makes me an expert.  I still have a whole lot less knowledge that the people on this list.

    I brought this up in the past and Alex and I have gone back and forth about it and he’s constantly contended that this is either not a problem or that it’s such a rare thing that it doesn’t matter.   As a long time Java proponent, I am frustrated about various things that have happened around the “Java is a server platform” mantra that many of the people pulling strings in this community and others.  I write code from the bottom to the top of the software stack.  I do nothing on the web, because I prefer native apps better and I feel like Swing had the opportunity to solve a lot of portability problems and allow UNIXish OSes to have an easy to use GUI environment.  But there were all kinds of problems around missing APIs to simplify things.  There were too many ways to get screwed over by the threading mode because there wasn’t anything explicit, like the API I showed above.  Even in code like netbeans, people were using the AWT even thread to make network connections specifically because of the non-volatile data sharing problem.  It’s really everywhere, and I don’t know how else to illustrate that this creates a really large difficulty in places where ’small’ data exchanges are frequent and everywhere.  People just don’t create large data structures and wrapper APIs that can solve this simple issue of hoisting references, because you can’t solve it simply by an API, because you still need both threads to know about some reference or use some rendezvous mechanism to exchange a value through a class wrapped reference that is managed appropriate in declaration and happens before.

    Gregg


>     On Jul 20, 2021, at 8:39 PM, Joe Bowbeer via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     Gregg,
>
>     You've been involved off-and-on in the concurrency and JMM discussions for over 20 years, if I recall correctly.
>
>     Are you proposing that an existing optimization now be disallowed? Is this a new proposal (from you), or has your argument changed? 
>
>     (For example, now you are arguing that our understanding of Java's intended audience is different than it was 20+ years ago?)
>
>
>     On Tue, Jul 20, 2021, 12:29 PM Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>         Andrew, I appreciate all of the details you enumerate below about the design of Java and how concurrency with multi-threading is a primary design element.  The reference hoist has nothing to do with that though.  It has to do with optimizing the execution time of a block of code.  Yes, the analysis takes all the details of concurrent access into consideration around code paths of this thread, able to reach back into the class in some form.  But that analysis is totally based on the ‘volatile’ nature of the value, not simply on the fact that we are in a language that provides APIs that allow multi-threading to work.
>
>         I understand that the specifics seem integrated.  But my perspective is still that this reference hoist is assuming something that is so difficult to prove and variable based on what can be proved, that it’s an alarming side effect that is a surprise, more than it is a discernible behavior without extensive knowledge to all the implementation details which control when the hoist can actually occur.  Yes, that is what optimization is about, but the reality is that this optimization breaks the logic of the application and this is observable even in a debugger because of the logic change due to the hoisted read.  Other language compilers have over decades of development broken code due to mis-architected optimizations and we’ve not left them in.
>
>         The contention I am sensing revolves around the fact that this single optimization would appear to be something that everyone is relying on to solve lots of performance problems.  In days gone by of C and C++ programming, block-level, copy-of-value declarations were used as a moment to copy needed immutable references into block level values as a form of optimization of reference.  Things like
>
>         SomeType val;
>         if( ( val = externVal) != null ) {
>         …lots of references to val...
>         }
>
>         As a general non-locking mutation scheme, copy and replace (via CAS) reference strategies are ever present in concurrent systems, to avoid locks.  There’s just so many things that are done explicitly and provide such better documentation than a compiler optimization does.
>
>         The recurring counter point over the years, has been that experienced software developers can know why this occurs and will be able to readily fix the problem.  Really, believing that as a precursor to inaction, I feel, is a pretentious attitude that has caused a lot of people to not participate in many discussions.  It speaks to the belief that one can and does know everything, and that’s the only way to be a real software developer.  I’ve tried to have this discussion for years in a productive way.  But repeatedly, we arrive at “those are not real developers and so we don’t care about their problems” or “this is not a big problem, only some ignorant want-to-be programmers have this problem” so why should anyone care about them.
>
>         It’s really a privilege for all who spend time on this level of software construction and have the knowledge to understand all the details that are discussed in this group and amongst people of this caliber of knowledge.  Declaring it somehow required and achievable by all, is problematic, and that’s what I am continuing to stress.  Software doesn’t have to appear to be magic.  The notion of least surprise (https://en.wikipedia.org/wiki/Principle_of_least_astonishment) is an old principle that has books written about it to try and illuminate the ideals of how we should consider system design for the users of those systems.
>
>         There are countless examples of how “training” is a requirement before performing lots of tasks in jobs and in life in general.  It’s not the training that I am complaining about.  It’s the notion that this single optimization is something that breaks software systems in non-predictable ways because it’s a large scale software system inspection, not a local, recognizable optimization that the user somehow knows they purposefully requested.  
>
>         I am go to once again cease here because I appear to be pushing buttons with my conversation mode and I am really not trying to make people made or defensive.  At some level these are hard discussions to have, I get that, but I just really sense to much defensive posturing and so I really don’t believe that the discussion can happen without creating even more walls to have to figure out how to talk through.
>
>         Gregg
>
>>         On Jul 20, 2021, at 5:41 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>>         On 19/07/2021 22:39, Gregg Wonderly via Concurrency-interest wrote:
>>>         Thanks for you comments.   I am still trying to assert that the problem is this kind of assumption about people writing the code, actually being trained software engineers.  Instead, think of them as self taught coders.  People who only every wrote “basic” or “vb” style integrations with just some knowledge that threads even exist, let alone, as in this case, knowing that the AWT event queue is involved and that there are threads (or more in the case of dialogs and other blocking actions) reaping events from the queue and dispatching them into your code.  Even the term callback or listener, for these people, doesn’t invoke any picture of “two” things working together.
>>
>>         And I am still trying to assert that we should not hobble the language implementation to cater for that category of 'programmer' (rabbit ears de rigeur). Java has been specified and implemented for use by skilled and knowledgeable professionals. That includes knowing about and having the skill to deal with the presence of multi-threading as a core element of the language, with all its attendant complexities.
>>
>>         Of course, as a Java implementor I make no assumption that all those who use Java will be skilled, knowledgeable professionals. What I do assume is that I don't have to take the concerns or failings of unskilled or ignorant 'would-be' coders into account.
>>
>>         By the way, I believe you are having your cake and eating it in the way you present your arguments here. You cited an example program as simple to understand and behaving as expected until you remove some logging code to simplify it and suddenly ... oh,. how surprising, a non-volatile access gets hoisted! At which point this simple to understand code becomes incomprehensible to the average reader.
>>
>>         In truth, if you know how to read the different versions of this code with an awareness that Java is a multi-threaded language the complexity is never absent. The surprise you describe is prima facie evidence that your posited average reader is not reading the code correctly, whether in the original or reduced version. They just think they understand it.
>>
>>         regards,
>>
>>
>>         Andrew Dinn
>>         -----------
>>         Red Hat Distinguished Engineer
>>         Red Hat UK Ltd
>>         Registered in England and Wales under Company Registration No. 03798903
>>         Directors: Michael Cunningham, Michael ("Mike") O'Neill
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest@cs.oswego.edu
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest@cs.oswego.edu
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 12:14
To: Brian S O'Neill <bronee@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>

At various times over the years, I’ve met people who have talked about this issue and their own practical problems around non-volatile being the default. In several cases, they have told me that they’ve just adopted the practice that in any class they create (even outside of Swing use), class level declarations should either by final, or volatile.  The final fields are objects that manage concurrency themselves, or are primitive types that are parameters to constructors or are otherwise immutable.  The other fields are declared volatile because then if the user of the class uses it in more than one thread, the values of such fields will readily escape hoisted references or writes to those fields will not be missed by subsequent reads.  In many cases, this can result in data races, but for things that are atomically assigned or referenced values, this at least keeps sanity in the usage, and for non-atomic assignment/reference, one can observe the value changing erratically at least to then have a problem to solve that generally will require Atomic<T> to be used.

This document, https://apps.dtic.mil/sti/pdfs/ADA528370.pdf, describes all of the details around the fragility of non-volatile values in various ways and usages.  I think everyone here would agree with the observations there and the examples readily describe the pitfalls of non-volatile values.   These scenarios illustrate examples of non-volatile use including the text around section 2.1.1, which is the structure that I’ve illustrated and discussed here.  It’s a specific example that it well recognized and documented.

Gregg Wonderly

> On Jul 20, 2021, at 6:18 PM, Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> I was able to reproduce the problem by changing the example code to have an empty loop body. It now looks like this:
>
>  while (!done) {}
>  tm.setText("" + new java.util.Date());
>
> A new user might not understand the benefit of adding the sleep in the loop, but adding that back in does prevent hoisting.
>
> I don't think the problem is totally made up. I've worked with new and experienced programmers who make mistakes like this, and it's not at all obvious why this is a problem.
>
>
> On 2021-07-20 02:38 PM, Alex Otenko wrote:
>> I think the problem is totally made up. You can't be using Swing, and not know about threads. Thread safety clauses are all over documentation for components. The hoist that Gregg has an issue with can happen only if non-thread-safe methods are used. Other methods are likely using locks inside, so even though not synchronized properly, the hoisting in question simply cannot happen.
>> I was hoping to see a working example that shows otherwise.
>> Alex
>> On Tue, 20 Jul 2021, 21:47 Brian S O'Neill via Concurrency-interest, <concurrency-interest@cs.oswego.edu <mailto:concurrency-interest@cs.oswego.edu>> wrote:
>>    This is a continuation of the "Are there real use cases with the Java
>>    access modes?", but in a separate discussion thread to maintain
>>    focus on
>>    what I feel is the crux of the matter.
>>    Gregg pointed out a potential problem that can affect new Java users
>>    when writing desktop applications. In particular, one thread can set a
>>    shared "isDone" field, and another thread might never observe this. In
>>    practice, the specific example which was provided wouldn't actually
>>    have
>>    a problem, but knowing why this is the case isn't something that a new
>>    Java user would have any knowledge of. In other languages/frameworks,
>>    users don't need to understand concurrency except as an advanced topic.
>>    The suggested solution is to require that all fields be volatile as
>>    default. This naturally causes a knee-jerk reaction to anyone who wants
>>    the Java platform to be concurrent and highly efficient. And for those
>>    of us who mostly write server-side applications, we don't understand
>>    why
>>    this change is needed at all. After all, there's a bunch of modern
>>    async/task scheduling frameworks available that allow new users to
>>    write
>>    safe, efficient, and completely non-surprising programs.
>>    New users of Swing/AWT don't have this luxury. And to them, Java ==
>>    Swing, and so any problems in Swing are equivalent to problems in Java
>>    itself.
>>    Would declaring all fields as volatile actually fix Swing? Not really.
>>    Consider the case in which one thread does this:
>>       isDone = true;
>>       doneMessage = "all done!";
>>    Both fields are volatile, and both are thus visible to other threads.
>>    Except what I did is wrong, and it's not obvious to a new user. In
>>    their
>>    head, they think, "this task is done, and the message is 'all
>>    done'". So
>>    naturally the code should be written the same way. In almost all cases,
>>    this works just fine. Randomly it fails, and now you have to explain to
>>    the new user the concepts of concurrency, sequential consistency, etc.
>>    If Swing/AWT was designed around a "pure" event loop, then all tasks
>>    run
>>    atomically, and so the order in which fields are assigned isn't
>>    relevant. They don't need to be volatile either. If the event loop
>>    implementation wants to use multiple threads, then it's responsible for
>>    using the correct thread-safe constructs and memory barriers to prevent
>>    strange issues from cropping up.
>>    Modern frameworks exist on the server side to do just this, but have
>>    they been adapted for writing desktop apps? Is there an alternative to
>>    Swing/AWT? If not, my hope is that someone reading this becomes
>>    inspired
>>    to write such a thing. In the past, this seemed quite scary because it
>>    would likely involve a bunch of JNI coding. Hopefully the Panama
>>    project
>>    will take the sting out of this.
>>    By the way, I know very little about "real world" Swing
>>    applications. My
>>    understanding of the issues might be wrong, so please be nice!
>>    _______________________________________________
>>    Concurrency-interest mailing list
>>    Concurrency-interest@cs.oswego.edu
>>    <mailto:Concurrency-interest@cs.oswego.edu>
>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>    <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 12:19
To: Andrew Haley <aph@redhat.com>
CC: concurrency-interest@cs.oswego.edu
Reply-To: Gregg Wonderly <gergg@cox.net>

Yes Andrew, I stooped below the belt on that comment and I apologize for doing that. 

> > On Jul 21, 2021, at 4:04 AM, Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > On 7/20/21 8:27 PM, Gregg Wonderly via Concurrency-interest wrote:
> > 
>> >> I am go to once again cease here because I appear to be pushing
>> >> buttons with my conversation mode and I am really not trying to make
>> >> people made or defensive.  At some level these are hard discussions
>> >> to have, I get that, but I just really sense to much defensive
>> >> posturing and so I really don’t believe that the discussion can
>> >> happen without creating even more walls to have to figure out how to
>> >> talk through.
> > 
> > Gregg, really. Please have some respect.
> > 
> > People are giving you time and explaining their reasons to you. We are
> > not "defensively posturing". In my case, it's sheer amazement that
> > something like hosting a value into a register, one of the most common
> > and powerful optimizations we have, is in some way weird.
> > 
> > It's like this: operations in a CPU act on registers. There is near-
> > zero cost for accessing them, so the basic arithmetic and logical
> > operations can deliver their results in a single cycle. Memory, on the
> > other hand, even cache memory, has a latency of four or five cycles,
> > and costs more energy too. So this optimization is a really big deal
> > on the billions (probably?) of computers running Java.
> > 
> > I'll try an analogy. Imagine someone came up with a way to make
> > internal combustion engines run 10% better, consume less fuel, and
> > produce less emissions. (It's not hard to imagine: it happens.) Then
> > someone else comes along and says it's terribly complicated, and Bono
> > in the repair shop on the corner will not be able to maintain it, so
> > we shouldn't do it.
> > 
> > This is, almost exactly, the same as your argument.
> > 
> > -- 
> > Andrew Haley  (he/him)
> > Java Platform Lead Engineer
> > Red Hat UK Ltd. <https://www.redhat.com>
> > https://keybase.io/andrewhaley
> > EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 18:26
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: Joe Bowbeer <joe.bowbeer@gmail.com>, Valentin Kovalenko <valentin.male.kovalenko@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 21, 2021, at 4:11 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > The principle of least astonishment is misapplied, too. Astonishment to whom?

The programmer is surprised by an optimization that happens at one point in the code due to the relationship and exact nature of code elsewhere in the block.  Automated hoisting of references is certainly a great optimization for things that are being computed with, but a ’truth’ or ‘control’ statement implies that mutation would have to happen.  In the very specific case of a loop, would the programmer really be purposefully creating an infinite loop with an expression/condition involving a non-volatile, class level value reference?

> > In C all loops terminate, so a C programmer may be astonished that the loop you gave as an example does anything at all, if we throw away everything out of the loop body. A Python or Javascript programmer may be astonished that that loop ever terminates, because it never yields control to a routine that mutates the flag.

Depending on ones background, you could be used to something like green threads of old.  You could just be guessing that there is an interrupt/timer thing that calls out to other code like the V8 runtime does.

> > A Rust programmer may be surprised that it compiles - mutability is not a given.

And this is more precisely the type of thing that I am trying to speak to.  I don’t know a lot about Rust, because I haven’t been able to make time to dive in and use it for something significant.  But my casual knowledge of it, informs me that people are actually trying to make safe software systems by eliminating all of the things that “runtime”, “compiler” and “extensions” to software systems can hide form the user and invalidate their software without them knowing it.

If the compiler is going to hoist a value, and it’s part of a control statement that would be invalidated by the hoist, it seems like warning the developer of the mis-declaration or use of concurrent access might be prudent so that they can understand what is being overlooked in the current software design.  What would happen to large java applications if the java compiler did this today?  Would we find bugs?  I am going to bet that we would find lots of non-volatile use that is not valid, technically, but works practically because of the compiler not being able to reach a conclusion allowing it to hoist the read.  So, due to the use of fences for so many other things, there is an implicit cache coherency state that allows a write to be read across thread boundaries and everyone is happy because all tests past.

Gregg Wonderly


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 18:50
To: Gregg Wonderly <gergg@cox.net>
CC: Joe Bowbeer <joe.bowbeer@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>, Valentin Kovalenko <valentin.male.kovalenko@gmail.com>
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

> In the very specific case of a loop, would the programmer really be purposefully creating an infinite loop with an expression/condition involving a non-volatile, class level value reference?

Sounds like a job for a linter.  For easier cases, an easy PMD rule will catch such a problem.  For harder cases, the PMD rule will need to traverse the call tree to see if a thread executing the loop could change the field.  If not, flag a problem to the programmer.

With such a rule in place, an advanced programmer might write an infinite loop but PMD will flag the issue and the programmer will learn.  When the code is changed in the future and this creates an infinite loop, PMD will flag a problem.

In fact, PMD's rules catch so many mistakes that beginner programmers can quickly become better programmers.  I work with a bunch of programmers that have not written production-level code for more than a decade.  I find a lot of problems during code reviews.  I then write PMD rules to catch almost all of these problems automatically.  The code quality I see in code reviews is much better now.  During code reviews, I spend less time flagging simple mistakes and more time catching deep problems.

On Wed, Jul 21, 2021 at 9:30 AM Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:



    > On Jul 21, 2021, at 4:11 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
    > The principle of least astonishment is misapplied, too. Astonishment to whom?

    The programmer is surprised by an optimization that happens at one point in the code due to the relationship and exact nature of code elsewhere in the block.  Automated hoisting of references is certainly a great optimization for things that are being computed with, but a ’truth’ or ‘control’ statement implies that mutation would have to happen.  In the very specific case of a loop, would the programmer really be purposefully creating an infinite loop with an expression/condition involving a non-volatile, class level value reference?

    > In C all loops terminate, so a C programmer may be astonished that the loop you gave as an example does anything at all, if we throw away everything out of the loop body. A Python or Javascript programmer may be astonished that that loop ever terminates, because it never yields control to a routine that mutates the flag.

    Depending on ones background, you could be used to something like green threads of old.  You could just be guessing that there is an interrupt/timer thing that calls out to other code like the V8 runtime does.

    > A Rust programmer may be surprised that it compiles - mutability is not a given.

    And this is more precisely the type of thing that I am trying to speak to.  I don’t know a lot about Rust, because I haven’t been able to make time to dive in and use it for something significant.  But my casual knowledge of it, informs me that people are actually trying to make safe software systems by eliminating all of the things that “runtime”, “compiler” and “extensions” to software systems can hide form the user and invalidate their software without them knowing it.

    If the compiler is going to hoist a value, and it’s part of a control statement that would be invalidated by the hoist, it seems like warning the developer of the mis-declaration or use of concurrent access might be prudent so that they can understand what is being overlooked in the current software design.  What would happen to large java applications if the java compiler did this today?  Would we find bugs?  I am going to bet that we would find lots of non-volatile use that is not valid, technically, but works practically because of the compiler not being able to reach a conclusion allowing it to hoist the read.  So, due to the use of fences for so many other things, there is an implicit cache coherency state that allows a write to be read across thread boundaries and everyone is happy because all tests past.

    Gregg Wonderly


    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-21, 19:46
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>



On Wed, 21 Jul 2021, 16:26 Gregg Wonderly, <gergg@cox.net> wrote:



    > On Jul 21, 2021, at 4:11 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
    > The principle of least astonishment is misapplied, too. Astonishment to whom?

    The programmer is surprised by an optimization that happens at one point in the code due to the relationship and exact nature of code elsewhere in the block.  Automated hoisting of references is certainly a great optimization for things that are being computed with, but a ’truth’ or ‘control’ statement implies that mutation would have to happen.  In the very specific case of a loop, would the programmer really be purposefully creating an infinite loop with an expression/condition involving a non-volatile, class level value reference?


Just a second. The compiler is not in a position to decide what the programmer meant. Some loops prevent progress upon an incorrect condition. Some loops introduce delays. Which one did the programmer mean? How does this differ from a case where the programmer simply made a mistake and the condition is not meant to become true? 

I have a question, too. Will a programmer not use j.u.c.locks.Condition or just Object.wait in the body of the loop? Will the programmer not follow the recommendations you quote, if they have no time to learn the subject and become comfortable juggling volatiles?



    > In C all loops terminate, so a C programmer may be astonished that the loop you gave as an example does anything at all, if we throw away everything out of the loop body. A Python or Javascript programmer may be astonished that that loop ever terminates, because it never yields control to a routine that mutates the flag.

    Depending on ones background, you could be used to something like green threads of old.  You could just be guessing that there is an interrupt/timer thing that calls out to other code like the V8 runtime does.

    > A Rust programmer may be surprised that it compiles - mutability is not a given.

    And this is more precisely the type of thing that I am trying to speak to.  I don’t know a lot about Rust, because I haven’t been able to make time to dive in and use it for something significant.  But my casual knowledge of it, informs me that people are actually trying to make safe software systems by eliminating all of the things that “runtime”, “compiler” and “extensions” to software systems can hide form the user and invalidate their software without them knowing it.

    If the compiler is going to hoist a value, and it’s part of a control statement that would be invalidated by the hoist, it seems like warning the developer of the mis-declaration or use of concurrent access might be prudent so that they can understand what is being overlooked in the current software design.  What would happen to large java applications if the java compiler did this today?  Would we find bugs?  I am going to bet that we would find lots of non-volatile use that is not valid, technically, but works practically because of the compiler not being able to reach a conclusion allowing it to hoist the read.  So, due to the use of fences for so many other things, there is an implicit cache coherency state that allows a write to be read across thread boundaries and everyone is happy because all tests past.


Sure thing. But as anyone who tried to convince Agda that the function does what its specification says, can tell you, it does make mistakes harder to make, but does not make programming correctly easier.

In Java we are in the situation where there is no formal proof that your program makes no sense. So it is easy to create nonsense, and impossible to automatically check that something is nonsense.


Alex


    Gregg Wonderly


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Olivier Peyrusse via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 10:38
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Olivier Peyrusse <kineolyan@protonmail.com>

If I may chime in, even if I am not a Swing developer, I find the policy of "final or volatile" a bit strange. It gives a false sense of security as it seems that the only way volatile really help is for boolean, while a standard `this.i += 1` will often fail.
I may be inspired / tainted by functional languages where immutability is everywhere, but I would have stick to a rule like "final primitive fields or final Atomic classes". This way, you must explicitly deal with updates, not to painfully using the series of updateAndGet.
And it seems to be suggested in your linked document, though solutions with volatile are present a lot. I would have thought that one starts using volatile when they see performance issue with "safer" methods. But it this moment, one stops being a beginner and dives into Java concurrency :)

Have a nice day
Olivier Peyrusse

‐‐‐‐‐‐‐ Original Message ‐‐‐‐‐‐‐
Le mercredi 21 juillet 2021 à 11:14 AM, Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> a écrit :

> At various times over the years, I’ve met people who have talked about this issue and their own practical problems around non-volatile being the default. In several cases, they have told me that they’ve just adopted the practice that in any class they create (even outside of Swing use), class level declarations should either by final, or volatile.  The final fields are objects that manage concurrency themselves, or are primitive types that are parameters to constructors or are otherwise immutable.  The other fields are declared volatile because then if the user of the class uses it in more than one thread, the values of such fields will readily escape hoisted references or writes to those fields will not be missed by subsequent reads.  In many cases, this can result in data races, but for things that are atomically assigned or referenced values, this at least keeps sanity in the usage, and for non-atomic assignment/reference, one can observe the value changing erratically at least to then have a problem to solve that generally will require Atomic<T> to be used.
>
> This document, https://apps.dtic.mil/sti/pdfs/ADA528370.pdf, describes all of the details around the fragility of non-volatile values in various ways and usages.  I think everyone here would agree with the observations there and the examples readily describe the pitfalls of non-volatile values.   These scenarios illustrate examples of non-volatile use including the text around section 2.1.1, which is the structure that I’ve illustrated and discussed here.  It’s a specific example that it well recognized and documented.
>
> Gregg Wonderly
>
>> On Jul 20, 2021, at 6:18 PM, Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>
>> I was able to reproduce the problem by changing the example code to have an empty loop body. It now looks like this:
>>
>>  while (!done) {}
>>  tm.setText("" + new java.util.Date());
>>
>> A new user might not understand the benefit of adding the sleep in the loop, but adding that back in does prevent hoisting.
>>
>> I don't think the problem is totally made up. I've worked with new and experienced programmers who make mistakes like this, and it's not at all obvious why this is a problem.
>>
>>
>> On 2021-07-20 02:38 PM, Alex Otenko wrote:
>>> I think the problem is totally made up. You can't be using Swing, and not know about threads. Thread safety clauses are all over documentation for components. The hoist that Gregg has an issue with can happen only if non-thread-safe methods are used. Other methods are likely using locks inside, so even though not synchronized properly, the hoisting in question simply cannot happen.
>>> I was hoping to see a working example that shows otherwise.
>>> Alex
>>> On Tue, 20 Jul 2021, 21:47 Brian S O'Neill via Concurrency-interest, <concurrency-interest@cs.oswego.edu <mailto:concurrency-interest@cs.oswego.edu>> wrote:
>>>    This is a continuation of the "Are there real use cases with the Java
>>>    access modes?", but in a separate discussion thread to maintain
>>>    focus on
>>>    what I feel is the crux of the matter.
>>>    Gregg pointed out a potential problem that can affect new Java users
>>>    when writing desktop applications. In particular, one thread can set a
>>>    shared "isDone" field, and another thread might never observe this. In
>>>    practice, the specific example which was provided wouldn't actually
>>>    have
>>>    a problem, but knowing why this is the case isn't something that a new
>>>    Java user would have any knowledge of. In other languages/frameworks,
>>>    users don't need to understand concurrency except as an advanced topic.
>>>    The suggested solution is to require that all fields be volatile as
>>>    default. This naturally causes a knee-jerk reaction to anyone who wants
>>>    the Java platform to be concurrent and highly efficient. And for those
>>>    of us who mostly write server-side applications, we don't understand
>>>    why
>>>    this change is needed at all. After all, there's a bunch of modern
>>>    async/task scheduling frameworks available that allow new users to
>>>    write
>>>    safe, efficient, and completely non-surprising programs.
>>>    New users of Swing/AWT don't have this luxury. And to them, Java ==
>>>    Swing, and so any problems in Swing are equivalent to problems in Java
>>>    itself.
>>>    Would declaring all fields as volatile actually fix Swing? Not really.
>>>    Consider the case in which one thread does this:
>>>       isDone = true;
>>>       doneMessage = "all done!";
>>>    Both fields are volatile, and both are thus visible to other threads.
>>>    Except what I did is wrong, and it's not obvious to a new user. In
>>>    their
>>>    head, they think, "this task is done, and the message is 'all
>>>    done'". So
>>>    naturally the code should be written the same way. In almost all cases,
>>>    this works just fine. Randomly it fails, and now you have to explain to
>>>    the new user the concepts of concurrency, sequential consistency, etc.
>>>    If Swing/AWT was designed around a "pure" event loop, then all tasks
>>>    run
>>>    atomically, and so the order in which fields are assigned isn't
>>>    relevant. They don't need to be volatile either. If the event loop
>>>    implementation wants to use multiple threads, then it's responsible for
>>>    using the correct thread-safe constructs and memory barriers to prevent
>>>    strange issues from cropping up.
>>>    Modern frameworks exist on the server side to do just this, but have
>>>    they been adapted for writing desktop apps? Is there an alternative to
>>>    Swing/AWT? If not, my hope is that someone reading this becomes
>>>    inspired
>>>    to write such a thing. In the past, this seemed quite scary because it
>>>    would likely involve a bunch of JNI coding. Hopefully the Panama
>>>    project
>>>    will take the sting out of this.
>>>    By the way, I know very little about "real world" Swing
>>>    applications. My
>>>    understanding of the issues might be wrong, so please be nice!
>>>    _______________________________________________
>>>    Concurrency-interest mailing list
>>>    Concurrency-interest@cs.oswego.edu
>>>    <mailto:Concurrency-interest@cs.oswego.edu>
>>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>    <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest@cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 11:33
To: concurrency-interest@cs.oswego.edu
Reply-To: Andrew Haley <aph@redhat.com>

On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

> > Sounds like a job for a linter.  For easier cases, an easy PMD rule
> > will catch such a problem.  For harder cases, the PMD rule will need
> > to traverse the call tree to see if a thread executing the loop
> > could change the field.  If not, flag a problem to the programmer.

I suspect that getting this right (no false positives or negatives) is
equivalent to the halting problem, i.e. it's uncomputable. The best
you can say is that if an expression used as the exit condition of a
loop has a term hoisted from memory, the loop might not terminate.

However, while linting for that provides some information to the naive
programmer, it "solves" the problem of infinite loops but ignores
silently returning false results.

-- Andrew Haley (he/him) Java Platform Lead Engineer Red Hat UK Ltd. <https://www.redhat.com> https://keybase.io/andrewhaley EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671 _______________________________________________ Concurrency-interest mailing list Concurrency-interest@cs.oswego.edu http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 12:38
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Even though we've beaten this topic to death several times over, and perhaps some already find the discussion overlong, let me point out one last observation.

Your claim about the level of ignorance is incompatible with your own view of the principle of least astonishment. Here's how.

The "problematic" hoist can happen only if the loop body has no interaction with the other threads, *and* there is no modification of the loop variable inside the loop body. So, if the programmer, no matter how naive, has not put any expression that may modify the loop exit condition, he either is not surprised at the loop being infinite, or is aware of concurrency - the condition being updated by some mechanism that us not described by the syntactic order of expressions.

Granted, a novice cannot put it in such words, but still, you can no longer insist that they are blissfully unaware of concurrency, because for the thing to work, they have to rely on it in their minds.

There may be some surprise, but that is the surprise of a learner finding out how it works, not a programmer that is surprised at the thing not working as written - because the interaction bit is *not* written.


Alex


On Wed, 21 Jul 2021, 16:26 Gregg Wonderly, <gergg@cox.net> wrote:



    > On Jul 21, 2021, at 4:11 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
    > The principle of least astonishment is misapplied, too. Astonishment to whom?

    The programmer is surprised by an optimization that happens at one point in the code due to the relationship and exact nature of code elsewhere in the block.  Automated hoisting of references is certainly a great optimization for things that are being computed with, but a ’truth’ or ‘control’ statement implies that mutation would have to happen.  In the very specific case of a loop, would the programmer really be purposefully creating an infinite loop with an expression/condition involving a non-volatile, class level value reference?

    > In C all loops terminate, so a C programmer may be astonished that the loop you gave as an example does anything at all, if we throw away everything out of the loop body. A Python or Javascript programmer may be astonished that that loop ever terminates, because it never yields control to a routine that mutates the flag.

    Depending on ones background, you could be used to something like green threads of old.  You could just be guessing that there is an interrupt/timer thing that calls out to other code like the V8 runtime does.

    > A Rust programmer may be surprised that it compiles - mutability is not a given.

    And this is more precisely the type of thing that I am trying to speak to.  I don’t know a lot about Rust, because I haven’t been able to make time to dive in and use it for something significant.  But my casual knowledge of it, informs me that people are actually trying to make safe software systems by eliminating all of the things that “runtime”, “compiler” and “extensions” to software systems can hide form the user and invalidate their software without them knowing it.

    If the compiler is going to hoist a value, and it’s part of a control statement that would be invalidated by the hoist, it seems like warning the developer of the mis-declaration or use of concurrent access might be prudent so that they can understand what is being overlooked in the current software design.  What would happen to large java applications if the java compiler did this today?  Would we find bugs?  I am going to bet that we would find lots of non-volatile use that is not valid, technically, but works practically because of the compiler not being able to reach a conclusion allowing it to hoist the read.  So, due to the use of fences for so many other things, there is an implicit cache coherency state that allows a write to be read across thread boundaries and everyone is happy because all tests past.

    Gregg Wonderly



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 15:44
To: Andrew Haley <aph@redhat.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.

Consider this code...

private boolean quit;

while (!quit)
{
   createRandomAlgorithmInPforNP();

   if (doesAlgorithmWork())
   {
      quit = true;
   } 
}

The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.

But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.

On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

    > Sounds like a job for a linter.  For easier cases, an easy PMD rule
    > will catch such a problem.  For harder cases, the PMD rule will need
    > to traverse the call tree to see if a thread executing the loop
    > could change the field.  If not, flag a problem to the programmer.

    I suspect that getting this right (no false positives or negatives) is
    equivalent to the halting problem, i.e. it's uncomputable. The best
    you can say is that if an expression used as the exit condition of a
    loop has a term hoisted from memory, the loop might not terminate.

    However, while linting for that provides some information to the naive
    programmer, it "solves" the problem of infinite loops but ignores
    silently returning false results.

    -- 
    Andrew Haley  (he/him)
    Java Platform Lead Engineer
    Red Hat UK Ltd. <https://www.redhat.com>
    https://keybase.io/andrewhaley
    EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 16:35
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 22, 2021, at 4:38 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > Even though we've beaten this topic to death several times over, and perhaps some already find the discussion overlong, let me point out one last observation.
> > 
> > Your claim about the level of ignorance is incompatible with your own view of the principle of least astonishment. Here's how.
> > 
> > The "problematic" hoist can happen only if the loop body has no interaction with the other threads, *and* there is no modification of the loop variable inside the loop body. So, if the programmer, no matter how naive, has not put any expression that may modify the loop exit condition, he either is not surprised at the loop being infinite, or is aware of concurrency - the condition being updated by some mechanism that us not described by the syntactic order of expressions.

It’s not concurrency that I am talking about specifically around ignorance.  It’s volatile vs non-volatile.  Yes, they may know that some how the listener/notification/callback is involved to set done = true.  But the implementation of how that happens, is not directly visible.  Specifically, they are using some “platform” or “package” of software that has all these APIs that provide for listener/callback/notification and how those things are invoked and with what thread, and what HB conditions exist, including fences, is not in any code they write explicitly.  Thus, they are not thinking about this nor have any real knowledge about what to think about, nor what to exhaustively search through to discover why their loop is not exiting.

The web page I included in an earlier post at .mil demonstrates that there are a huge number of "non-volatile by default" considerations that are thought to be extremely important to know about.  Had non-volatile been the default, with a ‘local’ or ‘unshared’ keyword used instead, we’d have a whole different set of APIs that were created around efficient sharing of data, with hoisting and the lot being explicitly described by the software keywords, constructs and architecture.  It’s that explicit designation of behavior that would make it so much easier to know what was going to happen around optimizations and performance improvements.  

For me, there is no way to look at a class with class level variables and not conclude that each of those values is shared across 1 or more methods as long lived values.  The point of them existing at that declaration level, is to make them persistent across method calls (shared access by one or more threads at any moment).  This is why I keep suggesting that this behavior of non-sharing/non-volatile behavior, by default, for class level values is not really making sense to the whole notion of Java being a multi-threaded language.  When you use multiple threads, you either need to distribute work for performance or isolate work for simplified concurrency as the AWT event queue does.  The listeners are the path between the two thread groups involved, and sharing data values is trivially done in listener method implementations.  That’s the mistake people readily make.

I am sorry that you find my argument inconsistent or imperfect.  I’d like you to not be lured down that path of argument, because then I feel like I have to repeat myself with different words because you’re distracted by my word choices or are logically bothered by them at any rate.

> > Granted, a novice cannot put it in such words, but still, you can no longer insist that they are blissfully unaware of concurrency, because for the thing to work, they have to rely on it in their minds.

Again, its not really “concurrency” but the fact that “volatile” is not the default and non-volatile values create the lack of sharing across threads as a seamless form of communications.  You have to thus know about volatile to make references work across thread groups.

Because this is about a non-volatile field reference, we can’t event change the declaration to:

AtomicBoolean done = new AtomicBoolean();

I.e. even this seemly concurrency ready class can’t solve the problem of reference hoisting.  We have to know that volatile is required, and it’s that specific knowledge that I want to keep the conversation focused on.

> > There may be some surprise, but that is the surprise of a learner finding out how it works, not a programmer that is surprised at the thing not working as written - because the interaction bit is *not* written.
> > 
> > 
> > Alex
> > 

Gregg Wonderly

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 16:37
To: Nathan Reynolds <numeralnathan@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

I think the problem is still the halting problem. You only have the text of the program, and you need to decide not only that quit=true exists, but that it is reachable from the loop body.

There are trivial cases where you can do this, but the world is full of nontrivial things. Say, createRandom...NP sets quit=true. Now what? Say, a subclass overrides createRandom...NP. Now what? Say, you call someone that has reference to this, and calls createRandom...NP. Now what? Is it the same instance or not?

Etc, etc, etc

The bottom line is: often there is no simple answer to a complex problem, and infinitely often there is no answer.

Alex 


On Thu, 22 Jul 2021, 13:46 Nathan Reynolds via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

    It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.

    Consider this code...

    private boolean quit;

    while (!quit)
    {
       createRandomAlgorithmInPforNP();

       if (doesAlgorithmWork())
       {
          quit = true;
       } 
    }

    The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.

    But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.

    On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

        On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

        > Sounds like a job for a linter.  For easier cases, an easy PMD rule
        > will catch such a problem.  For harder cases, the PMD rule will need
        > to traverse the call tree to see if a thread executing the loop
        > could change the field.  If not, flag a problem to the programmer.

        I suspect that getting this right (no false positives or negatives) is
        equivalent to the halting problem, i.e. it's uncomputable. The best
        you can say is that if an expression used as the exit condition of a
        loop has a term hoisted from memory, the loop might not terminate.

        However, while linting for that provides some information to the naive
        programmer, it "solves" the problem of infinite loops but ignores
        silently returning false results.

        -- 
        Andrew Haley  (he/him)
        Java Platform Lead Engineer
        Red Hat UK Ltd. <https://www.redhat.com>
        https://keybase.io/andrewhaley
        EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Swing/AWT concurrency
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 16:41
To: Olivier Peyrusse <kineolyan@protonmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> On Jul 22, 2021, at 2:38 AM, Olivier Peyrusse <kineolyan@protonmail.com> wrote:
>
> If I may chime in, even if I am not a Swing developer, I find the policy of "final or volatile" a bit strange. It gives a false sense of security as it seems that the only way volatile really help is for boolean, while a standard `this.i += 1` will often fail.

It’s really any object reference.  If you replaced “this.i” with “someClassField.i”, you’d have the same problem with ‘someClassField' being hoisted.  A set of radio buttons, or a dropdown or some other GUI selection might change what 'someClassField’ is referencing and create a different visible problem where now the GUI is modifying the wrong data for the selection. A concurrency “class” doesn’t solve the problem of reference hoisting.  Only volatile can do that.

> I may be inspired / tainted by functional languages where immutability is everywhere, but I would have stick to a rule like "final primitive fields or final Atomic classes". This way, you must explicitly deal with updates, not to painfully using the series of updateAndGet.
> And it seems to be suggested in your linked document, though solutions with volatile are present a lot. I would have thought that one starts using volatile when they see performance issue with "safer" methods. But it this moment, one stops being a beginner and dives into Java concurrency :)

Since only volatile solves the problem of reference hoisting, that’s why the linked document is so huge and so full of many examples of where you can git bitten by this.

Gregg Wonderly

> Have a nice day
> Olivier Peyrusse
>
> ‐‐‐‐‐‐‐ Original Message ‐‐‐‐‐‐‐
> Le mercredi 21 juillet 2021 à 11:14 AM, Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> a écrit :
>
>> At various times over the years, I’ve met people who have talked about this issue and their own practical problems around non-volatile being the default. In several cases, they have told me that they’ve just adopted the practice that in any class they create (even outside of Swing use), class level declarations should either by final, or volatile.  The final fields are objects that manage concurrency themselves, or are primitive types that are parameters to constructors or are otherwise immutable.  The other fields are declared volatile because then if the user of the class uses it in more than one thread, the values of such fields will readily escape hoisted references or writes to those fields will not be missed by subsequent reads.  In many cases, this can result in data races, but for things that are atomically assigned or referenced values, this at least keeps sanity in the usage, and for non-atomic assignment/reference, one can observe the value changing erratically at least to then have a problem to solve that generally will require Atomic<T> to be used.
>>
>> This document, https://apps.dtic.mil/sti/pdfs/ADA528370.pdf, describes all of the details around the fragility of non-volatile values in various ways and usages.  I think everyone here would agree with the observations there and the examples readily describe the pitfalls of non-volatile values.   These scenarios illustrate examples of non-volatile use including the text around section 2.1.1, which is the structure that I’ve illustrated and discussed here.  It’s a specific example that it well recognized and documented.
>>
>> Gregg Wonderly
>>
>>> On Jul 20, 2021, at 6:18 PM, Brian S O'Neill via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>>>
>>> I was able to reproduce the problem by changing the example code to have an empty loop body. It now looks like this:
>>>
>>>  while (!done) {}
>>>  tm.setText("" + new java.util.Date());
>>>
>>> A new user might not understand the benefit of adding the sleep in the loop, but adding that back in does prevent hoisting.
>>>
>>> I don't think the problem is totally made up. I've worked with new and experienced programmers who make mistakes like this, and it's not at all obvious why this is a problem.
>>>
>>>
>>> On 2021-07-20 02:38 PM, Alex Otenko wrote:
>>>> I think the problem is totally made up. You can't be using Swing, and not know about threads. Thread safety clauses are all over documentation for components. The hoist that Gregg has an issue with can happen only if non-thread-safe methods are used. Other methods are likely using locks inside, so even though not synchronized properly, the hoisting in question simply cannot happen.
>>>> I was hoping to see a working example that shows otherwise.
>>>> Alex
>>>> On Tue, 20 Jul 2021, 21:47 Brian S O'Neill via Concurrency-interest, <concurrency-interest@cs.oswego.edu <mailto:concurrency-interest@cs.oswego.edu>> wrote:
>>>>    This is a continuation of the "Are there real use cases with the Java
>>>>    access modes?", but in a separate discussion thread to maintain
>>>>    focus on
>>>>    what I feel is the crux of the matter.
>>>>    Gregg pointed out a potential problem that can affect new Java users
>>>>    when writing desktop applications. In particular, one thread can set a
>>>>    shared "isDone" field, and another thread might never observe this. In
>>>>    practice, the specific example which was provided wouldn't actually
>>>>    have
>>>>    a problem, but knowing why this is the case isn't something that a new
>>>>    Java user would have any knowledge of. In other languages/frameworks,
>>>>    users don't need to understand concurrency except as an advanced topic.
>>>>    The suggested solution is to require that all fields be volatile as
>>>>    default. This naturally causes a knee-jerk reaction to anyone who wants
>>>>    the Java platform to be concurrent and highly efficient. And for those
>>>>    of us who mostly write server-side applications, we don't understand
>>>>    why
>>>>    this change is needed at all. After all, there's a bunch of modern
>>>>    async/task scheduling frameworks available that allow new users to
>>>>    write
>>>>    safe, efficient, and completely non-surprising programs.
>>>>    New users of Swing/AWT don't have this luxury. And to them, Java ==
>>>>    Swing, and so any problems in Swing are equivalent to problems in Java
>>>>    itself.
>>>>    Would declaring all fields as volatile actually fix Swing? Not really.
>>>>    Consider the case in which one thread does this:
>>>>       isDone = true;
>>>>       doneMessage = "all done!";
>>>>    Both fields are volatile, and both are thus visible to other threads.
>>>>    Except what I did is wrong, and it's not obvious to a new user. In
>>>>    their
>>>>    head, they think, "this task is done, and the message is 'all
>>>>    done'". So
>>>>    naturally the code should be written the same way. In almost all cases,
>>>>    this works just fine. Randomly it fails, and now you have to explain to
>>>>    the new user the concepts of concurrency, sequential consistency, etc.
>>>>    If Swing/AWT was designed around a "pure" event loop, then all tasks
>>>>    run
>>>>    atomically, and so the order in which fields are assigned isn't
>>>>    relevant. They don't need to be volatile either. If the event loop
>>>>    implementation wants to use multiple threads, then it's responsible for
>>>>    using the correct thread-safe constructs and memory barriers to prevent
>>>>    strange issues from cropping up.
>>>>    Modern frameworks exist on the server side to do just this, but have
>>>>    they been adapted for writing desktop apps? Is there an alternative to
>>>>    Swing/AWT? If not, my hope is that someone reading this becomes
>>>>    inspired
>>>>    to write such a thing. In the past, this seemed quite scary because it
>>>>    would likely involve a bunch of JNI coding. Hopefully the Panama
>>>>    project
>>>>    will take the sting out of this.
>>>>    By the way, I know very little about "real world" Swing
>>>>    applications. My
>>>>    understanding of the issues might be wrong, so please be nice!
>>>>    _______________________________________________
>>>>    Concurrency-interest mailing list
>>>>    Concurrency-interest@cs.oswego.edu
>>>>    <mailto:Concurrency-interest@cs.oswego.edu>
>>>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>    <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest@cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 17:39
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

JIT has to decide if the loop condition can be hoisted.  JIT halts the hoisting optimization even on the world "full of nontrivial things"... and if not the JIT team gets a bug to fix.  Hence, I suspect JIT is conservative on how deep it tries to examine to figure out if the condition can be hoisted.  I suspect that when JIT does not know what the destination is (e.g. Runnable.run()), then it halts.

So, the PMD rule needs to be at least as good as JIT at determining if the variable can be hoisted.  This will prevent unintentional infinite loops at run time.  If the PMD rule is better than JIT, then that is just a bonus for the programmer.  I suspect the PMD rule can be better than JIT.  If I understand correctly, JIT is limited to looking at what is inlined due to runtime constraints.  PMD can has the time to go much deeper.  Also, if the loop calls Runnable.run(), then PMD can look at all classes that implement Runnable.  Yes, this will mean false negatives, but as long as it is better than JIT who cares.

If the PMD rule cannot be as good as JIT, then the PMD rule will catch most unintentional infinite loops and has a few false negatives for the nontrivial things.  This is much better than no PMD rule.  However, for those that use Graal, the PMD rule can be just as good as Graal since Graal produces a single executable (i.e. a closed system).

On Thu, Jul 22, 2021 at 7:38 AM Alex Otenko <oleksandr.otenko@gmail.com> wrote:

    I think the problem is still the halting problem. You only have the text of the program, and you need to decide not only that quit=true exists, but that it is reachable from the loop body.

    There are trivial cases where you can do this, but the world is full of nontrivial things. Say, createRandom...NP sets quit=true. Now what? Say, a subclass overrides createRandom...NP. Now what? Say, you call someone that has reference to this, and calls createRandom...NP. Now what? Is it the same instance or not?

    Etc, etc, etc

    The bottom line is: often there is no simple answer to a complex problem, and infinitely often there is no answer.

    Alex 


    On Thu, 22 Jul 2021, 13:46 Nathan Reynolds via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

        It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.

        Consider this code...

        private boolean quit;

        while (!quit)
        {
           createRandomAlgorithmInPforNP();

           if (doesAlgorithmWork())
           {
              quit = true;
           } 
        }

        The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.

        But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.

        On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

            On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

            > Sounds like a job for a linter.  For easier cases, an easy PMD rule
            > will catch such a problem.  For harder cases, the PMD rule will need
            > to traverse the call tree to see if a thread executing the loop
            > could change the field.  If not, flag a problem to the programmer.

            I suspect that getting this right (no false positives or negatives) is
            equivalent to the halting problem, i.e. it's uncomputable. The best
            you can say is that if an expression used as the exit condition of a
            loop has a term hoisted from memory, the loop might not terminate.

            However, while linting for that provides some information to the naive
            programmer, it "solves" the problem of infinite loops but ignores
            silently returning false results.

            -- 
            Andrew Haley  (he/him)
            Java Platform Lead Engineer
            Red Hat UK Ltd. <https://www.redhat.com>
            https://keybase.io/andrewhaley
            EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest

        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Joe Bowbeer via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 22:15
To: Nathan Reynolds <numeralnathan@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Joe Bowbeer <joe.bowbeer@gmail.com>

In my 20+ years of reviewing Java code, my best indicator (red flag) for the presence of bugs has been the existence of synchronized methods and/or volatile fields.

Programming concurrency at this low level (in Java) is for experts only; whenever mere mortals try it, I can almost guarantee that I will find a bug.

The only hope for beginners is to leverage single-threaded subsystems and higher-level concurrency patterns.

In summary, making volatile the default would make it harder for me to find bugs 😀

On Thu, Jul 22, 2021 at 7:40 AM Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

    JIT has to decide if the loop condition can be hoisted.  JIT halts the hoisting optimization even on the world "full of nontrivial things"... and if not the JIT team gets a bug to fix.  Hence, I suspect JIT is conservative on how deep it tries to examine to figure out if the condition can be hoisted.  I suspect that when JIT does not know what the destination is (e.g. Runnable.run()), then it halts.

    So, the PMD rule needs to be at least as good as JIT at determining if the variable can be hoisted.  This will prevent unintentional infinite loops at run time.  If the PMD rule is better than JIT, then that is just a bonus for the programmer.  I suspect the PMD rule can be better than JIT.  If I understand correctly, JIT is limited to looking at what is inlined due to runtime constraints.  PMD can has the time to go much deeper.  Also, if the loop calls Runnable.run(), then PMD can look at all classes that implement Runnable.  Yes, this will mean false negatives, but as long as it is better than JIT who cares.

    If the PMD rule cannot be as good as JIT, then the PMD rule will catch most unintentional infinite loops and has a few false negatives for the nontrivial things.  This is much better than no PMD rule.  However, for those that use Graal, the PMD rule can be just as good as Graal since Graal produces a single executable (i.e. a closed system).

    On Thu, Jul 22, 2021 at 7:38 AM Alex Otenko <oleksandr.otenko@gmail.com> wrote:

        I think the problem is still the halting problem. You only have the text of the program, and you need to decide not only that quit=true exists, but that it is reachable from the loop body.

        There are trivial cases where you can do this, but the world is full of nontrivial things. Say, createRandom...NP sets quit=true. Now what? Say, a subclass overrides createRandom...NP. Now what? Say, you call someone that has reference to this, and calls createRandom...NP. Now what? Is it the same instance or not?

        Etc, etc, etc

        The bottom line is: often there is no simple answer to a complex problem, and infinitely often there is no answer.

        Alex 


        On Thu, 22 Jul 2021, 13:46 Nathan Reynolds via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

            It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.

            Consider this code...

            private boolean quit;

            while (!quit)
            {
               createRandomAlgorithmInPforNP();

               if (doesAlgorithmWork())
               {
                  quit = true;
               } 
            }

            The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.

            But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.

            On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

                On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

                > Sounds like a job for a linter.  For easier cases, an easy PMD rule
                > will catch such a problem.  For harder cases, the PMD rule will need
                > to traverse the call tree to see if a thread executing the loop
                > could change the field.  If not, flag a problem to the programmer.

                I suspect that getting this right (no false positives or negatives) is
                equivalent to the halting problem, i.e. it's uncomputable. The best
                you can say is that if an expression used as the exit condition of a
                loop has a term hoisted from memory, the loop might not terminate.

                However, while linting for that provides some information to the naive
                programmer, it "solves" the problem of infinite loops but ignores
                silently returning false results.

                -- 
                Andrew Haley  (he/him)
                Java Platform Lead Engineer
                Red Hat UK Ltd. <https://www.redhat.com>
                https://keybase.io/andrewhaley
                EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

                _______________________________________________
                Concurrency-interest mailing list
                Concurrency-interest@cs.oswego.edu
                http://cs.oswego.edu/mailman/listinfo/concurrency-interest

            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 22:43
To: Nathan Reynolds <numeralnathan@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

JIT can speculate (as we've seen a spectacular example of recently) and recompile. This alone makes PMD's task intractable.

Alex

On Thu, 22 Jul 2021, 15:39 Nathan Reynolds, <numeralnathan@gmail.com> wrote:

    JIT has to decide if the loop condition can be hoisted.  JIT halts the hoisting optimization even on the world "full of nontrivial things"... and if not the JIT team gets a bug to fix.  Hence, I suspect JIT is conservative on how deep it tries to examine to figure out if the condition can be hoisted.  I suspect that when JIT does not know what the destination is (e.g. Runnable.run()), then it halts.

    So, the PMD rule needs to be at least as good as JIT at determining if the variable can be hoisted.  This will prevent unintentional infinite loops at run time.  If the PMD rule is better than JIT, then that is just a bonus for the programmer.  I suspect the PMD rule can be better than JIT.  If I understand correctly, JIT is limited to looking at what is inlined due to runtime constraints.  PMD can has the time to go much deeper.  Also, if the loop calls Runnable.run(), then PMD can look at all classes that implement Runnable.  Yes, this will mean false negatives, but as long as it is better than JIT who cares.

    If the PMD rule cannot be as good as JIT, then the PMD rule will catch most unintentional infinite loops and has a few false negatives for the nontrivial things.  This is much better than no PMD rule.  However, for those that use Graal, the PMD rule can be just as good as Graal since Graal produces a single executable (i.e. a closed system).

    On Thu, Jul 22, 2021 at 7:38 AM Alex Otenko <oleksandr.otenko@gmail.com> wrote:

        I think the problem is still the halting problem. You only have the text of the program, and you need to decide not only that quit=true exists, but that it is reachable from the loop body.

        There are trivial cases where you can do this, but the world is full of nontrivial things. Say, createRandom...NP sets quit=true. Now what? Say, a subclass overrides createRandom...NP. Now what? Say, you call someone that has reference to this, and calls createRandom...NP. Now what? Is it the same instance or not?

        Etc, etc, etc

        The bottom line is: often there is no simple answer to a complex problem, and infinitely often there is no answer.

        Alex 


        On Thu, 22 Jul 2021, 13:46 Nathan Reynolds via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

            It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.

            Consider this code...

            private boolean quit;

            while (!quit)
            {
               createRandomAlgorithmInPforNP();

               if (doesAlgorithmWork())
               {
                  quit = true;
               } 
            }

            The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.

            But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.

            On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

                On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

                > Sounds like a job for a linter.  For easier cases, an easy PMD rule
                > will catch such a problem.  For harder cases, the PMD rule will need
                > to traverse the call tree to see if a thread executing the loop
                > could change the field.  If not, flag a problem to the programmer.

                I suspect that getting this right (no false positives or negatives) is
                equivalent to the halting problem, i.e. it's uncomputable. The best
                you can say is that if an expression used as the exit condition of a
                loop has a term hoisted from memory, the loop might not terminate.

                However, while linting for that provides some information to the naive
                programmer, it "solves" the problem of infinite loops but ignores
                silently returning false results.

                -- 
                Andrew Haley  (he/him)
                Java Platform Lead Engineer
                Red Hat UK Ltd. <https://www.redhat.com>
                https://keybase.io/andrewhaley
                EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

                _______________________________________________
                Concurrency-interest mailing list
                Concurrency-interest@cs.oswego.edu
                http://cs.oswego.edu/mailman/listinfo/concurrency-interest

            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest@cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-22, 23:29
To: Joe Bowbeer <joe.bowbeer@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> On Jul 22, 2021, at 2:15 PM, Joe Bowbeer via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
> In my 20+ years of reviewing Java code, my best indicator (red flag) for the presence of bugs has been the existence of synchronized methods and/or volatile fields.
>
> Programming concurrency at this low level (in Java) is for experts only; whenever mere mortals try it, I can almost guarantee that I will find a bug.

The basic issue is that any mutating value, whether it’s a native type or an object reference, when shared across threads, is going to require volatile or synchronized access control, to make it’s use work within a loop, or multiple consecutive accesses in the same block when reference/value hoisting is possible.  For me, this is the “giant problem”.  To make simple “sharing” possible, you have to know that volatile/synchronized is imperative, but only is the case of “multiple” references (loop or within a block) does it become a visible roadblock.  It works everywhere else, because the compiler can’t say “only one thread does this” when a block has “one" reference to a class field, and thus a hoist doesn’t “occur” right?

In the case of a block with multiple, consecutive access to the same reference/value, there’s a mixed set of circumstances involved where many actions that would require a new reference to be retrieved, the JIT does this because it sees an HB event.

> The only hope for beginners is to leverage single-threaded subsystems and higher-level concurrency patterns.

This is what many people rely on, but as my example “how-to not do bad things” linked document shows, there are countless examples, where such patterns must be used and codified in reusable ways.  The problem with “random” java written by beginners is that it’s possible to experience problems because you aren’t using a concurrency proficient platform.

> In summary, making volatile the default would make it harder for me to find bugs 😀

I can chuckle at that, but it’s hard to have a straight face about it! :-)

Gregg Wonderly

>
> On Thu, Jul 22, 2021 at 7:40 AM Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>     JIT has to decide if the loop condition can be hoisted.  JIT halts the hoisting optimization even on the world "full of nontrivial things"... and if not the JIT team gets a bug to fix.  Hence, I suspect JIT is conservative on how deep it tries to examine to figure out if the condition can be hoisted.  I suspect that when JIT does not know what the destination is (e.g. Runnable.run()), then it halts.
>
>     So, the PMD rule needs to be at least as good as JIT at determining if the variable can be hoisted.  This will prevent unintentional infinite loops at run time.  If the PMD rule is better than JIT, then that is just a bonus for the programmer.  I suspect the PMD rule can be better than JIT.  If I understand correctly, JIT is limited to looking at what is inlined due to runtime constraints.  PMD can has the time to go much deeper.  Also, if the loop calls Runnable.run(), then PMD can look at all classes that implement Runnable.  Yes, this will mean false negatives, but as long as it is better than JIT who cares.
>
>     If the PMD rule cannot be as good as JIT, then the PMD rule will catch most unintentional infinite loops and has a few false negatives for the nontrivial things.  This is much better than no PMD rule.  However, for those that use Graal, the PMD rule can be just as good as Graal since Graal produces a single executable (i.e. a closed system).
>
>     On Thu, Jul 22, 2021 at 7:38 AM Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
>         I think the problem is still the halting problem. You only have the text of the program, and you need to decide not only that quit=true exists, but that it is reachable from the loop body.
>
>         There are trivial cases where you can do this, but the world is full of nontrivial things. Say, createRandom...NP sets quit=true. Now what? Say, a subclass overrides createRandom...NP. Now what? Say, you call someone that has reference to this, and calls createRandom...NP. Now what? Is it the same instance or not?
>
>         Etc, etc, etc
>
>         The bottom line is: often there is no simple answer to a complex problem, and infinitely often there is no answer.
>
>         Alex 
>
>
>         On Thu, 22 Jul 2021, 13:46 Nathan Reynolds via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:
>
>             It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.
>
>             Consider this code...
>
>             private boolean quit;
>
>             while (!quit)
>             {
>                createRandomAlgorithmInPforNP();
>
>                if (doesAlgorithmWork())
>                {
>                   quit = true;
>                } 
>             }
>
>             The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.
>
>             But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.
>
>             On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>
>                 On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:
>
>                 > Sounds like a job for a linter.  For easier cases, an easy PMD rule
>                 > will catch such a problem.  For harder cases, the PMD rule will need
>                 > to traverse the call tree to see if a thread executing the loop
>                 > could change the field.  If not, flag a problem to the programmer.
>
>                 I suspect that getting this right (no false positives or negatives) is
>                 equivalent to the halting problem, i.e. it's uncomputable. The best
>                 you can say is that if an expression used as the exit condition of a
>                 loop has a term hoisted from memory, the loop might not terminate.
>
>                 However, while linting for that provides some information to the naive
>                 programmer, it "solves" the problem of infinite loops but ignores
>                 silently returning false results.
>
>                 -- 
>                 Andrew Haley  (he/him)
>                 Java Platform Lead Engineer
>                 Red Hat UK Ltd. <https://www.redhat.com>
>                 https://keybase.io/andrewhaley
>                 EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
>
>                 _______________________________________________
>                 Concurrency-interest mailing list
>                 Concurrency-interest@cs.oswego.edu
>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest@cs.oswego.edu
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest@cs.oswego.edu
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 00:18
To: Joe Bowbeer <joe.bowbeer@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

:) concurrency libraries create a sense of security.

But in the end you have to tackle ordering of events, possible interleavings, lifetimes and ownership of things become unclear, who owns errors, and how to get them to the correct place in the right order. To say nothing of expression problem: loops are replaced with chains of events, and become indistinguishable from recursion.

So you get rid of a lot of support the language provides for you, all for the security through obscurity.

In other words, race conditions happen even in single-threaded languages like javascript or python.

Alex

On Thu, 22 Jul 2021, 20:15 Joe Bowbeer, <joe.bowbeer@gmail.com> wrote:

    In my 20+ years of reviewing Java code, my best indicator (red flag) for the presence of bugs has been the existence of synchronized methods and/or volatile fields.

    Programming concurrency at this low level (in Java) is for experts only; whenever mere mortals try it, I can almost guarantee that I will find a bug.

    The only hope for beginners is to leverage single-threaded subsystems and higher-level concurrency patterns.

    In summary, making volatile the default would make it harder for me to find bugs 😀

    On Thu, Jul 22, 2021 at 7:40 AM Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

        JIT has to decide if the loop condition can be hoisted.  JIT halts the hoisting optimization even on the world "full of nontrivial things"... and if not the JIT team gets a bug to fix.  Hence, I suspect JIT is conservative on how deep it tries to examine to figure out if the condition can be hoisted.  I suspect that when JIT does not know what the destination is (e.g. Runnable.run()), then it halts.

        So, the PMD rule needs to be at least as good as JIT at determining if the variable can be hoisted.  This will prevent unintentional infinite loops at run time.  If the PMD rule is better than JIT, then that is just a bonus for the programmer.  I suspect the PMD rule can be better than JIT.  If I understand correctly, JIT is limited to looking at what is inlined due to runtime constraints.  PMD can has the time to go much deeper.  Also, if the loop calls Runnable.run(), then PMD can look at all classes that implement Runnable.  Yes, this will mean false negatives, but as long as it is better than JIT who cares.

        If the PMD rule cannot be as good as JIT, then the PMD rule will catch most unintentional infinite loops and has a few false negatives for the nontrivial things.  This is much better than no PMD rule.  However, for those that use Graal, the PMD rule can be just as good as Graal since Graal produces a single executable (i.e. a closed system).

        On Thu, Jul 22, 2021 at 7:38 AM Alex Otenko <oleksandr.otenko@gmail.com> wrote:

            I think the problem is still the halting problem. You only have the text of the program, and you need to decide not only that quit=true exists, but that it is reachable from the loop body.

            There are trivial cases where you can do this, but the world is full of nontrivial things. Say, createRandom...NP sets quit=true. Now what? Say, a subclass overrides createRandom...NP. Now what? Say, you call someone that has reference to this, and calls createRandom...NP. Now what? Is it the same instance or not?

            Etc, etc, etc

            The bottom line is: often there is no simple answer to a complex problem, and infinitely often there is no answer.

            Alex 


            On Thu, 22 Jul 2021, 13:46 Nathan Reynolds via Concurrency-interest, <concurrency-interest@cs.oswego.edu> wrote:

                It is not quite the halting problem.  The halting problem asks if the computation ends.  The PMD rule asks if among the many branches inside the loop's call tree if the exit variable is set.  It does not care if the branch is never taken.

                Consider this code...

                private boolean quit;

                while (!quit)
                {
                   createRandomAlgorithmInPforNP();

                   if (doesAlgorithmWork())
                   {
                      quit = true;
                   } 
                }

                The method createRandomAlgorithmInPforNP() creates a random algorithm that runs in polynomial time and hopefully solves a NP problem.  The method doesAlgorithmWork() tests the created algorithm to see if it works.  This is an example of a halting problem.  We don't 100% know if an algorithm will ever be found and hence if the loop will run forever.

                But, this does not matter for the PMD rule.  The PMD rule only cares that there is a "quit = true" in the loop body (or in the call tree).  Why?  The PMD rule is looking to see if "while (!quit)" can be hoisted out of the loop thus creating an infinite loop.  It will execute the same logic that JIT does to determine if "while (!quit)" can be hoisted.  We have working code (i.e. JIT) that we can use to implement the PMD rule.

                On Thu, Jul 22, 2021 at 2:35 AM Andrew Haley via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:

                    On 7/21/21 4:50 PM, Nathan Reynolds via Concurrency-interest wrote:

                    > Sounds like a job for a linter.  For easier cases, an easy PMD rule
                    > will catch such a problem.  For harder cases, the PMD rule will need
                    > to traverse the call tree to see if a thread executing the loop
                    > could change the field.  If not, flag a problem to the programmer.

                    I suspect that getting this right (no false positives or negatives) is
                    equivalent to the halting problem, i.e. it's uncomputable. The best
                    you can say is that if an expression used as the exit condition of a
                    loop has a term hoisted from memory, the loop might not terminate.

                    However, while linting for that provides some information to the naive
                    programmer, it "solves" the problem of infinite loops but ignores
                    silently returning false results.

                    -- 
                    Andrew Haley  (he/him)
                    Java Platform Lead Engineer
                    Red Hat UK Ltd. <https://www.redhat.com>
                    https://keybase.io/andrewhaley
                    EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

                    _______________________________________________
                    Concurrency-interest mailing list
                    Concurrency-interest@cs.oswego.edu
                    http://cs.oswego.edu/mailman/listinfo/concurrency-interest

                _______________________________________________
                Concurrency-interest mailing list
                Concurrency-interest@cs.oswego.edu
                http://cs.oswego.edu/mailman/listinfo/concurrency-interest

        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest@cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 06:29
To: Valentin Kovalenko <valentin.male.kovalenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> On Jul 19, 2021, at 11:01 AM, Valentin Kovalenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> There is only one explanation I can think of with regard to how the code in the listener added via `addActionListener` can be run: by a `java.lang.Thread` different from the one running `main` and blocked in `open` (this statement remains true even if one thinks about the project Loom). If an engineer writing the code like that does not even question himself about how can this application in principle be run in a single thread (that's the assumption in the example), then eliminating some optimizations that clearly do not violate JMM helps nothing. That same engineer can then pass between threads not a single `boolean`, but a more complex piece of data the same way with the same assumption (that there is only one thread), and be surprised to the same extent to observe not the piece of data that was shared. In fact, I think that the more often incorrectly synchronized code fails, the more likely it is that the author will discover and fix the bug, potentially improving his understanding along the way.

Those here, have this thought process already burned into our heads.  It seems likely to people who have experience in computer science training and more formal exposure to concurrent software systems.   The audience I am trying to point out would have little chance to understand these details.  They understand logic, and can readily read documentation that they can find.  The “hole” I am trying to illustrate is that the requirement for volatile, as the least amount of actual code to make this example work, is not something they would readily know to specify in a google search even.  If you try yourself to search for “loop doesn’t exit” or “java loop doesn’t exit” you will be hard pressed to find discussion of volatile, based on what I’ve experienced trying to see if there is something that I’ve just missed out on.  Instead, you have to know that the key is to include volatile.  If you don’t specify ‘java’ in your search, you’ll get tons of results about C#, C++ and C ahead of Java, and the example is about stopping a thread by monitoring a boolean, not ending a stuck loop, but it does include volatile use which may be instructive (https://www.java67.com/2015/07/how-to-stop-thread-in-java-example.html).

Is there anything else I haven’t beat to death about this?

Gregg

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 06:36
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: Joe Bowbeer <joe.bowbeer@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 22, 2021, at 4:18 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > 🙂 concurrency libraries create a sense of security.
> > 
> > But in the end you have to tackle ordering of events, possible interleavings, lifetimes and ownership of things become unclear, who owns errors, and how to get them to the correct place in the right order. To say nothing of expression problem: loops are replaced with chains of events, and become indistinguishable from recursion.
> > 
> > So you get rid of a lot of support the language provides for you, all for the security through obscurity.
> > 
> > In other words, race conditions happen even in single-threaded languages like javascript or python.

The subtle detail is that volatile data races show you everything that can happen without hiding the fact that you have data races.  non-volatile data races behave beyond recognition of the actual cause in many cases, which is precisely why we have so many concurrency libraries that make people feel more secure in the use of concurrent programming, after they’ve encountered completely random behavior not using them, or trying to roll their own.  Truly, it takes pretty extreme expertise and experience to truly understand how to use Java to do concurrent programming.  That’s the point that I am trying to discuss and illustrate with a simple one way data sharing example that rather than acting like a multi instruction write revealing corrupted pointers/values, it just doesn’t execute as you’d expect from reading the logical flow of the code.  That, for many people that I’ve watched debug code they’ve never seen, is what causes great pause and confusion.  

Gregg Wonderly

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 12:14
To: Gregg Wonderly <gergg@cox.net>, Alex Otenko <oleksandr.otenko@gmail.com>
CC: Joe Bowbeer <joe.bowbeer@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Andrew Dinn <adinn@redhat.com>

On 23/07/2021 04:36, Gregg Wonderly via Concurrency-interest

> Truly, it takes pretty extreme expertise and experience to truly
> understand how to [use Java to] do concurrent programming.

Let's just note that if you take out the bracketed phrase that statement still remains true.

I think the real point you are trying to make here is that insertion of that qualifying phrase referencing Java makes a /significant/ difference, whether that's just modulo the general problem or modulo some specific alternative language (or Java variant) that you want to offer as an inprovement. Over the years I have written a lot of concurrent and parallel code in a lot of different languages and I have to disagree with your contention on two grounds.

1) I have invariably found that almost all of the difficulty in concurrent/parallel programming is to do with the concurrency not the language in which the program is encoded. Fixating on the details of a language encoding is something beginners do because they don't know how to think about concurrency problems in the abstract, independent of the language they are using. However, they are seriously missing the point in being so fixated because the lesson to be learnt from writing a parallel/concurrent program is not how to encode it in language X but how any encoding one comes up with embodies a solution that (as is almost invariably the case) transcends the specifics of language X.

2) Horses for courses is also an edge effect. While some languages do indeed make management of the concurrency/parallelism easier they often do so at the cost of making other goals much harder. In the worst case a clear concurrency model can cost al of the performance gains the concurrency primitives are there to provide. For example, I worked on the implementation of a parallel logic language 30 years ago that was wonderfully transparent as far as modelling concurrency was concerned, most especially for problems with irregular parallel decompositons. Unfortunately, achieving high speed-up on multi-core machines was extremely difficult because the language was /too/ parallel. Efficient local scheduling of operations with good data locality was extremely hard to achieve. By contrast, parallel Fortran enables very good localization of computation and data accesses but only for tasks that decompose (and recompose) regularly.

Your mileage may vary, naturally.

regards,


Andrew Dinn
-----------
Red Hat Distinguished Engineer
Red Hat UK Ltd
Registered in England and Wales under Company Registration No. 03798903
Directors: Michael Cunningham, Michael ("Mike") O'Neill

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 18:24
To: Andrew Dinn <adinn@redhat.com>
CC: Joe Bowbeer <joe.bowbeer@gmail.com>, concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 23, 2021, at 4:14 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > On 23/07/2021 04:36, Gregg Wonderly via Concurrency-interest
> > 
>> >> Truly, it takes pretty extreme expertise and experience to truly
>> >> understand how to [use Java to] do concurrent programming.
> > 
> > Let's just note that if you take out the bracketed phrase that statement still remains true.

I added that phrase because my experience with concurrency inside of Java programs is the largest exposure I have.  But that is dated compared to my use of multi-threaded application in C/C++ that I’ve recently been involved in.  In those cases, there is no worry about non-volatile hoisting doesn’t occur at all.  Data races are specifically because of lack of inter-thread mediation of access.  The language just doesn’t specify that this is possible.  Instruction scheduling compilers do exist, and have for some time for those languages.  I used one on my Amiga with a Motorolla 68040 in the early 1990’s.  That’s a aged and ever-present technology today, but because of small block construction of much software, it rarely has an opportunity to fully utilize an extra ALU, but still we have hyper threaded processors trying to provide that capability.

> > I think the real point you are trying to make here is that insertion of that qualifying phrase referencing Java makes a /significant/ difference, whether that's just modulo the general problem or modulo some specific alternative language (or Java variant) that you want to offer as an inprovement. Over the years I have written a lot of concurrent and parallel code in a lot of different languages and I have to disagree with your contention on two grounds.

Non-volatile by default with hoisting being performed makes a significant difference in how your code is compiled and thus how it is executed and the locality of logic changes that you may not be directly aware of due to the logic of the software as visibly coded.

> > 
> > 1) I have invariably found that almost all of the difficulty in concurrent/parallel programming is to do with the concurrency not the language in which the program is encoded. Fixating on the details of a language encoding is something beginners do because they don't know how to think about concurrency problems in the abstract, independent of the language they are using. However, they are seriously missing the point in being so fixated because the lesson to be learnt from writing a parallel/concurrent program is not how to encode it in language X but how any encoding one comes up with embodies a solution that (as is almost invariably the case) transcends the specifics of language X.

Yes, but as we all may have learned in college classes, there are well known algorithms (codified in java.util.concurrent) for managing data sharing across threads.  That’s fine and dandy stuff.  However the mere presence of “volatile” vs “non-volatile” references has little to do with concurrency, but rather asynchronous behaviors, no matter how they are controlled/initiated. What I mean, is that if you had a boolean in a class, and provided a JNI method to pass the class reference into some C-language software that setup a hardware interrupt that would dispatch into that C code, and the C code then called back through JNI to set the boolean, and you are on a single core processor, that’s a “thread of execution” and concurrent behavior, but it’s the stuff that has been done for ages, and in C and C++ there has never been hoisting and the changes that Java’s non-volatile default presents, is a completely different behavior.  This is the surprise.  It’s not something explicitly requested, but rather something implicitly part of the language and it’s completely different to what most people have experienced in other languages.

Concurrency through the use of well known patterns allows all kinds of sharing and not-sharing references to be managed.  The fact that Java, as a concurrent language, chose to not share data by default is the detail.  The SPARC hardware memory model was the weakest.  It had better throughput because Sun optimized the JVM to allow that to happen.  The JMM  largely reflects the need to have a weak memory model in the processor.  The JMM presses parts of hardware design up into the software systems design where the concurrency libraries have to manipulate hardware features (happens before requirements) to make memory references work correctly.

> > 2) Horses for courses is also an edge effect. While some languages do indeed make management of the concurrency/parallelism easier they often do so at the cost of making other goals much harder. In the worst case a clear concurrency model can cost al of the performance gains the concurrency primitives are there to provide.

This is the reason why the JMM was an important thing to have.  It provides a behavior specification that is independent of the hardware implementation mostly, but does require some memory consistency constraints necessary for happens-before to work.

> > For example, I worked on the implementation of a parallel logic language 30 years ago that was wonderfully transparent as far as modelling concurrency was concerned, most especially for problems with irregular parallel decompositons. Unfortunately, achieving high speed-up on multi-core machines was extremely difficult because the language was /too/ parallel. Efficient local scheduling of operations with good data locality was extremely hard to achieve. By contrast, parallel Fortran enables very good localization of computation and data accesses but only for tasks that decompose (and recompose) regularly.

One of the interesting things about Fortran is the type of application that it usually is used for.  Lots of math operations do allow instruction scheduling to be taken care of more readily.  When I worked at Bell Labs on the 5ESS software project, in the early 1990s, their compiler team was thinking about adding instruction scheduling when they were switching to use the 68040.  I had talked to them about having an Amiga with a 68040 and a scheduling compiler.  They asked me to compile some of the 5ESS code to see what the compiler could do with it.  They were concerned that the number of “if” statements and other conditional logic around the “audit” subsystem implementation would not really allow scheduling to be very effective.  It was clear after showing them diffs, that it was hard to schedule things.  But, I did find an assembly statement in the memory checksumming code where they had used LD R1,0 instead of CLR R1.  Making that change was a huge reduction in CPU “busy” work alone.

I completely understand all the desires around performance not being impacted.  So realistically, removing non-volatile as a default is not an ideal thing.  I’ve been suggesting at least context sensitive warnings about the hoisting actually invalidating the software as coded.  This is not a simple deal, thanks for your insights into this and providing some prodding to think about the bigger picture.  

I am still interested in figuring out whether there is some useful strategy of inspection that can allow developers to be warned readily of the misuse of non-volatile values when their intention is volatile/sharing of references.

Gregg Wonderly

> > 
> > Your mileage may vary, naturally.
> > 
> > regards,
> > 
> > 
> > Andrew Dinn
> > -----------
> > Red Hat Distinguished Engineer
> > Red Hat UK Ltd
> > Registered in England and Wales under Company Registration No. 03798903
> > Directors: Michael Cunningham, Michael ("Mike") O'Neill
> > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 22:31
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>



On Fri, 23 Jul 2021, 16:24 Gregg Wonderly, <gergg@cox.net> wrote:



    > On Jul 23, 2021, at 4:14 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
    >
    > On 23/07/2021 04:36, Gregg Wonderly via Concurrency-interest
    >
    >> Truly, it takes pretty extreme expertise and experience to truly
    >> understand how to [use Java to] do concurrent programming.
    >
    > Let's just note that if you take out the bracketed phrase that statement still remains true.

    I added that phrase because my experience with concurrency inside of Java programs is the largest exposure I have.  But that is dated compared to my use of multi-threaded application in C/C++ that I’ve recently been involved in.  In those cases, there is no worry about non-volatile hoisting doesn’t occur at all.  


I am sorry to burst your bubble...

http://eel.is/c++draft/intro.progress

Quote:
The implementation may assume that any thread will eventually do one of the following:

    (1.1)
    terminate,
    (1.2)
    make a call to a library I/O function,
    (1.3)
    perform an access through a volatile glvalue, or
    (1.4)
    perform a synchronization operation or an atomic operation.

[Note 1: 
This is intended to allow compiler transformations such as removal of empty loops, even when termination cannot be proven.
 — end note]

Alex


    Data races are specifically because of lack of inter-thread mediation of access.  The language just doesn’t specify that this is possible.  Instruction scheduling compilers do exist, and have for some time for those languages.  I used one on my Amiga with a Motorolla 68040 in the early 1990’s.  That’s a aged and ever-present technology today, but because of small block construction of much software, it rarely has an opportunity to fully utilize an extra ALU, but still we have hyper threaded processors trying to provide that capability.

    > I think the real point you are trying to make here is that insertion of that qualifying phrase referencing Java makes a /significant/ difference, whether that's just modulo the general problem or modulo some specific alternative language (or Java variant) that you want to offer as an inprovement. Over the years I have written a lot of concurrent and parallel code in a lot of different languages and I have to disagree with your contention on two grounds.

    Non-volatile by default with hoisting being performed makes a significant difference in how your code is compiled and thus how it is executed and the locality of logic changes that you may not be directly aware of due to the logic of the software as visibly coded.

    >
    > 1) I have invariably found that almost all of the difficulty in concurrent/parallel programming is to do with the concurrency not the language in which the program is encoded. Fixating on the details of a language encoding is something beginners do because they don't know how to think about concurrency problems in the abstract, independent of the language they are using. However, they are seriously missing the point in being so fixated because the lesson to be learnt from writing a parallel/concurrent program is not how to encode it in language X but how any encoding one comes up with embodies a solution that (as is almost invariably the case) transcends the specifics of language X.

    Yes, but as we all may have learned in college classes, there are well known algorithms (codified in java.util.concurrent) for managing data sharing across threads.  That’s fine and dandy stuff.  However the mere presence of “volatile” vs “non-volatile” references has little to do with concurrency, but rather asynchronous behaviors, no matter how they are controlled/initiated. What I mean, is that if you had a boolean in a class, and provided a JNI method to pass the class reference into some C-language software that setup a hardware interrupt that would dispatch into that C code, and the C code then called back through JNI to set the boolean, and you are on a single core processor, that’s a “thread of execution” and concurrent behavior, but it’s the stuff that has been done for ages, and in C and C++ there has never been hoisting and the changes that Java’s non-volatile default presents, is a completely different behavior.  This is the surprise.  It’s not something explicitly requested, but rather something implicitly part of the language and it’s completely different to what most people have experienced in other languages.

    Concurrency through the use of well known patterns allows all kinds of sharing and not-sharing references to be managed.  The fact that Java, as a concurrent language, chose to not share data by default is the detail.  The SPARC hardware memory model was the weakest.  It had better throughput because Sun optimized the JVM to allow that to happen.  The JMM  largely reflects the need to have a weak memory model in the processor.  The JMM presses parts of hardware design up into the software systems design where the concurrency libraries have to manipulate hardware features (happens before requirements) to make memory references work correctly.

    > 2) Horses for courses is also an edge effect. While some languages do indeed make management of the concurrency/parallelism easier they often do so at the cost of making other goals much harder. In the worst case a clear concurrency model can cost al of the performance gains the concurrency primitives are there to provide.

    This is the reason why the JMM was an important thing to have.  It provides a behavior specification that is independent of the hardware implementation mostly, but does require some memory consistency constraints necessary for happens-before to work.

    > For example, I worked on the implementation of a parallel logic language 30 years ago that was wonderfully transparent as far as modelling concurrency was concerned, most especially for problems with irregular parallel decompositons. Unfortunately, achieving high speed-up on multi-core machines was extremely difficult because the language was /too/ parallel. Efficient local scheduling of operations with good data locality was extremely hard to achieve. By contrast, parallel Fortran enables very good localization of computation and data accesses but only for tasks that decompose (and recompose) regularly.

    One of the interesting things about Fortran is the type of application that it usually is used for.  Lots of math operations do allow instruction scheduling to be taken care of more readily.  When I worked at Bell Labs on the 5ESS software project, in the early 1990s, their compiler team was thinking about adding instruction scheduling when they were switching to use the 68040.  I had talked to them about having an Amiga with a 68040 and a scheduling compiler.  They asked me to compile some of the 5ESS code to see what the compiler could do with it.  They were concerned that the number of “if” statements and other conditional logic around the “audit” subsystem implementation would not really allow scheduling to be very effective.  It was clear after showing them diffs, that it was hard to schedule things.  But, I did find an assembly statement in the memory checksumming code where they had used LD R1,0 instead of CLR R1.  Making that change was a huge reduction in CPU “busy” work alone.

    I completely understand all the desires around performance not being impacted.  So realistically, removing non-volatile as a default is not an ideal thing.  I’ve been suggesting at least context sensitive warnings about the hoisting actually invalidating the software as coded.  This is not a simple deal, thanks for your insights into this and providing some prodding to think about the bigger picture. 

    I am still interested in figuring out whether there is some useful strategy of inspection that can allow developers to be warned readily of the misuse of non-volatile values when their intention is volatile/sharing of references.

    Gregg Wonderly

    >
    > Your mileage may vary, naturally.
    >
    > regards,
    >
    >
    > Andrew Dinn
    > -----------
    > Red Hat Distinguished Engineer
    > Red Hat UK Ltd
    > Registered in England and Wales under Company Registration No. 03798903
    > Directors: Michael Cunningham, Michael ("Mike") O'Neill
    >
    > _______________________________________________
    > Concurrency-interest mailing list
    > Concurrency-interest@cs.oswego.edu
    > http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-23, 23:02
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> On Jul 23, 2021, at 2:31 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> On Fri, 23 Jul 2021, 16:24 Gregg Wonderly, <gergg@cox.net> wrote:
>
>
>
>     > On Jul 23, 2021, at 4:14 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>     > 
>     > On 23/07/2021 04:36, Gregg Wonderly via Concurrency-interest
>     > 
>     >> Truly, it takes pretty extreme expertise and experience to truly
>     >> understand how to [use Java to] do concurrent programming.
>     > 
>     > Let's just note that if you take out the bracketed phrase that statement still remains true.
>
>     I added that phrase because my experience with concurrency inside of Java programs is the largest exposure I have.  But that is dated compared to my use of multi-threaded application in C/C++ that I’ve recently been involved in.  In those cases, there is no worry about non-volatile hoisting doesn’t occur at all.  
>
>
> I am sorry to burst your bubble...
>
> http://eel.is/c++draft/intro.progress
>
> Quote:
> The implementation may assume that any thread will eventually do one of the following:
>
>     (1.1)
>     terminate,
>     (1.2)
>     make a call to a library I/O function,
>     (1.3)
>     perform an access through a volatile glvalue, or
>     (1.4)
>     perform a synchronization operation or an atomic operation.
>
> [Note 1: 
> This is intended to allow compiler transformations such as removal of empty loops, even when termination cannot be proven.
>  — end note]

Empty loop optimizations have been around for a long time.  I suppose you may be trying to tell me that there’s all kinds of places in all kinds of ways that your code may disappear or executed differently than you expect?

Gregg Wonderly


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-24, 08:18
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Yes. It depends on what you think an empty loop is.

char odd(int x){
  for(;;){
    x++;
    if(!x) return 1;
    x++;
  }
}

Oops, this can tell you that 2 is an odd number. But you can prove x never becomes 0 for even inputs. How's that for the least astonishment? 

Alex

On Fri, 23 Jul 2021, 21:02 Gregg Wonderly, <gergg@cox.net> wrote:



>     On Jul 23, 2021, at 2:31 PM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>     On Fri, 23 Jul 2021, 16:24 Gregg Wonderly, <gergg@cox.net> wrote:
>
>
>
>         > On Jul 23, 2021, at 4:14 AM, Andrew Dinn via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>         > 
>         > On 23/07/2021 04:36, Gregg Wonderly via Concurrency-interest
>         > 
>         >> Truly, it takes pretty extreme expertise and experience to truly
>         >> understand how to [use Java to] do concurrent programming.
>         > 
>         > Let's just note that if you take out the bracketed phrase that statement still remains true.
>
>         I added that phrase because my experience with concurrency inside of Java programs is the largest exposure I have.  But that is dated compared to my use of multi-threaded application in C/C++ that I’ve recently been involved in.  In those cases, there is no worry about non-volatile hoisting doesn’t occur at all.  
>
>
>     I am sorry to burst your bubble...
>
>     http://eel.is/c++draft/intro.progress
>
>     Quote:
>     The implementation may assume that any thread will eventually do one of the following:
>
>         (1.1)
>         terminate,
>         (1.2)
>         make a call to a library I/O function,
>         (1.3)
>         perform an access through a volatile glvalue, or
>         (1.4)
>         perform a synchronization operation or an atomic operation.
>
>     [Note 1: 
>     This is intended to allow compiler transformations such as removal of empty loops, even when termination cannot be proven.
>      — end note]

    Empty loop optimizations have been around for a long time.  I suppose you may be trying to tell me that there’s all kinds of places in all kinds of ways that your code may disappear or executed differently than you expect?

    Gregg Wonderly


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-26, 07:46
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 24, 2021, at 12:18 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
> > 
> > Yes. It depends on what you think an empty loop is.
> > 
> > char odd(int x){
> >   for(;;){
> >     x++;
> >     if(!x) return 1;
> >     x++;
> >   }
> > }
> > 
> > Oops, this can tell you that 2 is an odd number. But you can prove x never becomes 0 for even inputs. How's that for the least astonishment? 

I don’t see how this function tests anything about odd.  It should use (x&1) should it not?   I don’t understand what this function is supposed to do.  Why is there a loop?

char odd(int x) { return !(x&1); }

Gregg Wonderly


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-26, 10:06
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

"Don't write the code like that" is what the others said about while(!done), so maybe you can see the point they are making.

As for this example - please take it as an example of code that may not behave as written.

As to why it is written like that - well, it is derived from a more elaborate mutually recursive case (with a bug).

It is perfectly normal to state "zero is even", "x+1 is even, if x is odd", and "x+1 is odd, if x is even". This is a recursive definition that is derived from a recursive definition of natural numbers. It is not complete, but you can't tell if you don't have the compiler that will tell you that.

So you have:

char odd(int x){return even(x-1);}
char even(int x){return !x || odd(x-1);}

Inline even into odd, do tail call optimization, and you end up with a loop like that (ok, x--, not x++). Both of these steps is what modern clang, gcc and llvm do.

Alex

On Mon, 26 Jul 2021, 05:46 Gregg Wonderly, <gergg@cox.net> wrote:



    > On Jul 24, 2021, at 12:18 AM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
    >
    > Yes. It depends on what you think an empty loop is.
    >
    > char odd(int x){
    >   for(;;){
    >     x++;
    >     if(!x) return 1;
    >     x++;
    >   }
    > }
    >
    > Oops, this can tell you that 2 is an odd number. But you can prove x never becomes 0 for even inputs. How's that for the least astonishment?

    I don’t see how this function tests anything about odd.  It should use (x&1) should it not?   I don’t understand what this function is supposed to do.  Why is there a loop?

    char odd(int x) { return !(x&1); }

    Gregg Wonderly



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-27, 01:27
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> > On Jul 26, 2021, at 2:06 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
> > 
> > "Don't write the code like that" is what the others said about while(!done), so maybe you can see the point they are making.
> > 
> > As for this example - please take it as an example of code that may not behave as written.
> > 
> > As to why it is written like that - well, it is derived from a more elaborate mutually recursive case (with a bug).
> > 
> > It is perfectly normal to state "zero is even", "x+1 is even, if x is odd", and "x+1 is odd, if x is even". This is a recursive definition that is derived from a recursive definition of natural numbers. It is not complete, but you can't tell if you don't have the compiler that will tell you that.
> > 
> > So you have:
> > 
> > char odd(int x){return even(x-1);}
> > char even(int x){return !x || odd(x-1);}
> > 
> > Inline even into odd, do tail call optimization, and you end up with a loop like that (ok, x--, not x++). Both of these steps is what modern clang, gcc and llvm do

Yes, but this is broken because you can only call even() on evens and odd() on odds for it to work.  But the tail recursion resolution on a -O compilation never loops and just results in a bogus ‘1’ return for all cases.  With -g, you get infinite recursion that crashes with a stack explosion.  You can debug this and see what’s happening.

I’m still completely focused on the fact that the hoist of the loop condition makes the code into an infinite loop that you can’t observe, readily, why a value of done=true doesn’t cause the loop to exit.  What you can observe in the value of done should cause the loop to exit.  It’s subtly different in my consideration, but it looks like its a bug because you can’t see the code that is executing incorrectly.  With this example you show, you can put printf in even() and odd(), see the values of x, and notice how you end up in odd() with x==0 when you call even() with an odd value or odd() with an even value and thus the bug occurs.

Gregg Wonderly



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-27, 07:46
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Alex Otenko <oleksandr.otenko@gmail.com>

Well, you made a statement that the hoist of this kind never happens in C. It's not true. All I did is found a bizarre example where even worse things happen.

Alex

On Mon, 26 Jul 2021, 23:27 Gregg Wonderly, <gergg@cox.net> wrote:



    > On Jul 26, 2021, at 2:06 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
    >
    > "Don't write the code like that" is what the others said about while(!done), so maybe you can see the point they are making.
    >
    > As for this example - please take it as an example of code that may not behave as written.
    >
    > As to why it is written like that - well, it is derived from a more elaborate mutually recursive case (with a bug).
    >
    > It is perfectly normal to state "zero is even", "x+1 is even, if x is odd", and "x+1 is odd, if x is even". This is a recursive definition that is derived from a recursive definition of natural numbers. It is not complete, but you can't tell if you don't have the compiler that will tell you that.
    >
    > So you have:
    >
    > char odd(int x){return even(x-1);}
    > char even(int x){return !x || odd(x-1);}
    >
    > Inline even into odd, do tail call optimization, and you end up with a loop like that (ok, x--, not x++). Both of these steps is what modern clang, gcc and llvm do

    Yes, but this is broken because you can only call even() on evens and odd() on odds for it to work.  But the tail recursion resolution on a -O compilation never loops and just results in a bogus ‘1’ return for all cases.  With -g, you get infinite recursion that crashes with a stack explosion.  You can debug this and see what’s happening.

    I’m still completely focused on the fact that the hoist of the loop condition makes the code into an infinite loop that you can’t observe, readily, why a value of done=true doesn’t cause the loop to exit.  What you can observe in the value of done should cause the loop to exit.  It’s subtly different in my consideration, but it looks like its a bug because you can’t see the code that is executing incorrectly.  With this example you show, you can put printf in even() and odd(), see the values of x, and notice how you end up in odd() with x==0 when you call even() with an odd value or odd() with an even value and thus the bug occurs.

    Gregg Wonderly




_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-27, 17:57
To: Alex Otenko <oleksandr.otenko@gmail.com>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Gregg Wonderly <gergg@cox.net>



> On Jul 26, 2021, at 11:46 PM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
> Well, you made a statement that the hoist of this kind never happens in C. It's not true. All I did is found a bizarre example where even worse things happen.

You are calling them worse. They are at least debuggable.  You can use cc -S to stare at the code generated and see that the loop disappears.

I said this example was not the same because it’s a logic error that can be debugged to understand what is happening.  I'd take a C/C++ program and compile it with -g to have symbol and line number information.  This allows you to debug this code. The optimizer disappears from view and the loop comes back.  What I stated about C++ specifically is that the loop control expression is not hoisted out of the loop and evaluated once, turning the loop into a while(true){} condition that never exits and which a debugger can never show you the problem because it’s not a logic or data race, it’s an optimization that invalidates the way the code is written.

If the dev adds logging or other printing debugging, the JIT stops the hoist in many cases, and thus it looks like something is happening with the “compiler” breaking the code, which it is.  But, the user has no idea that ‘volatile’ is required unless they’ve had exposure to the details around the whole set of optimizations with fences, cache lines and the like.   I am contesting that being a precursor to getting working code, plain and simple.  Why is understanding hardware ever a consideration for correct logic to operate?  Optimization yes, working code, I feel it’s really a detracting ‘feature’ of the JIT.

Gregg

>
> On Mon, 26 Jul 2021, 23:27 Gregg Wonderly, <gergg@cox.net> wrote:
>
>
>
>     > On Jul 26, 2021, at 2:06 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>     >
>     > "Don't write the code like that" is what the others said about while(!done), so maybe you can see the point they are making.
>     >
>     > As for this example - please take it as an example of code that may not behave as written.
>     >
>     > As to why it is written like that - well, it is derived from a more elaborate mutually recursive case (with a bug).
>     >
>     > It is perfectly normal to state "zero is even", "x+1 is even, if x is odd", and "x+1 is odd, if x is even". This is a recursive definition that is derived from a recursive definition of natural numbers. It is not complete, but you can't tell if you don't have the compiler that will tell you that.
>     >
>     > So you have:
>     >
>     > char odd(int x){return even(x-1);}
>     > char even(int x){return !x || odd(x-1);}
>     >
>     > Inline even into odd, do tail call optimization, and you end up with a loop like that (ok, x--, not x++). Both of these steps is what modern clang, gcc and llvm do
>
>     Yes, but this is broken because you can only call even() on evens and odd() on odds for it to work.  But the tail recursion resolution on a -O compilation never loops and just results in a bogus ‘1’ return for all cases.  With -g, you get infinite recursion that crashes with a stack explosion.  You can debug this and see what’s happening.
>
>     I’m still completely focused on the fact that the hoist of the loop condition makes the code into an infinite loop that you can’t observe, readily, why a value of done=true doesn’t cause the loop to exit.  What you can observe in the value of done should cause the loop to exit.  It’s subtly different in my consideration, but it looks like its a bug because you can’t see the code that is executing incorrectly.  With this example you show, you can put printf in even() and odd(), see the values of x, and notice how you end up in odd() with x==0 when you call even() with an odd value or odd() with an even value and thus the bug occurs.
>
>     Gregg Wonderly
>
>
>


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------------------

Subject: Re: [concurrency-interest] Are there real use cases with the Java access modes?
From: Nathan Reynolds via Concurrency-interest <concurrency-interest@cs.oswego.edu>
Date: 2021-07-27, 22:53
To: Gregg Wonderly <gergg@cox.net>
CC: concurrency-interest <concurrency-interest@cs.oswego.edu>
Reply-To: Nathan Reynolds <numeralnathan@gmail.com>

I brought up creating a PMD rule that traverses the call tree inside the loop looking for the non-volatile field condition to change.  One problem with such a rule is that it wouldn't know how to handle a reflected call or to say Runnable.run().  In these cases, the PMD rule can ignore these calls.  In other words, the rule will decide that the call does not change the condition.

This could result in false positives.  To help the programmer, the PMD rule can show in the message (and Eclipse tooltip) that the problem might be a false positive.  The programmer can then decide if it is a false positive or fix the problem.  These false positives are easily suppressed with a "// NOPMD" comment or @SuppressWarnings("PMD.RuleName").

What percentage of loops have indeterminate calls?

I realize that a non-final method in a non-final class could be an indeterminate call.  At runtime a new class can be introduced that overrides the method and prevents the loop condition field from changing.  I consider this case very rare.  Most programs and servlets are self-contained and all classes are known at build time.

On Tue, Jul 27, 2021 at 8:59 AM Gregg Wonderly via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:



>     On Jul 26, 2021, at 11:46 PM, Alex Otenko <oleksandr.otenko@gmail.com> wrote:
>
>     Well, you made a statement that the hoist of this kind never happens in C. It's not true. All I did is found a bizarre example where even worse things happen.

    You are calling them worse. They are at least debuggable.  You can use cc -S to stare at the code generated and see that the loop disappears.

    I said this example was not the same because it’s a logic error that can be debugged to understand what is happening.  I'd take a C/C++ program and compile it with -g to have symbol and line number information.  This allows you to debug this code. The optimizer disappears from view and the loop comes back.  What I stated about C++ specifically is that the loop control expression is not hoisted out of the loop and evaluated once, turning the loop into a while(true){} condition that never exits and which a debugger can never show you the problem because it’s not a logic or data race, it’s an optimization that invalidates the way the code is written.

    If the dev adds logging or other printing debugging, the JIT stops the hoist in many cases, and thus it looks like something is happening with the “compiler” breaking the code, which it is.  But, the user has no idea that ‘volatile’ is required unless they’ve had exposure to the details around the whole set of optimizations with fences, cache lines and the like.   I am contesting that being a precursor to getting working code, plain and simple.  Why is understanding hardware ever a consideration for correct logic to operate?  Optimization yes, working code, I feel it’s really a detracting ‘feature’ of the JIT.

    Gregg

>
>     On Mon, 26 Jul 2021, 23:27 Gregg Wonderly, <gergg@cox.net> wrote:
>
>
>
>         > On Jul 26, 2021, at 2:06 AM, Alex Otenko via Concurrency-interest <concurrency-interest@cs.oswego.edu> wrote:
>         >
>         > "Don't write the code like that" is what the others said about while(!done), so maybe you can see the point they are making.
>         >
>         > As for this example - please take it as an example of code that may not behave as written.
>         >
>         > As to why it is written like that - well, it is derived from a more elaborate mutually recursive case (with a bug).
>         >
>         > It is perfectly normal to state "zero is even", "x+1 is even, if x is odd", and "x+1 is odd, if x is even". This is a recursive definition that is derived from a recursive definition of natural numbers. It is not complete, but you can't tell if you don't have the compiler that will tell you that.
>         >
>         > So you have:
>         >
>         > char odd(int x){return even(x-1);}
>         > char even(int x){return !x || odd(x-1);}
>         >
>         > Inline even into odd, do tail call optimization, and you end up with a loop like that (ok, x--, not x++). Both of these steps is what modern clang, gcc and llvm do
>
>         Yes, but this is broken because you can only call even() on evens and odd() on odds for it to work.  But the tail recursion resolution on a -O compilation never loops and just results in a bogus ‘1’ return for all cases.  With -g, you get infinite recursion that crashes with a stack explosion.  You can debug this and see what’s happening.
>
>         I’m still completely focused on the fact that the hoist of the loop condition makes the code into an infinite loop that you can’t observe, readily, why a value of done=true doesn’t cause the loop to exit.  What you can observe in the value of done should cause the loop to exit.  It’s subtly different in my consideration, but it looks like its a bug because you can’t see the code that is executing incorrectly.  With this example you show, you can put printf in even() and odd(), see the values of x, and notice how you end up in odd() with x==0 when you call even() with an odd value or odd() with an even value and thus the bug occurs.
>
>         Gregg Wonderly
>
>
>

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest@cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
