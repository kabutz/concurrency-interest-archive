From nabeelalimemon at gmail.com  Tue Nov  1 11:57:05 2011
From: nabeelalimemon at gmail.com (Nabeel Ali Memon)
Date: Tue, 1 Nov 2011 19:57:05 +0400
Subject: [concurrency-interest] java fork-join getting-started notes for
	beginners <-> Java 7
In-Reply-To: <CACSA5wYdH8D+dm2BZoQ0aG7P==51goua7YP-v0r0m-NcJXVd2w@mail.gmail.com>
References: <CADruQ+i74Uxd_pWAQweQf36htJ7H+34=KQtxx7a1wh4GvSyHVg@mail.gmail.com>
	<4E4D6E76.3030800@cs.oswego.edu> <4E4D7428.3090602@univ-mlv.fr>
	<CADruQ+inQ0xdBWX_MiV8wEhyDCWyarwu3uqf7wUaZ1dTC8DwxA@mail.gmail.com>
	<CACSA5wYdH8D+dm2BZoQ0aG7P==51goua7YP-v0r0m-NcJXVd2w@mail.gmail.com>
Message-ID: <B418A00C-3387-47AD-8150-E357480D858A@gmail.com>

Both Intellij Idea (10 and 11 EAP) CE  and Netbeans 7 support Java 7 syntax enhancements. Both are free and stable (except the Intellij 11 EAP of course).


Nabeel
 
On Aug 20, 2011, at 11:35 AM, zuxiong lin wrote:

> Or maybe use Eclipse Juno (4.2) M1.
> 
> The best paractice is like Doug .  Run releases without IDE support.
> 
> 
> 
> 2011/8/19 Dan Grossman <djg at cs.washington.edu>
> Thanks, Remi.  My understanding is that it is fine to ignore this
> warning since using the Java ForkJoin Framework does not require any
> language enhancements.  Ignoring this warning is a small price to pay
> for simple standard installation instructions, and, as you note, the
> warning should go away with a near-term release of Eclipse.
> 
> --Dan
> 
> On Thu, Aug 18, 2011 at 1:20 PM, R?mi Forax <forax at univ-mlv.fr> wrote:
> > Eclipse Indigo's compiler is not updated for Java 7,
> > all language enhancements of Java 7 are not recognized,
> > that's why you have this warning, the release 3.7.1 (not yet release) should
> > be Ok,
> > you can already test the compiler behaviour by installing the 3.8M1.
> >
> > R?mi
> >
> > On 08/18/2011 09:56 PM, Doug Lea wrote:
> >>
> >> On 08/16/11 18:00, Dan Grossman wrote:
> >>>
> >>> Short version:
> >>>
> >>> I'm looking for quick confirmation that using the fork-join framework
> >>> with the Java 7 JRE is just as easy as it seems and that I'm pointing
> >>> students to the right stable versions of things.
> >>
> >> I'm still hoping that someone else replies about most of this,
> >> since I normally experimental run releases without IDE support.
> >> But otherwise -- yes, things should Just Work.
> >>
> >> -Doug
> >>
> >>>
> >>> Long version:
> >>>
> >>> Background:
> >>>
> >>> As I've mentioned on this list a couple times, I've developed a
> >>> course-unit for second-year undergraduates that introduces parallelism
> >>> and concurrency using Java and the Fork-Join Framework (though it's
> >>> not really that Java-specific).  At Washington, we've used this unit
> >>> in our required data-structures course for 1.5 years now and it's been
> >>> picked up by 5 other schools so far.  In all, 10 instructors, most
> >>> non-experts in Java, parallelism, or both have used it and they all
> >>> claim success and, "I will do this again."  For more information,
> >>> http://www.cs.washington.edu/homes/djg/teachingMaterials/spac/
> >>>
> >>> One thing that has proven absolutely essential is step-by-step
> >>> instructions suitable for beginners, specialized to just what they
> >>> need: ForkJoinPool, RecursiveTask, RecursiveAction.  This was
> >>> particularly important for Java 1.6.  The url
> >>>
> >>> http://www.cs.washington.edu/homes/djg/teachingMaterials/spac/grossmanSPAC_forkJoinFramework.html
> >>> has these instructions and was last updated a few months ago.  For
> >>> those of you who have not taught undergraduates, let me assure you
> >>> that there are, nonetheless, a mind-boggling number of ways to enter
> >>> -Xbootclasspath/p:jsr166.jar incorrectly. :-)
> >>>
> >>> So what now:
> >>>
> >>> It seems time to update my step-by-step instructions to say:
> >>>   1. Please use Java 7 following steps a, b, c.
> >>>   2. If you really can't, then here are the more complicated steps for
> >>> using Java 6 following steps, d, e, f, g.
> >>>
> >>> In preparation for this, I downloaded JDK 7 onto a [Windows 7, 64-bit]
> >>> machine that has never had Java on it, installed Eclipse IDE for Java
> >>> Developers, indigo release (my instructions prefer but don't mandate
> >>> eclipse), set the Java Project JRE to JavaSE-1.7, and ran the attached
> >>> file.  It Just Worked.  This is So Wonderful and I send my heartfelt
> >>> appreciation to everyone on this list who helped make it happen.
> >>>
> >>> Now my questions -- I think the answers are all 'yes' but this is the
> >>> place to confirm and I'm most concerned about (C):
> >>>
> >>> A. Java 7: Is this the real deal -- the framework will use the
> >>> available processors and, after suitable VM warmup, be the parallel
> >>> execution engine we expect?
> >>>
> >>> B. Installation: Will upgrading on machines that already have Java 6
> >>> be just as seamless?
> >>>
> >>> C. Code: Is the attached file the way to show things to beginners?
> >>> (Note: My point is to show them the reduction explicitly rather than
> >>> using a library method.  This is for pedagogical purposes.  So no
> >>> complaining about that.)
> >>>
> >>> D. Eclipse: When choosing JavaSE1-1.7, Eclipse Indigo release warns,
> >>> "The 1.7 compiler compliance level
> >>>    is not yet supported.  The new project will use a project specific
> >>> compiler compliance level of 1.6".  Am I correct that this can be
> >>> ignored since I'm not using any new /language/ features, just a new
> >>> /library/? (Note: My understanding is there are Eclipse versions
> >>> available with 1.7 compilers, but if we're okay with the most standard
> >>> most stable Eclipse release, this is extremely helpful.)
> >>>
> >>> E: Anything else I can do to make this as bullet-proof for beginners
> >>> as possible?
> >>>
> >>> Thanks!
> >>>
> >>> --Dan
> >>>
> >>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111101/e9196d5a/attachment.html>

From nathan.reynolds at oracle.com  Mon Nov  7 19:48:12 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 07 Nov 2011 17:48:12 -0700
Subject: [concurrency-interest] Checking for Race Conditions in Concurrent
	Code
In-Reply-To: <4E5BCE50.50205@cs.oswego.edu>
References: <4E5A95E0.1080309@cs.oswego.edu>
	<CAHzJPEoXfdgW3xsVF-AL7995qDAc2G5W9Z_6oA3=eVZAEDEsiw@mail.gmail.com>
	<4E5BCE50.50205@cs.oswego.edu>
Message-ID: <4EB87C4C.5030107@oracle.com>

When writing concurrent code what are some good tools to check for race 
conditions?

I use Java Path Finder.  It allows for testing the Java code without 
converting it into some abstract model.  The challenge is writing useful 
tests which don't take forever to check all of the thread scheduling 
interleavings.  So, I am wondering what other tools exist out there that 
will run very quickly and are very easy to map Java to model.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111107/97b40f0e/attachment.html>

From fslzdd at gmail.com  Tue Nov  8 20:31:51 2011
From: fslzdd at gmail.com (Daniel Luo)
Date: Wed, 9 Nov 2011 09:31:51 +0800
Subject: [concurrency-interest] Checking for Race Conditions in
	Concurrent Code
In-Reply-To: <4EB87C4C.5030107@oracle.com>
References: <4E5A95E0.1080309@cs.oswego.edu>
	<CAHzJPEoXfdgW3xsVF-AL7995qDAc2G5W9Z_6oA3=eVZAEDEsiw@mail.gmail.com>
	<4E5BCE50.50205@cs.oswego.edu> <4EB87C4C.5030107@oracle.com>
Message-ID: <CABBcFj-tzOFDT6H6JF0verVKcFZJ6_pJXxy2H0TY6Bd1_AmHuA@mail.gmail.com>

IBM Multicore Software Development Kit(MSDK) is a full-feature toolkit to
test, debug and profile Java multithreaded applications. It includes an
effective and efficient runtime data race detector that may meet your need.

Sent from Daniel's HTC Android
? 2011-11-8 ??8:50?"Nathan Reynolds" <nathan.reynolds at oracle.com>???

>  When writing concurrent code what are some good tools to check for race
> conditions?
>
> I use Java Path Finder.  It allows for testing the Java code without
> converting it into some abstract model.  The challenge is writing useful
> tests which don't take forever to check all of the thread scheduling
> interleavings.  So, I am wondering what other tools exist out there that
> will run very quickly and are very easy to map Java to model.
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111109/aa04686a/attachment.html>

From nchen.dev at mac.com  Wed Nov  9 10:51:23 2011
From: nchen.dev at mac.com (nchen.dev at mac.com)
Date: Wed, 09 Nov 2011 09:51:23 -0600
Subject: [concurrency-interest] Dataflow/Flow-Based programming Frameworks
	for Java?
Message-ID: <38DA9372-5E40-45CD-87C1-6A3B4D56EF43@mac.com>

Hi

Short version
==========

What are some dataflow/flow-based programming frameworks that this group has used for Java? I know that there is a commercial version (Pervasive Datarush [1]) and there are at least three open source version (GPars [2], Akka [3], Java FBP [4]). I am interested in open source versions because of what I am doing (see below) but it's hard to find real applications written in them. I've only found very simple examples on their websites and other developer blogs/articles.

I'd like to get this group's expert opinions on the following two questions:

1) What are some of the frameworks that this group has used and what are the strengths/weaknesses that you can share?
2) What are some applications that you (or someone you know) have written in those frameworks? Preferably, the source is available so I can take a look and learn from that.

Long version
==========

I'm looking at flow-based applications (content-based image retrieval, data deduplication, signal processing, ETL [5], etc) and trying to look for design patterns on how developers transform their code. After cataloging these patterns I would then try to automate some of the transformations. 

My group and I have already looked at some applications from the PARSEC benchmark suite [6] over summer and have published a paper about our preliminary results [7]. Since PARSEC is written in C/C++ we used Intel TBB which had excellent support for both pipelines and flow graphs. What we discovered is that a library/framework makes the transformation process more convenient, the resulting code more succinct and easier to understand and the performance was on-par with the PThreads version.

Nonetheless, it's hard to write good source-to-source transformation tools for C++ because of all the intricacies of the language. Thus, we have decided to switch to Java because of our familiarity with the Eclipse Refactoring Toolkit and the existing static/dynamic analysis tools for the Java language. One thing that we have trouble finding is a good library/framework for expressing pipeline and flow based applications. We could probably do this from scratch with the Fork/Join framework or ExecutorService but we would rather extend on an existing library that others have found useful.

So any thoughts on frameworks in Java that support expressing these kinds of applications would be appreciated.

Thanks!

--
Nicholas Chen
PhD Candidate
University of Illinois at Urbana-Champaign

[1] http://www.pervasivedatarush.com/
[2] http://gpars.codehaus.org/
[3] http://akka.io/
[4] http://sourceforge.net/projects/flow-based-pgmg/
[5] http://en.wikipedia.org/wiki/Extract,_transform,_load
[6] http://parsec.cs.princeton.edu/
[7] http://tmc.supertriceratops.com/papers/tmc2011-3-Reed.pdf



From mohanr at fss.co.in  Thu Nov 10 06:33:13 2011
From: mohanr at fss.co.in (Mohan Radhakrishnan)
Date: Thu, 10 Nov 2011 17:03:13 +0530
Subject: [concurrency-interest] ConcurrentSkipListMap performance
In-Reply-To: <4EA6E0AE.1060502@oracle.com>
Message-ID: <85BAFD8D7E74D044B0D7245FA572D04B27B857@fssbemail.fss.india>

I found this a section on 'Compilation' in http://www.cs.princeton.edu/picasso/mats/HotspotOverview.pdf that has some details.

 

Thanks,

Mohan

 

________________________________

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Nathan Reynolds
Sent: Tuesday, October 25, 2011 9:46 PM
To: Thorsten M?ller
Cc: concurrency-interest
Subject: Re: [concurrency-interest] ConcurrentSkipListMap performance

 

I turn on HotSpot's -XX:-PrintCompliation and run the warmup and test.  If I see any messages during the actual test (after warmup), then I know I didn't warmup the JVM long enough.

The parameter -XX:CompileThreshold (i.e. optimizer threshold) defaults to 10,000 when using the "-server" flag.  I find that if I run the method under test and all of the test harness code 11,000 times then I don't see any compiler (optimizer) messages during my test.  I also put a Thread.sleep after warmup but before running the test.  This gives time and CPU resources to the compiler (optimizer) threads.

Getting this right was very tricky.  I am still not confident that I have mastered it yet.  I should really do some harness tests to gain more confidence.

Nathan Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>  | Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/>  | Server Technology


On 10/25/2011 2:13 AM, Thorsten M?ller wrote: 

 
Am 24.10.2011 um 22:20 schrieb Nathan Reynolds:
 

	Note:  HotSpot does have an optimizer logging feature and can be used to determine if the optimizer is finished (i.e. by lack of further output).

 
Interesting - wasn't aware of this yet. Could you detail how it can be used. Seems that it is a JVM parameter [1]?
 
Thorsten
 
[1] http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html
 
 
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


DISCLAIMER:
==========================================================================================================================================================The information contained in this e-mail message may be privileged and/or confidential and protected from disclosure under applicable law. It is intended only for the individual to whom or entity to which it is addressed as shown at the beginning of the message. If the reader of this message is not the intended recipient, or if the employee or agent responsible for delivering the message is not an employee or agent of the intended recipient, you are hereby notified that any review, dissemination,distribution, use, or copying of this message is strictly prohibited. If you have received this message in error, please notify us immediately by return e-mail and permanently delete this message and your reply to the extent it includes this message. Any views or opinions presented in this message or attachments are those of the author and do not necessarily represent those of the Company. All e-mails and attachments sent and received are subject to monitoring, reading, and archival by the Company.==========================================================================================================================================================
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111110/231b74d3/attachment.html>

From heinz at javaspecialists.eu  Thu Nov 10 08:15:03 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 10 Nov 2011 15:15:03 +0200
Subject: [concurrency-interest] Propagation of signals to non-interrupted
	thread
Message-ID: <4EBBCE57.7000709@javaspecialists.eu>

In Java 6, the ArrayBlockingQueue used this construct for the take() method:

    public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            try {
                while (count == 0)
                    notEmpty.await();
            } catch (InterruptedException ie) {
                notEmpty.signal(); // propagate to non-interrupted thread
                throw ie;
            }
            E x = extract();
            return x;
        } finally {
            lock.unlock();
        }
    }

In other words, it would /always/ send a signal on interrupt, even if it 
had not received one.

In Java 7, this was taken away, so we now have:

    public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == 0)
                notEmpty.await();
            return extract();
        } finally {
            lock.unlock();
        }
    }

However, I could not find substantial differences between the await() 
methods of Java 6 and 7.  Does this mean that propagating of the signal 
was not necessary in Java 6 either?  According to Doug Lea's book 
section 3.2.4.2, it is necessary with wait/notify to propagate the 
signal if you get interrupted.  However, it looks like Condition.await() 
is coded to cater for this eventuality anyway.

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 


From martinrb at google.com  Thu Nov 10 09:06:37 2011
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 10 Nov 2011 06:06:37 -0800
Subject: [concurrency-interest] Propagation of signals to
	non-interrupted thread
In-Reply-To: <4EBBCE57.7000709@javaspecialists.eu>
References: <4EBBCE57.7000709@javaspecialists.eu>
Message-ID: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>

These classes are designed to work with JDK6 as well as JDK7.

AbstractQueuedSynchronizer has been written so that interrupts can never
cause signals to be lost.  If this were not the case, there would be many
more places than just in ArrayBlockingQueue where special handling of
interrupts would be required (and getting concurrent classes right is
already hard enough).  Implementation of ABQ has merely been simplified to
rely on AQS's de-facto guarantee.

This ought to be better documented.

I would like to see the classes in j.u.c.locks document more guarantees
than they currently do.
For example, I'd like to see this guarantee:

diff -u -r1.96 ReentrantLock.java
--- main/java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011 07:48:44
-0000 1.96
+++ main/java/util/concurrent/locks/ReentrantLock.java 10 Nov 2011 14:00:08
-0000
@@ -467,6 +467,9 @@
      * but for <em>fair</em> locks favors those threads that have been
      * waiting the longest.
      *
+     * <li>None of the condition {@linkplain Condition#await() waiting}
+     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
+     *
      * </ul>
      *
      * @return the Condition object

Martin

On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu>wrote:

> In Java 6, the ArrayBlockingQueue used this construct for the take()
> method:
>
>   public E take() throws InterruptedException {
>       final ReentrantLock lock = this.lock;
>       lock.lockInterruptibly();
>       try {
>           try {
>               while (count == 0)
>                   notEmpty.await();
>           } catch (InterruptedException ie) {
>               notEmpty.signal(); // propagate to non-interrupted thread
>               throw ie;
>           }
>           E x = extract();
>           return x;
>       } finally {
>           lock.unlock();
>       }
>   }
>
> In other words, it would /always/ send a signal on interrupt, even if it
> had not received one.
>
> In Java 7, this was taken away, so we now have:
>
>   public E take() throws InterruptedException {
>       final ReentrantLock lock = this.lock;
>       lock.lockInterruptibly();
>       try {
>           while (count == 0)
>               notEmpty.await();
>           return extract();
>       } finally {
>           lock.unlock();
>       }
>   }
>
> However, I could not find substantial differences between the await()
> methods of Java 6 and 7.  Does this mean that propagating of the signal was
> not necessary in Java 6 either?  According to Doug Lea's book section
> 3.2.4.2, it is necessary with wait/notify to propagate the signal if you
> get interrupted.  However, it looks like Condition.await() is coded to
> cater for this eventuality anyway.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111110/694b2604/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Nov 10 17:50:52 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 11 Nov 2011 08:50:52 +1000
Subject: [concurrency-interest] Propagation of signals to
	non-interruptedthread
In-Reply-To: <4EBBCE57.7000709@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCAECPJBAA.davidcholmes@aapt.net.au>

Pre-Java 5 the semantics of how interrupts and notifications interacted was
under-specified and at one time a thread that received a notification could
then see it was also interrupted and throw the IE, causing the notification
to be lost. We fixed that in the spec in Java 5 (and in the VM) but the
defensive coding construct of sending a signal/notify upon getting IE
remained in the code. We eventually removed that in the Java 7 time-frame.

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dr Heinz
> M. Kabutz
> Sent: Thursday, 10 November 2011 11:15 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Propagation of signals to
> non-interruptedthread
>
>
> In Java 6, the ArrayBlockingQueue used this construct for the
> take() method:
>
>     public E take() throws InterruptedException {
>         final ReentrantLock lock = this.lock;
>         lock.lockInterruptibly();
>         try {
>             try {
>                 while (count == 0)
>                     notEmpty.await();
>             } catch (InterruptedException ie) {
>                 notEmpty.signal(); // propagate to non-interrupted thread
>                 throw ie;
>             }
>             E x = extract();
>             return x;
>         } finally {
>             lock.unlock();
>         }
>     }
>
> In other words, it would /always/ send a signal on interrupt, even if it
> had not received one.
>
> In Java 7, this was taken away, so we now have:
>
>     public E take() throws InterruptedException {
>         final ReentrantLock lock = this.lock;
>         lock.lockInterruptibly();
>         try {
>             while (count == 0)
>                 notEmpty.await();
>             return extract();
>         } finally {
>             lock.unlock();
>         }
>     }
>
> However, I could not find substantial differences between the await()
> methods of Java 6 and 7.  Does this mean that propagating of the signal
> was not necessary in Java 6 either?  According to Doug Lea's book
> section 3.2.4.2, it is necessary with wait/notify to propagate the
> signal if you get interrupted.  However, it looks like Condition.await()
> is coded to cater for this eventuality anyway.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Thu Nov 10 17:56:36 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 11 Nov 2011 08:56:36 +1000
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
	thread
In-Reply-To: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>

Martin,

As discussed in the past the reason for not documenting/guaranteeing "no
spurious wakeups" is that it would encourage people to use await() in an
if-statement rather than a loop, which would often be incorrect even without
spurious wakeups. It is a safer multi-threaded world if programmers believe
that spurious wakeups are lying in wait (pun intended) and so are always
accounted for - this will instil safe programming practice across all the
main threading systems.

Cheers,
David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
Buchholz
  Sent: Friday, 11 November 2011 12:07 AM
  To: Dr Heinz M. Kabutz
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Propagation of signals
tonon-interrupted thread


  These classes are designed to work with JDK6 as well as JDK7.


  AbstractQueuedSynchronizer has been written so that interrupts can never
cause signals to be lost.  If this were not the case, there would be many
more places than just in ArrayBlockingQueue where special handling of
interrupts would be required (and getting concurrent classes right is
already hard enough).  Implementation of ABQ has merely been simplified to
rely on AQS's de-facto guarantee.

  This ought to be better documented.


  I would like to see the classes in j.u.c.locks document more guarantees
than they currently do.
  For example, I'd like to see this guarantee:


  diff -u -r1.96 ReentrantLock.java
  --- main/java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011
07:48:44 -0000 1.96
  +++ main/java/util/concurrent/locks/ReentrantLock.java 10 Nov 2011
14:00:08 -0000
  @@ -467,6 +467,9 @@
        * but for <em>fair</em> locks favors those threads that have been
        * waiting the longest.
        *
  +     * <li>None of the condition {@linkplain Condition#await() waiting}
  +     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
  +     *
        * </ul>
        *
        * @return the Condition object


  Martin


  On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:

    In Java 6, the ArrayBlockingQueue used this construct for the take()
method:

      public E take() throws InterruptedException {
          final ReentrantLock lock = this.lock;
          lock.lockInterruptibly();
          try {
              try {
                  while (count == 0)
                      notEmpty.await();
              } catch (InterruptedException ie) {
                  notEmpty.signal(); // propagate to non-interrupted thread
                  throw ie;
              }
              E x = extract();
              return x;
          } finally {
              lock.unlock();
          }
      }

    In other words, it would /always/ send a signal on interrupt, even if it
had not received one.

    In Java 7, this was taken away, so we now have:

      public E take() throws InterruptedException {
          final ReentrantLock lock = this.lock;
          lock.lockInterruptibly();
          try {
              while (count == 0)
                  notEmpty.await();
              return extract();
          } finally {
              lock.unlock();
          }
      }

    However, I could not find substantial differences between the await()
methods of Java 6 and 7.  Does this mean that propagating of the signal was
not necessary in Java 6 either?  According to Doug Lea's book section
3.2.4.2, it is necessary with wait/notify to propagate the signal if you get
interrupted.  However, it looks like Condition.await() is coded to cater for
this eventuality anyway.

    Regards

    Heinz
    --
    Dr Heinz M. Kabutz (PhD CompSci)
    Author of "The Java(tm) Specialists' Newsletter"
    Sun Java Champion
    IEEE Certified Software Development Professional
    http://www.javaspecialists.eu
    Tel: +30 69 72 850 460
    Skype: kabutz
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/a3f1fa57/attachment.html>

From tim at peierls.net  Fri Nov 11 10:36:27 2011
From: tim at peierls.net (Tim Peierls)
Date: Fri, 11 Nov 2011 10:36:27 -0500
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
	thread
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
Message-ID: <CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>

This just bit me. (I never really followed the discussions that resulted in
that documentation strategy.) I suggested some code for someone that I
claimed was not ready to use because it didn't handle spurious wakeups. I
now think in fact it *was* ready to use. Better safe than sorry, of course,
but it would have been nicer to read that await was not prone to spurious
wakeups along with a reminder that in many cases await should be called in
a loop to check the condition.

--tim

On Thu, Nov 10, 2011 at 5:56 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> Martin,
>
> As discussed in the past the reason for not documenting/guaranteeing "no
> spurious wakeups" is that it would encourage people to use await() in an
> if-statement rather than a loop, which would often be incorrect even
> without spurious wakeups. It is a safer multi-threaded world if programmers
> believe that spurious wakeups are lying in wait (pun intended) and so are
> always accounted for - this will instil safe programming practice across
> all the main threading systems.
>
> Cheers,
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Martin Buchholz
> *Sent:* Friday, 11 November 2011 12:07 AM
> *To:* Dr Heinz M. Kabutz
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Propagation of signals
> tonon-interrupted thread
>
> These classes are designed to work with JDK6 as well as JDK7.
>
> AbstractQueuedSynchronizer has been written so that interrupts can never
> cause signals to be lost.  If this were not the case, there would be many
> more places than just in ArrayBlockingQueue where special handling of
> interrupts would be required (and getting concurrent classes right is
> already hard enough).  Implementation of ABQ has merely been simplified to
> rely on AQS's de-facto guarantee.
>
> This ought to be better documented.
>
> I would like to see the classes in j.u.c.locks document more guarantees
> than they currently do.
> For example, I'd like to see this guarantee:
>
>  diff -u -r1.96 ReentrantLock.java
> --- main/java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011
> 07:48:44 -0000 1.96
> +++ main/java/util/concurrent/locks/ReentrantLock.java 10 Nov 2011
> 14:00:08 -0000
> @@ -467,6 +467,9 @@
>       * but for <em>fair</em> locks favors those threads that have been
>       * waiting the longest.
>       *
> +     * <li>None of the condition {@linkplain Condition#await() waiting}
> +     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
> +     *
>       * </ul>
>       *
>       * @return the Condition object
>
> Martin
>
> On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz <
> heinz at javaspecialists.eu> wrote:
>
>> In Java 6, the ArrayBlockingQueue used this construct for the take()
>> method:
>>
>>   public E take() throws InterruptedException {
>>       final ReentrantLock lock = this.lock;
>>       lock.lockInterruptibly();
>>       try {
>>           try {
>>               while (count == 0)
>>                   notEmpty.await();
>>           } catch (InterruptedException ie) {
>>               notEmpty.signal(); // propagate to non-interrupted thread
>>               throw ie;
>>           }
>>           E x = extract();
>>           return x;
>>       } finally {
>>           lock.unlock();
>>       }
>>   }
>>
>> In other words, it would /always/ send a signal on interrupt, even if it
>> had not received one.
>>
>> In Java 7, this was taken away, so we now have:
>>
>>   public E take() throws InterruptedException {
>>       final ReentrantLock lock = this.lock;
>>       lock.lockInterruptibly();
>>       try {
>>           while (count == 0)
>>               notEmpty.await();
>>           return extract();
>>       } finally {
>>           lock.unlock();
>>       }
>>   }
>>
>> However, I could not find substantial differences between the await()
>> methods of Java 6 and 7.  Does this mean that propagating of the signal was
>> not necessary in Java 6 either?  According to Doug Lea's book section
>> 3.2.4.2, it is necessary with wait/notify to propagate the signal if you
>> get interrupted.  However, it looks like Condition.await() is coded to
>> cater for this eventuality anyway.
>>
>> Regards
>>
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 72 850 460
>> Skype: kabutz
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/1e7e385b/attachment-0001.html>

From nathan.reynolds at oracle.com  Fri Nov 11 11:50:02 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 11 Nov 2011 09:50:02 -0700
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
 thread
In-Reply-To: <CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
Message-ID: <4EBD523A.5010304@oracle.com>

Does Solaris/SPARC or some other platform still cause spurious wakeups?  
Or is this email chain saying that has been fixed?

Spurious wakeups should always be considered possible even if the 
hardware and JVM don't allow it.  LockSupport.unpark() can be called by 
any thread in any piece of code.  It has a globally accessible flag.  
One piece of code could call unpark() and cause what seems to be a 
"spurious" wakeup in another piece of code.

For example, let's say some buggy code allows for two threads (A & B) to 
call LockSupport.unpark() on the same thread (C).  Thread A calls 
unpark().  Thread C wakes up exits that piece of code and then goes into 
another piece of code.  Thread C then calls LockSupport.park().  Thread 
B gets some CPU time and calls LockSupport.unpark() on Thread C.  Thread 
C now wakes up and thinks it has been signaled correctly.  This problem 
is really tough to debug because the two pieces of code are completely 
unrelated except via LockSupport.

Coding for spurious wakeups (i.e. rechecking the condition) is always a 
good thing.  Sure the piece of code you are looking at could be 
perfect.  But, some other piece of code which you have never seen could 
be doing things in a way that breaks your code.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/11/2011 8:36 AM, Tim Peierls wrote:
> This just bit me. (I never really followed the discussions that 
> resulted in that documentation strategy.) I suggested some code for 
> someone that I claimed was not ready to use because it didn't handle 
> spurious wakeups. I now think in fact it /was/ ready to use. Better 
> safe than sorry, of course, but it would have been nicer to read that 
> await was not prone to spurious wakeups along with a reminder that in 
> many cases await should be called in a loop to check the condition.
>
> --tim
>
> On Thu, Nov 10, 2011 at 5:56 PM, David Holmes 
> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>
>     Martin,
>     As discussed in the past the reason for not
>     documenting/guaranteeing "no spurious wakeups" is that it would
>     encourage people to use await() in an if-statement rather than a
>     loop, which would often be incorrect even without spurious
>     wakeups. It is a safer multi-threaded world if programmers believe
>     that spurious wakeups are lying in wait (pun intended) and so are
>     always accounted for - this will instil safe programming practice
>     across all the main threading systems.
>     Cheers,
>     David
>
>         -----Original Message-----
>         *From:* concurrency-interest-bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>         [mailto:concurrency-interest-bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf
>         Of *Martin Buchholz
>         *Sent:* Friday, 11 November 2011 12:07 AM
>         *To:* Dr Heinz M. Kabutz
>         *Cc:* concurrency-interest at cs.oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>
>         *Subject:* Re: [concurrency-interest] Propagation of signals
>         tonon-interrupted thread
>
>         These classes are designed to work with JDK6 as well as JDK7.
>
>         AbstractQueuedSynchronizer has been written so that interrupts
>         can never cause signals to be lost.  If this were not the
>         case, there would be many more places than just
>         in ArrayBlockingQueue where special handling of interrupts
>         would be required (and getting concurrent classes right is
>         already hard enough).  Implementation of ABQ has merely been
>         simplified to rely on AQS's de-facto guarantee.
>
>         This ought to be better documented.
>
>         I would like to see the classes in j.u.c.locks document more
>         guarantees than they currently do.
>         For example, I'd like to see this guarantee:
>
>         diff -u -r1.96 ReentrantLock.java
>         --- main/java/util/concurrent/locks/ReentrantLock.java9 Jun
>         2011 07:48:44 -00001.96
>         +++ main/java/util/concurrent/locks/ReentrantLock.java10 Nov
>         2011 14:00:08 -0000
>         @@ -467,6 +467,9 @@
>               * but for <em>fair</em> locks favors those threads that
>         have been
>               * waiting the longest.
>               *
>         +     * <li>None of the condition {@linkplain
>         Condition#await() waiting}
>         +     * methods ever return due to a &quot;<em>spurious
>         wakeup</em>&quot;.
>         +     *
>               * </ul>
>               *
>               * @return the Condition object
>
>         Martin
>
>         On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz
>         <heinz at javaspecialists.eu <mailto:heinz at javaspecialists.eu>>
>         wrote:
>
>             In Java 6, the ArrayBlockingQueue used this construct for
>             the take() method:
>
>               public E take() throws InterruptedException {
>                   final ReentrantLock lock = this.lock;
>                   lock.lockInterruptibly();
>                   try {
>                       try {
>                           while (count == 0)
>                               notEmpty.await();
>                       } catch (InterruptedException ie) {
>                           notEmpty.signal(); // propagate to
>             non-interrupted thread
>                           throw ie;
>                       }
>                       E x = extract();
>                       return x;
>                   } finally {
>                       lock.unlock();
>                   }
>               }
>
>             In other words, it would /always/ send a signal on
>             interrupt, even if it had not received one.
>
>             In Java 7, this was taken away, so we now have:
>
>               public E take() throws InterruptedException {
>                   final ReentrantLock lock = this.lock;
>                   lock.lockInterruptibly();
>                   try {
>                       while (count == 0)
>                           notEmpty.await();
>                       return extract();
>                   } finally {
>                       lock.unlock();
>                   }
>               }
>
>             However, I could not find substantial differences between
>             the await() methods of Java 6 and 7.  Does this mean that
>             propagating of the signal was not necessary in Java 6
>             either?  According to Doug Lea's book section 3.2.4.2, it
>             is necessary with wait/notify to propagate the signal if
>             you get interrupted.  However, it looks like
>             Condition.await() is coded to cater for this eventuality
>             anyway.
>
>             Regards
>
>             Heinz
>             -- 
>             Dr Heinz M. Kabutz (PhD CompSci)
>             Author of "The Java(tm) Specialists' Newsletter"
>             Sun Java Champion
>             IEEE Certified Software Development Professional
>             http://www.javaspecialists.eu
>             Tel: +30 69 72 850 460 <tel:%2B30%2069%2072%20850%20460>
>             Skype: kabutz
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/a72f3249/attachment.html>

From david.lloyd at redhat.com  Fri Nov 11 12:00:09 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Fri, 11 Nov 2011 11:00:09 -0600
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
 thread
In-Reply-To: <4EBD523A.5010304@oracle.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
	<4EBD523A.5010304@oracle.com>
Message-ID: <4EBD5499.4060002@redhat.com>

Absolutely.  Spurious wakeups are an indelible part of the 
park()/unpark() contract, and in fact can make coding certain things 
possible or at least much easier.  Never, ever, ever, ever assume that 
they can't happen, no matter what you hear from anyone.

On 11/11/2011 10:50 AM, Nathan Reynolds wrote:
> Does Solaris/SPARC or some other platform still cause spurious wakeups?
> Or is this email chain saying that has been fixed?
>
> Spurious wakeups should always be considered possible even if the
> hardware and JVM don't allow it. LockSupport.unpark() can be called by
> any thread in any piece of code. It has a globally accessible flag. One
> piece of code could call unpark() and cause what seems to be a
> "spurious" wakeup in another piece of code.
>
> For example, let's say some buggy code allows for two threads (A & B) to
> call LockSupport.unpark() on the same thread (C). Thread A calls
> unpark(). Thread C wakes up exits that piece of code and then goes into
> another piece of code. Thread C then calls LockSupport.park(). Thread B
> gets some CPU time and calls LockSupport.unpark() on Thread C. Thread C
> now wakes up and thinks it has been signaled correctly. This problem is
> really tough to debug because the two pieces of code are completely
> unrelated except via LockSupport.
>
> Coding for spurious wakeups (i.e. rechecking the condition) is always a
> good thing. Sure the piece of code you are looking at could be perfect.
> But, some other piece of code which you have never seen could be doing
> things in a way that breaks your code.
>
> Nathan Reynolds
> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 11/11/2011 8:36 AM, Tim Peierls wrote:
>> This just bit me. (I never really followed the discussions that
>> resulted in that documentation strategy.) I suggested some code for
>> someone that I claimed was not ready to use because it didn't handle
>> spurious wakeups. I now think in fact it /was/ ready to use. Better
>> safe than sorry, of course, but it would have been nicer to read that
>> await was not prone to spurious wakeups along with a reminder that in
>> many cases await should be called in a loop to check the condition.
>>
>> --tim
>>
>> On Thu, Nov 10, 2011 at 5:56 PM, David Holmes
>> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>     Martin,
>>     As discussed in the past the reason for not
>>     documenting/guaranteeing "no spurious wakeups" is that it would
>>     encourage people to use await() in an if-statement rather than a
>>     loop, which would often be incorrect even without spurious
>>     wakeups. It is a safer multi-threaded world if programmers believe
>>     that spurious wakeups are lying in wait (pun intended) and so are
>>     always accounted for - this will instil safe programming practice
>>     across all the main threading systems.
>>     Cheers,
>>     David
>>
>>         -----Original Message-----
>>         *From:* concurrency-interest-bounces at cs.oswego.edu
>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>         [mailto:concurrency-interest-bounces at cs.oswego.edu
>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf
>>         Of *Martin Buchholz
>>         *Sent:* Friday, 11 November 2011 12:07 AM
>>         *To:* Dr Heinz M. Kabutz
>>         *Cc:* concurrency-interest at cs.oswego.edu
>>         <mailto:concurrency-interest at cs.oswego.edu>
>>         *Subject:* Re: [concurrency-interest] Propagation of signals
>>         tonon-interrupted thread
>>
>>         These classes are designed to work with JDK6 as well as JDK7.
>>
>>         AbstractQueuedSynchronizer has been written so that interrupts
>>         can never cause signals to be lost. If this were not the case,
>>         there would be many more places than just in
>>         ArrayBlockingQueue where special handling of interrupts would
>>         be required (and getting concurrent classes right is already
>>         hard enough). Implementation of ABQ has merely been simplified
>>         to rely on AQS's de-facto guarantee.
>>
>>         This ought to be better documented.
>>
>>         I would like to see the classes in j.u.c.locks document more
>>         guarantees than they currently do.
>>         For example, I'd like to see this guarantee:
>>
>>         diff -u -r1.96 ReentrantLock.java
>>         --- main/java/util/concurrent/locks/ReentrantLock.java9 Jun
>>         2011 07:48:44 -00001.96
>>         +++ main/java/util/concurrent/locks/ReentrantLock.java10 Nov
>>         2011 14:00:08 -0000
>>         @@ -467,6 +467,9 @@
>>         * but for <em>fair</em> locks favors those threads that have been
>>         * waiting the longest.
>>         *
>>         + * <li>None of the condition {@linkplain Condition#await()
>>         waiting}
>>         + * methods ever return due to a &quot;<em>spurious
>>         wakeup</em>&quot;.
>>         + *
>>         * </ul>
>>         *
>>         * @return the Condition object
>>
>>         Martin
>>
>>         On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz
>>         <heinz at javaspecialists.eu <mailto:heinz at javaspecialists.eu>>
>>         wrote:
>>
>>             In Java 6, the ArrayBlockingQueue used this construct for
>>             the take() method:
>>
>>             public E take() throws InterruptedException {
>>             final ReentrantLock lock = this.lock;
>>             lock.lockInterruptibly();
>>             try {
>>             try {
>>             while (count == 0)
>>             notEmpty.await();
>>             } catch (InterruptedException ie) {
>>             notEmpty.signal(); // propagate to non-interrupted thread
>>             throw ie;
>>             }
>>             E x = extract();
>>             return x;
>>             } finally {
>>             lock.unlock();
>>             }
>>             }
>>
>>             In other words, it would /always/ send a signal on
>>             interrupt, even if it had not received one.
>>
>>             In Java 7, this was taken away, so we now have:
>>
>>             public E take() throws InterruptedException {
>>             final ReentrantLock lock = this.lock;
>>             lock.lockInterruptibly();
>>             try {
>>             while (count == 0)
>>             notEmpty.await();
>>             return extract();
>>             } finally {
>>             lock.unlock();
>>             }
>>             }
>>
>>             However, I could not find substantial differences between
>>             the await() methods of Java 6 and 7. Does this mean that
>>             propagating of the signal was not necessary in Java 6
>>             either? According to Doug Lea's book section 3.2.4.2, it
>>             is necessary with wait/notify to propagate the signal if
>>             you get interrupted. However, it looks like
>>             Condition.await() is coded to cater for this eventuality
>>             anyway.
>>
>>             Regards
>>
>>             Heinz
>>             --
>>             Dr Heinz M. Kabutz (PhD CompSci)
>>             Author of "The Java(tm) Specialists' Newsletter"
>>             Sun Java Champion
>>             IEEE Certified Software Development Professional
>>             http://www.javaspecialists.eu
>>             Tel: +30 69 72 850 460 <tel:%2B30%2069%2072%20850%20460>
>>             Skype: kabutz
>>             _______________________________________________
>>             Concurrency-interest mailing list
>>             Concurrency-interest at cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
- DML

From heinz at javaspecialists.eu  Fri Nov 11 13:05:44 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 11 Nov 2011 20:05:44 +0200
Subject: [concurrency-interest] Propagation of signals to
 non-interrupted thread
In-Reply-To: <4EBD5499.4060002@redhat.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>	<4EBD523A.5010304@oracle.com>
	<4EBD5499.4060002@redhat.com>
Message-ID: <4EBD63F8.10606@javaspecialists.eu>

Yes, the spurious wakeup is definitely part of the game.  One of my 
customers had a system that basically imploded in Java 6 because they 
happened frequently under heavy load.

I agree with David's assessment that it is much easier to convince 
people to use a while() loop to test their condition predicate if they 
know that "spurious wakeups" might occur.  For many years I tried to 
explain during courses that this is wrong:

public synchronized void put(Object o) {
  queue.add(o);
  notify();
}

public synchronized Object take() throws InterruptedException {
  if (queue.isEmpty()) {
    wait();
  }
  return queue.remove(0);
}

My argument was:  Thread 1 calls take, queue is empty and is parked with 
wait() and thus lets go of the lock.  Thread 2 comes along, gets the 
lock, adds an element and calls notify(), which thus wakes up thread 1.  
However, thread 1 cannot proceed until he has the lock again.  Thread 2 
now returns the lock, but at that instant, Thread 3 comes along and 
calls take().  Finding the queue non-empty, it removes the first element 
and returns.  Thread 1 now finally gets the lock and calls 
queue.remove(0), which results in a NoSuchElementException.

A long argument, which is much easier to argue with spurious wakeups 
:-)  "Thread 1 is waiting, but can wake up due to a spurious signal.  
These things really do happen in production.  Any questions?"

Some of my customers are still using Java 1.4.2.  Do we need to 
propagate the signal if we use low-level synchronized?  I would feel 
most comfortable even doing this in Java 5+, even if it is not 
necessary, since the take() method needs to cope with spurious signals 
anyway.

public synchronized Object take() throws InterruptedException {
  while (queue.isEmpty()) {
    try {
      wait();
    } catch(InterruptedException ex) {
      notify();
      throw ex;
    }
  }
  return queue.remove(0);
}
 

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 11/11/11 7:00 PM, David M. Lloyd wrote:
> Absolutely.  Spurious wakeups are an indelible part of the 
> park()/unpark() contract, and in fact can make coding certain things 
> possible or at least much easier.  Never, ever, ever, ever assume that 
> they can't happen, no matter what you hear from anyone.
>
> On 11/11/2011 10:50 AM, Nathan Reynolds wrote:
>> Does Solaris/SPARC or some other platform still cause spurious wakeups?
>> Or is this email chain saying that has been fixed?
>>
>> Spurious wakeups should always be considered possible even if the
>> hardware and JVM don't allow it. LockSupport.unpark() can be called by
>> any thread in any piece of code. It has a globally accessible flag. One
>> piece of code could call unpark() and cause what seems to be a
>> "spurious" wakeup in another piece of code.
>>
>> For example, let's say some buggy code allows for two threads (A & B) to
>> call LockSupport.unpark() on the same thread (C). Thread A calls
>> unpark(). Thread C wakes up exits that piece of code and then goes into
>> another piece of code. Thread C then calls LockSupport.park(). Thread B
>> gets some CPU time and calls LockSupport.unpark() on Thread C. Thread C
>> now wakes up and thinks it has been signaled correctly. This problem is
>> really tough to debug because the two pieces of code are completely
>> unrelated except via LockSupport.
>>
>> Coding for spurious wakeups (i.e. rechecking the condition) is always a
>> good thing. Sure the piece of code you are looking at could be perfect.
>> But, some other piece of code which you have never seen could be doing
>> things in a way that breaks your code.
>>
>> Nathan Reynolds
>> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>> Consulting Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 11/11/2011 8:36 AM, Tim Peierls wrote:
>>> This just bit me. (I never really followed the discussions that
>>> resulted in that documentation strategy.) I suggested some code for
>>> someone that I claimed was not ready to use because it didn't handle
>>> spurious wakeups. I now think in fact it /was/ ready to use. Better
>>> safe than sorry, of course, but it would have been nicer to read that
>>> await was not prone to spurious wakeups along with a reminder that in
>>> many cases await should be called in a loop to check the condition.
>>>
>>> --tim
>>>
>>> On Thu, Nov 10, 2011 at 5:56 PM, David Holmes
>>> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>
>>>     Martin,
>>>     As discussed in the past the reason for not
>>>     documenting/guaranteeing "no spurious wakeups" is that it would
>>>     encourage people to use await() in an if-statement rather than a
>>>     loop, which would often be incorrect even without spurious
>>>     wakeups. It is a safer multi-threaded world if programmers believe
>>>     that spurious wakeups are lying in wait (pun intended) and so are
>>>     always accounted for - this will instil safe programming practice
>>>     across all the main threading systems.
>>>     Cheers,
>>>     David
>>>
>>>         -----Original Message-----
>>>         *From:* concurrency-interest-bounces at cs.oswego.edu
>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>         [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf
>>>         Of *Martin Buchholz
>>>         *Sent:* Friday, 11 November 2011 12:07 AM
>>>         *To:* Dr Heinz M. Kabutz
>>>         *Cc:* concurrency-interest at cs.oswego.edu
>>>         <mailto:concurrency-interest at cs.oswego.edu>
>>>         *Subject:* Re: [concurrency-interest] Propagation of signals
>>>         tonon-interrupted thread
>>>
>>>         These classes are designed to work with JDK6 as well as JDK7.
>>>
>>>         AbstractQueuedSynchronizer has been written so that interrupts
>>>         can never cause signals to be lost. If this were not the case,
>>>         there would be many more places than just in
>>>         ArrayBlockingQueue where special handling of interrupts would
>>>         be required (and getting concurrent classes right is already
>>>         hard enough). Implementation of ABQ has merely been simplified
>>>         to rely on AQS's de-facto guarantee.
>>>
>>>         This ought to be better documented.
>>>
>>>         I would like to see the classes in j.u.c.locks document more
>>>         guarantees than they currently do.
>>>         For example, I'd like to see this guarantee:
>>>
>>>         diff -u -r1.96 ReentrantLock.java
>>>         --- main/java/util/concurrent/locks/ReentrantLock.java9 Jun
>>>         2011 07:48:44 -00001.96
>>>         +++ main/java/util/concurrent/locks/ReentrantLock.java10 Nov
>>>         2011 14:00:08 -0000
>>>         @@ -467,6 +467,9 @@
>>>         * but for <em>fair</em> locks favors those threads that have 
>>> been
>>>         * waiting the longest.
>>>         *
>>>         + * <li>None of the condition {@linkplain Condition#await()
>>>         waiting}
>>>         + * methods ever return due to a &quot;<em>spurious
>>>         wakeup</em>&quot;.
>>>         + *
>>>         * </ul>
>>>         *
>>>         * @return the Condition object
>>>
>>>         Martin
>>>
>>>         On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz
>>>         <heinz at javaspecialists.eu <mailto:heinz at javaspecialists.eu>>
>>>         wrote:
>>>
>>>             In Java 6, the ArrayBlockingQueue used this construct for
>>>             the take() method:
>>>
>>>             public E take() throws InterruptedException {
>>>             final ReentrantLock lock = this.lock;
>>>             lock.lockInterruptibly();
>>>             try {
>>>             try {
>>>             while (count == 0)
>>>             notEmpty.await();
>>>             } catch (InterruptedException ie) {
>>>             notEmpty.signal(); // propagate to non-interrupted thread
>>>             throw ie;
>>>             }
>>>             E x = extract();
>>>             return x;
>>>             } finally {
>>>             lock.unlock();
>>>             }
>>>             }
>>>
>>>             In other words, it would /always/ send a signal on
>>>             interrupt, even if it had not received one.
>>>
>>>             In Java 7, this was taken away, so we now have:
>>>
>>>             public E take() throws InterruptedException {
>>>             final ReentrantLock lock = this.lock;
>>>             lock.lockInterruptibly();
>>>             try {
>>>             while (count == 0)
>>>             notEmpty.await();
>>>             return extract();
>>>             } finally {
>>>             lock.unlock();
>>>             }
>>>             }
>>>
>>>             However, I could not find substantial differences between
>>>             the await() methods of Java 6 and 7. Does this mean that
>>>             propagating of the signal was not necessary in Java 6
>>>             either? According to Doug Lea's book section 3.2.4.2, it
>>>             is necessary with wait/notify to propagate the signal if
>>>             you get interrupted. However, it looks like
>>>             Condition.await() is coded to cater for this eventuality
>>>             anyway.
>>>
>>>             Regards
>>>
>>>             Heinz
>>>             --
>>>             Dr Heinz M. Kabutz (PhD CompSci)
>>>             Author of "The Java(tm) Specialists' Newsletter"
>>>             Sun Java Champion
>>>             IEEE Certified Software Development Professional
>>>             http://www.javaspecialists.eu
>>>             Tel: +30 69 72 850 460 <tel:%2B30%2069%2072%20850%20460>
>>>             Skype: kabutz
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest at cs.oswego.edu
>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From heinz at javaspecialists.eu  Fri Nov 11 13:07:02 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 11 Nov 2011 20:07:02 +0200
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
 thread
In-Reply-To: <CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
Message-ID: <4EBD6446.2060502@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/524cf2b7/attachment-0001.html>

From martinrb at google.com  Fri Nov 11 13:27:00 2011
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Nov 2011 10:27:00 -0800
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
	thread
In-Reply-To: <4EBD5499.4060002@redhat.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
	<4EBD523A.5010304@oracle.com> <4EBD5499.4060002@redhat.com>
Message-ID: <CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>

(Heinz: apologies for the thread hijack)

On Fri, Nov 11, 2011 at 09:00, David M. Lloyd <david.lloyd at redhat.com>wrote:

> Absolutely.  Spurious wakeups are an indelible part of the park()/unpark()
> contract, and in fact can make coding certain things possible or at least
> much easier.  Never, ever, ever, ever assume that they can't happen, no
> matter what you hear from anyone.
>
> park/unpark can and do wake up spuriously.

Object.wait is documented as being able to wake up spuriously (not sure
whether it happens in practice)

I'm only trying to change the spec for AQS-based conditions, since AQS is
carefully written to exclude spurious wakeups.
Arguably, Condition *requires* us to document the additional guarantee:

 * <p>A {@code Condition} implementation can provide behavior and semantics
 * that is
 * different from that of the {@code Object} monitor methods, such as
 * guaranteed ordering for notifications, or not requiring a lock to be held
 * when performing notifications.
 * If an implementation provides such specialized semantics then the
 * implementation must document those semantics.

We can add disclaimers:

--- java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011 07:48:44 -0000
1.96
+++ java/util/concurrent/locks/ReentrantLock.java 11 Nov 2011 18:16:05 -0000
@@ -467,6 +467,13 @@
      * but for <em>fair</em> locks favors those threads that have been
      * waiting the longest.
      *
+     * <li>None of the condition {@linkplain Condition#await() waiting}
+     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
+     * However, as explained in the {@link Condition} documentation,
+     * this has little practical impact on most application programs as
+     * a {@code Condition} should generally be waited upon in a loop,
+     * testing the state predicate that is being waited for.
+     *
      * </ul>
      *
      * @return the Condition object
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/76b75b32/attachment.html>

From heinz at javaspecialists.eu  Fri Nov 11 13:36:14 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 11 Nov 2011 20:36:14 +0200
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
 thread
In-Reply-To: <CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>	<4EBD523A.5010304@oracle.com>	<4EBD5499.4060002@redhat.com>
	<CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>
Message-ID: <4EBD6B1E.1000801@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/978428af/attachment.html>

From martinrb at google.com  Fri Nov 11 13:48:37 2011
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Nov 2011 10:48:37 -0800
Subject: [concurrency-interest] Propagation of signals to
	non-interrupted thread
In-Reply-To: <4EBD63F8.10606@javaspecialists.eu>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
	<4EBD523A.5010304@oracle.com> <4EBD5499.4060002@redhat.com>
	<4EBD63F8.10606@javaspecialists.eu>
Message-ID: <CA+kOe09tH7G7pQFpmtmJOBDjC92cfs=3EsoMMHbP3K0K0LxTng@mail.gmail.com>

On Fri, Nov 11, 2011 at 10:05, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu>wrote:

> Yes, the spurious wakeup is definitely part of the game.  One of my
> customers had a system that basically imploded in Java 6 because they
> happened frequently under heavy load.
>
> Interesting.


> My argument was:  Thread 1 calls take, queue is empty and is parked with
> wait() and thus lets go of the lock.  Thread 2 comes along, gets the lock,
> adds an element and calls notify(), which thus wakes up thread 1.  However,
> thread 1 cannot proceed until he has the lock again.  Thread 2 now returns
> the lock, but at that instant, Thread 3 comes along and calls take().
>  Finding the queue non-empty, it removes the first element and returns.
>  Thread 1 now finally gets the lock and calls queue.remove(0), which
> results in a NoSuchElementException.
>
> A long argument, which is much easier to argue with spurious wakeups :-)
>  "Thread 1 is waiting, but can wake up due to a spurious signal.  These
> things really do happen in production.  Any questions?"
>

For Object.wait, spurious wakeups are still possible.

The "long argument" is hard for humans to understand, but is what I
consider the "real" reason to call Condition.await in a loop.  When
teaching this material, it might be easier to say,

"Always call wait/await in a loop. If you don't, you will have mysterious
failures in production.  If you care about the long story, or want to
understand how java monitors *really* work, we can discuss in depth later."



> Some of my customers are still using Java 1.4.2.  Do we need to propagate
> the signal if we use low-level synchronized?  I would feel most comfortable
> even doing this in Java 5+, even if it is not necessary, since the take()
> method needs to cope with spurious signals anyway.
>
> public synchronized Object take() throws InterruptedException {
>  while (queue.isEmpty()) {
>   try {
>     wait();
>   } catch(InterruptedException ex) {
>     notify();
>     throw ex;
>   }
>  }
>  return queue.remove(0);
>
> }
>

My condolences for all of you out there who are trying to write concurrent
code for Java 1.4.2.  If I were doing that, I would also be paranoid and
notify() on catching InterruptedException.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/23cb0dbb/attachment.html>

From martinrb at google.com  Fri Nov 11 13:50:23 2011
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Nov 2011 10:50:23 -0800
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
	thread
In-Reply-To: <CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
	<4EBD523A.5010304@oracle.com> <4EBD5499.4060002@redhat.com>
	<CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>
Message-ID: <CA+kOe0_y-g5nekeWmt9v4bonLgV6jvpnUAkQMUxh1EOP0xp6sg@mail.gmail.com>

My latest spec proposal for ReentrantLock, with stronger disclaimer:

--- java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011 07:48:44 -0000
1.96
+++ java/util/concurrent/locks/ReentrantLock.java 11 Nov 2011 18:41:22 -0000
@@ -467,6 +467,13 @@
      * but for <em>fair</em> locks favors those threads that have been
      * waiting the longest.
      *
+     * <li>None of the condition {@linkplain Condition#await() waiting}
+     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
+     * However, as explained in the {@link Condition} documentation,
+     * application programs should almost never rely on this guarantee.
+     * A {@code Condition} should generally be waited upon in a loop,
+     * testing the state predicate that is being waited for.
+     *
      * </ul>
      *
      * @return the Condition object
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/3e6f1126/attachment.html>

From david.lloyd at redhat.com  Fri Nov 11 14:21:10 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Fri, 11 Nov 2011 13:21:10 -0600
Subject: [concurrency-interest] Propagation of signals to
 non-interrupted thread
In-Reply-To: <4EBD63F8.10606@javaspecialists.eu>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>	<4EBD523A.5010304@oracle.com>
	<4EBD5499.4060002@redhat.com> <4EBD63F8.10606@javaspecialists.eu>
Message-ID: <4EBD75A6.2020807@redhat.com>

I would personally never bother with propagation.  It is only a somewhat 
effective protection for poorly-written code.  Once you open the door of 
"well, I'll try to work around any poorly-written code which might or 
might not exist in the wild", it can be really hard to close again.  You 
might actually make real problems harder to find.

I find that the best policy engineering-wise is to always code to the 
contract and expect others to do as so as well (unless it's a case where 
a contract violation is detectable and handleable in a sensible way, 
e.g. an exception, which seems to come up most frequently in framework 
development as opposed to application development).

On 11/11/2011 12:05 PM, Dr Heinz M. Kabutz wrote:
> Yes, the spurious wakeup is definitely part of the game. One of my
> customers had a system that basically imploded in Java 6 because they
> happened frequently under heavy load.
>
> I agree with David's assessment that it is much easier to convince
> people to use a while() loop to test their condition predicate if they
> know that "spurious wakeups" might occur. For many years I tried to
> explain during courses that this is wrong:
>
> public synchronized void put(Object o) {
> queue.add(o);
> notify();
> }
>
> public synchronized Object take() throws InterruptedException {
> if (queue.isEmpty()) {
> wait();
> }
> return queue.remove(0);
> }
>
> My argument was: Thread 1 calls take, queue is empty and is parked with
> wait() and thus lets go of the lock. Thread 2 comes along, gets the
> lock, adds an element and calls notify(), which thus wakes up thread 1.
> However, thread 1 cannot proceed until he has the lock again. Thread 2
> now returns the lock, but at that instant, Thread 3 comes along and
> calls take(). Finding the queue non-empty, it removes the first element
> and returns. Thread 1 now finally gets the lock and calls
> queue.remove(0), which results in a NoSuchElementException.
>
> A long argument, which is much easier to argue with spurious wakeups :-)
> "Thread 1 is waiting, but can wake up due to a spurious signal. These
> things really do happen in production. Any questions?"
>
> Some of my customers are still using Java 1.4.2. Do we need to propagate
> the signal if we use low-level synchronized? I would feel most
> comfortable even doing this in Java 5+, even if it is not necessary,
> since the take() method needs to cope with spurious signals anyway.
>
> public synchronized Object take() throws InterruptedException {
> while (queue.isEmpty()) {
> try {
> wait();
> } catch(InterruptedException ex) {
> notify();
> throw ex;
> }
> }
> return queue.remove(0);
> }
>
>
> Regards
>
> Heinz


-- 
- DML

From heinz at javaspecialists.eu  Fri Nov 11 14:47:29 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 11 Nov 2011 21:47:29 +0200
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
 thread
In-Reply-To: <CA+kOe0_y-g5nekeWmt9v4bonLgV6jvpnUAkQMUxh1EOP0xp6sg@mail.gmail.com>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>	<4EBD523A.5010304@oracle.com>	<4EBD5499.4060002@redhat.com>	<CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>
	<CA+kOe0_y-g5nekeWmt9v4bonLgV6jvpnUAkQMUxh1EOP0xp6sg@mail.gmail.com>
Message-ID: <4EBD7BD1.7050207@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/9332ffda/attachment.html>

From martinrb at google.com  Fri Nov 11 15:27:56 2011
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Nov 2011 12:27:56 -0800
Subject: [concurrency-interest] Propagation of signals tonon-interrupted
	thread
In-Reply-To: <4EBD7BD1.7050207@javaspecialists.eu>
References: <CA+kOe0_ZqYXA7xqa87=givKynPk7AB6P2t1JpTkvDu_AB=H8Og@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKECPJBAA.davidcholmes@aapt.net.au>
	<CA+F8eeTorkwFvUgBXxP3V-PZnNxtZF8O_otcsrby9dhrZifBWw@mail.gmail.com>
	<4EBD523A.5010304@oracle.com> <4EBD5499.4060002@redhat.com>
	<CA+kOe08tbByjf8cdjKCXiBUW5X2xd-iF7gJTe+21Koy2b_O7kw@mail.gmail.com>
	<CA+kOe0_y-g5nekeWmt9v4bonLgV6jvpnUAkQMUxh1EOP0xp6sg@mail.gmail.com>
	<4EBD7BD1.7050207@javaspecialists.eu>
Message-ID: <CA+kOe0_hYUFJG0zsoY5EO0Q0e=tM8Z94n_jugix0m0Yy6u2zLg@mail.gmail.com>

I am not trying to change the spec for Condition or Object.

I am trying to change the spec for ReentrantLock, ReentrantReadWriteLock,
AQS.ConditionObject, AQLS.ConditionObject to offer more guarantees than
Condition does.

Martin

On Fri, Nov 11, 2011 at 11:47, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu>wrote:

> **
> Remember to also change the Condition documentation:
>
>  * <p>When waiting upon a {@code Condition}, a &quot;<em>spurious
>  * wakeup</em>&quot; is permitted to occur, in
>  * general, as a concession to the underlying platform semantics.
>  * This has little practical impact on most application programs as a
>  * {@code Condition} should always be waited upon in a loop, testing
>  * the state predicate that is being waited for.  An implementation is
>  * free to remove the possibility of spurious wakeups but it is
>  * recommended that applications programmers always assume that they can
>  * occur and so always wait in a loop.
>
> It is also mentioned in all the await() methods.
>
> This does worry me a bit though.  Just because it is not happening in your
> implementation, is it then guaranteed to not happen in *any* implementation?
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professionalhttp://www.javaspecialists.eu
> Tel: +30 69 72 850 460
>
> Skype: kabutz
>
>
>
> On 11/11/11 8:50 PM, Martin Buchholz wrote:
>
> My latest spec proposal for ReentrantLock, with stronger disclaimer:
>
>  --- java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011 07:48:44
> -0000 1.96
> +++ java/util/concurrent/locks/ReentrantLock.java 11 Nov 2011 18:41:22
> -0000
> @@ -467,6 +467,13 @@
>       * but for <em>fair</em> locks favors those threads that have been
>       * waiting the longest.
>       *
> +     * <li>None of the condition {@linkplain Condition#await() waiting}
> +     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
> +     * However, as explained in the {@link Condition} documentation,
> +     * application programs should almost never rely on this guarantee.
> +     * A {@code Condition} should generally be waited upon in a loop,
> +     * testing the state predicate that is being waited for.
> +     *
>       * </ul>
>       *
>       * @return the Condition object
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111111/7befaafe/attachment.html>

From davidcholmes at aapt.net.au  Sun Nov 13 16:32:13 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 Nov 2011 07:32:13 +1000
Subject: [concurrency-interest] Propagation of signals to
	non-interrupted thread
In-Reply-To: <4EBD75A6.2020807@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEDHJBAA.davidcholmes@aapt.net.au>

David M. Lloyd writes:
> I would personally never bother with propagation.  It is only a somewhat
> effective protection for poorly-written code.  Once you open the door of
> "well, I'll try to work around any poorly-written code which might or
> might not exist in the wild", it can be really hard to close again.  You
> might actually make real problems harder to find.

The propagation here is nothing to do with poorly written code but a
work-around for lack of detail in the spec prior to JDK 5 that allowed an
interrupted thread to consume a notification.

David Holmes
------------

> I find that the best policy engineering-wise is to always code to the
> contract and expect others to do as so as well (unless it's a case where
> a contract violation is detectable and handleable in a sensible way,
> e.g. an exception, which seems to come up most frequently in framework
> development as opposed to application development).
>
> On 11/11/2011 12:05 PM, Dr Heinz M. Kabutz wrote:
> > Yes, the spurious wakeup is definitely part of the game. One of my
> > customers had a system that basically imploded in Java 6 because they
> > happened frequently under heavy load.
> >
> > I agree with David's assessment that it is much easier to convince
> > people to use a while() loop to test their condition predicate if they
> > know that "spurious wakeups" might occur. For many years I tried to
> > explain during courses that this is wrong:
> >
> > public synchronized void put(Object o) {
> > queue.add(o);
> > notify();
> > }
> >
> > public synchronized Object take() throws InterruptedException {
> > if (queue.isEmpty()) {
> > wait();
> > }
> > return queue.remove(0);
> > }
> >
> > My argument was: Thread 1 calls take, queue is empty and is parked with
> > wait() and thus lets go of the lock. Thread 2 comes along, gets the
> > lock, adds an element and calls notify(), which thus wakes up thread 1.
> > However, thread 1 cannot proceed until he has the lock again. Thread 2
> > now returns the lock, but at that instant, Thread 3 comes along and
> > calls take(). Finding the queue non-empty, it removes the first element
> > and returns. Thread 1 now finally gets the lock and calls
> > queue.remove(0), which results in a NoSuchElementException.
> >
> > A long argument, which is much easier to argue with spurious wakeups :-)
> > "Thread 1 is waiting, but can wake up due to a spurious signal. These
> > things really do happen in production. Any questions?"
> >
> > Some of my customers are still using Java 1.4.2. Do we need to propagate
> > the signal if we use low-level synchronized? I would feel most
> > comfortable even doing this in Java 5+, even if it is not necessary,
> > since the take() method needs to cope with spurious signals anyway.
> >
> > public synchronized Object take() throws InterruptedException {
> > while (queue.isEmpty()) {
> > try {
> > wait();
> > } catch(InterruptedException ex) {
> > notify();
> > throw ex;
> > }
> > }
> > return queue.remove(0);
> > }
> >
> >
> > Regards
> >
> > Heinz
>
>
> --
> - DML
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Sun Nov 13 16:45:30 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 Nov 2011 07:45:30 +1000
Subject: [concurrency-interest] Propagation of signals to
	non-interrupted thread
In-Reply-To: <4EBD63F8.10606@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEDIJBAA.davidcholmes@aapt.net.au>

Dr Heinz M. Kabutz writes:
> Yes, the spurious wakeup is definitely part of the game.  One of my

The park/unpark scenario is somewhat different to the wait/await situation,
though.

Also a "spurious wakeup" does not refer to the case of some other thread
invoking unpark or signal/notify, but of the implementation doing so. Of
course the same coding practices protect against both.

> customers had a system that basically imploded in Java 6 because they
> happened frequently under heavy load.

That is not just interesting (as Martin put it) but somewhat disturbing, as
even when permitted they should be extremely rare. I'd like to hear more on
this if you can send some details to me.

> I agree with David's assessment that it is much easier to convince
> people to use a while() loop to test their condition predicate if they
> know that "spurious wakeups" might occur.

The basic requirement for looping on the predicate is easily explained by
"the condition may have have changed again by the time you can respond to
it" - ala the two threads taking example. The "spurious wakeup" argument
comes into play when someone asks about specialized cases like single
producer with single consumer "can't I just use if in that case?".

Cheers,
David
-----

> For many years I tried to
> explain during courses that this is wrong:
>
> public synchronized void put(Object o) {
>   queue.add(o);
>   notify();
> }
>
> public synchronized Object take() throws InterruptedException {
>   if (queue.isEmpty()) {
>     wait();
>   }
>   return queue.remove(0);
> }
>
> My argument was:  Thread 1 calls take, queue is empty and is parked with
> wait() and thus lets go of the lock.  Thread 2 comes along, gets the
> lock, adds an element and calls notify(), which thus wakes up thread 1.
> However, thread 1 cannot proceed until he has the lock again.  Thread 2
> now returns the lock, but at that instant, Thread 3 comes along and
> calls take().  Finding the queue non-empty, it removes the first element
> and returns.  Thread 1 now finally gets the lock and calls
> queue.remove(0), which results in a NoSuchElementException.
>
> A long argument, which is much easier to argue with spurious wakeups
> :-)  "Thread 1 is waiting, but can wake up due to a spurious signal.
> These things really do happen in production.  Any questions?"
>
> Some of my customers are still using Java 1.4.2.  Do we need to
> propagate the signal if we use low-level synchronized?  I would feel
> most comfortable even doing this in Java 5+, even if it is not
> necessary, since the take() method needs to cope with spurious signals
> anyway.
>
> public synchronized Object take() throws InterruptedException {
>   while (queue.isEmpty()) {
>     try {
>       wait();
>     } catch(InterruptedException ex) {
>       notify();
>       throw ex;
>     }
>   }
>   return queue.remove(0);
> }
>
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
>
> On 11/11/11 7:00 PM, David M. Lloyd wrote:
> > Absolutely.  Spurious wakeups are an indelible part of the
> > park()/unpark() contract, and in fact can make coding certain things
> > possible or at least much easier.  Never, ever, ever, ever assume that
> > they can't happen, no matter what you hear from anyone.
> >
> > On 11/11/2011 10:50 AM, Nathan Reynolds wrote:
> >> Does Solaris/SPARC or some other platform still cause spurious wakeups?
> >> Or is this email chain saying that has been fixed?
> >>
> >> Spurious wakeups should always be considered possible even if the
> >> hardware and JVM don't allow it. LockSupport.unpark() can be called by
> >> any thread in any piece of code. It has a globally accessible flag. One
> >> piece of code could call unpark() and cause what seems to be a
> >> "spurious" wakeup in another piece of code.
> >>
> >> For example, let's say some buggy code allows for two threads
> (A & B) to
> >> call LockSupport.unpark() on the same thread (C). Thread A calls
> >> unpark(). Thread C wakes up exits that piece of code and then goes into
> >> another piece of code. Thread C then calls LockSupport.park(). Thread B
> >> gets some CPU time and calls LockSupport.unpark() on Thread C. Thread C
> >> now wakes up and thinks it has been signaled correctly. This problem is
> >> really tough to debug because the two pieces of code are completely
> >> unrelated except via LockSupport.
> >>
> >> Coding for spurious wakeups (i.e. rechecking the condition) is always a
> >> good thing. Sure the piece of code you are looking at could be perfect.
> >> But, some other piece of code which you have never seen could be doing
> >> things in a way that breaks your code.
> >>
> >> Nathan Reynolds
> >> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> >> Consulting Member of Technical Staff | 602.333.9091
> >> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
> >>
> >> On 11/11/2011 8:36 AM, Tim Peierls wrote:
> >>> This just bit me. (I never really followed the discussions that
> >>> resulted in that documentation strategy.) I suggested some code for
> >>> someone that I claimed was not ready to use because it didn't handle
> >>> spurious wakeups. I now think in fact it /was/ ready to use. Better
> >>> safe than sorry, of course, but it would have been nicer to read that
> >>> await was not prone to spurious wakeups along with a reminder that in
> >>> many cases await should be called in a loop to check the condition.
> >>>
> >>> --tim
> >>>
> >>> On Thu, Nov 10, 2011 at 5:56 PM, David Holmes
> >>> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
> >>>
> >>>     Martin,
> >>>     As discussed in the past the reason for not
> >>>     documenting/guaranteeing "no spurious wakeups" is that it would
> >>>     encourage people to use await() in an if-statement rather than a
> >>>     loop, which would often be incorrect even without spurious
> >>>     wakeups. It is a safer multi-threaded world if programmers believe
> >>>     that spurious wakeups are lying in wait (pun intended) and so are
> >>>     always accounted for - this will instil safe programming practice
> >>>     across all the main threading systems.
> >>>     Cheers,
> >>>     David
> >>>
> >>>         -----Original Message-----
> >>>         *From:* concurrency-interest-bounces at cs.oswego.edu
> >>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
> >>>         [mailto:concurrency-interest-bounces at cs.oswego.edu
> >>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf
> >>>         Of *Martin Buchholz
> >>>         *Sent:* Friday, 11 November 2011 12:07 AM
> >>>         *To:* Dr Heinz M. Kabutz
> >>>         *Cc:* concurrency-interest at cs.oswego.edu
> >>>         <mailto:concurrency-interest at cs.oswego.edu>
> >>>         *Subject:* Re: [concurrency-interest] Propagation of signals
> >>>         tonon-interrupted thread
> >>>
> >>>         These classes are designed to work with JDK6 as well as JDK7.
> >>>
> >>>         AbstractQueuedSynchronizer has been written so that interrupts
> >>>         can never cause signals to be lost. If this were not the case,
> >>>         there would be many more places than just in
> >>>         ArrayBlockingQueue where special handling of interrupts would
> >>>         be required (and getting concurrent classes right is already
> >>>         hard enough). Implementation of ABQ has merely been simplified
> >>>         to rely on AQS's de-facto guarantee.
> >>>
> >>>         This ought to be better documented.
> >>>
> >>>         I would like to see the classes in j.u.c.locks document more
> >>>         guarantees than they currently do.
> >>>         For example, I'd like to see this guarantee:
> >>>
> >>>         diff -u -r1.96 ReentrantLock.java
> >>>         --- main/java/util/concurrent/locks/ReentrantLock.java9 Jun
> >>>         2011 07:48:44 -00001.96
> >>>         +++ main/java/util/concurrent/locks/ReentrantLock.java10 Nov
> >>>         2011 14:00:08 -0000
> >>>         @@ -467,6 +467,9 @@
> >>>         * but for <em>fair</em> locks favors those threads that have
> >>> been
> >>>         * waiting the longest.
> >>>         *
> >>>         + * <li>None of the condition {@linkplain Condition#await()
> >>>         waiting}
> >>>         + * methods ever return due to a &quot;<em>spurious
> >>>         wakeup</em>&quot;.
> >>>         + *
> >>>         * </ul>
> >>>         *
> >>>         * @return the Condition object
> >>>
> >>>         Martin
> >>>
> >>>         On Thu, Nov 10, 2011 at 05:15, Dr Heinz M. Kabutz
> >>>         <heinz at javaspecialists.eu <mailto:heinz at javaspecialists.eu>>
> >>>         wrote:
> >>>
> >>>             In Java 6, the ArrayBlockingQueue used this construct for
> >>>             the take() method:
> >>>
> >>>             public E take() throws InterruptedException {
> >>>             final ReentrantLock lock = this.lock;
> >>>             lock.lockInterruptibly();
> >>>             try {
> >>>             try {
> >>>             while (count == 0)
> >>>             notEmpty.await();
> >>>             } catch (InterruptedException ie) {
> >>>             notEmpty.signal(); // propagate to non-interrupted thread
> >>>             throw ie;
> >>>             }
> >>>             E x = extract();
> >>>             return x;
> >>>             } finally {
> >>>             lock.unlock();
> >>>             }
> >>>             }
> >>>
> >>>             In other words, it would /always/ send a signal on
> >>>             interrupt, even if it had not received one.
> >>>
> >>>             In Java 7, this was taken away, so we now have:
> >>>
> >>>             public E take() throws InterruptedException {
> >>>             final ReentrantLock lock = this.lock;
> >>>             lock.lockInterruptibly();
> >>>             try {
> >>>             while (count == 0)
> >>>             notEmpty.await();
> >>>             return extract();
> >>>             } finally {
> >>>             lock.unlock();
> >>>             }
> >>>             }
> >>>
> >>>             However, I could not find substantial differences between
> >>>             the await() methods of Java 6 and 7. Does this mean that
> >>>             propagating of the signal was not necessary in Java 6
> >>>             either? According to Doug Lea's book section 3.2.4.2, it
> >>>             is necessary with wait/notify to propagate the signal if
> >>>             you get interrupted. However, it looks like
> >>>             Condition.await() is coded to cater for this eventuality
> >>>             anyway.
> >>>
> >>>             Regards
> >>>
> >>>             Heinz
> >>>             --
> >>>             Dr Heinz M. Kabutz (PhD CompSci)
> >>>             Author of "The Java(tm) Specialists' Newsletter"
> >>>             Sun Java Champion
> >>>             IEEE Certified Software Development Professional
> >>>             http://www.javaspecialists.eu
> >>>             Tel: +30 69 72 850 460 <tel:%2B30%2069%2072%20850%20460>
> >>>             Skype: kabutz
> >>>             _______________________________________________
> >>>             Concurrency-interest mailing list
> >>>             Concurrency-interest at cs.oswego.edu
> >>>             <mailto:Concurrency-interest at cs.oswego.edu>
> >>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>>
> >>>
> >>>     _______________________________________________
> >>>     Concurrency-interest mailing list
> >>>     Concurrency-interest at cs.oswego.edu
> >>>     <mailto:Concurrency-interest at cs.oswego.edu>
> >>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>>
> >>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Sun Nov 13 16:50:22 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 Nov 2011 07:50:22 +1000
Subject: [concurrency-interest] Propagation of signals
	tonon-interruptedthread
In-Reply-To: <CA+kOe0_y-g5nekeWmt9v4bonLgV6jvpnUAkQMUxh1EOP0xp6sg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEDJJBAA.davidcholmes@aapt.net.au>

Martin,

I still oppose this and see little point in it. Why guarantee something only
to then say that noone should be acting based on the guarantee? What do you
gain by this? The ability to change a while loop to an if-statement - and
what does that gain you, a saving of  one comparison and one branch in a
code block that suspends a thread ???

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
Buchholz
  Sent: Saturday, 12 November 2011 4:50 AM
  To: David M. Lloyd; Dr Heinz M. Kabutz
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Propagation of signals
tonon-interruptedthread


  My latest spec proposal for ReentrantLock, with stronger disclaimer:


  --- java/util/concurrent/locks/ReentrantLock.java 9 Jun 2011
07:48:44 -0000 1.96
  +++ java/util/concurrent/locks/ReentrantLock.java 11 Nov 2011
18:41:22 -0000
  @@ -467,6 +467,13 @@
        * but for <em>fair</em> locks favors those threads that have been
        * waiting the longest.
        *
  +     * <li>None of the condition {@linkplain Condition#await() waiting}
  +     * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
  +     * However, as explained in the {@link Condition} documentation,
  +     * application programs should almost never rely on this guarantee.
  +     * A {@code Condition} should generally be waited upon in a loop,
  +     * testing the state predicate that is being waited for.
  +     *
        * </ul>
        *
        * @return the Condition object

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111114/a800fb80/attachment.html>

From dl at cs.oswego.edu  Sun Nov 13 17:04:48 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 13 Nov 2011 17:04:48 -0500
Subject: [concurrency-interest] Propagation of
	signals	tonon-interruptedthread
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEDJJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEDJJBAA.davidcholmes@aapt.net.au>
Message-ID: <4EC03F00.6090409@cs.oswego.edu>

On 11/13/11 16:50, David Holmes wrote:
> Martin,
> I still oppose this and see little point in it. Why guarantee something only to
> then say that noone should be acting based on the guarantee? What do you gain by
> this? The ability to change a while loop to an if-statement - and what does that
> gain you, a saving of one comparison and one branch in a code block that
> suspends a thread ???

I think Martin would like stronger guarantees in part so that we can use
stronger unit tests for j.u.c. We do take extra measures in AQS-based
synchronizers to avoid users seeing spurious wakeups, and it would be
nice to ensure that these work as intended in all tests (rather than
only in unofficial tests).

My main reservation is that I can just barely conceive of someday
wanting to re-implementing ReentrantLock etc in a way that does not
preserve this guarantee. While this doesn't seem too likely, we've
been hurt enough times in the past by overspecifiying implementations
for me to advocate changing these.

-Doug

> David
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Martin
>     Buchholz
>     *Sent:* Saturday, 12 November 2011 4:50 AM
>     *To:* David M. Lloyd; Dr Heinz M. Kabutz
>     *Cc:* concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Propagation of signals
>     tonon-interruptedthread
>
>     My latest spec proposal for ReentrantLock, with stronger disclaimer:
>
>     --- java/util/concurrent/locks/ReentrantLock.java9 Jun 2011 07:48:44 -00001.96
>     +++ java/util/concurrent/locks/ReentrantLock.java11 Nov 2011 18:41:22 -0000
>     @@ -467,6 +467,13 @@
>     * but for <em>fair</em> locks favors those threads that have been
>     * waiting the longest.
>     *
>     + * <li>None of the condition {@linkplain Condition#await() waiting}
>     + * methods ever return due to a &quot;<em>spurious wakeup</em>&quot;.
>     + * However, as explained in the {@link Condition} documentation,
>     + * application programs should almost never rely on this guarantee.
>     + * A {@code Condition} should generally be waited upon in a loop,
>     + * testing the state predicate that is being waited for.
>     + *
>     * </ul>
>     *
>     * @return the Condition object
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From davidcholmes at aapt.net.au  Sun Nov 13 17:39:33 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 Nov 2011 08:39:33 +1000
Subject: [concurrency-interest] Propagation of signals to
	non-interruptedthread
In-Reply-To: <4EC03F00.6090409@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEDJJBAA.davidcholmes@aapt.net.au>

Hi Doug,

Doug Lea writes:
> On 11/13/11 16:50, David Holmes wrote:
> > Martin,
> > I still oppose this and see little point in it. Why guarantee
> > something only to then say that noone should be acting based
> > on the guarantee? What do you gain by this? The ability to
> > change a while loop to an if-statement - and what does that
> > gain you, a saving of one comparison and one branch in a code block that
> > suspends a thread ???
>
> I think Martin would like stronger guarantees in part so that we can use
> stronger unit tests for j.u.c. We do take extra measures in AQS-based
> synchronizers to avoid users seeing spurious wakeups, and it would be
> nice to ensure that these work as intended in all tests (rather than
> only in unofficial tests).

I assume the "official" tests are the JCK tests that have to test compliance
with the spec. But we should be able to have additional tests that test the
actual JDK implementation classes - which could check for these stronger
guarantees.

> My main reservation is that I can just barely conceive of someday
> wanting to re-implementing ReentrantLock etc in a way that does not
> preserve this guarantee. While this doesn't seem too likely, we've
> been hurt enough times in the past by overspecifiying implementations
> for me to advocate changing these.

I'd also be concerned that in the absence of any definitive testing
mechanism to ensure these guarantees hold, that bug fixes or performance
tweaks might also inadvertently break something.

David

> -Doug
>
> > David
> >
> >     -----Original Message-----
> >     *From:* concurrency-interest-bounces at cs.oswego.edu
> >     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On
> Behalf Of *Martin
> >     Buchholz
> >     *Sent:* Saturday, 12 November 2011 4:50 AM
> >     *To:* David M. Lloyd; Dr Heinz M. Kabutz
> >     *Cc:* concurrency-interest at cs.oswego.edu
> >     *Subject:* Re: [concurrency-interest] Propagation of signals
> >     tonon-interruptedthread
> >
> >     My latest spec proposal for ReentrantLock, with stronger disclaimer:
> >
> >     --- java/util/concurrent/locks/ReentrantLock.java9 Jun 2011
> 07:48:44 -00001.96
> >     +++ java/util/concurrent/locks/ReentrantLock.java11 Nov
> 2011 18:41:22 -0000
> >     @@ -467,6 +467,13 @@
> >     * but for <em>fair</em> locks favors those threads that have been
> >     * waiting the longest.
> >     *
> >     + * <li>None of the condition {@linkplain Condition#await() waiting}
> >     + * methods ever return due to a &quot;<em>spurious
> wakeup</em>&quot;.
> >     + * However, as explained in the {@link Condition} documentation,
> >     + * application programs should almost never rely on this guarantee.
> >     + * A {@code Condition} should generally be waited upon in a loop,
> >     + * testing the state predicate that is being waited for.
> >     + *
> >     * </ul>
> >     *
> >     * @return the Condition object
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From martinrb at google.com  Sun Nov 13 22:30:32 2011
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 13 Nov 2011 19:30:32 -0800
Subject: [concurrency-interest] Propagation of signals to
	non-interrupted thread
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEDHJBAA.davidcholmes@aapt.net.au>
References: <4EBD75A6.2020807@redhat.com>
	<NFBBKALFDCPFIDBNKAPCMEDHJBAA.davidcholmes@aapt.net.au>
Message-ID: <CA+kOe09MUQuZmYgi8PDM=s+YJgEt8MnFVFkJTiKk8xznfv=oqw@mail.gmail.com>

The propagation here is nothing to do with poorly written code but a
> work-around for lack of detail in the spec prior to JDK 5 that allowed an
> interrupted thread to consume a notification.


I rediscovered this spec:

      * <p>An implementation can favor responding to an interrupt over
normal
     * method return in response to a signal. In that case the
implementation
     * must ensure that the signal is redirected to another waiting thread,
if
     * there is one.

but this is an "Implementation Consideration" and it could be clearer that
a thread returning abnormally from await cannot cause a lost signal.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111113/f49d2e4e/attachment.html>

From martinrb at google.com  Sun Nov 13 23:13:12 2011
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 13 Nov 2011 20:13:12 -0800
Subject: [concurrency-interest] Propagation of signals
	tonon-interruptedthread
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEDJJBAA.davidcholmes@aapt.net.au>
References: <CA+kOe0_y-g5nekeWmt9v4bonLgV6jvpnUAkQMUxh1EOP0xp6sg@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEDJJBAA.davidcholmes@aapt.net.au>
Message-ID: <CA+kOe0_vK-s6HRr8Zhs1up=q6vV4qp7XKY=-qM_qFMtJzRe5Gw@mail.gmail.com>

>
>
> I still oppose this and see little point in it. Why guarantee something
> only to then say that noone should be acting based on the guarantee? What
> do you gain by this? The ability to change a while loop to an if-statement
> - and what does that gain you, a saving of  one comparison and one branch
> in a code block that suspends a thread ???
>

As a practical matter, enough programmers have made the mistake (?) of
depending on the current no-spurious-signal guarantee.  jsr166 has too many
users to reverse this implementation decision now - it must be enshrined in
the spec.  In fact, the jsr166 tck tests themselves are incorrect in making
this assumption.  I considered "fixing" them, but I couldn't bring myself
to weaken/complexify the tests when we could just go ahead and trivially
fix the spec instead.

In cases where conditions represent irreversible state transitions, it
seems not unreasonable to me to discard the loop, e.g.

        lock.lock();
        try {
            if (!isTerminated())
                termination.await();
        } finally {
            lock.unlock();
        }

the code will still work while being marginally more efficient, and there's
probably lots of code out there depending on that.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111113/adaf454c/attachment.html>

From davidcholmes at aapt.net.au  Mon Nov 14 17:15:28 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 15 Nov 2011 08:15:28 +1000
Subject: [concurrency-interest] Propagation of signals to
	non-interrupted thread
In-Reply-To: <CA+kOe09MUQuZmYgi8PDM=s+YJgEt8MnFVFkJTiKk8xznfv=oqw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEDPJBAA.davidcholmes@aapt.net.au>

Actually I was referring to the spec around wait/notify not Condition.await.

Note that "Implementation Consideration" is not the same as an
"Implementation Note" - this is still very much a part of the spec. These
items are called out specifically to the attention of implementors because
they need to think about them and if necessary document them.

David
  -----Original Message-----
  From: Martin Buchholz [mailto:martinrb at google.com]
  Sent: Monday, 14 November 2011 1:31 PM
  To: dholmes at ieee.org
  Cc: David M. Lloyd; Dr Heinz M. Kabutz; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Propagation of signals to
non-interrupted thread





    The propagation here is nothing to do with poorly written code but a
    work-around for lack of detail in the spec prior to JDK 5 that allowed
an
    interrupted thread to consume a notification.


  I rediscovered this spec:


        * <p>An implementation can favor responding to an interrupt over
normal
       * method return in response to a signal. In that case the
implementation
       * must ensure that the signal is redirected to another waiting
thread, if
       * there is one.


  but this is an "Implementation Consideration" and it could be clearer that
a thread returning abnormally from await cannot cause a lost signal.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/72bfdd5e/attachment.html>

From davidcholmes at aapt.net.au  Mon Nov 14 17:19:47 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 15 Nov 2011 08:19:47 +1000
Subject: [concurrency-interest] Propagation of
	signalstonon-interruptedthread
In-Reply-To: <CA+kOe0_vK-s6HRr8Zhs1up=q6vV4qp7XKY=-qM_qFMtJzRe5Gw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEEAJBAA.davidcholmes@aapt.net.au>

Martin,

You are going to have to back up statements like that with some hard
evidence. Who is depending on this unstated guarantee and why?

If the JSR166 TCK tests are incorrect then they need to be fixed. Part of
the problem is the distinction between tests against the spec versus tests
of this implementation.

I would be loathe to enshrine this guarantee in the spec for the simple
reason that it is an unprovable and untestable property.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
Buchholz
  Sent: Monday, 14 November 2011 2:13 PM
  To: concurrency-interest
  Subject: Re: [concurrency-interest] Propagation of
signalstonon-interruptedthread



    I still oppose this and see little point in it. Why guarantee something
only to then say that noone should be acting based on the guarantee? What do
you gain by this? The ability to change a while loop to an if-statement -
and what does that gain you, a saving of  one comparison and one branch in a
code block that suspends a thread ???


  As a practical matter, enough programmers have made the mistake (?) of
depending on the current no-spurious-signal guarantee.  jsr166 has too many
users to reverse this implementation decision now - it must be enshrined in
the spec.  In fact, the jsr166 tck tests themselves are incorrect in making
this assumption.  I considered "fixing" them, but I couldn't bring myself to
weaken/complexify the tests when we could just go ahead and trivially fix
the spec instead.


  In cases where conditions represent irreversible state transitions, it
seems not unreasonable to me to discard the loop, e.g.


          lock.lock();
          try {
              if (!isTerminated())
                  termination.await();
          } finally {
              lock.unlock();
          }


  the code will still work while being marginally more efficient, and
there's probably lots of code out there depending on that.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/a9e150be/attachment.html>

From martinrb at google.com  Mon Nov 14 21:26:56 2011
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 14 Nov 2011 18:26:56 -0800
Subject: [concurrency-interest] Propagation of
	signalstonon-interruptedthread
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEEAJBAA.davidcholmes@aapt.net.au>
References: <CA+kOe0_vK-s6HRr8Zhs1up=q6vV4qp7XKY=-qM_qFMtJzRe5Gw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEEAJBAA.davidcholmes@aapt.net.au>
Message-ID: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>

 Who is depending on this unstated guarantee and why?
>


http://www.google.com/codesearch#ZdqJIjLOcOo/trunk/anaglyphe/PanneauAnaglyphe.java&ct=rc&cd=35&q=%5CbawaitNanos%5C(%20lang:%5Ejava$&sq=&l=402
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111114/1dc567ec/attachment.html>

From davidcholmes at aapt.net.au  Mon Nov 14 21:37:15 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 15 Nov 2011 12:37:15 +1000
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>

One example of some broken code is not very compelling. This code doesn't
even handle timeout correctly. I strongly suspect the author of this code
was not relying on no-spurious-wakeups but was simply completely ignorant of
them and so would have used the same style of code even with Object.wait.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
Buchholz
  Sent: Tuesday, 15 November 2011 12:27 PM
  To: concurrency-interest
  Subject: Re: [concurrency-interest] Propagation
ofsignalstonon-interruptedthread





     Who is depending on this unstated guarantee and why?


   http://www.google.com/codesearch#ZdqJIjLOcOo/trunk/anaglyphe/PanneauAnagl
yphe.java&ct=rc&cd=35&q=%5CbawaitNanos%5C(%20lang:%5Ejava$&sq=&l=402
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/0e2f41c1/attachment.html>

From martinrb at google.com  Tue Nov 15 09:57:16 2011
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 15 Nov 2011 06:57:16 -0800
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
Message-ID: <CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>

On Mon, Nov 14, 2011 at 18:37, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> One example of some broken code is not very compelling. This code doesn't
> even handle timeout correctly. I strongly suspect the author of this code
> was not relying on no-spurious-wakeups but was simply completely ignorant
> of them and so would have used the same style of code even with Object.wait.
>

Sure.

My argument is not about careful programmers who have thoughtfully read the
spec, whose number is vanishingly small.  This is all about real-world
crappy code in production that happens to work today, and will fail
unpredictably under stress if you withdraw the de-facto guarantees.

If Object.wait has also been providing the de-facto guarantee in recent
releases, I would like its spec updated as well to provide the stronger
guarantee.  But my argument is stronger for j.u.c.locks, since everyone
uses the same implementation in practice.

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/cfe011e5/attachment-0001.html>

From heinz at javaspecialists.eu  Tue Nov 15 13:59:59 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 Nov 2011 20:59:59 +0200
Subject: [concurrency-interest]
	Propagation	ofsignalstonon-interruptedthread
In-Reply-To: <CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
Message-ID: <4EC2B6AF.1070302@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/33055ae7/attachment.html>

From viktor.klang at gmail.com  Tue Nov 15 14:27:31 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 15 Nov 2011 20:27:31 +0100
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <4EC2B6AF.1070302@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
Message-ID: <CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>

On Tue, Nov 15, 2011 at 7:59 PM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> **
> On an only vaguely related note, I discovered today, whilst doing a
> throughput test of atomic integer vs reentrant lock, that every time you
> call lock.lock(), it creates a new object of 32 bytes!  For some reason, I
> always assumed that lock.lock() would not construct any objects, so was
> surprised when the GC started acting up.  The object that is constructed is
> the AbstractQueuedSynchronizer$Node in the addWaiter() method in the
> AbstractQueuedSynchronizer.
>

Yeah, that one's a real treat.


>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professionalhttp://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
>
> On 11/15/11 4:57 PM, Martin Buchholz wrote:
>
>
>
> On Mon, Nov 14, 2011 at 18:37, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>>  One example of some broken code is not very compelling. This code
>> doesn't even handle timeout correctly. I strongly suspect the author of
>> this code was not relying on no-spurious-wakeups but was simply completely
>> ignorant of them and so would have used the same style of code even with
>> Object.wait.
>>
>
>  Sure.
>
>  My argument is not about careful programmers who have thoughtfully read
> the spec, whose number is vanishingly small.  This is all about real-world
> crappy code in production that happens to work today, and will fail
> unpredictably under stress if you withdraw the de-facto guarantees.
>
>  If Object.wait has also been providing the de-facto guarantee in recent
> releases, I would like its spec updated as well to provide the stronger
> guarantee.  But my argument is stronger for j.u.c.locks, since everyone
> uses the same implementation in practice.
>
>  Martin
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/2a4d8344/attachment.html>

From heinz at javaspecialists.eu  Tue Nov 15 14:29:18 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 Nov 2011 21:29:18 +0200
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
Message-ID: <4EC2BD8E.3010107@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/8bc904d8/attachment.html>

From david.lloyd at redhat.com  Tue Nov 15 14:37:59 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 15 Nov 2011 13:37:59 -0600
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
Message-ID: <4EC2BF97.5030504@redhat.com>

Seems necessary to me though - somewhere you have to record what threads 
are waiting for the lock so you can wake one of them up when it becomes 
available.

On 11/15/2011 01:27 PM, ?iktor ?lang wrote:
>
>
> On Tue, Nov 15, 2011 at 7:59 PM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu <mailto:heinz at javaspecialists.eu>> wrote:
>
>     __
>     On an only vaguely related note, I discovered today, whilst doing a
>     throughput test of atomic integer vs reentrant lock, that every time
>     you call lock.lock(), it creates a new object of 32 bytes!  For some
>     reason, I always assumed that lock.lock() would not construct any
>     objects, so was surprised when the GC started acting up.  The object
>     that is constructed is the AbstractQueuedSynchronizer$Node in the
>     addWaiter() method in the AbstractQueuedSynchronizer.
>
>
> Yeah, that one's a real treat.
>
>
>     Regards
>
>     Heinz
>     --
>     Dr Heinz M. Kabutz (PhD CompSci)
>     Author of"The Java(tm) Specialists'  Newsletter"
>     Sun Java Champion
>     IEEE Certified Software Development Professional
>     http://www.javaspecialists.eu
>     Tel:+30 69 72 850 460  <tel:%2B30%2069%2072%20850%20460>
>     Skype: kabutz
>
>
>
>     On 11/15/11 4:57 PM, Martin Buchholz wrote:
>>
>>
>>     On Mon, Nov 14, 2011 at 18:37, David Holmes
>>     <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>         One example of some broken code is not very compelling. This
>>         code doesn't even handle timeout correctly. I strongly suspect
>>         the author of this code was not relying on no-spurious-wakeups
>>         but was simply completely ignorant of them and so would have
>>         used the same style of code even with Object.wait.
>>
>>
>>     Sure.
>>
>>     My argument is not about careful programmers who have thoughtfully
>>     read the spec, whose number is vanishingly small.  This is all
>>     about real-world crappy code in production that happens to work
>>     today, and will fail unpredictably under stress if you withdraw
>>     the de-facto guarantees.
>>
>>     If Object.wait has also been providing the de-facto guarantee in
>>     recent releases, I would like its spec updated as well to provide
>>     the stronger guarantee.  But my argument is stronger for
>>     j.u.c.locks, since everyone uses the same implementation in practice.
>>
>>     Martin
>>     ------------------------------------------------------------------------
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/>- Enterprise-Grade Scala from the Experts
>
> Twitter: @viktorklang
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
- DML

From martinrb at google.com  Tue Nov 15 14:39:39 2011
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 15 Nov 2011 11:39:39 -0800
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <4EC2BD8E.3010107@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
Message-ID: <CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>

On Tue, Nov 15, 2011 at 11:29, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu>wrote:

> **
> Just a follow-up on my last post.  This object is only constructed when
> there is contention over the lock.
>
> But if the lock is not available and you have to block anyways, the cost
of context switching dwarfs the cost of allocating the Node object.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/d0ed2e72/attachment-0001.html>

From jim.andreou at gmail.com  Tue Nov 15 14:46:34 2011
From: jim.andreou at gmail.com (Dimitris Andreou)
Date: Tue, 15 Nov 2011 11:46:34 -0800
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <4EC2BD8E.3010107@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
Message-ID: <CADJdpBxaiXYN2TmM3a4v2Wryg53Km27bxXQ2u+TCP5S7hkJtNA@mail.gmail.com>

Which is (almost) the same deal as with synchronized blocks. The
difference is that the allocated object is from a native object pool,
not in the java heap, so no extra gc overhead involved there.

2011/11/15 Dr Heinz M. Kabutz <heinz at javaspecialists.eu>:
> Just a follow-up on my last post.? This object is only constructed when
> there is contention over the lock.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> On 11/15/11 9:27 PM, ?iktor ?lang wrote:
>
> On Tue, Nov 15, 2011 at 7:59 PM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
>>
>> On an only vaguely related note, I discovered today, whilst doing a
>> throughput test of atomic integer vs reentrant lock, that every time you
>> call lock.lock(), it creates a new object of 32 bytes!? For some reason, I
>> always assumed that lock.lock() would not construct any objects, so was
>> surprised when the GC started acting up.? The object that is constructed is
>> the AbstractQueuedSynchronizer$Node in the addWaiter() method in the
>> AbstractQueuedSynchronizer.
>
> Yeah, that one's a real treat.
>
>>
>> Regards
>>
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 72 850 460
>> Skype: kabutz
>>
>>
>> On 11/15/11 4:57 PM, Martin Buchholz wrote:
>>
>> On Mon, Nov 14, 2011 at 18:37, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>>>
>>> One example of some broken code is not very compelling. This code doesn't
>>> even handle timeout correctly. I strongly suspect the author of this code
>>> was not relying on no-spurious-wakeups but was simply completely ignorant of
>>> them and so would have used the same style of code even with Object.wait.
>>
>> Sure.
>> My argument is not about careful programmers who have thoughtfully read
>> the spec, whose number is vanishingly small. ?This is all about real-world
>> crappy code in production that happens to work today, and will fail
>> unpredictably under stress if you withdraw the de-facto guarantees.
>> If Object.wait has also been providing the de-facto guarantee in recent
>> releases, I would like its spec updated as well to provide the stronger
>> guarantee. ?But my argument is stronger for j.u.c.locks, since everyone uses
>> the same implementation in practice.
>> Martin
>>
>> ________________________________
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe?- Enterprise-Grade Scala from the Experts
>
> Twitter: @viktorklang
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From heinz at javaspecialists.eu  Tue Nov 15 15:50:26 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 Nov 2011 22:50:26 +0200
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
Message-ID: <4EC2D092.1020707@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/7cfc6e80/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: AtomicThroughputGraphs.pdf
Type: application/pdf
Size: 73062 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111115/7cfc6e80/attachment-0001.pdf>

From cheremin at gmail.com  Tue Nov 15 16:03:39 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Wed, 16 Nov 2011 01:03:39 +0400
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <4EC2D092.1020707@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
Message-ID: <CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>

It seems very strange to me -- how can value updated by many threads
guarded by ReentrantLock outperform just simple CAS? As far, as I
know, ReentrantLock on fast path still has at least one CAS + value
update itself, it must be slower then just one CAS in an way.

From heinz at javaspecialists.eu  Tue Nov 15 16:10:19 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 Nov 2011 23:10:19 +0200
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
Message-ID: <4EC2D53B.6040203@javaspecialists.eu>

I would imagine that there could be quite a few times that the CAS has 
to be retried until it is successful.  Look at the bottom right graph - 
"Throughput - Thirty-two Threads" - this is now throughput (normalized 
and on a logarithmic scale) against number of threads.  The 
AtomicPseudoRandom class is the same as in Brian's book.  If you look at 
the blue line, it dips down the more threads you have per 
AtomicPseudoRandom class, as the probability of clashes increases.  I 
could add a counter into that class to verify my assertion, but I'm 
pretty sure that the number of clashes will be substantial.

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 11/15/11 11:03 PM, Ruslan Cheremin wrote:
> It seems very strange to me -- how can value updated by many threads
> guarded by ReentrantLock outperform just simple CAS? As far, as I
> know, ReentrantLock on fast path still has at least one CAS + value
> update itself, it must be slower then just one CAS in an way.
>
>   

From cheremin at gmail.com  Wed Nov 16 05:23:03 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Wed, 16 Nov 2011 14:23:03 +0400
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <4EC2D53B.6040203@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
Message-ID: <CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>

But it should be also more clashes inside AQS.compareAndSetState() --
which called on fast path of ReentrantLock.lock(). Or you want to say,
that ReentrantLock version has longer code path, so it has effect of
back off, slowering execution down a bit, and so reducing actual
contention on CASed variables?

2011/11/16 Dr Heinz M. Kabutz <heinz at javaspecialists.eu>:
> I would imagine that there could be quite a few times that the CAS has to be
> retried until it is successful. ?Look at the bottom right graph -
> "Throughput - Thirty-two Threads" - this is now throughput (normalized and
> on a logarithmic scale) against number of threads. ?The AtomicPseudoRandom
> class is the same as in Brian's book. ?If you look at the blue line, it dips
> down the more threads you have per AtomicPseudoRandom class, as the
> probability of clashes increases. ?I could add a counter into that class to
> verify my assertion, but I'm pretty sure that the number of clashes will be
> substantial.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> On 11/15/11 11:03 PM, Ruslan Cheremin wrote:
>>
>> It seems very strange to me -- how can value updated by many threads
>> guarded by ReentrantLock outperform just simple CAS? As far, as I
>> know, ReentrantLock on fast path still has at least one CAS + value
>> update itself, it must be slower then just one CAS in an way.
>>
>>
>


From vitalyd at gmail.com  Wed Nov 16 09:05:17 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 16 Nov 2011 09:05:17 -0500
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
Message-ID: <CAHjP37HvepLewKqcz0wM0ufMDcu9GS0G8XTNRoHLtk4GNEmZGg@mail.gmail.com>

But AQS doesn't spin on the CAS so if it fails to lock it suspends the
thread.  When you have lots of contention, it's usually the case that a
spinning CAS is less efficient than a mutex at that point.

In the example in this thread, the machine has 8 cores.  8 cas-spinning
threads still beats the lock.  Once you increase the number of threads >
number of cpus, it loses because now you have runnable threads exceeding
core count and os has to context switch them.  With a mutex, that's not the
case so it's more efficient.
On Nov 16, 2011 5:26 AM, "Ruslan Cheremin" <cheremin at gmail.com> wrote:

> But it should be also more clashes inside AQS.compareAndSetState() --
> which called on fast path of ReentrantLock.lock(). Or you want to say,
> that ReentrantLock version has longer code path, so it has effect of
> back off, slowering execution down a bit, and so reducing actual
> contention on CASed variables?
>
> 2011/11/16 Dr Heinz M. Kabutz <heinz at javaspecialists.eu>:
> > I would imagine that there could be quite a few times that the CAS has
> to be
> > retried until it is successful.  Look at the bottom right graph -
> > "Throughput - Thirty-two Threads" - this is now throughput (normalized
> and
> > on a logarithmic scale) against number of threads.  The
> AtomicPseudoRandom
> > class is the same as in Brian's book.  If you look at the blue line, it
> dips
> > down the more threads you have per AtomicPseudoRandom class, as the
> > probability of clashes increases.  I could add a counter into that class
> to
> > verify my assertion, but I'm pretty sure that the number of clashes will
> be
> > substantial.
> >
> > Regards
> >
> > Heinz
> > --
> > Dr Heinz M. Kabutz (PhD CompSci)
> > Author of "The Java(tm) Specialists' Newsletter"
> > Sun Java Champion
> > IEEE Certified Software Development Professional
> > http://www.javaspecialists.eu
> > Tel: +30 69 72 850 460
> > Skype: kabutz
> >
> >
> > On 11/15/11 11:03 PM, Ruslan Cheremin wrote:
> >>
> >> It seems very strange to me -- how can value updated by many threads
> >> guarded by ReentrantLock outperform just simple CAS? As far, as I
> >> know, ReentrantLock on fast path still has at least one CAS + value
> >> update itself, it must be slower then just one CAS in an way.
> >>
> >>
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/bbd0c71b/attachment.html>

From heinz at javaspecialists.eu  Wed Nov 16 10:08:20 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 16 Nov 2011 17:08:20 +0200
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
Message-ID: <4EC3D1E4.8080206@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/8c403357/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen shot 2011-11-16 at 2.58.56 PM.png
Type: image/png
Size: 43514 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/8c403357/attachment-0001.png>

From morganconrad at yahoo.com  Wed Nov 16 16:31:38 2011
From: morganconrad at yahoo.com (Morgan Conrad)
Date: Wed, 16 Nov 2011 13:31:38 -0800 (PST)
Subject: [concurrency-interest] Question / Feature Request for
	ExecutorService
Message-ID: <1321479098.67178.YahooMailClassic@web112120.mail.gq1.yahoo.com>

This question came up on StackOverflow.
??
see?http://stackoverflow.com/questions/8158500/with-a-java-executorservice-how-do-i-complete-actively-executing-tasks-but-halt

Basically, the request seems reasonable:

"I want to call a command that:??
  a. Completes the currently active task or tasks (like?shutdown).
??b. Halts the processing of waiting tasks (like?shutdownNow)."

Is there a good way to do this using the existing code?

Sincerely,
Morgan Conrad




From heinz at javaspecialists.eu  Wed Nov 16 16:37:04 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 16 Nov 2011 23:37:04 +0200
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
Message-ID: <4EC42D00.20003@javaspecialists.eu>

In Java 6, classes like ConcurrentLinkedQueue and SynchronousQueue used 
the AtomicReferenceFieldUpdater to update the next, head, etc. fields.

In Java 7, this was changed to instead use Unsafe.compareAndSwapObject() 
directly.

The AtomicReferenceFieldUpdater does a bunch of error checking every 
time it is called, like this:

            if (obj == null || obj.getClass() != tclass || cclass != null ||
                (update != null && vclass != null &&
                 vclass != update.getClass()))
                updateCheck(obj, update);
            return unsafe.compareAndSwapObject(obj, offset, expect, update);

My thinking is that the programmers changing ConcurrentLinkedQueue et al 
probably wanted to improve the performance by not having to do all that 
checking every time it is called.  The Unsafe.compareAndSwapObject() 
method is probably compiled to a single CPU instruction.

Is that correct?

Is there any other reason for this change?

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz


From heinz at javaspecialists.eu  Wed Nov 16 16:52:52 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 16 Nov 2011 23:52:52 +0200
Subject: [concurrency-interest] Question / Feature Request
	for	ExecutorService
In-Reply-To: <1321479098.67178.YahooMailClassic@web112120.mail.gq1.yahoo.com>
References: <1321479098.67178.YahooMailClassic@web112120.mail.gq1.yahoo.com>
Message-ID: <4EC430B4.9090908@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/d4de904b/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: FutureResultIterable.java
Type: text/x-java
Size: 3041 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/d4de904b/attachment.bin>

From joe.bowbeer at gmail.com  Wed Nov 16 17:05:00 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 16 Nov 2011 14:05:00 -0800
Subject: [concurrency-interest] Question / Feature Request for
	ExecutorService
In-Reply-To: <1321479098.67178.YahooMailClassic@web112120.mail.gq1.yahoo.com>
References: <1321479098.67178.YahooMailClassic@web112120.mail.gq1.yahoo.com>
Message-ID: <CAHzJPEoo9bEtp2tyaRotiCma9UsNHLA6a7fCkJiyCxq+P9ns2w@mail.gmail.com>

With ThreadPoolExecutor, you have the API to accomplish this in a couple of
ways.

1: tpe.shutdown(); tpe.getQueue().drainTo(submitted);

The above is similar to what shutdownNow does.

2. Another way would be to wrap the tasks on submission with a Runnable
that checks isTerminating() and punts if it is true.

Joe

On Wed, Nov 16, 2011 at 1:31 PM, Morgan Conrad <morganconrad at yahoo.com>wrote:

> This question came up on StackOverflow.
>
> see
> http://stackoverflow.com/questions/8158500/with-a-java-executorservice-how-do-i-complete-actively-executing-tasks-but-halt
>
> Basically, the request seems reasonable:
>
> "I want to call a command that:
>  a. Completes the currently active task or tasks (like shutdown).
>   b. Halts the processing of waiting tasks (like shutdownNow)."
>
> Is there a good way to do this using the existing code?
>
> Sincerely,
> Morgan Conrad
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/02e3ba8b/attachment.html>

From martinrb at google.com  Wed Nov 16 18:44:58 2011
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 16 Nov 2011 15:44:58 -0800
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC42D00.20003@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
Message-ID: <CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>

On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu>wrote:

> In Java 6, classes like ConcurrentLinkedQueue and SynchronousQueue used
> the AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>
> In Java 7, this was changed to instead use Unsafe.compareAndSwapObject()
> directly.
>
> The AtomicReferenceFieldUpdater does a bunch of error checking every time
> it is called, like this:
>
>           if (obj == null || obj.getClass() != tclass || cclass != null ||
>               (update != null && vclass != null &&
>                vclass != update.getClass()))
>               updateCheck(obj, update);
>           return unsafe.compareAndSwapObject(**obj, offset, expect,
> update);
>
> My thinking is that the programmers changing ConcurrentLinkedQueue et al
> probably wanted to improve the performance by not having to do all that
> checking every time it is called.  The Unsafe.compareAndSwapObject() method
> is probably compiled to a single CPU instruction.
>
> Is that correct?
>
> Yes.


> Is there any other reason for this change?
>
> The previous way was more principled, in the manner of "eat your own
dogfood".  Maybe we've become just a tiny bit less principled.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111116/59defd56/attachment.html>

From gkorland at gmail.com  Thu Nov 17 02:40:38 2011
From: gkorland at gmail.com (Guy Korland)
Date: Thu, 17 Nov 2011 09:40:38 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
	what about Java?
Message-ID: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>

It seems like the upcoming GCC 4.7.0 is going to include a build-in support
for Transactional memory.

See: http://lwn.net/Articles/466513/
"Following a last-minute request, the "transactional memory" GCC branch has
been merged into the trunk for the 4.7.0 release. Transactional memory is
specified in a draft standard [PDF] for C and C++; the idea is to provide a
relatively simple way for developers to execute code with atomic "all or
nothing" semantics."

I think it's about time to set a JSR about adding STM to Java also:
1. Adding to that the fact that STM can be added much more easily to Java
than JVM.
2. JVM based Dynamic languages like Scala already offer their alternative.
3. There exists couple of working implementations like
Multiverse, DSTM2, DeuceSTM...

Any thoughts?

Regards,
Guy Korland
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/b418a426/attachment-0001.html>

From elizarov at devexperts.com  Thu Nov 17 05:53:52 2011
From: elizarov at devexperts.com (Roman Elizarov)
Date: Thu, 17 Nov 2011 10:53:52 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
Message-ID: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>

The downside is that it fuels the use of sun.misc.Unsafe by 3rd party programmer. Every day there are more and more blogs explaining advantages of Unsafe to the average programmer. I've just recently reposted one of those for the Russian programmers community.

Are there any concrete plans (say for Java 8) to bring the performance of **Updater classes on par with Unsafe (maybe by improving HotSpot, so that it can eliminate all the extra checks and compile **Updater method into the same code as produced by direct use of Unsafe)? Shall we continue to rely on Unsafe for Java 8 and beyond or get ready for its eventual elimination from our codebase?

Sincerely,
Roman Elizarov

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin Buchholz
Sent: Thursday, November 17, 2011 3:45 AM
To: Dr Heinz M. Kabutz
Cc: concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe


On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz <heinz at javaspecialists.eu<mailto:heinz at javaspecialists.eu>> wrote:
In Java 6, classes like ConcurrentLinkedQueue and SynchronousQueue used the AtomicReferenceFieldUpdater to update the next, head, etc. fields.

In Java 7, this was changed to instead use Unsafe.compareAndSwapObject() directly.

The AtomicReferenceFieldUpdater does a bunch of error checking every time it is called, like this:

          if (obj == null || obj.getClass() != tclass || cclass != null ||
              (update != null && vclass != null &&
               vclass != update.getClass()))
              updateCheck(obj, update);
          return unsafe.compareAndSwapObject(obj, offset, expect, update);

My thinking is that the programmers changing ConcurrentLinkedQueue et al probably wanted to improve the performance by not having to do all that checking every time it is called.  The Unsafe.compareAndSwapObject() method is probably compiled to a single CPU instruction.

Is that correct?
Yes.

Is there any other reason for this change?
The previous way was more principled, in the manner of "eat your own dogfood".  Maybe we've become just a tiny bit less principled.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/cf2f3047/attachment.html>

From heinz at javaspecialists.eu  Thu Nov 17 06:01:12 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 17 Nov 2011 13:01:12 +0200
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>	<4EC2D53B.6040203@javaspecialists.eu>	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
Message-ID: <4EC4E978.2080105@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/531da712/attachment.html>

From viktor.klang at gmail.com  Thu Nov 17 06:10:57 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 17 Nov 2011 12:10:57 +0100
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
Message-ID: <CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>

On Thu, Nov 17, 2011 at 11:53 AM, Roman Elizarov <elizarov at devexperts.com>wrote:

>  The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
> programmer. Every day there are more and more blogs explaining advantages
> of Unsafe to the average programmer. I?ve just recently reposted one of
> those for the Russian programmers community.****
>
> ** **
>
> Are there any concrete plans (say for Java 8) to bring the performance of
> **Updater classes on par with Unsafe (maybe by improving HotSpot, so that
> it can eliminate all the extra checks and compile **Updater method into the
> same code as produced by direct use of Unsafe)? Shall we co
>
ntinue to rely on Unsafe for Java 8 and beyond
>
or get ready for its eventual elimination from our codebase? ****
>
> **
>

Yes, this is really important. I was under the assumption (yes, always a
bad thing) that the Updater was highly optimized, why would I else use them?

Right now it feels like if you're doing high-perf concurrency in this sense
you have to choose between:

A) Cache-trashing (and extra memory usage) because you went with
AtomicLong/Ref whatnot
B) CPU overhead caused by Atomic*Updaters and if you do any inheritance
you'll get even more checks each call (and extra mem usage due to padding).
C) Sacrifice cross-platform because you had to drop down to Unsafe to get
the correct machinecode emitted.

Would be nice to have "unsafe" versions of all methods of the
Atomic*Updaters that does not do checks each invocation.

Cheers,
?



> **
>
> Sincerely,****
>
> Roman Elizarov****
>
> ** **
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Martin Buchholz
> *Sent:* Thursday, November 17, 2011 3:45 AM
> *To:* Dr Heinz M. Kabutz
> *Cc:* concurrency-interest
> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
> Unsafe****
>
> ** **
>
> ** **
>
> On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz <
> heinz at javaspecialists.eu> wrote:****
>
> In Java 6, classes like ConcurrentLinkedQueue and SynchronousQueue used
> the AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>
> In Java 7, this was changed to instead use Unsafe.compareAndSwapObject()
> directly.
>
> The AtomicReferenceFieldUpdater does a bunch of error checking every time
> it is called, like this:
>
>           if (obj == null || obj.getClass() != tclass || cclass != null ||
>               (update != null && vclass != null &&
>                vclass != update.getClass()))
>               updateCheck(obj, update);
>           return unsafe.compareAndSwapObject(obj, offset, expect, update);
>
> My thinking is that the programmers changing ConcurrentLinkedQueue et al
> probably wanted to improve the performance by not having to do all that
> checking every time it is called.  The Unsafe.compareAndSwapObject() method
> is probably compiled to a single CPU instruction.
>
> Is that correct?****
>
> Yes.****
>
>  ****
>
> Is there any other reason for this change?****
>
>  The previous way was more principled, in the manner of "eat your own
> dogfood".  Maybe we've become just a tiny bit less principled.****
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/55c99b18/attachment-0001.html>

From elizarov at devexperts.com  Thu Nov 17 06:26:40 2011
From: elizarov at devexperts.com (Roman Elizarov)
Date: Thu, 17 Nov 2011 11:26:40 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC4E978.2080105@javaspecialists.eu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com><NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au><CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com><4EC2B6AF.1070302@javaspecialists.eu><CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com><4EC2BD8E.3010107@javaspecialists.eu><CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com><4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com><4EC2D53B.6040203@javaspecialists.eu><CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com><4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<4EC4E978.2080105@javaspecialists.eu>
Message-ID: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F458@RAVEN.office.devexperts.com>

Unfortunately, I had to use Unsafe myself from time to time just for performance reasons (because I have to write a lot of high-performance code).

/Roman

From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
Sent: Thursday, November 17, 2011 3:01 PM
To: Roman Elizarov
Cc: Martin Buchholz; concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

My thoughts exactly, Roman.  Us mere mortals figure out the "how to" by reading JDK source code and when we see Unsafe being used, we go: "Ah, now that's a good class to use..." ;-)

>From my newsletter:  http://www.javaspecialists.eu/archive/Issue194.html

"In a recent email, one of my youngest readers, 17 year old Mr S.Perlov from the Ukraine, suggested that I tell you about the class sun.misc.Unsafe. Up to now I have avoided writing about it, as it is a class that should be avoided. Here are two reasons: #1 it is "unsafe" and lets us do all the nasty things that we had in C, such as pointer arithmetic or modifying memory directly. #2 it is a sun.misc.* class. You do not know when that might be renamed to oracle.misc.Unsafe or whether you will even run your program on a Sun JVM. By binding yourself to a specific implementation of the JVM, you are limiting the application of your code.

Two reasons to not use Unsafe. I have personally never used Unsafe in production code. Some experts do use it to write directly to memory. Dangerous stuff! "


Regards



Heinz

--

Dr Heinz M. Kabutz (PhD CompSci)

Author of "The Java(tm) Specialists' Newsletter"

Sun Java Champion

IEEE Certified Software Development Professional

http://www.javaspecialists.eu

Tel: +30 69 72 850 460

Skype: kabutz


On 11/17/11 12:53 PM, Roman Elizarov wrote:
The downside is that it fuels the use of sun.misc.Unsafe by 3rd party programmer. Every day there are more and more blogs explaining advantages of Unsafe to the average programmer. I've just recently reposted one of those for the Russian programmers community.

Are there any concrete plans (say for Java 8) to bring the performance of **Updater classes on par with Unsafe (maybe by improving HotSpot, so that it can eliminate all the extra checks and compile **Updater method into the same code as produced by direct use of Unsafe)? Shall we continue to rely on Unsafe for Java 8 and beyond or get ready for its eventual elimination from our codebase?

Sincerely,
Roman Elizarov

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin Buchholz
Sent: Thursday, November 17, 2011 3:45 AM
To: Dr Heinz M. Kabutz
Cc: concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe


On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz <heinz at javaspecialists.eu<mailto:heinz at javaspecialists.eu>> wrote:
In Java 6, classes like ConcurrentLinkedQueue and SynchronousQueue used the AtomicReferenceFieldUpdater to update the next, head, etc. fields.

In Java 7, this was changed to instead use Unsafe.compareAndSwapObject() directly.

The AtomicReferenceFieldUpdater does a bunch of error checking every time it is called, like this:

          if (obj == null || obj.getClass() != tclass || cclass != null ||
              (update != null && vclass != null &&
               vclass != update.getClass()))
              updateCheck(obj, update);
          return unsafe.compareAndSwapObject(obj, offset, expect, update);

My thinking is that the programmers changing ConcurrentLinkedQueue et al probably wanted to improve the performance by not having to do all that checking every time it is called.  The Unsafe.compareAndSwapObject() method is probably compiled to a single CPU instruction.

Is that correct?
Yes.

Is there any other reason for this change?
The previous way was more principled, in the manner of "eat your own dogfood".  Maybe we've become just a tiny bit less principled.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/f6653b7e/attachment.html>

From mlists at juma.me.uk  Thu Nov 17 07:01:39 2011
From: mlists at juma.me.uk (Ismael Juma)
Date: Thu, 17 Nov 2011 12:01:39 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
Message-ID: <CAD5tkZa_T+u8ozK760jHOTrtHmMnRkXnERVtMrLBprzqmsdBjw@mail.gmail.com>

On Thu, Nov 17, 2011 at 10:53 AM, Roman Elizarov <elizarov at devexperts.com>wrote:

>  The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
> programmer. Every day there are more and more blogs explaining advantages
> of Unsafe to the average programmer.
>

Yes. A common use of Unsafe these days is to improve the performance of
compression algorithms written in pure Java:

https://github.com/dain/snappy/blob/master/src/main/java/org/iq80/snappy/UnsafeMemory.java
https://github.com/ning/compress/blob/master/src/main/java/com/ning/compress/lzf/impl/UnsafeChunkDecoder.java

Off-heap caches too:

https://issues.apache.org/jira/browse/CASSANDRA-3271

It's a shame that this is needed.

Best,
Ismael
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/332693a5/attachment.html>

From dl at cs.oswego.edu  Thu Nov 17 07:37:07 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 17 Nov 2011 07:37:07 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>	<4EC2D53B.6040203@javaspecialists.eu>	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>	<4EC42D00.20003@javaspecialists.eu>	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
Message-ID: <4EC4FFF3.8090804@cs.oswego.edu>

On 11/17/11 06:10, ?iktor ?lang wrote:
> Right now it feels like if you're doing high-perf concurrency in this sense you
> have to choose between:
>
> A) Cache-trashing (and extra memory usage) because you went with AtomicLong/Ref
> whatnot
> B) CPU overhead caused by Atomic*Updaters and if you do any inheritance you'll
> get even more checks each call (and extra mem usage due to padding).
> C) Sacrifice cross-platform because you had to drop down to Unsafe to get the
> correct machinecode emitted.
>

Yes.

The main underlying problem is a fundamental one: Java bytecodes
support only two field read/write operations (getField/putField),
plus an implicit mode argument for volatiles. However, there is no
casField, or special r/w modes like releaseField. One level up,
there is no syntax for "lvalue" operations on fields. So the
only options are to directly invoke these lvalue operations
via Unsafe, which require that you know the address of the field,
or to use Updaters, that don't require the address, but must
perform type checks and security checks that you have access to the
field.

No one knows of any good alternatives. We tried for Java7
to reduce need for either option by proposing Fences that
would at least emulate the different memory modes, but that's
also problematic enough to not be worth adopting.

It's not hard to imagine some nicer syntax to support
these operations (as in a.someField.compareAndSet(x, y))
and also to perform class-loading-time validations (similarly
to "quickening") and/or using invokeDynamic. But these matters
never attain high enough priority when people consider syntax
enhancements.

Portability of Unsafe constructions is not really a problem.
We frequently communicate with all production JVM implementors
to help ensure that they are correctly supported.

-Doug



From viktor.klang at gmail.com  Thu Nov 17 07:49:00 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 17 Nov 2011 13:49:00 +0100
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC4FFF3.8090804@cs.oswego.edu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
	<4EC4FFF3.8090804@cs.oswego.edu>
Message-ID: <CANPzfU_WacEvNdG=5eTn_uxmTSU09ppoM+7o_L29k6KQVo1Wtg@mail.gmail.com>

On Thu, Nov 17, 2011 at 1:37 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 11/17/11 06:10, ?iktor ?lang wrote:
>
>> Right now it feels like if you're doing high-perf concurrency in this
>> sense you
>> have to choose between:
>>
>> A) Cache-trashing (and extra memory usage) because you went with
>> AtomicLong/Ref
>> whatnot
>> B) CPU overhead caused by Atomic*Updaters and if you do any inheritance
>> you'll
>> get even more checks each call (and extra mem usage due to padding).
>> C) Sacrifice cross-platform because you had to drop down to Unsafe to get
>> the
>> correct machinecode emitted.
>>
>>
> Yes.
>
> The main underlying problem is a fundamental one: Java bytecodes
> support only two field read/write operations (getField/putField),
> plus an implicit mode argument for volatiles. However, there is no
> casField, or special r/w modes like releaseField. One level up,
> there is no syntax for "lvalue" operations on fields. So the
> only options are to directly invoke these lvalue operations
> via Unsafe, which require that you know the address of the field,
> or to use Updaters, that don't require the address, but must
> perform type checks and security checks that you have access to the
> field.
>
> No one knows of any good alternatives. We tried for Java7
> to reduce need for either option by proposing Fences that
> would at least emulate the different memory modes, but that's
> also problematic enough to not be worth adopting.
>
> It's not hard to imagine some nicer syntax to support
> these operations (as in a.someField.compareAndSet(x, y))
> and also to perform class-loading-time validations (similarly
> to "quickening") and/or using invokeDynamic. But these matters
> never attain high enough priority when people consider syntax
> enhancements.
>
> Portability of Unsafe constructions is not really a problem.
> We frequently communicate with all production JVM implementors
> to help ensure that they are correctly supported.
>

Alright, that's a good clarification, I've always avoided it from
compatibility reasons.
Is this case the same with Android?

Cheers,
?


>
> -Doug
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/cc5f29b4/attachment-0001.html>

From dl at cs.oswego.edu  Thu Nov 17 07:55:09 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 17 Nov 2011 07:55:09 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CANPzfU_WacEvNdG=5eTn_uxmTSU09ppoM+7o_L29k6KQVo1Wtg@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>	<4EC2D53B.6040203@javaspecialists.eu>	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>	<4EC42D00.20003@javaspecialists.eu>	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>	<CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>	<4EC4FFF3.8090804@cs.oswego.edu>
	<CANPzfU_WacEvNdG=5eTn_uxmTSU09ppoM+7o_L29k6KQVo1Wtg@mail.gmail.com>
Message-ID: <4EC5042D.7060909@cs.oswego.edu>

On 11/17/11 07:49, ?iktor ?lang wrote:
>     Portability of Unsafe constructions is not really a problem.
>     We frequently communicate with all production JVM implementors
>     to help ensure that they are correctly supported.
>
>
> Alright, that's a good clarification, I've always avoided it from compatibility
> reasons.
> Is this case the same with Android?

Android runs unmodified java.util.concurrent, so at least supports
the Unsafe methods that we use.

-Doug



From elizarov at devexperts.com  Thu Nov 17 08:03:35 2011
From: elizarov at devexperts.com (Roman Elizarov)
Date: Thu, 17 Nov 2011 13:03:35 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAD5tkZa_T+u8ozK760jHOTrtHmMnRkXnERVtMrLBprzqmsdBjw@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu> 
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CAD5tkZa_T+u8ozK760jHOTrtHmMnRkXnERVtMrLBprzqmsdBjw@mail.gmail.com>
Message-ID: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F557@RAVEN.office.devexperts.com>

Unsafe is big and that?s a separate issue from concurrency patterns (CAS is that we started with). The problem is that ByteBuffer is not as fast as byte[] ? even though it uses Unsafe inside, HotSpot is not able to eliminate range checks and translate ByteBuffer usage to an efficient code (while at the same time being very efficient with optimizing byte[] usage). I?ve even reported that fact (that ByteBuffer is slower than byte[]) to Sun bug database several years ago when it first appeared in 1.5 and I did tests on it and it was accepted, but never gained any priority.

/Roman

From: ismaelj at gmail.com [mailto:ismaelj at gmail.com] On Behalf Of Ismael Juma
Sent: Thursday, November 17, 2011 4:02 PM
To: Roman Elizarov
Cc: Martin Buchholz; Dr Heinz M. Kabutz; concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

On Thu, Nov 17, 2011 at 10:53 AM, Roman Elizarov <elizarov at devexperts.com<mailto:elizarov at devexperts.com>> wrote:
The downside is that it fuels the use of sun.misc.Unsafe by 3rd party programmer. Every day there are more and more blogs explaining advantages of Unsafe to the average programmer.

Yes. A common use of Unsafe these days is to improve the performance of compression algorithms written in pure Java:

https://github.com/dain/snappy/blob/master/src/main/java/org/iq80/snappy/UnsafeMemory.java
https://github.com/ning/compress/blob/master/src/main/java/com/ning/compress/lzf/impl/UnsafeChunkDecoder.java

Off-heap caches too:

https://issues.apache.org/jira/browse/CASSANDRA-3271

It's a shame that this is needed.

Best,
Ismael
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/043197cd/attachment.html>

From elizarov at devexperts.com  Thu Nov 17 08:11:00 2011
From: elizarov at devexperts.com (Roman Elizarov)
Date: Thu, 17 Nov 2011 13:11:00 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC4FFF3.8090804@cs.oswego.edu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com><NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au><CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com><4EC2B6AF.1070302@javaspecialists.eu><CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com><4EC2BD8E.3010107@javaspecialists.eu><CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com><4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com><4EC2D53B.6040203@javaspecialists.eu><CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com><4EC42D00.20003@javaspecialists.eu><CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com><C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com><CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
	<4EC4FFF3.8090804@cs.oswego.edu>
Message-ID: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F57F@RAVEN.office.devexperts.com>

Doug,

Frankly, I don't see what is preventing HotSpot team to look into it and make sure that a code using **Updater classes is translated to the direct native instructions. There are multiple equally feasible approaches starting from recognition 
of select **Updater methods as intrinsics (whenever their usage permits) or learning typical cases where the checks in **Updater classes can be eliminated, so that HotSpot inlining & Unsafe intrinsics can do their job at producing efficient machine code.

The only thing that is need is priority to this project. And that needs some decisions first. If sun.misc.Unsafe is there to stay in all major JVMs, then Ok -- let everybody use it for their high-performance code. They will not work in sand-boxed scenarios, but one can argue that nobody need high-performance concurrency in a sandbox anyway.

Sincerely,
Roman Elizarov

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Doug Lea
Sent: Thursday, November 17, 2011 4:37 PM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

On 11/17/11 06:10, ?iktor ?lang wrote:
> Right now it feels like if you're doing high-perf concurrency in this sense you
> have to choose between:
>
> A) Cache-trashing (and extra memory usage) because you went with AtomicLong/Ref
> whatnot
> B) CPU overhead caused by Atomic*Updaters and if you do any inheritance you'll
> get even more checks each call (and extra mem usage due to padding).
> C) Sacrifice cross-platform because you had to drop down to Unsafe to get the
> correct machinecode emitted.
>

Yes.

The main underlying problem is a fundamental one: Java bytecodes
support only two field read/write operations (getField/putField),
plus an implicit mode argument for volatiles. However, there is no
casField, or special r/w modes like releaseField. One level up,
there is no syntax for "lvalue" operations on fields. So the
only options are to directly invoke these lvalue operations
via Unsafe, which require that you know the address of the field,
or to use Updaters, that don't require the address, but must
perform type checks and security checks that you have access to the
field.

No one knows of any good alternatives. We tried for Java7
to reduce need for either option by proposing Fences that
would at least emulate the different memory modes, but that's
also problematic enough to not be worth adopting.

It's not hard to imagine some nicer syntax to support
these operations (as in a.someField.compareAndSet(x, y))
and also to perform class-loading-time validations (similarly
to "quickening") and/or using invokeDynamic. But these matters
never attain high enough priority when people consider syntax
enhancements.

Portability of Unsafe constructions is not really a problem.
We frequently communicate with all production JVM implementors
to help ensure that they are correctly supported.

-Doug


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From mlists at juma.me.uk  Thu Nov 17 08:30:12 2011
From: mlists at juma.me.uk (Ismael Juma)
Date: Thu, 17 Nov 2011 13:30:12 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F557@RAVEN.office.devexperts.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CAD5tkZa_T+u8ozK760jHOTrtHmMnRkXnERVtMrLBprzqmsdBjw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F557@RAVEN.office.devexperts.com>
Message-ID: <CAD5tkZZWfRgF7DDx5=Dyi+JvfbZfLWnY4N0HnLSy92TKuRhe+w@mail.gmail.com>

On Thu, Nov 17, 2011 at 1:03 PM, Roman Elizarov <elizarov at devexperts.com>wrote:

>  Unsafe is big and that?s a separate issue from concurrency patterns (CAS
> is that we started with).
>

I know that, of course. Many people in this list (most?) are not only
interested in concurrency so I thought it was relevant.


>  The problem is that ByteBuffer is not as fast as byte[] ? even though it
> uses Unsafe inside,
>

That is not the only problem (both snappy and compress-lzf moved from using
normal operations on byte[] to using Unsafe with byte[]).

Best,
Ismael
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/80e9fa33/attachment.html>

From forax at univ-mlv.fr  Thu Nov 17 08:47:52 2011
From: forax at univ-mlv.fr (=?UTF-8?B?UsOpbWkgRm9yYXg=?=)
Date: Thu, 17 Nov 2011 14:47:52 +0100
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC4FFF3.8090804@cs.oswego.edu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>	<4EC2B6AF.1070302@javaspecialists.eu>	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>	<4EC2BD8E.3010107@javaspecialists.eu>	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>	<4EC2D092.1020707@javaspecialists.eu>	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>	<4EC2D53B.6040203@javaspecialists.eu>	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>	<4EC42D00.20003@javaspecialists.eu>	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
	<4EC4FFF3.8090804@cs.oswego.edu>
Message-ID: <4EC51088.9060200@univ-mlv.fr>

On 11/17/2011 01:37 PM, Doug Lea wrote:
> On 11/17/11 06:10, ?iktor ?lang wrote:
>> Right now it feels like if you're doing high-perf concurrency in this 
>> sense you
>> have to choose between:
>>
>> A) Cache-trashing (and extra memory usage) because you went with 
>> AtomicLong/Ref
>> whatnot
>> B) CPU overhead caused by Atomic*Updaters and if you do any 
>> inheritance you'll
>> get even more checks each call (and extra mem usage due to padding).
>> C) Sacrifice cross-platform because you had to drop down to Unsafe to 
>> get the
>> correct machinecode emitted.
>>
>
> Yes.
>
> The main underlying problem is a fundamental one: Java bytecodes
> support only two field read/write operations (getField/putField),
> plus an implicit mode argument for volatiles. However, there is no
> casField, or special r/w modes like releaseField. One level up,
> there is no syntax for "lvalue" operations on fields. So the
> only options are to directly invoke these lvalue operations
> via Unsafe, which require that you know the address of the field,
> or to use Updaters, that don't require the address, but must
> perform type checks and security checks that you have access to the
> field.

You can do the security check once exactly like the method handle API
does using a Lookup object.
I beleive that you can create a safe MethodHandle that will do a CAS
with an extra cost of a pointer comparison at runtime compared
with the unsafe compareAndSet.

>
> No one knows of any good alternatives. We tried for Java7
> to reduce need for either option by proposing Fences that
> would at least emulate the different memory modes, but that's
> also problematic enough to not be worth adopting.
>
> It's not hard to imagine some nicer syntax to support
> these operations (as in a.someField.compareAndSet(x, y))
> and also to perform class-loading-time validations (similarly
> to "quickening") and/or using invokeDynamic. But these matters
> never attain high enough priority when people consider syntax
> enhancements.
>
> Portability of Unsafe constructions is not really a problem.
> We frequently communicate with all production JVM implementors
> to help ensure that they are correctly supported.
>
> -Doug

R?mi


From kumpera at gmail.com  Thu Nov 17 12:25:03 2011
From: kumpera at gmail.com (Rodrigo Kumpera)
Date: Thu, 17 Nov 2011 12:25:03 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC4FFF3.8090804@cs.oswego.edu>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
	<4EC4FFF3.8090804@cs.oswego.edu>
Message-ID: <CACmR+BAwin648OLQZEX5sxOPvqd_YrDZNK+qDCK5DTPs9Hg6Ng@mail.gmail.com>

On Thu, Nov 17, 2011 at 7:37 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 11/17/11 06:10, ?iktor ?lang wrote:
>
>> Right now it feels like if you're doing high-perf concurrency in this
>> sense you
>> have to choose between:
>>
>> A) Cache-trashing (and extra memory usage) because you went with
>> AtomicLong/Ref
>> whatnot
>> B) CPU overhead caused by Atomic*Updaters and if you do any inheritance
>> you'll
>> get even more checks each call (and extra mem usage due to padding).
>> C) Sacrifice cross-platform because you had to drop down to Unsafe to get
>> the
>> correct machinecode emitted.
>>
>>
> Yes.
>
> The main underlying problem is a fundamental one: Java bytecodes
> support only two field read/write operations (getField/putField),
> plus an implicit mode argument for volatiles. However, there is no
> casField, or special r/w modes like releaseField. One level up,
> there is no syntax for "lvalue" operations on fields. So the
> only options are to directly invoke these lvalue operations
> via Unsafe, which require that you know the address of the field,
> or to use Updaters, that don't require the address, but must
> perform type checks and security checks that you have access to the
> field.
>
> No one knows of any good alternatives. We tried for Java7
> to reduce need for either option by proposing Fences that
> would at least emulate the different memory modes, but that's
> also problematic enough to not be worth adopting.
>
>
The CLR has a general enough solution for all those problems for almost a
decade.
All you need is pass by reference and reified generics and all it will take
is trivial
JIT support for some method intrinsics. For example, in C# you'd do:

class Foo { int a; string b; }

Foo f = ...
Interlocked.CompareExchange (ref f.a, 1, 0);
Interlocked.CompareExchange (ref f.b, "test", null);

It works fine and enable it to work correctly across fields, locals,
captured locals and array elements.

Given Java 9 will have reified generics, one could wish for pass by
reference on java 10 and the solution
to this issue will be trivial.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/c14688ab/attachment.html>

From martinrb at google.com  Thu Nov 17 23:38:10 2011
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 17 Nov 2011 20:38:10 -0800
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4EC51088.9060200@univ-mlv.fr>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<CANPzfU-V-JoVYdRvkWHbvm6nG9QpzDCDVxginfjffTsMk5Q5yA@mail.gmail.com>
	<4EC4FFF3.8090804@cs.oswego.edu> <4EC51088.9060200@univ-mlv.fr>
Message-ID: <CA+kOe08z2xEn+nsZ=P-GQR6LRwrJuO9mkYGSBe27+tz8MpM07Q@mail.gmail.com>

On Thu, Nov 17, 2011 at 05:47, R?mi Forax <forax at univ-mlv.fr> wrote:

> I beleive that you can create a safe MethodHandle that will do a CAS
> with an extra cost of a pointer comparison at runtime compared
> with the unsafe compareAndSet.


It's good to know that it's possible.  So what's stopping us?

- the maintainers are unfamiliar with MethodHandle (especially with getting
the security details right).
- we'd like to keep supporting jdk6 and don't want to fork our code base
... yet.

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111117/2fecb224/attachment.html>

From radhakrishnan.mohan at gmail.com  Fri Nov 18 06:24:54 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Fri, 18 Nov 2011 16:54:54 +0530
Subject: [concurrency-interest] Question about phasers and cache lines
Message-ID: <CAOoXFP97+NEHaeBZ8VXmmv=08qnggV1XUo87YJLvO=nQyO6udQ@mail.gmail.com>

Hi,
         Request some explanation about these two items.

1. I have used the Phaser API and looked at the Rice university paper
which mentions deadlock-freedom and phase-ordering. What exactly are
these advantages of the Phaser API and use cases for it ? I am
basically able to understand that threads can advance in phases like
leaders and followers but I am not getting the real idea behind the
performance considerations of phasers. Are there more examples ?

2. Where do I read about cache lines , false sharing and why locations
have to be 4-words apart so that they don't fall in the same cache
line (Herlihy and shavit) ? Can I write a Java program to induce false
sharing ?

Though the topics might be advanced my questions are more basic. Thanks.


Mohan

From holger.hoffstaette at googlemail.com  Fri Nov 18 07:35:30 2011
From: holger.hoffstaette at googlemail.com (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Fri, 18 Nov 2011 13:35:30 +0100
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <CAOoXFP97+NEHaeBZ8VXmmv=08qnggV1XUo87YJLvO=nQyO6udQ@mail.gmail.com>
References: <CAOoXFP97+NEHaeBZ8VXmmv=08qnggV1XUo87YJLvO=nQyO6udQ@mail.gmail.com>
Message-ID: <4EC65112.5080802@googlemail.com>

On 18.11.2011 12:24, Mohan Radhakrishnan wrote:
> 2. Where do I read about cache lines , false sharing and why locations
> have to be 4-words apart so that they don't fall in the same cache
> line (Herlihy and shavit) ? Can I write a Java program to induce false
> sharing ?

Can't help with the Phaser question but false sharing is absolutely real
and can be observed easily. Run the attached snippet and you will see the
pretty serious effect that memory contention between threads can have. You
might need to adjust the number of threads for your machine.
Credits go to Martin Thompson, see blog URL in comments.

On my old-ish Core2Duo laptop with slow bus & memory:

--snip--
Times in ns for 5000000 writes with 2 threads:
plain  : 1171084314
plain  : 1208625956
plain  : 1230311953
padded : 140929085
padded : 140683802
padded : 141457922
--snip--

That's a difference in throughput by a factor of ~8, though the impact of
course depends on the details of the CPU, caches, memory controller,
memory system etc.

-h
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: FalseSharing.java
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111118/96527f67/attachment.ksh>

From nathan.reynolds at oracle.com  Fri Nov 18 12:09:48 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 18 Nov 2011 10:09:48 -0700
Subject: [concurrency-interest] Propagation
	ofsignalstonon-interruptedthread
In-Reply-To: <CADJdpBxaiXYN2TmM3a4v2Wryg53Km27bxXQ2u+TCP5S7hkJtNA@mail.gmail.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CADJdpBxaiXYN2TmM3a4v2Wryg53Km27bxXQ2u+TCP5S7hkJtNA@mail.gmail.com>
Message-ID: <4EC6915C.9060901@oracle.com>

If GC is a concern, the implementation could be changed so that a static 
ThreadLocal caches the AbstractQueuedSynchronizer$Node for each thread.  
The question is if the AbstractQueuedSynchronizer$Node can be reused 
without running into other concurrency issues such as ABA.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/15/2011 12:46 PM, Dimitris Andreou wrote:
> Which is (almost) the same deal as with synchronized blocks. The
> difference is that the allocated object is from a native object pool,
> not in the java heap, so no extra gc overhead involved there.
>
> 2011/11/15 Dr Heinz M. Kabutz<heinz at javaspecialists.eu>:
>> Just a follow-up on my last post.  This object is only constructed when
>> there is contention over the lock.
>>
>> Regards
>>
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 72 850 460
>> Skype: kabutz
>>
>>
>> On 11/15/11 9:27 PM, ?iktor ?lang wrote:
>>
>> On Tue, Nov 15, 2011 at 7:59 PM, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu>  wrote:
>>> On an only vaguely related note, I discovered today, whilst doing a
>>> throughput test of atomic integer vs reentrant lock, that every time you
>>> call lock.lock(), it creates a new object of 32 bytes!  For some reason, I
>>> always assumed that lock.lock() would not construct any objects, so was
>>> surprised when the GC started acting up.  The object that is constructed is
>>> the AbstractQueuedSynchronizer$Node in the addWaiter() method in the
>>> AbstractQueuedSynchronizer.
>> Yeah, that one's a real treat.
>>
>>> Regards
>>>
>>> Heinz
>>> --
>>> Dr Heinz M. Kabutz (PhD CompSci)
>>> Author of "The Java(tm) Specialists' Newsletter"
>>> Sun Java Champion
>>> IEEE Certified Software Development Professional
>>> http://www.javaspecialists.eu
>>> Tel: +30 69 72 850 460
>>> Skype: kabutz
>>>
>>>
>>> On 11/15/11 4:57 PM, Martin Buchholz wrote:
>>>
>>> On Mon, Nov 14, 2011 at 18:37, David Holmes<davidcholmes at aapt.net.au>
>>> wrote:
>>>> One example of some broken code is not very compelling. This code doesn't
>>>> even handle timeout correctly. I strongly suspect the author of this code
>>>> was not relying on no-spurious-wakeups but was simply completely ignorant of
>>>> them and so would have used the same style of code even with Object.wait.
>>> Sure.
>>> My argument is not about careful programmers who have thoughtfully read
>>> the spec, whose number is vanishingly small.  This is all about real-world
>>> crappy code in production that happens to work today, and will fail
>>> unpredictably under stress if you withdraw the de-facto guarantees.
>>> If Object.wait has also been providing the de-facto guarantee in recent
>>> releases, I would like its spec updated as well to provide the stronger
>>> guarantee.  But my argument is stronger for j.u.c.locks, since everyone uses
>>> the same implementation in practice.
>>> Martin
>>>
>>> ________________________________
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> --
>> Viktor Klang
>>
>> Akka Tech Lead
>> Typesafe - Enterprise-Grade Scala from the Experts
>>
>> Twitter: @viktorklang
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111118/ffada286/attachment.html>

From nathan.reynolds at oracle.com  Fri Nov 18 12:15:15 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 18 Nov 2011 10:15:15 -0700
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>
References: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>
Message-ID: <4EC692A3.6020506@oracle.com>

We would probably need to consider STM and hardware support.  IBM 
recently released a chip that supports transaction memory.  Sun's Rock 
(cancelled) was going to support transactional memory.  I wouldn't be 
surprised if other hardware vendors were considering transactional 
memory support for their processors.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/17/2011 12:40 AM, Guy Korland wrote:
> It seems like the upcoming GCC 4.7.0 is going to include a build-in 
> support for Transactional memory.
>
> See: http://lwn.net/Articles/466513/
> "Following a last-minute request, the "transactional memory" GCC 
> branch has been merged into the trunk for the 4.7.0 release. 
> Transactional memory is specified in a draft standard [PDF] for C and 
> C++; the idea is to provide a relatively simple way for developers to 
> execute code with atomic "all or nothing" semantics."
>
> I think it's about time to set a JSR about adding STM to Java also:
> 1. Adding to that the fact that STM can be added much more easily to 
> Java than JVM.
> 2. JVM based Dynamic languages like Scala already offer their alternative.
> 3. There exists couple of working implementations like 
> Multiverse, DSTM2, DeuceSTM...
>
> Any thoughts?
>
> Regards,
> Guy Korland
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111118/f4cf3918/attachment.html>

From gkorland at gmail.com  Sat Nov 19 02:00:32 2011
From: gkorland at gmail.com (Guy Korland)
Date: Sat, 19 Nov 2011 09:00:32 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4EC692A3.6020506@oracle.com>
References: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>
	<4EC692A3.6020506@oracle.com>
Message-ID: <CAMaz81KjJQ=fvmCwpvW-f21YYi1V-M3QPvQhM5Xy0WJEHQn_+A@mail.gmail.com>

Hardware support might be great but it seems like it won't be
generally available in the near future, while STM is becoming,
widely available see Scala, Intel C++, and GCC 4.7... I think this process
should start in Java also.

Regards,
Guy Korland


On Fri, Nov 18, 2011 at 7:15 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

> We would probably need to consider STM and hardware support.  IBM recently
> released a chip that supports transaction memory.  Sun's Rock (cancelled)
> was going to support transactional memory.  I wouldn't be surprised if
> other hardware vendors were considering transactional memory support for
> their processors.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111119/e7bc99e1/attachment.html>

From mthornton at optrak.com  Sat Nov 19 04:21:23 2011
From: mthornton at optrak.com (Mark Thornton)
Date: Sat, 19 Nov 2011 09:21:23 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81KjJQ=fvmCwpvW-f21YYi1V-M3QPvQhM5Xy0WJEHQn_+A@mail.gmail.com>
References: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>
	<4EC692A3.6020506@oracle.com>
	<CAMaz81KjJQ=fvmCwpvW-f21YYi1V-M3QPvQhM5Xy0WJEHQn_+A@mail.gmail.com>
Message-ID: <4EC77513.5040807@optrak.com>

On 19/11/11 07:00, Guy Korland wrote:
> Hardware support might be great but it seems like it won't be 
> generally available in the near future, while STM is becoming, 
> widely available see Scala, Intel C++, and GCC 4.7... I think this 
> process should start in Java also.
>
> Regards,
> Guy Korland
>
Yet Microsoft abandoned STM.net after 6 years development.

http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx

Have the issues changed or the has the focus been narrowed to something 
which is achievable?

Mark Thornton


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111119/e0d9c392/attachment.html>

From viktor.klang at gmail.com  Sat Nov 19 05:00:35 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 19 Nov 2011 11:00:35 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4EC77513.5040807@optrak.com>
References: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>
	<4EC692A3.6020506@oracle.com>
	<CAMaz81KjJQ=fvmCwpvW-f21YYi1V-M3QPvQhM5Xy0WJEHQn_+A@mail.gmail.com>
	<4EC77513.5040807@optrak.com>
Message-ID: <CANPzfU8vD0s8kfKfqaXtDkjBH=PV55Y0mGUx7b1PPCRCbmwaaA@mail.gmail.com>

Check Multiverse STM for Java.

Cheers,
V
On Nov 19, 2011 10:25 AM, "Mark Thornton" <mthornton at optrak.com> wrote:

>  On 19/11/11 07:00, Guy Korland wrote:
>
> Hardware support might be great but it seems like it won't be
> generally available in the near future, while STM is becoming,
> widely available see Scala, Intel C++, and GCC 4.7... I think this process
> should start in Java also.
>
> Regards,
> Guy Korland
>
>   Yet Microsoft abandoned STM.net after 6 years development.
>
>
> http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx
>
> Have the issues changed or the has the focus been narrowed to something
> which is achievable?
>
> Mark Thornton
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111119/b717c2ef/attachment-0001.html>

From gkorland at gmail.com  Sun Nov 20 02:42:45 2011
From: gkorland at gmail.com (Guy Korland)
Date: Sun, 20 Nov 2011 09:42:45 +0200
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 82,
	Issue 21
In-Reply-To: <mailman.245.1321696844.6569.concurrency-interest@cs.oswego.edu>
References: <mailman.245.1321696844.6569.concurrency-interest@cs.oswego.edu>
Message-ID: <CAMaz81K0fhh1rNK7OmqHLcPvPZcOF5=4n9VA==40-ca-nmvkag@mail.gmail.com>

Not all the issues are solved, but it seems like most of the issues have
good answers.
Also, notice that in .NET they have issues which Java doesn't have like
Native code.

Guy

> Date: Sat, 19 Nov 2011 09:21:23 +0000?
> From: Mark Thornton <mthornton at optrak.com>
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>        what about Java?
> Message-ID: <4EC77513.5040807 at optrak.com>
> Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
>
> On 19/11/11 07:00, Guy Korland wrote:
>> Hardware support might be great but it seems like it won't be
>> generally available in the near future, while STM is becoming,
>> widely available see Scala, Intel C++, and GCC 4.7... I think this
>> process should start in Java also.
>>
>> Regards,
>> Guy Korland
>>
> Yet Microsoft abandoned STM.net after 6 years development.
>
>
http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx
>
> Have the issues changed or the has the focus been narrowed to something
> which is achievable?
>
> Mark Thornton
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111120/428ff481/attachment.html>

From sanders at cise.ufl.edu  Mon Nov 21 10:52:28 2011
From: sanders at cise.ufl.edu (Beverly Sanders)
Date: Mon, 21 Nov 2011 10:52:28 -0500
Subject: [concurrency-interest] looking for code with benign data races
Message-ID: <783eab319ec58a39b38fb2cf4b33a0fc.squirrel@webmail.cise.ufl.edu>


We have a JPF-based tool that can analyze programs with data races and
would appreciate pointers to Java programs that contain intentional and/or
known data races that are considered to be benign.  We know about the one
in java.lang.String.

Many thanks
--Beverly




From kav at it.edu  Mon Nov 21 11:17:21 2011
From: kav at it.edu (Kasper Nielsen)
Date: Mon, 21 Nov 2011 17:17:21 +0100
Subject: [concurrency-interest] looking for code with benign data races
In-Reply-To: <783eab319ec58a39b38fb2cf4b33a0fc.squirrel@webmail.cise.ufl.edu>
References: <783eab319ec58a39b38fb2cf4b33a0fc.squirrel@webmail.cise.ufl.edu>
Message-ID: <CAPs6152ERVNDk_1fs2Fnfb2XEfE3X4ObcsyU84TJsyrj+S0X8g@mail.gmail.com>

Hi Beverly

Take a look at ConcurrentSkipListMap.
It has a non volatile randomSeed field.

- Kasper

On Mon, Nov 21, 2011 at 16:52, Beverly Sanders <sanders at cise.ufl.edu> wrote:
>
> We have a JPF-based tool that can analyze programs with data races and
> would appreciate pointers to Java programs that contain intentional and/or
> known data races that are considered to be benign. ?We know about the one
> in java.lang.String.
>
> Many thanks
> --Beverly
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From forax at univ-mlv.fr  Mon Nov 21 12:43:36 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 21 Nov 2011 18:43:36 +0100
Subject: [concurrency-interest] looking for code with benign data races
In-Reply-To: <CAPs6152ERVNDk_1fs2Fnfb2XEfE3X4ObcsyU84TJsyrj+S0X8g@mail.gmail.com>
References: <783eab319ec58a39b38fb2cf4b33a0fc.squirrel@webmail.cise.ufl.edu>
	<CAPs6152ERVNDk_1fs2Fnfb2XEfE3X4ObcsyU84TJsyrj+S0X8g@mail.gmail.com>
Message-ID: <4ECA8DC8.3070601@univ-mlv.fr>

java.lang.Class has also this kind of data-races.

R?mi

On 11/21/2011 05:17 PM, Kasper Nielsen wrote:
> Hi Beverly
>
> Take a look at ConcurrentSkipListMap.
> It has a non volatile randomSeed field.
>
> - Kasper
>
> On Mon, Nov 21, 2011 at 16:52, Beverly Sanders<sanders at cise.ufl.edu>  wrote:
>> We have a JPF-based tool that can analyze programs with data races and
>> would appreciate pointers to Java programs that contain intentional and/or
>> known data races that are considered to be benign.  We know about the one
>> in java.lang.String.
>>
>> Many thanks
>> --Beverly
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gkorland at gmail.com  Mon Nov 21 14:04:01 2011
From: gkorland at gmail.com (Guy Korland)
Date: Mon, 21 Nov 2011 21:04:01 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
Message-ID: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>

Not all the issues are solved, but it seems like most of the issues have
good answers.
Also, notice that in .NET they have issues which Java doesn't have like
Native code and pointers in C++.

Guy

> Date: Sat, 19 Nov 2011 09:21:23 +0000?
>
> > From: Mark Thornton <mthornton at optrak.com>
> > To: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
> >        what about Java?
> > Message-ID: <4EC77513.5040807 at optrak.com>
> > Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
> >
> > On 19/11/11 07:00, Guy Korland wrote:
> >> Hardware support might be great but it seems like it won't be
> >> generally available in the near future, while STM is becoming,
> >> widely available see Scala, Intel C++, and GCC 4.7... I think this
> >> process should start in Java also.
> >>
> >> Regards,
> >> Guy Korland
> >>
> > Yet Microsoft abandoned STM.net after 6 years development.
> >
> >
> http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx
> >
> > Have the issues changed or the has the focus been narrowed to something
> > which is achievable?
> >
> > Mark Thornton
> >
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111121/04c531ea/attachment.html>

From dharrigan at gmail.com  Mon Nov 21 16:15:44 2011
From: dharrigan at gmail.com (David Harrigan)
Date: Mon, 21 Nov 2011 21:15:44 +0000
Subject: [concurrency-interest] A beginner question (on fork-and-join)
Message-ID: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>

Hi Everyone,

I'm learning about the fork and join framework in JDK7 and to test it
out I wrote a little program that tries to find a number at the end of
a list with 50,000 elements.
What puzzles me is when I run the "find" in a sequential fashion, it
returns faster than if I use a fork-and-join implementation. I'm
running each "find" 5000 times
so as to "warm" up the JVM. I've got a timing listed below:

Generating some data...done!
Sequential
Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
mean 203 ms [sequential INHERIT]
Parallel
Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
mean 270 ms [parallel INHERIT]

(some runtime information)

openjdk version "1.7.0-ea"
OpenJDK Runtime Environment (build 1.7.0-ea-b215)
OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)

2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
and 4MB L3 cache) running on a MBP (Lion 10.7.2)

Forgive my ignorance but this type of programming is still quite new
to me and I'm obviously doing something wrong, but I don't know what.
My suspicion is
something to do with spinning up and down threads and the overhead
that entails. I've posted the src here http://pastebin.com/p96R24R0.

My sincere apologies if this list is not appropriate for this posting,
if so I would welcome a pointer on where I can find more information
to help me understand
better the behaviour of my program when using F&J.

I thought that by using F&J I would be able to find the answer quicker
than doing the searching sequentially, perhaps I've choosen a wrong
initial problem to
test this out (something that is suited to a sequential search and not
a parallel search?)

Thank you all in advance.

-=david=-

-- 
I prefer encrypted and signed messages. KeyID: B20A22F9
Fingerprint: 110A F423 3647 54E2 880F ADAD 1C52 85BF B20A 22F9

"It is not usually until you've built and used a version of the
program that you understand the issues well enough to get the design
right." - Rob Pike, Brian Kernighan.

No trees were harmed in the sending of this message, however, a number
of electrons were inconvenienced.

From karmazilla at gmail.com  Mon Nov 21 16:28:29 2011
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Mon, 21 Nov 2011 22:28:29 +0100
Subject: [concurrency-interest] looking for code with benign data races
In-Reply-To: <4ECA8DC8.3070601@univ-mlv.fr>
References: <783eab319ec58a39b38fb2cf4b33a0fc.squirrel@webmail.cise.ufl.edu>
	<CAPs6152ERVNDk_1fs2Fnfb2XEfE3X4ObcsyU84TJsyrj+S0X8g@mail.gmail.com>
	<4ECA8DC8.3070601@univ-mlv.fr>
Message-ID: <CACyP5Pdt+nrFWke7cZw=O2=xhiPawZw_URWmtbgZCSvBg=P04A@mail.gmail.com>

Hi Beverly,

There is a data-race bug in this code of mine:
https://github.com/chrisvest/stormpot/blob/master/src/main/java/stormpot/qpool/QueuePool.java#L81

Specifically, the slot.poison field might be cleared by the time the
exception is created.
I have held back from fixing it because I wanted to experiment with JPF
myself, but just have not gotten around to it.

On Mon, Nov 21, 2011 at 18:43, R?mi Forax <forax at univ-mlv.fr> wrote:

> java.lang.Class has also this kind of data-races.
>
> R?mi
>
>
> On 11/21/2011 05:17 PM, Kasper Nielsen wrote:
>
>> Hi Beverly
>>
>> Take a look at ConcurrentSkipListMap.
>> It has a non volatile randomSeed field.
>>
>> - Kasper
>>
>> On Mon, Nov 21, 2011 at 16:52, Beverly Sanders<sanders at cise.ufl.edu>
>>  wrote:
>>
>>> We have a JPF-based tool that can analyze programs with data races and
>>> would appreciate pointers to Java programs that contain intentional
>>> and/or
>>> known data races that are considered to be benign.  We know about the one
>>> in java.lang.String.
>>>
>>> Many thanks
>>> --Beverly
>>>
>>>
>>>
>>> ______________________________**_________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>
>>>  ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111121/a4b2792b/attachment.html>

From nathan.reynolds at oracle.com  Mon Nov 21 16:40:36 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 21 Nov 2011 14:40:36 -0700
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
Message-ID: <4ECAC554.1060604@oracle.com>

Microbenchmarks are incredibly hard to get right.  For example, HotSpot 
7 JVM won't do a full optimization of a method until 10,000 
invocations.  You need to bump up the priority of the test thread so 
that other things on the system don't add noise.  These probably aren't 
applicable to your case, but you may to force a full GC right before 
running the test.

You probably want to use http://code.google.com/p/caliper/ which deals 
with all of these gotchas.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/21/2011 2:15 PM, David Harrigan wrote:
> Hi Everyone,
>
> I'm learning about the fork and join framework in JDK7 and to test it
> out I wrote a little program that tries to find a number at the end of
> a list with 50,000 elements.
> What puzzles me is when I run the "find" in a sequential fashion, it
> returns faster than if I use a fork-and-join implementation. I'm
> running each "find" 5000 times
> so as to "warm" up the JVM. I've got a timing listed below:
>
> Generating some data...done!
> Sequential
> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
> mean 203 ms [sequential INHERIT]
> Parallel
> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
> mean 270 ms [parallel INHERIT]
>
> (some runtime information)
>
> openjdk version "1.7.0-ea"
> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>
> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>
> Forgive my ignorance but this type of programming is still quite new
> to me and I'm obviously doing something wrong, but I don't know what.
> My suspicion is
> something to do with spinning up and down threads and the overhead
> that entails. I've posted the src here http://pastebin.com/p96R24R0.
>
> My sincere apologies if this list is not appropriate for this posting,
> if so I would welcome a pointer on where I can find more information
> to help me understand
> better the behaviour of my program when using F&J.
>
> I thought that by using F&J I would be able to find the answer quicker
> than doing the searching sequentially, perhaps I've choosen a wrong
> initial problem to
> test this out (something that is suited to a sequential search and not
> a parallel search?)
>
> Thank you all in advance.
>
> -=david=-
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111121/c94ecd5c/attachment-0001.html>

From forax at univ-mlv.fr  Mon Nov 21 17:03:31 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 21 Nov 2011 23:03:31 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
Message-ID: <4ECACAB3.3000001@univ-mlv.fr>

On 11/21/2011 08:04 PM, Guy Korland wrote:
> Not all the issues are solved, but it seems like most of the issues 
> have good answers.
> Also, notice that in .NET they have issues which Java doesn't have 
> like Native code and pointers in C++.
>
> Guy

And how do you solve the IO problems (when you retry) ?
Also the semantics chosen by Microsoft when an exception is thrown
and the one chosen by GCC is not the same.

cheers,
R?mi

>
>     > Date: Sat, 19 Nov 2011 09:21:23 +0000?
>
>     > From: Mark Thornton <mthornton at optrak.com
>     <mailto:mthornton at optrak.com>>
>     > To: concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     > Subject: Re: [concurrency-interest] Transactional memory on GCC
>     4.7.0,
>     >        what about Java?
>     > Message-ID: <4EC77513.5040807 at optrak.com
>     <mailto:4EC77513.5040807 at optrak.com>>
>     > Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
>     >
>     > On 19/11/11 07:00, Guy Korland wrote:
>     >> Hardware support might be great but it seems like it won't be
>     >> generally available in the near future, while STM is becoming,
>     >> widely available see Scala, Intel C++, and GCC 4.7... I think this
>     >> process should start in Java also.
>     >>
>     >> Regards,
>     >> Guy Korland
>     >>
>     > Yet Microsoft abandoned STM.net after 6 years development.
>     >
>     >
>     http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx
>     >
>     > Have the issues changed or the has the focus been narrowed to
>     something
>     > which is achievable?
>     >
>     > Mark Thornton
>     >
>     >
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111121/c485a421/attachment-0001.html>

From gregg at cytetech.com  Mon Nov 21 17:36:20 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 21 Nov 2011 16:36:20 -0600
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <4ECAC554.1060604@oracle.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
	<4ECAC554.1060604@oracle.com>
Message-ID: <4ECAD264.2080503@cytetech.com>

So I have to ask, why don't you use the command line property to change this to 
something like 100 for a faster warm up?  For some of my applications, doing 
this reduces startup time by orders of magnitude because of the number of times 
some things are invoked.  In particular, server applications using a security 
manager seem to start much faster.

Gregg Wonderly

On 11/21/2011 3:40 PM, Nathan Reynolds wrote:
> Microbenchmarks are incredibly hard to get right. For example, HotSpot 7 JVM
> won't do a full optimization of a method until 10,000 invocations. You need to
> bump up the priority of the test thread so that other things on the system don't
> add noise. These probably aren't applicable to your case, but you may to force a
> full GC right before running the test.
>
> You probably want to use http://code.google.com/p/caliper/ which deals with all
> of these gotchas.
>
> Nathan Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 11/21/2011 2:15 PM, David Harrigan wrote:
>> Hi Everyone,
>>
>> I'm learning about the fork and join framework in JDK7 and to test it
>> out I wrote a little program that tries to find a number at the end of
>> a list with 50,000 elements.
>> What puzzles me is when I run the "find" in a sequential fashion, it
>> returns faster than if I use a fork-and-join implementation. I'm
>> running each "find" 5000 times
>> so as to "warm" up the JVM. I've got a timing listed below:
>>
>> Generating some data...done!
>> Sequential
>> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
>> mean 203 ms [sequential INHERIT]
>> Parallel
>> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
>> mean 270 ms [parallel INHERIT]
>>
>> (some runtime information)
>>
>> openjdk version "1.7.0-ea"
>> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
>> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>>
>> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
>> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>>
>> Forgive my ignorance but this type of programming is still quite new
>> to me and I'm obviously doing something wrong, but I don't know what.
>> My suspicion is
>> something to do with spinning up and down threads and the overhead
>> that entails. I've posted the src herehttp://pastebin.com/p96R24R0.
>>
>> My sincere apologies if this list is not appropriate for this posting,
>> if so I would welcome a pointer on where I can find more information
>> to help me understand
>> better the behaviour of my program when using F&J.
>>
>> I thought that by using F&J I would be able to find the answer quicker
>> than doing the searching sequentially, perhaps I've choosen a wrong
>> initial problem to
>> test this out (something that is suited to a sequential search and not
>> a parallel search?)
>>
>> Thank you all in advance.
>>
>> -=david=-
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From kav at it.edu  Mon Nov 21 17:42:01 2011
From: kav at it.edu (Kasper Nielsen)
Date: Mon, 21 Nov 2011 23:42:01 +0100
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
Message-ID: <CAPs6151+uZFL+4H+y91cmGxn9JYdiYnMyxx4iCLaFwxMVC5DVw@mail.gmail.com>

Hi David,

It looks like you aren't doing any real CPU work.
So you are most likely just thrashing the memory system.
That is all threads are spending most of the time just waiting for
memory access.

Try doing some mindless calculations on each element.
I am pretty sure you will see the parallel version come out as a winner.

cheers
  Kasper

On Mon, Nov 21, 2011 at 22:15, David Harrigan <dharrigan at gmail.com> wrote:
> Hi Everyone,
>
> I'm learning about the fork and join framework in JDK7 and to test it
> out I wrote a little program that tries to find a number at the end of
> a list with 50,000 elements.
> What puzzles me is when I run the "find" in a sequential fashion, it
> returns faster than if I use a fork-and-join implementation. I'm
> running each "find" 5000 times
> so as to "warm" up the JVM. I've got a timing listed below:
>
> Generating some data...done!
> Sequential
> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
> mean 203 ms [sequential INHERIT]
> Parallel
> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
> mean 270 ms [parallel INHERIT]
>
> (some runtime information)
>
> openjdk version "1.7.0-ea"
> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>
> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>
> Forgive my ignorance but this type of programming is still quite new
> to me and I'm obviously doing something wrong, but I don't know what.
> My suspicion is
> something to do with spinning up and down threads and the overhead
> that entails. I've posted the src here http://pastebin.com/p96R24R0.
>
> My sincere apologies if this list is not appropriate for this posting,
> if so I would welcome a pointer on where I can find more information
> to help me understand
> better the behaviour of my program when using F&J.
>
> I thought that by using F&J I would be able to find the answer quicker
> than doing the searching sequentially, perhaps I've choosen a wrong
> initial problem to
> test this out (something that is suited to a sequential search and not
> a parallel search?)
>
> Thank you all in advance.
>
> -=david=-
>
> --
> I prefer encrypted and signed messages. KeyID: B20A22F9
> Fingerprint: 110A F423 3647 54E2 880F ADAD 1C52 85BF B20A 22F9
>
> "It is not usually until you've built and used a version of the
> program that you understand the issues well enough to get the design
> right." - Rob Pike, Brian Kernighan.
>
> No trees were harmed in the sending of this message, however, a number
> of electrons were inconvenienced.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From viktor.klang at gmail.com  Mon Nov 21 17:57:21 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 21 Nov 2011 23:57:21 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECACAB3.3000001@univ-mlv.fr>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr>
Message-ID: <CANPzfU8-fH=Sgc6a1d8xvAtsDrMbWXVoaJ3udV5YH2KoqUwwfQ@mail.gmail.com>

I think that managed references is the only way to go when it comes to STM.
You can't make it implicit since traditional "OO"-code is completely ridden
with side effects.

Cheers,
?

On Mon, Nov 21, 2011 at 11:03 PM, R?mi Forax <forax at univ-mlv.fr> wrote:

>  On 11/21/2011 08:04 PM, Guy Korland wrote:
>
>  Not all the issues are solved, but it seems like most of the issues have
> good answers.
> Also, notice that in .NET they have issues which Java doesn't have like
> Native code and pointers in C++.
>
> Guy
>
>
> And how do you solve the IO problems (when you retry) ?
> Also the semantics chosen by Microsoft when an exception is thrown
> and the one chosen by GCC is not the same.
>
> cheers,
> R?mi
>
>
>  > Date: Sat, 19 Nov 2011 09:21:23 +0000?
>>
>> > From: Mark Thornton <mthornton at optrak.com>
>> > To: concurrency-interest at cs.oswego.edu
>> > Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>> >        what about Java?
>> > Message-ID: <4EC77513.5040807 at optrak.com>
>> > Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
>> >
>> > On 19/11/11 07:00, Guy Korland wrote:
>> >> Hardware support might be great but it seems like it won't be
>> >> generally available in the near future, while STM is becoming,
>> >> widely available see Scala, Intel C++, and GCC 4.7... I think this
>> >> process should start in Java also.
>> >>
>> >> Regards,
>> >> Guy Korland
>> >>
>> > Yet Microsoft abandoned STM.net after 6 years development.
>> >
>> >
>> http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx
>> >
>> > Have the issues changed or the has the focus been narrowed to something
>> > which is achievable?
>> >
>> > Mark Thornton
>> >
>> >
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111121/ff05566b/attachment.html>

From heinz at javaspecialists.eu  Mon Nov 21 18:17:07 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 22 Nov 2011 01:17:07 +0200
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
Message-ID: <4ECADBF3.1040908@javaspecialists.eu>

Hi David,

you are lucky that you have such a good machine to test on - I have an 
older MBP with an Intel Core 2 Duo which has 2 cores, it performs MUCH 
worse using the parallel search algorithm than the sequential one.

Each of your tasks is too small.  You are basically just doing a search 
through a list that is at most 100 elements long.  If you give each 
thread more work, you will manage to get the parallel to be faster than 
the sequential.

The biggest bottleneck in your test is context switching.  You can see 
that if you look at the task manager, most of the time is spent in 
system time.

Personally, I have yet to find a really compelling example that shows 
how the parallel recursive algorithm improves performance.  I'm sure 
there must be some out there, such as some forms of sorting.  In your 
case, I would much rather use the CompletionService to get the answer 
back as soon as it is available.  In other words, something like this:

  protected void doInParallel(final List<First> firsts) {
    ExecutorService pool = Executors.newFixedThreadPool(
        Runtime.getRuntime().availableProcessors()
    );
    CompletionService<Boolean> service = new 
ExecutorCompletionService<>(pool);
    int submittedJobs = 0;
    for (final First first : firsts) {
      service.submit(new Callable<Boolean>() {
        public Boolean call() throws Exception {
          for (Second second : first.getSeconds()) {
            final List<Third> thirds = second.getThirds();
            for (Third third : thirds) {
              if (third.getValue() == Main.NUMBER) {
                return true;
              }
            }
          }
          return false;
        }
      });
      submittedJobs++;
    }
    for (int i = 0; i < submittedJobs; i++) {
      try {
        if (service.take().get()) break;
      } catch (Exception e) {
        e.printStackTrace();
      }
    }
    pool.shutdown();
    return;
  }


I reduced the number of Thirds and also the call count, and got the 
following results on a dual-processor machine:

Generating some data...done!
Sequential
Simon Stopwatch: total 14.7 s, counter 500, max 126 ms, min 25.3 ms, 
mean 29.3 ms [sequential INHERIT]
Parallel
Simon Stopwatch: total 15.0 s, counter 500, max 72.0 ms, min 25.6 ms, 
mean 29.9 ms [parallel INHERIT]

On your machine you should see significant performance gains in the 
parallel vs sequential version.

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 11/21/11 11:15 PM, David Harrigan wrote:
> Hi Everyone,
>
> I'm learning about the fork and join framework in JDK7 and to test it
> out I wrote a little program that tries to find a number at the end of
> a list with 50,000 elements.
> What puzzles me is when I run the "find" in a sequential fashion, it
> returns faster than if I use a fork-and-join implementation. I'm
> running each "find" 5000 times
> so as to "warm" up the JVM. I've got a timing listed below:
>
> Generating some data...done!
> Sequential
> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
> mean 203 ms [sequential INHERIT]
> Parallel
> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
> mean 270 ms [parallel INHERIT]
>
> (some runtime information)
>
> openjdk version "1.7.0-ea"
> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>
> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>
> Forgive my ignorance but this type of programming is still quite new
> to me and I'm obviously doing something wrong, but I don't know what.
> My suspicion is
> something to do with spinning up and down threads and the overhead
> that entails. I've posted the src here http://pastebin.com/p96R24R0.
>
> My sincere apologies if this list is not appropriate for this posting,
> if so I would welcome a pointer on where I can find more information
> to help me understand
> better the behaviour of my program when using F&J.
>
> I thought that by using F&J I would be able to find the answer quicker
> than doing the searching sequentially, perhaps I've choosen a wrong
> initial problem to
> test this out (something that is suited to a sequential search and not
> a parallel search?)
>
> Thank you all in advance.
>
> -=david=-
>
>   

From dharrigan at gmail.com  Mon Nov 21 18:20:32 2011
From: dharrigan at gmail.com (David Harrigan)
Date: Mon, 21 Nov 2011 23:20:32 +0000
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <4ECADBF3.1040908@javaspecialists.eu>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
	<4ECADBF3.1040908@javaspecialists.eu>
Message-ID: <CAKdGheMvDYbmKR83siCq_a-Q9qbmfrk=jtK+a8XG3jNiU09VxA@mail.gmail.com>

Hi Everyone,

I would like to thank everyone for their generous and kind answers to
my question. I'll try out the few suggestions offered so far and see
the results I get. This is most fun! :-)

Thanks again!.

-=david=-

On 21 November 2011 23:17, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:
> Hi David,
>
> you are lucky that you have such a good machine to test on - I have an older
> MBP with an Intel Core 2 Duo which has 2 cores, it performs MUCH worse using
> the parallel search algorithm than the sequential one.
>
> Each of your tasks is too small. ?You are basically just doing a search
> through a list that is at most 100 elements long. ?If you give each thread
> more work, you will manage to get the parallel to be faster than the
> sequential.
>
> The biggest bottleneck in your test is context switching. ?You can see that
> if you look at the task manager, most of the time is spent in system time.
>
> Personally, I have yet to find a really compelling example that shows how
> the parallel recursive algorithm improves performance. ?I'm sure there must
> be some out there, such as some forms of sorting. ?In your case, I would
> much rather use the CompletionService to get the answer back as soon as it
> is available. ?In other words, something like this:
>
> ?protected void doInParallel(final List<First> firsts) {
> ? ExecutorService pool = Executors.newFixedThreadPool(
> ? ? ? Runtime.getRuntime().availableProcessors()
> ? );
> ? CompletionService<Boolean> service = new
> ExecutorCompletionService<>(pool);
> ? int submittedJobs = 0;
> ? for (final First first : firsts) {
> ? ? service.submit(new Callable<Boolean>() {
> ? ? ? public Boolean call() throws Exception {
> ? ? ? ? for (Second second : first.getSeconds()) {
> ? ? ? ? ? final List<Third> thirds = second.getThirds();
> ? ? ? ? ? for (Third third : thirds) {
> ? ? ? ? ? ? if (third.getValue() == Main.NUMBER) {
> ? ? ? ? ? ? ? return true;
> ? ? ? ? ? ? }
> ? ? ? ? ? }
> ? ? ? ? }
> ? ? ? ? return false;
> ? ? ? }
> ? ? });
> ? ? submittedJobs++;
> ? }
> ? for (int i = 0; i < submittedJobs; i++) {
> ? ? try {
> ? ? ? if (service.take().get()) break;
> ? ? } catch (Exception e) {
> ? ? ? e.printStackTrace();
> ? ? }
> ? }
> ? pool.shutdown();
> ? return;
> ?}
>
>
> I reduced the number of Thirds and also the call count, and got the
> following results on a dual-processor machine:
>
> Generating some data...done!
> Sequential
> Simon Stopwatch: total 14.7 s, counter 500, max 126 ms, min 25.3 ms, mean
> 29.3 ms [sequential INHERIT]
> Parallel
> Simon Stopwatch: total 15.0 s, counter 500, max 72.0 ms, min 25.6 ms, mean
> 29.9 ms [parallel INHERIT]
>
> On your machine you should see significant performance gains in the parallel
> vs sequential version.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> On 11/21/11 11:15 PM, David Harrigan wrote:
>>
>> Hi Everyone,
>>
>> I'm learning about the fork and join framework in JDK7 and to test it
>> out I wrote a little program that tries to find a number at the end of
>> a list with 50,000 elements.
>> What puzzles me is when I run the "find" in a sequential fashion, it
>> returns faster than if I use a fork-and-join implementation. I'm
>> running each "find" 5000 times
>> so as to "warm" up the JVM. I've got a timing listed below:
>>
>> Generating some data...done!
>> Sequential
>> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
>> mean 203 ms [sequential INHERIT]
>> Parallel
>> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
>> mean 270 ms [parallel INHERIT]
>>
>> (some runtime information)
>>
>> openjdk version "1.7.0-ea"
>> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
>> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>>
>> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
>> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>>
>> Forgive my ignorance but this type of programming is still quite new
>> to me and I'm obviously doing something wrong, but I don't know what.
>> My suspicion is
>> something to do with spinning up and down threads and the overhead
>> that entails. I've posted the src here http://pastebin.com/p96R24R0.
>>
>> My sincere apologies if this list is not appropriate for this posting,
>> if so I would welcome a pointer on where I can find more information
>> to help me understand
>> better the behaviour of my program when using F&J.
>>
>> I thought that by using F&J I would be able to find the answer quicker
>> than doing the searching sequentially, perhaps I've choosen a wrong
>> initial problem to
>> test this out (something that is suited to a sequential search and not
>> a parallel search?)
>>
>> Thank you all in advance.
>>
>> -=david=-
>>
>>



-- 
I prefer encrypted and signed messages. KeyID: B20A22F9
Fingerprint: 110A F423 3647 54E2 880F ADAD 1C52 85BF B20A 22F9

"It is not usually until you've built and used a version of the
program that you understand the issues well enough to get the design
right." - Rob Pike, Brian Kernighan.

No trees were harmed in the sending of this message, however, a number
of electrons were inconvenienced.


From gkorland at gmail.com  Mon Nov 21 18:26:17 2011
From: gkorland at gmail.com (Guy Korland)
Date: Tue, 22 Nov 2011 01:26:17 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
Message-ID: <CAMaz81J30E8dxbWh589Hb0yMxwvO-Fd4KQJkLMmx3jceT8oe2w@mail.gmail.com>

First, I think this is a discussion that should be done as part of a JSR.
Meaning, I think the wheels should start moving and then we'll carve out
the best solution.
As for your questions:
1. There're two realistic options to handle I/O and one naiive.
     In other words (a) you can ignore I/O or Native code call as you do
with I/O or Native call when called under a lock context (You don't enforce
any memory semantic). (b) you can abort any transaction trying to get
outside the scope of the JVM. (c) you can hope for transactional I/O but it
won't help for Native method call.
I think a realistic solution should go with (b).

2. The semantic we choose in DeuceSTM was to commit a transaction that
throws an application Exception, and that since (sadly) throwing an
Exception is a valid way to return from method in java and pretty common.
Also again when running under a context of coarse grained lock Exception is
a valid way to get out of it.

Guy



> Date: Mon, 21 Nov 2011 23:03:31 +0100
> From: R?mi Forax <forax at univ-mlv.fr>
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>        what about Java?
> Message-ID: <4ECACAB3.3000001 at univ-mlv.fr>
> Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
>
> On 11/21/2011 08:04 PM, Guy Korland wrote:
> > Not all the issues are solved, but it seems like most of the issues
> > have good answers.
> > Also, notice that in .NET they have issues which Java doesn't have
> > like Native code and pointers in C++.
> >
> > Guy
>
> And how do you solve the IO problems (when you retry) ?
> Also the semantics chosen by Microsoft when an exception is thrown
> and the one chosen by GCC is not the same.
>
> cheers,
> R?mi
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/263a3d1f/attachment.html>

From nathan.reynolds at oracle.com  Mon Nov 21 18:29:00 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 21 Nov 2011 16:29:00 -0700
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <4ECAD264.2080503@cytetech.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
	<4ECAC554.1060604@oracle.com> <4ECAD264.2080503@cytetech.com>
Message-ID: <4ECADEBC.8010900@oracle.com>

The JVM does profile-guided optimization.  If you reduce the warm up to 
only 100 invocations, then the JVM only looks at those 100 samples and 
determines how to optimize the method.  I would guess that for some 
methods 100, or 1000 or 10000 invocations isn't going to make any 
difference on the optimized code.  However, other methods need the full 
10,000 invocations in order to fully understand how the method is used 
and the best way to optimize it.

In production, you could start one JVM with 100 invocations and the 
other with the default.  If both JVMs have the same CPU usage, response 
times and throughput after warmup and compilation, then 100 invocations 
is sufficient for your workload.  I would guess that the one with 100 
invocations will suffer.

I'm not sure, but I believe HotSpot 7 includes a tiered compilation.  
After 1,000 invocations, the method is deemed hot enough that the JVM 
optimizes it without any profiling data to guide the optimizations.  The 
JVM adds profiling code to the method at this time.  After 10,000 
invocations, the JVM does the profile-guided optimization of the method.

On a heavily used server, 10,000 invocations should happen very 
quickly.  For some servers, they will process that many requests per 
second or even sub-second.  So, the question becomes does the first few 
minutes of execution really matter considering the lifespan of the 
server?  In the overall picture, the start up time is much less than 1% 
of the total time the server is running.

For client applications, this is a much different story.  The 10,000 
invocation won't be reached until the user presses a button 10,000 
times.  However, _some_ of the time the response time of the program 
isn't critical.  The response time for fully optimized code might be 1 
ms.  With unoptimized code it might be 10 ms.  The user may not be able 
to notice.  For example, the older flat-panel monitors refresh at 60 Hz 
(= 16.6 ms).  So, if the program responds within 16.6 ms, the user may 
not even be able to see that it took a bit longer.

However, I hear your pain.  I wish there were a good way to have instant 
warm up.  I and several others have given this problem a lot of 
thought.  All of the schemes we have come up with have a lot of issues 
and were rejected flat-out or were tried and then rejected due to 
performance issues.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/21/2011 3:36 PM, Gregg Wonderly wrote:
> So I have to ask, why don't you use the command line property to 
> change this to something like 100 for a faster warm up?  For some of 
> my applications, doing this reduces startup time by orders of 
> magnitude because of the number of times some things are invoked.  In 
> particular, server applications using a security manager seem to start 
> much faster.
>
> Gregg Wonderly
>
> On 11/21/2011 3:40 PM, Nathan Reynolds wrote:
>> Microbenchmarks are incredibly hard to get right. For example, 
>> HotSpot 7 JVM
>> won't do a full optimization of a method until 10,000 invocations. 
>> You need to
>> bump up the priority of the test thread so that other things on the 
>> system don't
>> add noise. These probably aren't applicable to your case, but you may 
>> to force a
>> full GC right before running the test.
>>
>> You probably want to use http://code.google.com/p/caliper/ which 
>> deals with all
>> of these gotchas.
>>
>> Nathan Reynolds 
>> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>> Consulting Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 11/21/2011 2:15 PM, David Harrigan wrote:
>>> Hi Everyone,
>>>
>>> I'm learning about the fork and join framework in JDK7 and to test it
>>> out I wrote a little program that tries to find a number at the end of
>>> a list with 50,000 elements.
>>> What puzzles me is when I run the "find" in a sequential fashion, it
>>> returns faster than if I use a fork-and-join implementation. I'm
>>> running each "find" 5000 times
>>> so as to "warm" up the JVM. I've got a timing listed below:
>>>
>>> Generating some data...done!
>>> Sequential
>>> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
>>> mean 203 ms [sequential INHERIT]
>>> Parallel
>>> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
>>> mean 270 ms [parallel INHERIT]
>>>
>>> (some runtime information)
>>>
>>> openjdk version "1.7.0-ea"
>>> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
>>> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>>>
>>> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
>>> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>>>
>>> Forgive my ignorance but this type of programming is still quite new
>>> to me and I'm obviously doing something wrong, but I don't know what.
>>> My suspicion is
>>> something to do with spinning up and down threads and the overhead
>>> that entails. I've posted the src herehttp://pastebin.com/p96R24R0.
>>>
>>> My sincere apologies if this list is not appropriate for this posting,
>>> if so I would welcome a pointer on where I can find more information
>>> to help me understand
>>> better the behaviour of my program when using F&J.
>>>
>>> I thought that by using F&J I would be able to find the answer quicker
>>> than doing the searching sequentially, perhaps I've choosen a wrong
>>> initial problem to
>>> test this out (something that is suited to a sequential search and not
>>> a parallel search?)
>>>
>>> Thank you all in advance.
>>>
>>> -=david=-
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111121/e12f0695/attachment.html>

From gkorland at gmail.com  Mon Nov 21 18:39:58 2011
From: gkorland at gmail.com (Guy Korland)
Date: Tue, 22 Nov 2011 01:39:58 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
Message-ID: <CAMaz81J-PLV+6u_MeiGx9Nep3t3d7Nv+ePgTdmkH7trzj4Qf2w@mail.gmail.com>

Again, I think such discussion should be done under a context of a JSR.

But, for your comment, using "managed references" or some other explicit
model to mark managed references in my opinion might be a blocker for
adding STM to Java.
I don't see any chance for successful Java STM which is not composable and
supports calling legacy libraries.
Unless I'm missing something?

Guy

Date: Mon, 21 Nov 2011 23:57:21 +0100
From: ?iktor ?lang <viktor.klang at gmail.com>
To: R?mi Forax <forax at univ-mlv.fr>
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
       what about Java?
Message-ID:
       <CANPzfU8-fH=Sgc6a1d8xvAtsDrMbWXVoaJ3udV5YH2KoqUwwfQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

I think that managed references is the only way to go when it comes to STM.
You can't make it implicit since traditional "OO"-code is completely ridden
with side effects.

Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/88351b5d/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue Nov 22 00:23:23 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 22 Nov 2011 15:23:23 +1000
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEGNJBAA.davidcholmes@aapt.net.au>

David,

The typical/usual approach with FJ is to submit only a single top-level task
via FJPool.invoke/submit and that task then does the parallel decomposition
via fork/join. Your algorithm, which I confess I can not follow, creates
numerous top-level tasks - which is more akin to submitting tasks to a plain
executor.

To avoid all the other microbenchmark gotchas trying running with -Xint and
do away with all the warmups; or keep a simple warmup and run with -Xcomp.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David
> Harrigan
> Sent: Tuesday, 22 November 2011 7:16 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] A beginner question (on fork-and-join)
>
>
> Hi Everyone,
>
> I'm learning about the fork and join framework in JDK7 and to test it
> out I wrote a little program that tries to find a number at the end of
> a list with 50,000 elements.
> What puzzles me is when I run the "find" in a sequential fashion, it
> returns faster than if I use a fork-and-join implementation. I'm
> running each "find" 5000 times
> so as to "warm" up the JVM. I've got a timing listed below:
>
> Generating some data...done!
> Sequential
> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
> mean 203 ms [sequential INHERIT]
> Parallel
> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
> mean 270 ms [parallel INHERIT]
>
> (some runtime information)
>
> openjdk version "1.7.0-ea"
> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>
> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>
> Forgive my ignorance but this type of programming is still quite new
> to me and I'm obviously doing something wrong, but I don't know what.
> My suspicion is
> something to do with spinning up and down threads and the overhead
> that entails. I've posted the src here http://pastebin.com/p96R24R0.
>
> My sincere apologies if this list is not appropriate for this posting,
> if so I would welcome a pointer on where I can find more information
> to help me understand
> better the behaviour of my program when using F&J.
>
> I thought that by using F&J I would be able to find the answer quicker
> than doing the searching sequentially, perhaps I've choosen a wrong
> initial problem to
> test this out (something that is suited to a sequential search and not
> a parallel search?)
>
> Thank you all in advance.
>
> -=david=-
>
> --
> I prefer encrypted and signed messages. KeyID: B20A22F9
> Fingerprint: 110A F423 3647 54E2 880F ADAD 1C52 85BF B20A 22F9
>
> "It is not usually until you've built and used a version of the
> program that you understand the issues well enough to get the design
> right." - Rob Pike, Brian Kernighan.
>
> No trees were harmed in the sending of this message, however, a number
> of electrons were inconvenienced.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From benjamin.john.evans at gmail.com  Tue Nov 22 02:12:45 2011
From: benjamin.john.evans at gmail.com (Ben Evans)
Date: Tue, 22 Nov 2011 07:12:45 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81J-PLV+6u_MeiGx9Nep3t3d7Nv+ePgTdmkH7trzj4Qf2w@mail.gmail.com>
References: <CAMaz81J-PLV+6u_MeiGx9Nep3t3d7Nv+ePgTdmkH7trzj4Qf2w@mail.gmail.com>
Message-ID: <CABKW8Rg_fhvN=xzUW0Mt_DaawtkffG+Qq+rYLdog=Y_B-eOCOg@mail.gmail.com>

I utterly disagree.

JSRs should be places for standardization of existing mature or
maturing markets.

They are not a place for speculative experimentation. That should be
done in a regular OSS project, or e.g. as part of mlvm-dev (as it
seems to be that transactional memory is a VM feature, not a purely
Java-language one).

I also can't believe that we've got this far in the discussion without
anyone mentioning Clojure's approach to STM, including co-ordination
of its ref constructs. In particular, the retry semantics, and the
requirement that transactions be side-effect-free seem incredibly
pertinent to this discussion.

Completely agree about the need for "managed concurrent references"
though, and also that support for legacy libraries seems pretty much
essential.

However, let's not kid ourselves. Java is the world's
centre-of-the-mean programming language - and unenforceable
compromises such as Clojure's: "Transactions must be side-effect-free.
Or else." are not practical for Java. If they're the best we can do,
then we should leave STM out as a feature.

Thanks,

Ben

On Mon, Nov 21, 2011 at 11:39 PM, Guy Korland <gkorland at gmail.com> wrote:
> Again, I think such discussion should be done under a context of a JSR.
> But, for your comment, using "managed references" or some other explicit
> model to mark managed references in my opinion might be a blocker for adding
> STM to Java.
> I don't see any chance for successful Java STM which is not composable and
> supports calling legacy libraries.
> Unless I'm missing something?
> Guy
> Date: Mon, 21 Nov 2011 23:57:21 +0100
> From: ?iktor ?lang <viktor.klang at gmail.com>
> To: R?mi Forax <forax at univ-mlv.fr>
> Cc:?concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
> ? ? ? ?what about Java?
> Message-ID:
> ? ? ? ?<CANPzfU8-fH=Sgc6a1d8xvAtsDrMbWXVoaJ3udV5YH2KoqUwwfQ at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> I think that managed references is the only way to go when it comes to STM.
> You can't make it implicit since traditional "OO"-code is completely ridden
> with side effects.
>
> Cheers,
> ?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From joe.bowbeer at gmail.com  Tue Nov 22 03:31:46 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 22 Nov 2011 00:31:46 -0800
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CABKW8Rg_fhvN=xzUW0Mt_DaawtkffG+Qq+rYLdog=Y_B-eOCOg@mail.gmail.com>
References: <CAMaz81J-PLV+6u_MeiGx9Nep3t3d7Nv+ePgTdmkH7trzj4Qf2w@mail.gmail.com>
	<CABKW8Rg_fhvN=xzUW0Mt_DaawtkffG+Qq+rYLdog=Y_B-eOCOg@mail.gmail.com>
Message-ID: <CAHzJPErHzCsM8ak1daX9+qbFyXu_pLCASM8cTuBmvZEJDUHLmg@mail.gmail.com>

Speaking for myself, I'm looking forward to reading more of this discussion
on concurrency-interest.

Is it unreasonable to think that something along the lines of
scala.concurrent.stm will make its way to java.util.concurrent.stm?

http://nbronson.github.com/scala-stm/expert_group.html

--Joe
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/74bbdbfb/attachment.html>

From viktor.klang at gmail.com  Tue Nov 22 03:36:52 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 22 Nov 2011 09:36:52 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CABKW8Rg_fhvN=xzUW0Mt_DaawtkffG+Qq+rYLdog=Y_B-eOCOg@mail.gmail.com>
References: <CAMaz81J-PLV+6u_MeiGx9Nep3t3d7Nv+ePgTdmkH7trzj4Qf2w@mail.gmail.com>
	<CABKW8Rg_fhvN=xzUW0Mt_DaawtkffG+Qq+rYLdog=Y_B-eOCOg@mail.gmail.com>
Message-ID: <CANPzfU_60EF+hyvTRMzyN=GgunE0COv2B-zMb+QtuAvWYJU8QQ@mail.gmail.com>

On Tue, Nov 22, 2011 at 8:12 AM, Ben Evans <benjamin.john.evans at gmail.com>wrote:

> I utterly disagree.
>
> JSRs should be places for standardization of existing mature or
> maturing markets.
>
> They are not a place for speculative experimentation. That should be
> done in a regular OSS project, or e.g. as part of mlvm-dev (as it
> seems to be that transactional memory is a VM feature, not a purely
> Java-language one).
>
> I also can't believe that we've got this far in the discussion without
> anyone mentioning Clojure's approach to STM, including co-ordination
> of its ref constructs. In particular, the retry semantics, and the
> requirement that transactions be side-effect-free seem incredibly
> pertinent to this discussion.
>
> Completely agree about the need for "managed concurrent references"
> though, and also that support for legacy libraries seems pretty much
> essential.
>
> However, let's not kid ourselves. Java is the world's
> centre-of-the-mean programming language - and unenforceable
> compromises such as Clojure's: "Transactions must be side-effect-free.
> Or else." are not practical for Java. If they're the best we can do,
> then we should leave STM out as a feature.
>

What he said.

Cheers,
?


>
> Thanks,
>
> Ben
>
> On Mon, Nov 21, 2011 at 11:39 PM, Guy Korland <gkorland at gmail.com> wrote:
> > Again, I think such discussion should be done under a context of a JSR.
> > But, for your comment, using "managed references" or some other explicit
> > model to mark managed references in my opinion might be a blocker for
> adding
> > STM to Java.
> > I don't see any chance for successful Java STM which is not composable
> and
> > supports calling legacy libraries.
> > Unless I'm missing something?
> > Guy
> > Date: Mon, 21 Nov 2011 23:57:21 +0100
> > From: ?iktor ?lang <viktor.klang at gmail.com>
> > To: R?mi Forax <forax at univ-mlv.fr>
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
> >        what about Java?
> > Message-ID:
> >        <CANPzfU8-fH=
> Sgc6a1d8xvAtsDrMbWXVoaJ3udV5YH2KoqUwwfQ at mail.gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> >
> > I think that managed references is the only way to go when it comes to
> STM.
> > You can't make it implicit since traditional "OO"-code is completely
> ridden
> > with side effects.
> >
> > Cheers,
> > ?
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/3c510540/attachment.html>

From gregg at cytetech.com  Tue Nov 22 09:04:11 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 22 Nov 2011 08:04:11 -0600
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81J30E8dxbWh589Hb0yMxwvO-Fd4KQJkLMmx3jceT8oe2w@mail.gmail.com>
References: <CAMaz81J30E8dxbWh589Hb0yMxwvO-Fd4KQJkLMmx3jceT8oe2w@mail.gmail.com>
Message-ID: <4ECBABDB.5000009@cytetech.com>

A few years back, I built a multi-machine system which required that all 
machines have a mirrored copy of the systems database, and that the change of 
database content be synchronized with the operational data used by the software 
on each machine, and on any connected client computer system.

I built the transactional operations around the use of the Jini transactional 
services.  I create the synchronization around a mesh network, that was 
structured around an InvocationHandler which received inbound calls and 
guaranteed they only passed into the JVM once (within a small time interval), 
but also had references to all connected clients.  The transaction join happened 
on the inbound call.  Each method of the service API included a "CallContext" 
argument which held the transaction ID and other information.

I used an interface with "onCommit", "onPrepare" and "onAbort" methods in the 
service API methods.  The object took the call context, joined the transaction 
specified, placed itself into a static container (to maintain the reference 
chain), and then waited for the transaction owner to act.

This is pretty much the best model that I could imagine which would allow the 
transactional model to work across all the machine with a lose coupling (the 
mesh network makes it unnecessary to worry about who is a client).

Clients would connect to a server and register themselves as a listener.  They 
were called out to, on commit, and had no ability to lodge a rejection on 
prepare or commit.  They just took the call passed to them, and acted on it. 
This keeps clients from interfering with the forward progress of the system, and 
they can get a repaired view, by restarting.  In a sense, their view of the 
system was read only (they couldn't argue about the ability to commit), but they 
could modify the system transactionally.

I was not aware of the work at MS labs regarding their use of the model, but was 
driven by the mechanisms available with Jini's transactional services and the 
leasing model.

Yes, there is quite a bit of "code" involved to make this happen, but once you 
have the system wired this way, extension of the API and actions of the clients 
are pretty much as they would be for any simple client-server or "external I/O 
interface" application.

Hiding the complexity of "I/O" or "remote calls" will never be viable without an 
mechanism for the application to deal with "partial failure."  The RMI and later 
Jini (now housed in the Apache River project) work around remoting really 
demonstrates how to do transactional computing with arbitrary participants.

Gregg Wonderly

On 11/21/2011 5:26 PM, Guy Korland wrote:
> First, I think this is a discussion that should be done as part of a JSR.
> Meaning, I think the wheels should start moving and then we'll carve out the
> best solution.
> As for your questions:
> 1. There're two realistic options to handle I/O and one naiive.
>       In other words (a) you can ignore I/O or Native code call as you do with
> I/O or Native call when called under a lock context (You don't enforce any
> memory semantic). (b) you can abort any transaction trying to get outside the
> scope of the JVM. (c) you can hope for transactional I/O but it won't help for
> Native method call.
> I think a realistic solution should go with (b).
>
> 2. The semantic we choose in DeuceSTM was to commit a transaction that throws an
> application Exception, and that since (sadly) throwing an Exception is a valid
> way to return from method in java and pretty common. Also again when running
> under a context of coarse grained lock Exception is a valid way to get out of it.
>
> Guy
>
>     Date: Mon, 21 Nov 2011 23:03:31 +0100
>     From: R?mi Forax <forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>>
>     To: concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>             what about Java?
>     Message-ID: <4ECACAB3.3000001 at univ-mlv.fr <mailto:4ECACAB3.3000001 at univ-mlv.fr>>
>     Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
>
>     On 11/21/2011 08:04 PM, Guy Korland wrote:
>      > Not all the issues are solved, but it seems like most of the issues
>      > have good answers.
>      > Also, notice that in .NET they have issues which Java doesn't have
>      > like Native code and pointers in C++.
>      >
>      > Guy
>
>     And how do you solve the IO problems (when you retry) ?
>     Also the semantics chosen by Microsoft when an exception is thrown
>     and the one chosen by GCC is not the same.
>
>     cheers,
>     R?mi
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Tue Nov 22 09:40:36 2011
From: aph at redhat.com (Andrew Haley)
Date: Tue, 22 Nov 2011 14:40:36 +0000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
Message-ID: <4ECBB464.8070000@redhat.com>

A little mystery:

Inserting Barriers
...

   2. Issue a StoreStore barrier after all stores but before return
   from any constructor for any class with a final field.

So, I'm looking for this barrier in the HotSpot code but I have been
unable to find it.  Can someone please put me out of my misery and
tell me where it is?

Thanks,
Andrew.

From aph at redhat.com  Tue Nov 22 10:37:26 2011
From: aph at redhat.com (Andrew Haley)
Date: Tue, 22 Nov 2011 15:37:26 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4EC692A3.6020506@oracle.com>
References: <CAMaz81+K=_Zy-UGtM6nZ3FLNMNFJLXjYBtwk49mEGywLqMd1=A@mail.gmail.com>
	<4EC692A3.6020506@oracle.com>
Message-ID: <4ECBC1B6.8070006@redhat.com>

On 11/18/2011 05:15 PM, Nathan Reynolds wrote:
> We would probably need to consider STM and hardware support.

Sure, but we don't need hardware support for Java.  If
C++ can do it without hardware, so can Java.  Algorithms like
TL2 make it practical to do in software.  Figuring out language
integration is the big challenge.

Andrew.

From nathan.reynolds at oracle.com  Tue Nov 22 10:56:07 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 22 Nov 2011 08:56:07 -0700
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <4ECBB464.8070000@redhat.com>
References: <4ECBB464.8070000@redhat.com>
Message-ID: <4ECBC617.3070201@oracle.com>

On x86 and Sparc TSO, the StoreStore barrier becomes a no-op.  (See the 
table in the Multiprocessors section.)  These processors will not allow 
stores to go before other stores.  Thus, the StoreStore barrier is 
already enforced for all store operations by the processor.  The only 
barrier required on x86 and Sparc TSO is the StoreLoad barrier.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/22/2011 7:40 AM, Andrew Haley wrote:
> A little mystery:
>
> Inserting Barriers
> ...
>
>     2. Issue a StoreStore barrier after all stores but before return
>     from any constructor for any class with a final field.
>
> So, I'm looking for this barrier in the HotSpot code but I have been
> unable to find it.  Can someone please put me out of my misery and
> tell me where it is?
>
> Thanks,
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/90e98895/attachment.html>

From heinz at javaspecialists.eu  Tue Nov 22 11:09:53 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 22 Nov 2011 18:09:53 +0200
Subject: [concurrency-interest] CompareAndSet - can there also be NO winner?
Message-ID: <4ECBC951.2090207@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/da2f048d/attachment.html>

From nathan.reynolds at oracle.com  Tue Nov 22 11:28:36 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 22 Nov 2011 09:28:36 -0700
Subject: [concurrency-interest] CompareAndSet - can there also be NO
	winner?
In-Reply-To: <4ECBC951.2090207@javaspecialists.eu>
References: <4ECBC951.2090207@javaspecialists.eu>
Message-ID: <4ECBCDB4.3060508@oracle.com>

It depends upon the processor.  On x86, there will always be a clear 
winner because forward progress is guaranteed.  On other processors, it 
depends if it guarantees forward progress.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/22/2011 9:09 AM, Dr Heinz M. Kabutz wrote:
> Something I've wondered about for a while...
>
> If we have an atomic integer (or any other atomic class) and two 
> threads call compareAndSet(42, 43) at the same time, is it possible 
> that both calls fail?  Or is there /always/ a winner?
> Regards
>
> Heinz
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/0f103eb7/attachment.html>

From viktor.klang at gmail.com  Tue Nov 22 11:33:57 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 22 Nov 2011 17:33:57 +0100
Subject: [concurrency-interest] CompareAndSet - can there also be NO
	winner?
In-Reply-To: <4ECBCDB4.3060508@oracle.com>
References: <4ECBC951.2090207@javaspecialists.eu> <4ECBCDB4.3060508@oracle.com>
Message-ID: <CANPzfU_PFF6HvZ+41kH6b1igOOBk-Vyr_pDneLyqbJ4rQeqayg@mail.gmail.com>

On Tue, Nov 22, 2011 at 5:28 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  It depends upon the processor.  On x86, there will always be a clear
> winner because forward progress is guaranteed.  On other processors, it
> depends if it guarantees forward progress.
>

It also heavily depends on the current value ;-)


>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 11/22/2011 9:09 AM, Dr Heinz M. Kabutz wrote:
>
> Something I've wondered about for a while...
>
> If we have an atomic integer (or any other atomic class) and two threads
> call compareAndSet(42, 43) at the same time, is it possible that both calls
> fail?  Or is there *always* a winner?
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professionalhttp://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/15e8e4f8/attachment.html>

From aph at redhat.com  Tue Nov 22 11:41:08 2011
From: aph at redhat.com (Andrew Haley)
Date: Tue, 22 Nov 2011 16:41:08 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECACAB3.3000001@univ-mlv.fr>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr>
Message-ID: <4ECBD0A4.9010604@redhat.com>

On 11/21/2011 10:03 PM, R?mi Forax wrote:
> On 11/21/2011 08:04 PM, Guy Korland wrote:
>> Not all the issues are solved, but it seems like most of the issues 
>> have good answers.
>> Also, notice that in .NET they have issues which Java doesn't have 
>> like Native code and pointers in C++.
> 
> And how do you solve the IO problems (when you retry) ?

There are basically two practical approaches to I/O:

1.  Don't do I/O in a transaction.

2.  Convert the transaction into a "relaxed" transaction, i.e. one
that uses a single global lock.

Andrew.

From dl at cs.oswego.edu  Tue Nov 22 11:46:33 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 22 Nov 2011 11:46:33 -0500
Subject: [concurrency-interest] CompareAndSet - can there also be NO
	winner?
In-Reply-To: <4ECBC951.2090207@javaspecialists.eu>
References: <4ECBC951.2090207@javaspecialists.eu>
Message-ID: <4ECBD1E9.60809@cs.oswego.edu>

On 11/22/11 11:09, Dr Heinz M. Kabutz wrote:

> If we have an atomic integer (or any other atomic class) and two threads call
> compareAndSet(42, 43) at the same time, is it possible that both calls fail? Or
> is there /always/ a winner?

Assuming that the value was 42, yes, there must be a winner.
The weakCompareAndSet method makes no such guarantees.
On machines with LL/SC not CAS, plain CAS must be (and is) emulated
to preserve this guarantee, but weak-CAS may fail spuriously.
For more background, see Herlihy and Shavit's book.

-Doug

From viktor.klang at gmail.com  Tue Nov 22 11:50:06 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 22 Nov 2011 17:50:06 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECBD0A4.9010604@redhat.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
Message-ID: <CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>

On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:

> On 11/21/2011 10:03 PM, R?mi Forax wrote:
> > On 11/21/2011 08:04 PM, Guy Korland wrote:
> >> Not all the issues are solved, but it seems like most of the issues
> >> have good answers.
> >> Also, notice that in .NET they have issues which Java doesn't have
> >> like Native code and pointers in C++.
> >
> > And how do you solve the IO problems (when you retry) ?
>
> There are basically two practical approaches to I/O:
>
> 1.  Don't do I/O in a transaction.
>
> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
> that uses a single global lock.
>

Problem is that you can't reliably detect IO, so that makes any call to a
3rd party jar a can of worms.
Also, you cannot reliably detect blocking or non-termination, which makes
this global lock the Devil(tm)

Cheers,
?


> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/13b385cf/attachment.html>

From gregg at cytetech.com  Tue Nov 22 11:52:24 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 22 Nov 2011 10:52:24 -0600
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <4ECADEBC.8010900@oracle.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
	<4ECAC554.1060604@oracle.com> <4ECAD264.2080503@cytetech.com>
	<4ECADEBC.8010900@oracle.com>
Message-ID: <4ECBD348.5090400@cytetech.com>

Nathan, thanks for your insight.  My experience is that most of my code does 
absolutely little which would be "tuned" for improved throughput by an 
optimizer.  Instead, my applications are largely client server and remote 
communications based, and the vast majority of wall clock time involves latency 
in communications between machines.

The SecurityManager, Permission, PermissionCollection and other related classes 
are absolutely at odds with throughput because of course grained locking and 
other extremely poor design choices.  Use of a SecurityManager seems like it is 
a much overlooked part of the JVM performance.

We have things like the use of reflection in subclasses of Thread and "locking" 
to single threaded construction (a static container of all things) which kills 
throughput, no matter when the Jit takes over because of

	private static boolean isCCLOverridden(Class cl);

That mechanism should be using Future (inside CHM perhaps) and not 
synchronized().  This can, to some degree be worked around by using a Runnable, 
instead, but sometimes a Thread is what works better because of its 
accessibility through Thread.currentThread() and yes you could use ThreadLocal 
instead for many cases.  But, subclassing thread for a Thread factory can be a 
necessity, and that's where many server kinds of applications with a security 
manager active get into trouble.

For me, anything with a security manager that is a client, starts much faster 
with 100 invocations.  If there is anything appreciable that I miss by compiling 
that soon, I've not noticed it.

Your discussion on heuristics being used to make more intelligent decisions 
about what optimizations might be beneficial (branch optimizations I'm guessing) 
help me see that there might be some better reasons to delay for some heavily 
compute bound classes.

Gregg

On 11/21/2011 5:29 PM, Nathan Reynolds wrote:
> The JVM does profile-guided optimization. If you reduce the warm up to only 100
> invocations, then the JVM only looks at those 100 samples and determines how to
> optimize the method. I would guess that for some methods 100, or 1000 or 10000
> invocations isn't going to make any difference on the optimized code. However,
> other methods need the full 10,000 invocations in order to fully understand how
> the method is used and the best way to optimize it.
>
> In production, you could start one JVM with 100 invocations and the other with
> the default. If both JVMs have the same CPU usage, response times and throughput
> after warmup and compilation, then 100 invocations is sufficient for your
> workload. I would guess that the one with 100 invocations will suffer.
>
> I'm not sure, but I believe HotSpot 7 includes a tiered compilation. After 1,000
> invocations, the method is deemed hot enough that the JVM optimizes it without
> any profiling data to guide the optimizations. The JVM adds profiling code to
> the method at this time. After 10,000 invocations, the JVM does the
> profile-guided optimization of the method.
>
> On a heavily used server, 10,000 invocations should happen very quickly. For
> some servers, they will process that many requests per second or even
> sub-second. So, the question becomes does the first few minutes of execution
> really matter considering the lifespan of the server? In the overall picture,
> the start up time is much less than 1% of the total time the server is running.
>
> For client applications, this is a much different story. The 10,000 invocation
> won't be reached until the user presses a button 10,000 times. However, _some_
> of the time the response time of the program isn't critical. The response time
> for fully optimized code might be 1 ms. With unoptimized code it might be 10 ms.
> The user may not be able to notice. For example, the older flat-panel monitors
> refresh at 60 Hz (= 16.6 ms). So, if the program responds within 16.6 ms, the
> user may not even be able to see that it took a bit longer.
>
> However, I hear your pain. I wish there were a good way to have instant warm up.
> I and several others have given this problem a lot of thought. All of the
> schemes we have come up with have a lot of issues and were rejected flat-out or
> were tried and then rejected due to performance issues.
>
> Nathan Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 11/21/2011 3:36 PM, Gregg Wonderly wrote:
>> So I have to ask, why don't you use the command line property to change this
>> to something like 100 for a faster warm up? For some of my applications, doing
>> this reduces startup time by orders of magnitude because of the number of
>> times some things are invoked. In particular, server applications using a
>> security manager seem to start much faster.
>>
>> Gregg Wonderly
>>
>> On 11/21/2011 3:40 PM, Nathan Reynolds wrote:
>>> Microbenchmarks are incredibly hard to get right. For example, HotSpot 7 JVM
>>> won't do a full optimization of a method until 10,000 invocations. You need to
>>> bump up the priority of the test thread so that other things on the system don't
>>> add noise. These probably aren't applicable to your case, but you may to force a
>>> full GC right before running the test.
>>>
>>> You probably want to use http://code.google.com/p/caliper/ which deals with all
>>> of these gotchas.
>>>
>>> Nathan Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>>> Consulting Member of Technical Staff | 602.333.9091
>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>
>>> On 11/21/2011 2:15 PM, David Harrigan wrote:
>>>> Hi Everyone,
>>>>
>>>> I'm learning about the fork and join framework in JDK7 and to test it
>>>> out I wrote a little program that tries to find a number at the end of
>>>> a list with 50,000 elements.
>>>> What puzzles me is when I run the "find" in a sequential fashion, it
>>>> returns faster than if I use a fork-and-join implementation. I'm
>>>> running each "find" 5000 times
>>>> so as to "warm" up the JVM. I've got a timing listed below:
>>>>
>>>> Generating some data...done!
>>>> Sequential
>>>> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
>>>> mean 203 ms [sequential INHERIT]
>>>> Parallel
>>>> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
>>>> mean 270 ms [parallel INHERIT]
>>>>
>>>> (some runtime information)
>>>>
>>>> openjdk version "1.7.0-ea"
>>>> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
>>>> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>>>>
>>>> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
>>>> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>>>>
>>>> Forgive my ignorance but this type of programming is still quite new
>>>> to me and I'm obviously doing something wrong, but I don't know what.
>>>> My suspicion is
>>>> something to do with spinning up and down threads and the overhead
>>>> that entails. I've posted the src herehttp://pastebin.com/p96R24R0.
>>>>
>>>> My sincere apologies if this list is not appropriate for this posting,
>>>> if so I would welcome a pointer on where I can find more information
>>>> to help me understand
>>>> better the behaviour of my program when using F&J.
>>>>
>>>> I thought that by using F&J I would be able to find the answer quicker
>>>> than doing the searching sequentially, perhaps I've choosen a wrong
>>>> initial problem to
>>>> test this out (something that is suited to a sequential search and not
>>>> a parallel search?)
>>>>
>>>> Thank you all in advance.
>>>>
>>>> -=david=-
>>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>


From gregg at cytetech.com  Tue Nov 22 11:55:22 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 22 Nov 2011 10:55:22 -0600
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECBD0A4.9010604@redhat.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
Message-ID: <4ECBD3FA.6050804@cytetech.com>

On 11/22/2011 10:41 AM, Andrew Haley wrote:
> On 11/21/2011 10:03 PM, R?mi Forax wrote:
>> On 11/21/2011 08:04 PM, Guy Korland wrote:
>>> Not all the issues are solved, but it seems like most of the issues
>>> have good answers.
>>> Also, notice that in .NET they have issues which Java doesn't have
>>> like Native code and pointers in C++.
>>
>> And how do you solve the IO problems (when you retry) ?
>
> There are basically two practical approaches to I/O:
>
> 1.  Don't do I/O in a transaction.
>
> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
> that uses a single global lock.

I think it's better to say "one way operations", instead of I/O.  Basically it's 
pointless to attempt to use transactional behavior on a one way operation, 
unless it can not fail, in which case, you actually do something like

try {
    xxx.commit();
    doOneWayStuff();
} catch( ) {

}

so that you do it to create the atomic view, but you have to be able to 
guarantee ACID and completion.

Gregg

From nathan.reynolds at oracle.com  Tue Nov 22 12:24:43 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 22 Nov 2011 10:24:43 -0700
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <4ECBD348.5090400@cytetech.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>
	<4ECAC554.1060604@oracle.com> <4ECAD264.2080503@cytetech.com>
	<4ECADEBC.8010900@oracle.com> <4ECBD348.5090400@cytetech.com>
Message-ID: <4ECBDADB.7020404@oracle.com>

There are many optimizations that are useful with profiling data.  For 
example, I was surprised the other day that a virtual method got 
inlined!  The profile showed that only 1 class of many was being called 
into.  So, the optimizer put an if statement to check the class (3 cycle 
penalty) and then inlined the virtual method.  The check branches out to 
slower code if a different class is encountered.  Without profiling 
data, the optimizer would have to assume that any class was equally 
likely and therefore leave it as a pure virtual call.  However, if I had 
switch to 100 invocations then optimize, the code would have been just 
as good in this case.  The profile samples would have said the same 
thing to the optimizer.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/22/2011 9:52 AM, Gregg Wonderly wrote:
> Nathan, thanks for your insight.  My experience is that most of my 
> code does absolutely little which would be "tuned" for improved 
> throughput by an optimizer.  Instead, my applications are largely 
> client server and remote communications based, and the vast majority 
> of wall clock time involves latency in communications between machines.
>
> The SecurityManager, Permission, PermissionCollection and other 
> related classes are absolutely at odds with throughput because of 
> course grained locking and other extremely poor design choices.  Use 
> of a SecurityManager seems like it is a much overlooked part of the 
> JVM performance.
>
> We have things like the use of reflection in subclasses of Thread and 
> "locking" to single threaded construction (a static container of all 
> things) which kills throughput, no matter when the Jit takes over 
> because of
>
>     private static boolean isCCLOverridden(Class cl);
>
> That mechanism should be using Future (inside CHM perhaps) and not 
> synchronized().  This can, to some degree be worked around by using a 
> Runnable, instead, but sometimes a Thread is what works better because 
> of its accessibility through Thread.currentThread() and yes you could 
> use ThreadLocal instead for many cases.  But, subclassing thread for a 
> Thread factory can be a necessity, and that's where many server kinds 
> of applications with a security manager active get into trouble.
>
> For me, anything with a security manager that is a client, starts much 
> faster with 100 invocations.  If there is anything appreciable that I 
> miss by compiling that soon, I've not noticed it.
>
> Your discussion on heuristics being used to make more intelligent 
> decisions about what optimizations might be beneficial (branch 
> optimizations I'm guessing) help me see that there might be some 
> better reasons to delay for some heavily compute bound classes.
>
> Gregg
>
> On 11/21/2011 5:29 PM, Nathan Reynolds wrote:
>> The JVM does profile-guided optimization. If you reduce the warm up 
>> to only 100
>> invocations, then the JVM only looks at those 100 samples and 
>> determines how to
>> optimize the method. I would guess that for some methods 100, or 1000 
>> or 10000
>> invocations isn't going to make any difference on the optimized code. 
>> However,
>> other methods need the full 10,000 invocations in order to fully 
>> understand how
>> the method is used and the best way to optimize it.
>>
>> In production, you could start one JVM with 100 invocations and the 
>> other with
>> the default. If both JVMs have the same CPU usage, response times and 
>> throughput
>> after warmup and compilation, then 100 invocations is sufficient for 
>> your
>> workload. I would guess that the one with 100 invocations will suffer.
>>
>> I'm not sure, but I believe HotSpot 7 includes a tiered compilation. 
>> After 1,000
>> invocations, the method is deemed hot enough that the JVM optimizes 
>> it without
>> any profiling data to guide the optimizations. The JVM adds profiling 
>> code to
>> the method at this time. After 10,000 invocations, the JVM does the
>> profile-guided optimization of the method.
>>
>> On a heavily used server, 10,000 invocations should happen very 
>> quickly. For
>> some servers, they will process that many requests per second or even
>> sub-second. So, the question becomes does the first few minutes of 
>> execution
>> really matter considering the lifespan of the server? In the overall 
>> picture,
>> the start up time is much less than 1% of the total time the server 
>> is running.
>>
>> For client applications, this is a much different story. The 10,000 
>> invocation
>> won't be reached until the user presses a button 10,000 times. 
>> However, _some_
>> of the time the response time of the program isn't critical. The 
>> response time
>> for fully optimized code might be 1 ms. With unoptimized code it 
>> might be 10 ms.
>> The user may not be able to notice. For example, the older flat-panel 
>> monitors
>> refresh at 60 Hz (= 16.6 ms). So, if the program responds within 16.6 
>> ms, the
>> user may not even be able to see that it took a bit longer.
>>
>> However, I hear your pain. I wish there were a good way to have 
>> instant warm up.
>> I and several others have given this problem a lot of thought. All of 
>> the
>> schemes we have come up with have a lot of issues and were rejected 
>> flat-out or
>> were tried and then rejected due to performance issues.
>>
>> Nathan Reynolds 
>> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>> Consulting Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 11/21/2011 3:36 PM, Gregg Wonderly wrote:
>>> So I have to ask, why don't you use the command line property to 
>>> change this
>>> to something like 100 for a faster warm up? For some of my 
>>> applications, doing
>>> this reduces startup time by orders of magnitude because of the 
>>> number of
>>> times some things are invoked. In particular, server applications 
>>> using a
>>> security manager seem to start much faster.
>>>
>>> Gregg Wonderly
>>>
>>> On 11/21/2011 3:40 PM, Nathan Reynolds wrote:
>>>> Microbenchmarks are incredibly hard to get right. For example, 
>>>> HotSpot 7 JVM
>>>> won't do a full optimization of a method until 10,000 invocations. 
>>>> You need to
>>>> bump up the priority of the test thread so that other things on the 
>>>> system don't
>>>> add noise. These probably aren't applicable to your case, but you 
>>>> may to force a
>>>> full GC right before running the test.
>>>>
>>>> You probably want to use http://code.google.com/p/caliper/ which 
>>>> deals with all
>>>> of these gotchas.
>>>>
>>>> Nathan Reynolds 
>>>> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>>>> Consulting Member of Technical Staff | 602.333.9091
>>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>>
>>>> On 11/21/2011 2:15 PM, David Harrigan wrote:
>>>>> Hi Everyone,
>>>>>
>>>>> I'm learning about the fork and join framework in JDK7 and to test it
>>>>> out I wrote a little program that tries to find a number at the 
>>>>> end of
>>>>> a list with 50,000 elements.
>>>>> What puzzles me is when I run the "find" in a sequential fashion, it
>>>>> returns faster than if I use a fork-and-join implementation. I'm
>>>>> running each "find" 5000 times
>>>>> so as to "warm" up the JVM. I've got a timing listed below:
>>>>>
>>>>> Generating some data...done!
>>>>> Sequential
>>>>> Simon Stopwatch: total 1015 s, counter 5000, max 292 ms, min 195 ms,
>>>>> mean 203 ms [sequential INHERIT]
>>>>> Parallel
>>>>> Simon Stopwatch: total 1352 s, counter 5000, max 4.70 s, min 243 ms,
>>>>> mean 270 ms [parallel INHERIT]
>>>>>
>>>>> (some runtime information)
>>>>>
>>>>> openjdk version "1.7.0-ea"
>>>>> OpenJDK Runtime Environment (build 1.7.0-ea-b215)
>>>>> OpenJDK 64-Bit Server VM (build 21.0-b17, mixed mode)
>>>>>
>>>>> 2.66Mhz Intel Core i7 with 8GB RAM (256KB L2 cache per core (4 cores)
>>>>> and 4MB L3 cache) running on a MBP (Lion 10.7.2)
>>>>>
>>>>> Forgive my ignorance but this type of programming is still quite new
>>>>> to me and I'm obviously doing something wrong, but I don't know what.
>>>>> My suspicion is
>>>>> something to do with spinning up and down threads and the overhead
>>>>> that entails. I've posted the src herehttp://pastebin.com/p96R24R0.
>>>>>
>>>>> My sincere apologies if this list is not appropriate for this 
>>>>> posting,
>>>>> if so I would welcome a pointer on where I can find more information
>>>>> to help me understand
>>>>> better the behaviour of my program when using F&J.
>>>>>
>>>>> I thought that by using F&J I would be able to find the answer 
>>>>> quicker
>>>>> than doing the searching sequentially, perhaps I've choosen a wrong
>>>>> initial problem to
>>>>> test this out (something that is suited to a sequential search and 
>>>>> not
>>>>> a parallel search?)
>>>>>
>>>>> Thank you all in advance.
>>>>>
>>>>> -=david=-
>>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/1e11ba79/attachment.html>

From nathan.reynolds at oracle.com  Tue Nov 22 12:28:41 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 22 Nov 2011 10:28:41 -0700
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECBD3FA.6050804@cytetech.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<4ECBD3FA.6050804@cytetech.com>
Message-ID: <4ECBDBC9.9040303@oracle.com>

Some STM implementations buffer the I/O in a transaction.  At a safe 
point in the commit, the buffers are flushed.  The same thing might be 
possible with one-way operations albeit a lock might be necessary.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/22/2011 9:55 AM, Gregg Wonderly wrote:
> On 11/22/2011 10:41 AM, Andrew Haley wrote:
>> On 11/21/2011 10:03 PM, R?mi Forax wrote:
>>> On 11/21/2011 08:04 PM, Guy Korland wrote:
>>>> Not all the issues are solved, but it seems like most of the issues
>>>> have good answers.
>>>> Also, notice that in .NET they have issues which Java doesn't have
>>>> like Native code and pointers in C++.
>>>
>>> And how do you solve the IO problems (when you retry) ?
>>
>> There are basically two practical approaches to I/O:
>>
>> 1.  Don't do I/O in a transaction.
>>
>> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
>> that uses a single global lock.
>
> I think it's better to say "one way operations", instead of I/O.  
> Basically it's pointless to attempt to use transactional behavior on a 
> one way operation, unless it can not fail, in which case, you actually 
> do something like
>
> try {
>    xxx.commit();
>    doOneWayStuff();
> } catch( ) {
>
> }
>
> so that you do it to create the atomic view, but you have to be able 
> to guarantee ACID and completion.
>
> Gregg
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/19e64046/attachment-0001.html>

From gkorland at gmail.com  Tue Nov 22 12:30:43 2011
From: gkorland at gmail.com (Guy Korland)
Date: Tue, 22 Nov 2011 19:30:43 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
Message-ID: <CAMaz81KTCW=FcssBXVJJBzf71Qex7o5QOoLbA8qGV1N3Qd7T9w@mail.gmail.com>

What do you mean by you can't detect I/O? You can detect I/O also when
calling external libraries.

Guy

Date: Tue, 22 Nov 2011 17:50:06 +0100
From: ?iktor ?lang <viktor.klang at gmail.com>
To: Andrew Haley <aph at redhat.com>
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
       what about Java?
Message-ID:
       <CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:

> On 11/21/2011 10:03 PM, R?mi Forax wrote:
> > On 11/21/2011 08:04 PM, Guy Korland wrote:
> >> Not all the issues are solved, but it seems like most of the issues
> >> have good answers.
> >> Also, notice that in .NET they have issues which Java doesn't have
> >> like Native code and pointers in C++.
> >
> > And how do you solve the IO problems (when you retry) ?
>
> There are basically two practical approaches to I/O:
>
> 1.  Don't do I/O in a transaction.
>
> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
> that uses a single global lock.
>

Problem is that you can't reliably detect IO, so that makes any call to a
3rd party jar a can of worms.
Also, you cannot reliably detect blocking or non-termination, which makes
this global lock the Devil(tm)

Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/ffedc599/attachment.html>

From heinz at javaspecialists.eu  Tue Nov 22 12:42:08 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 22 Nov 2011 19:42:08 +0200
Subject: [concurrency-interest] A beginner question (on fork-and-join)
In-Reply-To: <4ECBDADB.7020404@oracle.com>
References: <CAKdGheOiB8oqhNav8GNV-ni-sYthYnPwPBaw8Kvctq=ucL_+xQ@mail.gmail.com>	<4ECAC554.1060604@oracle.com>
	<4ECAD264.2080503@cytetech.com>	<4ECADEBC.8010900@oracle.com>
	<4ECBD348.5090400@cytetech.com> <4ECBDADB.7020404@oracle.com>
Message-ID: <4ECBDEF0.60307@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/62e11a43/attachment-0001.html>

From aph at redhat.com  Tue Nov 22 13:11:17 2011
From: aph at redhat.com (Andrew Haley)
Date: Tue, 22 Nov 2011 18:11:17 +0000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <4ECBC617.3070201@oracle.com>
References: <4ECBB464.8070000@redhat.com> <4ECBC617.3070201@oracle.com>
Message-ID: <4ECBE5C5.4020006@redhat.com>

OK, I see.  So, the only place you'd need this is in the cpu-specific
code, and all the cpu-specific code is on arches that don't need
StoreStore.

Thanks,

Andrew.

On 11/22/2011 03:56 PM, Nathan Reynolds wrote:
> On x86 and Sparc TSO, the StoreStore barrier becomes a no-op.  (See the 
> table in the Multiprocessors section.)  These processors will not allow 
> stores to go before other stores.  Thus, the StoreStore barrier is 
> already enforced for all store operations by the processor.  The only 
> barrier required on x86 and Sparc TSO is the StoreLoad barrier.
> 
> Nathan Reynolds 
> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
> Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
> 
> On 11/22/2011 7:40 AM, Andrew Haley wrote:
>> A little mystery:
>>
>> Inserting Barriers
>> ...
>>
>>     2. Issue a StoreStore barrier after all stores but before return
>>     from any constructor for any class with a final field.
>>
>> So, I'm looking for this barrier in the HotSpot code but I have been
>> unable to find it.  Can someone please put me out of my misery and
>> tell me where it is?

From viktor.klang at gmail.com  Tue Nov 22 13:32:26 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 22 Nov 2011 19:32:26 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECBD3FA.6050804@cytetech.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<4ECBD3FA.6050804@cytetech.com>
Message-ID: <CANPzfU8_3XioVpzyyjLYoy7=vyW21Tn5cohpibftFEqa27+A3g@mail.gmail.com>

On Tue, Nov 22, 2011 at 5:55 PM, Gregg Wonderly <gregg at cytetech.com> wrote:

> On 11/22/2011 10:41 AM, Andrew Haley wrote:
>
>> On 11/21/2011 10:03 PM, R?mi Forax wrote:
>>
>>> On 11/21/2011 08:04 PM, Guy Korland wrote:
>>>
>>>> Not all the issues are solved, but it seems like most of the issues
>>>> have good answers.
>>>> Also, notice that in .NET they have issues which Java doesn't have
>>>> like Native code and pointers in C++.
>>>>
>>>
>>> And how do you solve the IO problems (when you retry) ?
>>>
>>
>> There are basically two practical approaches to I/O:
>>
>> 1.  Don't do I/O in a transaction.
>>
>> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
>> that uses a single global lock.
>>
>
> I think it's better to say "one way operations", instead of I/O.
>  Basically it's pointless to attempt to use transactional behavior on a one
> way operation, unless it can not fail, in which case, you actually do
> something like
>
> try {
>   xxx.commit();
>   doOneWayStuff();
> } catch( ) {
>
> }
>

That does not compose, you need to be able to do deferred operations at
will.


>
> so that you do it to create the atomic view, but you have to be able to
> guarantee ACID and completion.
>
> Gregg
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/abe75573/attachment.html>

From viktor.klang at gmail.com  Tue Nov 22 13:33:30 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 22 Nov 2011 19:33:30 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81KTCW=FcssBXVJJBzf71Qex7o5QOoLbA8qGV1N3Qd7T9w@mail.gmail.com>
References: <CAMaz81KTCW=FcssBXVJJBzf71Qex7o5QOoLbA8qGV1N3Qd7T9w@mail.gmail.com>
Message-ID: <CANPzfU9z871a8tE-gkUSZ62+yodEbBrMKggw+H-tDSaBk7-ZBw@mail.gmail.com>

On Tue, Nov 22, 2011 at 6:30 PM, Guy Korland <gkorland at gmail.com> wrote:

> What do you mean by you can't detect I/O? You can detect I/O also when
> calling external libraries.
>

Perhaps I'm missing what level you were planning to add this.


>
> Guy
>
> Date: Tue, 22 Nov 2011 17:50:06 +0100
> From: ?iktor ?lang <viktor.klang at gmail.com>
> To: Andrew Haley <aph at redhat.com>
> Cc: concurrency-interest at cs.oswego.edu
>
> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>        what about Java?
> Message-ID:
>        <CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw at mail.gmail.com
> >
> Content-Type: text/plain; charset="utf-8"
>
> On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:
>
>
> > On 11/21/2011 10:03 PM, R?mi Forax wrote:
> > > On 11/21/2011 08:04 PM, Guy Korland wrote:
> > >> Not all the issues are solved, but it seems like most of the issues
> > >> have good answers.
> > >> Also, notice that in .NET they have issues which Java doesn't have
> > >> like Native code and pointers in C++.
> > >
> > > And how do you solve the IO problems (when you retry) ?
> >
> > There are basically two practical approaches to I/O:
> >
> > 1.  Don't do I/O in a transaction.
> >
> > 2.  Convert the transaction into a "relaxed" transaction, i.e. one
> > that uses a single global lock.
> >
>
> Problem is that you can't reliably detect IO, so that makes any call to a
> 3rd party jar a can of worms.
> Also, you cannot reliably detect blocking or non-termination, which makes
> this global lock the Devil(tm)
>
> Cheers,
> ?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/002245c1/attachment.html>

From gregg at cytetech.com  Tue Nov 22 16:50:46 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 22 Nov 2011 15:50:46 -0600
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CANPzfU8_3XioVpzyyjLYoy7=vyW21Tn5cohpibftFEqa27+A3g@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<4ECBD3FA.6050804@cytetech.com>
	<CANPzfU8_3XioVpzyyjLYoy7=vyW21Tn5cohpibftFEqa27+A3g@mail.gmail.com>
Message-ID: <4ECC1936.9030201@cytetech.com>

On 11/22/2011 12:32 PM, ?iktor ?lang wrote:
>
>
> On Tue, Nov 22, 2011 at 5:55 PM, Gregg Wonderly <gregg at cytetech.com
> <mailto:gregg at cytetech.com>> wrote:
>
>     On 11/22/2011 10:41 AM, Andrew Haley wrote:
>
>         On 11/21/2011 10:03 PM, R?mi Forax wrote:
>
>             On 11/21/2011 08:04 PM, Guy Korland wrote:
>
>                 Not all the issues are solved, but it seems like most of the issues
>                 have good answers.
>                 Also, notice that in .NET they have issues which Java doesn't have
>                 like Native code and pointers in C++.
>
>
>             And how do you solve the IO problems (when you retry) ?
>
>
>         There are basically two practical approaches to I/O:
>
>         1.  Don't do I/O in a transaction.
>
>         2.  Convert the transaction into a "relaxed" transaction, i.e. one
>         that uses a single global lock.
>
>
>     I think it's better to say "one way operations", instead of I/O.  Basically
>     it's pointless to attempt to use transactional behavior on a one way
>     operation, unless it can not fail, in which case, you actually do something like
>
>     try {
>        xxx.commit();
>        doOneWayStuff();
>     } catch( ) {
>
>     }
>
>
> That does not compose, you need to be able to do deferred operations at will.

Can you clarify this comment?

Gregg

From viktor.klang at gmail.com  Tue Nov 22 16:58:14 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 22 Nov 2011 22:58:14 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECC1936.9030201@cytetech.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<4ECBD3FA.6050804@cytetech.com>
	<CANPzfU8_3XioVpzyyjLYoy7=vyW21Tn5cohpibftFEqa27+A3g@mail.gmail.com>
	<4ECC1936.9030201@cytetech.com>
Message-ID: <CANPzfU_kaDG7KXwfqBHNv8JoFspjm6Df8kmRJzWC6B0SPM-mXA@mail.gmail.com>

2011/11/22 Gregg Wonderly <gregg at cytetech.com>

> On 11/22/2011 12:32 PM, ?iktor ?lang wrote:
>
>>
>>
>> On Tue, Nov 22, 2011 at 5:55 PM, Gregg Wonderly <gregg at cytetech.com
>> <mailto:gregg at cytetech.com>> wrote:
>>
>>    On 11/22/2011 10:41 AM, Andrew Haley wrote:
>>
>>        On 11/21/2011 10:03 PM, R?mi Forax wrote:
>>
>>            On 11/21/2011 08:04 PM, Guy Korland wrote:
>>
>>                Not all the issues are solved, but it seems like most of
>> the issues
>>                have good answers.
>>                Also, notice that in .NET they have issues which Java
>> doesn't have
>>                like Native code and pointers in C++.
>>
>>
>>            And how do you solve the IO problems (when you retry) ?
>>
>>
>>        There are basically two practical approaches to I/O:
>>
>>        1.  Don't do I/O in a transaction.
>>
>>        2.  Convert the transaction into a "relaxed" transaction, i.e. one
>>        that uses a single global lock.
>>
>>
>>    I think it's better to say "one way operations", instead of I/O.
>>  Basically
>>    it's pointless to attempt to use transactional behavior on a one way
>>    operation, unless it can not fail, in which case, you actually do
>> something like
>>
>>    try {
>>       xxx.commit();
>>       doOneWayStuff();
>>    } catch( ) {
>>
>>    }
>>
>>
>> That does not compose, you need to be able to do deferred operations at
>> will.
>>
>
> Can you clarify this comment?
>

methodA() {
  changeSomething
  changeSomethingElse
  sendEmailsToYourCustomers
}

methodB() {
  changeSomething
  changeSomethingAwesome
  drinkAShotOfJaeger
}

methodC() {
  How do I call methodA and methodB here...
  transaction.commit()
  ... and have their dangerous side effects only performed at-most-once here
}



>
> Gregg
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/f90bc515/attachment-0001.html>

From radhakrishnan.mohan at gmail.com  Tue Nov 22 22:58:25 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 23 Nov 2011 09:28:25 +0530
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <4EC65112.5080802@googlemail.com>
References: <CAOoXFP97+NEHaeBZ8VXmmv=08qnggV1XUo87YJLvO=nQyO6udQ@mail.gmail.com>
	<4EC65112.5080802@googlemail.com>
Message-ID: <CAOoXFP_r7A+4W+sY-5sWk2aMXnCkQNb1RaD3iAZ-bnta+LnSxA@mail.gmail.com>

Very useful. I also asked and found the intel manual on false sharing.
Now I can view this type of code using Oracle Studio analyzer because
the intel tools mentioned in the manual are expensive.

Thanks,
Mohan

2011/11/18 Holger Hoffst?tte <holger.hoffstaette at googlemail.com>:
> On 18.11.2011 12:24, Mohan Radhakrishnan wrote:
>> 2. Where do I read about cache lines , false sharing and why locations
>> have to be 4-words apart so that they don't fall in the same cache
>> line (Herlihy and shavit) ? Can I write a Java program to induce false
>> sharing ?
>
> Can't help with the Phaser question but false sharing is absolutely real
> and can be observed easily. Run the attached snippet and you will see the
> pretty serious effect that memory contention between threads can have. You
> might need to adjust the number of threads for your machine.
> Credits go to Martin Thompson, see blog URL in comments.
>
> On my old-ish Core2Duo laptop with slow bus & memory:
>
> --snip--
> Times in ns for 5000000 writes with 2 threads:
> plain ?: 1171084314
> plain ?: 1208625956
> plain ?: 1230311953
> padded : 140929085
> padded : 140683802
> padded : 141457922
> --snip--
>
> That's a difference in throughput by a factor of ~8, though the impact of
> course depends on the details of the CPU, caches, memory controller,
> memory system etc.
>
> -h
>


From gkorland at gmail.com  Wed Nov 23 01:08:13 2011
From: gkorland at gmail.com (Guy Korland)
Date: Wed, 23 Nov 2011 08:08:13 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
Message-ID: <CAMaz81JaK56wCR4pxhHL4iNLfYqBvB_67=8QmcKc4C6SkwYoEQ@mail.gmail.com>

I guess you should look as a reference at DeuceSTM (www.deucestm.org), what
we've done there is to instrument classes on load time.
This way we were able to support legacy libraries and not only the user
code.

Guy

Date: Tue, 22 Nov 2011 19:33:30 +0100
From: ?iktor ?lang <viktor.klang at gmail.com>
To: Guy Korland <gkorland at gmail.com>
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
       what about Java?
Message-ID:
       <CANPzfU9z871a8tE-gkUSZ62+yodEbBrMKggw+H-tDSaBk7-ZBw at mail.gmail.com>
Content-Type: text/plain; charset="iso-8859-1"

On Tue, Nov 22, 2011 at 6:30 PM, Guy Korland <gkorland at gmail.com> wrote:

> What do you mean by you can't detect I/O? You can detect I/O also when
> calling external libraries.
>

Perhaps I'm missing what level you were planning to add this.


>
> Guy
>
> Date: Tue, 22 Nov 2011 17:50:06 +0100
> From: ?iktor ?lang <viktor.klang at gmail.com>
> To: Andrew Haley <aph at redhat.com>
> Cc: concurrency-interest at cs.oswego.edu
>
> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>        what about Java?
> Message-ID:
>        <CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw at mail.gmail.com
> >
> Content-Type: text/plain; charset="utf-8"
>
> On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:
>
>
> > On 11/21/2011 10:03 PM, R?mi Forax wrote:
> > > On 11/21/2011 08:04 PM, Guy Korland wrote:
> > >> Not all the issues are solved, but it seems like most of the issues
> > >> have good answers.
> > >> Also, notice that in .NET they have issues which Java doesn't have
> > >> like Native code and pointers in C++.
> > >
> > > And how do you solve the IO problems (when you retry) ?
> >
> > There are basically two practical approaches to I/O:
> >
> > 1.  Don't do I/O in a transaction.
> >
> > 2.  Convert the transaction into a "relaxed" transaction, i.e. one
> > that uses a single global lock.
> >
>
> Problem is that you can't reliably detect IO, so that makes any call to a
> 3rd party jar a can of worms.
> Also, you cannot reliably detect blocking or non-termination, which makes
> this global lock the Devil(tm)
>
> Cheers,
> ?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


--
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111122/002245c1/attachment-0001.html
>

------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111123/ba97f179/attachment.html>

From dharrigan at gmail.com  Wed Nov 23 02:13:43 2011
From: dharrigan at gmail.com (David Harrigan)
Date: Wed, 23 Nov 2011 07:13:43 +0000
Subject: [concurrency-interest] JCIP Update?
Message-ID: <CAKdGheM_7Ss819nmt9K4hTk9APjFiU-MzEOsO655gXzs4OOrbg@mail.gmail.com>

Hi,

I was wondering if there are plans for a new edition of the Java
Concurrency in Practice book updated to include all the new features
that have made their way into
Java 7 (like Phasers and ForkAndJoin)? It would be really neat to see
an update to include idomatic usages of these libraries along with
updates of the older (but no
less important) libraries.

-=david=-

-- 
I prefer encrypted and signed messages. KeyID: B20A22F9
Fingerprint: 110A F423 3647 54E2 880F ADAD 1C52 85BF B20A 22F9

"It is not usually until you've built and used a version of the
program that you understand the issues well enough to get the design
right." - Rob Pike, Brian Kernighan.

No trees were harmed in the sending of this message, however, a number
of electrons were inconvenienced.

From aph at redhat.com  Wed Nov 23 06:54:34 2011
From: aph at redhat.com (Andrew Haley)
Date: Wed, 23 Nov 2011 11:54:34 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>	<4ECACAB3.3000001@univ-mlv.fr>	<4ECBD0A4.9010604@redhat.com>
	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>
Message-ID: <4ECCDEFA.708@redhat.com>

On 11/22/2011 04:50 PM, ?iktor ?lang wrote:
> On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:
> 
>> On 11/21/2011 10:03 PM, R?mi Forax wrote:
>>> On 11/21/2011 08:04 PM, Guy Korland wrote:
>>>> Not all the issues are solved, but it seems like most of the issues
>>>> have good answers.
>>>> Also, notice that in .NET they have issues which Java doesn't have
>>>> like Native code and pointers in C++.
>>>
>>> And how do you solve the IO problems (when you retry) ?
>>
>> There are basically two practical approaches to I/O:
>>
>> 1.  Don't do I/O in a transaction.
>>
>> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
>> that uses a single global lock.
> 
> Problem is that you can't reliably detect IO, so that makes any call to a
> 3rd party jar a can of worms.

No more than usual: if you don't know what a library might do, you're
taking a risk.  If you're not certain what a transaction might do, you
have to treat it as a relaxed transaction.

> Also, you cannot reliably detect blocking or non-termination, which makes
> this global lock the Devil(tm)

Well, yes.  Again, if you don't know what a library might do, you
shouldn't be calling it.  This is true regardless of whether you're
in a transaction.

Andrew.


From viktor.klang at gmail.com  Wed Nov 23 08:08:38 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 23 Nov 2011 14:08:38 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECCDEFA.708@redhat.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>
	<4ECCDEFA.708@redhat.com>
Message-ID: <CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>

2011/11/23 Andrew Haley <aph at redhat.com>

> On 11/22/2011 04:50 PM, ?iktor ?lang wrote:
> > On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:
> >
> >> On 11/21/2011 10:03 PM, R?mi Forax wrote:
> >>> On 11/21/2011 08:04 PM, Guy Korland wrote:
> >>>> Not all the issues are solved, but it seems like most of the issues
> >>>> have good answers.
> >>>> Also, notice that in .NET they have issues which Java doesn't have
> >>>> like Native code and pointers in C++.
> >>>
> >>> And how do you solve the IO problems (when you retry) ?
> >>
> >> There are basically two practical approaches to I/O:
> >>
> >> 1.  Don't do I/O in a transaction.
> >>
> >> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
> >> that uses a single global lock.
> >
> > Problem is that you can't reliably detect IO, so that makes any call to a
> > 3rd party jar a can of worms.
>
> No more than usual: if you don't know what a library might do, you're
> taking a risk.


You might have known it at the time of writing the code, but since then the
3rd party jar has been updated, now you're in trouble.


>  If you're not certain what a transaction might do, you
> have to treat it as a relaxed transaction.
>
> > Also, you cannot reliably detect blocking or non-termination, which makes
> > this global lock the Devil(tm)
>
> Well, yes.  Again, if you don't know what a library might do, you
> shouldn't be calling it.


You mean that you have full knowledge of the inner workings of all your 3rd
party (and stdlib for instance) dependencies?

Did you know that java.net.URL does a DNS resolve in .equals?


>  This is true regardless of whether you're
> in a transaction.
>

I'm just saying that making the transactions completely transparent without
managed references gives the impression that there is no worries to be had,
which is quite to the contrary.

I'm not trying to bash STM here, I think it's great for some concurrency
control problems like consensus.
In Akka we went the Clojure route with managed references and it's worked
out great.

Cheers,
?


> Andrew.
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111123/cb5e59be/attachment.html>

From gregg at cytetech.com  Wed Nov 23 10:14:15 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 23 Nov 2011 09:14:15 -0600
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CANPzfU_kaDG7KXwfqBHNv8JoFspjm6Df8kmRJzWC6B0SPM-mXA@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<4ECBD3FA.6050804@cytetech.com>
	<CANPzfU8_3XioVpzyyjLYoy7=vyW21Tn5cohpibftFEqa27+A3g@mail.gmail.com>
	<4ECC1936.9030201@cytetech.com>
	<CANPzfU_kaDG7KXwfqBHNv8JoFspjm6Df8kmRJzWC6B0SPM-mXA@mail.gmail.com>
Message-ID: <4ECD0DC7.20000@cytetech.com>

On 11/22/2011 3:58 PM, ?iktor ?lang wrote:
>
>
> 2011/11/22 Gregg Wonderly <gregg at cytetech.com <mailto:gregg at cytetech.com>>
>
>     On 11/22/2011 12:32 PM, ?iktor ?lang wrote:
>
>
>
>         On Tue, Nov 22, 2011 at 5:55 PM, Gregg Wonderly <gregg at cytetech.com
>         <mailto:gregg at cytetech.com>
>         <mailto:gregg at cytetech.com <mailto:gregg at cytetech.com>>> wrote:
>
>             On 11/22/2011 10:41 AM, Andrew Haley wrote:
>
>                 On 11/21/2011 10:03 PM, R?mi Forax wrote:
>
>                     On 11/21/2011 08:04 PM, Guy Korland wrote:
>
>                         Not all the issues are solved, but it seems like most of
>         the issues
>                         have good answers.
>                         Also, notice that in .NET they have issues which Java
>         doesn't have
>                         like Native code and pointers in C++.
>
>
>                     And how do you solve the IO problems (when you retry) ?
>
>
>                 There are basically two practical approaches to I/O:
>
>                 1.  Don't do I/O in a transaction.
>
>                 2.  Convert the transaction into a "relaxed" transaction, i.e. one
>                 that uses a single global lock.
>
>
>             I think it's better to say "one way operations", instead of I/O.
>           Basically
>             it's pointless to attempt to use transactional behavior on a one way
>             operation, unless it can not fail, in which case, you actually do
>         something like
>
>             try {
>                xxx.commit();
>                doOneWayStuff();
>             } catch( ) {
>
>             }
>
>
>         That does not compose, you need to be able to do deferred operations at
>         will.
>
>
>     Can you clarify this comment?
>
>
> methodA() {
>    changeSomething
>    changeSomethingElse
>    sendEmailsToYourCustomers
> }
>
> methodB() {
>    changeSomething
>    changeSomethingAwesome
>    drinkAShotOfJaeger
> }
>
> methodC() {
>    How do I call methodA and methodB here...
>    transaction.commit()
>    ... and have their dangerous side effects only performed at-most-once here
> }

Okay, this is what I was alluding to.  If you can't guarantee that a one way 
action will have ACID properties, then you pretty much can't provide 
transactional behavior in any "transactional operation" which includes that action.

At best, you can just hope.  For example, in my previously mentioned distributed 
data application, I didn't want the clients to hold up the completion of the 
transaction.  There "display" updates had to be "one way" and "non-interfering" 
in behavior, because I didn't really care if they "showed the right data" or not 
as a controlling behavior of the system.  So, client data updates are forwarded 
to the clients as the last step of the processing, as the final phase of the 
commit.  The failure of any one of those updates is ignored.

So, the part that I want to be transactional, is.  The part that I want to see 
the transactional state change, sees it.  If there are problems with creating 
the transactional state change, processing stops, and can be retried.  If there 
are problems where a client closes the window halfway through the update of 
state sent to them, the system doesn't care, and ignores that, because we don't 
care whether or not that they see the update.

Gregg Wonderly

From Joe.Kearney at gsacapital.com  Wed Nov 23 10:46:21 2011
From: Joe.Kearney at gsacapital.com (Kearney, Joe)
Date: Wed, 23 Nov 2011 15:46:21 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECD0DC7.20000@cytetech.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<4ECBD3FA.6050804@cytetech.com>
	<CANPzfU8_3XioVpzyyjLYoy7=vyW21Tn5cohpibftFEqa27+A3g@mail.gmail.com>
	<4ECC1936.9030201@cytetech.com>
	<CANPzfU_kaDG7KXwfqBHNv8JoFspjm6Df8kmRJzWC6B0SPM-mXA@mail.gmail.com>
	<4ECD0DC7.20000@cytetech.com>
Message-ID: <9319F360221C65428EA819A4E8DC34ED037921E5EA@OPMBOX21UK.options-it.com>

This is exactly the Spring model of transactions with *synchronizations*, that is, operations that *synchronize with* the transaction. This is modelled using nothing more than listeners that can be registered with the transaction. For example, beforeCommit() callbacks are fired before commit and can veto the transaction commit, afterCompletion() callbacks are fired after any commit/rollback completion and failure in these is ignored.

This is fine if we're ok with having no guarantee that those listeners will be notified, but doesn't help the case of calling outside code we control before we've called commit. That's still a very separate case, and it still has to be up to the client of the transaction API/construct/whatever to ensure that these potentially bad things don't happen in the body of the transaction.

Joe

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Gregg Wonderly
Sent: 23 November 2011 15:14
To: ?iktor ?lang
Cc: concurrency-interest at cs.oswego.edu; gregg.wonderly at pobox.com
Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0, what about Java?

On 11/22/2011 3:58 PM, ?iktor ?lang wrote:
>
>
> 2011/11/22 Gregg Wonderly <gregg at cytetech.com 
> <mailto:gregg at cytetech.com>>
>
>     On 11/22/2011 12:32 PM, ?iktor ?lang wrote:
>
>
>
>         On Tue, Nov 22, 2011 at 5:55 PM, Gregg Wonderly <gregg at cytetech.com
>         <mailto:gregg at cytetech.com>
>         <mailto:gregg at cytetech.com <mailto:gregg at cytetech.com>>> wrote:
>
>             On 11/22/2011 10:41 AM, Andrew Haley wrote:
>
>                 On 11/21/2011 10:03 PM, R?mi Forax wrote:
>
>                     On 11/21/2011 08:04 PM, Guy Korland wrote:
>
>                         Not all the issues are solved, but it seems like most of
>         the issues
>                         have good answers.
>                         Also, notice that in .NET they have issues which Java
>         doesn't have
>                         like Native code and pointers in C++.
>
>
>                     And how do you solve the IO problems (when you retry) ?
>
>
>                 There are basically two practical approaches to I/O:
>
>                 1.  Don't do I/O in a transaction.
>
>                 2.  Convert the transaction into a "relaxed" transaction, i.e. one
>                 that uses a single global lock.
>
>
>             I think it's better to say "one way operations", instead of I/O.
>           Basically
>             it's pointless to attempt to use transactional behavior on a one way
>             operation, unless it can not fail, in which case, you actually do
>         something like
>
>             try {
>                xxx.commit();
>                doOneWayStuff();
>             } catch( ) {
>
>             }
>
>
>         That does not compose, you need to be able to do deferred operations at
>         will.
>
>
>     Can you clarify this comment?
>
>
> methodA() {
>    changeSomething
>    changeSomethingElse
>    sendEmailsToYourCustomers
> }
>
> methodB() {
>    changeSomething
>    changeSomethingAwesome
>    drinkAShotOfJaeger
> }
>
> methodC() {
>    How do I call methodA and methodB here...
>    transaction.commit()
>    ... and have their dangerous side effects only performed 
> at-most-once here }

Okay, this is what I was alluding to.  If you can't guarantee that a one way action will have ACID properties, then you pretty much can't provide transactional behavior in any "transactional operation" which includes that action.

At best, you can just hope.  For example, in my previously mentioned distributed data application, I didn't want the clients to hold up the completion of the transaction.  There "display" updates had to be "one way" and "non-interfering" 
in behavior, because I didn't really care if they "showed the right data" or not as a controlling behavior of the system.  So, client data updates are forwarded to the clients as the last step of the processing, as the final phase of the commit.  The failure of any one of those updates is ignored.

So, the part that I want to be transactional, is.  The part that I want to see the transactional state change, sees it.  If there are problems with creating the transactional state change, processing stops, and can be retried.  If there are problems where a client closes the window halfway through the update of state sent to them, the system doesn't care, and ignores that, because we don't care whether or not that they see the update.

Gregg Wonderly
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Wed Nov 23 10:54:35 2011
From: aph at redhat.com (Andrew Haley)
Date: Wed, 23 Nov 2011 15:54:35 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>	<4ECACAB3.3000001@univ-mlv.fr>	<4ECBD0A4.9010604@redhat.com>	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>	<4ECCDEFA.708@redhat.com>
	<CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>
Message-ID: <4ECD173B.40609@redhat.com>

On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
> 2011/11/23 Andrew Haley <aph at redhat.com>
> 
>> On 11/22/2011 04:50 PM, ?iktor ?lang wrote:
>>> On Tue, Nov 22, 2011 at 5:41 PM, Andrew Haley <aph at redhat.com> wrote:
>>>
>>>> On 11/21/2011 10:03 PM, R?mi Forax wrote:
>>>>> On 11/21/2011 08:04 PM, Guy Korland wrote:
>>>>>> Not all the issues are solved, but it seems like most of the issues
>>>>>> have good answers.
>>>>>> Also, notice that in .NET they have issues which Java doesn't have
>>>>>> like Native code and pointers in C++.
>>>>>
>>>>> And how do you solve the IO problems (when you retry) ?
>>>>
>>>> There are basically two practical approaches to I/O:
>>>>
>>>> 1.  Don't do I/O in a transaction.
>>>>
>>>> 2.  Convert the transaction into a "relaxed" transaction, i.e. one
>>>> that uses a single global lock.
>>>
>>> Problem is that you can't reliably detect IO, so that makes any
>>> call to a 3rd party jar a can of worms.
>>
>> No more than usual: if you don't know what a library might do, you're
>> taking a risk.
> 
> You might have known it at the time of writing the code, but since then the
> 3rd party jar has been updated, now you're in trouble.
> 
>>  If you're not certain what a transaction might do, you
>> have to treat it as a relaxed transaction.
>>
>>> Also, you cannot reliably detect blocking or non-termination, which makes
>>> this global lock the Devil(tm)
>>
>> Well, yes.  Again, if you don't know what a library might do, you
>> shouldn't be calling it.
> 
> You mean that you have full knowledge of the inner workings of all your 3rd
> party (and stdlib for instance) dependencies?

No.  It simply means that if you're calling random code from within a
transaction you have to expect the worst, which in this case is a
relaxed transaction.

> I'm just saying that making the transactions completely transparent
> without managed references gives the impression that there is no
> worries to be had, which is quite to the contrary.

Whoever said that?  For STM to work well transactions should be small,
short-lived and not do I/O.  I think everyone here knows that, at
least.

> I'm not trying to bash STM here, I think it's great for some concurrency
> control problems like consensus.
> In Akka we went the Clojure route with managed references and it's worked
> out great.

Indeed, but with STM, as with so many other things, there's more than
one way to do it.  I don't really like relaxed transactions, but
they've been adopted into C++ for pretty good pragmatic reasons.

Andrew.

From benjamin.john.evans at gmail.com  Wed Nov 23 11:52:06 2011
From: benjamin.john.evans at gmail.com (Ben Evans)
Date: Wed, 23 Nov 2011 16:52:06 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <4ECD173B.40609@redhat.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>
	<4ECCDEFA.708@redhat.com>
	<CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>
	<4ECD173B.40609@redhat.com>
Message-ID: <CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>

2011/11/23 Andrew Haley <aph at redhat.com>:
> On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
>>
>> You mean that you have full knowledge of the inner workings of all your 3rd
>> party (and stdlib for instance) dependencies?
>
> No. ?It simply means that if you're calling random code from within a
> transaction you have to expect the worst, which in this case is a
> relaxed transaction.

[snip]

>> I'm just saying that making the transactions completely transparent
>> without managed references gives the impression that there is no
>> worries to be had, which is quite to the contrary.
>
> Whoever said that? ?For STM to work well transactions should be small,
> short-lived and not do I/O. ?I think everyone here knows that, at
> least.

This is exactly the crux of the problem. Everyone here knows that. We are
talking about new language level features, however. The target audience
for those is not "everyone here" - it is all 10 million (and rising) Java
developers.

Any new features have, in my opinion, three key tests to pass:

1) They must not be capable of producing "spooky action at a distance"
damage to an entire JVM process, even if used incorrectly by a novice
programmer

2) They must not interact badly with existing language features that are
already widely deployed in the wild. E.g. a new concurrency feature that
does not play nice with finalizers is one thing. Not playing nice with
Thread is quite another.

3) They must have a use case which is so compelling to a large subset
of Java developers, that the feature cries out to be included - so much so
that it's capable of overcoming a default position of not adding any
new features.

STM, in my view fails 1) and possibly 2) as well. We need to keep in
mind that we're producing features for a developer population that
includes quite a few whose attitude to concurrency is either: "Huh?" or,
if you're lucky: "Synchronize All The Things!!!"

Explaining the caveats around memory transactions to the overall dev
population is, in my view, neither an achievable nor desirable possibility.

Thanks,

Ben


From sergio.fernandes at ist.utl.pt  Wed Nov 23 12:10:48 2011
From: sergio.fernandes at ist.utl.pt (=?iso-8859-1?Q?S=E9rgio_Miguel_Fernandes?=)
Date: Wed, 23 Nov 2011 17:10:48 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
	what about Java?
In-Reply-To: <4ECD173B.40609@redhat.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>	<4ECACAB3.3000001@univ-mlv.fr>	<4ECBD0A4.9010604@redhat.com>	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>	<4ECCDEFA.708@redhat.com>
	<CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>
	<4ECD173B.40609@redhat.com>
Message-ID: <87F127C5-DF71-403B-A55C-0D3EDAB5A425@ist.utl.pt>

Hello All,

On 23 Nov 2011, at 15:54, Andrew Haley wrote:

> On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
>> 2011/11/23 Andrew Haley <aph at redhat.com>

>> I'm just saying that making the transactions completely transparent
>> without managed references gives the impression that there is no
>> worries to be had, which is quite to the contrary.
> 
> Whoever said that?  For STM to work well transactions should be small,
> short-lived and not do I/O.  I think everyone here knows that, at
> least.

In the context of this discussion I just wanted to let you know of the following email (previously posted to trans-memory at cs.wisc.edu):

On 7 Oct 2011, at 12:09, S?rgio Miguel Fernandes wrote:

> Dear All,
> 
> We will be presenting in SPLASH Wavefront 2011 a paper that describes our approach to use a Software Transactional Memory (JVSTM) to manage transactions in an enterprise application.
> 
> If you happen to be participating in SPLASH, feel free to come and talk to us about this.
> 
> Paper: 'Strict Serializability is Harmless: A New Architecture for Enterprise Applications'
> S?rgio Miguel Fernandes and Jo?o Cachopo
> https://dspace.ist.utl.pt/bitstream/2295/1015911/2/wafr07-fernandesps.pdf


This STM has been operating daily since 2006 in a real-world object-oriented enterprise application managing not-so-small transactions (some of them read over 1 million memory locations) with more than acceptable performance vs. the previous more-traditional approach that used an ORM and database-managed transactions.

-- 
S?rgio Miguel Fernandes
Instituto Superior T?cnico
Technical university of Lisbon






From viktor.klang at gmail.com  Wed Nov 23 12:16:18 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 23 Nov 2011 18:16:18 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>
	<4ECCDEFA.708@redhat.com>
	<CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>
	<4ECD173B.40609@redhat.com>
	<CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>
Message-ID: <CANPzfU_sda37bk6bbpZabW0oGEj5Da8VymvO9GryW+EnsbtZYA@mail.gmail.com>

On Wed, Nov 23, 2011 at 5:52 PM, Ben Evans <benjamin.john.evans at gmail.com>wrote:

> 2011/11/23 Andrew Haley <aph at redhat.com>:
> > On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
> >>
> >> You mean that you have full knowledge of the inner workings of all your
> 3rd
> >> party (and stdlib for instance) dependencies?
> >
> > No.  It simply means that if you're calling random code from within a
> > transaction you have to expect the worst, which in this case is a
> > relaxed transaction.
>
> [snip]
>
> >> I'm just saying that making the transactions completely transparent
> >> without managed references gives the impression that there is no
> >> worries to be had, which is quite to the contrary.
> >
> > Whoever said that?  For STM to work well transactions should be small,
> > short-lived and not do I/O.  I think everyone here knows that, at
> > least.
>
> This is exactly the crux of the problem. Everyone here knows that. We are
> talking about new language level features, however. The target audience
> for those is not "everyone here" - it is all 10 million (and rising) Java
> developers.
>
> Any new features have, in my opinion, three key tests to pass:
>
> 1) They must not be capable of producing "spooky action at a distance"
> damage to an entire JVM process, even if used incorrectly by a novice
> programmer
>
> 2) They must not interact badly with existing language features that are
> already widely deployed in the wild. E.g. a new concurrency feature that
> does not play nice with finalizers is one thing. Not playing nice with
> Thread is quite another.
>
> 3) They must have a use case which is so compelling to a large subset
> of Java developers, that the feature cries out to be included - so much so
> that it's capable of overcoming a default position of not adding any
> new features.
>
> STM, in my view fails 1) and possibly 2) as well. We need to keep in
> mind that we're producing features for a developer population that
> includes quite a few whose attitude to concurrency is either: "Huh?" or,
> if you're lucky: "Synchronize All The Things!!!"
>
> Explaining the caveats around memory transactions to the overall dev
> population is, in my view, neither an achievable nor desirable possibility.
>

+1

Also, what does language integration buy over the library support that
already exists out there for STMs on the JVM?



>
> Thanks,
>
> Ben
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111123/ae3cfa2c/attachment.html>

From concurrency-interest at stefan-marr.de  Wed Nov 23 12:19:05 2011
From: concurrency-interest at stefan-marr.de (Stefan Marr)
Date: Wed, 23 Nov 2011 18:19:05 +0100
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
	what about Java?
In-Reply-To: <CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>
	<4ECACAB3.3000001@univ-mlv.fr> <4ECBD0A4.9010604@redhat.com>
	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>
	<4ECCDEFA.708@redhat.com>
	<CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>
	<4ECD173B.40609@redhat.com>
	<CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>
Message-ID: <5321572E-6CA5-4709-AACC-121FBEC10B84@stefan-marr.de>


On 23 Nov 2011, at 17:52, Ben Evans wrote:

>> Whoever said that?  For STM to work well transactions should be small,
>> short-lived and not do I/O.  I think everyone here knows that, at
>> least.
> 
> 3) They must have a use case which is so compelling to a large subset
> of Java developers, that the feature cries out to be included - so much so
> that it's capable of overcoming a default position of not adding any
> new features.

Our experience from teaching with Clojure's STM is that the I/O problem leads to a situation where STM is not really of help.

The hard part is still the same as with locking: defining what are the atomic steps and then properly handling the potential data races between the steps.

If you do it like Clojure, excluding I/O from transactions, the hard problems are still all over the place.

You might get some additional parallelism out of the system for 'free', but the conceptual problems the programmer has to solve shift only slightly.

Best regards
Stefan

-- 
Stefan Marr
Software Languages Lab
Vrije Universiteit Brussel
Pleinlaan 2 / B-1050 Brussels / Belgium
http://soft.vub.ac.be/~smarr
Phone: +32 2 629 2974
Fax:   +32 2 629 3525



From aph at redhat.com  Wed Nov 23 12:53:31 2011
From: aph at redhat.com (Andrew Haley)
Date: Wed, 23 Nov 2011 17:53:31 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>
References: <CAMaz81+e6A7wVBObOWCUUX6_NvpF-o1tNQZXQOy3qiZXL8E-fg@mail.gmail.com>	<4ECACAB3.3000001@univ-mlv.fr>	<4ECBD0A4.9010604@redhat.com>	<CANPzfU9VXNsjARFS9byt2DVSVLER3pWr2e3UsPktjA_1tapjuw@mail.gmail.com>	<4ECCDEFA.708@redhat.com>	<CANPzfU_fZAiZmFS=0JJDRTBXDZ-Nbesx-AnaQJdZcSF3J0y8DQ@mail.gmail.com>	<4ECD173B.40609@redhat.com>
	<CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ@mail.gmail.com>
Message-ID: <4ECD331B.4010800@redhat.com>

On 11/23/2011 04:52 PM, Ben Evans wrote:
> 2011/11/23 Andrew Haley <aph at redhat.com>:
>> On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
>>>
>>> You mean that you have full knowledge of the inner workings of all your 3rd
>>> party (and stdlib for instance) dependencies?
>>
>> No.  It simply means that if you're calling random code from within a
>> transaction you have to expect the worst, which in this case is a
>> relaxed transaction.
> 
> [snip]
> 
>>> I'm just saying that making the transactions completely transparent
>>> without managed references gives the impression that there is no
>>> worries to be had, which is quite to the contrary.
>>
>> Whoever said that?  For STM to work well transactions should be small,
>> short-lived and not do I/O.  I think everyone here knows that, at
>> least.
> 
> This is exactly the crux of the problem. Everyone here knows that. We are
> talking about new language level features, however. The target audience
> for those is not "everyone here" - it is all 10 million (and rising) Java
> developers.
> 
> Any new features have, in my opinion, three key tests to pass:
> 
> 1) They must not be capable of producing "spooky action at a distance"
> damage to an entire JVM process, even if used incorrectly by a novice
> programmer

Please, let's not have "what about the average programmer?", or I'll
be forced to quote Dijkstra's "What about the average mathematician?"
:-)  The problems we have to solve are hard, and we need the best tools
we can get.

> 2) They must not interact badly with existing language features that are
> already widely deployed in the wild. E.g. a new concurrency feature that
> does not play nice with finalizers is one thing. Not playing nice with
> Thread is quite another.
> 
> 3) They must have a use case which is so compelling to a large subset
> of Java developers, that the feature cries out to be included - so much so
> that it's capable of overcoming a default position of not adding any
> new features.
> 
> STM, in my view fails 1) and possibly 2) as well.

I hear you, but the other side of the coin is, per Herlihy and Shavit:

* Locks are hard to manage effectively, especially in large systems.

* Atomic primitives like compareAndSet operate only on one word at at
  time, leading to complex algorithms.

* It is difficult to compose multiple calls to multiple objects into
  atomic units.

> Explaining the caveats around memory transactions to the overall dev
> population is, in my view, neither an achievable nor desirable
> possibility.

If the overall dev population isn't capable of understanding memory
transactions it's certain that it's not capable of handling complex
systems with other tools either.  Herlihy and Shavit again: "No-one
really known how to organize and maintain large systems that rely on
locking."  This includes the population of Java programmers out there,
but they're doing the best they can.

It's going to be very interesting to see how C++ transactions are
received by the community.

Andrew.

From gkorland at gmail.com  Wed Nov 23 13:56:25 2011
From: gkorland at gmail.com (Guy Korland)
Date: Wed, 23 Nov 2011 20:56:25 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
Message-ID: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>

>Explaining the caveats around memory transactions to the overall dev
>population is, in my view, neither an achievable nor desirable possibility.
Don't you think that explaining the curt JMM, Synchronized, Lock semantics
and etc. is more difficult.
I saw concurrency experts which stood with puzzled eyes when they tried to
explain the result of a concurrent run or even were wrong when asked.
The STM with all its performance limitation and I/O issues is much more
clear to the average user than the current JMM.

On Wed, Nov 23, 2011 at 7:00 PM, <concurrency-interest-request at cs.oswego.edu
> wrote:

> Date: Wed, 23 Nov 2011 16:52:06 +0000
> From: Ben Evans <benjamin.john.evans at gmail.com>
> To: Andrew Haley <aph at redhat.com>
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>        what about Java?
> Message-ID:
>        <CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ at mail.gmail.com
> >
> Content-Type: text/plain; charset=UTF-8
>
> 2011/11/23 Andrew Haley <aph at redhat.com>:
> > On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
> >>
> >> You mean that you have full knowledge of the inner workings of all your
> 3rd
> >> party (and stdlib for instance) dependencies?
> >
> > No. ?It simply means that if you're calling random code from within a
> > transaction you have to expect the worst, which in this case is a
> > relaxed transaction.
>
> [snip]
>
> >> I'm just saying that making the transactions completely transparent
> >> without managed references gives the impression that there is no
> >> worries to be had, which is quite to the contrary.
> >
> > Whoever said that? ?For STM to work well transactions should be small,
> > short-lived and not do I/O. ?I think everyone here knows that, at
> > least.
>
> This is exactly the crux of the problem. Everyone here knows that. We are
> talking about new language level features, however. The target audience
> for those is not "everyone here" - it is all 10 million (and rising) Java
> developers.
>
> Any new features have, in my opinion, three key tests to pass:
>
> 1) They must not be capable of producing "spooky action at a distance"
> damage to an entire JVM process, even if used incorrectly by a novice
> programmer
>
> 2) They must not interact badly with existing language features that are
> already widely deployed in the wild. E.g. a new concurrency feature that
> does not play nice with finalizers is one thing. Not playing nice with
> Thread is quite another.
>
> 3) They must have a use case which is so compelling to a large subset
> of Java developers, that the feature cries out to be included - so much so
> that it's capable of overcoming a default position of not adding any
> new features.
>
> STM, in my view fails 1) and possibly 2) as well. We need to keep in
> mind that we're producing features for a developer population that
> includes quite a few whose attitude to concurrency is either: "Huh?" or,
> if you're lucky: "Synchronize All The Things!!!"
>
> Explaining the caveats around memory transactions to the overall dev
> population is, in my view, neither an achievable nor desirable possibility.
>
> Thanks,
>
> Ben
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111123/f790cdff/attachment-0001.html>

From dan.berindei at gmail.com  Wed Nov 23 14:36:37 2011
From: dan.berindei at gmail.com (Dan Berindei)
Date: Wed, 23 Nov 2011 21:36:37 +0200
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>
References: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>
Message-ID: <CA+nfvwQqhUGAyL8RGnMVZfTgYmcEouq8pTFJ78DPRNhd5vB4vA@mail.gmail.com>

On Wed, Nov 23, 2011 at 8:56 PM, Guy Korland <gkorland at gmail.com> wrote:
>>Explaining the caveats around memory transactions to the overall dev
>>population is, in my view, neither an achievable nor desirable possibility.
> Don't you think that explaining the curt JMM, Synchronized, Lock semantics
> and etc. is more difficult.
> I saw concurrency experts which stood with?puzzled?eyes when they tried to
> explain the result of a concurrent run or even were wrong when asked.
> The STM with all its performance limitation and I/O issues is much more
> clear to the average user than the current JMM.

What happens when I add a logger.debug("bla") statement at the
beginning of a transaction?
Is that easier to explain then what happens when I add a
logger.debug("bla") statement in a synchronized block?

> On Wed, Nov 23, 2011 at 7:00 PM,
> <concurrency-interest-request at cs.oswego.edu> wrote:
>>
>> Date: Wed, 23 Nov 2011 16:52:06 +0000
>> From: Ben Evans <benjamin.john.evans at gmail.com>
>> To: Andrew Haley <aph at redhat.com>
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
>> ? ? ? ?what about Java?
>> Message-ID:
>>
>> ?<CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ at mail.gmail.com>
>> Content-Type: text/plain; charset=UTF-8
>>
>> 2011/11/23 Andrew Haley <aph at redhat.com>:
>> > On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
>> >>
>> >> You mean that you have full knowledge of the inner workings of all your
>> >> 3rd
>> >> party (and stdlib for instance) dependencies?
>> >
>> > No. ?It simply means that if you're calling random code from within a
>> > transaction you have to expect the worst, which in this case is a
>> > relaxed transaction.
>>
>> [snip]
>>
>> >> I'm just saying that making the transactions completely transparent
>> >> without managed references gives the impression that there is no
>> >> worries to be had, which is quite to the contrary.
>> >
>> > Whoever said that? ?For STM to work well transactions should be small,
>> > short-lived and not do I/O. ?I think everyone here knows that, at
>> > least.
>>
>> This is exactly the crux of the problem. Everyone here knows that. We are
>> talking about new language level features, however. The target audience
>> for those is not "everyone here" - it is all 10 million (and rising) Java
>> developers.
>>
>> Any new features have, in my opinion, three key tests to pass:
>>
>> 1) They must not be capable of producing "spooky action at a distance"
>> damage to an entire JVM process, even if used incorrectly by a novice
>> programmer
>>
>> 2) They must not interact badly with existing language features that are
>> already widely deployed in the wild. E.g. a new concurrency feature that
>> does not play nice with finalizers is one thing. Not playing nice with
>> Thread is quite another.
>>
>> 3) They must have a use case which is so compelling to a large subset
>> of Java developers, that the feature cries out to be included - so much so
>> that it's capable of overcoming a default position of not adding any
>> new features.
>>
>> STM, in my view fails 1) and possibly 2) as well. We need to keep in
>> mind that we're producing features for a developer population that
>> includes quite a few whose attitude to concurrency is either: "Huh?" or,
>> if you're lucky: "Synchronize All The Things!!!"
>>
>> Explaining the caveats around memory transactions to the overall dev
>> population is, in my view, neither an achievable nor desirable
>> possibility.
>>
>> Thanks,
>>
>> Ben
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From hans.boehm at hp.com  Wed Nov 23 15:00:04 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 23 Nov 2011 20:00:04 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>
References: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CB510@G4W3299.americas.hpqcorp.net>

From: Guy Korland

> >Explaining the caveats around memory transactions to the overall dev
> >population is, in my view, neither an achievable nor desirable possibility.
> Don't you think that explaining the curt JMM, Synchronized, Lock semantics and etc. is more difficult.
> I saw concurrency experts which stood with?puzzled?eyes when they tried to explain the result of a concurrent run or even were wrong > when asked.
> The STM with all its performance limitation and I/O issues is much more clear to the average user than the current JMM.

Although I agree with the conclusion, I think we're comparing things here that are completely orthogonal and incomparable.

The Java memory model does have a simple core, which I think is as easy to explain as concurrent programming ever is.  If you write programs without data races, you get sequential consistency.  And you can decide whether your program has a data race without understanding any memory consistency issues beyond sequential consistency.  And this doesn't depend on whether you have locks or C++-style STM.  The difficulty with the Java memory model is that we can't quite get away with ignoring data races, for a variety of reasons, stemming in large part from Java's security model and legacy issues.  But none of those are likely to apply to code written by beginners.

I do think that the C++ approach to STM that we've been discussing here, at least as I view it, significantly simplifies the programming model.  The presence of relaxed transactions essentially allows you to program as though you had a single lock, avoiding deadlock, while potentially preserving significantly more concurrency than an implementation that actually used a single lock for all transactions.  Arbitrary code in transactions, including I/O, works correctly (if by "correctly" you mean single global lock semantics, as you should :-) ), though potentially slowly.  I think that's fundamentally a very good thing, especially for less experienced programmers.  However, I also think that verdicts on a lot of the details here are still out.

Hans


From davidcholmes at aapt.net.au  Wed Nov 23 17:30:22 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 24 Nov 2011 08:30:22 +1000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
	what about Java?
In-Reply-To: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEIBJBAA.davidcholmes@aapt.net.au>

Let's not compare apples with fruit baskets here. The complete package of
multi-threaded concurrent programming is indeed complex. But the simple
transactional model really only matches to the basic need for mutual
exclusion. Afterall the logical/conceptual model of STM is "one giant
lock" - if you couldn't code it using synchronized(theLock) then you won't
be able to code it using the simple transactional model. STMs have to add
back complexity to deal with the other synchronization issues in concurrent
programming and that impacts on the simplicity of the model.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Guy Korland
  Sent: Thursday, 24 November 2011 4:56 AM
  To: Ben Evans; Andrew Haley
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
what about Java?


  >Explaining the caveats around memory transactions to the overall dev
  >population is, in my view, neither an achievable nor desirable
possibility.
  Don't you think that explaining the curt JMM, Synchronized, Lock semantics
and etc. is more difficult.
  I saw concurrency experts which stood with puzzled eyes when they tried to
explain the result of a concurrent run or even were wrong when asked.
  The STM with all its performance limitation and I/O issues is much more
clear to the average user than the current JMM.


  On Wed, Nov 23, 2011 at 7:00 PM,
<concurrency-interest-request at cs.oswego.edu> wrote:

    Date: Wed, 23 Nov 2011 16:52:06 +0000
    From: Ben Evans <benjamin.john.evans at gmail.com>
    To: Andrew Haley <aph at redhat.com>
    Cc: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] Transactional memory on GCC 4.7.0,
           what about Java?
    Message-ID:
           <CABKW8Rhtz3NkrgqyjwOWCHd4f-qmC_aKDRPjO5LFw5iYUA-GMQ at mail.gmail.c
om>
    Content-Type: text/plain; charset=UTF-8

    2011/11/23 Andrew Haley <aph at redhat.com>:
    > On 11/23/2011 01:08 PM, ?iktor ?lang wrote:
    >>
    >> You mean that you have full knowledge of the inner workings of all
your 3rd
    >> party (and stdlib for instance) dependencies?
    >
    > No. ?It simply means that if you're calling random code from within a
    > transaction you have to expect the worst, which in this case is a
    > relaxed transaction.

    [snip]

    >> I'm just saying that making the transactions completely transparent
    >> without managed references gives the impression that there is no
    >> worries to be had, which is quite to the contrary.
    >
    > Whoever said that? ?For STM to work well transactions should be small,
    > short-lived and not do I/O. ?I think everyone here knows that, at
    > least.

    This is exactly the crux of the problem. Everyone here knows that. We
are
    talking about new language level features, however. The target audience
    for those is not "everyone here" - it is all 10 million (and rising)
Java
    developers.

    Any new features have, in my opinion, three key tests to pass:

    1) They must not be capable of producing "spooky action at a distance"
    damage to an entire JVM process, even if used incorrectly by a novice
    programmer

    2) They must not interact badly with existing language features that are
    already widely deployed in the wild. E.g. a new concurrency feature that
    does not play nice with finalizers is one thing. Not playing nice with
    Thread is quite another.

    3) They must have a use case which is so compelling to a large subset
    of Java developers, that the feature cries out to be included - so much
so
    that it's capable of overcoming a default position of not adding any
    new features.

    STM, in my view fails 1) and possibly 2) as well. We need to keep in
    mind that we're producing features for a developer population that
    includes quite a few whose attitude to concurrency is either: "Huh?" or,
    if you're lucky: "Synchronize All The Things!!!"

    Explaining the caveats around memory transactions to the overall dev
    population is, in my view, neither an achievable nor desirable
possibility.

    Thanks,

    Ben

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111124/f2cfcdd2/attachment.html>

From aph at redhat.com  Thu Nov 24 06:10:38 2011
From: aph at redhat.com (Andrew Haley)
Date: Thu, 24 Nov 2011 11:10:38 +0000
Subject: [concurrency-interest] Transactional memory on GCC 4.7.0,
 what about Java?
In-Reply-To: <CA+nfvwQqhUGAyL8RGnMVZfTgYmcEouq8pTFJ78DPRNhd5vB4vA@mail.gmail.com>
References: <CAMaz81LyVkSOkqh5+pFeGjhihf+eUX5SHXzMs4BPP=EM-mkawQ@mail.gmail.com>
	<CA+nfvwQqhUGAyL8RGnMVZfTgYmcEouq8pTFJ78DPRNhd5vB4vA@mail.gmail.com>
Message-ID: <4ECE262E.2020400@redhat.com>

On 11/23/2011 07:36 PM, Dan Berindei wrote:
> What happens when I add a logger.debug("bla") statement at the
> beginning of a transaction?

That depends on your transactional model.  If you use the C++ model
you'll get a relaxed transaction, and everything will work as you
expect.

> Is that easier to explain then what happens when I add a
> logger.debug("bla") statement in a synchronized block?

I think so.  But it's much better to educate people to keep
their atomic blocks short.

Andrew.

From davidcholmes at aapt.net.au  Fri Nov 25 01:12:24 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 25 Nov 2011 16:12:24 +1000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <4ECBE5C5.4020006@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEIKJBAA.davidcholmes@aapt.net.au>

Andrew Haley writes:
> OK, I see.  So, the only place you'd need this is in the cpu-specific
> code, and all the cpu-specific code is on arches that don't need
> StoreStore.

Actually no.  The C2 code for this is in shared code. See
share/vm/opto/parse1.cpp

void Parse::do_exits() {
   ...

  if (wrote_final()) {
    // This method (which must be a constructor by the rules of Java)
    // wrote a final.  The effects of all initializations must be
    // committed to memory before any code after the constructor
    // publishes the reference to the newly constructor object.
    // Rather than wait for the publication, we simply block the
    // writes here.  Rather than put a barrier on only those writes
    // which are required to complete, we force all writes to complete.
    //
    // "All bets are off" unless the first publication occurs after a
    // normal return from the constructor.  We do not attempt to detect
    // such unusual early publications.  But no barrier is needed on
    // exceptional returns, since they cannot publish normally.
    //
    _exits.insert_mem_bar(Op_MemBarRelease);

As already stated the MembarRelease will be a noop on x86 and sparc.

My thanks to Paul Hohenszee for tracking this code down.

I'm still searching for the C1 and interpreter versions of this.

David Holmes
------------


> Thanks,
>
> Andrew.
>
> On 11/22/2011 03:56 PM, Nathan Reynolds wrote:
> > On x86 and Sparc TSO, the StoreStore barrier becomes a no-op.  (See the
> > table in the Multiprocessors section.)  These processors will not allow
> > stores to go before other stores.  Thus, the StoreStore barrier is
> > already enforced for all store operations by the processor.  The only
> > barrier required on x86 and Sparc TSO is the StoreLoad barrier.
> >
> > Nathan Reynolds
> > <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> > Consulting Member of Technical Staff | 602.333.9091
> > Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
> >
> > On 11/22/2011 7:40 AM, Andrew Haley wrote:
> >> A little mystery:
> >>
> >> Inserting Barriers
> >> ...
> >>
> >>     2. Issue a StoreStore barrier after all stores but before return
> >>     from any constructor for any class with a final field.
> >>
> >> So, I'm looking for this barrier in the HotSpot code but I have been
> >> unable to find it.  Can someone please put me out of my misery and
> >> tell me where it is?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From aph at redhat.com  Fri Nov 25 05:22:01 2011
From: aph at redhat.com (Andrew Haley)
Date: Fri, 25 Nov 2011 10:22:01 +0000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEIKJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEIKJBAA.davidcholmes@aapt.net.au>
Message-ID: <4ECF6C49.8010207@redhat.com>

On 11/25/2011 06:12 AM, David Holmes wrote:
> My thanks to Paul Hohenszee for tracking this code down.
> 
> I'm still searching for the C1 and interpreter versions of this.

Thanks indeed.  I'm thinking about Zero on ARM.

Andrew.



From radhakrishnan.mohan at gmail.com  Fri Nov 25 22:37:36 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Sat, 26 Nov 2011 09:07:36 +0530
Subject: [concurrency-interest] JCIP Update?
In-Reply-To: <CAKdGheM_7Ss819nmt9K4hTk9APjFiU-MzEOsO655gXzs4OOrbg@mail.gmail.com>
References: <CAKdGheM_7Ss819nmt9K4hTk9APjFiU-MzEOsO655gXzs4OOrbg@mail.gmail.com>
Message-ID: <CAOoXFP-RMpU_eVa40UVAPXKBX+sKb8uJLjnPYi_C2bjbp6x4kw@mail.gmail.com>

Hi,

         I think a book or more examples are required to get
programmers interested in these features. Many programmers we come
across have no idea how to use the API's with or without application
servers. Simpler examples are preferred to complex algorithm
implementations that are not generally used for commercial java
development.

Thanks,
Mohan

On Wed, Nov 23, 2011 at 12:43 PM, David Harrigan <dharrigan at gmail.com> wrote:
> Hi,
>
> I was wondering if there are plans for a new edition of the Java
> Concurrency in Practice book updated to include all the new features
> that have made their way into
> Java 7 (like Phasers and ForkAndJoin)? It would be really neat to see
> an update to include idomatic usages of these libraries along with
> updates of the older (but no
> less important) libraries.
>
> -=david=-
>
> --
> I prefer encrypted and signed messages. KeyID: B20A22F9
> Fingerprint: 110A F423 3647 54E2 880F ADAD 1C52 85BF B20A 22F9
>
> "It is not usually until you've built and used a version of the
> program that you understand the issues well enough to get the design
> right." - Rob Pike, Brian Kernighan.
>
> No trees were harmed in the sending of this message, however, a number
> of electrons were inconvenienced.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From hanson.char at gmail.com  Sat Nov 26 19:45:19 2011
From: hanson.char at gmail.com (Hanson Char)
Date: Sat, 26 Nov 2011 16:45:19 -0800
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F458@RAVEN.office.devexperts.com>
References: <CA+kOe08vPXvaU752ZqumW7E8W-27gekbeRvfoWzc_EJLwJ+f-g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDJBAA.davidcholmes@aapt.net.au>
	<CA+kOe09dSOksE-LBwuH9i_EFNK6MNQkPwnBjFa_iQCcsn-ciCw@mail.gmail.com>
	<4EC2B6AF.1070302@javaspecialists.eu>
	<CANPzfU9sfwLL4R9GPJ9RR3z8GjVSsj4sbcU12Y73zm7uc+US_g@mail.gmail.com>
	<4EC2BD8E.3010107@javaspecialists.eu>
	<CA+kOe09APSpDqC5kB5pNVU=jkRonx+r=dvEPADfx8fN-onV3Cg@mail.gmail.com>
	<4EC2D092.1020707@javaspecialists.eu>
	<CAOwENiKpp-J4cJbV3sqyT4EKCA3_OzZD0wwqV59S76YB6PmScQ@mail.gmail.com>
	<4EC2D53B.6040203@javaspecialists.eu>
	<CAOwENiKzDD-T-PKhp-PUiDqPi-YGCzyRB0zwzsRd8bXU1DzFsQ@mail.gmail.com>
	<4EC42D00.20003@javaspecialists.eu>
	<CA+kOe08UbmZ-triO=CY2VEL1dhYVqaMsfgRY=sTKLsZaUvQdrw@mail.gmail.com>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F3C3@RAVEN.office.devexperts.com>
	<4EC4E978.2080105@javaspecialists.eu>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80AC2F458@RAVEN.office.devexperts.com>
Message-ID: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>

Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
extremely valuable in face of legacy code that uses synchronized
block/method but the caller cannot afford to be "trapped" when calling
the legacy code even when it entered into a indefinitely blocking
state (within the synchronized block/method).

It would be really nice if the tryMonitor{Enter,Exit} can be promoted
into a normal and safe jdk class for general use, so we don't need to
use it in stealth mode.  Or maybe it already is in Java 7+ ?

Regards,
Hanson

On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov <elizarov at devexperts.com> wrote:
> Unfortunately, I had to use Unsafe myself from time to time just for
> performance reasons (because I have to write a lot of high-performance
> code).
>
>
>
> /Roman
>
>
>
> From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
> Sent: Thursday, November 17, 2011 3:01 PM
> To: Roman Elizarov
> Cc: Martin Buchholz; concurrency-interest
>
> Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
>
>
>
> My thoughts exactly, Roman.? Us mere mortals figure out the "how to" by
> reading JDK source code and when we see Unsafe being used, we go: "Ah, now
> that's a good class to use..." ;-)
>
> From my newsletter:? http://www.javaspecialists.eu/archive/Issue194.html
>
> "In a recent email, one of my youngest readers, 17 year old Mr S.Perlov from
> the Ukraine, suggested that I tell you about the class sun.misc.Unsafe. Up
> to now I have avoided writing about it, as it is a class that should be
> avoided. Here are two reasons: #1 it is "unsafe" and lets us do all the
> nasty things that we had in C, such as pointer arithmetic or modifying
> memory directly. #2 it is a sun.misc.* class. You do not know when that
> might be renamed to oracle.misc.Unsafe or whether you will even run your
> program on a Sun JVM. By binding yourself to a specific implementation of
> the JVM, you are limiting the application of your code.
>
> Two reasons to not use Unsafe. I have personally never used Unsafe in
> production code. Some experts do use it to write directly to memory.
> Dangerous stuff! "
>
> Regards
>
>
>
> Heinz
>
> --
>
> Dr Heinz M. Kabutz (PhD CompSci)
>
> Author of "The Java(tm) Specialists' Newsletter"
>
> Sun Java Champion
>
> IEEE Certified Software Development Professional
>
> http://www.javaspecialists.eu
>
> Tel: +30 69 72 850 460
>
> Skype: kabutz
>
> On 11/17/11 12:53 PM, Roman Elizarov wrote:
>
> The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
> programmer. Every day there are more and more blogs explaining advantages of
> Unsafe to the average programmer. I?ve just recently reposted one of those
> for the Russian programmers community.
>
>
>
> Are there any concrete plans (say for Java 8) to bring the performance of
> **Updater classes on par with Unsafe (maybe by improving HotSpot, so that it
> can eliminate all the extra checks and compile **Updater method into the
> same code as produced by direct use of Unsafe)? Shall we continue to rely on
> Unsafe for Java 8 and beyond or get ready for its eventual elimination from
> our codebase?
>
>
>
> Sincerely,
>
> Roman Elizarov
>
>
>
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin
> Buchholz
> Sent: Thursday, November 17, 2011 3:45 AM
> To: Dr Heinz M. Kabutz
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
>
>
>
>
>
> On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz <heinz at javaspecialists.eu>
> wrote:
>
> In Java 6, classes like ConcurrentLinkedQueue and SynchronousQueue used the
> AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>
> In Java 7, this was changed to instead use Unsafe.compareAndSwapObject()
> directly.
>
> The AtomicReferenceFieldUpdater does a bunch of error checking every time it
> is called, like this:
>
> ? ? ? ? ? if (obj == null || obj.getClass() != tclass || cclass != null ||
> ? ? ? ? ? ? ? (update != null && vclass != null &&
> ? ? ? ? ? ? ? ?vclass != update.getClass()))
> ? ? ? ? ? ? ? updateCheck(obj, update);
> ? ? ? ? ? return unsafe.compareAndSwapObject(obj, offset, expect, update);
>
> My thinking is that the programmers changing ConcurrentLinkedQueue et al
> probably wanted to improve the performance by not having to do all that
> checking every time it is called. ?The Unsafe.compareAndSwapObject() method
> is probably compiled to a single CPU instruction.
>
> Is that correct?
>
> Yes.
>
>
>
> Is there any other reason for this change?
>
> The previous way was more principled, in the manner of "eat your own
> dogfood". ?Maybe we've become just a tiny bit less principled.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From ross.mcilroy at gmail.com  Sun Nov 27 16:01:51 2011
From: ross.mcilroy at gmail.com (Ross McIlroy)
Date: Sun, 27 Nov 2011 21:01:51 +0000
Subject: [concurrency-interest] CFP: Runtime Environments, Systems,
 Layering and Virtual Environments at ASPLOS 2012
In-Reply-To: <CABaC1FH0225iKNHTNBwWgCZAYZPzN-tE4mJuBLmuWMA4YGS9iw@mail.gmail.com>
References: <CABaC1FH0225iKNHTNBwWgCZAYZPzN-tE4mJuBLmuWMA4YGS9iw@mail.gmail.com>
Message-ID: <CABaC1FG+ndtRiaJJXdg-x=_UtyaHwsCPHgKMayDOFJn=6C4LGg@mail.gmail.com>

[Appologies if you receive multiple copies of this CfP]

Please consider publishing work-in-progress OS or language based
virtual machine research at the following workshop, colocated with
ASPLOS 2012 in London.

--- PAPER SUBMISSION DEADLINE: This Saturday, 3rd of December --

--- CALL FOR PAPERS ---

Runtime Environments, Systems, Layering and Virtualized
Environments (RESoLVE'12)

Workshop at ASPLOS 2012, London, UK
March 3rd, 2012
http://www.dcs.gla.ac.uk/conferences/resolve12


The second workshop on Runtime Environments, Systems,
Layering, and Virtualized Environments (RESoLVE'12) aims to
brings together researchers in both the OS and language
level virtual machine communities to exchange ideas and
experiences and to discuss how these separate layers can
take advantage of each others' services.

This workshop will discuss work-in-progress research around
how these layers interact and complement each other, and how
best to support new software architectures. Topics of
interest include:

* better structuring / communication of services and
 divisions of labor
* trade-offs in the boundary between trusted and untrusted
 bases and mechanisms to provide information / feedback
 across the layers
* approaches for particular services (e.g. memory management
 / garbage collection / synchronization / signalling /
 scheduling)
* prototypes demonstrating combinations of SW- and HW-based
 techniques to provide better isolation, scaling, and
 quality-of-service
* enabling legacy systems to more readily take advantage of
 new hardware and software capabilities through virtual
 appliances and services
* visualization / introspection techniques for understanding
 the resulting systems

IMPORTANT DATES

Submission deadline: 3 Dec 2011
Notification: 14 Jan 2012
Camera-ready deadline: 4 Feb 2012
Workshop: 3 Mar 2012

SUBMISSIONS

We solicit papers for informal, non-archival
proceedings. Papers should be 6-8 pages, in the SIGPLAN
conference format. Full details are available on the
workshop website at
http://www.dcs.gla.ac.uk/conferences/resolve12
Also note that several travel grants are available for student
paper presentations.

PROGRAM COMMITTEE

Ross McIlroy (co-chair, Google, UK)
Jeremy Singer (co-chair, University of Glasgow, UK)
Alex Garthwaite (VMWare, USA)
Tim Harris (Microsoft Research, UK)
Chris Hawblitzel (Microsoft Research, USA)
Matt Horsnell (ARM, UK)
Tomas Kalibera (University of Kent, UK)
Stephen Kell (University of Oxford, UK)
Orran Krieger
Chandra Krintz (University of California, Santa Barbara, USA)
Geoffrey Lefebvre (Ericsson, Canada)
Ian Rogers (Google, USA)
Ian Sommerville (St Andrews, UK)
Bennet Yee (Google, USA)
Olivier Zendra (INRIA, France)

SPONSORS

VMWare - http://www.vmware.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111127/8a34c918/attachment.html>

From davidcholmes at aapt.net.au  Sun Nov 27 23:23:05 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 28 Nov 2011 14:23:05 +1000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>

Hanson Char writes:
> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}

tryExit ???

> extremely valuable in face of legacy code that uses synchronized
> block/method but the caller cannot afford to be "trapped" when calling
> the legacy code even when it entered into a indefinitely blocking
> state (within the synchronized block/method).

Can you expand on this. The only use case I can see is if you know the
legacy code will synchronize on a given instance and so you acquire it first
using tryLock. But that only protects you from the initial monitor
acquisition blocking indefinitely. This seems of very limited applicability.

> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
> into a normal and safe jdk class for general use, so we don't need to
> use it in stealth mode.  Or maybe it already is in Java 7+ ?

There's no such proposal on the table at the moment. A tryLock without a
timed-variant is of limited use and monitors don't currently support
timed-acquisition, so there would be a bit of VM work to do - particularly
if you wanted it intrinisfied by the compilers.

Cheers,
David Holmes

> Regards,
> Hanson
>
> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
> <elizarov at devexperts.com> wrote:
> > Unfortunately, I had to use Unsafe myself from time to time just for
> > performance reasons (because I have to write a lot of high-performance
> > code).
> >
> >
> >
> > /Roman
> >
> >
> >
> > From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
> > Sent: Thursday, November 17, 2011 3:01 PM
> > To: Roman Elizarov
> > Cc: Martin Buchholz; concurrency-interest
> >
> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
> vs Unsafe
> >
> >
> >
> > My thoughts exactly, Roman.? Us mere mortals figure out the "how to" by
> > reading JDK source code and when we see Unsafe being used, we
> go: "Ah, now
> > that's a good class to use..." ;-)
> >
> > From my newsletter:? http://www.javaspecialists.eu/archive/Issue194.html
> >
> > "In a recent email, one of my youngest readers, 17 year old Mr
> S.Perlov from
> > the Ukraine, suggested that I tell you about the class
> sun.misc.Unsafe. Up
> > to now I have avoided writing about it, as it is a class that should be
> > avoided. Here are two reasons: #1 it is "unsafe" and lets us do all the
> > nasty things that we had in C, such as pointer arithmetic or modifying
> > memory directly. #2 it is a sun.misc.* class. You do not know when that
> > might be renamed to oracle.misc.Unsafe or whether you will even run your
> > program on a Sun JVM. By binding yourself to a specific
> implementation of
> > the JVM, you are limiting the application of your code.
> >
> > Two reasons to not use Unsafe. I have personally never used Unsafe in
> > production code. Some experts do use it to write directly to memory.
> > Dangerous stuff! "
> >
> > Regards
> >
> >
> >
> > Heinz
> >
> > --
> >
> > Dr Heinz M. Kabutz (PhD CompSci)
> >
> > Author of "The Java(tm) Specialists' Newsletter"
> >
> > Sun Java Champion
> >
> > IEEE Certified Software Development Professional
> >
> > http://www.javaspecialists.eu
> >
> > Tel: +30 69 72 850 460
> >
> > Skype: kabutz
> >
> > On 11/17/11 12:53 PM, Roman Elizarov wrote:
> >
> > The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
> > programmer. Every day there are more and more blogs explaining
> advantages of
> > Unsafe to the average programmer. I?ve just recently reposted
> one of those
> > for the Russian programmers community.
> >
> >
> >
> > Are there any concrete plans (say for Java 8) to bring the
> performance of
> > **Updater classes on par with Unsafe (maybe by improving
> HotSpot, so that it
> > can eliminate all the extra checks and compile **Updater method into the
> > same code as produced by direct use of Unsafe)? Shall we
> continue to rely on
> > Unsafe for Java 8 and beyond or get ready for its eventual
> elimination from
> > our codebase?
> >
> >
> >
> > Sincerely,
> >
> > Roman Elizarov
> >
> >
> >
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin
> > Buchholz
> > Sent: Thursday, November 17, 2011 3:45 AM
> > To: Dr Heinz M. Kabutz
> > Cc: concurrency-interest
> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
> vs Unsafe
> >
> >
> >
> >
> >
> > On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu>
> > wrote:
> >
> > In Java 6, classes like ConcurrentLinkedQueue and
> SynchronousQueue used the
> > AtomicReferenceFieldUpdater to update the next, head, etc. fields.
> >
> > In Java 7, this was changed to instead use Unsafe.compareAndSwapObject()
> > directly.
> >
> > The AtomicReferenceFieldUpdater does a bunch of error checking
> every time it
> > is called, like this:
> >
> > ? ? ? ? ? if (obj == null || obj.getClass() != tclass || cclass
> != null ||
> > ? ? ? ? ? ? ? (update != null && vclass != null &&
> > ? ? ? ? ? ? ? ?vclass != update.getClass()))
> > ? ? ? ? ? ? ? updateCheck(obj, update);
> > ? ? ? ? ? return unsafe.compareAndSwapObject(obj, offset,
> expect, update);
> >
> > My thinking is that the programmers changing ConcurrentLinkedQueue et al
> > probably wanted to improve the performance by not having to do all that
> > checking every time it is called. ?The
> Unsafe.compareAndSwapObject() method
> > is probably compiled to a single CPU instruction.
> >
> > Is that correct?
> >
> > Yes.
> >
> >
> >
> > Is there any other reason for this change?
> >
> > The previous way was more principled, in the manner of "eat your own
> > dogfood". ?Maybe we've become just a tiny bit less principled.
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From hans.boehm at hp.com  Mon Nov 28 00:44:45 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 28 Nov 2011 05:44:45 +0000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEIKJBAA.davidcholmes@aapt.net.au>
References: <4ECBE5C5.4020006@redhat.com>
	<NFBBKALFDCPFIDBNKAPCCEIKJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CBFA2@G4W3299.americas.hpqcorp.net>

How is the method table pointer any different from any other final field here?  This code looks like the fence is not generated if the method table pointer is written, but there are no other final fields.  I can't at the moment think of a way to defend that choice.

Presumably the initial zeroing is handled separately be pre-clearing memory returned from the GC, and putting a fence after the bulk-clearing operation?

Hans

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> Sent: Thursday, November 24, 2011 10:12 PM
> To: Andrew Haley; Nathan Reynolds
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] The JSR-133 Cookbook for Compiler
> Writers
> 
> Andrew Haley writes:
> > OK, I see.  So, the only place you'd need this is in the cpu-specific
> > code, and all the cpu-specific code is on arches that don't need
> > StoreStore.
> 
> Actually no.  The C2 code for this is in shared code. See
> share/vm/opto/parse1.cpp
> 
> void Parse::do_exits() {
>    ...
> 
>   if (wrote_final()) {
>     // This method (which must be a constructor by the rules of Java)
>     // wrote a final.  The effects of all initializations must be
>     // committed to memory before any code after the constructor
>     // publishes the reference to the newly constructor object.
>     // Rather than wait for the publication, we simply block the
>     // writes here.  Rather than put a barrier on only those writes
>     // which are required to complete, we force all writes to complete.
>     //
>     // "All bets are off" unless the first publication occurs after a
>     // normal return from the constructor.  We do not attempt to detect
>     // such unusual early publications.  But no barrier is needed on
>     // exceptional returns, since they cannot publish normally.
>     //
>     _exits.insert_mem_bar(Op_MemBarRelease);
> 
> As already stated the MembarRelease will be a noop on x86 and sparc.
> 
> My thanks to Paul Hohenszee for tracking this code down.
> 
> I'm still searching for the C1 and interpreter versions of this.
> 
> David Holmes
> ------------
> 
> 
> > Thanks,
> >
> > Andrew.
> >
> > On 11/22/2011 03:56 PM, Nathan Reynolds wrote:
> > > On x86 and Sparc TSO, the StoreStore barrier becomes a no-op.  (See
> > > the table in the Multiprocessors section.)  These processors will
> > > not allow stores to go before other stores.  Thus, the StoreStore
> > > barrier is already enforced for all store operations by the
> > > processor.  The only barrier required on x86 and Sparc TSO is the
> StoreLoad barrier.
> > >
> > > Nathan Reynolds
> > > <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> > > Consulting Member of Technical Staff | 602.333.9091 Oracle PSR
> > > Engineering <http://psr.us.oracle.com/> | Server Technology
> > >
> > > On 11/22/2011 7:40 AM, Andrew Haley wrote:
> > >> A little mystery:
> > >>
> > >> Inserting Barriers
> > >> ...
> > >>
> > >>     2. Issue a StoreStore barrier after all stores but before return
> > >>     from any constructor for any class with a final field.
> > >>
> > >> So, I'm looking for this barrier in the HotSpot code but I have
> > >> been unable to find it.  Can someone please put me out of my misery
> > >> and tell me where it is?
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From hanson.char at gmail.com  Mon Nov 28 01:27:54 2011
From: hanson.char at gmail.com (Hanson Char)
Date: Sun, 27 Nov 2011 22:27:54 -0800
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
Message-ID: <CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>

Hi David,

Sorry I meant Unsafe#tryMonitorEnter and #monitorExit.  (I realized
the mistake after sending out the email, but thought the context would
self recover/make it clear :))

> Can you expand on this.

One practical (and critical) case I've come across is that under some
extreme circumstances , a 3rd party database connection pool would get
into a "stuck" state.  Doesn't happen often but it does happen.  When
it did, any attempt to inspect the respective pool via JMX calling the
getter methods for info such as the number of active/idle connections
would cause the inspecting thread to get stuck.

Looking into the code (of the third party library) it was clearly
related to the use of synchronized methods, including the getter
methods for the stats.

Via Unsafe#tryMonitorEnter, the application was able to get some
information out of the pool, and initiate some emergent recovery
actions such as interrupting the blocked threads, resetting the db
connection pool and jdbc driver, or even just generating alerts/alarms
to the support staff.

This also allows the application to avoid piling up threads getting
sucked into a black hole which would lead to the eventual death of the
JVM (ie requiring a restart).

 >There's no such proposal on the table at the moment. A tryLock without a
> timed-variant is of limited use and monitors don't currently support
> timed-acquisition, so there would be a bit of VM work to do - particularly
> if you wanted it intrinisfied by the compilers.

Indeed that's what I guessed was the reason (of why these two methods
are hidden behind Unsafe).  But isn't limited use better than nothing
in this case ?  It seems clearly I am not alone:

  http://www.javaspecialists.eu/archive/Issue194.html

It appears the use of this tryMonitorEnter is the only way we (or just
I) can guarantee the application to retain liveness in accessing third
party library in face of invoking (3rd party owned) synchronized
methods.  As long as there is liveness, the application can do
something about it and therefore allow such synchronized problems to
be limited to a partial failure that can be recovered.  The use could
be limited, but important.

I don't know if, however, the tryMonitorEnter/monitorExit method is
truly "unsafe" in the sense that if calling them may cause the JVM to
crash ?  If not, these methods should probably be re-located to a more
sensible class anyway, like perhaps Object ?

Regards,
Hanson

On Sun, Nov 27, 2011 at 8:23 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Hanson Char writes:
>> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
>
> tryExit ???
>
>> extremely valuable in face of legacy code that uses synchronized
>> block/method but the caller cannot afford to be "trapped" when calling
>> the legacy code even when it entered into a indefinitely blocking
>> state (within the synchronized block/method).
>
> Can you expand on this. The only use case I can see is if you know the
> legacy code will synchronize on a given instance and so you acquire it first
> using tryLock. But that only protects you from the initial monitor
> acquisition blocking indefinitely. This seems of very limited applicability.
>
>> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
>> into a normal and safe jdk class for general use, so we don't need to
>> use it in stealth mode. ?Or maybe it already is in Java 7+ ?
>
> There's no such proposal on the table at the moment. A tryLock without a
> timed-variant is of limited use and monitors don't currently support
> timed-acquisition, so there would be a bit of VM work to do - particularly
> if you wanted it intrinisfied by the compilers.
>
> Cheers,
> David Holmes
>
>> Regards,
>> Hanson
>>
>> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
>> <elizarov at devexperts.com> wrote:
>> > Unfortunately, I had to use Unsafe myself from time to time just for
>> > performance reasons (because I have to write a lot of high-performance
>> > code).
>> >
>> >
>> >
>> > /Roman
>> >
>> >
>> >
>> > From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
>> > Sent: Thursday, November 17, 2011 3:01 PM
>> > To: Roman Elizarov
>> > Cc: Martin Buchholz; concurrency-interest
>> >
>> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>> vs Unsafe
>> >
>> >
>> >
>> > My thoughts exactly, Roman.? Us mere mortals figure out the "how to" by
>> > reading JDK source code and when we see Unsafe being used, we
>> go: "Ah, now
>> > that's a good class to use..." ;-)
>> >
>> > From my newsletter:? http://www.javaspecialists.eu/archive/Issue194.html
>> >
>> > "In a recent email, one of my youngest readers, 17 year old Mr
>> S.Perlov from
>> > the Ukraine, suggested that I tell you about the class
>> sun.misc.Unsafe. Up
>> > to now I have avoided writing about it, as it is a class that should be
>> > avoided. Here are two reasons: #1 it is "unsafe" and lets us do all the
>> > nasty things that we had in C, such as pointer arithmetic or modifying
>> > memory directly. #2 it is a sun.misc.* class. You do not know when that
>> > might be renamed to oracle.misc.Unsafe or whether you will even run your
>> > program on a Sun JVM. By binding yourself to a specific
>> implementation of
>> > the JVM, you are limiting the application of your code.
>> >
>> > Two reasons to not use Unsafe. I have personally never used Unsafe in
>> > production code. Some experts do use it to write directly to memory.
>> > Dangerous stuff! "
>> >
>> > Regards
>> >
>> >
>> >
>> > Heinz
>> >
>> > --
>> >
>> > Dr Heinz M. Kabutz (PhD CompSci)
>> >
>> > Author of "The Java(tm) Specialists' Newsletter"
>> >
>> > Sun Java Champion
>> >
>> > IEEE Certified Software Development Professional
>> >
>> > http://www.javaspecialists.eu
>> >
>> > Tel: +30 69 72 850 460
>> >
>> > Skype: kabutz
>> >
>> > On 11/17/11 12:53 PM, Roman Elizarov wrote:
>> >
>> > The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
>> > programmer. Every day there are more and more blogs explaining
>> advantages of
>> > Unsafe to the average programmer. I?ve just recently reposted
>> one of those
>> > for the Russian programmers community.
>> >
>> >
>> >
>> > Are there any concrete plans (say for Java 8) to bring the
>> performance of
>> > **Updater classes on par with Unsafe (maybe by improving
>> HotSpot, so that it
>> > can eliminate all the extra checks and compile **Updater method into the
>> > same code as produced by direct use of Unsafe)? Shall we
>> continue to rely on
>> > Unsafe for Java 8 and beyond or get ready for its eventual
>> elimination from
>> > our codebase?
>> >
>> >
>> >
>> > Sincerely,
>> >
>> > Roman Elizarov
>> >
>> >
>> >
>> > From: concurrency-interest-bounces at cs.oswego.edu
>> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin
>> > Buchholz
>> > Sent: Thursday, November 17, 2011 3:45 AM
>> > To: Dr Heinz M. Kabutz
>> > Cc: concurrency-interest
>> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>> vs Unsafe
>> >
>> >
>> >
>> >
>> >
>> > On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu>
>> > wrote:
>> >
>> > In Java 6, classes like ConcurrentLinkedQueue and
>> SynchronousQueue used the
>> > AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>> >
>> > In Java 7, this was changed to instead use Unsafe.compareAndSwapObject()
>> > directly.
>> >
>> > The AtomicReferenceFieldUpdater does a bunch of error checking
>> every time it
>> > is called, like this:
>> >
>> > ? ? ? ? ? if (obj == null || obj.getClass() != tclass || cclass
>> != null ||
>> > ? ? ? ? ? ? ? (update != null && vclass != null &&
>> > ? ? ? ? ? ? ? ?vclass != update.getClass()))
>> > ? ? ? ? ? ? ? updateCheck(obj, update);
>> > ? ? ? ? ? return unsafe.compareAndSwapObject(obj, offset,
>> expect, update);
>> >
>> > My thinking is that the programmers changing ConcurrentLinkedQueue et al
>> > probably wanted to improve the performance by not having to do all that
>> > checking every time it is called. ?The
>> Unsafe.compareAndSwapObject() method
>> > is probably compiled to a single CPU instruction.
>> >
>> > Is that correct?
>> >
>> > Yes.
>> >
>> >
>> >
>> > Is there any other reason for this change?
>> >
>> > The previous way was more principled, in the manner of "eat your own
>> > dogfood". ?Maybe we've become just a tiny bit less principled.
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> >
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>


From davidcholmes at aapt.net.au  Mon Nov 28 02:18:48 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 28 Nov 2011 17:18:48 +1000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20CBFA2@G4W3299.americas.hpqcorp.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEJDJBAA.davidcholmes@aapt.net.au>

Hi Hans,

Hans Boehm writes:
> How is the method table pointer any different from any other
> final field here?  This code looks like the fence is not
> generated if the method table pointer is written, but there are
> no other final fields.  I can't at the moment think of a way to
> defend that choice.

A Java object contains a reference to its class, which in turn holds the
vtable pointer. That class reference may be stored using "release
semantics". I say "may" because the code is somewhat complex and its hard to
know exactly what paths will be executed just be reading the code.

>From a practical perspective this is only an issue for non-TSO systems when
the object reference is subject to unsafe publication. Even for non-TSO
systems the "distance" between the two stores makes it unlikely (and no I
can't quantify that) they will be reordered.

The constructor executes after that, so any final field assignments there
need their own release barrier.

> Presumably the initial zeroing is handled separately be
> pre-clearing memory returned from the GC, and putting a fence
> after the bulk-clearing operation?

Also a complex story, but the store to the class reference can act as a
barrier for both.

David
-----

> Hans
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> > interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> > Sent: Thursday, November 24, 2011 10:12 PM
> > To: Andrew Haley; Nathan Reynolds
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] The JSR-133 Cookbook for Compiler
> > Writers
> >
> > Andrew Haley writes:
> > > OK, I see.  So, the only place you'd need this is in the cpu-specific
> > > code, and all the cpu-specific code is on arches that don't need
> > > StoreStore.
> >
> > Actually no.  The C2 code for this is in shared code. See
> > share/vm/opto/parse1.cpp
> >
> > void Parse::do_exits() {
> >    ...
> >
> >   if (wrote_final()) {
> >     // This method (which must be a constructor by the rules of Java)
> >     // wrote a final.  The effects of all initializations must be
> >     // committed to memory before any code after the constructor
> >     // publishes the reference to the newly constructor object.
> >     // Rather than wait for the publication, we simply block the
> >     // writes here.  Rather than put a barrier on only those writes
> >     // which are required to complete, we force all writes to complete.
> >     //
> >     // "All bets are off" unless the first publication occurs after a
> >     // normal return from the constructor.  We do not attempt to detect
> >     // such unusual early publications.  But no barrier is needed on
> >     // exceptional returns, since they cannot publish normally.
> >     //
> >     _exits.insert_mem_bar(Op_MemBarRelease);
> >
> > As already stated the MembarRelease will be a noop on x86 and sparc.
> >
> > My thanks to Paul Hohenszee for tracking this code down.
> >
> > I'm still searching for the C1 and interpreter versions of this.
> >
> > David Holmes
> > ------------
> >
> >
> > > Thanks,
> > >
> > > Andrew.
> > >
> > > On 11/22/2011 03:56 PM, Nathan Reynolds wrote:
> > > > On x86 and Sparc TSO, the StoreStore barrier becomes a no-op.  (See
> > > > the table in the Multiprocessors section.)  These processors will
> > > > not allow stores to go before other stores.  Thus, the StoreStore
> > > > barrier is already enforced for all store operations by the
> > > > processor.  The only barrier required on x86 and Sparc TSO is the
> > StoreLoad barrier.
> > > >
> > > > Nathan Reynolds
> > > > <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> > > > Consulting Member of Technical Staff | 602.333.9091 Oracle PSR
> > > > Engineering <http://psr.us.oracle.com/> | Server Technology
> > > >
> > > > On 11/22/2011 7:40 AM, Andrew Haley wrote:
> > > >> A little mystery:
> > > >>
> > > >> Inserting Barriers
> > > >> ...
> > > >>
> > > >>     2. Issue a StoreStore barrier after all stores but
> before return
> > > >>     from any constructor for any class with a final field.
> > > >>
> > > >> So, I'm looking for this barrier in the HotSpot code but I have
> > > >> been unable to find it.  Can someone please put me out of my misery
> > > >> and tell me where it is?
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From radhakrishnan.mohan at gmail.com  Mon Nov 28 04:31:29 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 28 Nov 2011 15:01:29 +0530
Subject: [concurrency-interest] Basic question about memory barriers
Message-ID: <CAOoXFP-6mXv=Q_qNXU6TtDUt4RZBFhLkYYpS-7Sq4QWaPkvSfw@mail.gmail.com>

Hi,

     Have a few questions.

     1. Who issues the memory barriers ?
     2. Can I look at memory barriers in machine code ? Is it done by
the processor ?


Thanks,
Mohan

From davidcholmes at aapt.net.au  Mon Nov 28 05:18:50 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 28 Nov 2011 20:18:50 +1000
Subject: [concurrency-interest] Basic question about memory barriers
In-Reply-To: <CAOoXFP-6mXv=Q_qNXU6TtDUt4RZBFhLkYYpS-7Sq4QWaPkvSfw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEJEJBAA.davidcholmes@aapt.net.au>

Mohan Radhakrishnan writes:
>      1. Who issues the memory barriers ?

In the context of Java it is the runtime support code of the JVM together
with the code emitted by the JIT.

>      2. Can I look at memory barriers in machine code ? Is it done by
> the processor ?

The "barriers" depend on the architecture. They can be explicit
synchronization instructions; modes applied to loads and stores; or specific
instruction sequences (eg dependent loads) that produce the desired effect.
See the Java Memory Model Cookbook for compiler writers to learn more:

http://g.oswego.edu/dl/jmm/cookbook.html

David Holmes
-----------

>
> Thanks,
> Mohan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From vitalyd at gmail.com  Mon Nov 28 09:24:08 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 09:24:08 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
Message-ID: <CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>

Relocating these methods to a "proper" JDK class will imply that it's ok to
use them in normal operation, which I don't think is the case and hence, to
me, unsafe sounds like the right place.

Why not have the 3rd party fix their code? I realize that won't help in the
immediate situation, but that's actually the right solution here.

$.02

Vitaly
On Nov 28, 2011 1:29 AM, "Hanson Char" <hanson.char at gmail.com> wrote:

> Hi David,
>
> Sorry I meant Unsafe#tryMonitorEnter and #monitorExit.  (I realized
> the mistake after sending out the email, but thought the context would
> self recover/make it clear :))
>
> > Can you expand on this.
>
> One practical (and critical) case I've come across is that under some
> extreme circumstances , a 3rd party database connection pool would get
> into a "stuck" state.  Doesn't happen often but it does happen.  When
> it did, any attempt to inspect the respective pool via JMX calling the
> getter methods for info such as the number of active/idle connections
> would cause the inspecting thread to get stuck.
>
> Looking into the code (of the third party library) it was clearly
> related to the use of synchronized methods, including the getter
> methods for the stats.
>
> Via Unsafe#tryMonitorEnter, the application was able to get some
> information out of the pool, and initiate some emergent recovery
> actions such as interrupting the blocked threads, resetting the db
> connection pool and jdbc driver, or even just generating alerts/alarms
> to the support staff.
>
> This also allows the application to avoid piling up threads getting
> sucked into a black hole which would lead to the eventual death of the
> JVM (ie requiring a restart).
>
>  >There's no such proposal on the table at the moment. A tryLock without a
> > timed-variant is of limited use and monitors don't currently support
> > timed-acquisition, so there would be a bit of VM work to do -
> particularly
> > if you wanted it intrinisfied by the compilers.
>
> Indeed that's what I guessed was the reason (of why these two methods
> are hidden behind Unsafe).  But isn't limited use better than nothing
> in this case ?  It seems clearly I am not alone:
>
>  http://www.javaspecialists.eu/archive/Issue194.html
>
> It appears the use of this tryMonitorEnter is the only way we (or just
> I) can guarantee the application to retain liveness in accessing third
> party library in face of invoking (3rd party owned) synchronized
> methods.  As long as there is liveness, the application can do
> something about it and therefore allow such synchronized problems to
> be limited to a partial failure that can be recovered.  The use could
> be limited, but important.
>
> I don't know if, however, the tryMonitorEnter/monitorExit method is
> truly "unsafe" in the sense that if calling them may cause the JVM to
> crash ?  If not, these methods should probably be re-located to a more
> sensible class anyway, like perhaps Object ?
>
> Regards,
> Hanson
>
> On Sun, Nov 27, 2011 at 8:23 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
> > Hanson Char writes:
> >> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
> >
> > tryExit ???
> >
> >> extremely valuable in face of legacy code that uses synchronized
> >> block/method but the caller cannot afford to be "trapped" when calling
> >> the legacy code even when it entered into a indefinitely blocking
> >> state (within the synchronized block/method).
> >
> > Can you expand on this. The only use case I can see is if you know the
> > legacy code will synchronize on a given instance and so you acquire it
> first
> > using tryLock. But that only protects you from the initial monitor
> > acquisition blocking indefinitely. This seems of very limited
> applicability.
> >
> >> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
> >> into a normal and safe jdk class for general use, so we don't need to
> >> use it in stealth mode.  Or maybe it already is in Java 7+ ?
> >
> > There's no such proposal on the table at the moment. A tryLock without a
> > timed-variant is of limited use and monitors don't currently support
> > timed-acquisition, so there would be a bit of VM work to do -
> particularly
> > if you wanted it intrinisfied by the compilers.
> >
> > Cheers,
> > David Holmes
> >
> >> Regards,
> >> Hanson
> >>
> >> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
> >> <elizarov at devexperts.com> wrote:
> >> > Unfortunately, I had to use Unsafe myself from time to time just for
> >> > performance reasons (because I have to write a lot of high-performance
> >> > code).
> >> >
> >> >
> >> >
> >> > /Roman
> >> >
> >> >
> >> >
> >> > From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
> >> > Sent: Thursday, November 17, 2011 3:01 PM
> >> > To: Roman Elizarov
> >> > Cc: Martin Buchholz; concurrency-interest
> >> >
> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
> >> vs Unsafe
> >> >
> >> >
> >> >
> >> > My thoughts exactly, Roman.  Us mere mortals figure out the "how to"
> by
> >> > reading JDK source code and when we see Unsafe being used, we
> >> go: "Ah, now
> >> > that's a good class to use..." ;-)
> >> >
> >> > From my newsletter:
> http://www.javaspecialists.eu/archive/Issue194.html
> >> >
> >> > "In a recent email, one of my youngest readers, 17 year old Mr
> >> S.Perlov from
> >> > the Ukraine, suggested that I tell you about the class
> >> sun.misc.Unsafe. Up
> >> > to now I have avoided writing about it, as it is a class that should
> be
> >> > avoided. Here are two reasons: #1 it is "unsafe" and lets us do all
> the
> >> > nasty things that we had in C, such as pointer arithmetic or modifying
> >> > memory directly. #2 it is a sun.misc.* class. You do not know when
> that
> >> > might be renamed to oracle.misc.Unsafe or whether you will even run
> your
> >> > program on a Sun JVM. By binding yourself to a specific
> >> implementation of
> >> > the JVM, you are limiting the application of your code.
> >> >
> >> > Two reasons to not use Unsafe. I have personally never used Unsafe in
> >> > production code. Some experts do use it to write directly to memory.
> >> > Dangerous stuff! "
> >> >
> >> > Regards
> >> >
> >> >
> >> >
> >> > Heinz
> >> >
> >> > --
> >> >
> >> > Dr Heinz M. Kabutz (PhD CompSci)
> >> >
> >> > Author of "The Java(tm) Specialists' Newsletter"
> >> >
> >> > Sun Java Champion
> >> >
> >> > IEEE Certified Software Development Professional
> >> >
> >> > http://www.javaspecialists.eu
> >> >
> >> > Tel: +30 69 72 850 460
> >> >
> >> > Skype: kabutz
> >> >
> >> > On 11/17/11 12:53 PM, Roman Elizarov wrote:
> >> >
> >> > The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
> >> > programmer. Every day there are more and more blogs explaining
> >> advantages of
> >> > Unsafe to the average programmer. I?ve just recently reposted
> >> one of those
> >> > for the Russian programmers community.
> >> >
> >> >
> >> >
> >> > Are there any concrete plans (say for Java 8) to bring the
> >> performance of
> >> > **Updater classes on par with Unsafe (maybe by improving
> >> HotSpot, so that it
> >> > can eliminate all the extra checks and compile **Updater method into
> the
> >> > same code as produced by direct use of Unsafe)? Shall we
> >> continue to rely on
> >> > Unsafe for Java 8 and beyond or get ready for its eventual
> >> elimination from
> >> > our codebase?
> >> >
> >> >
> >> >
> >> > Sincerely,
> >> >
> >> > Roman Elizarov
> >> >
> >> >
> >> >
> >> > From: concurrency-interest-bounces at cs.oswego.edu
> >> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of
> Martin
> >> > Buchholz
> >> > Sent: Thursday, November 17, 2011 3:45 AM
> >> > To: Dr Heinz M. Kabutz
> >> > Cc: concurrency-interest
> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
> >> vs Unsafe
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
> >> <heinz at javaspecialists.eu>
> >> > wrote:
> >> >
> >> > In Java 6, classes like ConcurrentLinkedQueue and
> >> SynchronousQueue used the
> >> > AtomicReferenceFieldUpdater to update the next, head, etc. fields.
> >> >
> >> > In Java 7, this was changed to instead use
> Unsafe.compareAndSwapObject()
> >> > directly.
> >> >
> >> > The AtomicReferenceFieldUpdater does a bunch of error checking
> >> every time it
> >> > is called, like this:
> >> >
> >> >           if (obj == null || obj.getClass() != tclass || cclass
> >> != null ||
> >> >               (update != null && vclass != null &&
> >> >                vclass != update.getClass()))
> >> >               updateCheck(obj, update);
> >> >           return unsafe.compareAndSwapObject(obj, offset,
> >> expect, update);
> >> >
> >> > My thinking is that the programmers changing ConcurrentLinkedQueue et
> al
> >> > probably wanted to improve the performance by not having to do all
> that
> >> > checking every time it is called.  The
> >> Unsafe.compareAndSwapObject() method
> >> > is probably compiled to a single CPU instruction.
> >> >
> >> > Is that correct?
> >> >
> >> > Yes.
> >> >
> >> >
> >> >
> >> > Is there any other reason for this change?
> >> >
> >> > The previous way was more principled, in the manner of "eat your own
> >> > dogfood".  Maybe we've become just a tiny bit less principled.
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> >
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/4537af46/attachment-0001.html>

From viktor.klang at gmail.com  Mon Nov 28 09:35:29 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 28 Nov 2011 15:35:29 +0100
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
Message-ID: <CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>

On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Relocating these methods to a "proper" JDK class will imply that it's ok
> to use them in normal operation, which I don't think is the case and hence,
> to me, unsafe sounds like the right place.
>
It should probably be java.lang.Unsafe instead of sun.misc.Unsafe though



> Why not have the 3rd party fix their code? I realize that won't help in
> the immediate situation, but that's actually the right solution here.
>
> $.02
>
> Vitaly
> On Nov 28, 2011 1:29 AM, "Hanson Char" <hanson.char at gmail.com> wrote:
>
>> Hi David,
>>
>> Sorry I meant Unsafe#tryMonitorEnter and #monitorExit.  (I realized
>> the mistake after sending out the email, but thought the context would
>> self recover/make it clear :))
>>
>> > Can you expand on this.
>>
>> One practical (and critical) case I've come across is that under some
>> extreme circumstances , a 3rd party database connection pool would get
>> into a "stuck" state.  Doesn't happen often but it does happen.  When
>> it did, any attempt to inspect the respective pool via JMX calling the
>> getter methods for info such as the number of active/idle connections
>> would cause the inspecting thread to get stuck.
>>
>> Looking into the code (of the third party library) it was clearly
>> related to the use of synchronized methods, including the getter
>> methods for the stats.
>>
>> Via Unsafe#tryMonitorEnter, the application was able to get some
>> information out of the pool, and initiate some emergent recovery
>> actions such as interrupting the blocked threads, resetting the db
>> connection pool and jdbc driver, or even just generating alerts/alarms
>> to the support staff.
>>
>> This also allows the application to avoid piling up threads getting
>> sucked into a black hole which would lead to the eventual death of the
>> JVM (ie requiring a restart).
>>
>>  >There's no such proposal on the table at the moment. A tryLock without a
>> > timed-variant is of limited use and monitors don't currently support
>> > timed-acquisition, so there would be a bit of VM work to do -
>> particularly
>> > if you wanted it intrinisfied by the compilers.
>>
>> Indeed that's what I guessed was the reason (of why these two methods
>> are hidden behind Unsafe).  But isn't limited use better than nothing
>> in this case ?  It seems clearly I am not alone:
>>
>>  http://www.javaspecialists.eu/archive/Issue194.html
>>
>> It appears the use of this tryMonitorEnter is the only way we (or just
>> I) can guarantee the application to retain liveness in accessing third
>> party library in face of invoking (3rd party owned) synchronized
>> methods.  As long as there is liveness, the application can do
>> something about it and therefore allow such synchronized problems to
>> be limited to a partial failure that can be recovered.  The use could
>> be limited, but important.
>>
>> I don't know if, however, the tryMonitorEnter/monitorExit method is
>> truly "unsafe" in the sense that if calling them may cause the JVM to
>> crash ?  If not, these methods should probably be re-located to a more
>> sensible class anyway, like perhaps Object ?
>>
>> Regards,
>> Hanson
>>
>> On Sun, Nov 27, 2011 at 8:23 PM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>> > Hanson Char writes:
>> >> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
>> >
>> > tryExit ???
>> >
>> >> extremely valuable in face of legacy code that uses synchronized
>> >> block/method but the caller cannot afford to be "trapped" when calling
>> >> the legacy code even when it entered into a indefinitely blocking
>> >> state (within the synchronized block/method).
>> >
>> > Can you expand on this. The only use case I can see is if you know the
>> > legacy code will synchronize on a given instance and so you acquire it
>> first
>> > using tryLock. But that only protects you from the initial monitor
>> > acquisition blocking indefinitely. This seems of very limited
>> applicability.
>> >
>> >> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
>> >> into a normal and safe jdk class for general use, so we don't need to
>> >> use it in stealth mode.  Or maybe it already is in Java 7+ ?
>> >
>> > There's no such proposal on the table at the moment. A tryLock without a
>> > timed-variant is of limited use and monitors don't currently support
>> > timed-acquisition, so there would be a bit of VM work to do -
>> particularly
>> > if you wanted it intrinisfied by the compilers.
>> >
>> > Cheers,
>> > David Holmes
>> >
>> >> Regards,
>> >> Hanson
>> >>
>> >> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
>> >> <elizarov at devexperts.com> wrote:
>> >> > Unfortunately, I had to use Unsafe myself from time to time just for
>> >> > performance reasons (because I have to write a lot of
>> high-performance
>> >> > code).
>> >> >
>> >> >
>> >> >
>> >> > /Roman
>> >> >
>> >> >
>> >> >
>> >> > From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
>> >> > Sent: Thursday, November 17, 2011 3:01 PM
>> >> > To: Roman Elizarov
>> >> > Cc: Martin Buchholz; concurrency-interest
>> >> >
>> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>> >> vs Unsafe
>> >> >
>> >> >
>> >> >
>> >> > My thoughts exactly, Roman.  Us mere mortals figure out the "how to"
>> by
>> >> > reading JDK source code and when we see Unsafe being used, we
>> >> go: "Ah, now
>> >> > that's a good class to use..." ;-)
>> >> >
>> >> > From my newsletter:
>> http://www.javaspecialists.eu/archive/Issue194.html
>> >> >
>> >> > "In a recent email, one of my youngest readers, 17 year old Mr
>> >> S.Perlov from
>> >> > the Ukraine, suggested that I tell you about the class
>> >> sun.misc.Unsafe. Up
>> >> > to now I have avoided writing about it, as it is a class that should
>> be
>> >> > avoided. Here are two reasons: #1 it is "unsafe" and lets us do all
>> the
>> >> > nasty things that we had in C, such as pointer arithmetic or
>> modifying
>> >> > memory directly. #2 it is a sun.misc.* class. You do not know when
>> that
>> >> > might be renamed to oracle.misc.Unsafe or whether you will even run
>> your
>> >> > program on a Sun JVM. By binding yourself to a specific
>> >> implementation of
>> >> > the JVM, you are limiting the application of your code.
>> >> >
>> >> > Two reasons to not use Unsafe. I have personally never used Unsafe in
>> >> > production code. Some experts do use it to write directly to memory.
>> >> > Dangerous stuff! "
>> >> >
>> >> > Regards
>> >> >
>> >> >
>> >> >
>> >> > Heinz
>> >> >
>> >> > --
>> >> >
>> >> > Dr Heinz M. Kabutz (PhD CompSci)
>> >> >
>> >> > Author of "The Java(tm) Specialists' Newsletter"
>> >> >
>> >> > Sun Java Champion
>> >> >
>> >> > IEEE Certified Software Development Professional
>> >> >
>> >> > http://www.javaspecialists.eu
>> >> >
>> >> > Tel: +30 69 72 850 460
>> >> >
>> >> > Skype: kabutz
>> >> >
>> >> > On 11/17/11 12:53 PM, Roman Elizarov wrote:
>> >> >
>> >> > The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
>> >> > programmer. Every day there are more and more blogs explaining
>> >> advantages of
>> >> > Unsafe to the average programmer. I?ve just recently reposted
>> >> one of those
>> >> > for the Russian programmers community.
>> >> >
>> >> >
>> >> >
>> >> > Are there any concrete plans (say for Java 8) to bring the
>> >> performance of
>> >> > **Updater classes on par with Unsafe (maybe by improving
>> >> HotSpot, so that it
>> >> > can eliminate all the extra checks and compile **Updater method into
>> the
>> >> > same code as produced by direct use of Unsafe)? Shall we
>> >> continue to rely on
>> >> > Unsafe for Java 8 and beyond or get ready for its eventual
>> >> elimination from
>> >> > our codebase?
>> >> >
>> >> >
>> >> >
>> >> > Sincerely,
>> >> >
>> >> > Roman Elizarov
>> >> >
>> >> >
>> >> >
>> >> > From: concurrency-interest-bounces at cs.oswego.edu
>> >> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of
>> Martin
>> >> > Buchholz
>> >> > Sent: Thursday, November 17, 2011 3:45 AM
>> >> > To: Dr Heinz M. Kabutz
>> >> > Cc: concurrency-interest
>> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>> >> vs Unsafe
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
>> >> <heinz at javaspecialists.eu>
>> >> > wrote:
>> >> >
>> >> > In Java 6, classes like ConcurrentLinkedQueue and
>> >> SynchronousQueue used the
>> >> > AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>> >> >
>> >> > In Java 7, this was changed to instead use
>> Unsafe.compareAndSwapObject()
>> >> > directly.
>> >> >
>> >> > The AtomicReferenceFieldUpdater does a bunch of error checking
>> >> every time it
>> >> > is called, like this:
>> >> >
>> >> >           if (obj == null || obj.getClass() != tclass || cclass
>> >> != null ||
>> >> >               (update != null && vclass != null &&
>> >> >                vclass != update.getClass()))
>> >> >               updateCheck(obj, update);
>> >> >           return unsafe.compareAndSwapObject(obj, offset,
>> >> expect, update);
>> >> >
>> >> > My thinking is that the programmers changing ConcurrentLinkedQueue
>> et al
>> >> > probably wanted to improve the performance by not having to do all
>> that
>> >> > checking every time it is called.  The
>> >> Unsafe.compareAndSwapObject() method
>> >> > is probably compiled to a single CPU instruction.
>> >> >
>> >> > Is that correct?
>> >> >
>> >> > Yes.
>> >> >
>> >> >
>> >> >
>> >> > Is there any other reason for this change?
>> >> >
>> >> > The previous way was more principled, in the manner of "eat your own
>> >> > dogfood".  Maybe we've become just a tiny bit less principled.
>> >> >
>> >> > _______________________________________________
>> >> > Concurrency-interest mailing list
>> >> > Concurrency-interest at cs.oswego.edu
>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >
>> >> >
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >
>> >
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/418158ec/attachment.html>

From forax at univ-mlv.fr  Mon Nov 28 09:53:10 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 28 Nov 2011 15:53:10 +0100
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
Message-ID: <4ED3A056.2080909@univ-mlv.fr>

On 11/28/2011 03:35 PM, ?iktor ?lang wrote:
>
>
> On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com 
> <mailto:vitalyd at gmail.com>> wrote:
>
>     Relocating these methods to a "proper" JDK class will imply that
>     it's ok to use them in normal operation, which I don't think is
>     the case and hence, to me, unsafe sounds like the right place.
>
> It should probably be java.lang.Unsafe instead of sun.misc.Unsafe though

They are as unsafe as calling tryLock() and unlock() on a Lock,
so they can be in j.l.Thread as static methods.

>
>     Why not have the 3rd party fix their code? I realize that won't
>     help in the immediate situation, but that's actually the right
>     solution here.
>
>     $.02
>
>     Vitaly
>

R?mi

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/d1deecbe/attachment-0001.html>

From vitalyd at gmail.com  Mon Nov 28 10:10:42 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 10:10:42 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4ED3A056.2080909@univ-mlv.fr>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
Message-ID: <CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>

Difference is that locks were designed with tryXXX upfront whereas synch
block was not, as David pointed out its missing some things.  Therefore,
what you're proposing would encourage (or at least not discourage) a
feature that wasn't meant for wide public consumption, irrespective if it's
"safe" or not.
On Nov 28, 2011 10:01 AM, "R?mi Forax" <forax at univ-mlv.fr> wrote:

>  On 11/28/2011 03:35 PM, ?iktor ?lang wrote:
>
>
>
> On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> Relocating these methods to a "proper" JDK class will imply that it's ok
>> to use them in normal operation, which I don't think is the case and hence,
>> to me, unsafe sounds like the right place.
>>
> It should probably be java.lang.Unsafe instead of sun.misc.Unsafe though
>
>
> They are as unsafe as calling tryLock() and unlock() on a Lock,
> so they can be in j.l.Thread as static methods.
>
>
>
>
>> Why not have the 3rd party fix their code? I realize that won't help in
>> the immediate situation, but that's actually the right solution here.
>>
>> $.02
>>
>> Vitaly
>>
>
> R?mi
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/541dc522/attachment.html>

From gregg at cytetech.com  Mon Nov 28 11:02:34 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 28 Nov 2011 10:02:34 -0600
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
Message-ID: <4ED3B09A.6000200@cytetech.com>

On 11/28/2011 9:10 AM, Vitaly Davidovich wrote:
> Difference is that locks were designed with tryXXX upfront whereas synch block
> was not, as David pointed out its missing some things.  Therefore, what you're
> proposing would encourage (or at least not discourage) a feature that wasn't
> meant for wide public consumption, irrespective if it's "safe" or not.

IDEs warn about the use of Object.wait() in loops because the can create 
"forever" problems.  Object.wait(int) is always suggested, just to wake up the 
thread and attempt forward progress.

As a general rule of thumb, "polling for completion", is something that Java 
APIs have done quite pervasively, and in this day and age, the call back model 
is often a better choice because it provides thread context control to the 
calling thread so that the person writing the called code doesn't have to know 
what thread context applies.

Providing these methods, for me, just maintains the "polling" mentality, but can 
also provide some relief for developers having to deal with this kind of 
"broken" code.  Like lock()/trylock()/unlock(), it does create the ability for 
developers to make errors in how locking is applied if they miss an exit from a 
lock()/trylock() environment and thus miss the unlock().  But, I think that is a 
small pill to swallow compared to having to "give up" because some old crufty 
code is "polling" for completion status.

Gregg

> On Nov 28, 2011 10:01 AM, "R?mi Forax" <forax at univ-mlv.fr
> <mailto:forax at univ-mlv.fr>> wrote:
>
>     On 11/28/2011 03:35 PM, ?iktor ?lang wrote:
>>
>>
>>     On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com
>>     <mailto:vitalyd at gmail.com>> wrote:
>>
>>         Relocating these methods to a "proper" JDK class will imply that it's
>>         ok to use them in normal operation, which I don't think is the case
>>         and hence, to me, unsafe sounds like the right place.
>>
>>     It should probably be java.lang.Unsafe instead of sun.misc.Unsafe though
>
>     They are as unsafe as calling tryLock() and unlock() on a Lock,
>     so they can be in j.l.Thread as static methods.
>
>>
>>         Why not have the 3rd party fix their code? I realize that won't help
>>         in the immediate situation, but that's actually the right solution here.
>>
>>         $.02
>>
>>         Vitaly
>>
>
>     R?mi
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gregg at cytetech.com  Mon Nov 28 11:02:53 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 28 Nov 2011 10:02:53 -0600
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
Message-ID: <4ED3B0AD.1040109@cytetech.com>

On 11/28/2011 9:10 AM, Vitaly Davidovich wrote:
> Difference is that locks were designed with tryXXX upfront whereas synch block
> was not, as David pointed out its missing some things.  Therefore, what you're
> proposing would encourage (or at least not discourage) a feature that wasn't
> meant for wide public consumption, irrespective if it's "safe" or not.

IDEs warn about the use of Object.wait() in loops because the can create 
"forever" problems.  Object.wait(int) is always suggested, just to wake up the 
thread and attempt forward progress.

As a general rule of thumb, "polling for completion", is something that Java 
APIs have done quite pervasively, and in this day and age, the call back model 
is often a better choice because it provides thread context control to the 
calling thread so that the person writing the called code doesn't have to know 
what thread context applies.

Providing these methods, for me, just maintains the "polling" mentality, but can 
also provide some relief for developers having to deal with this kind of 
"broken" code.  Like lock()/trylock()/unlock(), it does create the ability for 
developers to make errors in how locking is applied if they miss an exit from a 
lock()/trylock() environment and thus miss the unlock().  But, I think that is a 
small pill to swallow compared to having to "give up" because some old crufty 
code is "polling" for completion status.

Gregg

> On Nov 28, 2011 10:01 AM, "R?mi Forax" <forax at univ-mlv.fr
> <mailto:forax at univ-mlv.fr>> wrote:
>
>     On 11/28/2011 03:35 PM, ?iktor ?lang wrote:
>>
>>
>>     On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com
>>     <mailto:vitalyd at gmail.com>> wrote:
>>
>>         Relocating these methods to a "proper" JDK class will imply that it's
>>         ok to use them in normal operation, which I don't think is the case
>>         and hence, to me, unsafe sounds like the right place.
>>
>>     It should probably be java.lang.Unsafe instead of sun.misc.Unsafe though
>
>     They are as unsafe as calling tryLock() and unlock() on a Lock,
>     so they can be in j.l.Thread as static methods.
>
>>
>>         Why not have the 3rd party fix their code? I realize that won't help
>>         in the immediate situation, but that's actually the right solution here.
>>
>>         $.02
>>
>>         Vitaly
>>
>
>     R?mi
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gregg at cytetech.com  Mon Nov 28 11:01:34 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 28 Nov 2011 10:01:34 -0600
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
Message-ID: <4ED3B05E.6020806@cytetech.com>

On 11/28/2011 9:10 AM, Vitaly Davidovich wrote:
> Difference is that locks were designed with tryXXX upfront whereas synch block
> was not, as David pointed out its missing some things.  Therefore, what you're
> proposing would encourage (or at least not discourage) a feature that wasn't
> meant for wide public consumption, irrespective if it's "safe" or not.

IDEs warn about the use of Object.wait() in loops because the can create 
"forever" problems.  Object.wait(int) is always suggested, just to wake up the 
thread and attempt forward progress.

As a general rule of thumb, "polling for completion", is something that Java 
APIs have done quite pervasively, and in this day and age, the call back model 
is often a better choice because it provides thread context control to the 
calling thread so that the person writing the called code doesn't have to know 
what thread context applies.

Providing these methods, for me, just maintains the "polling" mentality, but can 
also provide some relief for developers having to deal with this kind of 
"broken" code.  Like lock()/trylock()/unlock(), it does create the ability for 
developers to make errors in how locking is applied if they miss an exit from a 
lock()/trylock() environment and thus miss the unlock().  But, I think that is a 
small pill to swallow compared to having to "give up" because some old crufty 
code is "polling" for completion status.

Gregg

> On Nov 28, 2011 10:01 AM, "R?mi Forax" <forax at univ-mlv.fr
> <mailto:forax at univ-mlv.fr>> wrote:
>
>     On 11/28/2011 03:35 PM, ?iktor ?lang wrote:
>>
>>
>>     On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com
>>     <mailto:vitalyd at gmail.com>> wrote:
>>
>>         Relocating these methods to a "proper" JDK class will imply that it's
>>         ok to use them in normal operation, which I don't think is the case
>>         and hence, to me, unsafe sounds like the right place.
>>
>>     It should probably be java.lang.Unsafe instead of sun.misc.Unsafe though
>
>     They are as unsafe as calling tryLock() and unlock() on a Lock,
>     so they can be in j.l.Thread as static methods.
>
>>
>>         Why not have the 3rd party fix their code? I realize that won't help
>>         in the immediate situation, but that's actually the right solution here.
>>
>>         $.02
>>
>>         Vitaly
>>
>
>     R?mi
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From vitalyd at gmail.com  Mon Nov 28 11:44:16 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 11:44:16 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4ED3B09A.6000200@cytetech.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
	<4ED3B09A.6000200@cytetech.com>
Message-ID: <CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>

I don't have strong feelings on this as I wouldn't be the one making the
change :), but my point is that this functionality *is* available for the
rare occasion that it's needed, it's just "harder" to get at and discover
than if it were in j.l.Thread (or similar).  Since it's available (unless a
sec mgr prevents reflection) I personally don't see a good reason to move
it to a common JDK class to support broken code.
On Nov 28, 2011 11:04 AM, "Gregg Wonderly" <gregg at cytetech.com> wrote:

> On 11/28/2011 9:10 AM, Vitaly Davidovich wrote:
>
>> Difference is that locks were designed with tryXXX upfront whereas synch
>> block
>> was not, as David pointed out its missing some things.  Therefore, what
>> you're
>> proposing would encourage (or at least not discourage) a feature that
>> wasn't
>> meant for wide public consumption, irrespective if it's "safe" or not.
>>
>
> IDEs warn about the use of Object.wait() in loops because the can create
> "forever" problems.  Object.wait(int) is always suggested, just to wake up
> the thread and attempt forward progress.
>
> As a general rule of thumb, "polling for completion", is something that
> Java APIs have done quite pervasively, and in this day and age, the call
> back model is often a better choice because it provides thread context
> control to the calling thread so that the person writing the called code
> doesn't have to know what thread context applies.
>
> Providing these methods, for me, just maintains the "polling" mentality,
> but can also provide some relief for developers having to deal with this
> kind of "broken" code.  Like lock()/trylock()/unlock(), it does create the
> ability for developers to make errors in how locking is applied if they
> miss an exit from a lock()/trylock() environment and thus miss the
> unlock().  But, I think that is a small pill to swallow compared to having
> to "give up" because some old crufty code is "polling" for completion
> status.
>
> Gregg
>
>  On Nov 28, 2011 10:01 AM, "R?mi Forax" <forax at univ-mlv.fr
>> <mailto:forax at univ-mlv.fr>> wrote:
>>
>>    On 11/28/2011 03:35 PM, ?iktor ?lang wrote:
>>
>>>
>>>
>>>    On Mon, Nov 28, 2011 at 3:24 PM, Vitaly Davidovich <vitalyd at gmail.com
>>>    <mailto:vitalyd at gmail.com>> wrote:
>>>
>>>        Relocating these methods to a "proper" JDK class will imply that
>>> it's
>>>        ok to use them in normal operation, which I don't think is the
>>> case
>>>        and hence, to me, unsafe sounds like the right place.
>>>
>>>    It should probably be java.lang.Unsafe instead of sun.misc.Unsafe
>>> though
>>>
>>
>>    They are as unsafe as calling tryLock() and unlock() on a Lock,
>>    so they can be in j.l.Thread as static methods.
>>
>>
>>>        Why not have the 3rd party fix their code? I realize that won't
>>> help
>>>        in the immediate situation, but that's actually the right
>>> solution here.
>>>
>>>        $.02
>>>
>>>        Vitaly
>>>
>>>
>>    R?mi
>>
>>
>>    ______________________________**_________________
>>    Concurrency-interest mailing list
>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu><mailto:
>> Concurrency-interest@**cs.oswego.edu <Concurrency-interest at cs.oswego.edu>
>> >
>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/1cc7f5f7/attachment-0001.html>

From hans.boehm at hp.com  Mon Nov 28 14:05:33 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 28 Nov 2011 19:05:33 +0000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEJDJBAA.davidcholmes@aapt.net.au>
References: <A3E67C2071F49C4CBC4F17E6D77CDDD20CBFA2@G4W3299.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCOEJDJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC2F8@G4W3299.americas.hpqcorp.net>

> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> 
> Hi Hans,
> 
> Hans Boehm writes:
> > How is the method table pointer any different from any other final
> > field here?  This code looks like the fence is not generated if the
> > method table pointer is written, but there are no other final fields.
> > I can't at the moment think of a way to defend that choice.
> 
> A Java object contains a reference to its class, which in turn holds the vtable
> pointer. That class reference may be stored using "release semantics". I say
> "may" because the code is somewhat complex and its hard to know exactly
> what paths will be executed just be reading the code.
Thanks for the answer, but I remain confused.  Consider a weakly-ordered platform like ARM or PowerPC, and the allocation of an object p containing no final fields.  The generated sequence seems to look something like (in C syntax):

p = pointer_to_newly_allocated_memory;
p -> class_ptr = ptr_to_class;  // release operation ensures that prior accesses become visible earlier
maybe other initialization;
// p is ready to use

Assume this is done in thread 1, where user code then stores p into a global q, and thread 2 calls q -> foo() (which involves a racy read of q).  I see nothing ensuring that the store to p -> class becomes visible before the store to q.  Using a release store for the first one only orders it after preceding accesses, such as the initialization of the class object.  Without such ordering,  thread 2 can see the updated value of q, without seeing the correct class_ptr value, potentially resulting in many serious problems.

Or did you mean that there is another, separate, fence AFTER the class_ptr assignment?  That works, but it seems to me that should often be combinable with the one for final fields?

> 
> From a practical perspective this is only an issue for non-TSO systems when
> the object reference is subject to unsafe publication. Even for non-TSO
> systems the "distance" between the two stores makes it unlikely (and no I
> can't quantify that) they will be reordered.
True, but relying on the latter seems like a really bad idea.  I suspect that if this is really implemented incorrectly, the main reason nobody has noticed is that, like all these things, it works just fine in the absence of data races, which people already correctly avoid most of the time.

I'm pushing on this a bit, because I'm trying to understand exactly how broken the memory model story currently is in the presence of data races.  The more broken or needlessly expensive it is, the better our chances of making a drastic change to fix things :-)

> 
> The constructor executes after that, so any final field assignments there
> need their own release barrier.
I don't think that's the right way to think about it.  Turning the field assignments into release stores doesn't help.  You need to turn the racing publication (the assignment to q in the example) into a release store, but that publication may be very far away from the class_ptr or final field assignments.  I don't see a way to do this except with an essentially unconditional fence (lwsync on PowerPC) at the end of the constructor, and if you can't preclude unsafe publication, probably another one after the class_ptr store.

Hans


From hans.boehm at hp.com  Mon Nov 28 14:23:07 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 28 Nov 2011 19:23:07 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
	<4ED3B09A.6000200@cytetech.com>
	<CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>

There's another problem with tryLock()-like methods, which I pointed out in a 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not correctly specified.  The problem is illustrated by the following badly designed code:

Thread 1:
x = 17;
l.lock();

Thread 2:
while (l.tryLock()) l.unlock();
... x ...  // x should be 17 here!

Effectively this inverts the sense of the lock.  Thread 2 can only proceed after thread 1 acquires the lock.

The problem is that:

- There are no potentially concurrent accesses to x in a sequentially consistent execution of this code, and hence there should be no data races
- The Java memory model does not in fact guarantee that x is 17 in thread 2, because there is a data race by Java memory model definitions.  This race is too hard to explain.
- In order to ensure that x is actually 17, we would need to prevent reordering of the two lines of thread 1.  This is expensive on something like PowerPC, and doesn't benefit well-written code.

A solution, more or less adopted by C++11, is to specify tryLock() as allowing spurious failures, even though the implementation really doesn't.  That has the benefit that it makes it clear why there is a race for code like the above, and it provides an intuitive explanation of which tryLock() uses are really safe, and which are not.

Hans



From david.lloyd at redhat.com  Mon Nov 28 14:49:17 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Mon, 28 Nov 2011 13:49:17 -0600
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
	<4ED3B09A.6000200@cytetech.com>
	<CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
Message-ID: <4ED3E5BD.10707@redhat.com>

On 11/28/2011 01:23 PM, Boehm, Hans wrote:
> There's another problem with tryLock()-like methods, which I pointed out in a 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not correctly specified.  The problem is illustrated by the following badly designed code:
>
> Thread 1:
> x = 17;
> l.lock();
>
> Thread 2:
> while (l.tryLock()) l.unlock();
> ... x ...  // x should be 17 here!
>
> Effectively this inverts the sense of the lock.  Thread 2 can only proceed after thread 1 acquires the lock.
>
> The problem is that:
>
> - There are no potentially concurrent accesses to x in a sequentially consistent execution of this code, and hence there should be no data races
> - The Java memory model does not in fact guarantee that x is 17 in thread 2, because there is a data race by Java memory model definitions.  This race is too hard to explain.
> - In order to ensure that x is actually 17, we would need to prevent reordering of the two lines of thread 1.  This is expensive on something like PowerPC, and doesn't benefit well-written code.

I'd say that an even more basic problem is that if thread 1 locked and 
unlocked quickly enough, and the scheduling fell out just right, thread 
2 would never even notice that thread 1 took the lock if it was 
unscheduled after its unlock and not rescheduled until after thread 1 
unlocked again.

I'm not sure this is a weakness in tryLock().  The user is making all 
kinds of faulty assumptions in this code.
-- 
- DML

From hans.boehm at hp.com  Mon Nov 28 15:27:40 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 28 Nov 2011 20:27:40 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4ED3E5BD.10707@redhat.com>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
	<4ED3B09A.6000200@cytetech.com>
	<CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
	<4ED3E5BD.10707@redhat.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC3A4@G4W3299.americas.hpqcorp.net>

> From: David M. Lloyd
> Sent: Monday, November 28, 2011 11:49 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
> 
> On 11/28/2011 01:23 PM, Boehm, Hans wrote:
> > There's another problem with tryLock()-like methods, which I pointed out
> in a 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not correctly
> specified.  The problem is illustrated by the following badly designed code:
> >
> > Thread 1:
> > x = 17;
> > l.lock();
> >
> > Thread 2:
> > while (l.tryLock()) l.unlock();
> > ... x ...  // x should be 17 here!
> >
> > Effectively this inverts the sense of the lock.  Thread 2 can only proceed
> after thread 1 acquires the lock.
> >
> > The problem is that:
> >
> > - There are no potentially concurrent accesses to x in a sequentially
> > consistent execution of this code, and hence there should be no data
> > races
> > - The Java memory model does not in fact guarantee that x is 17 in thread 2,
> because there is a data race by Java memory model definitions.  This race is
> too hard to explain.
> > - In order to ensure that x is actually 17, we would need to prevent
> reordering of the two lines of thread 1.  This is expensive on something like
> PowerPC, and doesn't benefit well-written code.
> 
> I'd say that an even more basic problem is that if thread 1 locked and
> unlocked quickly enough, and the scheduling fell out just right, thread
> 2 would never even notice that thread 1 took the lock if it was unscheduled
> after its unlock and not rescheduled until after thread 1 unlocked again.
> 
> I'm not sure this is a weakness in tryLock().  The user is making all kinds of
> faulty assumptions in this code.
> --
I'm assuming that thread 1 never unlocks the lock l.  I agree this is not code you should write.  But the current specification suggests it should work.  It shouldn't.

Our experience with C++ is that this is not as esoteric a point as I once believed.  My initial hypothesis is that nobody would really write this kind of code.  However, once we allowed spurious failures for tryLock(), we got pushback from several sources, and they all came with real examples that either would actually fail with what I presume to be the standard PowerPC implementation, or were prone to subsequent innocuous-looking changes that would have subjected them to such failures.  They all came from experts, and looked much less ridiculous than the toy example above, though I still believe they all should have used atomics instead.  But I'm convinced that it's important to get this part of the spec right.

And this is a lousy reason to have to explain to beginners that Java's notion of data race is ALMOST what you would expect, but there are these weird cases in which operations that can't execute concurrently can race, and if you're going to use tryLock you really need to understand this happens-before stuff instead.

Hans


From dl at cs.oswego.edu  Mon Nov 28 15:34:04 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 28 Nov 2011 15:34:04 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>	<4ED3A056.2080909@univ-mlv.fr>	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>	<4ED3B09A.6000200@cytetech.com>	<CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
Message-ID: <4ED3F03C.1040300@cs.oswego.edu>

On 11/28/11 14:23, Boehm, Hans wrote:
> There's another problem with tryLock()-like methods, which I pointed out in a
> 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not correctly
> specified.  The problem is illustrated by the following badly designed code:
>
> Thread 1: x = 17; l.lock();
>
> Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be 17 here!
>
>
> A solution, more or less adopted by C++11, is to specify tryLock() as
> allowing spurious failures,

I think we are OK on this. The Lock spec defines tryLock in terms
of the lock being "available", which means different things
across different Lock implementations, and doesn't rule out
spurious false returns.

While I'm at it... Sorry to be too swamped to reply lately,
but here are a few quick comments on recent postings:

* I agree that store fences for object headers are normally
needed in constructors on ARM/POWER, and that they might as
well be piggybacked with those for final fields, but I don't
think implementations currently explicitly do so.

* I also agree that narrowly-targeted native STM support might
be worth  pursuing but not a high priority.

* I still don't know of a way to make AtomicReferenceFieldUpdaters
as fast as raw Unsafe. As long as there is any performance difference
at all, some people will use Unsafe.

-Doug

From davidcholmes at aapt.net.au  Mon Nov 28 18:11:18 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 29 Nov 2011 09:11:18 +1000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC2F8@G4W3299.americas.hpqcorp.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEJIJBAA.davidcholmes@aapt.net.au>

Hans,

I may be mixing terminology here so let me clarify, when I say "release" I'm
assuming an action such that given:

p = x;
release();
q = y;

then if you see q==y you are guaranteed to see p==x. Depending on the
platform release() may need to be a full memory synchronization instruction,
or a no-op.

In terms of the object allocation issue, constructing an object is a two
stage process even at the bytecode level:
- allocate the object
- invoke the constructor

So logically we need the following sequence:

- allocate (and zero) memory
- initialize object header etc
- release()
- invoke constructor
- if (wrote_final_field)
     release();

we need the release() after the object header initialization because at that
point the object can become visible to the GC and so must be seen to be
valid.

Now the JIT could inline all the above and maybe figure out how to remove
one release(), but presently in hotspot the allocation and construction
paths are quite distinct.

As release() is a no-op on x86 and sparc, you will not find explicit
release() actions in all of the current hotspot code paths - something we
will look at fixing.

David
-----

> -----Original Message-----
> From: Boehm, Hans [mailto:hans.boehm at hp.com]
> Sent: Tuesday, 29 November 2011 5:06 AM
> To: dholmes at ieee.org; Andrew Haley; Nathan Reynolds
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] The JSR-133 Cookbook for Compiler
> Writers
>
>
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> >
> > Hi Hans,
> >
> > Hans Boehm writes:
> > > How is the method table pointer any different from any other final
> > > field here?  This code looks like the fence is not generated if the
> > > method table pointer is written, but there are no other final fields.
> > > I can't at the moment think of a way to defend that choice.
> >
> > A Java object contains a reference to its class, which in turn
> holds the vtable
> > pointer. That class reference may be stored using "release
> semantics". I say
> > "may" because the code is somewhat complex and its hard to know exactly
> > what paths will be executed just be reading the code.
> Thanks for the answer, but I remain confused.  Consider a
> weakly-ordered platform like ARM or PowerPC, and the allocation
> of an object p containing no final fields.  The generated
> sequence seems to look something like (in C syntax):
>
> p = pointer_to_newly_allocated_memory;
> p -> class_ptr = ptr_to_class;  // release operation ensures that
> prior accesses become visible earlier
> maybe other initialization;
> // p is ready to use
>
> Assume this is done in thread 1, where user code then stores p
> into a global q, and thread 2 calls q -> foo() (which involves a
> racy read of q).  I see nothing ensuring that the store to p ->
> class becomes visible before the store to q.  Using a release
> store for the first one only orders it after preceding accesses,
> such as the initialization of the class object.  Without such
> ordering,  thread 2 can see the updated value of q, without
> seeing the correct class_ptr value, potentially resulting in many
> serious problems.
>
> Or did you mean that there is another, separate, fence AFTER the
> class_ptr assignment?  That works, but it seems to me that should
> often be combinable with the one for final fields?
>
> >
> > From a practical perspective this is only an issue for non-TSO
> systems when
> > the object reference is subject to unsafe publication. Even for non-TSO
> > systems the "distance" between the two stores makes it unlikely
> (and no I
> > can't quantify that) they will be reordered.
> True, but relying on the latter seems like a really bad idea.  I
> suspect that if this is really implemented incorrectly, the main
> reason nobody has noticed is that, like all these things, it
> works just fine in the absence of data races, which people
> already correctly avoid most of the time.
>
> I'm pushing on this a bit, because I'm trying to understand
> exactly how broken the memory model story currently is in the
> presence of data races.  The more broken or needlessly expensive
> it is, the better our chances of making a drastic change to fix things :-)
>
> >
> > The constructor executes after that, so any final field
> assignments there
> > need their own release barrier.
> I don't think that's the right way to think about it.  Turning
> the field assignments into release stores doesn't help.  You need
> to turn the racing publication (the assignment to q in the
> example) into a release store, but that publication may be very
> far away from the class_ptr or final field assignments.  I don't
> see a way to do this except with an essentially unconditional
> fence (lwsync on PowerPC) at the end of the constructor, and if
> you can't preclude unsafe publication, probably another one after
> the class_ptr store.
>
> Hans
>


From hans.boehm at hp.com  Mon Nov 28 20:20:31 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 29 Nov 2011 01:20:31 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4ED3F03C.1040300@cs.oswego.edu>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
	<4ED3B09A.6000200@cytetech.com>
	<CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
	<4ED3F03C.1040300@cs.oswego.edu>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC60E@G4W3299.americas.hpqcorp.net>

> From: Doug Lea
> 
> On 11/28/11 14:23, Boehm, Hans wrote:
> > There's another problem with tryLock()-like methods, which I pointed
> out in a
> > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
> correctly
> > specified.  The problem is illustrated by the following badly
> designed code:
> >
> > Thread 1: x = 17; l.lock();
> >
> > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
> 17 here!
> >
> >
> > A solution, more or less adopted by C++11, is to specify tryLock() as
> > allowing spurious failures,
> 
> I think we are OK on this. The Lock spec defines tryLock in terms
> of the lock being "available", which means different things
> across different Lock implementations, and doesn't rule out
> spurious false returns.
That interpretation sounds good to me.  It does mean that a lock that was constructed before the tryLock call and has never been accessed by anything else might not be "available".

Hans


From vitalyd at gmail.com  Mon Nov 28 21:29:56 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 21:29:56 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC60E@G4W3299.americas.hpqcorp.net>
References: <CABWgujbWovJhp3-hYSO89U3erHRSEAp7+PoG--NBjEZuuq3ZaQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJCJBAA.davidcholmes@aapt.net.au>
	<CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<CAHjP37GP_7D+JFmH4x78QjVrv2oYfhz5gAiVjHsWM+OcT_Ze8w@mail.gmail.com>
	<CANPzfU-9He8Fh=fvbL-MNJ_++YHyb+PhEcNxcgk2Cuq6BvOA5Q@mail.gmail.com>
	<4ED3A056.2080909@univ-mlv.fr>
	<CAHjP37FwCKAusjzLRaftk2TnCP9JypYhFra5WurqLQw_tmbfZQ@mail.gmail.com>
	<4ED3B09A.6000200@cytetech.com>
	<CAHjP37Hk3M=htEFc_3X8YQrLHX2onu4LOWa1EnjfNo06xK_V4Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC323@G4W3299.americas.hpqcorp.net>
	<4ED3F03C.1040300@cs.oswego.edu>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC60E@G4W3299.americas.hpqcorp.net>
Message-ID: <CAHjP37FvMv0zNNAzftBoaSsf3aywOtU-DFV9Do6-_P-o1tBKVQ@mail.gmail.com>

Hi Hans,

In your example why do you say that x should be 17 (or rather, why would
someone assume that)? If thread one writes to x but gets descheduled before
locking, then clearly thread 2 is not guaranteed to read 17; how is this
different from if instead of using a lock, a volatile y was used?

If thread 1 did lock before tryLock in thread 2 then the store to a
volatile inside lock and a read of that volatile in tryLock should be
sufficient to create the happens-before edge.

I must be missing your point though.

Thanks
On Nov 28, 2011 8:23 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

> > From: Doug Lea
> >
> > On 11/28/11 14:23, Boehm, Hans wrote:
> > > There's another problem with tryLock()-like methods, which I pointed
> > out in a
> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
> > correctly
> > > specified.  The problem is illustrated by the following badly
> > designed code:
> > >
> > > Thread 1: x = 17; l.lock();
> > >
> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
> > 17 here!
> > >
> > >
> > > A solution, more or less adopted by C++11, is to specify tryLock() as
> > > allowing spurious failures,
> >
> > I think we are OK on this. The Lock spec defines tryLock in terms
> > of the lock being "available", which means different things
> > across different Lock implementations, and doesn't rule out
> > spurious false returns.
> That interpretation sounds good to me.  It does mean that a lock that was
> constructed before the tryLock call and has never been accessed by anything
> else might not be "available".
>
> Hans
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/1cc08b43/attachment.html>

From davidcholmes at aapt.net.au  Mon Nov 28 21:39:39 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 29 Nov 2011 12:39:39 +1000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37FvMv0zNNAzftBoaSsf3aywOtU-DFV9Do6-_P-o1tBKVQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEJJJBAA.davidcholmes@aapt.net.au>

Vitaly,

Thread 2 only reads x if the lock is not available, which means thread 1
must have locked it, which occurs after setting x=17.

However in terms of happens-before, there is no HB edge here so no guarantee
of x being 17 AFAICS. Thread 2 has to acquire the lock after thread 1 to get
a HB edge that guarantees x == 17. Further, roach-motel tells us that x=17
could be reordered with the lock() anyway.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Vitaly
Davidovich
  Sent: Tuesday, 29 November 2011 12:30 PM
  To: Boehm, Hans
  Cc: Doug Lea; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe


  Hi Hans,

  In your example why do you say that x should be 17 (or rather, why would
someone assume that)? If thread one writes to x but gets descheduled before
locking, then clearly thread 2 is not guaranteed to read 17; how is this
different from if instead of using a lock, a volatile y was used?

  If thread 1 did lock before tryLock in thread 2 then the store to a
volatile inside lock and a read of that volatile in tryLock should be
sufficient to create the happens-before edge.

  I must be missing your point though.

  Thanks

  On Nov 28, 2011 8:23 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

    > From: Doug Lea
    >
    > On 11/28/11 14:23, Boehm, Hans wrote:
    > > There's another problem with tryLock()-like methods, which I pointed
    > out in a
    > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
    > correctly
    > > specified.  The problem is illustrated by the following badly
    > designed code:
    > >
    > > Thread 1: x = 17; l.lock();
    > >
    > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
    > 17 here!
    > >
    > >
    > > A solution, more or less adopted by C++11, is to specify tryLock()
as
    > > allowing spurious failures,
    >
    > I think we are OK on this. The Lock spec defines tryLock in terms
    > of the lock being "available", which means different things
    > across different Lock implementations, and doesn't rule out
    > spurious false returns.
    That interpretation sounds good to me.  It does mean that a lock that
was constructed before the tryLock call and has never been accessed by
anything else might not be "available".

    Hans

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/ca480d5e/attachment.html>

From vitalyd at gmail.com  Mon Nov 28 21:48:42 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 21:48:42 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEJJJBAA.davidcholmes@aapt.net.au>
References: <CAHjP37FvMv0zNNAzftBoaSsf3aywOtU-DFV9Do6-_P-o1tBKVQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEJJJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>

Yes I realized that I misread the snippet right after I sent the email -
thanks though :).

However doing a tryLock will entail reading a volatile that was set during
lock, so shouldn't that provide the HB? Granted I'm talking about a
specific impl in the JDK.

I don't see how roach motel applies here since the lock() writes a volatile
and prior stores can't reorder with it (subsequent ones can move in though).
On Nov 28, 2011 9:39 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> **
> Vitaly,
>
> Thread 2 only reads x if the lock is not available, which means thread 1
> must have locked it, which occurs after setting x=17.
>
> However in terms of happens-before, there is no HB edge here so no
> guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
> thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
> tells us that x=17 could be reordered with the lock() anyway.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
> Davidovich
> *Sent:* Tuesday, 29 November 2011 12:30 PM
> *To:* Boehm, Hans
> *Cc:* Doug Lea; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
> Unsafe
>
> Hi Hans,
>
> In your example why do you say that x should be 17 (or rather, why would
> someone assume that)? If thread one writes to x but gets descheduled before
> locking, then clearly thread 2 is not guaranteed to read 17; how is this
> different from if instead of using a lock, a volatile y was used?
>
> If thread 1 did lock before tryLock in thread 2 then the store to a
> volatile inside lock and a read of that volatile in tryLock should be
> sufficient to create the happens-before edge.
>
> I must be missing your point though.
>
> Thanks
> On Nov 28, 2011 8:23 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:
>
>> > From: Doug Lea
>> >
>> > On 11/28/11 14:23, Boehm, Hans wrote:
>> > > There's another problem with tryLock()-like methods, which I pointed
>> > out in a
>> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
>> > correctly
>> > > specified.  The problem is illustrated by the following badly
>> > designed code:
>> > >
>> > > Thread 1: x = 17; l.lock();
>> > >
>> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
>> > 17 here!
>> > >
>> > >
>> > > A solution, more or less adopted by C++11, is to specify tryLock() as
>> > > allowing spurious failures,
>> >
>> > I think we are OK on this. The Lock spec defines tryLock in terms
>> > of the lock being "available", which means different things
>> > across different Lock implementations, and doesn't rule out
>> > spurious false returns.
>> That interpretation sounds good to me.  It does mean that a lock that was
>> constructed before the tryLock call and has never been accessed by anything
>> else might not be "available".
>>
>> Hans
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/e6a5d844/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Nov 28 21:57:35 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 29 Nov 2011 12:57:35 +1000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>

The HB edge only arises between an unlock and subsequent lock. Here there is
no unlock  in T1 and hence no subsequent lock in T2 and so no HB. (Which is
not to say that the necessary memory barriers have not been issued as a
side-effect of other things - but there is no HB edge as per the JMM).

lock() has acquire semantics as does volatile read, hence regular
load/stores can move past them. So here:

x = 17;
l.lock();

can become

l.lock();
x = 17;

which in this case just makes it more likely that T2 would in practice see
17.

David
  -----Original Message-----
  From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
  Sent: Tuesday, 29 November 2011 12:49 PM
  To: dholmes at ieee.org
  Cc: Boehm, Hans; concurrency-interest at cs.oswego.edu; Doug Lea
  Subject: RE: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe


  Yes I realized that I misread the snippet right after I sent the email -
thanks though :).

  However doing a tryLock will entail reading a volatile that was set during
lock, so shouldn't that provide the HB? Granted I'm talking about a specific
impl in the JDK.

  I don't see how roach motel applies here since the lock() writes a
volatile and prior stores can't reorder with it (subsequent ones can move in
though).

  On Nov 28, 2011 9:39 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

    Vitaly,

    Thread 2 only reads x if the lock is not available, which means thread 1
must have locked it, which occurs after setting x=17.

    However in terms of happens-before, there is no HB edge here so no
guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
tells us that x=17 could be reordered with the lock() anyway.

    David
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Vitaly
Davidovich
      Sent: Tuesday, 29 November 2011 12:30 PM
      To: Boehm, Hans
      Cc: Doug Lea; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
Unsafe


      Hi Hans,

      In your example why do you say that x should be 17 (or rather, why
would someone assume that)? If thread one writes to x but gets descheduled
before locking, then clearly thread 2 is not guaranteed to read 17; how is
this different from if instead of using a lock, a volatile y was used?

      If thread 1 did lock before tryLock in thread 2 then the store to a
volatile inside lock and a read of that volatile in tryLock should be
sufficient to create the happens-before edge.

      I must be missing your point though.

      Thanks

      On Nov 28, 2011 8:23 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

        > From: Doug Lea
        >
        > On 11/28/11 14:23, Boehm, Hans wrote:
        > > There's another problem with tryLock()-like methods, which I
pointed
        > out in a
        > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
        > correctly
        > > specified.  The problem is illustrated by the following badly
        > designed code:
        > >
        > > Thread 1: x = 17; l.lock();
        > >
        > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should
be
        > 17 here!
        > >
        > >
        > > A solution, more or less adopted by C++11, is to specify
tryLock() as
        > > allowing spurious failures,
        >
        > I think we are OK on this. The Lock spec defines tryLock in terms
        > of the lock being "available", which means different things
        > across different Lock implementations, and doesn't rule out
        > spurious false returns.
        That interpretation sounds good to me.  It does mean that a lock
that was constructed before the tryLock call and has never been accessed by
anything else might not be "available".

        Hans

        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest at cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/67097c17/attachment.html>

From vitalyd at gmail.com  Mon Nov 28 22:08:00 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 22:08:00 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>

Ok I see - you're going by purely what JMM dictates.  In practice though I
can't imagine a lock() impl that won't issue a fence at some point
internally before the write.  Therefore I don't see how assignment to x can
move past it; the expanded lock would look something like:
- volatile load/acquire
...
- volatile write/cas/etc (assume lock succeeds, as in this example)
- x = 17

So I still don't understand how, in practice, x = 17 can move above the
lock.
 On Nov 28, 2011 9:57 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> **
> The HB edge only arises between an unlock and subsequent lock. Here there
> is no unlock  in T1 and hence no subsequent lock in T2 and so no HB. (Which
> is not to say that the necessary memory barriers have not been issued as a
> side-effect of other things - but there is no HB edge as per the JMM).
>
> lock() has acquire semantics as does volatile read, hence regular
> load/stores can move past them. So here:
>
> x = 17;
> l.lock();
>
> can become
>
> l.lock();
> x = 17;
>
> which in this case just makes it more likely that T2 would in practice see
> 17.
>
> David
>
> -----Original Message-----
> *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com]
> *Sent:* Tuesday, 29 November 2011 12:49 PM
> *To:* dholmes at ieee.org
> *Cc:* Boehm, Hans; concurrency-interest at cs.oswego.edu; Doug Lea
> *Subject:* RE: [concurrency-interest] AtomicReferenceFieldUpdater vs
> Unsafe
>
> Yes I realized that I misread the snippet right after I sent the email -
> thanks though :).
>
> However doing a tryLock will entail reading a volatile that was set during
> lock, so shouldn't that provide the HB? Granted I'm talking about a
> specific impl in the JDK.
>
> I don't see how roach motel applies here since the lock() writes a
> volatile and prior stores can't reorder with it (subsequent ones can move
> in though).
> On Nov 28, 2011 9:39 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:
>
>> **
>> Vitaly,
>>
>> Thread 2 only reads x if the lock is not available, which means thread 1
>> must have locked it, which occurs after setting x=17.
>>
>> However in terms of happens-before, there is no HB edge here so no
>> guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
>> thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
>> tells us that x=17 could be reordered with the lock() anyway.
>>
>> David
>>
>> -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
>> Davidovich
>> *Sent:* Tuesday, 29 November 2011 12:30 PM
>> *To:* Boehm, Hans
>> *Cc:* Doug Lea; concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
>> Unsafe
>>
>> Hi Hans,
>>
>> In your example why do you say that x should be 17 (or rather, why would
>> someone assume that)? If thread one writes to x but gets descheduled before
>> locking, then clearly thread 2 is not guaranteed to read 17; how is this
>> different from if instead of using a lock, a volatile y was used?
>>
>> If thread 1 did lock before tryLock in thread 2 then the store to a
>> volatile inside lock and a read of that volatile in tryLock should be
>> sufficient to create the happens-before edge.
>>
>> I must be missing your point though.
>>
>> Thanks
>> On Nov 28, 2011 8:23 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:
>>
>>> > From: Doug Lea
>>> >
>>> > On 11/28/11 14:23, Boehm, Hans wrote:
>>> > > There's another problem with tryLock()-like methods, which I pointed
>>> > out in a
>>> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
>>> > correctly
>>> > > specified.  The problem is illustrated by the following badly
>>> > designed code:
>>> > >
>>> > > Thread 1: x = 17; l.lock();
>>> > >
>>> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
>>> > 17 here!
>>> > >
>>> > >
>>> > > A solution, more or less adopted by C++11, is to specify tryLock() as
>>> > > allowing spurious failures,
>>> >
>>> > I think we are OK on this. The Lock spec defines tryLock in terms
>>> > of the lock being "available", which means different things
>>> > across different Lock implementations, and doesn't rule out
>>> > spurious false returns.
>>> That interpretation sounds good to me.  It does mean that a lock that
>>> was constructed before the tryLock call and has never been accessed by
>>> anything else might not be "available".
>>>
>>> Hans
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/00bdd353/attachment-0001.html>

From joe.bowbeer at gmail.com  Mon Nov 28 22:39:39 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 28 Nov 2011 19:39:39 -0800
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
	<CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
Message-ID: <CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>

On Mon, Nov 28, 2011 at 7:08 PM, Vitaly Davidovich wrote:

> Ok I see - you're going by purely what JMM dictates.  In practice though I
> can't imagine a lock() impl that won't issue a fence at some point
> internally before the write.  Therefore I don't see how assignment to x can
> move past it; the expanded lock would look something like:
> - volatile load/acquire
> ...
> - volatile write/cas/etc (assume lock succeeds, as in this example)
> - x = 17
>
> So I still don't understand how, in practice, x = 17 can move above the
> lock.
>

According to the "roach motel" semantics for critical sections, x=17 can
move after the lock in Thread 1, into the "critical section", but it can
never leave the critical section by moving past the unlock.  This is a
transformation that the JIT compiler might perform.

Except in this case there is no unlock in Thread 1...


>  On Nov 28, 2011 9:57 PM, "David Holmes" wrote:
>
>> **
>> The HB edge only arises between an unlock and subsequent lock. Here there
>> is no unlock  in T1 and hence no subsequent lock in T2 and so no HB. (Which
>> is not to say that the necessary memory barriers have not been issued as a
>> side-effect of other things - but there is no HB edge as per the JMM).
>>
>> lock() has acquire semantics as does volatile read, hence regular
>> load/stores can move past them. So here:
>>
>> x = 17;
>> l.lock();
>>
>> can become
>>
>> l.lock();
>> x = 17;
>>
>> which in this case just makes it more likely that T2 would in practice
>> see 17.
>>
>> David
>>
>> -----Original Message-----
>> *From:* Vitaly Davidovich
>> *Sent:* Tuesday, 29 November 2011 12:49 PM
>> *To: *David Holmes
>> *Cc:* Boehm, Hans; concurrency-interest at cs.oswego.edu; Doug Lea
>> *Subject:* RE: [concurrency-interest] AtomicReferenceFieldUpdater vs
>> Unsafe
>>
>> Yes I realized that I misread the snippet right after I sent the email -
>> thanks though :).
>>
>> However doing a tryLock will entail reading a volatile that was set
>> during lock, so shouldn't that provide the HB? Granted I'm talking about a
>> specific impl in the JDK.
>>
>> I don't see how roach motel applies here since the lock() writes a
>> volatile and prior stores can't reorder with it (subsequent ones can move
>> in though).
>> On Nov 28, 2011 9:39 PM, "David Holmes" wrote:
>>
>>> **
>>> Vitaly,
>>>
>>> Thread 2 only reads x if the lock is not available, which means thread 1
>>> must have locked it, which occurs after setting x=17.
>>>
>>> However in terms of happens-before, there is no HB edge here so no
>>> guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
>>> thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
>>> tells us that x=17 could be reordered with the lock() anyway.
>>>
>>> David
>>>
>>> -----Original Message-----
>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
>>> Davidovich
>>> *Sent:* Tuesday, 29 November 2011 12:30 PM
>>> *To:* Boehm, Hans
>>> *Cc:* Doug Lea; concurrency-interest at cs.oswego.edu
>>> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
>>> Unsafe
>>>
>>> Hi Hans,
>>>
>>> In your example why do you say that x should be 17 (or rather, why would
>>> someone assume that)? If thread one writes to x but gets descheduled before
>>> locking, then clearly thread 2 is not guaranteed to read 17; how is this
>>> different from if instead of using a lock, a volatile y was used?
>>>
>>> If thread 1 did lock before tryLock in thread 2 then the store to a
>>> volatile inside lock and a read of that volatile in tryLock should be
>>> sufficient to create the happens-before edge.
>>>
>>> I must be missing your point though.
>>>
>>> Thanks
>>> On Nov 28, 2011 8:23 PM, "Boehm, Hans" wrote:
>>>
>>>> > From: Doug Lea
>>>> >
>>>> > On 11/28/11 14:23, Boehm, Hans wrote:
>>>> > > There's another problem with tryLock()-like methods, which I pointed
>>>> > out in a
>>>> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
>>>> > correctly
>>>> > > specified.  The problem is illustrated by the following badly
>>>> > designed code:
>>>> > >
>>>> > > Thread 1: x = 17; l.lock();
>>>> > >
>>>> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
>>>> > 17 here!
>>>> > >
>>>> > >
>>>> > > A solution, more or less adopted by C++11, is to specify tryLock()
>>>> as
>>>> > > allowing spurious failures,
>>>> >
>>>> > I think we are OK on this. The Lock spec defines tryLock in terms
>>>> > of the lock being "available", which means different things
>>>> > across different Lock implementations, and doesn't rule out
>>>> > spurious false returns.
>>>> That interpretation sounds good to me.  It does mean that a lock that
>>>> was constructed before the tryLock call and has never been accessed by
>>>> anything else might not be "available".
>>>>
>>>> Hans
>>>>
>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/bed5fe0f/attachment.html>

From vitalyd at gmail.com  Mon Nov 28 23:01:43 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Nov 2011 23:01:43 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
	<CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
	<CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>
Message-ID: <CAHjP37G1rnyNXHH+NFL1ADb36Hb6H=f6OjgULJim9hR9OVgGDQ@mail.gmail.com>

Joe,

If you forget about the notion of critical sections and such and just think
about what code will be emitted here (even at the bytecode level), there's
going to be a volatile write before the write to x; I can't see how the JIT
(or interpreter, for that matter) can re-arrange the code in that case.

The assignment of x can move after the volatile read which will occur
inside lock(), but it cannot reorder with the actual volatile store.  The
compiler doesn't know what lock() actually is -- it just sees the bytecodes
inside it (and whatever else it calls), so I don't see how things can be
rearranged.

Vitaly

On Mon, Nov 28, 2011 at 10:39 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> On Mon, Nov 28, 2011 at 7:08 PM, Vitaly Davidovich wrote:
>
>> Ok I see - you're going by purely what JMM dictates.  In practice though
>> I can't imagine a lock() impl that won't issue a fence at some point
>> internally before the write.  Therefore I don't see how assignment to x can
>> move past it; the expanded lock would look something like:
>> - volatile load/acquire
>> ...
>> - volatile write/cas/etc (assume lock succeeds, as in this example)
>> - x = 17
>>
>> So I still don't understand how, in practice, x = 17 can move above the
>> lock.
>>
>
> According to the "roach motel" semantics for critical sections, x=17 can
> move after the lock in Thread 1, into the "critical section", but it can
> never leave the critical section by moving past the unlock.  This is a
> transformation that the JIT compiler might perform.
>
> Except in this case there is no unlock in Thread 1...
>
>
>>  On Nov 28, 2011 9:57 PM, "David Holmes" wrote:
>>
>>> **
>>> The HB edge only arises between an unlock and subsequent lock. Here
>>> there is no unlock  in T1 and hence no subsequent lock in T2 and so no HB.
>>> (Which is not to say that the necessary memory barriers have not been
>>> issued as a side-effect of other things - but there is no HB edge as per
>>> the JMM).
>>>
>>> lock() has acquire semantics as does volatile read, hence regular
>>> load/stores can move past them. So here:
>>>
>>> x = 17;
>>> l.lock();
>>>
>>> can become
>>>
>>> l.lock();
>>> x = 17;
>>>
>>> which in this case just makes it more likely that T2 would in practice
>>> see 17.
>>>
>>> David
>>>
>>> -----Original Message-----
>>> *From:* Vitaly Davidovich
>>> *Sent:* Tuesday, 29 November 2011 12:49 PM
>>> *To: *David Holmes
>>>
>>> *Cc:* Boehm, Hans; concurrency-interest at cs.oswego.edu; Doug Lea
>>> *Subject:* RE: [concurrency-interest] AtomicReferenceFieldUpdater vs
>>> Unsafe
>>>
>>> Yes I realized that I misread the snippet right after I sent the email -
>>> thanks though :).
>>>
>>> However doing a tryLock will entail reading a volatile that was set
>>> during lock, so shouldn't that provide the HB? Granted I'm talking about a
>>> specific impl in the JDK.
>>>
>>> I don't see how roach motel applies here since the lock() writes a
>>> volatile and prior stores can't reorder with it (subsequent ones can move
>>> in though).
>>> On Nov 28, 2011 9:39 PM, "David Holmes" wrote:
>>>
>>>> **
>>>> Vitaly,
>>>>
>>>> Thread 2 only reads x if the lock is not available, which means thread
>>>> 1 must have locked it, which occurs after setting x=17.
>>>>
>>>> However in terms of happens-before, there is no HB edge here so no
>>>> guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
>>>> thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
>>>> tells us that x=17 could be reordered with the lock() anyway.
>>>>
>>>> David
>>>>
>>>> -----Original Message-----
>>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
>>>> Davidovich
>>>> *Sent:* Tuesday, 29 November 2011 12:30 PM
>>>> *To:* Boehm, Hans
>>>> *Cc:* Doug Lea; concurrency-interest at cs.oswego.edu
>>>> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
>>>> Unsafe
>>>>
>>>> Hi Hans,
>>>>
>>>> In your example why do you say that x should be 17 (or rather, why
>>>> would someone assume that)? If thread one writes to x but gets descheduled
>>>> before locking, then clearly thread 2 is not guaranteed to read 17; how is
>>>> this different from if instead of using a lock, a volatile y was used?
>>>>
>>>> If thread 1 did lock before tryLock in thread 2 then the store to a
>>>> volatile inside lock and a read of that volatile in tryLock should be
>>>> sufficient to create the happens-before edge.
>>>>
>>>> I must be missing your point though.
>>>>
>>>> Thanks
>>>> On Nov 28, 2011 8:23 PM, "Boehm, Hans" wrote:
>>>>
>>>>> > From: Doug Lea
>>>>> >
>>>>> > On 11/28/11 14:23, Boehm, Hans wrote:
>>>>> > > There's another problem with tryLock()-like methods, which I
>>>>> pointed
>>>>> > out in a
>>>>> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
>>>>> > correctly
>>>>> > > specified.  The problem is illustrated by the following badly
>>>>> > designed code:
>>>>> > >
>>>>> > > Thread 1: x = 17; l.lock();
>>>>> > >
>>>>> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
>>>>> > 17 here!
>>>>> > >
>>>>> > >
>>>>> > > A solution, more or less adopted by C++11, is to specify tryLock()
>>>>> as
>>>>> > > allowing spurious failures,
>>>>> >
>>>>> > I think we are OK on this. The Lock spec defines tryLock in terms
>>>>> > of the lock being "available", which means different things
>>>>> > across different Lock implementations, and doesn't rule out
>>>>> > spurious false returns.
>>>>> That interpretation sounds good to me.  It does mean that a lock that
>>>>> was constructed before the tryLock call and has never been accessed by
>>>>> anything else might not be "available".
>>>>>
>>>>> Hans
>>>>>
>>>>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111128/53d8abb5/attachment-0001.html>

From hans.boehm at hp.com  Mon Nov 28 23:36:05 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 29 Nov 2011 04:36:05 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37G1rnyNXHH+NFL1ADb36Hb6H=f6OjgULJim9hR9OVgGDQ@mail.gmail.com>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
	<CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
	<CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>
	<CAHjP37G1rnyNXHH+NFL1ADb36Hb6H=f6OjgULJim9hR9OVgGDQ@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC70E@G4W3299.americas.hpqcorp.net>

I see your point if the lock operation is implemented in terms of Java volatiles or atomics.  I don't think there is any guarantee that something like j.u.c.l.ReentrantLock is implemented that way.  Certainly that wasn't true for the basic MonitorEntry and Exit implementations for any of the JVMs that I have worked on in the past.  And there are architectures for which there is substantial benefit in using implementations that allow roach motel reordering across lock acquisitions.  This is true on Itanium, which provides a CAS instruction with only acquire semantics.  And I believe the same is true of the usual PowerPC lock acquisition sequence:  The CAS equivalent is unordered.  That is normally followed by a fence (typically isync, possibly lwsync) that prevents reordering of the lock acquisition with critical section operations.  But nothing prevents reordering of the CAS with prior operations.

I was originally responding to a thread arguing for a tryLock-like operation on built-in monitors.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Vitaly Davidovich
Sent: Monday, November 28, 2011 8:02 PM
To: Joe Bowbeer
Cc: concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Joe,

If you forget about the notion of critical sections and such and just think about what code will be emitted here (even at the bytecode level), there's going to be a volatile write before the write to x; I can't see how the JIT (or interpreter, for that matter) can re-arrange the code in that case.

The assignment of x can move after the volatile read which will occur inside lock(), but it cannot reorder with the actual volatile store.  The compiler doesn't know what lock() actually is -- it just sees the bytecodes inside it (and whatever else it calls), so I don't see how things can be rearranged.

Vitaly
On Mon, Nov 28, 2011 at 10:39 PM, Joe Bowbeer <joe.bowbeer at gmail.com<mailto:joe.bowbeer at gmail.com>> wrote:
On Mon, Nov 28, 2011 at 7:08 PM, Vitaly Davidovich wrote:

Ok I see - you're going by purely what JMM dictates.  In practice though I can't imagine a lock() impl that won't issue a fence at some point internally before the write.  Therefore I don't see how assignment to x can move past it; the expanded lock would look something like:
- volatile load/acquire
...
- volatile write/cas/etc (assume lock succeeds, as in this example)
- x = 17

So I still don't understand how, in practice, x = 17 can move above the lock.

According to the "roach motel" semantics for critical sections, x=17 can move after the lock in Thread 1, into the "critical section", but it can never leave the critical section by moving past the unlock.  This is a transformation that the JIT compiler might perform.

Except in this case there is no unlock in Thread 1...

On Nov 28, 2011 9:57 PM, "David Holmes" wrote:
The HB edge only arises between an unlock and subsequent lock. Here there is no unlock  in T1 and hence no subsequent lock in T2 and so no HB. (Which is not to say that the necessary memory barriers have not been issued as a side-effect of other things - but there is no HB edge as per the JMM).

lock() has acquire semantics as does volatile read, hence regular load/stores can move past them. So here:

x = 17;
l.lock();

can become

l.lock();
x = 17;

which in this case just makes it more likely that T2 would in practice see 17.

David
-----Original Message-----
From: Vitaly Davidovich
Sent: Tuesday, 29 November 2011 12:49 PM
To: David Holmes

Cc: Boehm, Hans; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>; Doug Lea
Subject: RE: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Yes I realized that I misread the snippet right after I sent the email - thanks though :).

However doing a tryLock will entail reading a volatile that was set during lock, so shouldn't that provide the HB? Granted I'm talking about a specific impl in the JDK.

I don't see how roach motel applies here since the lock() writes a volatile and prior stores can't reorder with it (subsequent ones can move in though).
On Nov 28, 2011 9:39 PM, "David Holmes" wrote:
Vitaly,

Thread 2 only reads x if the lock is not available, which means thread 1 must have locked it, which occurs after setting x=17.

However in terms of happens-before, there is no HB edge here so no guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel tells us that x=17 could be reordered with the lock() anyway.

David
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu>]On Behalf Of Vitaly Davidovich
Sent: Tuesday, 29 November 2011 12:30 PM
To: Boehm, Hans
Cc: Doug Lea; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Hi Hans,

In your example why do you say that x should be 17 (or rather, why would someone assume that)? If thread one writes to x but gets descheduled before locking, then clearly thread 2 is not guaranteed to read 17; how is this different from if instead of using a lock, a volatile y was used?

If thread 1 did lock before tryLock in thread 2 then the store to a volatile inside lock and a read of that volatile in tryLock should be sufficient to create the happens-before edge.

I must be missing your point though.

Thanks
On Nov 28, 2011 8:23 PM, "Boehm, Hans" wrote:
> From: Doug Lea
>
> On 11/28/11 14:23, Boehm, Hans wrote:
> > There's another problem with tryLock()-like methods, which I pointed
> out in a
> > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
> correctly
> > specified.  The problem is illustrated by the following badly
> designed code:
> >
> > Thread 1: x = 17; l.lock();
> >
> > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
> 17 here!
> >
> >
> > A solution, more or less adopted by C++11, is to specify tryLock() as
> > allowing spurious failures,
>
> I think we are OK on this. The Lock spec defines tryLock in terms
> of the lock being "available", which means different things
> across different Lock implementations, and doesn't rule out
> spurious false returns.
That interpretation sounds good to me.  It does mean that a lock that was constructed before the tryLock call and has never been accessed by anything else might not be "available".

Hans

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



--
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/052b529a/attachment.html>

From davidcholmes at aapt.net.au  Mon Nov 28 23:49:56 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 29 Nov 2011 14:49:56 +1000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJMJBAA.davidcholmes@aapt.net.au>

Re: Unsafe.tryMonitorEnter and Unsafe.monitorExit

So returning to the "are these truly unsafe" question the answer is: yes. At
least monitorExit is potentially unsafe.

Dave Dice reminded me (thanks Dave!) about the issue of having balanced
monitorEnter and monitorExit instructions and that monitors are always
released in the same stackframe in which they were acquired. The JVM takes
advantage of balanced monitor use to optimize locking - synchronized usage
is always balanced and JITs generate similarly balanced code, and if you mix
JVMTI locking/unlocking with synchronized then you are on your own. If you
use Unsafe.monitorExit in an unbalanced fashion then you might run into
problems.

If we were to make these a public API then we would have to account for
unbalanced use. That might mean either dropping all the optimizations that
rely on balanced use, or adding additional analysis to detect unbalanced use
and drop back to interpreted code in such cases. Either way that is a lot of
work (not to mention the timeout support) to accommodate an uncommon need
already satisfiable through Unsafe - in my opinion of course.

Cheers,
David


Hanson Char writes:
>
> Sorry I meant Unsafe#tryMonitorEnter and #monitorExit.  (I realized
> the mistake after sending out the email, but thought the context would
> self recover/make it clear :))
>
> > Can you expand on this.
>
> One practical (and critical) case I've come across is that under some
> extreme circumstances , a 3rd party database connection pool would get
> into a "stuck" state.  Doesn't happen often but it does happen.  When
> it did, any attempt to inspect the respective pool via JMX calling the
> getter methods for info such as the number of active/idle connections
> would cause the inspecting thread to get stuck.
>
> Looking into the code (of the third party library) it was clearly
> related to the use of synchronized methods, including the getter
> methods for the stats.
>
> Via Unsafe#tryMonitorEnter, the application was able to get some
> information out of the pool, and initiate some emergent recovery
> actions such as interrupting the blocked threads, resetting the db
> connection pool and jdbc driver, or even just generating alerts/alarms
> to the support staff.
>
> This also allows the application to avoid piling up threads getting
> sucked into a black hole which would lead to the eventual death of the
> JVM (ie requiring a restart).
>
>  >There's no such proposal on the table at the moment. A tryLock without a
> > timed-variant is of limited use and monitors don't currently support
> > timed-acquisition, so there would be a bit of VM work to do -
> particularly
> > if you wanted it intrinisfied by the compilers.
>
> Indeed that's what I guessed was the reason (of why these two methods
> are hidden behind Unsafe).  But isn't limited use better than nothing
> in this case ?  It seems clearly I am not alone:
>
>   http://www.javaspecialists.eu/archive/Issue194.html
>
> It appears the use of this tryMonitorEnter is the only way we (or just
> I) can guarantee the application to retain liveness in accessing third
> party library in face of invoking (3rd party owned) synchronized
> methods.  As long as there is liveness, the application can do
> something about it and therefore allow such synchronized problems to
> be limited to a partial failure that can be recovered.  The use could
> be limited, but important.
>
> I don't know if, however, the tryMonitorEnter/monitorExit method is
> truly "unsafe" in the sense that if calling them may cause the JVM to
> crash ?  If not, these methods should probably be re-located to a more
> sensible class anyway, like perhaps Object ?
>
> Regards,
> Hanson
>
> On Sun, Nov 27, 2011 at 8:23 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Hanson Char writes:
> >> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
> >
> > tryExit ???
> >
> >> extremely valuable in face of legacy code that uses synchronized
> >> block/method but the caller cannot afford to be "trapped" when calling
> >> the legacy code even when it entered into a indefinitely blocking
> >> state (within the synchronized block/method).
> >
> > Can you expand on this. The only use case I can see is if you know the
> > legacy code will synchronize on a given instance and so you
> acquire it first
> > using tryLock. But that only protects you from the initial monitor
> > acquisition blocking indefinitely. This seems of very limited
> applicability.
> >
> >> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
> >> into a normal and safe jdk class for general use, so we don't need to
> >> use it in stealth mode. ?Or maybe it already is in Java 7+ ?
> >
> > There's no such proposal on the table at the moment. A tryLock without a
> > timed-variant is of limited use and monitors don't currently support
> > timed-acquisition, so there would be a bit of VM work to do -
> particularly
> > if you wanted it intrinisfied by the compilers.
> >
> > Cheers,
> > David Holmes
> >
> >> Regards,
> >> Hanson
> >>
> >> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
> >> <elizarov at devexperts.com> wrote:
> >> > Unfortunately, I had to use Unsafe myself from time to time just for
> >> > performance reasons (because I have to write a lot of
> high-performance
> >> > code).
> >> >
> >> >
> >> >
> >> > /Roman
> >> >
> >> >
> >> >
> >> > From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
> >> > Sent: Thursday, November 17, 2011 3:01 PM
> >> > To: Roman Elizarov
> >> > Cc: Martin Buchholz; concurrency-interest
> >> >
> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
> >> vs Unsafe
> >> >
> >> >
> >> >
> >> > My thoughts exactly, Roman.? Us mere mortals figure out the
> "how to" by
> >> > reading JDK source code and when we see Unsafe being used, we
> >> go: "Ah, now
> >> > that's a good class to use..." ;-)
> >> >
> >> > From my newsletter:?
> http://www.javaspecialists.eu/archive/Issue194.html
> >> >
> >> > "In a recent email, one of my youngest readers, 17 year old Mr
> >> S.Perlov from
> >> > the Ukraine, suggested that I tell you about the class
> >> sun.misc.Unsafe. Up
> >> > to now I have avoided writing about it, as it is a class
> that should be
> >> > avoided. Here are two reasons: #1 it is "unsafe" and lets us
> do all the
> >> > nasty things that we had in C, such as pointer arithmetic or
> modifying
> >> > memory directly. #2 it is a sun.misc.* class. You do not
> know when that
> >> > might be renamed to oracle.misc.Unsafe or whether you will
> even run your
> >> > program on a Sun JVM. By binding yourself to a specific
> >> implementation of
> >> > the JVM, you are limiting the application of your code.
> >> >
> >> > Two reasons to not use Unsafe. I have personally never used Unsafe in
> >> > production code. Some experts do use it to write directly to memory.
> >> > Dangerous stuff! "
> >> >
> >> > Regards
> >> >
> >> >
> >> >
> >> > Heinz
> >> >
> >> > --
> >> >
> >> > Dr Heinz M. Kabutz (PhD CompSci)
> >> >
> >> > Author of "The Java(tm) Specialists' Newsletter"
> >> >
> >> > Sun Java Champion
> >> >
> >> > IEEE Certified Software Development Professional
> >> >
> >> > http://www.javaspecialists.eu
> >> >
> >> > Tel: +30 69 72 850 460
> >> >
> >> > Skype: kabutz
> >> >
> >> > On 11/17/11 12:53 PM, Roman Elizarov wrote:
> >> >
> >> > The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
> >> > programmer. Every day there are more and more blogs explaining
> >> advantages of
> >> > Unsafe to the average programmer. I?ve just recently reposted
> >> one of those
> >> > for the Russian programmers community.
> >> >
> >> >
> >> >
> >> > Are there any concrete plans (say for Java 8) to bring the
> >> performance of
> >> > **Updater classes on par with Unsafe (maybe by improving
> >> HotSpot, so that it
> >> > can eliminate all the extra checks and compile **Updater
> method into the
> >> > same code as produced by direct use of Unsafe)? Shall we
> >> continue to rely on
> >> > Unsafe for Java 8 and beyond or get ready for its eventual
> >> elimination from
> >> > our codebase?
> >> >
> >> >
> >> >
> >> > Sincerely,
> >> >
> >> > Roman Elizarov
> >> >
> >> >
> >> >
> >> > From: concurrency-interest-bounces at cs.oswego.edu
> >> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On
> Behalf Of Martin
> >> > Buchholz
> >> > Sent: Thursday, November 17, 2011 3:45 AM
> >> > To: Dr Heinz M. Kabutz
> >> > Cc: concurrency-interest
> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
> >> vs Unsafe
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
> >> <heinz at javaspecialists.eu>
> >> > wrote:
> >> >
> >> > In Java 6, classes like ConcurrentLinkedQueue and
> >> SynchronousQueue used the
> >> > AtomicReferenceFieldUpdater to update the next, head, etc. fields.
> >> >
> >> > In Java 7, this was changed to instead use
> Unsafe.compareAndSwapObject()
> >> > directly.
> >> >
> >> > The AtomicReferenceFieldUpdater does a bunch of error checking
> >> every time it
> >> > is called, like this:
> >> >
> >> > ? ? ? ? ? if (obj == null || obj.getClass() != tclass || cclass
> >> != null ||
> >> > ? ? ? ? ? ? ? (update != null && vclass != null &&
> >> > ? ? ? ? ? ? ? ?vclass != update.getClass()))
> >> > ? ? ? ? ? ? ? updateCheck(obj, update);
> >> > ? ? ? ? ? return unsafe.compareAndSwapObject(obj, offset,
> >> expect, update);
> >> >
> >> > My thinking is that the programmers changing
> ConcurrentLinkedQueue et al
> >> > probably wanted to improve the performance by not having to
> do all that
> >> > checking every time it is called. ?The
> >> Unsafe.compareAndSwapObject() method
> >> > is probably compiled to a single CPU instruction.
> >> >
> >> > Is that correct?
> >> >
> >> > Yes.
> >> >
> >> >
> >> >
> >> > Is there any other reason for this change?
> >> >
> >> > The previous way was more principled, in the manner of "eat your own
> >> > dogfood". ?Maybe we've become just a tiny bit less principled.
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> >
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
>



From vitalyd at gmail.com  Tue Nov 29 00:03:18 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 29 Nov 2011 00:03:18 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC70E@G4W3299.americas.hpqcorp.net>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
	<CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
	<CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>
	<CAHjP37G1rnyNXHH+NFL1ADb36Hb6H=f6OjgULJim9hR9OVgGDQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC70E@G4W3299.americas.hpqcorp.net>
Message-ID: <CAHjP37HYou5kkTn9DR_cgLjY=t4CFHZkiyCwpdU7bCoCv34v+A@mail.gmail.com>

Hans,

What's the benefit of moving a prior write inside a critical section (i.e.
across a subsequent lock())? What's a use case where a compiler would elect
to do that? I can see moving loads earlier (across a lock()) as possibly
beneficial, but don't see a case for writes.  Or are you referring to
hardware reordering here?

As for the CAS example on PowerPC (or Itanium, but that arch is dead :)),
this would only be the case if the java code for the lock() was not using
atomics/volatiles -- correct? Are you aware of a production JVM that
implements the j.u.c.l locking primitives with something other than
volatile/atomics? I get that you're concerned about the spec and we
shouldn't rely on what current implementations do, but I'm just curious
here.

Cheers,

Vitaly

On Mon, Nov 28, 2011 at 11:36 PM, Boehm, Hans <hans.boehm at hp.com> wrote:

>  I see your point if the lock operation is implemented in terms of Java
> volatiles or atomics.  I don?t think there is any guarantee that something
> like j.u.c.l.ReentrantLock is implemented that way.  Certainly that wasn?t
> true for the basic MonitorEntry and Exit implementations for any of the
> JVMs that I have worked on in the past.  And there are architectures for
> which there is substantial benefit in using implementations that allow
> roach motel reordering across lock acquisitions.  This is true on Itanium,
> which provides a CAS instruction with only acquire semantics.  And I
> believe the same is true of the usual PowerPC lock acquisition sequence:
> The CAS equivalent is unordered.  That is normally followed by a fence
> (typically isync, possibly lwsync) that prevents reordering of the lock
> acquisition with critical section operations.  But nothing prevents
> reordering of the CAS with prior operations.****
>
> ** **
>
> I was originally responding to a thread arguing for a tryLock-like
> operation on built-in monitors.****
>
> ** **
>
> Hans****
>
> ** **
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Vitaly
> Davidovich
> *Sent:* Monday, November 28, 2011 8:02 PM
> *To:* Joe Bowbeer
> *Cc:* concurrency-interest
>
> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
> Unsafe****
>
>  ** **
>
> Joe,****
>
> ** **
>
> If you forget about the notion of critical sections and such and just
> think about what code will be emitted here (even at the bytecode level),
> there's going to be a volatile write before the write to x; I can't see how
> the JIT (or interpreter, for that matter) can re-arrange the code in that
> case.****
>
> ** **
>
> The assignment of x can move after the volatile read which will occur
> inside lock(), but it cannot reorder with the actual volatile store.  The
> compiler doesn't know what lock() actually is -- it just sees the bytecodes
> inside it (and whatever else it calls), so I don't see how things can be
> rearranged.****
>
> ** **
>
> Vitaly****
>
> On Mon, Nov 28, 2011 at 10:39 PM, Joe Bowbeer <joe.bowbeer at gmail.com>
> wrote:****
>
> On Mon, Nov 28, 2011 at 7:08 PM, Vitaly Davidovich wrote:****
>
> Ok I see - you're going by purely what JMM dictates.  In practice though I
> can't imagine a lock() impl that won't issue a fence at some point
> internally before the write.  Therefore I don't see how assignment to x can
> move past it; the expanded lock would look something like:
> - volatile load/acquire
> ...
> - volatile write/cas/etc (assume lock succeeds, as in this example)
> - x = 17****
>
> So I still don't understand how, in practice, x = 17 can move above the
> lock.****
>
> ** **
>
> According to the "roach motel" semantics for critical sections, x=17 can
> move after the lock in Thread 1, into the "critical section", but it can
> never leave the critical section by moving past the unlock.  This is a
> transformation that the JIT compiler might perform.****
>
> ** **
>
> Except in this case there is no unlock in Thread 1...****
>
>  ****
>
>   On Nov 28, 2011 9:57 PM, "David Holmes" wrote:****
>
>   The HB edge only arises between an unlock and subsequent lock. Here
> there is no unlock  in T1 and hence no subsequent lock in T2 and so no HB.
> (Which is not to say that the necessary memory barriers have not been
> issued as a side-effect of other things - but there is no HB edge as per
> the JMM).****
>
>  ****
>
> lock() has acquire semantics as does volatile read, hence regular
> load/stores can move past them. So here:****
>
>  ****
>
> x = 17;****
>
> l.lock();****
>
>  ****
>
> can become****
>
>  ****
>
> l.lock();****
>
> x = 17;****
>
>  ****
>
> which in this case just makes it more likely that T2 would in practice see
> 17.****
>
>  ****
>
> David****
>
>  -----Original Message-----
> *From:* Vitaly Davidovich****
>
> *Sent:* Tuesday, 29 November 2011 12:49 PM****
>
> *To: *David Holmes****
>
>
> *Cc:* Boehm, Hans; concurrency-interest at cs.oswego.edu; Doug Lea
> *Subject:* RE: [concurrency-interest] AtomicReferenceFieldUpdater vs
> Unsafe****
>
> Yes I realized that I misread the snippet right after I sent the email -
> thanks though :).****
>
> However doing a tryLock will entail reading a volatile that was set during
> lock, so shouldn't that provide the HB? Granted I'm talking about a
> specific impl in the JDK.****
>
> I don't see how roach motel applies here since the lock() writes a
> volatile and prior stores can't reorder with it (subsequent ones can move
> in though).****
>
> On Nov 28, 2011 9:39 PM, "David Holmes" wrote:****
>
> Vitaly,****
>
>  ****
>
> Thread 2 only reads x if the lock is not available, which means thread 1
> must have locked it, which occurs after setting x=17.****
>
>  ****
>
> However in terms of happens-before, there is no HB edge here so no
> guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
> thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
> tells us that x=17 could be reordered with the lock() anyway.****
>
>  ****
>
> David****
>
>  -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
> Davidovich
> *Sent:* Tuesday, 29 November 2011 12:30 PM
> *To:* Boehm, Hans
> *Cc:* Doug Lea; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
> Unsafe****
>
> Hi Hans,****
>
> In your example why do you say that x should be 17 (or rather, why would
> someone assume that)? If thread one writes to x but gets descheduled before
> locking, then clearly thread 2 is not guaranteed to read 17; how is this
> different from if instead of using a lock, a volatile y was used?****
>
> If thread 1 did lock before tryLock in thread 2 then the store to a
> volatile inside lock and a read of that volatile in tryLock should be
> sufficient to create the happens-before edge.****
>
> I must be missing your point though.****
>
> Thanks****
>
> On Nov 28, 2011 8:23 PM, "Boehm, Hans" wrote:****
>
> > From: Doug Lea
> >
> > On 11/28/11 14:23, Boehm, Hans wrote:
> > > There's another problem with tryLock()-like methods, which I pointed
> > out in a
> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
> > correctly
> > > specified.  The problem is illustrated by the following badly
> > designed code:
> > >
> > > Thread 1: x = 17; l.lock();
> > >
> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
> > 17 here!
> > >
> > >
> > > A solution, more or less adopted by C++11, is to specify tryLock() as
> > > allowing spurious failures,
> >
> > I think we are OK on this. The Lock spec defines tryLock in terms
> > of the lock being "available", which means different things
> > across different Lock implementations, and doesn't rule out
> > spurious false returns.
> That interpretation sounds good to me.  It does mean that a lock that was
> constructed before the tryLock call and has never been accessed by anything
> else might not be "available".
>
> Hans****
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest****
>
>
>
> ****
>
> ** **
>
> --
> Vitaly
> 617-548-7007 (mobile)****
>



-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/62f95959/attachment.html>

From vitalyd at gmail.com  Tue Nov 29 00:27:24 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 29 Nov 2011 00:27:24 -0500
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37HYou5kkTn9DR_cgLjY=t4CFHZkiyCwpdU7bCoCv34v+A@mail.gmail.com>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
	<CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
	<CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>
	<CAHjP37G1rnyNXHH+NFL1ADb36Hb6H=f6OjgULJim9hR9OVgGDQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC70E@G4W3299.americas.hpqcorp.net>
	<CAHjP37HYou5kkTn9DR_cgLjY=t4CFHZkiyCwpdU7bCoCv34v+A@mail.gmail.com>
Message-ID: <CAHjP37EjhdL0=kkjDechvYfjvCvGEO_1LeWKujL5ruWVoJE9ug@mail.gmail.com>

Re-reading the j.u.c.l.Lock javadoc, it does state the following:

All Lock implementations *must* enforce the same memory synchronization
semantics as provided by the built-in monitor lock:

   - A successful lock operation acts like a successful monitorEnter action
   - A successful unlock operation acts like a successful monitorExit action

Unsuccessful locking and unlocking operations, and reentrant
locking/unlocking operations, do not require any memory synchronization
effects.

So this seems pretty clear in that a failing tryLock or lack of unlock does
not provide any synchronization effects, although the actual impl we were
discussing happens to be stronger due to volatile use.

On Tue, Nov 29, 2011 at 12:03 AM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Hans,
>
> What's the benefit of moving a prior write inside a critical section (i.e.
> across a subsequent lock())? What's a use case where a compiler would elect
> to do that? I can see moving loads earlier (across a lock()) as possibly
> beneficial, but don't see a case for writes.  Or are you referring to
> hardware reordering here?
>
> As for the CAS example on PowerPC (or Itanium, but that arch is dead :)),
> this would only be the case if the java code for the lock() was not using
> atomics/volatiles -- correct? Are you aware of a production JVM that
> implements the j.u.c.l locking primitives with something other than
> volatile/atomics? I get that you're concerned about the spec and we
> shouldn't rely on what current implementations do, but I'm just curious
> here.
>
> Cheers,
>
> Vitaly
>
>
> On Mon, Nov 28, 2011 at 11:36 PM, Boehm, Hans <hans.boehm at hp.com> wrote:
>
>>  I see your point if the lock operation is implemented in terms of Java
>> volatiles or atomics.  I don?t think there is any guarantee that something
>> like j.u.c.l.ReentrantLock is implemented that way.  Certainly that wasn?t
>> true for the basic MonitorEntry and Exit implementations for any of the
>> JVMs that I have worked on in the past.  And there are architectures for
>> which there is substantial benefit in using implementations that allow
>> roach motel reordering across lock acquisitions.  This is true on Itanium,
>> which provides a CAS instruction with only acquire semantics.  And I
>> believe the same is true of the usual PowerPC lock acquisition sequence:
>> The CAS equivalent is unordered.  That is normally followed by a fence
>> (typically isync, possibly lwsync) that prevents reordering of the lock
>> acquisition with critical section operations.  But nothing prevents
>> reordering of the CAS with prior operations.****
>>
>> ** **
>>
>> I was originally responding to a thread arguing for a tryLock-like
>> operation on built-in monitors.****
>>
>> ** **
>>
>> Hans****
>>
>> ** **
>>
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Vitaly
>> Davidovich
>> *Sent:* Monday, November 28, 2011 8:02 PM
>> *To:* Joe Bowbeer
>> *Cc:* concurrency-interest
>>
>> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
>> Unsafe****
>>
>>  ** **
>>
>> Joe,****
>>
>> ** **
>>
>> If you forget about the notion of critical sections and such and just
>> think about what code will be emitted here (even at the bytecode level),
>> there's going to be a volatile write before the write to x; I can't see how
>> the JIT (or interpreter, for that matter) can re-arrange the code in that
>> case.****
>>
>> ** **
>>
>> The assignment of x can move after the volatile read which will occur
>> inside lock(), but it cannot reorder with the actual volatile store.  The
>> compiler doesn't know what lock() actually is -- it just sees the bytecodes
>> inside it (and whatever else it calls), so I don't see how things can be
>> rearranged.****
>>
>> ** **
>>
>> Vitaly****
>>
>> On Mon, Nov 28, 2011 at 10:39 PM, Joe Bowbeer <joe.bowbeer at gmail.com>
>> wrote:****
>>
>> On Mon, Nov 28, 2011 at 7:08 PM, Vitaly Davidovich wrote:****
>>
>> Ok I see - you're going by purely what JMM dictates.  In practice though
>> I can't imagine a lock() impl that won't issue a fence at some point
>> internally before the write.  Therefore I don't see how assignment to x can
>> move past it; the expanded lock would look something like:
>> - volatile load/acquire
>> ...
>> - volatile write/cas/etc (assume lock succeeds, as in this example)
>> - x = 17****
>>
>> So I still don't understand how, in practice, x = 17 can move above the
>> lock.****
>>
>> ** **
>>
>> According to the "roach motel" semantics for critical sections, x=17 can
>> move after the lock in Thread 1, into the "critical section", but it can
>> never leave the critical section by moving past the unlock.  This is a
>> transformation that the JIT compiler might perform.****
>>
>> ** **
>>
>> Except in this case there is no unlock in Thread 1...****
>>
>>  ****
>>
>>   On Nov 28, 2011 9:57 PM, "David Holmes" wrote:****
>>
>>   The HB edge only arises between an unlock and subsequent lock. Here
>> there is no unlock  in T1 and hence no subsequent lock in T2 and so no HB.
>> (Which is not to say that the necessary memory barriers have not been
>> issued as a side-effect of other things - but there is no HB edge as per
>> the JMM).****
>>
>>  ****
>>
>> lock() has acquire semantics as does volatile read, hence regular
>> load/stores can move past them. So here:****
>>
>>  ****
>>
>> x = 17;****
>>
>> l.lock();****
>>
>>  ****
>>
>> can become****
>>
>>  ****
>>
>> l.lock();****
>>
>> x = 17;****
>>
>>  ****
>>
>> which in this case just makes it more likely that T2 would in practice
>> see 17.****
>>
>>  ****
>>
>> David****
>>
>>  -----Original Message-----
>> *From:* Vitaly Davidovich****
>>
>> *Sent:* Tuesday, 29 November 2011 12:49 PM****
>>
>> *To: *David Holmes****
>>
>>
>> *Cc:* Boehm, Hans; concurrency-interest at cs.oswego.edu; Doug Lea
>> *Subject:* RE: [concurrency-interest] AtomicReferenceFieldUpdater vs
>> Unsafe****
>>
>> Yes I realized that I misread the snippet right after I sent the email -
>> thanks though :).****
>>
>> However doing a tryLock will entail reading a volatile that was set
>> during lock, so shouldn't that provide the HB? Granted I'm talking about a
>> specific impl in the JDK.****
>>
>> I don't see how roach motel applies here since the lock() writes a
>> volatile and prior stores can't reorder with it (subsequent ones can move
>> in though).****
>>
>> On Nov 28, 2011 9:39 PM, "David Holmes" wrote:****
>>
>> Vitaly,****
>>
>>  ****
>>
>> Thread 2 only reads x if the lock is not available, which means thread 1
>> must have locked it, which occurs after setting x=17.****
>>
>>  ****
>>
>> However in terms of happens-before, there is no HB edge here so no
>> guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after
>> thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel
>> tells us that x=17 could be reordered with the lock() anyway.****
>>
>>  ****
>>
>> David****
>>
>>  -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
>> Davidovich
>> *Sent:* Tuesday, 29 November 2011 12:30 PM
>> *To:* Boehm, Hans
>> *Cc:* Doug Lea; concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] AtomicReferenceFieldUpdater vs
>> Unsafe****
>>
>> Hi Hans,****
>>
>> In your example why do you say that x should be 17 (or rather, why would
>> someone assume that)? If thread one writes to x but gets descheduled before
>> locking, then clearly thread 2 is not guaranteed to read 17; how is this
>> different from if instead of using a lock, a volatile y was used?****
>>
>> If thread 1 did lock before tryLock in thread 2 then the store to a
>> volatile inside lock and a read of that volatile in tryLock should be
>> sufficient to create the happens-before edge.****
>>
>> I must be missing your point though.****
>>
>> Thanks****
>>
>> On Nov 28, 2011 8:23 PM, "Boehm, Hans" wrote:****
>>
>> > From: Doug Lea
>> >
>> > On 11/28/11 14:23, Boehm, Hans wrote:
>> > > There's another problem with tryLock()-like methods, which I pointed
>> > out in a
>> > > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
>> > correctly
>> > > specified.  The problem is illustrated by the following badly
>> > designed code:
>> > >
>> > > Thread 1: x = 17; l.lock();
>> > >
>> > > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
>> > 17 here!
>> > >
>> > >
>> > > A solution, more or less adopted by C++11, is to specify tryLock() as
>> > > allowing spurious failures,
>> >
>> > I think we are OK on this. The Lock spec defines tryLock in terms
>> > of the lock being "available", which means different things
>> > across different Lock implementations, and doesn't rule out
>> > spurious false returns.
>> That interpretation sounds good to me.  It does mean that a lock that was
>> constructed before the tryLock call and has never been accessed by anything
>> else might not be "available".
>>
>> Hans****
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest****
>>
>>
>>
>> ****
>>
>> ** **
>>
>> --
>> Vitaly
>> 617-548-7007 (mobile)****
>>
>
>
>
> --
> Vitaly
> 617-548-7007 (mobile)
>



-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/3d592af9/attachment-0001.html>

From hans.boehm at hp.com  Tue Nov 29 00:37:20 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 29 Nov 2011 05:37:20 +0000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <CAHjP37HYou5kkTn9DR_cgLjY=t4CFHZkiyCwpdU7bCoCv34v+A@mail.gmail.com>
References: <CAHjP37FLpFD-1eczW0ZE7sfdhkaPXJ87D7cdd1mbnFsR9BvKEQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJKJBAA.davidcholmes@aapt.net.au>
	<CAHjP37FT11a9k5tq4L4wPwDK4PeQ5q2OdhrBb6V_RgR3e+pfVQ@mail.gmail.com>
	<CAHzJPEqS_MnR=+tM1FYwwgw5NB09bB5wvSfk2QK--KcpYMyqQg@mail.gmail.com>
	<CAHjP37G1rnyNXHH+NFL1ADb36Hb6H=f6OjgULJim9hR9OVgGDQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20CC70E@G4W3299.americas.hpqcorp.net>
	<CAHjP37HYou5kkTn9DR_cgLjY=t4CFHZkiyCwpdU7bCoCv34v+A@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC75F@G4W3299.americas.hpqcorp.net>

I'm primarily worried about hardware reordering.  On architectures like Itanium and PowerPC it takes extra fences to prevent that, and that can cost quite a few cycles.

I haven't looked at the j.u.c.l. implementation, and whether that's sometimes optimized to use JVM-specific facilities.  But I know of no JVM that implements the built-in monitorentry and monitorexit bytecodes with volatiles or atomics.    I haven't worked on any JVMs for a while, but I suspect that's still true.

Hans

From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
Sent: Monday, November 28, 2011 9:03 PM
To: Boehm, Hans
Cc: Joe Bowbeer; concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Hans,

What's the benefit of moving a prior write inside a critical section (i.e. across a subsequent lock())? What's a use case where a compiler would elect to do that? I can see moving loads earlier (across a lock()) as possibly beneficial, but don't see a case for writes.  Or are you referring to hardware reordering here?

As for the CAS example on PowerPC (or Itanium, but that arch is dead :)), this would only be the case if the java code for the lock() was not using atomics/volatiles -- correct? Are you aware of a production JVM that implements the j.u.c.l locking primitives with something other than volatile/atomics? I get that you're concerned about the spec and we shouldn't rely on what current implementations do, but I'm just curious here.

Cheers,

Vitaly
On Mon, Nov 28, 2011 at 11:36 PM, Boehm, Hans <hans.boehm at hp.com<mailto:hans.boehm at hp.com>> wrote:
I see your point if the lock operation is implemented in terms of Java volatiles or atomics.  I don't think there is any guarantee that something like j.u.c.l.ReentrantLock is implemented that way.  Certainly that wasn't true for the basic MonitorEntry and Exit implementations for any of the JVMs that I have worked on in the past.  And there are architectures for which there is substantial benefit in using implementations that allow roach motel reordering across lock acquisitions.  This is true on Itanium, which provides a CAS instruction with only acquire semantics.  And I believe the same is true of the usual PowerPC lock acquisition sequence:  The CAS equivalent is unordered.  That is normally followed by a fence (typically isync, possibly lwsync) that prevents reordering of the lock acquisition with critical section operations.  But nothing prevents reordering of the CAS with prior operations.

I was originally responding to a thread arguing for a tryLock-like operation on built-in monitors.

Hans

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Vitaly Davidovich
Sent: Monday, November 28, 2011 8:02 PM
To: Joe Bowbeer
Cc: concurrency-interest

Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Joe,

If you forget about the notion of critical sections and such and just think about what code will be emitted here (even at the bytecode level), there's going to be a volatile write before the write to x; I can't see how the JIT (or interpreter, for that matter) can re-arrange the code in that case.

The assignment of x can move after the volatile read which will occur inside lock(), but it cannot reorder with the actual volatile store.  The compiler doesn't know what lock() actually is -- it just sees the bytecodes inside it (and whatever else it calls), so I don't see how things can be rearranged.

Vitaly
On Mon, Nov 28, 2011 at 10:39 PM, Joe Bowbeer <joe.bowbeer at gmail.com<mailto:joe.bowbeer at gmail.com>> wrote:
On Mon, Nov 28, 2011 at 7:08 PM, Vitaly Davidovich wrote:

Ok I see - you're going by purely what JMM dictates.  In practice though I can't imagine a lock() impl that won't issue a fence at some point internally before the write.  Therefore I don't see how assignment to x can move past it; the expanded lock would look something like:
- volatile load/acquire
...
- volatile write/cas/etc (assume lock succeeds, as in this example)
- x = 17

So I still don't understand how, in practice, x = 17 can move above the lock.

According to the "roach motel" semantics for critical sections, x=17 can move after the lock in Thread 1, into the "critical section", but it can never leave the critical section by moving past the unlock.  This is a transformation that the JIT compiler might perform.

Except in this case there is no unlock in Thread 1...

On Nov 28, 2011 9:57 PM, "David Holmes" wrote:
The HB edge only arises between an unlock and subsequent lock. Here there is no unlock  in T1 and hence no subsequent lock in T2 and so no HB. (Which is not to say that the necessary memory barriers have not been issued as a side-effect of other things - but there is no HB edge as per the JMM).

lock() has acquire semantics as does volatile read, hence regular load/stores can move past them. So here:

x = 17;
l.lock();

can become

l.lock();
x = 17;

which in this case just makes it more likely that T2 would in practice see 17.

David
-----Original Message-----
From: Vitaly Davidovich
Sent: Tuesday, 29 November 2011 12:49 PM
To: David Holmes

Cc: Boehm, Hans; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>; Doug Lea
Subject: RE: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Yes I realized that I misread the snippet right after I sent the email - thanks though :).

However doing a tryLock will entail reading a volatile that was set during lock, so shouldn't that provide the HB? Granted I'm talking about a specific impl in the JDK.

I don't see how roach motel applies here since the lock() writes a volatile and prior stores can't reorder with it (subsequent ones can move in though).
On Nov 28, 2011 9:39 PM, "David Holmes" wrote:
Vitaly,

Thread 2 only reads x if the lock is not available, which means thread 1 must have locked it, which occurs after setting x=17.

However in terms of happens-before, there is no HB edge here so no guarantee of x being 17 AFAICS. Thread 2 has to acquire the lock after thread 1 to get a HB edge that guarantees x == 17. Further, roach-motel tells us that x=17 could be reordered with the lock() anyway.

David
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu>]On Behalf Of Vitaly Davidovich
Sent: Tuesday, 29 November 2011 12:30 PM
To: Boehm, Hans
Cc: Doug Lea; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe

Hi Hans,

In your example why do you say that x should be 17 (or rather, why would someone assume that)? If thread one writes to x but gets descheduled before locking, then clearly thread 2 is not guaranteed to read 17; how is this different from if instead of using a lock, a volatile y was used?

If thread 1 did lock before tryLock in thread 2 then the store to a volatile inside lock and a read of that volatile in tryLock should be sufficient to create the happens-before edge.

I must be missing your point though.

Thanks
On Nov 28, 2011 8:23 PM, "Boehm, Hans" wrote:
> From: Doug Lea
>
> On 11/28/11 14:23, Boehm, Hans wrote:
> > There's another problem with tryLock()-like methods, which I pointed
> out in a
> > 2007 PPoPP paper.  I think the current j.u.c.tryLock() is not
> correctly
> > specified.  The problem is illustrated by the following badly
> designed code:
> >
> > Thread 1: x = 17; l.lock();
> >
> > Thread 2: while (l.tryLock()) l.unlock(); ... x ...  // x should be
> 17 here!
> >
> >
> > A solution, more or less adopted by C++11, is to specify tryLock() as
> > allowing spurious failures,
>
> I think we are OK on this. The Lock spec defines tryLock in terms
> of the lock being "available", which means different things
> across different Lock implementations, and doesn't rule out
> spurious false returns.
That interpretation sounds good to me.  It does mean that a lock that was constructed before the tryLock call and has never been accessed by anything else might not be "available".

Hans

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



--
Vitaly
617-548-7007<tel:617-548-7007> (mobile)



--
Vitaly
617-548-7007<tel:617-548-7007> (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/4e412656/attachment-0001.html>

From hanson.char at gmail.com  Tue Nov 29 01:34:46 2011
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 28 Nov 2011 22:34:46 -0800
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJMJBAA.davidcholmes@aapt.net.au>
References: <CABWgujbHDSejcpk7Nxgn7Jq+qi+kK_fqUBA5dHUNfAT0XF5smg@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJMJBAA.davidcholmes@aapt.net.au>
Message-ID: <CABWgujZ8hQkP2-JPzp0dxWJ+DgR10PdLPj-9a2Zw7igDAWRnUQ@mail.gmail.com>

Hi David,
Thank you for the detailed explanation. ?The message I get is to avoid
using Unsafe whenever possible.  But for the few "uncommon" needs,
it's ok/safe to use the Unsafe.tryMonitorEnter and Unsafe.monitorExit
as long as they are always made balanced (in a finally clause) in the
same stack frame.
Hanson
On Mon, Nov 28, 2011 at 8:49 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Re: Unsafe.tryMonitorEnter and Unsafe.monitorExit
>
> So returning to the "are these truly unsafe" question the answer is: yes. At
> least monitorExit is potentially unsafe.
>
> Dave Dice reminded me (thanks Dave!) about the issue of having balanced
> monitorEnter and monitorExit instructions and that monitors are always
> released in the same stackframe in which they were acquired. The JVM takes
> advantage of balanced monitor use to optimize locking - synchronized usage
> is always balanced and JITs generate similarly balanced code, and if you mix
> JVMTI locking/unlocking with synchronized then you are on your own. If you
> use Unsafe.monitorExit in an unbalanced fashion then you might run into
> problems.
>
> If we were to make these a public API then we would have to account for
> unbalanced use. That might mean either dropping all the optimizations that
> rely on balanced use, or adding additional analysis to detect unbalanced use
> and drop back to interpreted code in such cases. Either way that is a lot of
> work (not to mention the timeout support) to accommodate an uncommon need
> already satisfiable through Unsafe - in my opinion of course.
>
> Cheers,
> David
>
>
> Hanson Char writes:
>>
>> Sorry I meant Unsafe#tryMonitorEnter and #monitorExit. ?(I realized
>> the mistake after sending out the email, but thought the context would
>> self recover/make it clear :))
>>
>> > Can you expand on this.
>>
>> One practical (and critical) case I've come across is that under some
>> extreme circumstances , a 3rd party database connection pool would get
>> into a "stuck" state. ?Doesn't happen often but it does happen. ?When
>> it did, any attempt to inspect the respective pool via JMX calling the
>> getter methods for info such as the number of active/idle connections
>> would cause the inspecting thread to get stuck.
>>
>> Looking into the code (of the third party library) it was clearly
>> related to the use of synchronized methods, including the getter
>> methods for the stats.
>>
>> Via Unsafe#tryMonitorEnter, the application was able to get some
>> information out of the pool, and initiate some emergent recovery
>> actions such as interrupting the blocked threads, resetting the db
>> connection pool and jdbc driver, or even just generating alerts/alarms
>> to the support staff.
>>
>> This also allows the application to avoid piling up threads getting
>> sucked into a black hole which would lead to the eventual death of the
>> JVM (ie requiring a restart).
>>
>> ?>There's no such proposal on the table at the moment. A tryLock without a
>> > timed-variant is of limited use and monitors don't currently support
>> > timed-acquisition, so there would be a bit of VM work to do -
>> particularly
>> > if you wanted it intrinisfied by the compilers.
>>
>> Indeed that's what I guessed was the reason (of why these two methods
>> are hidden behind Unsafe). ?But isn't limited use better than nothing
>> in this case ? ?It seems clearly I am not alone:
>>
>> ? http://www.javaspecialists.eu/archive/Issue194.html
>>
>> It appears the use of this tryMonitorEnter is the only way we (or just
>> I) can guarantee the application to retain liveness in accessing third
>> party library in face of invoking (3rd party owned) synchronized
>> methods. ?As long as there is liveness, the application can do
>> something about it and therefore allow such synchronized problems to
>> be limited to a partial failure that can be recovered. ?The use could
>> be limited, but important.
>>
>> I don't know if, however, the tryMonitorEnter/monitorExit method is
>> truly "unsafe" in the sense that if calling them may cause the JVM to
>> crash ? ?If not, these methods should probably be re-located to a more
>> sensible class anyway, like perhaps Object ?
>>
>> Regards,
>> Hanson
>>
>> On Sun, Nov 27, 2011 at 8:23 PM, David Holmes
>> <davidcholmes at aapt.net.au> wrote:
>> > Hanson Char writes:
>> >> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
>> >
>> > tryExit ???
>> >
>> >> extremely valuable in face of legacy code that uses synchronized
>> >> block/method but the caller cannot afford to be "trapped" when calling
>> >> the legacy code even when it entered into a indefinitely blocking
>> >> state (within the synchronized block/method).
>> >
>> > Can you expand on this. The only use case I can see is if you know the
>> > legacy code will synchronize on a given instance and so you
>> acquire it first
>> > using tryLock. But that only protects you from the initial monitor
>> > acquisition blocking indefinitely. This seems of very limited
>> applicability.
>> >
>> >> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
>> >> into a normal and safe jdk class for general use, so we don't need to
>> >> use it in stealth mode. ?Or maybe it already is in Java 7+ ?
>> >
>> > There's no such proposal on the table at the moment. A tryLock without a
>> > timed-variant is of limited use and monitors don't currently support
>> > timed-acquisition, so there would be a bit of VM work to do -
>> particularly
>> > if you wanted it intrinisfied by the compilers.
>> >
>> > Cheers,
>> > David Holmes
>> >
>> >> Regards,
>> >> Hanson
>> >>
>> >> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
>> >> <elizarov at devexperts.com> wrote:
>> >> > Unfortunately, I had to use Unsafe myself from time to time just for
>> >> > performance reasons (because I have to write a lot of
>> high-performance
>> >> > code).
>> >> >
>> >> >
>> >> >
>> >> > /Roman
>> >> >
>> >> >
>> >> >
>> >> > From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
>> >> > Sent: Thursday, November 17, 2011 3:01 PM
>> >> > To: Roman Elizarov
>> >> > Cc: Martin Buchholz; concurrency-interest
>> >> >
>> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>> >> vs Unsafe
>> >> >
>> >> >
>> >> >
>> >> > My thoughts exactly, Roman.? Us mere mortals figure out the
>> "how to" by
>> >> > reading JDK source code and when we see Unsafe being used, we
>> >> go: "Ah, now
>> >> > that's a good class to use..." ;-)
>> >> >
>> >> > From my newsletter:
>> http://www.javaspecialists.eu/archive/Issue194.html
>> >> >
>> >> > "In a recent email, one of my youngest readers, 17 year old Mr
>> >> S.Perlov from
>> >> > the Ukraine, suggested that I tell you about the class
>> >> sun.misc.Unsafe. Up
>> >> > to now I have avoided writing about it, as it is a class
>> that should be
>> >> > avoided. Here are two reasons: #1 it is "unsafe" and lets us
>> do all the
>> >> > nasty things that we had in C, such as pointer arithmetic or
>> modifying
>> >> > memory directly. #2 it is a sun.misc.* class. You do not
>> know when that
>> >> > might be renamed to oracle.misc.Unsafe or whether you will
>> even run your
>> >> > program on a Sun JVM. By binding yourself to a specific
>> >> implementation of
>> >> > the JVM, you are limiting the application of your code.
>> >> >
>> >> > Two reasons to not use Unsafe. I have personally never used Unsafe in
>> >> > production code. Some experts do use it to write directly to memory.
>> >> > Dangerous stuff! "
>> >> >
>> >> > Regards
>> >> >
>> >> >
>> >> >
>> >> > Heinz
>> >> >
>> >> > --
>> >> >
>> >> > Dr Heinz M. Kabutz (PhD CompSci)
>> >> >
>> >> > Author of "The Java(tm) Specialists' Newsletter"
>> >> >
>> >> > Sun Java Champion
>> >> >
>> >> > IEEE Certified Software Development Professional
>> >> >
>> >> > http://www.javaspecialists.eu
>> >> >
>> >> > Tel: +30 69 72 850 460
>> >> >
>> >> > Skype: kabutz
>> >> >
>> >> > On 11/17/11 12:53 PM, Roman Elizarov wrote:
>> >> >
>> >> > The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
>> >> > programmer. Every day there are more and more blogs explaining
>> >> advantages of
>> >> > Unsafe to the average programmer. I?ve just recently reposted
>> >> one of those
>> >> > for the Russian programmers community.
>> >> >
>> >> >
>> >> >
>> >> > Are there any concrete plans (say for Java 8) to bring the
>> >> performance of
>> >> > **Updater classes on par with Unsafe (maybe by improving
>> >> HotSpot, so that it
>> >> > can eliminate all the extra checks and compile **Updater
>> method into the
>> >> > same code as produced by direct use of Unsafe)? Shall we
>> >> continue to rely on
>> >> > Unsafe for Java 8 and beyond or get ready for its eventual
>> >> elimination from
>> >> > our codebase?
>> >> >
>> >> >
>> >> >
>> >> > Sincerely,
>> >> >
>> >> > Roman Elizarov
>> >> >
>> >> >
>> >> >
>> >> > From: concurrency-interest-bounces at cs.oswego.edu
>> >> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On
>> Behalf Of Martin
>> >> > Buchholz
>> >> > Sent: Thursday, November 17, 2011 3:45 AM
>> >> > To: Dr Heinz M. Kabutz
>> >> > Cc: concurrency-interest
>> >> > Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>> >> vs Unsafe
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
>> >> <heinz at javaspecialists.eu>
>> >> > wrote:
>> >> >
>> >> > In Java 6, classes like ConcurrentLinkedQueue and
>> >> SynchronousQueue used the
>> >> > AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>> >> >
>> >> > In Java 7, this was changed to instead use
>> Unsafe.compareAndSwapObject()
>> >> > directly.
>> >> >
>> >> > The AtomicReferenceFieldUpdater does a bunch of error checking
>> >> every time it
>> >> > is called, like this:
>> >> >
>> >> > ? ? ? ? ? if (obj == null || obj.getClass() != tclass || cclass
>> >> != null ||
>> >> > ? ? ? ? ? ? ? (update != null && vclass != null &&
>> >> > ? ? ? ? ? ? ? ?vclass != update.getClass()))
>> >> > ? ? ? ? ? ? ? updateCheck(obj, update);
>> >> > ? ? ? ? ? return unsafe.compareAndSwapObject(obj, offset,
>> >> expect, update);
>> >> >
>> >> > My thinking is that the programmers changing
>> ConcurrentLinkedQueue et al
>> >> > probably wanted to improve the performance by not having to
>> do all that
>> >> > checking every time it is called. ?The
>> >> Unsafe.compareAndSwapObject() method
>> >> > is probably compiled to a single CPU instruction.
>> >> >
>> >> > Is that correct?
>> >> >
>> >> > Yes.
>> >> >
>> >> >
>> >> >
>> >> > Is there any other reason for this change?
>> >> >
>> >> > The previous way was more principled, in the manner of "eat your own
>> >> > dogfood". ?Maybe we've become just a tiny bit less principled.
>> >> >
>> >> > _______________________________________________
>> >> > Concurrency-interest mailing list
>> >> > Concurrency-interest at cs.oswego.edu
>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >
>> >> >
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >
>> >
>>
>
>


From nathan.reynolds at oracle.com  Tue Nov 29 11:54:35 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 29 Nov 2011 09:54:35 -0700
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJMJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEJMJBAA.davidcholmes@aapt.net.au>
Message-ID: <4ED50E4B.4010102@oracle.com>

javac will compile synchronized blocks with monitorenter and monitorexit 
byte codes in the same frame.  They are always produced in a balanced 
manner.  However, bytecode manipulation tools (i.e. BCEL, ASM, etc) can 
emit monitorenter and monitorexit byte codes at any time.  Other 
languages may (or may not) allow for unbalanced monitorenter and 
monitorexit.  It seems to me that a JVM has no choice but to deal with 
such unbalances.

The JRockit JVM dealt with unbalanced monitorenter and monitorexit by 
executing special yet slower code.  A couple of years ago, we found a 
bug in the unbalance detector which would generate false positives.  The 
performance of the code was dismal until they supplied a fix.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 11/28/2011 9:49 PM, David Holmes wrote:
> Re: Unsafe.tryMonitorEnter and Unsafe.monitorExit
>
> So returning to the "are these truly unsafe" question the answer is: yes. At
> least monitorExit is potentially unsafe.
>
> Dave Dice reminded me (thanks Dave!) about the issue of having balanced
> monitorEnter and monitorExit instructions and that monitors are always
> released in the same stackframe in which they were acquired. The JVM takes
> advantage of balanced monitor use to optimize locking - synchronized usage
> is always balanced and JITs generate similarly balanced code, and if you mix
> JVMTI locking/unlocking with synchronized then you are on your own. If you
> use Unsafe.monitorExit in an unbalanced fashion then you might run into
> problems.
>
> If we were to make these a public API then we would have to account for
> unbalanced use. That might mean either dropping all the optimizations that
> rely on balanced use, or adding additional analysis to detect unbalanced use
> and drop back to interpreted code in such cases. Either way that is a lot of
> work (not to mention the timeout support) to accommodate an uncommon need
> already satisfiable through Unsafe - in my opinion of course.
>
> Cheers,
> David
>
>
> Hanson Char writes:
>> Sorry I meant Unsafe#tryMonitorEnter and #monitorExit.  (I realized
>> the mistake after sending out the email, but thought the context would
>> self recover/make it clear :))
>>
>>> Can you expand on this.
>> One practical (and critical) case I've come across is that under some
>> extreme circumstances , a 3rd party database connection pool would get
>> into a "stuck" state.  Doesn't happen often but it does happen.  When
>> it did, any attempt to inspect the respective pool via JMX calling the
>> getter methods for info such as the number of active/idle connections
>> would cause the inspecting thread to get stuck.
>>
>> Looking into the code (of the third party library) it was clearly
>> related to the use of synchronized methods, including the getter
>> methods for the stats.
>>
>> Via Unsafe#tryMonitorEnter, the application was able to get some
>> information out of the pool, and initiate some emergent recovery
>> actions such as interrupting the blocked threads, resetting the db
>> connection pool and jdbc driver, or even just generating alerts/alarms
>> to the support staff.
>>
>> This also allows the application to avoid piling up threads getting
>> sucked into a black hole which would lead to the eventual death of the
>> JVM (ie requiring a restart).
>>
>>   >There's no such proposal on the table at the moment. A tryLock without a
>>> timed-variant is of limited use and monitors don't currently support
>>> timed-acquisition, so there would be a bit of VM work to do -
>> particularly
>>> if you wanted it intrinisfied by the compilers.
>> Indeed that's what I guessed was the reason (of why these two methods
>> are hidden behind Unsafe).  But isn't limited use better than nothing
>> in this case ?  It seems clearly I am not alone:
>>
>>    http://www.javaspecialists.eu/archive/Issue194.html
>>
>> It appears the use of this tryMonitorEnter is the only way we (or just
>> I) can guarantee the application to retain liveness in accessing third
>> party library in face of invoking (3rd party owned) synchronized
>> methods.  As long as there is liveness, the application can do
>> something about it and therefore allow such synchronized problems to
>> be limited to a partial failure that can be recovered.  The use could
>> be limited, but important.
>>
>> I don't know if, however, the tryMonitorEnter/monitorExit method is
>> truly "unsafe" in the sense that if calling them may cause the JVM to
>> crash ?  If not, these methods should probably be re-located to a more
>> sensible class anyway, like perhaps Object ?
>>
>> Regards,
>> Hanson
>>
>> On Sun, Nov 27, 2011 at 8:23 PM, David Holmes
>> <davidcholmes at aapt.net.au>  wrote:
>>> Hanson Char writes:
>>>> Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
>>> tryExit ???
>>>
>>>> extremely valuable in face of legacy code that uses synchronized
>>>> block/method but the caller cannot afford to be "trapped" when calling
>>>> the legacy code even when it entered into a indefinitely blocking
>>>> state (within the synchronized block/method).
>>> Can you expand on this. The only use case I can see is if you know the
>>> legacy code will synchronize on a given instance and so you
>> acquire it first
>>> using tryLock. But that only protects you from the initial monitor
>>> acquisition blocking indefinitely. This seems of very limited
>> applicability.
>>>> It would be really nice if the tryMonitor{Enter,Exit} can be promoted
>>>> into a normal and safe jdk class for general use, so we don't need to
>>>> use it in stealth mode.  Or maybe it already is in Java 7+ ?
>>> There's no such proposal on the table at the moment. A tryLock without a
>>> timed-variant is of limited use and monitors don't currently support
>>> timed-acquisition, so there would be a bit of VM work to do -
>> particularly
>>> if you wanted it intrinisfied by the compilers.
>>>
>>> Cheers,
>>> David Holmes
>>>
>>>> Regards,
>>>> Hanson
>>>>
>>>> On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
>>>> <elizarov at devexperts.com>  wrote:
>>>>> Unfortunately, I had to use Unsafe myself from time to time just for
>>>>> performance reasons (because I have to write a lot of
>> high-performance
>>>>> code).
>>>>>
>>>>>
>>>>>
>>>>> /Roman
>>>>>
>>>>>
>>>>>
>>>>> From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
>>>>> Sent: Thursday, November 17, 2011 3:01 PM
>>>>> To: Roman Elizarov
>>>>> Cc: Martin Buchholz; concurrency-interest
>>>>>
>>>>> Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>>>> vs Unsafe
>>>>>
>>>>>
>>>>> My thoughts exactly, Roman.  Us mere mortals figure out the
>> "how to" by
>>>>> reading JDK source code and when we see Unsafe being used, we
>>>> go: "Ah, now
>>>>> that's a good class to use..." ;-)
>>>>>
>>>>>  From my newsletter:
>> http://www.javaspecialists.eu/archive/Issue194.html
>>>>> "In a recent email, one of my youngest readers, 17 year old Mr
>>>> S.Perlov from
>>>>> the Ukraine, suggested that I tell you about the class
>>>> sun.misc.Unsafe. Up
>>>>> to now I have avoided writing about it, as it is a class
>> that should be
>>>>> avoided. Here are two reasons: #1 it is "unsafe" and lets us
>> do all the
>>>>> nasty things that we had in C, such as pointer arithmetic or
>> modifying
>>>>> memory directly. #2 it is a sun.misc.* class. You do not
>> know when that
>>>>> might be renamed to oracle.misc.Unsafe or whether you will
>> even run your
>>>>> program on a Sun JVM. By binding yourself to a specific
>>>> implementation of
>>>>> the JVM, you are limiting the application of your code.
>>>>>
>>>>> Two reasons to not use Unsafe. I have personally never used Unsafe in
>>>>> production code. Some experts do use it to write directly to memory.
>>>>> Dangerous stuff! "
>>>>>
>>>>> Regards
>>>>>
>>>>>
>>>>>
>>>>> Heinz
>>>>>
>>>>> --
>>>>>
>>>>> Dr Heinz M. Kabutz (PhD CompSci)
>>>>>
>>>>> Author of "The Java(tm) Specialists' Newsletter"
>>>>>
>>>>> Sun Java Champion
>>>>>
>>>>> IEEE Certified Software Development Professional
>>>>>
>>>>> http://www.javaspecialists.eu
>>>>>
>>>>> Tel: +30 69 72 850 460
>>>>>
>>>>> Skype: kabutz
>>>>>
>>>>> On 11/17/11 12:53 PM, Roman Elizarov wrote:
>>>>>
>>>>> The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
>>>>> programmer. Every day there are more and more blogs explaining
>>>> advantages of
>>>>> Unsafe to the average programmer. I?ve just recently reposted
>>>> one of those
>>>>> for the Russian programmers community.
>>>>>
>>>>>
>>>>>
>>>>> Are there any concrete plans (say for Java 8) to bring the
>>>> performance of
>>>>> **Updater classes on par with Unsafe (maybe by improving
>>>> HotSpot, so that it
>>>>> can eliminate all the extra checks and compile **Updater
>> method into the
>>>>> same code as produced by direct use of Unsafe)? Shall we
>>>> continue to rely on
>>>>> Unsafe for Java 8 and beyond or get ready for its eventual
>>>> elimination from
>>>>> our codebase?
>>>>>
>>>>>
>>>>>
>>>>> Sincerely,
>>>>>
>>>>> Roman Elizarov
>>>>>
>>>>>
>>>>>
>>>>> From: concurrency-interest-bounces at cs.oswego.edu
>>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu] On
>> Behalf Of Martin
>>>>> Buchholz
>>>>> Sent: Thursday, November 17, 2011 3:45 AM
>>>>> To: Dr Heinz M. Kabutz
>>>>> Cc: concurrency-interest
>>>>> Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
>>>> vs Unsafe
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
>>>> <heinz at javaspecialists.eu>
>>>>> wrote:
>>>>>
>>>>> In Java 6, classes like ConcurrentLinkedQueue and
>>>> SynchronousQueue used the
>>>>> AtomicReferenceFieldUpdater to update the next, head, etc. fields.
>>>>>
>>>>> In Java 7, this was changed to instead use
>> Unsafe.compareAndSwapObject()
>>>>> directly.
>>>>>
>>>>> The AtomicReferenceFieldUpdater does a bunch of error checking
>>>> every time it
>>>>> is called, like this:
>>>>>
>>>>>            if (obj == null || obj.getClass() != tclass || cclass
>>>> != null ||
>>>>>                (update != null&&  vclass != null&&
>>>>>                 vclass != update.getClass()))
>>>>>                updateCheck(obj, update);
>>>>>            return unsafe.compareAndSwapObject(obj, offset,
>>>> expect, update);
>>>>> My thinking is that the programmers changing
>> ConcurrentLinkedQueue et al
>>>>> probably wanted to improve the performance by not having to
>> do all that
>>>>> checking every time it is called.  The
>>>> Unsafe.compareAndSwapObject() method
>>>>> is probably compiled to a single CPU instruction.
>>>>>
>>>>> Is that correct?
>>>>>
>>>>> Yes.
>>>>>
>>>>>
>>>>>
>>>>> Is there any other reason for this change?
>>>>>
>>>>> The previous way was more principled, in the manner of "eat your own
>>>>> dogfood".  Maybe we've become just a tiny bit less principled.
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111129/48f4e9cf/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue Nov 29 17:15:32 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 30 Nov 2011 08:15:32 +1000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe
In-Reply-To: <4ED50E4B.4010102@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEJPJBAA.davidcholmes@aapt.net.au>

Nathan,

The JVM spec specifically calls out the issue of balanced/unbalanced monitor
actions aka structured locking - section 8.13. Hotspot relies on structured
locking in places, but like JRockit there are some uses (eg JVMTI raw
monitors) where balanced use can not be guaranteed and so it runs in
interpreted mode. Any bytecode manipulation tool, or alternative language
implementation using bytecodes, must be aware of JVMS 8.13 and act
accordingly.

David
  -----Original Message-----
  From: Nathan Reynolds [mailto:nathan.reynolds at oracle.com]
  Sent: Wednesday, 30 November 2011 2:55 AM
  To: dholmes at ieee.org
  Cc: David Holmes; Hanson Char; concurrency-interest
  Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater vs Unsafe


  javac will compile synchronized blocks with monitorenter and monitorexit
byte codes in the same frame.  They are always produced in a balanced
manner.  However, bytecode manipulation tools (i.e. BCEL, ASM, etc) can emit
monitorenter and monitorexit byte codes at any time.  Other languages may
(or may not) allow for unbalanced monitorenter and monitorexit.  It seems to
me that a JVM has no choice but to deal with such unbalances.

  The JRockit JVM dealt with unbalanced monitorenter and monitorexit by
executing special yet slower code.  A couple of years ago, we found a bug in
the unbalance detector which would generate false positives.  The
performance of the code was dismal until they supplied a fix.


  Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
  Oracle PSR Engineering | Server Technology


  On 11/28/2011 9:49 PM, David Holmes wrote:
Re: Unsafe.tryMonitorEnter and Unsafe.monitorExit

So returning to the "are these truly unsafe" question the answer is: yes. At
least monitorExit is potentially unsafe.

Dave Dice reminded me (thanks Dave!) about the issue of having balanced
monitorEnter and monitorExit instructions and that monitors are always
released in the same stackframe in which they were acquired. The JVM takes
advantage of balanced monitor use to optimize locking - synchronized usage
is always balanced and JITs generate similarly balanced code, and if you mix
JVMTI locking/unlocking with synchronized then you are on your own. If you
use Unsafe.monitorExit in an unbalanced fashion then you might run into
problems.

If we were to make these a public API then we would have to account for
unbalanced use. That might mean either dropping all the optimizations that
rely on balanced use, or adding additional analysis to detect unbalanced use
and drop back to interpreted code in such cases. Either way that is a lot of
work (not to mention the timeout support) to accommodate an uncommon need
already satisfiable through Unsafe - in my opinion of course.

Cheers,
David


Hanson Char writes:
Sorry I meant Unsafe#tryMonitorEnter and #monitorExit.  (I realized
the mistake after sending out the email, but thought the context would
self recover/make it clear :))

Can you expand on this.
One practical (and critical) case I've come across is that under some
extreme circumstances , a 3rd party database connection pool would get
into a "stuck" state.  Doesn't happen often but it does happen.  When
it did, any attempt to inspect the respective pool via JMX calling the
getter methods for info such as the number of active/idle connections
would cause the inspecting thread to get stuck.

Looking into the code (of the third party library) it was clearly
related to the use of synchronized methods, including the getter
methods for the stats.

Via Unsafe#tryMonitorEnter, the application was able to get some
information out of the pool, and initiate some emergent recovery
actions such as interrupting the blocked threads, resetting the db
connection pool and jdbc driver, or even just generating alerts/alarms
to the support staff.

This also allows the application to avoid piling up threads getting
sucked into a black hole which would lead to the eventual death of the
JVM (ie requiring a restart).

 >There's no such proposal on the table at the moment. A tryLock without a
timed-variant is of limited use and monitors don't currently support
timed-acquisition, so there would be a bit of VM work to do -
particularly
if you wanted it intrinisfied by the compilers.
Indeed that's what I guessed was the reason (of why these two methods
are hidden behind Unsafe).  But isn't limited use better than nothing
in this case ?  It seems clearly I am not alone:

  http://www.javaspecialists.eu/archive/Issue194.html

It appears the use of this tryMonitorEnter is the only way we (or just
I) can guarantee the application to retain liveness in accessing third
party library in face of invoking (3rd party owned) synchronized
methods.  As long as there is liveness, the application can do
something about it and therefore allow such synchronized problems to
be limited to a partial failure that can be recovered.  The use could
be limited, but important.

I don't know if, however, the tryMonitorEnter/monitorExit method is
truly "unsafe" in the sense that if calling them may cause the JVM to
crash ?  If not, these methods should probably be re-located to a more
sensible class anyway, like perhaps Object ?

Regards,
Hanson

On Sun, Nov 27, 2011 at 8:23 PM, David Holmes
<davidcholmes at aapt.net.au> wrote:
Hanson Char writes:
Performance aside, I find the use of Unsafe#tryMonitor{Enter,Exit}
tryExit ???

extremely valuable in face of legacy code that uses synchronized
block/method but the caller cannot afford to be "trapped" when calling
the legacy code even when it entered into a indefinitely blocking
state (within the synchronized block/method).
Can you expand on this. The only use case I can see is if you know the
legacy code will synchronize on a given instance and so you
acquire it first
using tryLock. But that only protects you from the initial monitor
acquisition blocking indefinitely. This seems of very limited
applicability.
It would be really nice if the tryMonitor{Enter,Exit} can be promoted
into a normal and safe jdk class for general use, so we don't need to
use it in stealth mode.  Or maybe it already is in Java 7+ ?
There's no such proposal on the table at the moment. A tryLock without a
timed-variant is of limited use and monitors don't currently support
timed-acquisition, so there would be a bit of VM work to do -
particularly
if you wanted it intrinisfied by the compilers.

Cheers,
David Holmes

Regards,
Hanson

On Thu, Nov 17, 2011 at 3:26 AM, Roman Elizarov
<elizarov at devexperts.com> wrote:
Unfortunately, I had to use Unsafe myself from time to time just for
performance reasons (because I have to write a lot of
high-performance
code).



/Roman



From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
Sent: Thursday, November 17, 2011 3:01 PM
To: Roman Elizarov
Cc: Martin Buchholz; concurrency-interest

Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
vs Unsafe


My thoughts exactly, Roman.  Us mere mortals figure out the
"how to" by
reading JDK source code and when we see Unsafe being used, we
go: "Ah, now
that's a good class to use..." ;-)

>From my newsletter:
http://www.javaspecialists.eu/archive/Issue194.html
"In a recent email, one of my youngest readers, 17 year old Mr
S.Perlov from
the Ukraine, suggested that I tell you about the class
sun.misc.Unsafe. Up
to now I have avoided writing about it, as it is a class
that should be
avoided. Here are two reasons: #1 it is "unsafe" and lets us
do all the
nasty things that we had in C, such as pointer arithmetic or
modifying
memory directly. #2 it is a sun.misc.* class. You do not
know when that
might be renamed to oracle.misc.Unsafe or whether you will
even run your
program on a Sun JVM. By binding yourself to a specific
implementation of
the JVM, you are limiting the application of your code.

Two reasons to not use Unsafe. I have personally never used Unsafe in
production code. Some experts do use it to write directly to memory.
Dangerous stuff! "

Regards



Heinz

--

Dr Heinz M. Kabutz (PhD CompSci)

Author of "The Java(tm) Specialists' Newsletter"

Sun Java Champion

IEEE Certified Software Development Professional

http://www.javaspecialists.eu

Tel: +30 69 72 850 460

Skype: kabutz

On 11/17/11 12:53 PM, Roman Elizarov wrote:

The downside is that it fuels the use of sun.misc.Unsafe by 3rd party
programmer. Every day there are more and more blogs explaining
advantages of
Unsafe to the average programmer. I?ve just recently reposted
one of those
for the Russian programmers community.



Are there any concrete plans (say for Java 8) to bring the
performance of
**Updater classes on par with Unsafe (maybe by improving
HotSpot, so that it
can eliminate all the extra checks and compile **Updater
method into the
same code as produced by direct use of Unsafe)? Shall we
continue to rely on
Unsafe for Java 8 and beyond or get ready for its eventual
elimination from
our codebase?



Sincerely,

Roman Elizarov



From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On
Behalf Of Martin
Buchholz
Sent: Thursday, November 17, 2011 3:45 AM
To: Dr Heinz M. Kabutz
Cc: concurrency-interest
Subject: Re: [concurrency-interest] AtomicReferenceFieldUpdater
vs Unsafe




On Wed, Nov 16, 2011 at 13:37, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu>
wrote:

In Java 6, classes like ConcurrentLinkedQueue and
SynchronousQueue used the
AtomicReferenceFieldUpdater to update the next, head, etc. fields.

In Java 7, this was changed to instead use
Unsafe.compareAndSwapObject()
directly.

The AtomicReferenceFieldUpdater does a bunch of error checking
every time it
is called, like this:

          if (obj == null || obj.getClass() != tclass || cclass
!= null ||
              (update != null && vclass != null &&
               vclass != update.getClass()))
              updateCheck(obj, update);
          return unsafe.compareAndSwapObject(obj, offset,
expect, update);
My thinking is that the programmers changing
ConcurrentLinkedQueue et al
probably wanted to improve the performance by not having to
do all that
checking every time it is called.  The
Unsafe.compareAndSwapObject() method
is probably compiled to a single CPU instruction.

Is that correct?

Yes.



Is there any other reason for this change?

The previous way was more principled, in the manner of "eat your own
dogfood".  Maybe we've become just a tiny bit less principled.

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111130/7682a5d0/attachment-0001.html>

From hans.boehm at hp.com  Tue Nov 29 23:48:04 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 30 Nov 2011 04:48:04 +0000
Subject: [concurrency-interest] The JSR-133 Cookbook for Compiler Writers
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJIJBAA.davidcholmes@aapt.net.au>
References: <A3E67C2071F49C4CBC4F17E6D77CDDD20CC2F8@G4W3299.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCCEJIJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20CD2DB@G4W3299.americas.hpqcorp.net>

Thanks.  That sounds right.  You're use of "release" here is more of a StoreStore fence.  It's stronger than, for example, an Itanium release store, since the ordering is with respect to ALL subsequent stores, not just one.  (It's weaker in that it probably doesn't have to order preceding loads, though I don't think that matters on any current hardware, in my opinion, for good reason.)

Hans

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, November 28, 2011 3:11 PM
> To: Boehm, Hans
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] The JSR-133 Cookbook for Compiler
> Writers
> 
> Hans,
> 
> I may be mixing terminology here so let me clarify, when I say
> "release" I'm
> assuming an action such that given:
> 
> p = x;
> release();
> q = y;
> 
> then if you see q==y you are guaranteed to see p==x. Depending on the
> platform release() may need to be a full memory synchronization
> instruction,
> or a no-op.
> 
> In terms of the object allocation issue, constructing an object is a
> two
> stage process even at the bytecode level:
> - allocate the object
> - invoke the constructor
> 
> So logically we need the following sequence:
> 
> - allocate (and zero) memory
> - initialize object header etc
> - release()
> - invoke constructor
> - if (wrote_final_field)
>      release();
> 
> we need the release() after the object header initialization because at
> that
> point the object can become visible to the GC and so must be seen to be
> valid.
> 
> Now the JIT could inline all the above and maybe figure out how to
> remove
> one release(), but presently in hotspot the allocation and construction
> paths are quite distinct.
> 
> As release() is a no-op on x86 and sparc, you will not find explicit
> release() actions in all of the current hotspot code paths - something
> we
> will look at fixing.
> 
> David
> -----
> 
> > -----Original Message-----
> > From: Boehm, Hans [mailto:hans.boehm at hp.com]
> > Sent: Tuesday, 29 November 2011 5:06 AM
> > To: dholmes at ieee.org; Andrew Haley; Nathan Reynolds
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] The JSR-133 Cookbook for Compiler
> > Writers
> >
> >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > >
> > > Hi Hans,
> > >
> > > Hans Boehm writes:
> > > > How is the method table pointer any different from any other
> final
> > > > field here?  This code looks like the fence is not generated if
> the
> > > > method table pointer is written, but there are no other final
> fields.
> > > > I can't at the moment think of a way to defend that choice.
> > >
> > > A Java object contains a reference to its class, which in turn
> > holds the vtable
> > > pointer. That class reference may be stored using "release
> > semantics". I say
> > > "may" because the code is somewhat complex and its hard to know
> exactly
> > > what paths will be executed just be reading the code.
> > Thanks for the answer, but I remain confused.  Consider a
> > weakly-ordered platform like ARM or PowerPC, and the allocation
> > of an object p containing no final fields.  The generated
> > sequence seems to look something like (in C syntax):
> >
> > p = pointer_to_newly_allocated_memory;
> > p -> class_ptr = ptr_to_class;  // release operation ensures that
> > prior accesses become visible earlier
> > maybe other initialization;
> > // p is ready to use
> >
> > Assume this is done in thread 1, where user code then stores p
> > into a global q, and thread 2 calls q -> foo() (which involves a
> > racy read of q).  I see nothing ensuring that the store to p ->
> > class becomes visible before the store to q.  Using a release
> > store for the first one only orders it after preceding accesses,
> > such as the initialization of the class object.  Without such
> > ordering,  thread 2 can see the updated value of q, without
> > seeing the correct class_ptr value, potentially resulting in many
> > serious problems.
> >
> > Or did you mean that there is another, separate, fence AFTER the
> > class_ptr assignment?  That works, but it seems to me that should
> > often be combinable with the one for final fields?
> >
> > >
> > > From a practical perspective this is only an issue for non-TSO
> > systems when
> > > the object reference is subject to unsafe publication. Even for
> non-TSO
> > > systems the "distance" between the two stores makes it unlikely
> > (and no I
> > > can't quantify that) they will be reordered.
> > True, but relying on the latter seems like a really bad idea.  I
> > suspect that if this is really implemented incorrectly, the main
> > reason nobody has noticed is that, like all these things, it
> > works just fine in the absence of data races, which people
> > already correctly avoid most of the time.
> >
> > I'm pushing on this a bit, because I'm trying to understand
> > exactly how broken the memory model story currently is in the
> > presence of data races.  The more broken or needlessly expensive
> > it is, the better our chances of making a drastic change to fix
> things :-)
> >
> > >
> > > The constructor executes after that, so any final field
> > assignments there
> > > need their own release barrier.
> > I don't think that's the right way to think about it.  Turning
> > the field assignments into release stores doesn't help.  You need
> > to turn the racing publication (the assignment to q in the
> > example) into a release store, but that publication may be very
> > far away from the class_ptr or final field assignments.  I don't
> > see a way to do this except with an essentially unconditional
> > fence (lwsync on PowerPC) at the end of the constructor, and if
> > you can't preclude unsafe publication, probably another one after
> > the class_ptr store.
> >
> > Hans
> >



From radhakrishnan.mohan at gmail.com  Wed Nov 30 03:24:59 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 30 Nov 2011 13:54:59 +0530
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <CAOoXFP_r7A+4W+sY-5sWk2aMXnCkQNb1RaD3iAZ-bnta+LnSxA@mail.gmail.com>
References: <CAOoXFP97+NEHaeBZ8VXmmv=08qnggV1XUo87YJLvO=nQyO6udQ@mail.gmail.com>
	<4EC65112.5080802@googlemail.com>
	<CAOoXFP_r7A+4W+sY-5sWk2aMXnCkQNb1RaD3iAZ-bnta+LnSxA@mail.gmail.com>
Message-ID: <CAOoXFP-B80YUhpeYHOUxtcN+oxQSuQT4SHn3xdThdYNgeOeQHQ@mail.gmail.com>

I understand forkjoin has a work stealing algorithm that could be
useful on multicore processors. Can anyone point out what facility a
phaser has similarly to work better on multicore processors ? I
couldn't locate anything after a search.

Mohan

From davidcholmes at aapt.net.au  Wed Nov 30 04:24:42 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 30 Nov 2011 19:24:42 +1000
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <CAOoXFP-B80YUhpeYHOUxtcN+oxQSuQT4SHn3xdThdYNgeOeQHQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEKBJBAA.davidcholmes@aapt.net.au>

Mohan Radhakrishnan writes:
> I understand forkjoin has a work stealing algorithm that could be
> useful on multicore processors.

I think that is somewhat inverted. Parallel decomposition techniques benefit
from parallel processing - ie from multi-processors or multi-cores. Within
such a framework work-stealing is just a generic technique to allow
otherwise idle threads to continue doing useful work, avoid the need for
context switching and thus reduce overhead.

> Can anyone point out what facility a
> phaser has similarly to work better on multicore processors ? I
> couldn't locate anything after a search.

Sorry I don't understand the question - "work better" than what? A Phaser is
a generic synchronization barrier. As with the other j.u.c synchronizers it
utilizes lock-free techniques to improve scalability on multi-processors.

David Holmes


From viktor.klang at gmail.com  Wed Nov 30 04:32:08 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 30 Nov 2011 10:32:08 +0100
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEKBJBAA.davidcholmes@aapt.net.au>
References: <CAOoXFP-B80YUhpeYHOUxtcN+oxQSuQT4SHn3xdThdYNgeOeQHQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEKBJBAA.davidcholmes@aapt.net.au>
Message-ID: <CANPzfU8fCfbM+5iXNvWqJtZ0AUCDXcwsVQqQ3=Go3SVwveVwzA@mail.gmail.com>

On Wed, Nov 30, 2011 at 10:24 AM, David Holmes <davidcholmes at aapt.net.au>wrote:

> Mohan Radhakrishnan writes:
> > I understand forkjoin has a work stealing algorithm that could be
> > useful on multicore processors.
>
> I think that is somewhat inverted. Parallel decomposition techniques
> benefit
> from parallel processing - ie from multi-processors or multi-cores. Within
> such a framework work-stealing is just a generic technique to allow
> otherwise idle threads to continue doing useful work, avoid the need for
> context switching and thus reduce overhead.
>

I'd also say that worker-local task queues provide a really needed means of
write-striping.


>
> > Can anyone point out what facility a
> > phaser has similarly to work better on multicore processors ? I
> > couldn't locate anything after a search.
>
> Sorry I don't understand the question - "work better" than what? A Phaser
> is
> a generic synchronization barrier. As with the other j.u.c synchronizers it
> utilizes lock-free techniques to improve scalability on multi-processors.
>
> David Holmes
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111130/59d38593/attachment.html>

From radhakrishnan.mohan at gmail.com  Wed Nov 30 05:02:33 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 30 Nov 2011 15:32:33 +0530
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEKBJBAA.davidcholmes@aapt.net.au>
References: <CAOoXFP-B80YUhpeYHOUxtcN+oxQSuQT4SHn3xdThdYNgeOeQHQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEKBJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAOoXFP-nZLN+UwBLoeRQPZBN9Mt50rVrBDjmqRuaA8PcLRBbeg@mail.gmail.com>

I read this in "Phasers: a Unified Deadlock-Free Construct for
Collective and Point-to-point Synchronization"

"
By design, phasers are amenable to scalable implementation
on multicore SMPs, as demonstrated in Section
4."   -- > Since it is mentioned I was trying to find out how it works
better. So this means that it uses lock-free techniques like CAS ??

and also

"An activity has the option of registering
with a phaser in signal-only mode or wait-only
mode for producer-consumer synchronization, in addition
to signal-wait mode for barrier synchronization." --> I didn't get how
to map this to the API.

On Wed, Nov 30, 2011 at 2:54 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Mohan Radhakrishnan writes:
>> I understand forkjoin has a work stealing algorithm that could be
>> useful on multicore processors.
>
> I think that is somewhat inverted. Parallel decomposition techniques benefit
> from parallel processing - ie from multi-processors or multi-cores. Within
> such a framework work-stealing is just a generic technique to allow
> otherwise idle threads to continue doing useful work, avoid the need for
> context switching and thus reduce overhead.
>
>> Can anyone point out what facility a
>> phaser has similarly to work better on multicore processors ? I
>> couldn't locate anything after a search.
>
> Sorry I don't understand the question - "work better" than what? A Phaser is
> a generic synchronization barrier. As with the other j.u.c synchronizers it
> utilizes lock-free techniques to improve scalability on multi-processors.
>
> David Holmes
>

From davidcholmes at aapt.net.au  Wed Nov 30 06:08:42 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 30 Nov 2011 21:08:42 +1000
Subject: [concurrency-interest] Question about phasers and cache lines
In-Reply-To: <CAOoXFP-nZLN+UwBLoeRQPZBN9Mt50rVrBDjmqRuaA8PcLRBbeg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEKCJBAA.davidcholmes@aapt.net.au>

Mohan Radhakrishnan writes:
> I read this in "Phasers: a Unified Deadlock-Free Construct for
> Collective and Point-to-point Synchronization"
>
> "
> By design, phasers are amenable to scalable implementation
> on multicore SMPs, as demonstrated in Section
> 4."   -- > Since it is mentioned I was trying to find out how it works
> better. So this means that it uses lock-free techniques like CAS ??

 For j.u.c yes. For the paper you are citing you need to see the
implementations they used.

> and also
>
> "An activity has the option of registering
> with a phaser in signal-only mode or wait-only
> mode for producer-consumer synchronization, in addition
> to signal-wait mode for barrier synchronization." --> I didn't get how
> to map this to the API.

For the j.u.c.Phaser API:

Signal-only: arrive()
Wait-only: awaitAdvance()
signal-wait: arriveAndAwaitAdvance()

David
-----

> On Wed, Nov 30, 2011 at 2:54 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Mohan Radhakrishnan writes:
> >> I understand forkjoin has a work stealing algorithm that could be
> >> useful on multicore processors.
> >
> > I think that is somewhat inverted. Parallel decomposition
> techniques benefit
> > from parallel processing - ie from multi-processors or
> multi-cores. Within
> > such a framework work-stealing is just a generic technique to allow
> > otherwise idle threads to continue doing useful work, avoid the need for
> > context switching and thus reduce overhead.
> >
> >> Can anyone point out what facility a
> >> phaser has similarly to work better on multicore processors ? I
> >> couldn't locate anything after a search.
> >
> > Sorry I don't understand the question - "work better" than
> what? A Phaser is
> > a generic synchronization barrier. As with the other j.u.c
> synchronizers it
> > utilizes lock-free techniques to improve scalability on
> multi-processors.
> >
> > David Holmes
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From ashwin.jayaprakash at gmail.com  Wed Nov 30 20:00:06 2011
From: ashwin.jayaprakash at gmail.com (Ashwin Jayaprakash)
Date: Wed, 30 Nov 2011 17:00:06 -0800
Subject: [concurrency-interest] Concurrent indexed queue
Message-ID: <CAF9YjSCFNUpG=rKGkYYQWCiBP-uSi3xfjSWOSo81yZCret1i-w@mail.gmail.com>

I realized only today that my attempt at describing my data structure using
ascii art was a bad idea. Formatting got messed up. Just for my ref, here's
an image of the same:


[image: Concurrent indexed queue.PNG]



Wouldn't you need multiple datastructures to have indexed access to a
> queue?
>
> Perhaps something like this?
>
> 1. The simple queue on the left just ensures the insertion order 2. But
> first you'd have to use a map where the values are a list of nodes. Each
> node in that list has a certain version of the data 3. Add the node to that
> list (middle of figure) atomically, then enqueue a pointer to that node
> into the main queue 4. The consumer will keep reading from the head of the
> queue, follow the pointer to the versioned node (the list in the middle) 1.
> It will remove the first versioned node from the list in the middle 2. If
> there are any other nodes, then it will keep going down that list and
> toggle those nodes are alreadySeen until it hits the end 5. Obviously it
> will see this versioned chain again further down the queue. But it now
> knows that it has already seen it, so it will clear that versioned node 1.
> It can follow that chain if there are any newer versions (Like Step 4.2)
>
> This would be a really useful datastructure to have as an open source
> library (hint hint).
>
> Regards, Ashwin Jayaprakash.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111130/c84112f5/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 23478 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111130/c84112f5/attachment-0001.png>

