From nathan.reynolds at oracle.com  Tue Oct  1 13:24:11 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 01 Oct 2013 10:24:11 -0700
Subject: [concurrency-interest] Default Functions for Lock Interface
Message-ID: <524B053B.3000605@oracle.com>

Here's an example of code using ReentrantLock.

private final ReentrantLock m_lock = new ReentrantLock();
private       int           m_count;
private final int           m_capacity;

public boolean reserve()
{
    m_lock.lock();

    try
    {
       if (m_count >= m_capacity)
          return(false);

       m_count++;

       return(true);
    }
    finally
    {
       m_lock.unlock();
    }
}

There are several problems with this code.  1)  You have to remember to 
call unlock().  2)  You have to put the unlock() in the finally block.  
3)  The finally block can't have other exception throwing constructs or 
the lock won't be released on some code paths.  4) The m_lock reference 
shouldn't be allowed to change while a thread is executing inside reserve().

After attending JavaOne and hearing about lambdas and default methods in 
interfaces, I came up with an idea to make writing locked code less 
error prone.  The idea is to provide default methods in the Lock 
interface which would make writing the above code simpler and less error 
prone.  Here's one such method.

public void guard(Runnable guarded)
{
    lock();

    try
    {
       guarded.run();
    }
    finally
    {
       unlock();
    }
}

With the guard() method available, the reserve() method can be rewritten 
in JDK 8 as such.

public boolean reserve()
{
    return(m_lock.guard(() ->
    {
       if (m_count >= m_capacity)
          return(false);

       m_count++;

       return(true);
    }));
}

All the aforementioned problems are no longer applicable.  guard() takes 
care of them.  The code is much clearer to understand since the 
boilerplate locking code is gone.  It also might help JIT by reducing 
the amount of cookie cutter code it has to optimize.

Here are the method signatures of other methods which could be added to 
the Lock interface.  The full code is available at 
https://bugs.openjdk.java.net/browse/JDK-8025597.

    public <T> T           guard(Callable<T> guarded) throws Exception
    public     void        guardInterruptibly(Runnable guarded) throws 
InterruptedException
    public <T> T guardInterruptibly(Callable<T> guarded) throws 
Exception, InterruptedException
    public     boolean     tryGuard(Runnable guarded)
    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
    public     boolean     tryGuard(Runnable guarded, long time, 
TimeUnit unit) throws InterruptedException
    public <T> Optional<T> tryGuard(Callable<T> guarded, long time, 
TimeUnit unit) throws Exception, InterruptedException

What do you think?  Please ignore formatting and method names for the 
moment.

-- 
-Nathan

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131001/a3616cc0/attachment.html>

From zhong.j.yu at gmail.com  Tue Oct  1 13:57:56 2013
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 1 Oct 2013 12:57:56 -0500
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <524B053B.3000605@oracle.com>
References: <524B053B.3000605@oracle.com>
Message-ID: <CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>

To make your decision process a little more difficult, also weigh in
the design choice of using try-with-resources statement

public boolean reserve()
{
   try(Foo foo = m_lock.foo()) // TBA names
   {
      if (m_count >= m_capacity)
         return(false);

      m_count++;

      return(true);
   }
   // auto close `foo` which releases the lock
}

This is more verbose; the benefit is that the critical section is a
local code block.

Zhong Yu




On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:
> Here's an example of code using ReentrantLock.
>
> private final ReentrantLock m_lock = new ReentrantLock();
> private       int           m_count;
> private final int           m_capacity;
>
> public boolean reserve()
> {
>    m_lock.lock();
>
>    try
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }
>    finally
>    {
>       m_lock.unlock();
>    }
> }
>
> There are several problems with this code.  1)  You have to remember to call
> unlock().  2)  You have to put the unlock() in the finally block.  3)  The
> finally block can't have other exception throwing constructs or the lock
> won't be released on some code paths.  4)  The m_lock reference shouldn't be
> allowed to change while a thread is executing inside reserve().
>
> After attending JavaOne and hearing about lambdas and default methods in
> interfaces, I came up with an idea to make writing locked code less error
> prone.  The idea is to provide default methods in the Lock interface which
> would make writing the above code simpler and less error prone.  Here's one
> such method.
>
> public void guard(Runnable guarded)
> {
>    lock();
>
>    try
>    {
>       guarded.run();
>    }
>    finally
>    {
>       unlock();
>    }
> }
>
> With the guard() method available, the reserve() method can be rewritten in
> JDK 8 as such.
>
> public boolean reserve()
> {
>    return(m_lock.guard(() ->
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }));
> }
>
> All the aforementioned problems are no longer applicable.  guard() takes
> care of them.  The code is much clearer to understand since the boilerplate
> locking code is gone.  It also might help JIT by reducing the amount of
> cookie cutter code it has to optimize.
>
> Here are the method signatures of other methods which could be added to the
> Lock interface.  The full code is available at
> https://bugs.openjdk.java.net/browse/JDK-8025597.
>
>    public <T> T           guard(Callable<T> guarded) throws Exception
>    public     void        guardInterruptibly(Runnable guarded) throws
> InterruptedException
>    public <T> T           guardInterruptibly(Callable<T> guarded) throws
> Exception, InterruptedException
>    public     boolean     tryGuard(Runnable guarded)
>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
> unit) throws InterruptedException
>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time, TimeUnit
> unit) throws Exception, InterruptedException
>
> What do you think?  Please ignore formatting and method names for the
> moment.
>
> --
> -Nathan
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From yankee.sierra at gmail.com  Tue Oct  1 15:38:14 2013
From: yankee.sierra at gmail.com (Yuval Shavit)
Date: Tue, 1 Oct 2013 15:38:14 -0400
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
References: <524B053B.3000605@oracle.com>
	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
Message-ID: <CAE+h5-AH0Tx4eHdstYmo1ogqFpaRmfBH5+rjo2g0K9zdHwCVbw@mail.gmail.com>

I've actually wondered for a while why Lock doesn't work with
try-with-resources. Seems like it could be as easy as implementing close()
to forward to unlock(). If binary compatibility was the issue, maybe Java
8's defender methods are the solution?

On Tue, Oct 1, 2013 at 1:57 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> To make your decision process a little more difficult, also weigh in
> the design choice of using try-with-resources statement
>
> public boolean reserve()
> {
>    try(Foo foo = m_lock.foo()) // TBA names
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }
>    // auto close `foo` which releases the lock
> }
>
> This is more verbose; the benefit is that the critical section is a
> local code block.
>
> Zhong Yu
>
>
>
>
> On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
> <nathan.reynolds at oracle.com> wrote:
> > Here's an example of code using ReentrantLock.
> >
> > private final ReentrantLock m_lock = new ReentrantLock();
> > private       int           m_count;
> > private final int           m_capacity;
> >
> > public boolean reserve()
> > {
> >    m_lock.lock();
> >
> >    try
> >    {
> >       if (m_count >= m_capacity)
> >          return(false);
> >
> >       m_count++;
> >
> >       return(true);
> >    }
> >    finally
> >    {
> >       m_lock.unlock();
> >    }
> > }
> >
> > There are several problems with this code.  1)  You have to remember to
> call
> > unlock().  2)  You have to put the unlock() in the finally block.  3)
>  The
> > finally block can't have other exception throwing constructs or the lock
> > won't be released on some code paths.  4)  The m_lock reference
> shouldn't be
> > allowed to change while a thread is executing inside reserve().
> >
> > After attending JavaOne and hearing about lambdas and default methods in
> > interfaces, I came up with an idea to make writing locked code less error
> > prone.  The idea is to provide default methods in the Lock interface
> which
> > would make writing the above code simpler and less error prone.  Here's
> one
> > such method.
> >
> > public void guard(Runnable guarded)
> > {
> >    lock();
> >
> >    try
> >    {
> >       guarded.run();
> >    }
> >    finally
> >    {
> >       unlock();
> >    }
> > }
> >
> > With the guard() method available, the reserve() method can be rewritten
> in
> > JDK 8 as such.
> >
> > public boolean reserve()
> > {
> >    return(m_lock.guard(() ->
> >    {
> >       if (m_count >= m_capacity)
> >          return(false);
> >
> >       m_count++;
> >
> >       return(true);
> >    }));
> > }
> >
> > All the aforementioned problems are no longer applicable.  guard() takes
> > care of them.  The code is much clearer to understand since the
> boilerplate
> > locking code is gone.  It also might help JIT by reducing the amount of
> > cookie cutter code it has to optimize.
> >
> > Here are the method signatures of other methods which could be added to
> the
> > Lock interface.  The full code is available at
> > https://bugs.openjdk.java.net/browse/JDK-8025597.
> >
> >    public <T> T           guard(Callable<T> guarded) throws Exception
> >    public     void        guardInterruptibly(Runnable guarded) throws
> > InterruptedException
> >    public <T> T           guardInterruptibly(Callable<T> guarded) throws
> > Exception, InterruptedException
> >    public     boolean     tryGuard(Runnable guarded)
> >    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
> >    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
> > unit) throws InterruptedException
> >    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> TimeUnit
> > unit) throws Exception, InterruptedException
> >
> > What do you think?  Please ignore formatting and method names for the
> > moment.
> >
> > --
> > -Nathan
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131001/6e6ce58e/attachment.html>

From jeffhain at rocketmail.com  Tue Oct  1 16:01:13 2013
From: jeffhain at rocketmail.com (Jeff Hain)
Date: Tue, 1 Oct 2013 21:01:13 +0100 (BST)
Subject: [concurrency-interest] Default Functions for Lock Interface
Message-ID: <1380657673.84878.YahooMailNeo@web171706.mail.ir2.yahoo.com>

Hi.

I would rather put these methods in a new interface (Locker?),
to make intrinsic-lock (or even no lock) based implementations
possible(and Lock could extend it).
Then you could define another interface extending both this
new one and Condition (could call it condilock(er)), that would
allow (on its own) to wait for a Supplier<Boolean> to supply true,
in a way that would abstract away both the wait policy (busy or yielding
spin before lock, etc.) and the lock type (intrinsic, extrinsic, or no lock).

-Jeff
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131001/40810c28/attachment-0001.html>

From dragonsinth at gmail.com  Tue Oct  1 17:30:37 2013
From: dragonsinth at gmail.com (Scott Blum)
Date: Tue, 1 Oct 2013 17:30:37 -0400
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <1380657673.84878.YahooMailNeo@web171706.mail.ir2.yahoo.com>
References: <1380657673.84878.YahooMailNeo@web171706.mail.ir2.yahoo.com>
Message-ID: <CALuNCpjJh6gkXiSQ6AAFbHyv10hyPGt+BasDzMkDAcKci_vgeA@mail.gmail.com>

Heh, I just added almost exactly this utility class to our internal common
library this week.  I too was a bit surprised Lock didn't already have
something like that, or some other sort of utility didn't exist.  We used a
syntax like

Locks.with(Lock).run(Runnable), Locks.with(Lock).call(Callable)

Not super attached to 'with' but I didn't have a better name handy.


On Tue, Oct 1, 2013 at 4:01 PM, Jeff Hain <jeffhain at rocketmail.com> wrote:

> Hi.
>
> I would rather put these methods in a new interface (Locker?),
> to make intrinsic-lock (or even no lock) based implementations
> possible (and Lock could extend it).
>
> Then you could define another interface extending both this
> new one and Condition (could call it condilock(er)), that would
> allow (on its own) to wait for a Supplier<Boolean> to supply true,
> in a way that would abstract away both the wait policy (busy or yielding
> spin before lock, etc.) and the lock type (intrinsic, extrinsic, or no
> lock).
>
> -Jeff
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131001/49314b6a/attachment.html>

From nathan.reynolds at oracle.com  Tue Oct  1 17:52:22 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 01 Oct 2013 14:52:22 -0700
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CALuNCpjJh6gkXiSQ6AAFbHyv10hyPGt+BasDzMkDAcKci_vgeA@mail.gmail.com>
References: <1380657673.84878.YahooMailNeo@web171706.mail.ir2.yahoo.com>
	<CALuNCpjJh6gkXiSQ6AAFbHyv10hyPGt+BasDzMkDAcKci_vgeA@mail.gmail.com>
Message-ID: <524B4416.3020206@oracle.com>

If the methods are added as I proposed, then you wouldn't need a 
".with(lock)".  You would simply do lock.run(Runnable) or 
lock.call(Callable) since run() and call() would be member methods of 
the Lock interface.

-Nathan

On 10/1/2013 2:30 PM, Scott Blum wrote:
> Heh, I just added almost exactly this utility class to our internal 
> common library this week.  I too was a bit surprised Lock didn't 
> already have something like that, or some other sort of utility didn't 
> exist.  We used a syntax like
>
> Locks.with(Lock).run(Runnable), Locks.with(Lock).call(Callable)
>
> Not super attached to 'with' but I didn't have a better name handy.
>
>
> On Tue, Oct 1, 2013 at 4:01 PM, Jeff Hain <jeffhain at rocketmail.com 
> <mailto:jeffhain at rocketmail.com>> wrote:
>
>     Hi.
>
>     I would rather put these methods in a new interface (Locker?),
>     to make intrinsic-lock (or even no lock) based implementations
>     possible(and Lock could extend it).
>
>     Then you could define another interface extending both this
>     new one and Condition (could call it condilock(er)), that would
>     allow (on its own) to wait for a Supplier<Boolean> to supply true,
>     in a way that would abstract away both the wait policy (busy or
>     yielding
>     spin before lock, etc.) and the lock type (intrinsic, extrinsic,
>     or no lock).
>
>     -Jeff
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131001/edbf981d/attachment.html>

From ron.pressler at gmail.com  Wed Oct  2 03:39:54 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Wed, 2 Oct 2013 10:39:54 +0300
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <524B053B.3000605@oracle.com>
References: <524B053B.3000605@oracle.com>
Message-ID: <CABg6-qiXzRuWJSxewJ=p-tL09uLGa3frq-PgE1fkJOBu9qm1AA@mail.gmail.com>

It could work. Scala has added a very similar feature recently:
https://github.com/lcycon/scala/commit/a911b247000bff517b65d306b31db1b4148c1ad0

I, too, would have preferred Yuval Shavit's try-with-resources solution,
though. It would save the extra 'return', and it actually fits the purpose
of TWR nicely. It would require ARM to work without assigning the return
value to a local, which is cumbersome (and while I'm on the subject, it
would be nice for TWR to work even if the  compile time type of the return
value isn't AutoCloseable, but the runtime type is).


On Tue, Oct 1, 2013 at 8:24 PM, Nathan Reynolds
<nathan.reynolds at oracle.com>wrote:

>  Here's an example of code using ReentrantLock.
>
> private final ReentrantLock m_lock = new ReentrantLock();
> private       int           m_count;
> private final int           m_capacity;
>
> public boolean reserve()
> {
>    m_lock.lock();
>
>    try
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }
>    finally
>    {
>       m_lock.unlock();
>    }
> }
>
> There are several problems with this code.  1)  You have to remember to
> call unlock().  2)  You have to put the unlock() in the finally block.  3)
> The finally block can't have other exception throwing constructs or the
> lock won't be released on some code paths.  4)  The m_lock reference
> shouldn't be allowed to change while a thread is executing inside reserve().
>
> After attending JavaOne and hearing about lambdas and default methods in
> interfaces, I came up with an idea to make writing locked code less error
> prone.  The idea is to provide default methods in the Lock interface which
> would make writing the above code simpler and less error prone.  Here's one
> such method.
>
> public void guard(Runnable guarded)
> {
>    lock();
>
>    try
>    {
>       guarded.run();
>    }
>    finally
>    {
>       unlock();
>    }
> }
>
> With the guard() method available, the reserve() method can be rewritten
> in JDK 8 as such.
>
> public boolean reserve()
> {
>    return(m_lock.guard(() ->
>    {
>        if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }));
> }
>
> All the aforementioned problems are no longer applicable.  guard() takes
> care of them.  The code is much clearer to understand since the boilerplate
> locking code is gone.  It also might help JIT by reducing the amount of
> cookie cutter code it has to optimize.
>
> Here are the method signatures of other methods which could be added to
> the Lock interface.  The full code is available at
> https://bugs.openjdk.java.net/browse/JDK-8025597.
>
>    public <T> T           guard(Callable<T> guarded) throws Exception
>    public     void        guardInterruptibly(Runnable guarded) throws
> InterruptedException
>    public <T> T           guardInterruptibly(Callable<T> guarded) throws
> Exception, InterruptedException
>    public     boolean     tryGuard(Runnable guarded)
>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
> unit) throws InterruptedException
>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> TimeUnit unit) throws Exception, InterruptedException
>
> What do you think?  Please ignore formatting and method names for the
> moment.
>
> --
> -Nathan
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/c40871aa/attachment.html>

From GJAllen at wellington.com  Wed Oct  2 04:50:54 2013
From: GJAllen at wellington.com (Allen, Greg J)
Date: Wed, 2 Oct 2013 08:50:54 +0000
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
References: <524B053B.3000605@oracle.com>
	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
Message-ID: <152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>

Wow, has Java finally caught up with Modula 3?

http://www.cs.purdue.edu/homes/hosking/m3/reference/lock.html

A LOCK statement has the form: 
    LOCK mu DO S END

where S is a statement and mu is an expression. It is equivalent to:     WITH m = mu DO
      Thread.Acquire(m);
      TRY S FINALLY Thread.Release(m) END
    END

where m stands for a variable that does not occur in S.

:) 

Greg

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Zhong Yu
Sent: Tuesday 01 October 2013 18:58
To: Nathan Reynolds
Cc: concurrency-interest
Subject: Re: [concurrency-interest] Default Functions for Lock Interface

To make your decision process a little more difficult, also weigh in
the design choice of using try-with-resources statement

public boolean reserve()
{
   try(Foo foo = m_lock.foo()) // TBA names
   {
      if (m_count >= m_capacity)
         return(false);

      m_count++;

      return(true);
   }
   // auto close `foo` which releases the lock
}

This is more verbose; the benefit is that the critical section is a
local code block.

Zhong Yu




On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:
> Here's an example of code using ReentrantLock.
>
> private final ReentrantLock m_lock = new ReentrantLock();
> private       int           m_count;
> private final int           m_capacity;
>
> public boolean reserve()
> {
>    m_lock.lock();
>
>    try
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }
>    finally
>    {
>       m_lock.unlock();
>    }
> }
>
> There are several problems with this code.  1)  You have to remember to call
> unlock().  2)  You have to put the unlock() in the finally block.  3)  The
> finally block can't have other exception throwing constructs or the lock
> won't be released on some code paths.  4)  The m_lock reference shouldn't be
> allowed to change while a thread is executing inside reserve().
>
> After attending JavaOne and hearing about lambdas and default methods in
> interfaces, I came up with an idea to make writing locked code less error
> prone.  The idea is to provide default methods in the Lock interface which
> would make writing the above code simpler and less error prone.  Here's one
> such method.
>
> public void guard(Runnable guarded)
> {
>    lock();
>
>    try
>    {
>       guarded.run();
>    }
>    finally
>    {
>       unlock();
>    }
> }
>
> With the guard() method available, the reserve() method can be rewritten in
> JDK 8 as such.
>
> public boolean reserve()
> {
>    return(m_lock.guard(() ->
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }));
> }
>
> All the aforementioned problems are no longer applicable.  guard() takes
> care of them.  The code is much clearer to understand since the boilerplate
> locking code is gone.  It also might help JIT by reducing the amount of
> cookie cutter code it has to optimize.
>
> Here are the method signatures of other methods which could be added to the
> Lock interface.  The full code is available at
> https://bugs.openjdk.java.net/browse/JDK-8025597.
>
>    public <T> T           guard(Callable<T> guarded) throws Exception
>    public     void        guardInterruptibly(Runnable guarded) throws
> InterruptedException
>    public <T> T           guardInterruptibly(Callable<T> guarded) throws
> Exception, InterruptedException
>    public     boolean     tryGuard(Runnable guarded)
>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
> unit) throws InterruptedException
>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time, TimeUnit
> unit) throws Exception, InterruptedException
>
> What do you think?  Please ignore formatting and method names for the
> moment.
>
> --
> -Nathan
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


--------------------------------------------
This is an email from Wellington Management International Limited, a limited company incorporated in England and Wales (company number 4283513). The contents of this email are confidential to the ordinary user of the email address to which it was addressed. No one else may copy or forward all or any of it in any form. If you receive this email in error, we should be obliged if you would telephone us on +44 20 7126 6000. This communication is directed only at persons (Relevant Persons) who are classified as eligible counterparties or professional clients under the rules of the Financial Conduct Authority. This communication must not be acted on or relied on by persons who are not Relevant Persons. Any investment or investment service to which this communication relates is available only to Relevant Persons and will be engaged in only with Relevant Persons. Wellington Management International Limited (FRN208573) is authorised and regulated in the United Kingdom by the Financial Conduct Authority and registered in the Financial Services Register (at http://www.fsa.gov.uk/register/) under the above number. The firm has its registered office at Cardinal Place, 80 Victoria Street, London SW1E 5JL.


From yankee.sierra at gmail.com  Wed Oct  2 11:04:53 2013
From: yankee.sierra at gmail.com (Yuval Shavit)
Date: Wed, 2 Oct 2013 11:04:53 -0400
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>
References: <524B053B.3000605@oracle.com>
	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
	<152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>
Message-ID: <CAE+h5-D9T2zj31gw1N5zjNZp9C-uPu1odZWqeARtHiuKp5Fzuw@mail.gmail.com>

One issue with lock.run(r) as opposed to Locks.with(lock).run(r) is that it
doesn't work well in the case that you want to acquire multiple locks. I
don't know if that's a major concern -- it could be that this is considered
enough of an experts-only use case that it's best to use a more manual
approach, like the current try-finally or TWR.

What's the connection between TWR and ARM? I didn't catch that.


On Wed, Oct 2, 2013 at 4:50 AM, Allen, Greg J <GJAllen at wellington.com>wrote:

> Wow, has Java finally caught up with Modula 3?
>
> http://www.cs.purdue.edu/homes/hosking/m3/reference/lock.html
>
> A LOCK statement has the form:
>     LOCK mu DO S END
>
> where S is a statement and mu is an expression. It is equivalent to:
> WITH m = mu DO
>       Thread.Acquire(m);
>       TRY S FINALLY Thread.Release(m) END
>     END
>
> where m stands for a variable that does not occur in S.
>
> :)
>
> Greg
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Zhong Yu
> Sent: Tuesday 01 October 2013 18:58
> To: Nathan Reynolds
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] Default Functions for Lock Interface
>
> To make your decision process a little more difficult, also weigh in
> the design choice of using try-with-resources statement
>
> public boolean reserve()
> {
>    try(Foo foo = m_lock.foo()) // TBA names
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }
>    // auto close `foo` which releases the lock
> }
>
> This is more verbose; the benefit is that the critical section is a
> local code block.
>
> Zhong Yu
>
>
>
>
> On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
> <nathan.reynolds at oracle.com> wrote:
> > Here's an example of code using ReentrantLock.
> >
> > private final ReentrantLock m_lock = new ReentrantLock();
> > private       int           m_count;
> > private final int           m_capacity;
> >
> > public boolean reserve()
> > {
> >    m_lock.lock();
> >
> >    try
> >    {
> >       if (m_count >= m_capacity)
> >          return(false);
> >
> >       m_count++;
> >
> >       return(true);
> >    }
> >    finally
> >    {
> >       m_lock.unlock();
> >    }
> > }
> >
> > There are several problems with this code.  1)  You have to remember to
> call
> > unlock().  2)  You have to put the unlock() in the finally block.  3)
>  The
> > finally block can't have other exception throwing constructs or the lock
> > won't be released on some code paths.  4)  The m_lock reference
> shouldn't be
> > allowed to change while a thread is executing inside reserve().
> >
> > After attending JavaOne and hearing about lambdas and default methods in
> > interfaces, I came up with an idea to make writing locked code less error
> > prone.  The idea is to provide default methods in the Lock interface
> which
> > would make writing the above code simpler and less error prone.  Here's
> one
> > such method.
> >
> > public void guard(Runnable guarded)
> > {
> >    lock();
> >
> >    try
> >    {
> >       guarded.run();
> >    }
> >    finally
> >    {
> >       unlock();
> >    }
> > }
> >
> > With the guard() method available, the reserve() method can be rewritten
> in
> > JDK 8 as such.
> >
> > public boolean reserve()
> > {
> >    return(m_lock.guard(() ->
> >    {
> >       if (m_count >= m_capacity)
> >          return(false);
> >
> >       m_count++;
> >
> >       return(true);
> >    }));
> > }
> >
> > All the aforementioned problems are no longer applicable.  guard() takes
> > care of them.  The code is much clearer to understand since the
> boilerplate
> > locking code is gone.  It also might help JIT by reducing the amount of
> > cookie cutter code it has to optimize.
> >
> > Here are the method signatures of other methods which could be added to
> the
> > Lock interface.  The full code is available at
> > https://bugs.openjdk.java.net/browse/JDK-8025597.
> >
> >    public <T> T           guard(Callable<T> guarded) throws Exception
> >    public     void        guardInterruptibly(Runnable guarded) throws
> > InterruptedException
> >    public <T> T           guardInterruptibly(Callable<T> guarded) throws
> > Exception, InterruptedException
> >    public     boolean     tryGuard(Runnable guarded)
> >    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
> >    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
> > unit) throws InterruptedException
> >    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> TimeUnit
> > unit) throws Exception, InterruptedException
> >
> > What do you think?  Please ignore formatting and method names for the
> > moment.
> >
> > --
> > -Nathan
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> --------------------------------------------
> This is an email from Wellington Management International Limited, a
> limited company incorporated in England and Wales (company number 4283513).
> The contents of this email are confidential to the ordinary user of the
> email address to which it was addressed. No one else may copy or forward
> all or any of it in any form. If you receive this email in error, we should
> be obliged if you would telephone us on +44 20 7126 6000. This
> communication is directed only at persons (Relevant Persons) who are
> classified as eligible counterparties or professional clients under the
> rules of the Financial Conduct Authority. This communication must not be
> acted on or relied on by persons who are not Relevant Persons. Any
> investment or investment service to which this communication relates is
> available only to Relevant Persons and will be engaged in only with
> Relevant Persons. Wellington Management International Limited (FRN208573)
> is authorised and regulated in the United Kingdom by the Financia!
>  l Conduct Authority and registered in the Financial Services Register (at
> http://www.fsa.gov.uk/register/) under the above number. The firm has its
> registered office at Cardinal Place, 80 Victoria Street, London SW1E 5JL.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/11f3f7a8/attachment.html>

From peter.levart at gmail.com  Wed Oct  2 12:21:01 2013
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 02 Oct 2013 18:21:01 +0200
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CAE+h5-D9T2zj31gw1N5zjNZp9C-uPu1odZWqeARtHiuKp5Fzuw@mail.gmail.com>
References: <524B053B.3000605@oracle.com>
	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
	<152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>
	<CAE+h5-D9T2zj31gw1N5zjNZp9C-uPu1odZWqeARtHiuKp5Fzuw@mail.gmail.com>
Message-ID: <524C47ED.4010006@gmail.com>

On 10/02/2013 05:04 PM, Yuval Shavit wrote:
> What's the connection between TWR and ARM? I didn't catch that.

ARM (Automatic Resource Management) was a working title for TWR (Try 
With Resources).

Peter


From zhong.j.yu at gmail.com  Wed Oct  2 12:26:04 2013
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 2 Oct 2013 11:26:04 -0500
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>
References: <524B053B.3000605@oracle.com>
	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
	<152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>
Message-ID: <CACuKZqH-ueUhWYRKshyqbX=ZyK6+Dn=bNs_HY4xpknA_VymrKA@mail.gmail.com>

Java does have this nice control structure since 1995 :)

    synchronized(lock)
    {

    } // auto release lock

The question now is whether it's easy to define custom control
structure in Java. Not every easy I would say. The problem with lambda
body is that it doesn't work like a local code block (well - it's not
a problem for people who dislike imperative programming and checked
exception anyway:)

Zhong Yu


On Wed, Oct 2, 2013 at 3:50 AM, Allen, Greg J <GJAllen at wellington.com> wrote:
> Wow, has Java finally caught up with Modula 3?
>
> http://www.cs.purdue.edu/homes/hosking/m3/reference/lock.html
>
> A LOCK statement has the form:
>     LOCK mu DO S END
>
> where S is a statement and mu is an expression. It is equivalent to:     WITH m = mu DO
>       Thread.Acquire(m);
>       TRY S FINALLY Thread.Release(m) END
>     END
>
> where m stands for a variable that does not occur in S.
>
> :)
>
> Greg
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Zhong Yu
> Sent: Tuesday 01 October 2013 18:58
> To: Nathan Reynolds
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] Default Functions for Lock Interface
>
> To make your decision process a little more difficult, also weigh in
> the design choice of using try-with-resources statement
>
> public boolean reserve()
> {
>    try(Foo foo = m_lock.foo()) // TBA names
>    {
>       if (m_count >= m_capacity)
>          return(false);
>
>       m_count++;
>
>       return(true);
>    }
>    // auto close `foo` which releases the lock
> }
>
> This is more verbose; the benefit is that the critical section is a
> local code block.
>
> Zhong Yu
>
>
>
>
> On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
> <nathan.reynolds at oracle.com> wrote:
>> Here's an example of code using ReentrantLock.
>>
>> private final ReentrantLock m_lock = new ReentrantLock();
>> private       int           m_count;
>> private final int           m_capacity;
>>
>> public boolean reserve()
>> {
>>    m_lock.lock();
>>
>>    try
>>    {
>>       if (m_count >= m_capacity)
>>          return(false);
>>
>>       m_count++;
>>
>>       return(true);
>>    }
>>    finally
>>    {
>>       m_lock.unlock();
>>    }
>> }
>>
>> There are several problems with this code.  1)  You have to remember to call
>> unlock().  2)  You have to put the unlock() in the finally block.  3)  The
>> finally block can't have other exception throwing constructs or the lock
>> won't be released on some code paths.  4)  The m_lock reference shouldn't be
>> allowed to change while a thread is executing inside reserve().
>>
>> After attending JavaOne and hearing about lambdas and default methods in
>> interfaces, I came up with an idea to make writing locked code less error
>> prone.  The idea is to provide default methods in the Lock interface which
>> would make writing the above code simpler and less error prone.  Here's one
>> such method.
>>
>> public void guard(Runnable guarded)
>> {
>>    lock();
>>
>>    try
>>    {
>>       guarded.run();
>>    }
>>    finally
>>    {
>>       unlock();
>>    }
>> }
>>
>> With the guard() method available, the reserve() method can be rewritten in
>> JDK 8 as such.
>>
>> public boolean reserve()
>> {
>>    return(m_lock.guard(() ->
>>    {
>>       if (m_count >= m_capacity)
>>          return(false);
>>
>>       m_count++;
>>
>>       return(true);
>>    }));
>> }
>>
>> All the aforementioned problems are no longer applicable.  guard() takes
>> care of them.  The code is much clearer to understand since the boilerplate
>> locking code is gone.  It also might help JIT by reducing the amount of
>> cookie cutter code it has to optimize.
>>
>> Here are the method signatures of other methods which could be added to the
>> Lock interface.  The full code is available at
>> https://bugs.openjdk.java.net/browse/JDK-8025597.
>>
>>    public <T> T           guard(Callable<T> guarded) throws Exception
>>    public     void        guardInterruptibly(Runnable guarded) throws
>> InterruptedException
>>    public <T> T           guardInterruptibly(Callable<T> guarded) throws
>> Exception, InterruptedException
>>    public     boolean     tryGuard(Runnable guarded)
>>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>>    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
>> unit) throws InterruptedException
>>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time, TimeUnit
>> unit) throws Exception, InterruptedException
>>
>> What do you think?  Please ignore formatting and method names for the
>> moment.
>>
>> --
>> -Nathan
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> --------------------------------------------
>
> This is an email from Wellington Management International Limited, a limited company incorporated in England and Wales (company number 4283513). The contents of this email are confidential to the ordinary user of the email address to which it was addressed. No one else may copy or forward all or any of it in any form. If you receive this email in error, we should be obliged if you would telephone us on +44 20 7126 6000. This communication is directed only at persons (Relevant Persons) who are classified as eligible counterparties or professional clients under the rules of the Financial Conduct Authority. This communication must not be acted on or relied on by persons who are not Relevant Persons. Any investment or investment service to which this communication relates is available only to Relevant Persons and will be engaged in only with Relevant Persons. Wellington Management International Limited (FRN208573) is authorised and regulated in the United Kingdom by the Financial Conduct Authority and registered in the Financial Services Register (at http://www.fsa.gov.uk/register/) under the above number. The firm has its registered office at Cardinal Place, 80 Victoria Street, London SW1E 5JL.


From martinrb at google.com  Wed Oct  2 12:29:32 2013
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 2 Oct 2013 09:29:32 -0700
Subject: [concurrency-interest] FutureTask.cancel(true) should run
	thread.interrupt within doPrivileged
Message-ID: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>

FutureTask.cancel(true) invokes thread.interrupt on the thread (if any)
currently running the task.
This should succeed even if modifyThread permission is denied by the
security manager.

Here's a proposed fix for jdk8+:

--- src/main/java/util/concurrent/FutureTask.java 15 May 2013 02:39:59 -0000
1.103
+++ src/main/java/util/concurrent/FutureTask.java 2 Oct 2013 16:25:23 -0000
@@ -132,6 +132,12 @@
         return state != NEW;
     }

+    private static void privilegedInterrupt(Thread t) {
+        java.security.PrivilegedAction<Void> doInterrupt =
+            () -> { t.interrupt(); return null; };
+        java.security.AccessController.doPrivileged(doInterrupt);
+    }
+
     public boolean cancel(boolean mayInterruptIfRunning) {
         if (!(state == NEW &&
               UNSAFE.compareAndSwapInt(this, stateOffset, NEW,
@@ -142,7 +148,11 @@
                 try {
                     Thread t = runner;
                     if (t != null)
-                        t.interrupt();
+                        try {
+                            t.interrupt();
+                        } catch (SecurityException e) {
+                            privilegedInterrupt(t);
+                        }
                 } finally { // final state
                     UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);
                 }
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/a942e5e7/attachment.html>

From peter.levart at gmail.com  Wed Oct  2 12:49:31 2013
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 02 Oct 2013 18:49:31 +0200
Subject: [concurrency-interest] FutureTask.cancel(true) should run
	thread.interrupt within doPrivileged
In-Reply-To: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
References: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
Message-ID: <524C4E9B.5080602@gmail.com>

Hi Martin,

If you want to optimize for without-security-manager case, then it would 
be better this way:

     private static void privilegedInterrupt(Thread t) {
         if (System.getSecurityManager() == null) {
             t.interrupt();
  	} else {
             PrivilegedAction<Void> doInterrupt =
                 () -> { t.interrupt(); return null; };
            AccessController.doPrivileged(doInterrupt);
         }
     }


...and no security exception catching. This way you don't trigger double 
security checks for case with-security-manager and not enough permission...

Regards, Peter

On 10/02/2013 06:29 PM, Martin Buchholz wrote:
> FutureTask.cancel(true) invokes thread.interrupt on the thread (if any)
> currently running the task.
> This should succeed even if modifyThread permission is denied by the
> security manager.
>
> Here's a proposed fix for jdk8+:
>
> --- src/main/java/util/concurrent/FutureTask.java 15 May 2013 02:39:59 -0000
> 1.103
> +++ src/main/java/util/concurrent/FutureTask.java 2 Oct 2013 16:25:23 -0000
> @@ -132,6 +132,12 @@
>           return state != NEW;
>       }
>
> +    private static void privilegedInterrupt(Thread t) {
> +        java.security.PrivilegedAction<Void> doInterrupt =
> +            () -> { t.interrupt(); return null; };
> +        java.security.AccessController.doPrivileged(doInterrupt);
> +    }
> +
>       public boolean cancel(boolean mayInterruptIfRunning) {
>           if (!(state == NEW &&
>                 UNSAFE.compareAndSwapInt(this, stateOffset, NEW,
> @@ -142,7 +148,11 @@
>                   try {
>                       Thread t = runner;
>                       if (t != null)
> -                        t.interrupt();
> +                        try {
> +                            t.interrupt();
> +                        } catch (SecurityException e) {
> +                            privilegedInterrupt(t);
> +                        }
>                   } finally { // final state
>                       UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);
>                   }


From yankee.sierra at gmail.com  Wed Oct  2 12:51:13 2013
From: yankee.sierra at gmail.com (Yuval Shavit)
Date: Wed, 2 Oct 2013 12:51:13 -0400
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CACuKZqH-ueUhWYRKshyqbX=ZyK6+Dn=bNs_HY4xpknA_VymrKA@mail.gmail.com>
References: <524B053B.3000605@oracle.com>
	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>
	<152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>
	<CACuKZqH-ueUhWYRKshyqbX=ZyK6+Dn=bNs_HY4xpknA_VymrKA@mail.gmail.com>
Message-ID: <CAE+h5-DoSYZSaFDHeFPKhenEQ9ty-D+H7cLwhRHyzLQKednafw@mail.gmail.com>

Correct me if I'm wrong, but I'm pretty sure that nice syntax doesn't work
with RW-locks, or Lock.tryLock, or semaphores, or...

But if these methods (or variants of them) returned a LockContext
implements AutoCloseable, then they could. Then developers wouldn't have to
choose between nice syntax and lock mechanism; they could have both.

try {Lock readLock = rwLock.readLock().lockWithContext()} {

} // auto release lock

Incidentally, why do we have to create that local variable, anyway? Why
couldn't we just do "try { rwLock.readLock() } " ? The only answer I found
via google was a post on StackOverflow which guessed that (1) it's not
useful for most resources and (2) the JDK designers didn't care about the
syntax for Locks, which are one kind of resource where it would be useful.
See http://stackoverflow.com/questions/16588843.


On Wed, Oct 2, 2013 at 12:26 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> Java does have this nice control structure since 1995 :)
>
>     synchronized(lock)
>     {
>
>     } // auto release lock
>
> The question now is whether it's easy to define custom control
> structure in Java. Not every easy I would say. The problem with lambda
> body is that it doesn't work like a local code block (well - it's not
> a problem for people who dislike imperative programming and checked
> exception anyway:)
>
> Zhong Yu
>
>
> On Wed, Oct 2, 2013 at 3:50 AM, Allen, Greg J <GJAllen at wellington.com>
> wrote:
> > Wow, has Java finally caught up with Modula 3?
> >
> > http://www.cs.purdue.edu/homes/hosking/m3/reference/lock.html
> >
> > A LOCK statement has the form:
> >     LOCK mu DO S END
> >
> > where S is a statement and mu is an expression. It is equivalent to:
> WITH m = mu DO
> >       Thread.Acquire(m);
> >       TRY S FINALLY Thread.Release(m) END
> >     END
> >
> > where m stands for a variable that does not occur in S.
> >
> > :)
> >
> > Greg
> >
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Zhong Yu
> > Sent: Tuesday 01 October 2013 18:58
> > To: Nathan Reynolds
> > Cc: concurrency-interest
> > Subject: Re: [concurrency-interest] Default Functions for Lock Interface
> >
> > To make your decision process a little more difficult, also weigh in
> > the design choice of using try-with-resources statement
> >
> > public boolean reserve()
> > {
> >    try(Foo foo = m_lock.foo()) // TBA names
> >    {
> >       if (m_count >= m_capacity)
> >          return(false);
> >
> >       m_count++;
> >
> >       return(true);
> >    }
> >    // auto close `foo` which releases the lock
> > }
> >
> > This is more verbose; the benefit is that the critical section is a
> > local code block.
> >
> > Zhong Yu
> >
> >
> >
> >
> > On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
> > <nathan.reynolds at oracle.com> wrote:
> >> Here's an example of code using ReentrantLock.
> >>
> >> private final ReentrantLock m_lock = new ReentrantLock();
> >> private       int           m_count;
> >> private final int           m_capacity;
> >>
> >> public boolean reserve()
> >> {
> >>    m_lock.lock();
> >>
> >>    try
> >>    {
> >>       if (m_count >= m_capacity)
> >>          return(false);
> >>
> >>       m_count++;
> >>
> >>       return(true);
> >>    }
> >>    finally
> >>    {
> >>       m_lock.unlock();
> >>    }
> >> }
> >>
> >> There are several problems with this code.  1)  You have to remember to
> call
> >> unlock().  2)  You have to put the unlock() in the finally block.  3)
>  The
> >> finally block can't have other exception throwing constructs or the lock
> >> won't be released on some code paths.  4)  The m_lock reference
> shouldn't be
> >> allowed to change while a thread is executing inside reserve().
> >>
> >> After attending JavaOne and hearing about lambdas and default methods in
> >> interfaces, I came up with an idea to make writing locked code less
> error
> >> prone.  The idea is to provide default methods in the Lock interface
> which
> >> would make writing the above code simpler and less error prone.  Here's
> one
> >> such method.
> >>
> >> public void guard(Runnable guarded)
> >> {
> >>    lock();
> >>
> >>    try
> >>    {
> >>       guarded.run();
> >>    }
> >>    finally
> >>    {
> >>       unlock();
> >>    }
> >> }
> >>
> >> With the guard() method available, the reserve() method can be
> rewritten in
> >> JDK 8 as such.
> >>
> >> public boolean reserve()
> >> {
> >>    return(m_lock.guard(() ->
> >>    {
> >>       if (m_count >= m_capacity)
> >>          return(false);
> >>
> >>       m_count++;
> >>
> >>       return(true);
> >>    }));
> >> }
> >>
> >> All the aforementioned problems are no longer applicable.  guard() takes
> >> care of them.  The code is much clearer to understand since the
> boilerplate
> >> locking code is gone.  It also might help JIT by reducing the amount of
> >> cookie cutter code it has to optimize.
> >>
> >> Here are the method signatures of other methods which could be added to
> the
> >> Lock interface.  The full code is available at
> >> https://bugs.openjdk.java.net/browse/JDK-8025597.
> >>
> >>    public <T> T           guard(Callable<T> guarded) throws Exception
> >>    public     void        guardInterruptibly(Runnable guarded) throws
> >> InterruptedException
> >>    public <T> T           guardInterruptibly(Callable<T> guarded) throws
> >> Exception, InterruptedException
> >>    public     boolean     tryGuard(Runnable guarded)
> >>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
> >>    public     boolean     tryGuard(Runnable guarded, long time, TimeUnit
> >> unit) throws InterruptedException
> >>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> TimeUnit
> >> unit) throws Exception, InterruptedException
> >>
> >> What do you think?  Please ignore formatting and method names for the
> >> moment.
> >>
> >> --
> >> -Nathan
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> > --------------------------------------------
> >
> > This is an email from Wellington Management International Limited, a
> limited company incorporated in England and Wales (company number 4283513).
> The contents of this email are confidential to the ordinary user of the
> email address to which it was addressed. No one else may copy or forward
> all or any of it in any form. If you receive this email in error, we should
> be obliged if you would telephone us on +44 20 7126 6000. This
> communication is directed only at persons (Relevant Persons) who are
> classified as eligible counterparties or professional clients under the
> rules of the Financial Conduct Authority. This communication must not be
> acted on or relied on by persons who are not Relevant Persons. Any
> investment or investment service to which this communication relates is
> available only to Relevant Persons and will be engaged in only with
> Relevant Persons. Wellington Management International Limited (FRN208573)
> is authorised and regulated in the United Kingdom by the Financ!
>  ial Conduct Authority and registered in the Financial Services Register
> (at http://www.fsa.gov.uk/register/) under the above number. The firm has
> its registered office at Cardinal Place, 80 Victoria Street, London SW1E
> 5JL.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/264dd8c0/attachment-0001.html>

From martinrb at google.com  Wed Oct  2 12:54:30 2013
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 2 Oct 2013 09:54:30 -0700
Subject: [concurrency-interest] FutureTask.cancel(true) should run
	thread.interrupt within doPrivileged
In-Reply-To: <524C4E9B.5080602@gmail.com>
References: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
	<524C4E9B.5080602@gmail.com>
Message-ID: <CA+kOe09DWt+BP47m-SfFjqPdpqR1NE4SrqtAdhvZXc1HnTTr-w@mail.gmail.com>

On Wed, Oct 2, 2013 at 9:49 AM, Peter Levart <peter.levart at gmail.com> wrote:

> Hi Martin,
>
> If you want to optimize for without-security-manager case


I want to optimize for the case that Thread.interrupt does not throw
SecurityException
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/e321912a/attachment.html>

From dl at cs.oswego.edu  Wed Oct  2 13:02:45 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 02 Oct 2013 13:02:45 -0400
Subject: [concurrency-interest] FutureTask.cancel(true) should run
 thread.interrupt within doPrivileged
In-Reply-To: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
References: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
Message-ID: <524C51B5.3040905@cs.oswego.edu>

On 10/02/2013 12:29 PM, Martin Buchholz wrote:
> FutureTask.cancel(true) invokes thread.interrupt on the thread (if any)
> currently running the task.
> This should succeed even if modifyThread permission is denied by the security
> manager.
>

We haven't interpreted "should" in this way in the past here or in
related contexts, but I don't see are reason not to,  pending any
objections by security folks.

-Doug


> Here's a proposed fix for jdk8+:
>
> --- src/main/java/util/concurrent/FutureTask.java15 May 2013 02:39:59 -00001.103
> +++ src/main/java/util/concurrent/FutureTask.java2 Oct 2013 16:25:23 -0000
> @@ -132,6 +132,12 @@
>           return state != NEW;
>       }
> +    private static void privilegedInterrupt(Thread t) {
> +        java.security.PrivilegedAction<Void> doInterrupt =
> +            () -> { t.interrupt(); return null; };
> +        java.security.AccessController.doPrivileged(doInterrupt);
> +    }
> +
>       public boolean cancel(boolean mayInterruptIfRunning) {
>           if (!(state == NEW &&
>                 UNSAFE.compareAndSwapInt(this, stateOffset, NEW,
> @@ -142,7 +148,11 @@
>                   try {
>                       Thread t = runner;
>                       if (t != null)
> -                        t.interrupt();
> +                        try {
> +                            t.interrupt();
> +                        } catch (SecurityException e) {
> +                            privilegedInterrupt(t);
> +                        }
>                   } finally { // final state
>                       UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);
>                   }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From nathan.reynolds at oracle.com  Wed Oct  2 13:41:28 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 02 Oct 2013 10:41:28 -0700
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CAE+h5-DoSYZSaFDHeFPKhenEQ9ty-D+H7cLwhRHyzLQKednafw@mail.gmail.com>
References: <524B053B.3000605@oracle.com>	<CACuKZqHw9LU43UJ+sMecAEHoY1cSMom3tKaj485LsF35osVgpQ@mail.gmail.com>	<152F7A0CFF3680418DF7B5D5F41FD198206C39FB@MDCPRDWINMBX14.wellmanage.com>	<CACuKZqH-ueUhWYRKshyqbX=ZyK6+Dn=bNs_HY4xpknA_VymrKA@mail.gmail.com>
	<CAE+h5-DoSYZSaFDHeFPKhenEQ9ty-D+H7cLwhRHyzLQKednafw@mail.gmail.com>
Message-ID: <524C5AC8.6060905@oracle.com>

*ReentrantReadWriteLock*
http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/locks/ReentrantReadWriteLock.html

You have to call readLock() or writeLock() to get a Lock instance upon 
which you call lock() and unlock().  The try-with-resources and the Lock 
interface default methods work.

*Lock.tryLock()*

This does not work with the try-with-resources approach.  However, it 
does work with the Lock interface default methods I gave at the bottom 
of the email chain.  To extend the original example.  The only 
difference is that I changed the call to guard() to a call to 
tryGuard().  This means if there is contention on the lock then the 
resource isn't reserved even if there are resources available.

public boolean reserve()
{
    return(m_lock.*try*Guard(() ->
    {
       if (m_count >= m_capacity)
          return(false);

       m_count++;

       return(true);
    }));
}

*Semphores, etc...*

If it doesn't implement the Lock interface then the Lock interface 
default methods can't be used.  The Semphore would have to provide its 
own functional method to ensure proper usage and protect the count.

-Nathan

On 10/2/2013 9:51 AM, Yuval Shavit wrote:
> Correct me if I'm wrong, but I'm pretty sure that nice syntax doesn't 
> work with RW-locks, or Lock.tryLock, or semaphores, or...
>
> But if these methods (or variants of them) returned a LockContext 
> implements AutoCloseable, then they could. Then developers wouldn't 
> have to choose between nice syntax and lock mechanism; they could have 
> both.
>
> try {Lock readLock = rwLock.readLock().lockWithContext()} {
> } // auto release lock
>
> Incidentally, why do we have to create that local variable, anyway? 
> Why couldn't we just do "try { rwLock.readLock() } " ? The only answer 
> I found via google was a post on StackOverflow which guessed that (1) 
> it's not useful for most resources and (2) the JDK designers didn't 
> care about the syntax for Locks, which are one kind of resource where 
> it would be useful. See http://stackoverflow.com/questions/16588843.
>
>
> On Wed, Oct 2, 2013 at 12:26 PM, Zhong Yu <zhong.j.yu at gmail.com 
> <mailto:zhong.j.yu at gmail.com>> wrote:
>
>     Java does have this nice control structure since 1995 :)
>
>         synchronized(lock)
>         {
>
>         } // auto release lock
>
>     The question now is whether it's easy to define custom control
>     structure in Java. Not every easy I would say. The problem with lambda
>     body is that it doesn't work like a local code block (well - it's not
>     a problem for people who dislike imperative programming and checked
>     exception anyway:)
>
>     Zhong Yu
>
>
>     On Wed, Oct 2, 2013 at 3:50 AM, Allen, Greg J
>     <GJAllen at wellington.com <mailto:GJAllen at wellington.com>> wrote:
>     > Wow, has Java finally caught up with Modula 3?
>     >
>     > http://www.cs.purdue.edu/homes/hosking/m3/reference/lock.html
>     >
>     > A LOCK statement has the form:
>     >     LOCK mu DO S END
>     >
>     > where S is a statement and mu is an expression. It is equivalent
>     to:     WITH m = mu DO
>     >       Thread.Acquire(m);
>     >       TRY S FINALLY Thread.Release(m) END
>     >     END
>     >
>     > where m stands for a variable that does not occur in S.
>     >
>     > :)
>     >
>     > Greg
>     >
>     > -----Original Message-----
>     > From: concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     [mailto:concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of
>     Zhong Yu
>     > Sent: Tuesday 01 October 2013 18:58
>     > To: Nathan Reynolds
>     > Cc: concurrency-interest
>     > Subject: Re: [concurrency-interest] Default Functions for Lock
>     Interface
>     >
>     > To make your decision process a little more difficult, also weigh in
>     > the design choice of using try-with-resources statement
>     >
>     > public boolean reserve()
>     > {
>     >    try(Foo foo = m_lock.foo()) // TBA names
>     >    {
>     >       if (m_count >= m_capacity)
>     >          return(false);
>     >
>     >       m_count++;
>     >
>     >       return(true);
>     >    }
>     >    // auto close `foo` which releases the lock
>     > }
>     >
>     > This is more verbose; the benefit is that the critical section is a
>     > local code block.
>     >
>     > Zhong Yu
>     >
>     >
>     >
>     >
>     > On Tue, Oct 1, 2013 at 12:24 PM, Nathan Reynolds
>     > <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>>
>     wrote:
>     >> Here's an example of code using ReentrantLock.
>     >>
>     >> private final ReentrantLock m_lock = new ReentrantLock();
>     >> private       int           m_count;
>     >> private final int           m_capacity;
>     >>
>     >> public boolean reserve()
>     >> {
>     >>    m_lock.lock();
>     >>
>     >>    try
>     >>    {
>     >>       if (m_count >= m_capacity)
>     >>          return(false);
>     >>
>     >>       m_count++;
>     >>
>     >>       return(true);
>     >>    }
>     >>    finally
>     >>    {
>     >>       m_lock.unlock();
>     >>    }
>     >> }
>     >>
>     >> There are several problems with this code.  1)  You have to
>     remember to call
>     >> unlock().  2)  You have to put the unlock() in the finally
>     block.  3)  The
>     >> finally block can't have other exception throwing constructs or
>     the lock
>     >> won't be released on some code paths.  4)  The m_lock reference
>     shouldn't be
>     >> allowed to change while a thread is executing inside reserve().
>     >>
>     >> After attending JavaOne and hearing about lambdas and default
>     methods in
>     >> interfaces, I came up with an idea to make writing locked code
>     less error
>     >> prone.  The idea is to provide default methods in the Lock
>     interface which
>     >> would make writing the above code simpler and less error prone.
>      Here's one
>     >> such method.
>     >>
>     >> public void guard(Runnable guarded)
>     >> {
>     >>    lock();
>     >>
>     >>    try
>     >>    {
>     >>       guarded.run();
>     >>    }
>     >>    finally
>     >>    {
>     >>       unlock();
>     >>    }
>     >> }
>     >>
>     >> With the guard() method available, the reserve() method can be
>     rewritten in
>     >> JDK 8 as such.
>     >>
>     >> public boolean reserve()
>     >> {
>     >>    return(m_lock.guard(() ->
>     >>    {
>     >>       if (m_count >= m_capacity)
>     >>          return(false);
>     >>
>     >>       m_count++;
>     >>
>     >>       return(true);
>     >>    }));
>     >> }
>     >>
>     >> All the aforementioned problems are no longer applicable.
>      guard() takes
>     >> care of them.  The code is much clearer to understand since the
>     boilerplate
>     >> locking code is gone.  It also might help JIT by reducing the
>     amount of
>     >> cookie cutter code it has to optimize.
>     >>
>     >> Here are the method signatures of other methods which could be
>     added to the
>     >> Lock interface.  The full code is available at
>     >> https://bugs.openjdk.java.net/browse/JDK-8025597.
>     >>
>     >>    public <T> T guard(Callable<T> guarded) throws Exception
>     >>    public     void  guardInterruptibly(Runnable guarded) throws
>     >> InterruptedException
>     >>    public <T> T guardInterruptibly(Callable<T> guarded) throws
>     >> Exception, InterruptedException
>     >>    public     boolean     tryGuard(Runnable guarded)
>     >>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws
>     Exception
>     >>    public     boolean     tryGuard(Runnable guarded, long time,
>     TimeUnit
>     >> unit) throws InterruptedException
>     >>    public <T> Optional<T> tryGuard(Callable<T> guarded, long
>     time, TimeUnit
>     >> unit) throws Exception, InterruptedException
>     >>
>     >> What do you think?  Please ignore formatting and method names
>     for the
>     >> moment.
>     >>
>     >> --
>     >> -Nathan
>     >>
>     >>
>     >> _______________________________________________
>     >> Concurrency-interest mailing list
>     >> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >>
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>     >
>     > --------------------------------------------
>     >
>     > This is an email from Wellington Management International
>     Limited, a limited company incorporated in England and Wales
>     (company number 4283513). The contents of this email are
>     confidential to the ordinary user of the email address to which it
>     was addressed. No one else may copy or forward all or any of it in
>     any form. If you receive this email in error, we should be obliged
>     if you would telephone us on +44 20 7126 6000
>     <tel:%2B44%2020%207126%206000>. This communication is directed
>     only at persons (Relevant Persons) who are classified as eligible
>     counterparties or professional clients under the rules of the
>     Financial Conduct Authority. This communication must not be acted
>     on or relied on by persons who are not Relevant Persons. Any
>     investment or investment service to which this communication
>     relates is available only to Relevant Persons and will be engaged
>     in only with Relevant Persons. Wellington Management International
>     Limited (FRN208573) is authorised and regulated in the United
>     Kingdom by the Financ!
>      ial Conduct Authority and registered in the Financial Services
>     Register (at http://www.fsa.gov.uk/register/) under the above
>     number. The firm has its registered office at Cardinal Place, 80
>     Victoria Street, London SW1E 5JL.
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/d1cd9722/attachment-0001.html>

From viktor.klang at gmail.com  Wed Oct  2 16:40:56 2013
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 2 Oct 2013 22:40:56 +0200
Subject: [concurrency-interest] FutureTask.cancel(true) should run
 thread.interrupt within doPrivileged
In-Reply-To: <524C51B5.3040905@cs.oswego.edu>
References: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
	<524C51B5.3040905@cs.oswego.edu>
Message-ID: <CANPzfU-1z24kTLiCfcRLvumr253n7kHdZgKzXr7sZxczzivs6w@mail.gmail.com>

My ignorance made me surprised that this wasn't the default of the
Thread.interrupt method.

Cheers,
?


On Wed, Oct 2, 2013 at 7:02 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 10/02/2013 12:29 PM, Martin Buchholz wrote:
>
>> FutureTask.cancel(true) invokes thread.interrupt on the thread (if any)
>> currently running the task.
>> This should succeed even if modifyThread permission is denied by the
>> security
>> manager.
>>
>>
> We haven't interpreted "should" in this way in the past here or in
> related contexts, but I don't see are reason not to,  pending any
> objections by security folks.
>
> -Doug
>
>
>  Here's a proposed fix for jdk8+:
>>
>> --- src/main/java/util/concurrent/**FutureTask.java15 May 2013 02:39:59
>> -00001.103
>> +++ src/main/java/util/concurrent/**FutureTask.java2 Oct 2013 16:25:23
>> -0000
>>
>> @@ -132,6 +132,12 @@
>>           return state != NEW;
>>       }
>> +    private static void privilegedInterrupt(Thread t) {
>> +        java.security.**PrivilegedAction<Void> doInterrupt =
>> +            () -> { t.interrupt(); return null; };
>> +        java.security.**AccessController.doPrivileged(**doInterrupt);
>> +    }
>> +
>>       public boolean cancel(boolean mayInterruptIfRunning) {
>>           if (!(state == NEW &&
>>                 UNSAFE.compareAndSwapInt(this, stateOffset, NEW,
>> @@ -142,7 +148,11 @@
>>                   try {
>>                       Thread t = runner;
>>                       if (t != null)
>> -                        t.interrupt();
>> +                        try {
>> +                            t.interrupt();
>> +                        } catch (SecurityException e) {
>> +                            privilegedInterrupt(t);
>> +                        }
>>                   } finally { // final state
>>                       UNSAFE.putOrderedInt(this, stateOffset,
>> INTERRUPTED);
>>                   }
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/a70686d1/attachment.html>

From martinrb at google.com  Wed Oct  2 23:55:00 2013
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 2 Oct 2013 20:55:00 -0700
Subject: [concurrency-interest] FutureTask.cancel(true) should run
	thread.interrupt within doPrivileged
In-Reply-To: <524CD2CA.2070901@oracle.com>
References: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
	<524C4E9B.5080602@gmail.com>
	<CA+kOe09DWt+BP47m-SfFjqPdpqR1NE4SrqtAdhvZXc1HnTTr-w@mail.gmail.com>
	<524CD2CA.2070901@oracle.com>
Message-ID: <CA+kOe09__FgCDxxTWZHvfKxiqGj_FV-2Lbchti8iAeW9Ce--EA@mail.gmail.com>

On Wed, Oct 2, 2013 at 7:13 PM, David Holmes <david.holmes at oracle.com>wrote:

> On 3/10/2013 2:54 AM, Martin Buchholz wrote:
>
>> On Wed, Oct 2, 2013 at 9:49 AM, Peter Levart <peter.levart at gmail.com>
>> wrote:
>>
>>  Hi Martin,
>>>
>>> If you want to optimize for without-security-manager case
>>>
>>
>>
>> I want to optimize for the case that Thread.interrupt does not throw
>> SecurityException
>>
>
> How is your proposal optimizing that case ???


Instead of doing extra work to avoid a SecurityException, I am assuming a
SecurityException is rare, and risk having to throw it twice.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/d81ea547/attachment.html>

From martinrb at google.com  Thu Oct  3 00:11:01 2013
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 2 Oct 2013 21:11:01 -0700
Subject: [concurrency-interest] FutureTask.cancel(true) should run
	thread.interrupt within doPrivileged
In-Reply-To: <524CEC93.20106@oracle.com>
References: <CA+kOe09Ra-iA=RrPGrj5GU0eHwRym0jRfxpnjyr0Wv-3fx0ofg@mail.gmail.com>
	<524C4E9B.5080602@gmail.com>
	<CA+kOe09DWt+BP47m-SfFjqPdpqR1NE4SrqtAdhvZXc1HnTTr-w@mail.gmail.com>
	<524CD2CA.2070901@oracle.com>
	<CA+kOe09__FgCDxxTWZHvfKxiqGj_FV-2Lbchti8iAeW9Ce--EA@mail.gmail.com>
	<524CEC93.20106@oracle.com>
Message-ID: <CA+kOe09m5Nn_fO7DZKS=8awnLcO6G=e2Es0VbkwZQzWK76cqZg@mail.gmail.com>

I was responding to Peter Levart's suggestion of checking for the presence
of a security manager before calling doPrivileged.  Which is not an
important question now, given that the primary question is whether we
should allow future.cancel() to interrupt within a doPrivileged.

Alternatively, is there a reasonable way for a security manager to enable
such usages without enabling arbitrary modifyThread?


On Wed, Oct 2, 2013 at 9:03 PM, David Holmes <david.holmes at oracle.com>wrote:

> On 3/10/2013 1:55 PM, Martin Buchholz wrote:
>
>> On Wed, Oct 2, 2013 at 7:13 PM, David Holmes <david.holmes at oracle.com>**
>> wrote:
>>
>>  On 3/10/2013 2:54 AM, Martin Buchholz wrote:
>>>
>>>  On Wed, Oct 2, 2013 at 9:49 AM, Peter Levart <peter.levart at gmail.com>
>>>> wrote:
>>>>
>>>>   Hi Martin,
>>>>
>>>>>
>>>>> If you want to optimize for without-security-manager case
>>>>>
>>>>>
>>>>
>>>> I want to optimize for the case that Thread.interrupt does not throw
>>>> SecurityException
>>>>
>>>>
>>> How is your proposal optimizing that case ???
>>>
>>
>>
>> Instead of doing extra work to avoid a SecurityException, I am assuming a
>> SecurityException is rare, and risk having to throw it twice.
>>
>
> Sorry I'm missing something - what extra work are you avoiding and where?
> The original code just did t.interrupt() now you've added try/catch with a
> second privileged interrupt attempt. I don't see anything being avoided.
> Are you referring to caller code that catches the SecurityException itself
> and somehow retries?
>
> David
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131002/d3454c2b/attachment.html>

From ron.pressler at gmail.com  Thu Oct  3 07:53:29 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 3 Oct 2013 14:53:29 +0300
Subject: [concurrency-interest] Bulk external submit to a ForkJoinPool in
	async mode
Message-ID: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>

Hi.
I'm using a ForkJoinPool in async mode as a task scheduler. FJ is a great
choice because most tasks are forked by other tasks. I also never join
tasks (at least not within other tasks), so the async mode works well.

Sometimes, though, I need to submit (externally) a bunch of tasks; say, a
few thousand. It is best to parallelize the submission process, and this
is, indeed, much of the point of FJ, but this will not work well in async
mode, because other threads will steal "small" tasks (i.e. ones that will
end up forking few, rather than many sub-tasks).

Looking at the FJP code, I found no way of selectively inserting a task at
the bottom of the queue (the difference between async and regular mode is
where tasks are removed, not where they're inserted).

Any ideas?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131003/c4fbb072/attachment.html>

From viktor.klang at gmail.com  Thu Oct  3 08:44:46 2013
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 3 Oct 2013 14:44:46 +0200
Subject: [concurrency-interest] Bulk external submit to a ForkJoinPool
 in async mode
In-Reply-To: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>
References: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>
Message-ID: <CANPzfU8sW_sZFUejMPx=6WbU3-jNJBqj1d665cwv1c4rtPqnjw@mail.gmail.com>

ForkJoinTask.fork():

    public final ForkJoinTask<V> fork() {
        Thread t;
        if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
            ((ForkJoinWorkerThread)t).workQueue.push(this);
        else
            ForkJoinPool.common.externalPush(this);
        return this;
    }



On Thu, Oct 3, 2013 at 1:53 PM, Ron Pressler <ron.pressler at gmail.com> wrote:

> Hi.
> I'm using a ForkJoinPool in async mode as a task scheduler. FJ is a great
> choice because most tasks are forked by other tasks. I also never join
> tasks (at least not within other tasks), so the async mode works well.
>
> Sometimes, though, I need to submit (externally) a bunch of tasks; say, a
> few thousand. It is best to parallelize the submission process, and this
> is, indeed, much of the point of FJ, but this will not work well in async
> mode, because other threads will steal "small" tasks (i.e. ones that will
> end up forking few, rather than many sub-tasks).
>
> Looking at the FJP code, I found no way of selectively inserting a task at
> the bottom of the queue (the difference between async and regular mode is
> where tasks are removed, not where they're inserted).
>
> Any ideas?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131003/608e5f11/attachment-0001.html>

From ron.pressler at gmail.com  Thu Oct  3 10:58:16 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 3 Oct 2013 17:58:16 +0300
Subject: [concurrency-interest] Bulk external submit to a ForkJoinPool
 in async mode
In-Reply-To: <CANPzfU8sW_sZFUejMPx=6WbU3-jNJBqj1d665cwv1c4rtPqnjw@mail.gmail.com>
References: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>
	<CANPzfU8sW_sZFUejMPx=6WbU3-jNJBqj1d665cwv1c4rtPqnjw@mail.gmail.com>
Message-ID: <CABg6-qh+pYNHVbN88Jc=tGP-XH0qsLZLUJ5F75BCEN2ryGFvxA@mail.gmail.com>

I don't have a problem with fork(), but with submit() (which calls
externalPush()). Actually, I don't even have a problem with that. Again,
ideally I would like to submit one large task, which will fork again and
again, thus parallelizing the submission process. But this doesn't work
well in async mode because you won't get the nice FJ "computation tree"
where larger tasks (which will end up forking lots of sub tasks) are the
ones stolen. One way of doing that would be to have an option to push an
individual task at the other end of the submission queue, but that might be
too big a change for FJPool.


On Thu, Oct 3, 2013 at 3:44 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:

> ForkJoinTask.fork():
>
>     public final ForkJoinTask<V> fork() {
>         Thread t;
>         if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
>             ((ForkJoinWorkerThread)t).workQueue.push(this);
>         else
>             ForkJoinPool.common.externalPush(this);
>         return this;
>     }
>
>
>
> On Thu, Oct 3, 2013 at 1:53 PM, Ron Pressler <ron.pressler at gmail.com>wrote:
>
>> Hi.
>> I'm using a ForkJoinPool in async mode as a task scheduler. FJ is a great
>> choice because most tasks are forked by other tasks. I also never join
>> tasks (at least not within other tasks), so the async mode works well.
>>
>> Sometimes, though, I need to submit (externally) a bunch of tasks; say, a
>> few thousand. It is best to parallelize the submission process, and this
>> is, indeed, much of the point of FJ, but this will not work well in async
>> mode, because other threads will steal "small" tasks (i.e. ones that will
>> end up forking few, rather than many sub-tasks).
>>
>> Looking at the FJP code, I found no way of selectively inserting a task
>> at the bottom of the queue (the difference between async and regular mode
>> is where tasks are removed, not where they're inserted).
>>
>> Any ideas?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> *Viktor Klang*
> *Director of Engineering*
> Typesafe <http://www.typesafe.com/>
>
> Twitter: @viktorklang
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131003/17b2f72e/attachment.html>

From viktor.klang at gmail.com  Thu Oct  3 14:21:46 2013
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 3 Oct 2013 20:21:46 +0200
Subject: [concurrency-interest] Bulk external submit to a ForkJoinPool
 in async mode
In-Reply-To: <CABg6-qh+pYNHVbN88Jc=tGP-XH0qsLZLUJ5F75BCEN2ryGFvxA@mail.gmail.com>
References: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>
	<CANPzfU8sW_sZFUejMPx=6WbU3-jNJBqj1d665cwv1c4rtPqnjw@mail.gmail.com>
	<CABg6-qh+pYNHVbN88Jc=tGP-XH0qsLZLUJ5F75BCEN2ryGFvxA@mail.gmail.com>
Message-ID: <CANPzfU9gp8vSsdq8u5-H4DSDadRRy0ZhOCLz6RwPEaZ31QvxOA@mail.gmail.com>

Do the splitting (fork()) on the commonPool and then have it submit() to
your pool?

Cheers,
?
I don't have a problem with fork(), but with submit() (which calls
externalPush()). Actually, I don't even have a problem with that. Again,
ideally I would like to submit one large task, which will fork again and
again, thus parallelizing the submission process. But this doesn't work
well in async mode because you won't get the nice FJ "computation tree"
where larger tasks (which will end up forking lots of sub tasks) are the
ones stolen. One way of doing that would be to have an option to push an
individual task at the other end of the submission queue, but that might be
too big a change for FJPool.


On Thu, Oct 3, 2013 at 3:44 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:

> ForkJoinTask.fork():
>
>     public final ForkJoinTask<V> fork() {
>         Thread t;
>         if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
>             ((ForkJoinWorkerThread)t).workQueue.push(this);
>         else
>             ForkJoinPool.common.externalPush(this);
>         return this;
>     }
>
>
>
> On Thu, Oct 3, 2013 at 1:53 PM, Ron Pressler <ron.pressler at gmail.com>wrote:
>
>> Hi.
>> I'm using a ForkJoinPool in async mode as a task scheduler. FJ is a great
>> choice because most tasks are forked by other tasks. I also never join
>> tasks (at least not within other tasks), so the async mode works well.
>>
>> Sometimes, though, I need to submit (externally) a bunch of tasks; say, a
>> few thousand. It is best to parallelize the submission process, and this
>> is, indeed, much of the point of FJ, but this will not work well in async
>> mode, because other threads will steal "small" tasks (i.e. ones that will
>> end up forking few, rather than many sub-tasks).
>>
>> Looking at the FJP code, I found no way of selectively inserting a task
>> at the bottom of the queue (the difference between async and regular mode
>> is where tasks are removed, not where they're inserted).
>>
>> Any ideas?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> *Viktor Klang*
> *Director of Engineering*
> Typesafe <http://www.typesafe.com/>
>
> Twitter: @viktorklang
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131003/ce2e222f/attachment.html>

From ron.pressler at gmail.com  Thu Oct  3 16:13:47 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 3 Oct 2013 23:13:47 +0300
Subject: [concurrency-interest] Bulk external submit to a ForkJoinPool
 in async mode
In-Reply-To: <CANPzfU9gp8vSsdq8u5-H4DSDadRRy0ZhOCLz6RwPEaZ31QvxOA@mail.gmail.com>
References: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>
	<CANPzfU8sW_sZFUejMPx=6WbU3-jNJBqj1d665cwv1c4rtPqnjw@mail.gmail.com>
	<CABg6-qh+pYNHVbN88Jc=tGP-XH0qsLZLUJ5F75BCEN2ryGFvxA@mail.gmail.com>
	<CANPzfU9gp8vSsdq8u5-H4DSDadRRy0ZhOCLz6RwPEaZ31QvxOA@mail.gmail.com>
Message-ID: <CABg6-qhQn8jCrfiHpv9uKhOJoBdW6BVMSkohuvA0OAW++QO+gg@mail.gmail.com>

That's an interesting idea. Might not be optimal because this does not
happen very frequently so the common pool's threads will all be parked and
will have to be unparked, but I'll give it a try.


On Thu, Oct 3, 2013 at 9:21 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:

> Do the splitting (fork()) on the commonPool and then have it submit() to
> your pool?
>
> Cheers,
> ?
> I don't have a problem with fork(), but with submit() (which calls
> externalPush()). Actually, I don't even have a problem with that. Again,
> ideally I would like to submit one large task, which will fork again and
> again, thus parallelizing the submission process. But this doesn't work
> well in async mode because you won't get the nice FJ "computation tree"
> where larger tasks (which will end up forking lots of sub tasks) are the
> ones stolen. One way of doing that would be to have an option to push an
> individual task at the other end of the submission queue, but that might be
> too big a change for FJPool.
>
>
> On Thu, Oct 3, 2013 at 3:44 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>> ForkJoinTask.fork():
>>
>>     public final ForkJoinTask<V> fork() {
>>         Thread t;
>>         if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
>>             ((ForkJoinWorkerThread)t).workQueue.push(this);
>>         else
>>             ForkJoinPool.common.externalPush(this);
>>         return this;
>>     }
>>
>>
>>
>> On Thu, Oct 3, 2013 at 1:53 PM, Ron Pressler <ron.pressler at gmail.com>wrote:
>>
>>> Hi.
>>> I'm using a ForkJoinPool in async mode as a task scheduler. FJ is a
>>> great choice because most tasks are forked by other tasks. I also never
>>> join tasks (at least not within other tasks), so the async mode works well.
>>>
>>> Sometimes, though, I need to submit (externally) a bunch of tasks; say,
>>> a few thousand. It is best to parallelize the submission process, and this
>>> is, indeed, much of the point of FJ, but this will not work well in async
>>> mode, because other threads will steal "small" tasks (i.e. ones that will
>>> end up forking few, rather than many sub-tasks).
>>>
>>> Looking at the FJP code, I found no way of selectively inserting a task
>>> at the bottom of the queue (the difference between async and regular mode
>>> is where tasks are removed, not where they're inserted).
>>>
>>> Any ideas?
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> --
>> *Viktor Klang*
>> *Director of Engineering*
>> Typesafe <http://www.typesafe.com/>
>>
>> Twitter: @viktorklang
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131003/4686965e/attachment.html>

From viktor.klang at gmail.com  Thu Oct  3 17:00:14 2013
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 3 Oct 2013 23:00:14 +0200
Subject: [concurrency-interest] Bulk external submit to a ForkJoinPool
 in async mode
In-Reply-To: <CABg6-qhQn8jCrfiHpv9uKhOJoBdW6BVMSkohuvA0OAW++QO+gg@mail.gmail.com>
References: <CABg6-qiB2aAJAifLs15L19b9mB9-DM2+D7DmtCjjohmtDZ8ESA@mail.gmail.com>
	<CANPzfU8sW_sZFUejMPx=6WbU3-jNJBqj1d665cwv1c4rtPqnjw@mail.gmail.com>
	<CABg6-qh+pYNHVbN88Jc=tGP-XH0qsLZLUJ5F75BCEN2ryGFvxA@mail.gmail.com>
	<CANPzfU9gp8vSsdq8u5-H4DSDadRRy0ZhOCLz6RwPEaZ31QvxOA@mail.gmail.com>
	<CABg6-qhQn8jCrfiHpv9uKhOJoBdW6BVMSkohuvA0OAW++QO+gg@mail.gmail.com>
Message-ID: <CANPzfU90xWureuv9iyMoNG_wYZekwcoW16t205=wxZY21XmyDA@mail.gmail.com>

Looking forward to hearing how it went!
On Oct 3, 2013 10:14 PM, "Ron Pressler" <ron.pressler at gmail.com> wrote:

> That's an interesting idea. Might not be optimal because this does not
> happen very frequently so the common pool's threads will all be parked and
> will have to be unparked, but I'll give it a try.
>
>
> On Thu, Oct 3, 2013 at 9:21 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>> Do the splitting (fork()) on the commonPool and then have it submit() to
>> your pool?
>>
>> Cheers,
>> ?
>> I don't have a problem with fork(), but with submit() (which calls
>> externalPush()). Actually, I don't even have a problem with that. Again,
>> ideally I would like to submit one large task, which will fork again and
>> again, thus parallelizing the submission process. But this doesn't work
>> well in async mode because you won't get the nice FJ "computation tree"
>> where larger tasks (which will end up forking lots of sub tasks) are the
>> ones stolen. One way of doing that would be to have an option to push an
>> individual task at the other end of the submission queue, but that might be
>> too big a change for FJPool.
>>
>>
>> On Thu, Oct 3, 2013 at 3:44 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>>
>>> ForkJoinTask.fork():
>>>
>>>     public final ForkJoinTask<V> fork() {
>>>         Thread t;
>>>         if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
>>>             ((ForkJoinWorkerThread)t).workQueue.push(this);
>>>         else
>>>             ForkJoinPool.common.externalPush(this);
>>>         return this;
>>>     }
>>>
>>>
>>>
>>> On Thu, Oct 3, 2013 at 1:53 PM, Ron Pressler <ron.pressler at gmail.com>wrote:
>>>
>>>> Hi.
>>>> I'm using a ForkJoinPool in async mode as a task scheduler. FJ is a
>>>> great choice because most tasks are forked by other tasks. I also never
>>>> join tasks (at least not within other tasks), so the async mode works well.
>>>>
>>>> Sometimes, though, I need to submit (externally) a bunch of tasks; say,
>>>> a few thousand. It is best to parallelize the submission process, and this
>>>> is, indeed, much of the point of FJ, but this will not work well in async
>>>> mode, because other threads will steal "small" tasks (i.e. ones that will
>>>> end up forking few, rather than many sub-tasks).
>>>>
>>>> Looking at the FJP code, I found no way of selectively inserting a task
>>>> at the bottom of the queue (the difference between async and regular mode
>>>> is where tasks are removed, not where they're inserted).
>>>>
>>>> Any ideas?
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>>
>>> --
>>> *Viktor Klang*
>>> *Director of Engineering*
>>> Typesafe <http://www.typesafe.com/>
>>>
>>> Twitter: @viktorklang
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131003/4740d73d/attachment-0001.html>

From aleksey.shipilev at oracle.com  Fri Oct  4 11:37:12 2013
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 04 Oct 2013 19:37:12 +0400
Subject: [concurrency-interest] Difficulty interpreting jcstress results
In-Reply-To: <5216151B.9000301@redhat.com>
References: <5215DD5B.1040208@redhat.com>
	<4A629F3D-5696-43B8-A005-A0BA884F64D7@oracle.com>
	<5216151B.9000301@redhat.com>
Message-ID: <524EE0A8.1030109@oracle.com>

On 08/22/2013 05:41 PM, Andrew Haley wrote:
> On 08/22/2013 01:02 PM, Aleksey Shipilev wrote:
> 
>> This seems to indicate the fatal error, not the test failure. Maybe
>> the VM crashed after a while? The forked VM can still have
>> communicated a few results before the crash.
> 
> I wouldn't be surprised.  It's still rather flakey.
> 
>> Let me see if I can get more reliable reporting in these cases.
>>
>> In the mean time, can you try to disable forking with "-f 0" and
>> re-run the test selectively with "-t .*FloatBuffer.*"?
> 
> Everything runs just fine.

Andrew, please try to pull the new revision, and try again. New version
should recover from the most types of error and provide more concise
debugging info.

Thanks,
-Aleksey.


From aph at redhat.com  Fri Oct  4 13:51:03 2013
From: aph at redhat.com (Andrew Haley)
Date: Fri, 04 Oct 2013 18:51:03 +0100
Subject: [concurrency-interest] Difficulty interpreting jcstress results
In-Reply-To: <524EE0A8.1030109@oracle.com>
References: <5215DD5B.1040208@redhat.com>
	<4A629F3D-5696-43B8-A005-A0BA884F64D7@oracle.com>
	<5216151B.9000301@redhat.com> <524EE0A8.1030109@oracle.com>
Message-ID: <524F0007.6020202@redhat.com>

On 10/04/2013 04:37 PM, Aleksey Shipilev wrote:
> Andrew, please try to pull the new revision, and try again. New version
> should recover from the most types of error and provide more concise
> debugging info.

Ok, thanks.

Andrew.


From billy at no-fixed-abode.com  Sun Oct  6 14:51:00 2013
From: billy at no-fixed-abode.com (Billy Wallace)
Date: Sun, 6 Oct 2013 19:51:00 +0100
Subject: [concurrency-interest] Best practices and idioms for
	java.util.concurrent collections?
Message-ID: <CAF7WZ=Qcf-SSryjQX+yNxgU5HNqWwG=A45D0PHYuScN2ebC0Sw@mail.gmail.com>

I'm having difficulty finding a good source of best practice or common
idioms for using java.util.concurrent collections. The paper
"CHECK-THEN-ACT Misuse of Java Concurrent Collections" by Yu Lin and Danny
Dig, lists several widely-used open source Java projects where
java.util.concurrent collection classes are frequently misused. This
implies to me that I'm not alone in lacking guidance. Given that concurrent
programming is fundamentally hard and these classes were designed to help
simplify certain tasks, where do I go to learn how to use these classes
effectively?

An example of what I'm talking about is the correct use of
ConcurrentHashMap.putIfAbsent(). Here's an example of this from
CorbaClientRequestDisplatcherImpl.java:

        // "locks" declared above here
        Object lock = locks.get(contactInfo);
        if (lock == null) {
            Object newLock = new Object();
            lock = locks.putIfAbsent(contactInfo, newLock);
            if (lock == null) {
                lock = newLock;
            }
        }
        // "locks" used below here

My understanding is that to use putIfAbsent properly, I should follow the
pattern above.

Although this is a good example, I'm having a hard time finding examples
for things like the other atomic operations in the ConcurrentMap interface.

Googling for "java util concurrent idioms" or "java util concurrent best
practices" doesn't find any obvious help. Oracle's Java concurrency
tutorial simply lists interface and class names. The "Java Concurrency in
Practice" book only has one paragraph on the "Additional atomic Map
operations" and the accompanying source doesn't have code examples to
illustrate any of these operations apart from putIfAbsent. Although there
are some examples in the source code of the Java libraries (like the one
above), most of the classes are only used in test code, and typically test
code won't illustrate best practice. The paper mentioned earlier tells me I
can't rely on code examples from open source projects, so where else should
I look?

Am I missing some obvious source of information?

Apologies for this horribly naive (and long-winded) "newbie" question, but
I didn't see an FAQ or any way to search the archives.

Thanks,

Billy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131006/424cc848/attachment.html>

From sjr at sjrx.net  Sun Oct  6 16:36:21 2013
From: sjr at sjrx.net (=?windows-1252?Q?Steve_Ramage?=)
Date: Sun, 6 Oct 2013 13:36:21 -0700
Subject: [concurrency-interest] Best practices and idioms for
 java.util.concurrent collections?
In-Reply-To: <CAF7WZ=Qcf-SSryjQX+yNxgU5HNqWwG=A45D0PHYuScN2ebC0Sw@mail.gmail.com>
References: <CAF7WZ=Qcf-SSryjQX+yNxgU5HNqWwG=A45D0PHYuScN2ebC0Sw@mail.gmail.com>
Message-ID: <zarafa.5251c9c5.2cc3.7ea22d881a4c9dd8@fermat.vc.shawcable.net>

Hi Billy,

?

As someone who is moderately familiar with concurrent Java programming, my guess is that the reason their isn't much guidance towards using the concurrent collections properly is because there would be little to be gained in being familiar with correct usage of this aspect of the API, on it's own.?The 'check than act' race condition, isn't something that occurs just with the concurrent collections, but potentially with any class that is intended to be used by multiple threads at the same time. I did a quick read of the paper you mention, and having read "Java Concurrency in Practice" (JCIP) twice over the years, I feel as if every single case they point out in Figure 1,2,4 and 5 are adequately covered by JCIP. Not specifically in the context of collections, but in the context of composing objects together that will be used by multiple threads.?I feel that if the coders on the projects they reference had read and internalized JCIP they would have not made those mistakes (except for the 'over synchronized' mistakes, which I think the authors of the paper are being too picky about). I guess my answer to your question would be that if you haven't read JCIP you should read it. It won't talk about Collections as much as you want, but that's because collections are slightly orthogonal to the problem of concurrency correctness. If you have read JCIP, what is it you feel is still missing?

?

Steve Ramage

?
-----Original message-----
To:concurrency-interest at cs.oswego.edu; 
From:Billy Wallace <billy at no-fixed-abode.com>
Sent:Sun 06-10-2013 12:02
Subject:[concurrency-interest] Best practices and idioms for java.util.concurrent collections?
Attachment:inline.txt
?
I'm having difficulty finding a good source of best practice or common idioms for using java.util.concurrent collections. The paper "CHECK-THEN-ACT Misuse of Java Concurrent Collections" by Yu Lin and Danny Dig, lists several widely-used open source Java projects where java.util.concurrent collection classes are frequently misused. This implies to me that I'm not alone in lacking guidance. Given that concurrent programming is fundamentally hard and these classes were designed to help simplify certain tasks, where do I go to learn how to use these classes effectively?
?
An example of what I'm talking about is the correct use of ConcurrentHashMap.putIfAbsent(). Here's an example of this from CorbaClientRequestDisplatcherImpl.java:
?
? ? ? ? // "locks" declared above here
? ? ? ? Object lock = locks.get(contactInfo);
? ? ? ? if (lock == null) {
? ? ? ? ? ? Object newLock = new Object();
? ? ? ? ? ? lock = locks.putIfAbsent(contactInfo, newLock);
? ? ? ? ? ? if (lock == null) {
? ? ? ? ? ? ? ? lock = newLock;
? ? ? ? ? ? }
? ? ? ? }

? ? ? ? // "locks" used below here
?
My understanding is that to use putIfAbsent properly, I should follow the pattern above.
?
Although this is a good example, I'm having a hard time finding examples for things like the other atomic operations in the ConcurrentMap interface.
?
Googling for "java util concurrent idioms" or "java util concurrent best practices" doesn't find any obvious help. Oracle's Java concurrency tutorial simply lists interface and class names. The "Java Concurrency in Practice" book only has one paragraph on the "Additional atomic Map operations" and the accompanying source doesn't have code examples to illustrate any of these operations apart from putIfAbsent. Although there are some examples in the source code of the Java libraries (like the one above), most of the classes are only used in test code, and typically test code won't illustrate best practice. The paper mentioned earlier tells me I can't rely on code examples from open source projects, so where else should I look?
?
Am I missing some obvious source of information?
?
Apologies for this horribly naive (and long-winded) "newbie" question, but I didn't see an FAQ or any way to search the archives.
?
Thanks,
?
Billy
?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131006/8d655b14/attachment.html>

From andrew_nuss at yahoo.com  Sun Oct  6 20:17:07 2013
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Sun, 6 Oct 2013 17:17:07 -0700 (PDT)
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
Message-ID: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>

Hi,

My idea is:

public class SimpleLock {
????? private volatile AtomicBoolean lock = new AtomicBoolean();

????? public void lock ()
????? {
???????????? while !lock.compareAndSet(false, true) {}

????? }

????? public void unlock ()
????? {
???????????? lock.set(false);
???????????? this.lock = lock;

????? }

}

Obviously this is a simple lockfree locker.? The question is whether this locker also ensures the unlock() publishes all non-volatile changes made to a complex data structure used within the critical section to the next call to lock()?? If not, how can I fix this?

Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131006/1e5d4d32/attachment-0001.html>

From hans.boehm at hp.com  Sun Oct  6 20:41:54 2013
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 7 Oct 2013 00:41:54 +0000
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23D4C698E@G9W0725.americas.hpqcorp.net>

Yes.  Performance issues aside, that works.  There is no reason for the this.lock = lock assignment, or for making lock volatile.  so long as lock is an AtomicBoolean, correct users of this code should be data-race-free (the only race is on lock, which is atomic), and hence sequentially consistent.  You're making this much too hard.

The publication issues only apply if you want to tolerate data races.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Andy Nuss
Sent: Sunday, October 06, 2013 5:17 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?

Hi,

My idea is:

public class SimpleLock {
      private volatile AtomicBoolean lock = new AtomicBoolean();

      public void lock ()
      {
             while !lock.compareAndSet(false, true) {}
      }

      public void unlock ()
      {
             lock.set(false);
             this.lock = lock;
      }
}

Obviously this is a simple lockfree locker.  The question is whether this locker also ensures the unlock() publishes all non-volatile changes made to a complex data structure used within the critical section to the next call to lock()?  If not, how can I fix this?

Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131007/313c4164/attachment.html>

From andrew_nuss at yahoo.com  Mon Oct  7 12:09:26 2013
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 7 Oct 2013 09:09:26 -0700 (PDT)
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23D4C698E@G9W0725.americas.hpqcorp.net>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D4C698E@G9W0725.americas.hpqcorp.net>
Message-ID: <1381162166.29365.YahooMailNeo@web141103.mail.bf1.yahoo.com>

Can someone explain how the successful atomic.compareAndSet() sees all 
changes to main memory made by the last thread that did atomic.set() 
without any use of a volatile assignment (as implied by Hans)?? Is this explained in JCIP?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131007/65d6f493/attachment.html>

From kasperni at gmail.com  Mon Oct  7 12:31:52 2013
From: kasperni at gmail.com (Kasper Nielsen)
Date: Mon, 7 Oct 2013 18:31:52 +0200
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <1381162166.29365.YahooMailNeo@web141103.mail.bf1.yahoo.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D4C698E@G9W0725.americas.hpqcorp.net>
	<1381162166.29365.YahooMailNeo@web141103.mail.bf1.yahoo.com>
Message-ID: <CAPs6151FEDXVxTuc_r9gXJ9anwV57x70OasDP7M_BhW+A6yAZg@mail.gmail.com>

On Mon, Oct 7, 2013 at 6:09 PM, Andy Nuss <andrew_nuss at yahoo.com> wrote:

> Can someone explain how the successful atomic.compareAndSet() sees all
> changes to main memory made by the last thread that did atomic.set()
> without any use of a volatile assignment (as implied by Hans)?
>
AtomicBoolean itself uses a volatile variable:

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/atomic/AtomicBoolean.java?revision=1.27
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131007/68622987/attachment.html>

From tim at peierls.net  Mon Oct  7 12:41:43 2013
From: tim at peierls.net (Tim Peierls)
Date: Mon, 7 Oct 2013 12:41:43 -0400
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <1381162166.29365.YahooMailNeo@web141103.mail.bf1.yahoo.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D4C698E@G9W0725.americas.hpqcorp.net>
	<1381162166.29365.YahooMailNeo@web141103.mail.bf1.yahoo.com>
Message-ID: <CA+F8eeSNo1XLZf=C6CfnHR4=ikG02ugu6QRVDqO6-osD4GOz=w@mail.gmail.com>

See the package doc for java.util.concurrent.atomic.

--tim


On Mon, Oct 7, 2013 at 12:09 PM, Andy Nuss <andrew_nuss at yahoo.com> wrote:

> Can someone explain how the successful atomic.compareAndSet() sees all
> changes to main memory made by the last thread that did atomic.set()
> without any use of a volatile assignment (as implied by Hans)?  Is this
> explained in JCIP?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131007/81eabc48/attachment.html>

From brian at briangoetz.com  Tue Oct  8 13:58:25 2013
From: brian at briangoetz.com (Brian Goetz)
Date: Tue, 08 Oct 2013 13:58:25 -0400
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <524B053B.3000605@oracle.com>
References: <524B053B.3000605@oracle.com>
Message-ID: <525447C1.4090007@briangoetz.com>

So, here's the definitive answer about why we haven't done this yet (it 
was discussed by the 335 and 166 EGs.)

 From an API perspective, improvements like these are obvious.  The code 
is shorter, clearer, and less error-prone.  So it seems like a no-brainer.

However, such an API would have a hidden performance cost, at least 
until some VM work plays out.  Here's why.

When you write a method like

   void withLock(Runnable)

the Runnable is going to have side-effects.  So its going to be a 
capturing lambda -- one that captures variables from its scope:

   withLock( () -> { counter++; } );  // counter is captured

With the current implementation of lambda, evaluating (not invoking) a 
capturing lambda expression will cause an allocation.  Whereas the 
hand-unrolled version:

   lock.lock();
   try { counter++; }
   finally { lock.unlock(); }

does not.  The sort of things people do with locks are generally pretty 
performance-sensitive, so such an API was deemed, at the current time, 
to be an "attractive nuisance."

However, we think it is worthwhile to invest in making such idioms 
suitably performant so that we do not have to make these tradeoffs.  The 
missing piece here is intrinsification of the lambda capture; with this, 
existing optimizations (code motion, escape analysis, inlining, and 
generalized box-unbox elimination) can eliminate the capture cost and 
render this idiom free in most cases.  When we get there, we'll revisit 
APIs like this.

On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
> Here's an example of code using ReentrantLock.
>
> private final ReentrantLock m_lock = new ReentrantLock();
> private       int           m_count;
> private final int           m_capacity;
>
> public boolean reserve()
> {
>     m_lock.lock();
>
>     try
>     {
>        if (m_count >= m_capacity)
>           return(false);
>
>        m_count++;
>
>        return(true);
>     }
>     finally
>     {
>        m_lock.unlock();
>     }
> }
>
> There are several problems with this code.  1)  You have to remember to
> call unlock().  2)  You have to put the unlock() in the finally block.
> 3)  The finally block can't have other exception throwing constructs or
> the lock won't be released on some code paths.  4) The m_lock reference
> shouldn't be allowed to change while a thread is executing inside reserve().
>
> After attending JavaOne and hearing about lambdas and default methods in
> interfaces, I came up with an idea to make writing locked code less
> error prone.  The idea is to provide default methods in the Lock
> interface which would make writing the above code simpler and less error
> prone.  Here's one such method.
>
> public void guard(Runnable guarded)
> {
>     lock();
>
>     try
>     {
>        guarded.run();
>     }
>     finally
>     {
>        unlock();
>     }
> }
>
> With the guard() method available, the reserve() method can be rewritten
> in JDK 8 as such.
>
> public boolean reserve()
> {
>     return(m_lock.guard(() ->
>     {
>        if (m_count >= m_capacity)
>           return(false);
>
>        m_count++;
>
>        return(true);
>     }));
> }
>
> All the aforementioned problems are no longer applicable.  guard() takes
> care of them.  The code is much clearer to understand since the
> boilerplate locking code is gone.  It also might help JIT by reducing
> the amount of cookie cutter code it has to optimize.
>
> Here are the method signatures of other methods which could be added to
> the Lock interface.  The full code is available at
> https://bugs.openjdk.java.net/browse/JDK-8025597.
>
>     public <T> T           guard(Callable<T> guarded) throws Exception
>     public     void        guardInterruptibly(Runnable guarded) throws
> InterruptedException
>     public <T> T guardInterruptibly(Callable<T> guarded) throws
> Exception, InterruptedException
>     public     boolean     tryGuard(Runnable guarded)
>     public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>     public     boolean     tryGuard(Runnable guarded, long time,
> TimeUnit unit) throws InterruptedException
>     public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> TimeUnit unit) throws Exception, InterruptedException
>
> What do you think?  Please ignore formatting and method names for the
> moment.
>
> --
> -Nathan
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From ron.pressler at gmail.com  Tue Oct  8 17:03:20 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Tue, 8 Oct 2013 23:03:20 +0200
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <525447C1.4090007@briangoetz.com>
References: <524B053B.3000605@oracle.com> <525447C1.4090007@briangoetz.com>
Message-ID: <CABg6-qhSP=9cdMpo3+BP_GuEnNFXZsttRRWvXapZxZXrxHFezw@mail.gmail.com>

Can't current escape analysis and scalar replacement avoid the allocation?
If the call to withLock is inlined, isn't it apparent to the JIT that the
capture doesn't escape?

Also, what about the try-with-resources suggestion? It requires no
allocation (although it would mean abandoning the language requirement for
a local var declaration in the try clause, as well as making Lock implement
AutoCloseable).


On Tue, Oct 8, 2013 at 8:58 PM, Brian Goetz <brian at briangoetz.com> wrote:

> So, here's the definitive answer about why we haven't done this yet (it
> was discussed by the 335 and 166 EGs.)
>
> From an API perspective, improvements like these are obvious.  The code is
> shorter, clearer, and less error-prone.  So it seems like a no-brainer.
>
> However, such an API would have a hidden performance cost, at least until
> some VM work plays out.  Here's why.
>
> When you write a method like
>
>   void withLock(Runnable)
>
> the Runnable is going to have side-effects.  So its going to be a
> capturing lambda -- one that captures variables from its scope:
>
>   withLock( () -> { counter++; } );  // counter is captured
>
> With the current implementation of lambda, evaluating (not invoking) a
> capturing lambda expression will cause an allocation.  Whereas the
> hand-unrolled version:
>
>   lock.lock();
>   try { counter++; }
>   finally { lock.unlock(); }
>
> does not.  The sort of things people do with locks are generally pretty
> performance-sensitive, so such an API was deemed, at the current time, to
> be an "attractive nuisance."
>
> However, we think it is worthwhile to invest in making such idioms
> suitably performant so that we do not have to make these tradeoffs.  The
> missing piece here is intrinsification of the lambda capture; with this,
> existing optimizations (code motion, escape analysis, inlining, and
> generalized box-unbox elimination) can eliminate the capture cost and
> render this idiom free in most cases.  When we get there, we'll revisit
> APIs like this.
>
>
> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>
>> Here's an example of code using ReentrantLock.
>>
>> private final ReentrantLock m_lock = new ReentrantLock();
>> private       int           m_count;
>> private final int           m_capacity;
>>
>> public boolean reserve()
>> {
>>     m_lock.lock();
>>
>>     try
>>     {
>>        if (m_count >= m_capacity)
>>           return(false);
>>
>>        m_count++;
>>
>>        return(true);
>>     }
>>     finally
>>     {
>>        m_lock.unlock();
>>     }
>> }
>>
>> There are several problems with this code.  1)  You have to remember to
>> call unlock().  2)  You have to put the unlock() in the finally block.
>> 3)  The finally block can't have other exception throwing constructs or
>> the lock won't be released on some code paths.  4) The m_lock reference
>> shouldn't be allowed to change while a thread is executing inside
>> reserve().
>>
>> After attending JavaOne and hearing about lambdas and default methods in
>> interfaces, I came up with an idea to make writing locked code less
>> error prone.  The idea is to provide default methods in the Lock
>> interface which would make writing the above code simpler and less error
>> prone.  Here's one such method.
>>
>> public void guard(Runnable guarded)
>> {
>>     lock();
>>
>>     try
>>     {
>>        guarded.run();
>>     }
>>     finally
>>     {
>>        unlock();
>>     }
>> }
>>
>> With the guard() method available, the reserve() method can be rewritten
>> in JDK 8 as such.
>>
>> public boolean reserve()
>> {
>>     return(m_lock.guard(() ->
>>     {
>>        if (m_count >= m_capacity)
>>           return(false);
>>
>>        m_count++;
>>
>>        return(true);
>>     }));
>> }
>>
>> All the aforementioned problems are no longer applicable.  guard() takes
>> care of them.  The code is much clearer to understand since the
>> boilerplate locking code is gone.  It also might help JIT by reducing
>> the amount of cookie cutter code it has to optimize.
>>
>> Here are the method signatures of other methods which could be added to
>> the Lock interface.  The full code is available at
>> https://bugs.openjdk.java.net/**browse/JDK-8025597<https://bugs.openjdk.java.net/browse/JDK-8025597>
>> .
>>
>>     public <T> T           guard(Callable<T> guarded) throws Exception
>>     public     void        guardInterruptibly(Runnable guarded) throws
>> InterruptedException
>>     public <T> T guardInterruptibly(Callable<T> guarded) throws
>> Exception, InterruptedException
>>     public     boolean     tryGuard(Runnable guarded)
>>     public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>>     public     boolean     tryGuard(Runnable guarded, long time,
>> TimeUnit unit) throws InterruptedException
>>     public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
>> TimeUnit unit) throws Exception, InterruptedException
>>
>> What do you think?  Please ignore formatting and method names for the
>> moment.
>>
>> --
>> -Nathan
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>  ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131008/e9c4ff31/attachment.html>

From forax at univ-mlv.fr  Tue Oct  8 17:49:48 2013
From: forax at univ-mlv.fr (Remi Forax)
Date: Tue, 08 Oct 2013 23:49:48 +0200
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CABg6-qhSP=9cdMpo3+BP_GuEnNFXZsttRRWvXapZxZXrxHFezw@mail.gmail.com>
References: <524B053B.3000605@oracle.com> <525447C1.4090007@briangoetz.com>
	<CABg6-qhSP=9cdMpo3+BP_GuEnNFXZsttRRWvXapZxZXrxHFezw@mail.gmail.com>
Message-ID: <52547DFC.9070206@univ-mlv.fr>

On 10/08/2013 11:03 PM, Ron Pressler wrote:
> Can't current escape analysis and scalar replacement avoid the 
> allocation? If the call to withLock is inlined, isn't it apparent to 
> the JIT that the capture doesn't escape?

Before escape analysis, you need inlining (at least with Hotspot) and 
because of the way Hotspot interpreter (or first tier compiler) does 
profiling, the VM can decide to not inline withLock. There are several 
VM engineers that are currently working on that, it's a well known issue 
and a hard problem so it will take time to figure out what is the best 
way to enabe inlining in this case.

>
> Also, what about the try-with-resources suggestion? It requires no 
> allocation (although it would mean abandoning the language requirement 
> for a local var declaration in the try clause, as well as making Lock 
> implement AutoCloseable).

Historically, the first version of t-w-r was without the local var 
declaration, it was introduced later to avoid to be able to use a 
reference to a closed object after the t-w-r.

cheers,
R?mi


>
>
> On Tue, Oct 8, 2013 at 8:58 PM, Brian Goetz <brian at briangoetz.com 
> <mailto:brian at briangoetz.com>> wrote:
>
>     So, here's the definitive answer about why we haven't done this
>     yet (it was discussed by the 335 and 166 EGs.)
>
>     From an API perspective, improvements like these are obvious.  The
>     code is shorter, clearer, and less error-prone.  So it seems like
>     a no-brainer.
>
>     However, such an API would have a hidden performance cost, at
>     least until some VM work plays out.  Here's why.
>
>     When you write a method like
>
>       void withLock(Runnable)
>
>     the Runnable is going to have side-effects.  So its going to be a
>     capturing lambda -- one that captures variables from its scope:
>
>       withLock( () -> { counter++; } );  // counter is captured
>
>     With the current implementation of lambda, evaluating (not
>     invoking) a capturing lambda expression will cause an allocation.
>      Whereas the hand-unrolled version:
>
>       lock.lock();
>       try { counter++; }
>       finally { lock.unlock(); }
>
>     does not.  The sort of things people do with locks are generally
>     pretty performance-sensitive, so such an API was deemed, at the
>     current time, to be an "attractive nuisance."
>
>     However, we think it is worthwhile to invest in making such idioms
>     suitably performant so that we do not have to make these
>     tradeoffs.  The missing piece here is intrinsification of the
>     lambda capture; with this, existing optimizations (code motion,
>     escape analysis, inlining, and generalized box-unbox elimination)
>     can eliminate the capture cost and render this idiom free in most
>     cases.  When we get there, we'll revisit APIs like this.
>
>
>     On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>
>         Here's an example of code using ReentrantLock.
>
>         private final ReentrantLock m_lock = new ReentrantLock();
>         private       int           m_count;
>         private final int           m_capacity;
>
>         public boolean reserve()
>         {
>             m_lock.lock();
>
>             try
>             {
>                if (m_count >= m_capacity)
>                   return(false);
>
>                m_count++;
>
>                return(true);
>             }
>             finally
>             {
>                m_lock.unlock();
>             }
>         }
>
>         There are several problems with this code.  1)  You have to
>         remember to
>         call unlock().  2)  You have to put the unlock() in the
>         finally block.
>         3)  The finally block can't have other exception throwing
>         constructs or
>         the lock won't be released on some code paths.  4) The m_lock
>         reference
>         shouldn't be allowed to change while a thread is executing
>         inside reserve().
>
>         After attending JavaOne and hearing about lambdas and default
>         methods in
>         interfaces, I came up with an idea to make writing locked code
>         less
>         error prone.  The idea is to provide default methods in the Lock
>         interface which would make writing the above code simpler and
>         less error
>         prone.  Here's one such method.
>
>         public void guard(Runnable guarded)
>         {
>             lock();
>
>             try
>             {
>                guarded.run();
>             }
>             finally
>             {
>                unlock();
>             }
>         }
>
>         With the guard() method available, the reserve() method can be
>         rewritten
>         in JDK 8 as such.
>
>         public boolean reserve()
>         {
>             return(m_lock.guard(() ->
>             {
>                if (m_count >= m_capacity)
>                   return(false);
>
>                m_count++;
>
>                return(true);
>             }));
>         }
>
>         All the aforementioned problems are no longer applicable.
>          guard() takes
>         care of them.  The code is much clearer to understand since the
>         boilerplate locking code is gone.  It also might help JIT by
>         reducing
>         the amount of cookie cutter code it has to optimize.
>
>         Here are the method signatures of other methods which could be
>         added to
>         the Lock interface.  The full code is available at
>         https://bugs.openjdk.java.net/browse/JDK-8025597.
>
>             public <T> T guard(Callable<T> guarded) throws Exception
>             public     void        guardInterruptibly(Runnable
>         guarded) throws
>         InterruptedException
>             public <T> T guardInterruptibly(Callable<T> guarded) throws
>         Exception, InterruptedException
>             public     boolean     tryGuard(Runnable guarded)
>             public <T> Optional<T> tryGuard(Callable<T> guarded)
>         throws Exception
>             public     boolean     tryGuard(Runnable guarded, long time,
>         TimeUnit unit) throws InterruptedException
>             public <T> Optional<T> tryGuard(Callable<T> guarded, long
>         time,
>         TimeUnit unit) throws Exception, InterruptedException
>
>         What do you think?  Please ignore formatting and method names
>         for the
>         moment.
>
>         --
>         -Nathan
>
>
>
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From ron.pressler at gmail.com  Tue Oct  8 19:56:06 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Wed, 9 Oct 2013 01:56:06 +0200
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <52547DFC.9070206@univ-mlv.fr>
References: <524B053B.3000605@oracle.com> <525447C1.4090007@briangoetz.com>
	<CABg6-qhSP=9cdMpo3+BP_GuEnNFXZsttRRWvXapZxZXrxHFezw@mail.gmail.com>
	<52547DFC.9070206@univ-mlv.fr>
Message-ID: <CABg6-qh5v0G2OMUaC1wYqWf7sNMtDtzGA8kcY+=hdHQD-uTs1A@mail.gmail.com>

On Wed, Oct 9, 2013 at 12:49 AM, Remi Forax <forax at univ-mlv.fr> wrote:

>
> Before escape analysis, you need inlining (at least with Hotspot) and
> because of the way Hotspot interpreter (or first tier compiler) does
> profiling, the VM can decide to not inline withLock. There are several VM
> engineers that are currently working on that, it's a well known issue and a
> hard problem so it will take time to figure out what is the best way to
> enabe inlining in this case.
>
>
Interesting.


>  Historically, the first version of t-w-r was without the local var
> declaration, it was introduced later to avoid to be able to use a reference
> to a closed object after the t-w-r.
>
>
Well, you can still do this:

        InputStream is = new FileInputStream("foo");
        try(InputStream is1 = is) {
        }
        is.read();

But I see what you're saying ? it looks weird and alerts the programmer to
incorrect usage.



>
>>
>> On Tue, Oct 8, 2013 at 8:58 PM, Brian Goetz <brian at briangoetz.com<mailto:
>> brian at briangoetz.com>> wrote:
>>
>>     So, here's the definitive answer about why we haven't done this
>>     yet (it was discussed by the 335 and 166 EGs.)
>>
>>     From an API perspective, improvements like these are obvious.  The
>>     code is shorter, clearer, and less error-prone.  So it seems like
>>     a no-brainer.
>>
>>     However, such an API would have a hidden performance cost, at
>>     least until some VM work plays out.  Here's why.
>>
>>     When you write a method like
>>
>>       void withLock(Runnable)
>>
>>     the Runnable is going to have side-effects.  So its going to be a
>>     capturing lambda -- one that captures variables from its scope:
>>
>>       withLock( () -> { counter++; } );  // counter is captured
>>
>>     With the current implementation of lambda, evaluating (not
>>     invoking) a capturing lambda expression will cause an allocation.
>>      Whereas the hand-unrolled version:
>>
>>       lock.lock();
>>       try { counter++; }
>>       finally { lock.unlock(); }
>>
>>     does not.  The sort of things people do with locks are generally
>>     pretty performance-sensitive, so such an API was deemed, at the
>>     current time, to be an "attractive nuisance."
>>
>>     However, we think it is worthwhile to invest in making such idioms
>>     suitably performant so that we do not have to make these
>>     tradeoffs.  The missing piece here is intrinsification of the
>>     lambda capture; with this, existing optimizations (code motion,
>>     escape analysis, inlining, and generalized box-unbox elimination)
>>     can eliminate the capture cost and render this idiom free in most
>>     cases.  When we get there, we'll revisit APIs like this.
>>
>>
>>     On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>>
>>         Here's an example of code using ReentrantLock.
>>
>>         private final ReentrantLock m_lock = new ReentrantLock();
>>         private       int           m_count;
>>         private final int           m_capacity;
>>
>>         public boolean reserve()
>>         {
>>             m_lock.lock();
>>
>>             try
>>             {
>>                if (m_count >= m_capacity)
>>                   return(false);
>>
>>                m_count++;
>>
>>                return(true);
>>             }
>>             finally
>>             {
>>                m_lock.unlock();
>>             }
>>         }
>>
>>         There are several problems with this code.  1)  You have to
>>         remember to
>>         call unlock().  2)  You have to put the unlock() in the
>>         finally block.
>>         3)  The finally block can't have other exception throwing
>>         constructs or
>>         the lock won't be released on some code paths.  4) The m_lock
>>         reference
>>         shouldn't be allowed to change while a thread is executing
>>         inside reserve().
>>
>>         After attending JavaOne and hearing about lambdas and default
>>         methods in
>>         interfaces, I came up with an idea to make writing locked code
>>         less
>>         error prone.  The idea is to provide default methods in the Lock
>>         interface which would make writing the above code simpler and
>>         less error
>>         prone.  Here's one such method.
>>
>>         public void guard(Runnable guarded)
>>         {
>>             lock();
>>
>>             try
>>             {
>>                guarded.run();
>>             }
>>             finally
>>             {
>>                unlock();
>>             }
>>         }
>>
>>         With the guard() method available, the reserve() method can be
>>         rewritten
>>         in JDK 8 as such.
>>
>>         public boolean reserve()
>>         {
>>             return(m_lock.guard(() ->
>>             {
>>                if (m_count >= m_capacity)
>>                   return(false);
>>
>>                m_count++;
>>
>>                return(true);
>>             }));
>>         }
>>
>>         All the aforementioned problems are no longer applicable.
>>          guard() takes
>>         care of them.  The code is much clearer to understand since the
>>         boilerplate locking code is gone.  It also might help JIT by
>>         reducing
>>         the amount of cookie cutter code it has to optimize.
>>
>>         Here are the method signatures of other methods which could be
>>         added to
>>         the Lock interface.  The full code is available at
>>         https://bugs.openjdk.java.net/**browse/JDK-8025597<https://bugs.openjdk.java.net/browse/JDK-8025597>
>> .
>>
>>             public <T> T guard(Callable<T> guarded) throws Exception
>>             public     void        guardInterruptibly(Runnable
>>         guarded) throws
>>         InterruptedException
>>             public <T> T guardInterruptibly(Callable<T> guarded) throws
>>         Exception, InterruptedException
>>             public     boolean     tryGuard(Runnable guarded)
>>             public <T> Optional<T> tryGuard(Callable<T> guarded)
>>         throws Exception
>>             public     boolean     tryGuard(Runnable guarded, long time,
>>         TimeUnit unit) throws InterruptedException
>>             public <T> Optional<T> tryGuard(Callable<T> guarded, long
>>         time,
>>         TimeUnit unit) throws Exception, InterruptedException
>>
>>         What do you think?  Please ignore formatting and method names
>>         for the
>>         moment.
>>
>>         --
>>         -Nathan
>>
>>
>>
>>         ______________________________**_________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>         <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>> >
>>
>>         http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>     ______________________________**_________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>     <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>> >
>>
>>     http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131009/8e9bd692/attachment.html>

From heinz at javaspecialists.eu  Wed Oct  9 00:39:04 2013
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 9 Oct 2013 07:39:04 +0300
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <525447C1.4090007@briangoetz.com>
References: <524B053B.3000605@oracle.com>
	<525447C1.4090007@briangoetz.com>
Message-ID: <CACLL95qkZyJ8t=nHi-+P9hM6h7JY0bOaiS87WA7cSHkFYjTQRg@mail.gmail.com>

Brian, when the lock is contended, it will itself cause an allocation.

On 08/10/2013, Brian Goetz <brian at briangoetz.com> wrote:
> So, here's the definitive answer about why we haven't done this yet (it
> was discussed by the 335 and 166 EGs.)
>
>  From an API perspective, improvements like these are obvious.  The code
> is shorter, clearer, and less error-prone.  So it seems like a no-brainer.
>
> However, such an API would have a hidden performance cost, at least
> until some VM work plays out.  Here's why.
>
> When you write a method like
>
>    void withLock(Runnable)
>
> the Runnable is going to have side-effects.  So its going to be a
> capturing lambda -- one that captures variables from its scope:
>
>    withLock( () -> { counter++; } );  // counter is captured
>
> With the current implementation of lambda, evaluating (not invoking) a
> capturing lambda expression will cause an allocation.  Whereas the
> hand-unrolled version:
>
>    lock.lock();
>    try { counter++; }
>    finally { lock.unlock(); }
>
> does not.  The sort of things people do with locks are generally pretty
> performance-sensitive, so such an API was deemed, at the current time,
> to be an "attractive nuisance."
>
> However, we think it is worthwhile to invest in making such idioms
> suitably performant so that we do not have to make these tradeoffs.  The
> missing piece here is intrinsification of the lambda capture; with this,
> existing optimizations (code motion, escape analysis, inlining, and
> generalized box-unbox elimination) can eliminate the capture cost and
> render this idiom free in most cases.  When we get there, we'll revisit
> APIs like this.
>
> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>> Here's an example of code using ReentrantLock.
>>
>> private final ReentrantLock m_lock = new ReentrantLock();
>> private       int           m_count;
>> private final int           m_capacity;
>>
>> public boolean reserve()
>> {
>>     m_lock.lock();
>>
>>     try
>>     {
>>        if (m_count >= m_capacity)
>>           return(false);
>>
>>        m_count++;
>>
>>        return(true);
>>     }
>>     finally
>>     {
>>        m_lock.unlock();
>>     }
>> }
>>
>> There are several problems with this code.  1)  You have to remember to
>> call unlock().  2)  You have to put the unlock() in the finally block.
>> 3)  The finally block can't have other exception throwing constructs or
>> the lock won't be released on some code paths.  4) The m_lock reference
>> shouldn't be allowed to change while a thread is executing inside
>> reserve().
>>
>> After attending JavaOne and hearing about lambdas and default methods in
>> interfaces, I came up with an idea to make writing locked code less
>> error prone.  The idea is to provide default methods in the Lock
>> interface which would make writing the above code simpler and less error
>> prone.  Here's one such method.
>>
>> public void guard(Runnable guarded)
>> {
>>     lock();
>>
>>     try
>>     {
>>        guarded.run();
>>     }
>>     finally
>>     {
>>        unlock();
>>     }
>> }
>>
>> With the guard() method available, the reserve() method can be rewritten
>> in JDK 8 as such.
>>
>> public boolean reserve()
>> {
>>     return(m_lock.guard(() ->
>>     {
>>        if (m_count >= m_capacity)
>>           return(false);
>>
>>        m_count++;
>>
>>        return(true);
>>     }));
>> }
>>
>> All the aforementioned problems are no longer applicable.  guard() takes
>> care of them.  The code is much clearer to understand since the
>> boilerplate locking code is gone.  It also might help JIT by reducing
>> the amount of cookie cutter code it has to optimize.
>>
>> Here are the method signatures of other methods which could be added to
>> the Lock interface.  The full code is available at
>> https://bugs.openjdk.java.net/browse/JDK-8025597.
>>
>>     public <T> T           guard(Callable<T> guarded) throws Exception
>>     public     void        guardInterruptibly(Runnable guarded) throws
>> InterruptedException
>>     public <T> T guardInterruptibly(Callable<T> guarded) throws
>> Exception, InterruptedException
>>     public     boolean     tryGuard(Runnable guarded)
>>     public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>>     public     boolean     tryGuard(Runnable guarded, long time,
>> TimeUnit unit) throws InterruptedException
>>     public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
>> TimeUnit unit) throws Exception, InterruptedException
>>
>> What do you think?  Please ignore formatting and method names for the
>> moment.
>>
>> --
>> -Nathan
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion 2005-2013
JavaOne Rockstar Speaker 2012
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz

From kirk at kodewerk.com  Wed Oct  9 07:27:10 2013
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 9 Oct 2013 13:27:10 +0200
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CACLL95qkZyJ8t=nHi-+P9hM6h7JY0bOaiS87WA7cSHkFYjTQRg@mail.gmail.com>
References: <524B053B.3000605@oracle.com> <525447C1.4090007@briangoetz.com>
	<CACLL95qkZyJ8t=nHi-+P9hM6h7JY0bOaiS87WA7cSHkFYjTQRg@mail.gmail.com>
Message-ID: <D472E21E-2932-4789-9887-18EC2487FB74@kodewerk.com>

an inflation and an over write of the biased lock bits along with the recording of an object identify hash that will prevent all future biasings of that lock....

On 2013-10-09, at 6:39 AM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:

> Brian, when the lock is contended, it will itself cause an allocation.
> 
> On 08/10/2013, Brian Goetz <brian at briangoetz.com> wrote:
>> So, here's the definitive answer about why we haven't done this yet (it
>> was discussed by the 335 and 166 EGs.)
>> 
>> From an API perspective, improvements like these are obvious.  The code
>> is shorter, clearer, and less error-prone.  So it seems like a no-brainer.
>> 
>> However, such an API would have a hidden performance cost, at least
>> until some VM work plays out.  Here's why.
>> 
>> When you write a method like
>> 
>>   void withLock(Runnable)
>> 
>> the Runnable is going to have side-effects.  So its going to be a
>> capturing lambda -- one that captures variables from its scope:
>> 
>>   withLock( () -> { counter++; } );  // counter is captured
>> 
>> With the current implementation of lambda, evaluating (not invoking) a
>> capturing lambda expression will cause an allocation.  Whereas the
>> hand-unrolled version:
>> 
>>   lock.lock();
>>   try { counter++; }
>>   finally { lock.unlock(); }
>> 
>> does not.  The sort of things people do with locks are generally pretty
>> performance-sensitive, so such an API was deemed, at the current time,
>> to be an "attractive nuisance."
>> 
>> However, we think it is worthwhile to invest in making such idioms
>> suitably performant so that we do not have to make these tradeoffs.  The
>> missing piece here is intrinsification of the lambda capture; with this,
>> existing optimizations (code motion, escape analysis, inlining, and
>> generalized box-unbox elimination) can eliminate the capture cost and
>> render this idiom free in most cases.  When we get there, we'll revisit
>> APIs like this.
>> 
>> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>>> Here's an example of code using ReentrantLock.
>>> 
>>> private final ReentrantLock m_lock = new ReentrantLock();
>>> private       int           m_count;
>>> private final int           m_capacity;
>>> 
>>> public boolean reserve()
>>> {
>>>    m_lock.lock();
>>> 
>>>    try
>>>    {
>>>       if (m_count >= m_capacity)
>>>          return(false);
>>> 
>>>       m_count++;
>>> 
>>>       return(true);
>>>    }
>>>    finally
>>>    {
>>>       m_lock.unlock();
>>>    }
>>> }
>>> 
>>> There are several problems with this code.  1)  You have to remember to
>>> call unlock().  2)  You have to put the unlock() in the finally block.
>>> 3)  The finally block can't have other exception throwing constructs or
>>> the lock won't be released on some code paths.  4) The m_lock reference
>>> shouldn't be allowed to change while a thread is executing inside
>>> reserve().
>>> 
>>> After attending JavaOne and hearing about lambdas and default methods in
>>> interfaces, I came up with an idea to make writing locked code less
>>> error prone.  The idea is to provide default methods in the Lock
>>> interface which would make writing the above code simpler and less error
>>> prone.  Here's one such method.
>>> 
>>> public void guard(Runnable guarded)
>>> {
>>>    lock();
>>> 
>>>    try
>>>    {
>>>       guarded.run();
>>>    }
>>>    finally
>>>    {
>>>       unlock();
>>>    }
>>> }
>>> 
>>> With the guard() method available, the reserve() method can be rewritten
>>> in JDK 8 as such.
>>> 
>>> public boolean reserve()
>>> {
>>>    return(m_lock.guard(() ->
>>>    {
>>>       if (m_count >= m_capacity)
>>>          return(false);
>>> 
>>>       m_count++;
>>> 
>>>       return(true);
>>>    }));
>>> }
>>> 
>>> All the aforementioned problems are no longer applicable.  guard() takes
>>> care of them.  The code is much clearer to understand since the
>>> boilerplate locking code is gone.  It also might help JIT by reducing
>>> the amount of cookie cutter code it has to optimize.
>>> 
>>> Here are the method signatures of other methods which could be added to
>>> the Lock interface.  The full code is available at
>>> https://bugs.openjdk.java.net/browse/JDK-8025597.
>>> 
>>>    public <T> T           guard(Callable<T> guarded) throws Exception
>>>    public     void        guardInterruptibly(Runnable guarded) throws
>>> InterruptedException
>>>    public <T> T guardInterruptibly(Callable<T> guarded) throws
>>> Exception, InterruptedException
>>>    public     boolean     tryGuard(Runnable guarded)
>>>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws Exception
>>>    public     boolean     tryGuard(Runnable guarded, long time,
>>> TimeUnit unit) throws InterruptedException
>>>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
>>> TimeUnit unit) throws Exception, InterruptedException
>>> 
>>> What do you think?  Please ignore formatting and method names for the
>>> moment.
>>> 
>>> --
>>> -Nathan
>>> 
>>> 
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
> 
> 
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion 2005-2013
> JavaOne Rockstar Speaker 2012
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From heinz at javaspecialists.eu  Wed Oct  9 07:45:26 2013
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 9 Oct 2013 14:45:26 +0300
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <D472E21E-2932-4789-9887-18EC2487FB74@kodewerk.com>
References: <524B053B.3000605@oracle.com> <525447C1.4090007@briangoetz.com>
	<CACLL95qkZyJ8t=nHi-+P9hM6h7JY0bOaiS87WA7cSHkFYjTQRg@mail.gmail.com>
	<D472E21E-2932-4789-9887-18EC2487FB74@kodewerk.com>
Message-ID: <CACLL95pkKytdJoX6vJqM5S36bjdvhoRgVCxQqaW1u1Ufc44F2A@mail.gmail.com>

There is no biased locking AFAIK with ReentrantLock.

On 09/10/2013, Kirk Pepperdine <kirk at kodewerk.com> wrote:
> an inflation and an over write of the biased lock bits along with the
> recording of an object identify hash that will prevent all future biasings
> of that lock....
>
> On 2013-10-09, at 6:39 AM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu>
> wrote:
>
>> Brian, when the lock is contended, it will itself cause an allocation.
>>
>> On 08/10/2013, Brian Goetz <brian at briangoetz.com> wrote:
>>> So, here's the definitive answer about why we haven't done this yet (it
>>> was discussed by the 335 and 166 EGs.)
>>>
>>> From an API perspective, improvements like these are obvious.  The code
>>> is shorter, clearer, and less error-prone.  So it seems like a
>>> no-brainer.
>>>
>>> However, such an API would have a hidden performance cost, at least
>>> until some VM work plays out.  Here's why.
>>>
>>> When you write a method like
>>>
>>>   void withLock(Runnable)
>>>
>>> the Runnable is going to have side-effects.  So its going to be a
>>> capturing lambda -- one that captures variables from its scope:
>>>
>>>   withLock( () -> { counter++; } );  // counter is captured
>>>
>>> With the current implementation of lambda, evaluating (not invoking) a
>>> capturing lambda expression will cause an allocation.  Whereas the
>>> hand-unrolled version:
>>>
>>>   lock.lock();
>>>   try { counter++; }
>>>   finally { lock.unlock(); }
>>>
>>> does not.  The sort of things people do with locks are generally pretty
>>> performance-sensitive, so such an API was deemed, at the current time,
>>> to be an "attractive nuisance."
>>>
>>> However, we think it is worthwhile to invest in making such idioms
>>> suitably performant so that we do not have to make these tradeoffs.  The
>>> missing piece here is intrinsification of the lambda capture; with this,
>>> existing optimizations (code motion, escape analysis, inlining, and
>>> generalized box-unbox elimination) can eliminate the capture cost and
>>> render this idiom free in most cases.  When we get there, we'll revisit
>>> APIs like this.
>>>
>>> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>>>> Here's an example of code using ReentrantLock.
>>>>
>>>> private final ReentrantLock m_lock = new ReentrantLock();
>>>> private       int           m_count;
>>>> private final int           m_capacity;
>>>>
>>>> public boolean reserve()
>>>> {
>>>>    m_lock.lock();
>>>>
>>>>    try
>>>>    {
>>>>       if (m_count >= m_capacity)
>>>>          return(false);
>>>>
>>>>       m_count++;
>>>>
>>>>       return(true);
>>>>    }
>>>>    finally
>>>>    {
>>>>       m_lock.unlock();
>>>>    }
>>>> }
>>>>
>>>> There are several problems with this code.  1)  You have to remember to
>>>> call unlock().  2)  You have to put the unlock() in the finally block.
>>>> 3)  The finally block can't have other exception throwing constructs or
>>>> the lock won't be released on some code paths.  4) The m_lock reference
>>>> shouldn't be allowed to change while a thread is executing inside
>>>> reserve().
>>>>
>>>> After attending JavaOne and hearing about lambdas and default methods
>>>> in
>>>> interfaces, I came up with an idea to make writing locked code less
>>>> error prone.  The idea is to provide default methods in the Lock
>>>> interface which would make writing the above code simpler and less
>>>> error
>>>> prone.  Here's one such method.
>>>>
>>>> public void guard(Runnable guarded)
>>>> {
>>>>    lock();
>>>>
>>>>    try
>>>>    {
>>>>       guarded.run();
>>>>    }
>>>>    finally
>>>>    {
>>>>       unlock();
>>>>    }
>>>> }
>>>>
>>>> With the guard() method available, the reserve() method can be
>>>> rewritten
>>>> in JDK 8 as such.
>>>>
>>>> public boolean reserve()
>>>> {
>>>>    return(m_lock.guard(() ->
>>>>    {
>>>>       if (m_count >= m_capacity)
>>>>          return(false);
>>>>
>>>>       m_count++;
>>>>
>>>>       return(true);
>>>>    }));
>>>> }
>>>>
>>>> All the aforementioned problems are no longer applicable.  guard()
>>>> takes
>>>> care of them.  The code is much clearer to understand since the
>>>> boilerplate locking code is gone.  It also might help JIT by reducing
>>>> the amount of cookie cutter code it has to optimize.
>>>>
>>>> Here are the method signatures of other methods which could be added to
>>>> the Lock interface.  The full code is available at
>>>> https://bugs.openjdk.java.net/browse/JDK-8025597.
>>>>
>>>>    public <T> T           guard(Callable<T> guarded) throws Exception
>>>>    public     void        guardInterruptibly(Runnable guarded) throws
>>>> InterruptedException
>>>>    public <T> T guardInterruptibly(Callable<T> guarded) throws
>>>> Exception, InterruptedException
>>>>    public     boolean     tryGuard(Runnable guarded)
>>>>    public <T> Optional<T> tryGuard(Callable<T> guarded) throws
>>>> Exception
>>>>    public     boolean     tryGuard(Runnable guarded, long time,
>>>> TimeUnit unit) throws InterruptedException
>>>>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
>>>> TimeUnit unit) throws Exception, InterruptedException
>>>>
>>>> What do you think?  Please ignore formatting and method names for the
>>>> moment.
>>>>
>>>> --
>>>> -Nathan
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun/Oracle Java Champion 2005-2013
>> JavaOne Rockstar Speaker 2012
>> http://www.javaspecialists.eu
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion 2005-2013
JavaOne Rockstar Speaker 2012
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz

From davidcholmes at aapt.net.au  Wed Oct  9 07:52:07 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 9 Oct 2013 21:52:07 +1000
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <D472E21E-2932-4789-9887-18EC2487FB74@kodewerk.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEEHKBAA.davidcholmes@aapt.net.au>

Kirk Pepperdine wrote:
>
> an inflation and an over write of the biased lock bits along with
> the recording of an object identify hash that will prevent all
> future biasings of that lock....

No we're talking about the use of Lock implementations not synchronized. The
allocation Heinz refers to is the Node to add the current thread to waiting
list. But the allocation Brian refers to is that related to the Lambda.

Anyway while I can understand the desire for automatic lock release (t-w-r
is not the right mechanism though) I find the withLock approach to be
contrary to good OO design where a class encapsulates the code and data for
a given abstraction, as withLock requires that you put the code into a bunch
of different objects that have to have access to the data of the real
object. And all because try/finally is considered "error prone"?

David
-----

> On 2013-10-09, at 6:39 AM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
>
> > Brian, when the lock is contended, it will itself cause an allocation.
> >
> > On 08/10/2013, Brian Goetz <brian at briangoetz.com> wrote:
> >> So, here's the definitive answer about why we haven't done this yet (it
> >> was discussed by the 335 and 166 EGs.)
> >>
> >> From an API perspective, improvements like these are obvious.  The code
> >> is shorter, clearer, and less error-prone.  So it seems like a
> no-brainer.
> >>
> >> However, such an API would have a hidden performance cost, at least
> >> until some VM work plays out.  Here's why.
> >>
> >> When you write a method like
> >>
> >>   void withLock(Runnable)
> >>
> >> the Runnable is going to have side-effects.  So its going to be a
> >> capturing lambda -- one that captures variables from its scope:
> >>
> >>   withLock( () -> { counter++; } );  // counter is captured
> >>
> >> With the current implementation of lambda, evaluating (not invoking) a
> >> capturing lambda expression will cause an allocation.  Whereas the
> >> hand-unrolled version:
> >>
> >>   lock.lock();
> >>   try { counter++; }
> >>   finally { lock.unlock(); }
> >>
> >> does not.  The sort of things people do with locks are generally pretty
> >> performance-sensitive, so such an API was deemed, at the current time,
> >> to be an "attractive nuisance."
> >>
> >> However, we think it is worthwhile to invest in making such idioms
> >> suitably performant so that we do not have to make these
> tradeoffs.  The
> >> missing piece here is intrinsification of the lambda capture;
> with this,
> >> existing optimizations (code motion, escape analysis, inlining, and
> >> generalized box-unbox elimination) can eliminate the capture cost and
> >> render this idiom free in most cases.  When we get there, we'll revisit
> >> APIs like this.
> >>
> >> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
> >>> Here's an example of code using ReentrantLock.
> >>>
> >>> private final ReentrantLock m_lock = new ReentrantLock();
> >>> private       int           m_count;
> >>> private final int           m_capacity;
> >>>
> >>> public boolean reserve()
> >>> {
> >>>    m_lock.lock();
> >>>
> >>>    try
> >>>    {
> >>>       if (m_count >= m_capacity)
> >>>          return(false);
> >>>
> >>>       m_count++;
> >>>
> >>>       return(true);
> >>>    }
> >>>    finally
> >>>    {
> >>>       m_lock.unlock();
> >>>    }
> >>> }
> >>>
> >>> There are several problems with this code.  1)  You have to
> remember to
> >>> call unlock().  2)  You have to put the unlock() in the finally block.
> >>> 3)  The finally block can't have other exception throwing
> constructs or
> >>> the lock won't be released on some code paths.  4) The m_lock
> reference
> >>> shouldn't be allowed to change while a thread is executing inside
> >>> reserve().
> >>>
> >>> After attending JavaOne and hearing about lambdas and default
> methods in
> >>> interfaces, I came up with an idea to make writing locked code less
> >>> error prone.  The idea is to provide default methods in the Lock
> >>> interface which would make writing the above code simpler and
> less error
> >>> prone.  Here's one such method.
> >>>
> >>> public void guard(Runnable guarded)
> >>> {
> >>>    lock();
> >>>
> >>>    try
> >>>    {
> >>>       guarded.run();
> >>>    }
> >>>    finally
> >>>    {
> >>>       unlock();
> >>>    }
> >>> }
> >>>
> >>> With the guard() method available, the reserve() method can
> be rewritten
> >>> in JDK 8 as such.
> >>>
> >>> public boolean reserve()
> >>> {
> >>>    return(m_lock.guard(() ->
> >>>    {
> >>>       if (m_count >= m_capacity)
> >>>          return(false);
> >>>
> >>>       m_count++;
> >>>
> >>>       return(true);
> >>>    }));
> >>> }
> >>>
> >>> All the aforementioned problems are no longer applicable.
> guard() takes
> >>> care of them.  The code is much clearer to understand since the
> >>> boilerplate locking code is gone.  It also might help JIT by reducing
> >>> the amount of cookie cutter code it has to optimize.
> >>>
> >>> Here are the method signatures of other methods which could
> be added to
> >>> the Lock interface.  The full code is available at
> >>> https://bugs.openjdk.java.net/browse/JDK-8025597.
> >>>
> >>>    public <T> T           guard(Callable<T> guarded) throws Exception
> >>>    public     void        guardInterruptibly(Runnable guarded) throws
> >>> InterruptedException
> >>>    public <T> T guardInterruptibly(Callable<T> guarded) throws
> >>> Exception, InterruptedException
> >>>    public     boolean     tryGuard(Runnable guarded)
> >>>    public <T> Optional<T> tryGuard(Callable<T> guarded)
> throws Exception
> >>>    public     boolean     tryGuard(Runnable guarded, long time,
> >>> TimeUnit unit) throws InterruptedException
> >>>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> >>> TimeUnit unit) throws Exception, InterruptedException
> >>>
> >>> What do you think?  Please ignore formatting and method names for the
> >>> moment.
> >>>
> >>> --
> >>> -Nathan
> >>>
> >>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
> > --
> > Dr Heinz M. Kabutz (PhD CompSci)
> > Author of "The Java(tm) Specialists' Newsletter"
> > Sun/Oracle Java Champion 2005-2013
> > JavaOne Rockstar Speaker 2012
> > http://www.javaspecialists.eu
> > Tel: +30 69 75 595 262
> > Skype: kabutz
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From oleksandr.otenko at oracle.com  Wed Oct  9 09:59:07 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 09 Oct 2013 14:59:07 +0100
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEEHKBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEEHKBAA.davidcholmes@aapt.net.au>
Message-ID: <5255612B.2010906@oracle.com>

On 09/10/2013 12:52, David Holmes wrote:
> Kirk Pepperdine wrote:
>> an inflation and an over write of the biased lock bits along with
>> the recording of an object identify hash that will prevent all
>> future biasings of that lock....
> No we're talking about the use of Lock implementations not synchronized. The
> allocation Heinz refers to is the Node to add the current thread to waiting
> list. But the allocation Brian refers to is that related to the Lambda.
>
> Anyway while I can understand the desire for automatic lock release (t-w-r
> is not the right mechanism though) I find the withLock approach to be
> contrary to good OO design where a class encapsulates the code and data for
It doesn't mean other designs are bad. It only means they possibly 
aren't OO designs.


> a given abstraction, as withLock requires that you put the code into a bunch
> of different objects that have to have access to the data of the real
> object. And all because try/finally is considered "error prone"?
No, all because we can reuse more than just a wrapper for try/finally - 
like we reuse the self-tuning heuristics at every synchronized() site by 
telling it what lock to use (functionality not part of lock object, and 
the data is not encapsulated) and what lamda to run (the expression in 
squiggly brackets).


Alex


>
> David
> -----
>
>> On 2013-10-09, at 6:39 AM, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu> wrote:
>>
>>> Brian, when the lock is contended, it will itself cause an allocation.
>>>
>>> On 08/10/2013, Brian Goetz <brian at briangoetz.com> wrote:
>>>> So, here's the definitive answer about why we haven't done this yet (it
>>>> was discussed by the 335 and 166 EGs.)
>>>>
>>>>  From an API perspective, improvements like these are obvious.  The code
>>>> is shorter, clearer, and less error-prone.  So it seems like a
>> no-brainer.
>>>> However, such an API would have a hidden performance cost, at least
>>>> until some VM work plays out.  Here's why.
>>>>
>>>> When you write a method like
>>>>
>>>>    void withLock(Runnable)
>>>>
>>>> the Runnable is going to have side-effects.  So its going to be a
>>>> capturing lambda -- one that captures variables from its scope:
>>>>
>>>>    withLock( () -> { counter++; } );  // counter is captured
>>>>
>>>> With the current implementation of lambda, evaluating (not invoking) a
>>>> capturing lambda expression will cause an allocation.  Whereas the
>>>> hand-unrolled version:
>>>>
>>>>    lock.lock();
>>>>    try { counter++; }
>>>>    finally { lock.unlock(); }
>>>>
>>>> does not.  The sort of things people do with locks are generally pretty
>>>> performance-sensitive, so such an API was deemed, at the current time,
>>>> to be an "attractive nuisance."
>>>>
>>>> However, we think it is worthwhile to invest in making such idioms
>>>> suitably performant so that we do not have to make these
>> tradeoffs.  The
>>>> missing piece here is intrinsification of the lambda capture;
>> with this,
>>>> existing optimizations (code motion, escape analysis, inlining, and
>>>> generalized box-unbox elimination) can eliminate the capture cost and
>>>> render this idiom free in most cases.  When we get there, we'll revisit
>>>> APIs like this.
>>>>
>>>> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>>>>> Here's an example of code using ReentrantLock.
>>>>>
>>>>> private final ReentrantLock m_lock = new ReentrantLock();
>>>>> private       int           m_count;
>>>>> private final int           m_capacity;
>>>>>
>>>>> public boolean reserve()
>>>>> {
>>>>>     m_lock.lock();
>>>>>
>>>>>     try
>>>>>     {
>>>>>        if (m_count >= m_capacity)
>>>>>           return(false);
>>>>>
>>>>>        m_count++;
>>>>>
>>>>>        return(true);
>>>>>     }
>>>>>     finally
>>>>>     {
>>>>>        m_lock.unlock();
>>>>>     }
>>>>> }
>>>>>
>>>>> There are several problems with this code.  1)  You have to
>> remember to
>>>>> call unlock().  2)  You have to put the unlock() in the finally block.
>>>>> 3)  The finally block can't have other exception throwing
>> constructs or
>>>>> the lock won't be released on some code paths.  4) The m_lock
>> reference
>>>>> shouldn't be allowed to change while a thread is executing inside
>>>>> reserve().
>>>>>
>>>>> After attending JavaOne and hearing about lambdas and default
>> methods in
>>>>> interfaces, I came up with an idea to make writing locked code less
>>>>> error prone.  The idea is to provide default methods in the Lock
>>>>> interface which would make writing the above code simpler and
>> less error
>>>>> prone.  Here's one such method.
>>>>>
>>>>> public void guard(Runnable guarded)
>>>>> {
>>>>>     lock();
>>>>>
>>>>>     try
>>>>>     {
>>>>>        guarded.run();
>>>>>     }
>>>>>     finally
>>>>>     {
>>>>>        unlock();
>>>>>     }
>>>>> }
>>>>>
>>>>> With the guard() method available, the reserve() method can
>> be rewritten
>>>>> in JDK 8 as such.
>>>>>
>>>>> public boolean reserve()
>>>>> {
>>>>>     return(m_lock.guard(() ->
>>>>>     {
>>>>>        if (m_count >= m_capacity)
>>>>>           return(false);
>>>>>
>>>>>        m_count++;
>>>>>
>>>>>        return(true);
>>>>>     }));
>>>>> }
>>>>>
>>>>> All the aforementioned problems are no longer applicable.
>> guard() takes
>>>>> care of them.  The code is much clearer to understand since the
>>>>> boilerplate locking code is gone.  It also might help JIT by reducing
>>>>> the amount of cookie cutter code it has to optimize.
>>>>>
>>>>> Here are the method signatures of other methods which could
>> be added to
>>>>> the Lock interface.  The full code is available at
>>>>> https://bugs.openjdk.java.net/browse/JDK-8025597.
>>>>>
>>>>>     public <T> T           guard(Callable<T> guarded) throws Exception
>>>>>     public     void        guardInterruptibly(Runnable guarded) throws
>>>>> InterruptedException
>>>>>     public <T> T guardInterruptibly(Callable<T> guarded) throws
>>>>> Exception, InterruptedException
>>>>>     public     boolean     tryGuard(Runnable guarded)
>>>>>     public <T> Optional<T> tryGuard(Callable<T> guarded)
>> throws Exception
>>>>>     public     boolean     tryGuard(Runnable guarded, long time,
>>>>> TimeUnit unit) throws InterruptedException
>>>>>     public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
>>>>> TimeUnit unit) throws Exception, InterruptedException
>>>>>
>>>>> What do you think?  Please ignore formatting and method names for the
>>>>> moment.
>>>>>
>>>>> --
>>>>> -Nathan
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>> --
>>> Dr Heinz M. Kabutz (PhD CompSci)
>>> Author of "The Java(tm) Specialists' Newsletter"
>>> Sun/Oracle Java Champion 2005-2013
>>> JavaOne Rockstar Speaker 2012
>>> http://www.javaspecialists.eu
>>> Tel: +30 69 75 595 262
>>> Skype: kabutz
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From ron.pressler at gmail.com  Wed Oct  9 12:30:41 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Wed, 9 Oct 2013 18:30:41 +0200
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEEHKBAA.davidcholmes@aapt.net.au>
References: <D472E21E-2932-4789-9887-18EC2487FB74@kodewerk.com>
	<NFBBKALFDCPFIDBNKAPCAEEHKBAA.davidcholmes@aapt.net.au>
Message-ID: <CABg6-qi3yLDEJ45UHbq+9djsWTNDQNK+RDQSmi7cY+nKN_023g@mail.gmail.com>

On Wed, Oct 9, 2013 at 2:52 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

>
> ... I find the withLock approach to be
> contrary to good OO design where a class encapsulates the code and data for
> a given abstraction, as withLock requires that you put the code into a
> bunch
> of different objects that have to have access to the data of the real
> object.
>
>
I don't think these methods are absolutely required, and I think that TWR
would be a better approach (given a few modifications to the TWR syntax),
but after all, the whole idea of lambdas is taken from functional
programming ? not OO, so the APIs using them could (should?) adopt a good
functional style rather than an OO style. On the other hand, locks, by
definition, deal with mutation which isn't very functional to begin with...


>
> > On 2013-10-09, at 6:39 AM, Dr Heinz M. Kabutz
> > <heinz at javaspecialists.eu> wrote:
> >
> > > Brian, when the lock is contended, it will itself cause an allocation.
> > >
> > > On 08/10/2013, Brian Goetz <brian at briangoetz.com> wrote:
> > >> So, here's the definitive answer about why we haven't done this yet
> (it
> > >> was discussed by the 335 and 166 EGs.)
> > >>
> > >> From an API perspective, improvements like these are obvious.  The
> code
> > >> is shorter, clearer, and less error-prone.  So it seems like a
> > no-brainer.
> > >>
> > >> However, such an API would have a hidden performance cost, at least
> > >> until some VM work plays out.  Here's why.
> > >>
> > >> When you write a method like
> > >>
> > >>   void withLock(Runnable)
> > >>
> > >> the Runnable is going to have side-effects.  So its going to be a
> > >> capturing lambda -- one that captures variables from its scope:
> > >>
> > >>   withLock( () -> { counter++; } );  // counter is captured
> > >>
> > >> With the current implementation of lambda, evaluating (not invoking) a
> > >> capturing lambda expression will cause an allocation.  Whereas the
> > >> hand-unrolled version:
> > >>
> > >>   lock.lock();
> > >>   try { counter++; }
> > >>   finally { lock.unlock(); }
> > >>
> > >> does not.  The sort of things people do with locks are generally
> pretty
> > >> performance-sensitive, so such an API was deemed, at the current time,
> > >> to be an "attractive nuisance."
> > >>
> > >> However, we think it is worthwhile to invest in making such idioms
> > >> suitably performant so that we do not have to make these
> > tradeoffs.  The
> > >> missing piece here is intrinsification of the lambda capture;
> > with this,
> > >> existing optimizations (code motion, escape analysis, inlining, and
> > >> generalized box-unbox elimination) can eliminate the capture cost and
> > >> render this idiom free in most cases.  When we get there, we'll
> revisit
> > >> APIs like this.
> > >>
> > >> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
> > >>> Here's an example of code using ReentrantLock.
> > >>>
> > >>> private final ReentrantLock m_lock = new ReentrantLock();
> > >>> private       int           m_count;
> > >>> private final int           m_capacity;
> > >>>
> > >>> public boolean reserve()
> > >>> {
> > >>>    m_lock.lock();
> > >>>
> > >>>    try
> > >>>    {
> > >>>       if (m_count >= m_capacity)
> > >>>          return(false);
> > >>>
> > >>>       m_count++;
> > >>>
> > >>>       return(true);
> > >>>    }
> > >>>    finally
> > >>>    {
> > >>>       m_lock.unlock();
> > >>>    }
> > >>> }
> > >>>
> > >>> There are several problems with this code.  1)  You have to
> > remember to
> > >>> call unlock().  2)  You have to put the unlock() in the finally
> block.
> > >>> 3)  The finally block can't have other exception throwing
> > constructs or
> > >>> the lock won't be released on some code paths.  4) The m_lock
> > reference
> > >>> shouldn't be allowed to change while a thread is executing inside
> > >>> reserve().
> > >>>
> > >>> After attending JavaOne and hearing about lambdas and default
> > methods in
> > >>> interfaces, I came up with an idea to make writing locked code less
> > >>> error prone.  The idea is to provide default methods in the Lock
> > >>> interface which would make writing the above code simpler and
> > less error
> > >>> prone.  Here's one such method.
> > >>>
> > >>> public void guard(Runnable guarded)
> > >>> {
> > >>>    lock();
> > >>>
> > >>>    try
> > >>>    {
> > >>>       guarded.run();
> > >>>    }
> > >>>    finally
> > >>>    {
> > >>>       unlock();
> > >>>    }
> > >>> }
> > >>>
> > >>> With the guard() method available, the reserve() method can
> > be rewritten
> > >>> in JDK 8 as such.
> > >>>
> > >>> public boolean reserve()
> > >>> {
> > >>>    return(m_lock.guard(() ->
> > >>>    {
> > >>>       if (m_count >= m_capacity)
> > >>>          return(false);
> > >>>
> > >>>       m_count++;
> > >>>
> > >>>       return(true);
> > >>>    }));
> > >>> }
> > >>>
> > >>> All the aforementioned problems are no longer applicable.
> > guard() takes
> > >>> care of them.  The code is much clearer to understand since the
> > >>> boilerplate locking code is gone.  It also might help JIT by reducing
> > >>> the amount of cookie cutter code it has to optimize.
> > >>>
> > >>> Here are the method signatures of other methods which could
> > be added to
> > >>> the Lock interface.  The full code is available at
> > >>> https://bugs.openjdk.java.net/browse/JDK-8025597.
> > >>>
> > >>>    public <T> T           guard(Callable<T> guarded) throws Exception
> > >>>    public     void        guardInterruptibly(Runnable guarded) throws
> > >>> InterruptedException
> > >>>    public <T> T guardInterruptibly(Callable<T> guarded) throws
> > >>> Exception, InterruptedException
> > >>>    public     boolean     tryGuard(Runnable guarded)
> > >>>    public <T> Optional<T> tryGuard(Callable<T> guarded)
> > throws Exception
> > >>>    public     boolean     tryGuard(Runnable guarded, long time,
> > >>> TimeUnit unit) throws InterruptedException
> > >>>    public <T> Optional<T> tryGuard(Callable<T> guarded, long time,
> > >>> TimeUnit unit) throws Exception, InterruptedException
> > >>>
> > >>> What do you think?  Please ignore formatting and method names for the
> > >>> moment.
> > >>>
> > >>> --
> > >>> -Nathan
> > >>>
> > >>>
> > >>>
> > >>> _______________________________________________
> > >>> Concurrency-interest mailing list
> > >>> Concurrency-interest at cs.oswego.edu
> > >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >>>
> > >> _______________________________________________
> > >> Concurrency-interest mailing list
> > >> Concurrency-interest at cs.oswego.edu
> > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >>
> > >
> > >
> > > --
> > > Dr Heinz M. Kabutz (PhD CompSci)
> > > Author of "The Java(tm) Specialists' Newsletter"
> > > Sun/Oracle Java Champion 2005-2013
> > > JavaOne Rockstar Speaker 2012
> > > http://www.javaspecialists.eu
> > > Tel: +30 69 75 595 262
> > > Skype: kabutz
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131009/933ca29a/attachment.html>

From oleksandr.otenko at oracle.com  Wed Oct  9 12:49:56 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 09 Oct 2013 17:49:56 +0100
Subject: [concurrency-interest] Default Functions for Lock Interface
In-Reply-To: <CABg6-qi3yLDEJ45UHbq+9djsWTNDQNK+RDQSmi7cY+nKN_023g@mail.gmail.com>
References: <D472E21E-2932-4789-9887-18EC2487FB74@kodewerk.com>
	<NFBBKALFDCPFIDBNKAPCAEEHKBAA.davidcholmes@aapt.net.au>
	<CABg6-qi3yLDEJ45UHbq+9djsWTNDQNK+RDQSmi7cY+nKN_023g@mail.gmail.com>
Message-ID: <52558934.2080306@oracle.com>

Lisp is mutable.

Locks are a flip side of continuations.

Alex

On 09/10/2013 17:30, Ron Pressler wrote:
> On Wed, Oct 9, 2013 at 2:52 PM, David Holmes <davidcholmes at aapt.net.au 
> <mailto:davidcholmes at aapt.net.au>> wrote:
>
>
>     ... I find the withLock approach to be
>     contrary to good OO design where a class encapsulates the code and
>     data for
>     a given abstraction, as withLock requires that you put the code
>     into a bunch
>     of different objects that have to have access to the data of the real
>     object.
>
>
> I don't think these methods are absolutely required, and I think that 
> TWR would be a better approach (given a few modifications to the TWR 
> syntax), but after all, the whole idea of lambdas is taken from 
> functional programming -- not OO, so the APIs using them could 
> (should?) adopt a good functional style rather than an OO style. On 
> the other hand, locks, by definition, deal with mutation which isn't 
> very functional to begin with...
>
>
>     > On 2013-10-09, at 6:39 AM, Dr Heinz M. Kabutz
>     > <heinz at javaspecialists.eu <mailto:heinz at javaspecialists.eu>> wrote:
>     >
>     > > Brian, when the lock is contended, it will itself cause an
>     allocation.
>     > >
>     > > On 08/10/2013, Brian Goetz <brian at briangoetz.com
>     <mailto:brian at briangoetz.com>> wrote:
>     > >> So, here's the definitive answer about why we haven't done
>     this yet (it
>     > >> was discussed by the 335 and 166 EGs.)
>     > >>
>     > >> From an API perspective, improvements like these are obvious.
>      The code
>     > >> is shorter, clearer, and less error-prone.  So it seems like a
>     > no-brainer.
>     > >>
>     > >> However, such an API would have a hidden performance cost, at
>     least
>     > >> until some VM work plays out.  Here's why.
>     > >>
>     > >> When you write a method like
>     > >>
>     > >>   void withLock(Runnable)
>     > >>
>     > >> the Runnable is going to have side-effects.  So its going to be a
>     > >> capturing lambda -- one that captures variables from its scope:
>     > >>
>     > >>   withLock( () -> { counter++; } );  // counter is captured
>     > >>
>     > >> With the current implementation of lambda, evaluating (not
>     invoking) a
>     > >> capturing lambda expression will cause an allocation.
>      Whereas the
>     > >> hand-unrolled version:
>     > >>
>     > >>   lock.lock();
>     > >>   try { counter++; }
>     > >>   finally { lock.unlock(); }
>     > >>
>     > >> does not.  The sort of things people do with locks are
>     generally pretty
>     > >> performance-sensitive, so such an API was deemed, at the
>     current time,
>     > >> to be an "attractive nuisance."
>     > >>
>     > >> However, we think it is worthwhile to invest in making such
>     idioms
>     > >> suitably performant so that we do not have to make these
>     > tradeoffs.  The
>     > >> missing piece here is intrinsification of the lambda capture;
>     > with this,
>     > >> existing optimizations (code motion, escape analysis,
>     inlining, and
>     > >> generalized box-unbox elimination) can eliminate the capture
>     cost and
>     > >> render this idiom free in most cases.  When we get there,
>     we'll revisit
>     > >> APIs like this.
>     > >>
>     > >> On 10/1/2013 1:24 PM, Nathan Reynolds wrote:
>     > >>> Here's an example of code using ReentrantLock.
>     > >>>
>     > >>> private final ReentrantLock m_lock = new ReentrantLock();
>     > >>> private       int           m_count;
>     > >>> private final int m_capacity;
>     > >>>
>     > >>> public boolean reserve()
>     > >>> {
>     > >>>    m_lock.lock();
>     > >>>
>     > >>>    try
>     > >>>    {
>     > >>>       if (m_count >= m_capacity)
>     > >>>          return(false);
>     > >>>
>     > >>>       m_count++;
>     > >>>
>     > >>>       return(true);
>     > >>>    }
>     > >>>    finally
>     > >>>    {
>     > >>>       m_lock.unlock();
>     > >>>    }
>     > >>> }
>     > >>>
>     > >>> There are several problems with this code.  1)  You have to
>     > remember to
>     > >>> call unlock().  2)  You have to put the unlock() in the
>     finally block.
>     > >>> 3)  The finally block can't have other exception throwing
>     > constructs or
>     > >>> the lock won't be released on some code paths.  4) The m_lock
>     > reference
>     > >>> shouldn't be allowed to change while a thread is executing
>     inside
>     > >>> reserve().
>     > >>>
>     > >>> After attending JavaOne and hearing about lambdas and default
>     > methods in
>     > >>> interfaces, I came up with an idea to make writing locked
>     code less
>     > >>> error prone.  The idea is to provide default methods in the Lock
>     > >>> interface which would make writing the above code simpler and
>     > less error
>     > >>> prone.  Here's one such method.
>     > >>>
>     > >>> public void guard(Runnable guarded)
>     > >>> {
>     > >>>    lock();
>     > >>>
>     > >>>    try
>     > >>>    {
>     > >>>       guarded.run();
>     > >>>    }
>     > >>>    finally
>     > >>>    {
>     > >>>       unlock();
>     > >>>    }
>     > >>> }
>     > >>>
>     > >>> With the guard() method available, the reserve() method can
>     > be rewritten
>     > >>> in JDK 8 as such.
>     > >>>
>     > >>> public boolean reserve()
>     > >>> {
>     > >>>    return(m_lock.guard(() ->
>     > >>>    {
>     > >>>       if (m_count >= m_capacity)
>     > >>>          return(false);
>     > >>>
>     > >>>       m_count++;
>     > >>>
>     > >>>       return(true);
>     > >>>    }));
>     > >>> }
>     > >>>
>     > >>> All the aforementioned problems are no longer applicable.
>     > guard() takes
>     > >>> care of them.  The code is much clearer to understand since the
>     > >>> boilerplate locking code is gone.  It also might help JIT by
>     reducing
>     > >>> the amount of cookie cutter code it has to optimize.
>     > >>>
>     > >>> Here are the method signatures of other methods which could
>     > be added to
>     > >>> the Lock interface.  The full code is available at
>     > >>> https://bugs.openjdk.java.net/browse/JDK-8025597.
>     > >>>
>     > >>>    public <T> T guard(Callable<T> guarded) throws Exception
>     > >>>    public     void  guardInterruptibly(Runnable guarded) throws
>     > >>> InterruptedException
>     > >>>    public <T> T guardInterruptibly(Callable<T> guarded) throws
>     > >>> Exception, InterruptedException
>     > >>>    public     boolean tryGuard(Runnable guarded)
>     > >>>    public <T> Optional<T> tryGuard(Callable<T> guarded)
>     > throws Exception
>     > >>>    public     boolean tryGuard(Runnable guarded, long time,
>     > >>> TimeUnit unit) throws InterruptedException
>     > >>>    public <T> Optional<T> tryGuard(Callable<T> guarded, long
>     time,
>     > >>> TimeUnit unit) throws Exception, InterruptedException
>     > >>>
>     > >>> What do you think?  Please ignore formatting and method
>     names for the
>     > >>> moment.
>     > >>>
>     > >>> --
>     > >>> -Nathan
>     > >>>
>     > >>>
>     > >>>
>     > >>> _______________________________________________
>     > >>> Concurrency-interest mailing list
>     > >>> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     > >>>
>     > >> _______________________________________________
>     > >> Concurrency-interest mailing list
>     > >> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     > >>
>     > >
>     > >
>     > > --
>     > > Dr Heinz M. Kabutz (PhD CompSci)
>     > > Author of "The Java(tm) Specialists' Newsletter"
>     > > Sun/Oracle Java Champion 2005-2013
>     > > JavaOne Rockstar Speaker 2012
>     > > http://www.javaspecialists.eu
>     > > Tel: +30 69 75 595 262 <tel:%2B30%2069%2075%20595%20262>
>     > > Skype: kabutz
>     > > _______________________________________________
>     > > Concurrency-interest mailing list
>     > > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>     >
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131009/455440be/attachment-0001.html>

From nathan.reynolds at oracle.com  Mon Oct 14 13:09:13 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 14 Oct 2013 10:09:13 -0700
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
Message-ID: <525C2539.5030301@oracle.com>

Here's a minor refinement.

public void lock ()
{
    while lock.getAndSet(true) {}
}

compareAndSet() is more expensive.  The CPU has to load the value, do a 
comparison and then store the new value based on the comparison.  The 
comparison adds latency.  getAndSet() can do a load followed by a store.

The JDK code implements getAndSet() as a CAS loop.  If I remember right, 
HotSpot 7u10 has intrinsics for most of the atomic methods so that more 
efficient instructions are used.  For example, it uses lock xchg, lock 
inc and lock dec instructions on x86.

-Nathan

On 10/6/2013 5:17 PM, Andy Nuss wrote:
> Hi,
>
> My idea is:
>
> public class SimpleLock {
>       private volatile AtomicBoolean lock = new AtomicBoolean();
>
>       public void lock ()
>       {
>              while !lock.compareAndSet(false, true) {}
>       }
>
>       public void unlock ()
>       {
> lock.set(false);
>              this.lock = lock;
>       }
> }
>
> Obviously this is a simple lockfree locker.  The question is whether 
> this locker also ensures the unlock() publishes all non-volatile 
> changes made to a complex data structure used within the critical 
> section to the next call to lock()?  If not, how can I fix this?
>
> Andy
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/49144bc1/attachment.html>

From kedar.mhaswade at gmail.com  Mon Oct 14 14:11:23 2013
From: kedar.mhaswade at gmail.com (kedar mhaswade)
Date: Mon, 14 Oct 2013 11:11:23 -0700
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <525C2539.5030301@oracle.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
Message-ID: <CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>

I read in the JDK source code that getAndSet calls compareAndSet in a loop.

If you have to write a lock of your own, isn't the TTASLock suggested in
the Art of Multiprocessor programming even better (e.g. it further reduces
the bus traffic)?

public void lock() {
  while(true) {
    while (lock.get()) {} //spin while true, but we're only reading the
value
    //lock is free here
    if (lock.compareAndSet(false, true))
      return; //we locked successfully, return
   }
}


On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds <
nathan.reynolds at oracle.com> wrote:

>  Here's a minor refinement.
>
> public void lock ()
> {
>    while lock.getAndSet(true) {}
>  }
>
> compareAndSet() is more expensive.  The CPU has to load the value, do a
> comparison and then store the new value based on the comparison.  The
> comparison adds latency.  getAndSet() can do a load followed by a store.
>
> The JDK code implements getAndSet() as a CAS loop.  If I remember right,
> HotSpot 7u10 has intrinsics for most of the atomic methods so that more
> efficient instructions are used.  For example, it uses lock xchg, lock inc
> and lock dec instructions on x86.
>
> -Nathan
>
> On 10/6/2013 5:17 PM, Andy Nuss wrote:
>
>  Hi,
>
>  My idea is:
>
>  public class SimpleLock {
>       private volatile AtomicBoolean lock = new AtomicBoolean();
>
>        public void lock ()
>       {
>              while !lock.compareAndSet(false, true) {}
>        }
>
>        public void unlock ()
>       {
>              lock.set(false);
>              this.lock = lock;
>        }
>  }
>
>  Obviously this is a simple lockfree locker.  The question is whether
> this locker also ensures the unlock() publishes all non-volatile changes
> made to a complex data structure used within the critical section to the
> next call to lock()?  If not, how can I fix this?
>
>  Andy
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/10e12cc1/attachment.html>

From nathan.reynolds at oracle.com  Mon Oct 14 14:29:32 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 14 Oct 2013 11:29:32 -0700
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
Message-ID: <525C380C.2070609@oracle.com>

On x86 and a few other platforms, JIT has an intrinsic for this method.  
The intrinsic gets rid of the compareAndSet() and the loop.  On x86, it 
replaces the entire method with "lock xchg" and maybe a few more support 
instructions.

 > If you have to write a lock of your own, isn't the TTASLock suggested 
in the Art of Multiprocessor programming even better (e.g. it further 
reduces the bus traffic)?

Test-and-test-and-set lock will enhance using getAndSet() even further.  
Every time a core has to write to a cache line, the cache line has to 
switch to the exclusive state.  This requires sending an invalidation 
message to all the other cores and processors in the machine.  If all of 
the cores on the machine are trying to execute getAndSet(), then there 
is going to be a lot of bus traffic to move the cache line from one core 
to another and then invalidate the cache line in all other cores.

With test-and-test-and-set, all of the waiting cores keep the cache line 
in the shared state.  When the owner thread wants to release the lock, 
it has to invalidate the cache line to allow its copy to enter the 
exclusive state.  It then performs the write to release the lock and 
then the rest of the cores in the system fight to read the cache line 
and then change it to the exclusive state.

test-and-test-and-set is better.  Here's test-and-test-and-set using 
getAndSet().  It is still recommend to use getAndSet() instead of 
compareAndSet() to improve latency (i.e. get rid of the comparison).

public void lock ()
{
while (true)
    {
       while lock.get() {}

       if !lock.getAndSet(true)
          break;
    }
}

-Nathan

On 10/14/2013 11:11 AM, kedar mhaswade wrote:
> I read in the JDK source code that getAndSet calls compareAndSet in a 
> loop.
>
> If you have to write a lock of your own, isn't the TTASLock suggested 
> in the Art of Multiprocessor programming even better (e.g. it further 
> reduces the bus traffic)?
>
> public void lock() {
>   while(true) {
>     while (lock.get()) {} //spin while true, but we're only reading 
> the value
>     //lock is free here
>     if (lock.compareAndSet(false, true))
>       return; //we locked successfully, return
>    }
> }
>
>
> On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     Here's a minor refinement.
>
>     public void lock ()
>     {
>     while lock.getAndSet(true) {}
>     }
>
>     compareAndSet() is more expensive.  The CPU has to load the value,
>     do a comparison and then store the new value based on the
>     comparison.  The comparison adds latency. getAndSet() can do a
>     load followed by a store.
>
>     The JDK code implements getAndSet() as a CAS loop.  If I remember
>     right, HotSpot 7u10 has intrinsics for most of the atomic methods
>     so that more efficient instructions are used.  For example, it
>     uses lock xchg, lock inc and lock dec instructions on x86.
>
>     -Nathan
>
>     On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>     Hi,
>>
>>     My idea is:
>>
>>     public class SimpleLock {
>>           private volatile AtomicBoolean lock = new AtomicBoolean();
>>
>>           public void lock ()
>>           {
>>     while !lock.compareAndSet(false, true) {}
>>           }
>>
>>           public void unlock ()
>>           {
>>     lock.set(false);
>>     this.lock = lock;
>>           }
>>     }
>>
>>     Obviously this is a simple lockfree locker.  The question is
>>     whether this locker also ensures the unlock() publishes all
>>     non-volatile changes made to a complex data structure used within
>>     the critical section to the next call to lock()?  If not, how can
>>     I fix this?
>>
>>     Andy
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/5b411eaf/attachment-0001.html>

From ron.pressler at gmail.com  Mon Oct 14 18:16:18 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Tue, 15 Oct 2013 00:16:18 +0200
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <525C380C.2070609@oracle.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
	<525C380C.2070609@oracle.com>
Message-ID: <CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>

On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  On x86 and a few other platforms, JIT has an intrinsic for this method.
> The intrinsic gets rid of the compareAndSet() and the loop.  On x86, it
> replaces the entire method with "lock xchg" and maybe a few more support
> instructions.
>

There is an intrinsic directly on the atomic classes without a matching
method in Unsafe?



On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>
>  I read in the JDK source code that getAndSet calls compareAndSet in a
> loop.
>
>  If you have to write a lock of your own, isn't the TTASLock suggested in
> the Art of Multiprocessor programming even better (e.g. it further reduces
> the bus traffic)?
>
>  public void lock() {
>   while(true) {
>     while (lock.get()) {} //spin while true, but we're only reading the
> value
>     //lock is free here
>      if (lock.compareAndSet(false, true))
>       return; //we locked successfully, return
>    }
> }
>
>
> On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds <
> nathan.reynolds at oracle.com> wrote:
>
>>  Here's a minor refinement.
>>
>> public void lock ()
>> {
>>    while lock.getAndSet(true) {}
>>  }
>>
>> compareAndSet() is more expensive.  The CPU has to load the value, do a
>> comparison and then store the new value based on the comparison.  The
>> comparison adds latency.  getAndSet() can do a load followed by a store.
>>
>> The JDK code implements getAndSet() as a CAS loop.  If I remember right,
>> HotSpot 7u10 has intrinsics for most of the atomic methods so that more
>> efficient instructions are used.  For example, it uses lock xchg, lock inc
>> and lock dec instructions on x86.
>>
>> -Nathan
>>
>>   On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>
>>   Hi,
>>
>>  My idea is:
>>
>>  public class SimpleLock {
>>       private volatile AtomicBoolean lock = new AtomicBoolean();
>>
>>        public void lock ()
>>       {
>>              while !lock.compareAndSet(false, true) {}
>>        }
>>
>>        public void unlock ()
>>       {
>>              lock.set(false);
>>              this.lock = lock;
>>        }
>>  }
>>
>>  Obviously this is a simple lockfree locker.  The question is whether
>> this locker also ensures the unlock() publishes all non-volatile changes
>> made to a complex data structure used within the critical section to the
>> next call to lock()?  If not, how can I fix this?
>>
>>  Andy
>>
>>
>>   _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131015/098cdf05/attachment.html>

From nathan.reynolds at oracle.com  Mon Oct 14 19:03:36 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 14 Oct 2013 16:03:36 -0700
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
	<525C380C.2070609@oracle.com>
	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
Message-ID: <525C7848.4070501@oracle.com>

Sorry.  I am not being very precise. If I understand the bugs right, 
then there are matching methods in Unsafe.  See getAndAddInt(), 
getAndAddLong(), getAndSetInt(), getAndSetLong() and getAndSetObject() 
in 
http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java

In case you wish to consult the actual bugs...

https://bugs.openjdk.java.net/browse/JDK-7023898
https://bugs.openjdk.java.net/browse/JDK-8004330
https://bugs.openjdk.java.net/browse/JDK-8005373
https://bugs.openjdk.java.net/browse/JDK-8005966

-Nathan

On 10/14/2013 3:16 PM, Ron Pressler wrote:
>
> On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     On x86 and a few other platforms, JIT has an intrinsic for this
>     method.  The intrinsic gets rid of the compareAndSet() and the
>     loop.  On x86, it replaces the entire method with "lock xchg" and
>     maybe a few more support instructions.
>
>
> There is an intrinsic directly on the atomic classes without a 
> matching method in Unsafe?
>
>
>
>     On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>     I read in the JDK source code that getAndSet calls compareAndSet
>>     in a loop.
>>
>>     If you have to write a lock of your own, isn't the TTASLock
>>     suggested in the Art of Multiprocessor programming even better
>>     (e.g. it further reduces the bus traffic)?
>>
>>     public void lock() {
>>       while(true) {
>>         while (lock.get()) {} //spin while true, but we're only
>>     reading the value
>>         //lock is free here
>>         if (lock.compareAndSet(false, true))
>>           return; //we locked successfully, return
>>        }
>>     }
>>
>>
>>     On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds
>>     <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>>
>>     wrote:
>>
>>         Here's a minor refinement.
>>
>>         public void lock ()
>>         {
>>         while lock.getAndSet(true) {}
>>         }
>>
>>         compareAndSet() is more expensive.  The CPU has to load the
>>         value, do a comparison and then store the new value based on
>>         the comparison.  The comparison adds latency.  getAndSet()
>>         can do a load followed by a store.
>>
>>         The JDK code implements getAndSet() as a CAS loop.  If I
>>         remember right, HotSpot 7u10 has intrinsics for most of the
>>         atomic methods so that more efficient instructions are used. 
>>         For example, it uses lock xchg, lock inc and lock dec
>>         instructions on x86.
>>
>>         -Nathan
>>
>>         On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>         Hi,
>>>
>>>         My idea is:
>>>
>>>         public class SimpleLock {
>>>         private volatile AtomicBoolean lock = new AtomicBoolean();
>>>
>>>         public void lock ()
>>>         {
>>>         while !lock.compareAndSet(false, true) {}
>>>         }
>>>
>>>         public void unlock ()
>>>         {
>>>         lock.set(false);
>>>         this.lock = lock;
>>>         }
>>>         }
>>>
>>>         Obviously this is a simple lockfree locker.  The question is
>>>         whether this locker also ensures the unlock() publishes all
>>>         non-volatile changes made to a complex data structure used
>>>         within the critical section to the next call to lock()?  If
>>>         not, how can I fix this?
>>>
>>>         Andy
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/7ba13c83/attachment-0001.html>

From andrew_nuss at yahoo.com  Mon Oct 14 19:20:17 2013
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 14 Oct 2013 16:20:17 -0700 (PDT)
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <525C7848.4070501@oracle.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>	<525C2539.5030301@oracle.com>	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>	<525C380C.2070609@oracle.com>	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
	<525C7848.4070501@oracle.com>
Message-ID: <1381792817.34577.YahooMailNeo@web141106.mail.bf1.yahoo.com>

Is it true that this design pattern and choice for getAndSet is only appropriate for AtomicBoolean, rather than atomics that can have 2 or more locking states?




On Monday, October 14, 2013 4:11 PM, Nathan Reynolds <nathan.reynolds at oracle.com> wrote:
 
Sorry.? I am not being very precise.? If I understand the bugs right, then there are matching methods in Unsafe.? See getAndAddInt(), getAndAddLong(), getAndSetInt(), getAndSetLong() and getAndSetObject() in http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java

In case you wish to consult the actual bugs...

https://bugs.openjdk.java.net/browse/JDK-7023898
https://bugs.openjdk.java.net/browse/JDK-8004330
https://bugs.openjdk.java.net/browse/JDK-8005373
https://bugs.openjdk.java.net/browse/JDK-8005966

-Nathan
On 10/14/2013 3:16 PM, Ron Pressler wrote:


>
>On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds <nathan.reynolds at oracle.com> wrote:
>
>On x86 and a few other platforms, JIT has an intrinsic for this method.? The intrinsic gets rid of the compareAndSet() and the loop.? On x86, it replaces the entire method with "lock xchg" and maybe a few more support instructions.
>
>
>There is an intrinsic directly on the atomic classes without a matching method in Unsafe?
>
>
>
>
>
>
>On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>
>>I read in the JDK source code that getAndSet calls compareAndSet in a loop.
>>>
>>>
If you have to write a lock of your own, isn't the TTASLock suggested in the Art of Multiprocessor programming even better (e.g. it further reduces the bus traffic)? 
>>>
>>>
>>>public void lock() {
>>>? while(true) {
>>>? ? while (lock.get()) {} //spin while true, but we're only reading the value
>>>? ? //lock is free here
>>>? ? if (lock.compareAndSet(false, true))
>>>? ? ? return; //we locked successfully, return
>>>? ?}
>>>}
>>>
>>>
>>>
>>>On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds <nathan.reynolds at oracle.com> wrote:
>>>
>>>Here's a minor refinement.
>>>>
>>>>
>>>>public void lock ()
>>>>{
>>>>?? while lock.getAndSet(true) {}
>>>>
>>>>}
>>>>compareAndSet() is more expensive.? The
                                CPU has to load the value, do a
                                comparison and then store the new value
                                based on the comparison.? The comparison
                                adds latency.? getAndSet() can do a load
                                followed by a store.
>>>>
>>>>The JDK code implements getAndSet() as a
                                CAS loop.? If I remember right, HotSpot
                                7u10 has intrinsics for most of the
                                atomic methods so that more efficient
                                instructions are used.? For example, it
                                uses lock xchg, lock inc and lock dec
                                instructions on x86.
>>>>
>>>>-Nathan
>>>>On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>>
>>>>Hi,
>>>>>
>>>>>
>>>>>My idea is:
>>>>>
>>>>>
>>>>>public class SimpleLock {
>>>>>????? private volatile AtomicBoolean lock = new AtomicBoolean();
>>>>>
>>>>>
>>>>>????? public void lock ()
>>>>>????? {
>>>>>???????????? while !lock.compareAndSet(false, true) {}
>>>>>
>>>>>????? }
>>>>>
>>>>>
>>>>>????? public void unlock ()
>>>>>????? {
>>>>>???????????? lock.set(false);
>>>>>???????????? this.lock = lock;
>>>>>
>>>>>????? }
>>>>>
>>>>>}
>>>>>
>>>>>
>>>>>Obviously this is a simple lockfree locker.? The question is whether this locker also ensures the unlock() publishes all non-volatile changes made to a complex data structure used within the critical section to the next call to lock()?? If not, how can I fix this?
>>>>>
>>>>>
>>>>>Andy
>>>>>
>>>>>
>>>>>_______________________________________________
Concurrency-interest mailing list Concurrency-interest at cs.oswego.edu http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
>>>>
>>>>_______________________________________________
>>>>Concurrency-interest mailing list
>>>>Concurrency-interest at cs.oswego.edu
>>>>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>
>>
>>_______________________________________________
>>Concurrency-interest mailing list
>>Concurrency-interest at cs.oswego.edu
>>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/b77fd51b/attachment.html>

From ron.pressler at gmail.com  Mon Oct 14 19:48:10 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Tue, 15 Oct 2013 01:48:10 +0200
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <525C7848.4070501@oracle.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
	<525C380C.2070609@oracle.com>
	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
	<525C7848.4070501@oracle.com>
Message-ID: <CABg6-qjbALLpPMtMT+cWS4W343hWNrVAV2gYxbcQ10Gdor_j_A@mail.gmail.com>

Oh, in JDK 8! That's why I couldn't find them.

Also, have you profiled the TTAS pattern? Because I don't know how CAS is
implemented in terms of MESI/MOESI (whatever Intel is using), but I know
that Doug always says that an uncontended CAS is really cheap nowadays, and
if the lock is heavily contended I'm not sure the test before the CAS would
help at all; it seems it might even hurt a little.


On Tue, Oct 15, 2013 at 2:03 AM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  Sorry.  I am not being very precise.  If I understand the bugs right,
> then there are matching methods in Unsafe.  See getAndAddInt(),
> getAndAddLong(), getAndSetInt(), getAndSetLong() and getAndSetObject() in
> http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java
>
> In case you wish to consult the actual bugs...
>
> https://bugs.openjdk.java.net/browse/JDK-7023898
> https://bugs.openjdk.java.net/browse/JDK-8004330
> https://bugs.openjdk.java.net/browse/JDK-8005373
> https://bugs.openjdk.java.net/browse/JDK-8005966
>
> -Nathan
>
> On 10/14/2013 3:16 PM, Ron Pressler wrote:
>
>
>  On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds <
> nathan.reynolds at oracle.com> wrote:
>
>>  On x86 and a few other platforms, JIT has an intrinsic for this
>> method.  The intrinsic gets rid of the compareAndSet() and the loop.  On
>> x86, it replaces the entire method with "lock xchg" and maybe a few more
>> support instructions.
>>
>
>  There is an intrinsic directly on the atomic classes without a matching
> method in Unsafe?
>
>
>
>    On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>
>>  I read in the JDK source code that getAndSet calls compareAndSet in a
>> loop.
>>
>>  If you have to write a lock of your own, isn't the TTASLock suggested in
>> the Art of Multiprocessor programming even better (e.g. it further reduces
>> the bus traffic)?
>>
>>  public void lock() {
>>   while(true) {
>>     while (lock.get()) {} //spin while true, but we're only reading the
>> value
>>     //lock is free here
>>      if (lock.compareAndSet(false, true))
>>       return; //we locked successfully, return
>>    }
>> }
>>
>>
>> On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds <
>> nathan.reynolds at oracle.com> wrote:
>>
>>>  Here's a minor refinement.
>>>
>>> public void lock ()
>>> {
>>>    while lock.getAndSet(true) {}
>>>  }
>>>
>>> compareAndSet() is more expensive.  The CPU has to load the value, do a
>>> comparison and then store the new value based on the comparison.  The
>>> comparison adds latency.  getAndSet() can do a load followed by a store.
>>>
>>> The JDK code implements getAndSet() as a CAS loop.  If I remember right,
>>> HotSpot 7u10 has intrinsics for most of the atomic methods so that more
>>> efficient instructions are used.  For example, it uses lock xchg, lock inc
>>> and lock dec instructions on x86.
>>>
>>> -Nathan
>>>
>>>   On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>
>>>   Hi,
>>>
>>>  My idea is:
>>>
>>>  public class SimpleLock {
>>>       private volatile AtomicBoolean lock = new AtomicBoolean();
>>>
>>>        public void lock ()
>>>       {
>>>              while !lock.compareAndSet(false, true) {}
>>>        }
>>>
>>>        public void unlock ()
>>>       {
>>>              lock.set(false);
>>>              this.lock = lock;
>>>        }
>>>  }
>>>
>>>  Obviously this is a simple lockfree locker.  The question is whether
>>> this locker also ensures the unlock() publishes all non-volatile changes
>>> made to a complex data structure used within the critical section to the
>>> next call to lock()?  If not, how can I fix this?
>>>
>>>  Andy
>>>
>>>
>>>   _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131015/7ae1eaad/attachment-0001.html>

From nathan.reynolds at oracle.com  Mon Oct 14 19:50:52 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 14 Oct 2013 16:50:52 -0700
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <1381792817.34577.YahooMailNeo@web141106.mail.bf1.yahoo.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>	<525C2539.5030301@oracle.com>	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>	<525C380C.2070609@oracle.com>	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>	<525C7848.4070501@oracle.com>
	<1381792817.34577.YahooMailNeo@web141106.mail.bf1.yahoo.com>
Message-ID: <525C835C.9070500@oracle.com>

When possible, using getAndSet() instead of compareAndSet() is a good 
idea for all data types (e.g. AtomicInteger, AtomicLong, 
AtomicReference, etc).  It is also a good idea to use getAndAdd(), 
addAndGet(), incrementAndGet(), getAndIncrement(), decrementAndGet() and 
getAndDecrement() instead of compareAndSet() where possible.

The advantage comes from avoiding the comparison.  On some processor 
implementations it might not make any difference since the latency of 
the get-and-set instruction(s) could be the same as compare-and-set.  On 
other processor implementations and platforms, it makes a difference.  
For example, on platforms with load-link and store-conditional 
instructions, using getAndSet() means there won't be a comparison 
instruction between the load-link and store-conditional instructions.  
This means 1 less instruction to execute, 1 less possible branch 
misprediction and lower latency.  However, if you change your code to 
use getAndSet() (or other methods) and this introduces a comparison, 
then the advantage is probably lost.

I don't know if I would call this a design pattern.  Its more of a rule 
for choosing a method.  The general rule is choose the least complex 
method possible (i.e. getAndSet() before getAndIncrement() before 
getAndAdd() before compareAndSet()).  Of course, some problems require 
compareAndSet() since there is no way getAndIncrement() is going to work.

For example, using getAndIncrement() in the following code would not be 
wise since m_count could be incremented above m_capacity. In some cases, 
this would break functionality since the count is > capacity and this 
doesn't make sense.  In other cases, it could be okay if m_count was 
later corrected with a decrement. However, executing 2 atomic operations 
instead of 1 is probably never a good idea.

private final AtomicInteger m_count = new AtomicInteger();
private final int           m_capacity;

public boolean reserve()
{
    int value;

    while (true)
    {
       value = m_count.get();

       if (value >= m_capacity)
          return(false);

       if (m_count.compareAndSet(value, value + 1))
          return(true);
    }
}

-Nathan

On 10/14/2013 4:20 PM, Andy Nuss wrote:
> Is it true that this design pattern and choice for getAndSet is only 
> appropriate for AtomicBoolean, rather than atomics that can have 2 or 
> more locking states?
>
>
> On Monday, October 14, 2013 4:11 PM, Nathan Reynolds 
> <nathan.reynolds at oracle.com> wrote:
> Sorry.  I am not being very precise.  If I understand the bugs right, 
> then there are matching methods in Unsafe.  See getAndAddInt(), 
> getAndAddLong(), getAndSetInt(), getAndSetLong() and getAndSetObject() 
> in 
> http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java
>
> In case you wish to consult the actual bugs...
>
> https://bugs.openjdk.java.net/browse/JDK-7023898
> https://bugs.openjdk.java.net/browse/JDK-8004330
> https://bugs.openjdk.java.net/browse/JDK-8005373
> https://bugs.openjdk.java.net/browse/JDK-8005966
> -Nathan
> On 10/14/2013 3:16 PM, Ron Pressler wrote:
>>
>> On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds 
>> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>>
>>     On x86 and a few other platforms, JIT has an intrinsic for this
>>     method.  The intrinsic gets rid of the compareAndSet() and the
>>     loop. On x86, it replaces the entire method with "lock xchg" and
>>     maybe a few more support instructions.
>>
>>
>> There is an intrinsic directly on the atomic classes without a 
>> matching method in Unsafe?
>>
>>
>>
>>     On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>>     I read in the JDK source code that getAndSet calls compareAndSet
>>>     in a loop.
>>>
>>>     If you have to write a lock of your own, isn't the TTASLock
>>>     suggested in the Art of Multiprocessor programming even better
>>>     (e.g. it further reduces the bus traffic)?
>>>
>>>     public void lock() {
>>>       while(true) {
>>>         while (lock.get()) {} //spin while true, but we're only
>>>     reading the value
>>>         //lock is free here
>>>         if (lock.compareAndSet(false, true))
>>>           return; //we locked successfully, return
>>>        }
>>>     }
>>>
>>>
>>>     On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds
>>>     <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>>
>>>     wrote:
>>>
>>>         Here's a minor refinement.
>>>
>>>         public void lock ()
>>>         {
>>>         while lock.getAndSet(true) {}
>>>         }
>>>
>>>         compareAndSet() is more expensive.  The CPU has to load the
>>>         value, do a comparison and then store the new value based on
>>>         the comparison.  The comparison adds latency.  getAndSet()
>>>         can do a load followed by a store.
>>>
>>>         The JDK code implements getAndSet() as a CAS loop.  If I
>>>         remember right, HotSpot 7u10 has intrinsics for most of the
>>>         atomic methods so that more efficient instructions are
>>>         used.  For example, it uses lock xchg, lock inc and lock dec
>>>         instructions on x86.
>>>
>>>         -Nathan
>>>
>>>         On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>>         Hi,
>>>>
>>>>         My idea is:
>>>>
>>>>         public class SimpleLock {
>>>>         private volatile AtomicBoolean lock = new AtomicBoolean();
>>>>
>>>>         public void lock ()
>>>>         {
>>>>         while !lock.compareAndSet(false, true) {}
>>>>         }
>>>>
>>>>         public void unlock ()
>>>>         {
>>>>         lock.set(false);
>>>>         this.lock = lock;
>>>>         }
>>>>         }
>>>>
>>>>         Obviously this is a simple lockfree locker.  The question
>>>>         is whether this locker also ensures the unlock() publishes
>>>>         all non-volatile changes made to a complex data structure
>>>>         used within the critical section to the next call to
>>>>         lock()?  If not, how can I fix this?
>>>>
>>>>         Andy
>>>>
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu 
> <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/af69ac13/attachment-0001.html>

From nathan.reynolds at oracle.com  Mon Oct 14 19:57:42 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 14 Oct 2013 16:57:42 -0700
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <CABg6-qjbALLpPMtMT+cWS4W343hWNrVAV2gYxbcQ10Gdor_j_A@mail.gmail.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
	<525C380C.2070609@oracle.com>
	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
	<525C7848.4070501@oracle.com>
	<CABg6-qjbALLpPMtMT+cWS4W343hWNrVAV2gYxbcQ10Gdor_j_A@mail.gmail.com>
Message-ID: <525C84F6.3010704@oracle.com>

I haven't profiled TTAS vs CAS.  Some times when using CAS, you have a 
CAS loop.  This is where the state is read, some conditions are checked 
and then CAS is executed.  In some cases, it might make sense to do a 
CAS first with a known common state.  If you luck out, then performance 
is improved because only 1 bus message has to be sent (i.e. read with 
invalidate) instead of 2 bus messages (i.e. read then later invalidate).

I should probably have stated where I am getting my information 
earlier.  See https://blogs.oracle.com/dave/entry/atomic_fetch_and_add_vs

-Nathan

On 10/14/2013 4:48 PM, Ron Pressler wrote:
> Oh, in JDK 8! That's why I couldn't find them.
>
> Also, have you profiled the TTAS pattern? Because I don't know how CAS 
> is implemented in terms of MESI/MOESI (whatever Intel is using), but I 
> know that Doug always says that an uncontended CAS is really cheap 
> nowadays, and if the lock is heavily contended I'm not sure the test 
> before the CAS would help at all; it seems it might even hurt a little.
>
>
> On Tue, Oct 15, 2013 at 2:03 AM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     Sorry.  I am not being very precise.  If I understand the bugs
>     right, then there are matching methods in Unsafe.  See
>     getAndAddInt(), getAndAddLong(), getAndSetInt(), getAndSetLong()
>     and getAndSetObject() in
>     http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java
>
>     In case you wish to consult the actual bugs...
>
>     https://bugs.openjdk.java.net/browse/JDK-7023898
>     https://bugs.openjdk.java.net/browse/JDK-8004330
>     https://bugs.openjdk.java.net/browse/JDK-8005373
>     https://bugs.openjdk.java.net/browse/JDK-8005966
>
>     -Nathan
>
>     On 10/14/2013 3:16 PM, Ron Pressler wrote:
>>
>>     On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds
>>     <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>>
>>     wrote:
>>
>>         On x86 and a few other platforms, JIT has an intrinsic for
>>         this method.  The intrinsic gets rid of the compareAndSet()
>>         and the loop.  On x86, it replaces the entire method with
>>         "lock xchg" and maybe a few more support instructions.
>>
>>
>>     There is an intrinsic directly on the atomic classes without a
>>     matching method in Unsafe?
>>
>>
>>
>>         On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>>         I read in the JDK source code that getAndSet calls
>>>         compareAndSet in a loop.
>>>
>>>         If you have to write a lock of your own, isn't the TTASLock
>>>         suggested in the Art of Multiprocessor programming even
>>>         better (e.g. it further reduces the bus traffic)?
>>>
>>>         public void lock() {
>>>           while(true) {
>>>             while (lock.get()) {} //spin while true, but we're only
>>>         reading the value
>>>             //lock is free here
>>>             if (lock.compareAndSet(false, true))
>>>               return; //we locked successfully, return
>>>            }
>>>         }
>>>
>>>
>>>         On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds
>>>         <nathan.reynolds at oracle.com
>>>         <mailto:nathan.reynolds at oracle.com>> wrote:
>>>
>>>             Here's a minor refinement.
>>>
>>>             public void lock ()
>>>             {
>>>             while lock.getAndSet(true) {}
>>>             }
>>>
>>>             compareAndSet() is more expensive.  The CPU has to load
>>>             the value, do a comparison and then store the new value
>>>             based on the comparison.  The comparison adds latency.
>>>             getAndSet() can do a load followed by a store.
>>>
>>>             The JDK code implements getAndSet() as a CAS loop.  If I
>>>             remember right, HotSpot 7u10 has intrinsics for most of
>>>             the atomic methods so that more efficient instructions
>>>             are used. For example, it uses lock xchg, lock inc and
>>>             lock dec instructions on x86.
>>>
>>>             -Nathan
>>>
>>>             On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>>             Hi,
>>>>
>>>>             My idea is:
>>>>
>>>>             public class SimpleLock {
>>>>             private volatile AtomicBoolean lock = new AtomicBoolean();
>>>>
>>>>             public void lock ()
>>>>             {
>>>>             while !lock.compareAndSet(false, true) {}
>>>>             }
>>>>
>>>>             public void unlock ()
>>>>             {
>>>>             lock.set(false);
>>>>             this.lock = lock;
>>>>             }
>>>>             }
>>>>
>>>>             Obviously this is a simple lockfree locker. The
>>>>             question is whether this locker also ensures the
>>>>             unlock() publishes all non-volatile changes made to a
>>>>             complex data structure used within the critical section
>>>>             to the next call to lock()?  If not, how can I fix this?
>>>>
>>>>             Andy
>>>>
>>>>
>>>>             _______________________________________________
>>>>             Concurrency-interest mailing list
>>>>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest at cs.oswego.edu
>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131014/934ac968/attachment-0001.html>

From dl at cs.oswego.edu  Mon Oct 14 20:00:59 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 14 Oct 2013 20:00:59 -0400
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <CABg6-qjbALLpPMtMT+cWS4W343hWNrVAV2gYxbcQ10Gdor_j_A@mail.gmail.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
	<525C380C.2070609@oracle.com>
	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
	<525C7848.4070501@oracle.com>
	<CABg6-qjbALLpPMtMT+cWS4W343hWNrVAV2gYxbcQ10Gdor_j_A@mail.gmail.com>
Message-ID: <525C85BB.3030601@cs.oswego.edu>

On 10/14/2013 07:48 PM, Ron Pressler wrote:

> Also, have you profiled the TTAS pattern? Because I don't know how CAS is
> implemented in terms of MESI/MOESI (whatever Intel is using), but I know that
> Doug always says that an uncontended CAS is really cheap nowadays, and if the
> lock is heavily contended I'm not sure the test before the CAS would help at
> all; it seems it might even hurt a little.
>

Your mileage will definitely vary. A plain spin lock is among the
cases where TATAS via getAndSet will usually be faster on platforms
natively supporting the intrinsic (but possibly slower on those
that don't). Hopefully people don't use  plain spin locks much.
When we first added the intrinsic, I checked across
java.util.concurrent internals looking for places where
they'd almost always be better, and only found and
changed a couple.

-Doug


>
> On Tue, Oct 15, 2013 at 2:03 AM, Nathan Reynolds <nathan.reynolds at oracle.com
> <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     Sorry.  I am not being very precise. If I understand the bugs right, then
>     there are matching methods in Unsafe.  See getAndAddInt(), getAndAddLong(),
>     getAndSetInt(), getAndSetLong() and getAndSetObject() in
>     http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java
>
>     In case you wish to consult the actual bugs...
>
>     https://bugs.openjdk.java.net/browse/JDK-7023898
>     https://bugs.openjdk.java.net/browse/JDK-8004330
>     https://bugs.openjdk.java.net/browse/JDK-8005373
>     https://bugs.openjdk.java.net/browse/JDK-8005966
>
>     -Nathan
>
>     On 10/14/2013 3:16 PM, Ron Pressler wrote:
>>
>>     On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds
>>     <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>>
>>         On x86 and a few other platforms, JIT has an intrinsic for this
>>         method.  The intrinsic gets rid of the compareAndSet() and the loop.
>>         On x86, it replaces the entire method with "lock xchg" and maybe a few
>>         more support instructions.
>>
>>
>>     There is an intrinsic directly on the atomic classes without a matching
>>     method in Unsafe?
>>
>>
>>
>>         On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>>         I read in the JDK source code that getAndSet calls compareAndSet in a
>>>         loop.
>>>
>>>         If you have to write a lock of your own, isn't the TTASLock suggested
>>>         in the Art of Multiprocessor programming even better (e.g. it further
>>>         reduces the bus traffic)?
>>>
>>>         public void lock() {
>>>           while(true) {
>>>             while (lock.get()) {} //spin while true, but we're only reading
>>>         the value
>>>             //lock is free here
>>>             if (lock.compareAndSet(false, true))
>>>               return; //we locked successfully, return
>>>            }
>>>         }
>>>
>>>
>>>         On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds
>>>         <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>>>
>>>             Here's a minor refinement.
>>>
>>>             public void lock ()
>>>             {
>>>             while lock.getAndSet(true) {}
>>>             }
>>>
>>>             compareAndSet() is more expensive.  The CPU has to load the
>>>             value, do a comparison and then store the new value based on the
>>>             comparison.  The comparison adds latency.  getAndSet() can do a
>>>             load followed by a store.
>>>
>>>             The JDK code implements getAndSet() as a CAS loop.  If I remember
>>>             right, HotSpot 7u10 has intrinsics for most of the atomic methods
>>>             so that more efficient instructions are used.  For example, it
>>>             uses lock xchg, lock inc and lock dec instructions on x86.
>>>
>>>             -Nathan
>>>
>>>             On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>>             Hi,
>>>>
>>>>             My idea is:
>>>>
>>>>             public class SimpleLock {
>>>>             private volatile AtomicBoolean lock = new AtomicBoolean();
>>>>
>>>>             public void lock ()
>>>>             {
>>>>             while !lock.compareAndSet(false, true) {}
>>>>             }
>>>>
>>>>             public void unlock ()
>>>>             {
>>>>             lock.set(false);
>>>>             this.lock = lock;
>>>>             }
>>>>             }
>>>>
>>>>             Obviously this is a simple lockfree locker.  The question is
>>>>             whether this locker also ensures the unlock() publishes all
>>>>             non-volatile changes made to a complex data structure used
>>>>             within the critical section to the next call to lock()?  If not,
>>>>             how can I fix this?
>>>>
>>>>             Andy
>>>>
>>>>
>>>>             _______________________________________________
>>>>             Concurrency-interest mailing list
>>>>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest at cs.oswego.edu
>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From vitalyd at gmail.com  Tue Oct 15 00:25:00 2013
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 15 Oct 2013 00:25:00 -0400
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <525C84F6.3010704@oracle.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C2539.5030301@oracle.com>
	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>
	<525C380C.2070609@oracle.com>
	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>
	<525C7848.4070501@oracle.com>
	<CABg6-qjbALLpPMtMT+cWS4W343hWNrVAV2gYxbcQ10Gdor_j_A@mail.gmail.com>
	<525C84F6.3010704@oracle.com>
Message-ID: <CAHjP37GgXsvvvXaH8fT18Fb1bU-N_RfcJG_jpn4u-1oHPYwApA@mail.gmail.com>

I think it all boils down to contention on cacheline(s) - performance is
going to suffer if multiple cores are writing to same lines, irrespective
of CAS or plain stores.  From what I've gathered, CAS on Nehalem and newer
Intel chips can be as cheap as 10-12 cycles provided that there aren't any
pending store/load ops and store buffer is empty and the CAS hits in L1
cache.  So that's why CAS is frequently referred to as a "core local"
operation, and can be done quite cheaply under right circumstances.  Also,
as someone pointed out on Dave Dice's blog, the core can perform coherence
speculation and either eliminate the 2nd transaction or hide its latency
via speculation/OoO.

Of course the minute you hit line contention clocks will go up, but that
will happen on plain writes as well.

Sent from my phone
On Oct 14, 2013 8:01 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

>  I haven't profiled TTAS vs CAS.  Some times when using CAS, you have a
> CAS loop.  This is where the state is read, some conditions are checked and
> then CAS is executed.  In some cases, it might make sense to do a CAS first
> with a known common state.  If you luck out, then performance is improved
> because only 1 bus message has to be sent (i.e. read with invalidate)
> instead of 2 bus messages (i.e. read then later invalidate).
>
> I should probably have stated where I am getting my information earlier.
> See https://blogs.oracle.com/dave/entry/atomic_fetch_and_add_vs
>
> -Nathan
>
> On 10/14/2013 4:48 PM, Ron Pressler wrote:
>
> Oh, in JDK 8! That's why I couldn't find them.
>
>  Also, have you profiled the TTAS pattern? Because I don't know how CAS
> is implemented in terms of MESI/MOESI (whatever Intel is using), but I know
> that Doug always says that an uncontended CAS is really cheap nowadays, and
> if the lock is heavily contended I'm not sure the test before the CAS would
> help at all; it seems it might even hurt a little.
>
>
> On Tue, Oct 15, 2013 at 2:03 AM, Nathan Reynolds <
> nathan.reynolds at oracle.com> wrote:
>
>>  Sorry.  I am not being very precise.  If I understand the bugs right,
>> then there are matching methods in Unsafe.  See getAndAddInt(),
>> getAndAddLong(), getAndSetInt(), getAndSetLong() and getAndSetObject() in
>> http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java
>>
>> In case you wish to consult the actual bugs...
>>
>> https://bugs.openjdk.java.net/browse/JDK-7023898
>> https://bugs.openjdk.java.net/browse/JDK-8004330
>> https://bugs.openjdk.java.net/browse/JDK-8005373
>> https://bugs.openjdk.java.net/browse/JDK-8005966
>>
>> -Nathan
>>
>>   On 10/14/2013 3:16 PM, Ron Pressler wrote:
>>
>>
>>  On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds <
>> nathan.reynolds at oracle.com> wrote:
>>
>>>  On x86 and a few other platforms, JIT has an intrinsic for this
>>> method.  The intrinsic gets rid of the compareAndSet() and the loop.  On
>>> x86, it replaces the entire method with "lock xchg" and maybe a few more
>>> support instructions.
>>>
>>
>>  There is an intrinsic directly on the atomic classes without a matching
>> method in Unsafe?
>>
>>
>>
>>    On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>>
>>>  I read in the JDK source code that getAndSet calls compareAndSet in a
>>> loop.
>>>
>>>  If you have to write a lock of your own, isn't the TTASLock suggested
>>> in the Art of Multiprocessor programming even better (e.g. it further
>>> reduces the bus traffic)?
>>>
>>>  public void lock() {
>>>   while(true) {
>>>     while (lock.get()) {} //spin while true, but we're only reading the
>>> value
>>>     //lock is free here
>>>      if (lock.compareAndSet(false, true))
>>>       return; //we locked successfully, return
>>>    }
>>> }
>>>
>>>
>>> On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds <
>>> nathan.reynolds at oracle.com> wrote:
>>>
>>>>  Here's a minor refinement.
>>>>
>>>> public void lock ()
>>>> {
>>>>    while lock.getAndSet(true) {}
>>>>  }
>>>>
>>>> compareAndSet() is more expensive.  The CPU has to load the value, do a
>>>> comparison and then store the new value based on the comparison.  The
>>>> comparison adds latency.  getAndSet() can do a load followed by a store.
>>>>
>>>> The JDK code implements getAndSet() as a CAS loop.  If I remember
>>>> right, HotSpot 7u10 has intrinsics for most of the atomic methods so that
>>>> more efficient instructions are used.  For example, it uses lock xchg, lock
>>>> inc and lock dec instructions on x86.
>>>>
>>>> -Nathan
>>>>
>>>>   On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>>
>>>>   Hi,
>>>>
>>>>  My idea is:
>>>>
>>>>  public class SimpleLock {
>>>>       private volatile AtomicBoolean lock = new AtomicBoolean();
>>>>
>>>>        public void lock ()
>>>>       {
>>>>              while !lock.compareAndSet(false, true) {}
>>>>        }
>>>>
>>>>        public void unlock ()
>>>>       {
>>>>              lock.set(false);
>>>>              this.lock = lock;
>>>>        }
>>>>  }
>>>>
>>>>  Obviously this is a simple lockfree locker.  The question is whether
>>>> this locker also ensures the unlock() publishes all non-volatile changes
>>>> made to a complex data structure used within the critical section to the
>>>> next call to lock()?  If not, how can I fix this?
>>>>
>>>>  Andy
>>>>
>>>>
>>>>   _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131015/13e004d6/attachment-0001.html>

From oleksandr.otenko at oracle.com  Tue Oct 15 13:03:26 2013
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 15 Oct 2013 18:03:26 +0100
Subject: [concurrency-interest] lock, unlock w/ publish, does it work?
In-Reply-To: <525C835C.9070500@oracle.com>
References: <1381105027.80042.YahooMailNeo@web141106.mail.bf1.yahoo.com>	<525C2539.5030301@oracle.com>	<CABzSAw9J+Rq-d8mfxjs+W3HM2UKP+9OaZt7C1wW1iTh1UYnfvA@mail.gmail.com>	<525C380C.2070609@oracle.com>	<CABg6-qiKdW1=+nyMiuYGiyNf5k4e9P=4nqCX3YHgE1TYk6dXOg@mail.gmail.com>	<525C7848.4070501@oracle.com>
	<1381792817.34577.YahooMailNeo@web141106.mail.bf1.yahoo.com>
	<525C835C.9070500@oracle.com>
Message-ID: <525D755E.50907@oracle.com>

On the contrary, it is common that if the system is sized right, you 
rarely reach capacity, so no point sacrificing the cost of atomic 
increment for a corner case (where you are likely to have relaxed 
criteria for fallback code path).


It is more a question of how big a deal is it to have the spare capacity 
(someone decremented the counter after releasing a resource), but not 
showing that for some time (until all contenders that overshot the 
capacity compensate the counter, too).


Alex


On 15/10/2013 00:50, Nathan Reynolds wrote:
> When possible, using getAndSet() instead of compareAndSet() is a good 
> idea for all data types (e.g. AtomicInteger, AtomicLong, 
> AtomicReference, etc).  It is also a good idea to use getAndAdd(), 
> addAndGet(), incrementAndGet(), getAndIncrement(), decrementAndGet() 
> and getAndDecrement() instead of compareAndSet() where possible.
>
> The advantage comes from avoiding the comparison.  On some processor 
> implementations it might not make any difference since the latency of 
> the get-and-set instruction(s) could be the same as compare-and-set.  
> On other processor implementations and platforms, it makes a 
> difference.  For example, on platforms with load-link and 
> store-conditional instructions, using getAndSet() means there won't be 
> a comparison instruction between the load-link and store-conditional 
> instructions.  This means 1 less instruction to execute, 1 less 
> possible branch misprediction and lower latency.  However, if you 
> change your code to use getAndSet() (or other methods) and this 
> introduces a comparison, then the advantage is probably lost.
>
> I don't know if I would call this a design pattern.  Its more of a 
> rule for choosing a method.  The general rule is choose the least 
> complex method possible (i.e. getAndSet() before getAndIncrement() 
> before getAndAdd() before compareAndSet()). Of course, some problems 
> require compareAndSet() since there is no way getAndIncrement() is 
> going to work.
>
> For example, using getAndIncrement() in the following code would not 
> be wise since m_count could be incremented above m_capacity.  In some 
> cases, this would break functionality since the count is > capacity 
> and this doesn't make sense.  In other cases, it could be okay if 
> m_count was later corrected with a decrement.  However, executing 2 
> atomic operations instead of 1 is probably never a good idea.
>
> private final AtomicInteger m_count = new AtomicInteger();
> private final int           m_capacity;
>
> public boolean reserve()
> {
>    int value;
>
>    while (true)
>    {
>       value = m_count.get();
>
>       if (value >= m_capacity)
>          return(false);
>
>       if (m_count.compareAndSet(value, value + 1))
>          return(true);
>    }
> }
>
> -Nathan
> On 10/14/2013 4:20 PM, Andy Nuss wrote:
>> Is it true that this design pattern and choice for getAndSet is only 
>> appropriate for AtomicBoolean, rather than atomics that can have 2 or 
>> more locking states?
>>
>>
>> On Monday, October 14, 2013 4:11 PM, Nathan Reynolds 
>> <nathan.reynolds at oracle.com> wrote:
>> Sorry. I am not being very precise.  If I understand the bugs right, 
>> then there are matching methods in Unsafe.  See getAndAddInt(), 
>> getAndAddLong(), getAndSetInt(), getAndSetLong() and 
>> getAndSetObject() in 
>> http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/575d4bc3bcae/src/share/classes/sun/misc/Unsafe.java
>>
>> In case you wish to consult the actual bugs...
>>
>> https://bugs.openjdk.java.net/browse/JDK-7023898
>> https://bugs.openjdk.java.net/browse/JDK-8004330
>> https://bugs.openjdk.java.net/browse/JDK-8005373
>> https://bugs.openjdk.java.net/browse/JDK-8005966
>> -Nathan
>> On 10/14/2013 3:16 PM, Ron Pressler wrote:
>>>
>>> On Mon, Oct 14, 2013 at 9:29 PM, Nathan Reynolds 
>>> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>>>
>>>     On x86 and a few other platforms, JIT has an intrinsic for this
>>>     method.  The intrinsic gets rid of the compareAndSet() and the
>>>     loop.  On x86, it replaces the entire method with "lock xchg"
>>>     and maybe a few more support instructions.
>>>
>>>
>>> There is an intrinsic directly on the atomic classes without a 
>>> matching method in Unsafe?
>>>
>>>
>>>
>>>     On 10/14/2013 11:11 AM, kedar mhaswade wrote:
>>>>     I read in the JDK source code that getAndSet calls
>>>>     compareAndSet in a loop.
>>>>
>>>>     If you have to write a lock of your own, isn't the TTASLock
>>>>     suggested in the Art of Multiprocessor programming even better
>>>>     (e.g. it further reduces the bus traffic)?
>>>>
>>>>     public void lock() {
>>>>       while(true) {
>>>>         while (lock.get()) {} //spin while true, but we're only
>>>>     reading the value
>>>>         //lock is free here
>>>>         if (lock.compareAndSet(false, true))
>>>>           return; //we locked successfully, return
>>>>        }
>>>>     }
>>>>
>>>>
>>>>     On Mon, Oct 14, 2013 at 10:09 AM, Nathan Reynolds
>>>>     <nathan.reynolds at oracle.com
>>>>     <mailto:nathan.reynolds at oracle.com>> wrote:
>>>>
>>>>         Here's a minor refinement.
>>>>
>>>>         public void lock ()
>>>>         {
>>>>         while lock.getAndSet(true) {}
>>>>         }
>>>>
>>>>         compareAndSet() is more expensive.  The CPU has to load the
>>>>         value, do a comparison and then store the new value based
>>>>         on the comparison.  The comparison adds latency.
>>>>         getAndSet() can do a load followed by a store.
>>>>
>>>>         The JDK code implements getAndSet() as a CAS loop.  If I
>>>>         remember right, HotSpot 7u10 has intrinsics for most of the
>>>>         atomic methods so that more efficient instructions are
>>>>         used.  For example, it uses lock xchg, lock inc and lock
>>>>         dec instructions on x86.
>>>>
>>>>         -Nathan
>>>>
>>>>         On 10/6/2013 5:17 PM, Andy Nuss wrote:
>>>>>         Hi,
>>>>>
>>>>>         My idea is:
>>>>>
>>>>>         public class SimpleLock {
>>>>>         private volatile AtomicBoolean lock = new AtomicBoolean();
>>>>>
>>>>>         public void lock ()
>>>>>         {
>>>>>         while !lock.compareAndSet(false, true) {}
>>>>>         }
>>>>>
>>>>>         public void unlock ()
>>>>>         {
>>>>>         lock.set(false);
>>>>>         this.lock = lock;
>>>>>         }
>>>>>         }
>>>>>
>>>>>         Obviously this is a simple lockfree locker.  The question
>>>>>         is whether this locker also ensures the unlock() publishes
>>>>>         all non-volatile changes made to a complex data structure
>>>>>         used within the critical section to the next call to
>>>>>         lock()?  If not, how can I fix this?
>>>>>
>>>>>         Andy
>>>>>
>>>>>
>>>>>         _______________________________________________
>>>>>         Concurrency-interest mailing list
>>>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu
>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131015/bd701e7f/attachment-0001.html>

From kedar.mhaswade at gmail.com  Tue Oct 15 18:48:06 2013
From: kedar.mhaswade at gmail.com (kedar mhaswade)
Date: Tue, 15 Oct 2013 15:48:06 -0700
Subject: [concurrency-interest] Examining thread state while it acquires a
	semaphore ...
Message-ID: <CABzSAw_yMBDY7knXVmKZs7LsgH1_wVC1zSoMrDB-5axLsGA-Sg@mail.gmail.com>

Documentation for
Semaphore.acquire<http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Semaphore.html#acquire()>says
that the acquiring thread is blocked until a permit is available.
Does it mean that getState() on such a thread should return BLOCKED?

I find that such a thread is in WAITING state with a thread dump similar to
[1] (I believe I have written a valid
test<https://github.com/kedarmhaswade/jmt/blob/master/src/test/java/org/kedar/base/NonReentrantLockSemaphoreTest.java#L51>
).

Thank you.



[1]
"Thread-1" prio=10 tid=0x00007fc9cc122000 nid=0x24f4 waiting on condition
[0x00007fc9cbffe000]
   java.lang.Thread.State: WAITING (parking)
at sun.misc.Unsafe.park(Native Method)
- parking to wait for  <0x00000007d6bfbec8> (a
java.util.concurrent.Semaphore$NonfairSync)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
at
java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
at
java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)
at
java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)
at java.util.concurrent.Semaphore.acquire(Semaphore.java:317)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131015/e3b6f1a3/attachment.html>

From davidcholmes at aapt.net.au  Tue Oct 15 19:06:23 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 16 Oct 2013 09:06:23 +1000
Subject: [concurrency-interest] Examining thread state while it acquires
	asemaphore ...
In-Reply-To: <CABzSAw_yMBDY7knXVmKZs7LsgH1_wVC1zSoMrDB-5axLsGA-Sg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEHGKBAA.davidcholmes@aapt.net.au>

No - see the definitions of the Thread states:

a.. BLOCKED
A thread that is blocked waiting for a monitor lock is in this state. 
a.. WAITING
A thread that is waiting indefinitely for another thread to perform a particular action is in this state. 

Hence a parked thread is WAITING.

http://docs.oracle.com/javase/7/docs/api/java/lang/Thread.State.html

Aside: "BLOCKED" should never have been used for waiting on a monitor as it is far too general a term.

David Holmes

  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of kedar mhaswade
  Sent: Wednesday, 16 October 2013 8:48 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Examining thread state while it acquires asemaphore ...


  Documentation for Semaphore.acquire says that the acquiring thread is blocked until a permit is available.
  Does it mean that getState() on such a thread should return BLOCKED?


  I find that such a thread is in WAITING state with a thread dump similar to [1] (I believe I have written a valid test).


  Thank you.






  [1]
  "Thread-1" prio=10 tid=0x00007fc9cc122000 nid=0x24f4 waiting on condition [0x00007fc9cbffe000]
     java.lang.Thread.State: WAITING (parking)
  at sun.misc.Unsafe.park(Native Method)
  - parking to wait for  <0x00000007d6bfbec8> (a java.util.concurrent.Semaphore$NonfairSync)
  at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)
  at java.util.concurrent.Semaphore.acquire(Semaphore.java:317)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131016/f6f11b22/attachment.html>

From nathan.reynolds at oracle.com  Tue Oct 15 19:23:35 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 15 Oct 2013 16:23:35 -0700
Subject: [concurrency-interest] Examining thread state while it acquires
 a semaphore ...
In-Reply-To: <CABzSAw_yMBDY7knXVmKZs7LsgH1_wVC1zSoMrDB-5axLsGA-Sg@mail.gmail.com>
References: <CABzSAw_yMBDY7knXVmKZs7LsgH1_wVC1zSoMrDB-5axLsGA-Sg@mail.gmail.com>
Message-ID: <525DCE77.6070004@oracle.com>

I can only say what I have seen from experience.  The Thread.BLOCKED 
state is reported only when the thread is blocked trying to acquire a 
lock using synchronized. The Thread.WAITING state is reported when the 
thread calls Object.wait() or LockSupport.park().  So, this call stack 
and thread state look normal.

-Nathan

On 10/15/2013 3:48 PM, kedar mhaswade wrote:
> Documentation for Semaphore.acquire 
> <http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Semaphore.html#acquire%28%29> 
> says that the acquiring thread is blocked until a permit is available.
> Does it mean that getState() on such a thread should return BLOCKED?
>
> I find that such a thread is in WAITING state with a thread dump 
> similar to [1] (I believe I have written a valid test 
> <https://github.com/kedarmhaswade/jmt/blob/master/src/test/java/org/kedar/base/NonReentrantLockSemaphoreTest.java#L51>).
>
> Thank you.
>
>
>
> [1]
> "Thread-1" prio=10 tid=0x00007fc9cc122000 nid=0x24f4 waiting on 
> condition [0x00007fc9cbffe000]
>    java.lang.Thread.State: WAITING (parking)
> at sun.misc.Unsafe.park(Native Method)
> - parking to wait for  <0x00000007d6bfbec8> (a 
> java.util.concurrent.Semaphore$NonfairSync)
> at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
> at 
> java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
> at 
> java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)
> at 
> java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)
> at java.util.concurrent.Semaphore.acquire(Semaphore.java:317)
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131015/f2b50922/attachment.html>

From ron.pressler at gmail.com  Wed Oct 16 17:32:15 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Wed, 16 Oct 2013 23:32:15 +0200
Subject: [concurrency-interest] ForkJoinPool, Phasers and Lightweight Threads
Message-ID: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>

Hi.
I'd like to share with this community something I've been working on for
the last six months, as well as describe some findings I've had as a result
regarding Java concurrency.

We've released an open source implementation of true Java lightweight
threads called Quasar <https://github.com/puniverse/quasar>.
There's an introductory blog
post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
and today we unveiled a nice
demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that
uses Quasar for a simulation of a big space battle.

First, let me explain what I mean by lightweight threads. A lightweight
thread (called fiber in Quasar) embodies a single flow of code execution,
and has a stack ? just like a regular thread ? only it's scheduled and
managed by Java code rather than by the OS. It is lightweight because it
consumes less memory than an OS thread, and has a much shorter
context-switch time (more on that later).

A fiber is implemented as a continuation (obtained with the help of runtime
bytecode instrumentation) scheduled on top of a ForkJoinPool in async mode.
The Fiber class implements a very similar API to the Thread class. Most
importantly is has park and unpark methods (as well as getStackTrace and
more).

To make mixing threads and fibers easy, we have an abstraction called
strand. A strand is simply either a fiber or a full blown Java thread. The
strand abstraction allowed us to easily (almost automatically) retrofit
java.util.concurrent classes to support either threads or fibers: all you
do is replace Thread with Strand everywhere, and then replace
LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
(sometimes, I've removed some spinning if we're running in a fiber because
blocking and unblocking is cheap). For example, the spaceships demo in the
blog post today uses a Phaser to synchronize fibers as well as threads.

*Thread Context Switching*
Naturally, we've dome some research about the cost of thread
context-switching. The cost of a context switch depends on many factors.
For example, a context switch on Linux is much cheaper than a context
switch on OS X. But even on Linux there is one important detail that
effects scheduling (perhaps Doug or someone else could elaborate on it): if
the thread is unblocked by the kernel (because the thread is doing a timed
sleep or blocking on IO), then the wakeup latency is very small (we
couldn't beat it with fibers by much). If, however, a thread is unparked by
another application thread, then it takes its time before getting back to
action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
faster than a thread unpark, even on Linux.

*ForkJoinPool Performance*
Fork join is awesome and performs very well. However, as I reported on this
mailing list a few months ago, there has been a significant drop in FJ
performance for async pools in what I think is the latest release. I
haven't benchmarked it again recently, and Doug said he's working on it.
Also, last I checked, ThreadPoolExecutorService still performs better than
external submissions to a FJPool. It doesn't matter, in practice, because
most submissions to an FJPool are supposed to be internal (forks).

*Phaser*
At first I was a little concerned about whether a Phaser will perform well
enough with blocked fibers, especially because unparking a fiber is so
cheap, and so unparking lots of them would best be done in parallel. My
concern turned out to be unfounded, because every unblocked thread/fiber
calls releaseWaiters() when it wakes up, so the first few woken strands
share the burden of waking the other strands. On the other hand, this also
means that all woken strands contend on popping from Treiber stack holding
the waiting strands.

Contention in releaseWaiters is very high. A simple count showed that
85-90% of CASs (attempted pops) fail.

Whatever effect this may have on performance is dwarfed by using a phaser
in the first place: it basically drains the FJPool, only to re-fill it
again, but sometimes it's a requirement.

Ron
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131016/4dc191c5/attachment.html>

From nathan.reynolds at oracle.com  Wed Oct 16 18:51:05 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 16 Oct 2013 15:51:05 -0700
Subject: [concurrency-interest] ForkJoinPool,
 Phasers and Lightweight Threads
In-Reply-To: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
Message-ID: <525F1859.3090008@oracle.com>

This is cool stuff!

 > Before the call to a suspendable method, code must be injected to 
push the caller's local variables onto a stack object.

Let me see if I understand.  Lets say Method A calls Method B which 
calls Method C and Method C blocks the thread.  Quasar will allocate a 
"stack object" and put all of the local variables into it before Method 
A calls Method B.  Likewise, Method B has to allocate a "stack object" 
and put all of the local variables into it before Method B calls Method 
C.  Correct?

However, if Method A calls Method D and Method D isn't "suspendable" 
then a "stack object" isn't used.  Correct?

So, in essence we only copy the local variables onto the heap when 
forced to.  In other words, the non-blocking code runs at full speed but 
the blocking code is going to be a bit slower.

In some server programs, a thread will have call stack depths of 100s of 
methods.  At the top of the stack is a blocking socket call to the DB.  
Does this mean that the local variables along this entire call stack 
have to be copied onto the heap?  That sounds like a huge performance hit.

-Nathan

On 10/16/2013 2:32 PM, Ron Pressler wrote:
> Hi.
> I'd like to share with this community something I've been working on 
> for the last six months, as well as describe some findings I've had as 
> a result regarding Java concurrency.
>
> We've released an open source implementation of true Java lightweight 
> threads called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post 
> <http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>, and 
> today we unveiled a nice demo 
> <http://blog.paralleluniverse.co/post/64210769930/spaceships2> that 
> uses Quasar for a simulation of a big space battle.
>
> First, let me explain what I mean by lightweight threads. A 
> lightweight thread (called fiber in Quasar) embodies a single flow of 
> code execution, and has a stack -- just like a regular thread -- only 
> it's scheduled and managed by Java code rather than by the OS. It is 
> lightweight because it consumes less memory than an OS thread, and has 
> a much shorter context-switch time (more on that later).
>
> A fiber is implemented as a continuation (obtained with the help of 
> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool 
> in async mode. The Fiber class implements a very similar API to the 
> Thread class. Most importantly is has park and unpark methods (as well 
> as getStackTrace and more).
>
> To make mixing threads and fibers easy, we have an abstraction called 
> strand. A strand is simply either a fiber or a full blown Java thread. 
> The strand abstraction allowed us to easily (almost automatically) 
> retrofit java.util.concurrent classes to support either threads or 
> fibers: all you do is replace Thread with Strand everywhere, and then 
> replace LockSupoort.park/unpark with Strand.park/unpark, and 
> everything just works! (sometimes, I've removed some spinning if we're 
> running in a fiber because blocking and unblocking is cheap). For 
> example, the spaceships demo in the blog post today uses a Phaser to 
> synchronize fibers as well as threads.
>
> *Thread Context Switching*
> Naturally, we've dome some research about the cost of thread 
> context-switching. The cost of a context switch depends on many 
> factors. For example, a context switch on Linux is much cheaper than a 
> context switch on OS X. But even on Linux there is one important 
> detail that effects scheduling (perhaps Doug or someone else could 
> elaborate on it): if the thread is unblocked by the kernel (because 
> the thread is doing a timed sleep or blocking on IO), then the wakeup 
> latency is very small (we couldn't beat it with fibers by much). If, 
> however, a thread is unparked by another application thread, then it 
> takes its time before getting back to action. A fiber context-switch 
> (basically, a FJTask.fork) is at least 10x faster than a thread 
> unpark, even on Linux.
>
> *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on 
> this mailing list a few months ago, there has been a significant drop 
> in FJ performance for async pools in what I think is the latest 
> release. I haven't benchmarked it again recently, and Doug said he's 
> working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better 
> than external submissions to a FJPool. It doesn't matter, in practice, 
> because most submissions to an FJPool are supposed to be internal (forks).
>
> *Phaser*
> At first I was a little concerned about whether a Phaser will perform 
> well enough with blocked fibers, especially because unparking a fiber 
> is so cheap, and so unparking lots of them would best be done in 
> parallel. My concern turned out to be unfounded, because every 
> unblocked thread/fiber calls releaseWaiters() when it wakes up, so the 
> first few woken strands share the burden of waking the other strands. 
> On the other hand, this also means that all woken strands contend on 
> popping from Treiber stack holding the waiting strands.
>
> Contention in releaseWaiters is very high. A simple count showed that 
> 85-90% of CASs (attempted pops) fail.
>
> Whatever effect this may have on performance is dwarfed by using a 
> phaser in the first place: it basically drains the FJPool, only to 
> re-fill it again, but sometimes it's a requirement.
>
> Ron
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131016/0c990851/attachment.html>

From nathan.reynolds at oracle.com  Wed Oct 16 19:17:11 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 16 Oct 2013 16:17:11 -0700
Subject: [concurrency-interest] ForkJoinPool,
 Phasers and Lightweight Threads
In-Reply-To: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
Message-ID: <525F1E77.3000500@oracle.com>

Here's a problem that maybe this could solve.

When a thread blocks on a lock, it will park in the kernel.  The kernel 
scheduler decides which thread to run next on the now available core.  
If the thread holding the lock is runnable, we would like the kernel 
scheduler to run that thread to ensure the lock is released as soon as 
possible.  This will improve the lock's throughput.  Unfortunately, the 
kernel scheduler doesn't have any information and usually doesn't run 
the right thread.

Could the fiber scheduler be made to run the fiber holding the lock that 
a blocking fiber is trying to acquire?

-Nathan

On 10/16/2013 2:32 PM, Ron Pressler wrote:
> Hi.
> I'd like to share with this community something I've been working on 
> for the last six months, as well as describe some findings I've had as 
> a result regarding Java concurrency.
>
> We've released an open source implementation of true Java lightweight 
> threads called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post 
> <http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>, and 
> today we unveiled a nice demo 
> <http://blog.paralleluniverse.co/post/64210769930/spaceships2> that 
> uses Quasar for a simulation of a big space battle.
>
> First, let me explain what I mean by lightweight threads. A 
> lightweight thread (called fiber in Quasar) embodies a single flow of 
> code execution, and has a stack -- just like a regular thread -- only 
> it's scheduled and managed by Java code rather than by the OS. It is 
> lightweight because it consumes less memory than an OS thread, and has 
> a much shorter context-switch time (more on that later).
>
> A fiber is implemented as a continuation (obtained with the help of 
> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool 
> in async mode. The Fiber class implements a very similar API to the 
> Thread class. Most importantly is has park and unpark methods (as well 
> as getStackTrace and more).
>
> To make mixing threads and fibers easy, we have an abstraction called 
> strand. A strand is simply either a fiber or a full blown Java thread. 
> The strand abstraction allowed us to easily (almost automatically) 
> retrofit java.util.concurrent classes to support either threads or 
> fibers: all you do is replace Thread with Strand everywhere, and then 
> replace LockSupoort.park/unpark with Strand.park/unpark, and 
> everything just works! (sometimes, I've removed some spinning if we're 
> running in a fiber because blocking and unblocking is cheap). For 
> example, the spaceships demo in the blog post today uses a Phaser to 
> synchronize fibers as well as threads.
>
> *Thread Context Switching*
> Naturally, we've dome some research about the cost of thread 
> context-switching. The cost of a context switch depends on many 
> factors. For example, a context switch on Linux is much cheaper than a 
> context switch on OS X. But even on Linux there is one important 
> detail that effects scheduling (perhaps Doug or someone else could 
> elaborate on it): if the thread is unblocked by the kernel (because 
> the thread is doing a timed sleep or blocking on IO), then the wakeup 
> latency is very small (we couldn't beat it with fibers by much). If, 
> however, a thread is unparked by another application thread, then it 
> takes its time before getting back to action. A fiber context-switch 
> (basically, a FJTask.fork) is at least 10x faster than a thread 
> unpark, even on Linux.
>
> *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on 
> this mailing list a few months ago, there has been a significant drop 
> in FJ performance for async pools in what I think is the latest 
> release. I haven't benchmarked it again recently, and Doug said he's 
> working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better 
> than external submissions to a FJPool. It doesn't matter, in practice, 
> because most submissions to an FJPool are supposed to be internal (forks).
>
> *Phaser*
> At first I was a little concerned about whether a Phaser will perform 
> well enough with blocked fibers, especially because unparking a fiber 
> is so cheap, and so unparking lots of them would best be done in 
> parallel. My concern turned out to be unfounded, because every 
> unblocked thread/fiber calls releaseWaiters() when it wakes up, so the 
> first few woken strands share the burden of waking the other strands. 
> On the other hand, this also means that all woken strands contend on 
> popping from Treiber stack holding the waiting strands.
>
> Contention in releaseWaiters is very high. A simple count showed that 
> 85-90% of CASs (attempted pops) fail.
>
> Whatever effect this may have on performance is dwarfed by using a 
> phaser in the first place: it basically drains the FJPool, only to 
> re-fill it again, but sometimes it's a requirement.
>
> Ron
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131016/6dff44a8/attachment-0001.html>

From ron.pressler at gmail.com  Wed Oct 16 19:28:19 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 17 Oct 2013 01:28:19 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <525F1859.3090008@oracle.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<525F1859.3090008@oracle.com>
Message-ID: <CABg6-qhg6=ywLOgPwsP+gXGmLbwkACByNKj+yLGAE-HAKToRLw@mail.gmail.com>

On Thu, Oct 17, 2013 at 1:51 AM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  This is cool stuff!
>
> Thank you!


>
> Let me see if I understand.  Lets say Method A calls Method B which calls
> Method C and Method C blocks the thread.  Quasar will allocate a "stack
> object" and put all of the local variables into it before Method A calls
> Method B.  Likewise, Method B has to allocate a "stack object" and put all
> of the local variables into it before Method B calls Method C.  Correct?
>

Yes, except that there's only one stack object, containing two arrays: one
for primitives and one for refs. The arrays grow when necessary. The stack
holds both the local vars as well as the location in the method we jump to
the next time the continuation runs.

>
> However, if Method A calls Method D and Method D isn't "suspendable" then
> a "stack object" isn't used.  Correct?
>

Yes.


>  So, in essence we only copy the local variables onto the heap when forced
> to.  In other words, the non-blocking code runs at full speed but the
> blocking code is going to be a bit slower.
>

Yes. The performance overhead is about 3%.


>  In some server programs, a thread will have call stack depths of 100s of
> methods.  At the top of the stack is a blocking socket call to the DB.
> Does this mean that the local variables along this entire call stack have
> to be copied onto the heap?  That sounds like a huge performance hit.
>

The performance hit is not huge, but you wouldn't want to use fibers like
that anyway. Fibers are not meant to replace threads. We don't try to beat
the OS scheduler in all circumstances, and we probably can't. Fibers (and
constructs built on top of them like actors) shine when there are lots and
lots of them, each doing a little bit of work and then passing on the
result to another fiber somehow, and then blocking waiting on another
fiber: i.e. lots of parks and unparks.


 P.S.
In case it wasn't clear, the Phaser used in the demo doesn't use
FJP.managedBlock because no FJ threads ? only the fibers running on top of
them ? are ever directly blocked by the phaser. The FJ threads would
eventually be indirectly blocked when the phaser drains them of all work.


 On 10/16/2013 2:32 PM, Ron Pressler wrote:
>
> Hi.
> I'd like to share with this community something I've been working on for
> the last six months, as well as describe some findings I've had as a result
> regarding Java concurrency.
>
>  We've released an open source implementation of true Java lightweight
> threads called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
> and today we unveiled a nice demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that uses Quasar for a simulation of a big space battle.
>
>  First, let me explain what I mean by lightweight threads. A lightweight
> thread (called fiber in Quasar) embodies a single flow of code execution,
> and has a stack ? just like a regular thread ? only it's scheduled and
> managed by Java code rather than by the OS. It is lightweight because it
> consumes less memory than an OS thread, and has a much shorter
> context-switch time (more on that later).
>
>  A fiber is implemented as a continuation (obtained with the help of
> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
> async mode. The Fiber class implements a very similar API to the Thread
> class. Most importantly is has park and unpark methods (as well as
> getStackTrace and more).
>
>  To make mixing threads and fibers easy, we have an abstraction called
> strand. A strand is simply either a fiber or a full blown Java thread. The
> strand abstraction allowed us to easily (almost automatically) retrofit
> java.util.concurrent classes to support either threads or fibers: all you
> do is replace Thread with Strand everywhere, and then replace
> LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
> (sometimes, I've removed some spinning if we're running in a fiber because
> blocking and unblocking is cheap). For example, the spaceships demo in the
> blog post today uses a Phaser to synchronize fibers as well as threads.
>
>  *Thread Context Switching*
> Naturally, we've dome some research about the cost of thread
> context-switching. The cost of a context switch depends on many factors.
> For example, a context switch on Linux is much cheaper than a context
> switch on OS X. But even on Linux there is one important detail that
> effects scheduling (perhaps Doug or someone else could elaborate on it): if
> the thread is unblocked by the kernel (because the thread is doing a timed
> sleep or blocking on IO), then the wakeup latency is very small (we
> couldn't beat it with fibers by much). If, however, a thread is unparked by
> another application thread, then it takes its time before getting back to
> action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
> faster than a thread unpark, even on Linux.
>
>  *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on
> this mailing list a few months ago, there has been a significant drop in FJ
> performance for async pools in what I think is the latest release. I
> haven't benchmarked it again recently, and Doug said he's working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better than
> external submissions to a FJPool. It doesn't matter, in practice, because
> most submissions to an FJPool are supposed to be internal (forks).
>
>  *Phaser*
> At first I was a little concerned about whether a Phaser will perform well
> enough with blocked fibers, especially because unparking a fiber is so
> cheap, and so unparking lots of them would best be done in parallel. My
> concern turned out to be unfounded, because every unblocked thread/fiber
> calls releaseWaiters() when it wakes up, so the first few woken strands
> share the burden of waking the other strands. On the other hand, this also
> means that all woken strands contend on popping from Treiber stack holding
> the waiting strands.
>
>  Contention in releaseWaiters is very high. A simple count showed that
> 85-90% of CASs (attempted pops) fail.
>
>  Whatever effect this may have on performance is dwarfed by using a
> phaser in the first place: it basically drains the FJPool, only to re-fill
> it again, but sometimes it's a requirement.
>
>  Ron
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/3b44abd3/attachment.html>

From davidcholmes at aapt.net.au  Wed Oct 16 19:33:59 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 17 Oct 2013 09:33:59 +1000
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <525F1E77.3000500@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEIDKBAA.davidcholmes@aapt.net.au>

Nathan,

That only helps in some cases. If the lock is continually acquired and
released then you potentially starve out other threads wanting the lock,
unless you ensure that a lock release includes a hand-off (and so precludes
barging). But hand-offs incur their own performance penalties.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan
Reynolds
  Sent: Thursday, 17 October 2013 9:17 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ForkJoinPool, Phasers and Lightweight
Threads


  Here's a problem that maybe this could solve.

  When a thread blocks on a lock, it will park in the kernel.  The kernel
scheduler decides which thread to run next on the now available core.  If
the thread holding the lock is runnable, we would like the kernel scheduler
to run that thread to ensure the lock is released as soon as possible.  This
will improve the lock's throughput.  Unfortunately, the kernel scheduler
doesn't have any information and usually doesn't run the right thread.

  Could the fiber scheduler be made to run the fiber holding the lock that a
blocking fiber is trying to acquire?

-NathanOn 10/16/2013 2:32 PM, Ron Pressler wrote:

    Hi.
    I'd like to share with this community something I've been working on for
the last six months, as well as describe some findings I've had as a result
regarding Java concurrency.


    We've released an open source implementation of true Java lightweight
threads called Quasar.
    There's an introductory blog post, and today we unveiled a nice demo
that uses Quasar for a simulation of a big space battle.


    First, let me explain what I mean by lightweight threads. A lightweight
thread (called fiber in Quasar) embodies a single flow of code execution,
and has a stack ? just like a regular thread ? only it's scheduled and
managed by Java code rather than by the OS. It is lightweight because it
consumes less memory than an OS thread, and has a much shorter
context-switch time (more on that later).


    A fiber is implemented as a continuation (obtained with the help of
runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
async mode. The Fiber class implements a very similar API to the Thread
class. Most importantly is has park and unpark methods (as well as
getStackTrace and more).


    To make mixing threads and fibers easy, we have an abstraction called
strand. A strand is simply either a fiber or a full blown Java thread. The
strand abstraction allowed us to easily (almost automatically) retrofit
java.util.concurrent classes to support either threads or fibers: all you do
is replace Thread with Strand everywhere, and then replace
LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
(sometimes, I've removed some spinning if we're running in a fiber because
blocking and unblocking is cheap). For example, the spaceships demo in the
blog post today uses a Phaser to synchronize fibers as well as threads.


    Thread Context Switching
    Naturally, we've dome some research about the cost of thread
context-switching. The cost of a context switch depends on many factors. For
example, a context switch on Linux is much cheaper than a context switch on
OS X. But even on Linux there is one important detail that effects
scheduling (perhaps Doug or someone else could elaborate on it): if the
thread is unblocked by the kernel (because the thread is doing a timed sleep
or blocking on IO), then the wakeup latency is very small (we couldn't beat
it with fibers by much). If, however, a thread is unparked by another
application thread, then it takes its time before getting back to action. A
fiber context-switch (basically, a FJTask.fork) is at least 10x faster than
a thread unpark, even on Linux.


    ForkJoinPool Performance
    Fork join is awesome and performs very well. However, as I reported on
this mailing list a few months ago, there has been a significant drop in FJ
performance for async pools in what I think is the latest release. I haven't
benchmarked it again recently, and Doug said he's working on it.
    Also, last I checked, ThreadPoolExecutorService still performs better
than external submissions to a FJPool. It doesn't matter, in practice,
because most submissions to an FJPool are supposed to be internal (forks).


    Phaser
    At first I was a little concerned about whether a Phaser will perform
well enough with blocked fibers, especially because unparking a fiber is so
cheap, and so unparking lots of them would best be done in parallel. My
concern turned out to be unfounded, because every unblocked thread/fiber
calls releaseWaiters() when it wakes up, so the first few woken strands
share the burden of waking the other strands. On the other hand, this also
means that all woken strands contend on popping from Treiber stack holding
the waiting strands.


    Contention in releaseWaiters is very high. A simple count showed that
85-90% of CASs (attempted pops) fail.


    Whatever effect this may have on performance is dwarfed by using a
phaser in the first place: it basically drains the FJPool, only to re-fill
it again, but sometimes it's a requirement.


    Ron



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/03640dbe/attachment-0001.html>

From ron.pressler at gmail.com  Wed Oct 16 19:37:10 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 17 Oct 2013 01:37:10 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <525F1E77.3000500@oracle.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<525F1E77.3000500@oracle.com>
Message-ID: <CABg6-qh9NVJHy2YwjAG5XQdszwUDsXmNUH1a2gA37CTN2XSHyw@mail.gmail.com>

On Thu, Oct 17, 2013 at 2:17 AM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  Here's a problem that maybe this could solve.
>
> When a thread blocks on a lock, it will park in the kernel.  The kernel
> scheduler decides which thread to run next on the now available core.  If
> the thread holding the lock is runnable, we would like the kernel scheduler
> to run that thread to ensure the lock is released as soon as possible.
> This will improve the lock's throughput.  Unfortunately, the kernel
> scheduler doesn't have any information and usually doesn't run the right
> thread.
>
> Could the fiber scheduler be made to run the fiber holding the lock that a
> blocking fiber is trying to acquire?
>
>
Ideally, the fiber holding the lock would be already running. If it isn't,
then either its not parked but its thread has been descheduled by the
kernel, in which case we can do nothing, or its blocked waiting on some
other fibers, so we'd need to track a dependency graph.

It can, however, work well with a read-write lock with many readers. Say a
writer has just released the lock, and now tens of readers need to be run.
A new writer attempting to grab the lock can then have its thread run some
of the newly runnable readers. We do exactly that in SpaceBase, but we
haven't explored the empirical effectiveness of this approach enough to say
how big a benefit this is. But yes, we can certainly examine the waiting
set of a synchronizer to see if we can help; there's a lot more work to do
in that area.


> -Nathan
>
> On 10/16/2013 2:32 PM, Ron Pressler wrote:
>
> Hi.
> I'd like to share with this community something I've been working on for
> the last six months, as well as describe some findings I've had as a result
> regarding Java concurrency.
>
>  We've released an open source implementation of true Java lightweight
> threads called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
> and today we unveiled a nice demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that uses Quasar for a simulation of a big space battle.
>
>  First, let me explain what I mean by lightweight threads. A lightweight
> thread (called fiber in Quasar) embodies a single flow of code execution,
> and has a stack ? just like a regular thread ? only it's scheduled and
> managed by Java code rather than by the OS. It is lightweight because it
> consumes less memory than an OS thread, and has a much shorter
> context-switch time (more on that later).
>
>  A fiber is implemented as a continuation (obtained with the help of
> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
> async mode. The Fiber class implements a very similar API to the Thread
> class. Most importantly is has park and unpark methods (as well as
> getStackTrace and more).
>
>  To make mixing threads and fibers easy, we have an abstraction called
> strand. A strand is simply either a fiber or a full blown Java thread. The
> strand abstraction allowed us to easily (almost automatically) retrofit
> java.util.concurrent classes to support either threads or fibers: all you
> do is replace Thread with Strand everywhere, and then replace
> LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
> (sometimes, I've removed some spinning if we're running in a fiber because
> blocking and unblocking is cheap). For example, the spaceships demo in the
> blog post today uses a Phaser to synchronize fibers as well as threads.
>
>  *Thread Context Switching*
> Naturally, we've dome some research about the cost of thread
> context-switching. The cost of a context switch depends on many factors.
> For example, a context switch on Linux is much cheaper than a context
> switch on OS X. But even on Linux there is one important detail that
> effects scheduling (perhaps Doug or someone else could elaborate on it): if
> the thread is unblocked by the kernel (because the thread is doing a timed
> sleep or blocking on IO), then the wakeup latency is very small (we
> couldn't beat it with fibers by much). If, however, a thread is unparked by
> another application thread, then it takes its time before getting back to
> action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
> faster than a thread unpark, even on Linux.
>
>  *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on
> this mailing list a few months ago, there has been a significant drop in FJ
> performance for async pools in what I think is the latest release. I
> haven't benchmarked it again recently, and Doug said he's working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better than
> external submissions to a FJPool. It doesn't matter, in practice, because
> most submissions to an FJPool are supposed to be internal (forks).
>
>  *Phaser*
> At first I was a little concerned about whether a Phaser will perform well
> enough with blocked fibers, especially because unparking a fiber is so
> cheap, and so unparking lots of them would best be done in parallel. My
> concern turned out to be unfounded, because every unblocked thread/fiber
> calls releaseWaiters() when it wakes up, so the first few woken strands
> share the burden of waking the other strands. On the other hand, this also
> means that all woken strands contend on popping from Treiber stack holding
> the waiting strands.
>
>  Contention in releaseWaiters is very high. A simple count showed that
> 85-90% of CASs (attempted pops) fail.
>
>  Whatever effect this may have on performance is dwarfed by using a
> phaser in the first place: it basically drains the FJPool, only to re-fill
> it again, but sometimes it's a requirement.
>
>  Ron
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/be05cef1/attachment.html>

From nathan.reynolds at oracle.com  Wed Oct 16 20:08:14 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 16 Oct 2013 17:08:14 -0700
Subject: [concurrency-interest] ForkJoinPool,
 Phasers and Lightweight Threads
In-Reply-To: <CABg6-qhg6=ywLOgPwsP+gXGmLbwkACByNKj+yLGAE-HAKToRLw@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<525F1859.3090008@oracle.com>
	<CABg6-qhg6=ywLOgPwsP+gXGmLbwkACByNKj+yLGAE-HAKToRLw@mail.gmail.com>
Message-ID: <525F2A6E.4070300@oracle.com>

On 10/16/2013 4:28 PM, Ron Pressler wrote:
>
> On Thu, Oct 17, 2013 at 1:51 AM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     This is cool stuff!
>
> Thank you!
>
>     Let me see if I understand.  Lets say Method A calls Method B
>     which calls Method C and Method C blocks the thread.  Quasar will
>     allocate a "stack object" and put all of the local variables into
>     it before Method A calls Method B.  Likewise, Method B has to
>     allocate a "stack object" and put all of the local variables into
>     it before Method B calls Method C.  Correct?
>
>
> Yes, except that there's only one stack object, containing two arrays: 
> one for primitives and one for refs. The arrays grow when necessary. 
> The stack holds both the local vars as well as the location in the 
> method we jump to the next time the continuation runs.
I figured only one stack object per fiber.  If I had thought deeper, I 
would have realized that it would have the two arrays.
>
>     However, if Method A calls Method D and Method D isn't
>     "suspendable" then a "stack object" isn't used. Correct?
>
>
> Yes.
>
>     So, in essence we only copy the local variables onto the heap when
>     forced to.  In other words, the non-blocking code runs at full
>     speed but the blocking code is going to be a bit slower.
>
> Yes. The performance overhead is about 3%.
Nice.  Except for some very competitive benchmarks, that sounds like an 
acceptable overhead for the added functionality and concurrency.

The cost of a Linux context switch between threads in the same process 
is about 1.05 ?s on Intel Westmere processors.  This does not account 
for having to load the cache with the data specific for that thread.  
Depending upon how much data has to be loaded and where the data is 
located (i.e. L2, L3, RAM), the cost of a context switch goes up quite a 
lot.

With fibers, I suppose the cost of a context switch would be much less 
than 1.05 ?s.  However, the cost of loading the cache can't be avoided.  
So, the context switch speed advantage of fibers disappears if the cache 
has to be completely reloaded from RAM.

Do fibers have a sticky affinity for the core they are running on?
>
>     In some server programs, a thread will have call stack depths of
>     100s of methods.  At the top of the stack is a blocking socket
>     call to the DB.  Does this mean that the local variables along
>     this entire call stack have to be copied onto the heap?  That
>     sounds like a huge performance hit.
>
>
> The performance hit is not huge, but you wouldn't want to use fibers 
> like that anyway. Fibers are not meant to replace threads. We don't 
> try to beat the OS scheduler in all circumstances, and we probably 
> can't. Fibers (and constructs built on top of them like actors) shine 
> when there are lots and lots of them, each doing a little bit of work 
> and then passing on the result to another fiber somehow, and then 
> blocking waiting on another fiber: i.e. lots of parks and unparks.
I am trying to figure out where this could be applied.

Does this basically eliminate application servers from using fibers?  I 
suppose one could re-write application servers and all of the APIs to 
make them fiber friendly.  Thus, the above 100s of method call stack 
would be broken down into small actors.

Does this eliminate JDBC access since JDBC drivers typically have 5-10 
methods between the API and blocking on a socket call to the DB?

I don't see this being terribly helpful on the client side since the 
core count is low and hence concurrency is not as useful.  So, I figure 
this is best for servers.  Where do you see this being used?
>  P.S.
> In case it wasn't clear, the Phaser used in the demo doesn't use 
> FJP.managedBlock because no FJ threads ? only the fibers running on 
> top of them ? are ever directly blocked by the phaser. The FJ threads 
> would eventually be indirectly blocked when the phaser drains them of 
> all work.
>
>
>     On 10/16/2013 2:32 PM, Ron Pressler wrote:
>>     Hi.
>>     I'd like to share with this community something I've been working
>>     on for the last six months, as well as describe some findings
>>     I've had as a result regarding Java concurrency.
>>
>>     We've released an open source implementation of true Java
>>     lightweight threads called Quasar
>>     <https://github.com/puniverse/quasar>.
>>     There's an introductory blog post
>>     <http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
>>     and today we unveiled a nice demo
>>     <http://blog.paralleluniverse.co/post/64210769930/spaceships2>
>>     that uses Quasar for a simulation of a big space battle.
>>
>>     First, let me explain what I mean by lightweight threads. A
>>     lightweight thread (called fiber in Quasar) embodies a single
>>     flow of code execution, and has a stack ? just like a regular
>>     thread ? only it's scheduled and managed by Java code rather than
>>     by the OS. It is lightweight because it consumes less memory than
>>     an OS thread, and has a much shorter context-switch time (more on
>>     that later).
>>
>>     A fiber is implemented as a continuation (obtained with the help
>>     of runtime bytecode instrumentation) scheduled on top of a
>>     ForkJoinPool in async mode. The Fiber class implements a very
>>     similar API to the Thread class. Most importantly is has park and
>>     unpark methods (as well as getStackTrace and more).
>>
>>     To make mixing threads and fibers easy, we have an abstraction
>>     called strand. A strand is simply either a fiber or a full blown
>>     Java thread. The strand abstraction allowed us to easily (almost
>>     automatically) retrofit java.util.concurrent classes to support
>>     either threads or fibers: all you do is replace Thread with
>>     Strand everywhere, and then replace LockSupoort.park/unpark with
>>     Strand.park/unpark, and everything just works! (sometimes, I've
>>     removed some spinning if we're running in a fiber because
>>     blocking and unblocking is cheap). For example, the spaceships
>>     demo in the blog post today uses a Phaser to synchronize fibers
>>     as well as threads.
>>
>>     *Thread Context Switching*
>>     Naturally, we've dome some research about the cost of thread
>>     context-switching. The cost of a context switch depends on many
>>     factors. For example, a context switch on Linux is much cheaper
>>     than a context switch on OS X. But even on Linux there is one
>>     important detail that effects scheduling (perhaps Doug or someone
>>     else could elaborate on it): if the thread is unblocked by the
>>     kernel (because the thread is doing a timed sleep or blocking on
>>     IO), then the wakeup latency is very small (we couldn't beat it
>>     with fibers by much). If, however, a thread is unparked by
>>     another application thread, then it takes its time before getting
>>     back to action. A fiber context-switch (basically, a FJTask.fork)
>>     is at least 10x faster than a thread unpark, even on Linux.
>>
>>     *ForkJoinPool Performance*
>>     Fork join is awesome and performs very well. However, as I
>>     reported on this mailing list a few months ago, there has been a
>>     significant drop in FJ performance for async pools in what I
>>     think is the latest release. I haven't benchmarked it again
>>     recently, and Doug said he's working on it.
>>     Also, last I checked, ThreadPoolExecutorService still performs
>>     better than external submissions to a FJPool. It doesn't matter,
>>     in practice, because most submissions to an FJPool are supposed
>>     to be internal (forks).
>>
>>     *Phaser*
>>     At first I was a little concerned about whether a Phaser will
>>     perform well enough with blocked fibers, especially because
>>     unparking a fiber is so cheap, and so unparking lots of them
>>     would best be done in parallel. My concern turned out to be
>>     unfounded, because every unblocked thread/fiber calls
>>     releaseWaiters() when it wakes up, so the first few woken strands
>>     share the burden of waking the other strands. On the other hand,
>>     this also means that all woken strands contend on popping from
>>     Treiber stack holding the waiting strands.
>>
>>     Contention in releaseWaiters is very high. A simple count showed
>>     that 85-90% of CASs (attempted pops) fail.
>>
>>     Whatever effect this may have on performance is dwarfed by using
>>     a phaser in the first place: it basically drains the FJPool, only
>>     to re-fill it again, but sometimes it's a requirement.
>>
>>     Ron
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131016/d9784022/attachment-0001.html>

From niall at npgall.com  Wed Oct 16 20:24:45 2013
From: niall at npgall.com (Niall Gallagher)
Date: Thu, 17 Oct 2013 01:24:45 +0100
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
Message-ID: <ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>

This sounds amazing.

So at the moment, there's a push away from request-per-thread models (e.g. classic servlets), towards asynchronous IO in frameworks like Netty and actor models, FJP etc. Because number of cores per box is increasing, or number of persistent connections etc. is increasing, but we can't create a million threads.

So am I understanding this correctly - could Phaser allow us to continue to write code for the thread-per-request model (which is definitely more intuitive), but yet underneath the code Quasar could intercept the point at which threads block or sleep etc., and swap their stacks to the heap?

Could a classic-servlet-style container be written on top of this to provide better scalability than the thread-per-request model, but transparently?

Thinking even further ahead, ultimately could the stacks (and referenced objects) of suspended fibers be serialized outside of the JVM, so number of suspended fibers would not even be bound by heap size?

I am wondering though, how would this compare with Java's green threads from the old days? Unless I've misunderstood something though, this brings with it a huge number of possibilities/opportunities. Awesome stuff.


On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com> wrote:

> Hi.
> I'd like to share with this community something I've been working on for the last six months, as well as describe some findings I've had as a result regarding Java concurrency.
> 
> We've released an open source implementation of true Java lightweight threads called Quasar.
> There's an introductory blog post, and today we unveiled a nice demo that uses Quasar for a simulation of a big space battle.
> 
> First, let me explain what I mean by lightweight threads. A lightweight thread (called fiber in Quasar) embodies a single flow of code execution, and has a stack ? just like a regular thread ? only it's scheduled and managed by Java code rather than by the OS. It is lightweight because it consumes less memory than an OS thread, and has a much shorter context-switch time (more on that later).
> 
> A fiber is implemented as a continuation (obtained with the help of runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in async mode. The Fiber class implements a very similar API to the Thread class. Most importantly is has park and unpark methods (as well as getStackTrace and more).
> 
> To make mixing threads and fibers easy, we have an abstraction called strand. A strand is simply either a fiber or a full blown Java thread. The strand abstraction allowed us to easily (almost automatically) retrofit java.util.concurrent classes to support either threads or fibers: all you do is replace Thread with Strand everywhere, and then replace LockSupoort.park/unpark with Strand.park/unpark, and everything just works! (sometimes, I've removed some spinning if we're running in a fiber because blocking and unblocking is cheap). For example, the spaceships demo in the blog post today uses a Phaser to synchronize fibers as well as threads.
> 
> Thread Context Switching
> Naturally, we've dome some research about the cost of thread context-switching. The cost of a context switch depends on many factors. For example, a context switch on Linux is much cheaper than a context switch on OS X. But even on Linux there is one important detail that effects scheduling (perhaps Doug or someone else could elaborate on it): if the thread is unblocked by the kernel (because the thread is doing a timed sleep or blocking on IO), then the wakeup latency is very small (we couldn't beat it with fibers by much). If, however, a thread is unparked by another application thread, then it takes its time before getting back to action. A fiber context-switch (basically, a FJTask.fork) is at least 10x faster than a thread unpark, even on Linux.
> 
> ForkJoinPool Performance
> Fork join is awesome and performs very well. However, as I reported on this mailing list a few months ago, there has been a significant drop in FJ performance for async pools in what I think is the latest release. I haven't benchmarked it again recently, and Doug said he's working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better than external submissions to a FJPool. It doesn't matter, in practice, because most submissions to an FJPool are supposed to be internal (forks).
> 
> Phaser
> At first I was a little concerned about whether a Phaser will perform well enough with blocked fibers, especially because unparking a fiber is so cheap, and so unparking lots of them would best be done in parallel. My concern turned out to be unfounded, because every unblocked thread/fiber calls releaseWaiters() when it wakes up, so the first few woken strands share the burden of waking the other strands. On the other hand, this also means that all woken strands contend on popping from Treiber stack holding the waiting strands. 
> 
> Contention in releaseWaiters is very high. A simple count showed that 85-90% of CASs (attempted pops) fail. 
> 
> Whatever effect this may have on performance is dwarfed by using a phaser in the first place: it basically drains the FJPool, only to re-fill it again, but sometimes it's a requirement.
> 
> Ron
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/5ed33f46/attachment.html>

From ron.pressler at gmail.com  Wed Oct 16 20:41:27 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 17 Oct 2013 02:41:27 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <525F2A6E.4070300@oracle.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<525F1859.3090008@oracle.com>
	<CABg6-qhg6=ywLOgPwsP+gXGmLbwkACByNKj+yLGAE-HAKToRLw@mail.gmail.com>
	<525F2A6E.4070300@oracle.com>
Message-ID: <CABg6-qi5BoUqw=zOoO4+5Y3FwCyE_C0nMJvi8i3R2an1xV2sMg@mail.gmail.com>

> Do fibers have a sticky affinity for the core they are running on?
>

You can assign a fiber to a given FJPool. If you assign affinity to the
pool threads, then by association, it would work for the fiber. Probably
won't be effective if you want core-affinity, but very effective for socket
affinity on a NUMA machine.

I am trying to figure out where this could be applied.
>
> Does this basically eliminate application servers from using fibers?  I
> suppose one could re-write application servers and all of the APIs to make
> them fiber friendly.  Thus, the above 100s of method call stack would be
> broken down into small actors.
>

First, people are already breaking up their applications into small pieces
for scalability reasons, by using actors, or stuff like JavaRx or Storm.
Look at how LinkedIn, Netflix or Twitter structure their code. What Quasar
tries to do is provide the concurrency while trying to maintain as much as
possible an intuitive and familiar programming model. Second, we've used
Quasar in application servers: much of the 100-deep call stack is actually
part of the framework (like Tomcat); we've used fibers below that, i.e.
starting in the servlet handler.


> Does this eliminate JDBC access since JDBC drivers typically have 5-10
> methods between the API and blocking on a socket call to the DB?
>

We have a JDBC layer for Quasar, and the idea is simple. All blocking IO
calls are done in a separate thread pool. A fiber blocking on a JDBC call
essentially dispatches the request to the IO thread pool, and then parks
until it's unparked by the IO thread when the call complete. The fiber
doesn't directly block on IO (we don't want the FJ worker to block on IO).
Obviously, an RDBMS has a certain capacity, and supports a given number of
concurrent connections ? fibers can't manufacture better DB throughput,
(though they might allow more DB request to queue up, and let the DB driver
or the DB benefit from a full pipeline, provided that the DB capacity
exceeds the plain-thread capacity of the client, which I guess is quite
possible).


>
> I don't see this being terribly helpful on the client side since the core
> count is low and hence concurrency is not as useful.  So, I figure this is
> best for servers.  Where do you see this being used?
>
>
Servers seem like the natural place, but someone already wants to try it on
Android (which I personally found surprising, but I'm not too familiar with
mobile app development).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/c1983a55/attachment.html>

From davidcholmes at aapt.net.au  Wed Oct 16 20:47:05 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 17 Oct 2013 10:47:05 +1000
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEIEKBAA.davidcholmes@aapt.net.au>

Operations that block in the kernel eg blocking I/O, will block the thread
not just the fiber. To just block the fiber you will still need async IO.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Niall
Gallagher
  Sent: Thursday, 17 October 2013 10:25 AM
  To: concurrency-interest
  Subject: Re: [concurrency-interest] ForkJoinPool,Phasers and Lightweight
Threads


  This sounds amazing.


  So at the moment, there's a push away from request-per-thread models (e.g.
classic servlets), towards asynchronous IO in frameworks like Netty and
actor models, FJP etc. Because number of cores per box is increasing, or
number of persistent connections etc. is increasing, but we can't create a
million threads.


  So am I understanding this correctly - could Phaser allow us to continue
to write code for the thread-per-request model (which is definitely more
intuitive), but yet underneath the code Quasar could intercept the point at
which threads block or sleep etc., and swap their stacks to the heap?


  Could a classic-servlet-style container be written on top of this to
provide better scalability than the thread-per-request model, but
transparently?


  Thinking even further ahead, ultimately could the stacks (and referenced
objects) of suspended fibers be serialized outside of the JVM, so number of
suspended fibers would not even be bound by heap size?


  I am wondering though, how would this compare with Java's green threads
from the old days? Unless I've misunderstood something though, this brings
with it a huge number of possibilities/opportunities. Awesome stuff.




  On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com> wrote:


    Hi.
    I'd like to share with this community something I've been working on for
the last six months, as well as describe some findings I've had as a result
regarding Java concurrency.


    We've released an open source implementation of true Java lightweight
threads called Quasar.
    There's an introductory blog post, and today we unveiled a nice demo
that uses Quasar for a simulation of a big space battle.


    First, let me explain what I mean by lightweight threads. A lightweight
thread (called fiber in Quasar) embodies a single flow of code execution,
and has a stack ? just like a regular thread ? only it's scheduled and
managed by Java code rather than by the OS. It is lightweight because it
consumes less memory than an OS thread, and has a much shorter
context-switch time (more on that later).


    A fiber is implemented as a continuation (obtained with the help of
runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
async mode. The Fiber class implements a very similar API to the Thread
class. Most importantly is has park and unpark methods (as well as
getStackTrace and more).


    To make mixing threads and fibers easy, we have an abstraction called
strand. A strand is simply either a fiber or a full blown Java thread. The
strand abstraction allowed us to easily (almost automatically) retrofit
java.util.concurrent classes to support either threads or fibers: all you do
is replace Thread with Strand everywhere, and then replace
LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
(sometimes, I've removed some spinning if we're running in a fiber because
blocking and unblocking is cheap). For example, the spaceships demo in the
blog post today uses a Phaser to synchronize fibers as well as threads.


    Thread Context Switching
    Naturally, we've dome some research about the cost of thread
context-switching. The cost of a context switch depends on many factors. For
example, a context switch on Linux is much cheaper than a context switch on
OS X. But even on Linux there is one important detail that effects
scheduling (perhaps Doug or someone else could elaborate on it): if the
thread is unblocked by the kernel (because the thread is doing a timed sleep
or blocking on IO), then the wakeup latency is very small (we couldn't beat
it with fibers by much). If, however, a thread is unparked by another
application thread, then it takes its time before getting back to action. A
fiber context-switch (basically, a FJTask.fork) is at least 10x faster than
a thread unpark, even on Linux.


    ForkJoinPool Performance
    Fork join is awesome and performs very well. However, as I reported on
this mailing list a few months ago, there has been a significant drop in FJ
performance for async pools in what I think is the latest release. I haven't
benchmarked it again recently, and Doug said he's working on it.
    Also, last I checked, ThreadPoolExecutorService still performs better
than external submissions to a FJPool. It doesn't matter, in practice,
because most submissions to an FJPool are supposed to be internal (forks).


    Phaser
    At first I was a little concerned about whether a Phaser will perform
well enough with blocked fibers, especially because unparking a fiber is so
cheap, and so unparking lots of them would best be done in parallel. My
concern turned out to be unfounded, because every unblocked thread/fiber
calls releaseWaiters() when it wakes up, so the first few woken strands
share the burden of waking the other strands. On the other hand, this also
means that all woken strands contend on popping from Treiber stack holding
the waiting strands.


    Contention in releaseWaiters is very high. A simple count showed that
85-90% of CASs (attempted pops) fail.


    Whatever effect this may have on performance is dwarfed by using a
phaser in the first place: it basically drains the FJPool, only to re-fill
it again, but sometimes it's a requirement.


    Ron
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/eaa1128e/attachment-0001.html>

From ron.pressler at gmail.com  Wed Oct 16 20:49:58 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 17 Oct 2013 02:49:58 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
Message-ID: <CABg6-qgEXpM8vKyk=6Ufnue7nGY5=OazmY1yi3MPwCyxwXi50A@mail.gmail.com>

On Thu, Oct 17, 2013 at 3:24 AM, Niall Gallagher <niall at npgall.com> wrote:
>
>
> So am I understanding this correctly - could Phaser [I guess you mean
> Quasar] allow us to continue to write code for the thread-per-request model
> (which is definitely more intuitive), but yet underneath the code Quasar
> could intercept the point at which threads block or sleep etc., and swap
> their stacks to the heap?
>

Yes, although we don't intercept the blocking point, but replace low-level
thread-blocking mechanisms with low-level fiber-blocking mechanism.

>
> Could a classic-servlet-style container be written on top of this to
> provide better scalability than the thread-per-request model, but
> transparently?
>
>
Theoretically ? absolutely. In practice it seems that the HTTP protocol is
so heavyweight, that you hit your CPU limit before you hit the threading
limit. I.e. the IO handling overhead exceeds the thread scheduling overhead.


> Thinking even further ahead, ultimately could the stacks (and referenced
> objects) of suspended fibers be serialized outside of the JVM, so number of
> suspended fibers would not even be bound by heap size?
>

This is not easy to do, because you can't really store references to Java
objects outside the heap (they keep moving, and you need the GC to fix your
pointers).


>
>
> On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com> wrote:
>
> Hi.
> I'd like to share with this community something I've been working on for
> the last six months, as well as describe some findings I've had as a result
> regarding Java concurrency.
>
> We've released an open source implementation of true Java lightweight
> threads called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
> and today we unveiled a nice demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that uses Quasar for a simulation of a big space battle.
>
> First, let me explain what I mean by lightweight threads. A lightweight
> thread (called fiber in Quasar) embodies a single flow of code execution,
> and has a stack ? just like a regular thread ? only it's scheduled and
> managed by Java code rather than by the OS. It is lightweight because it
> consumes less memory than an OS thread, and has a much shorter
> context-switch time (more on that later).
>
> A fiber is implemented as a continuation (obtained with the help of
> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
> async mode. The Fiber class implements a very similar API to the Thread
> class. Most importantly is has park and unpark methods (as well as
> getStackTrace and more).
>
> To make mixing threads and fibers easy, we have an abstraction called
> strand. A strand is simply either a fiber or a full blown Java thread. The
> strand abstraction allowed us to easily (almost automatically) retrofit
> java.util.concurrent classes to support either threads or fibers: all you
> do is replace Thread with Strand everywhere, and then replace
> LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
> (sometimes, I've removed some spinning if we're running in a fiber because
> blocking and unblocking is cheap). For example, the spaceships demo in the
> blog post today uses a Phaser to synchronize fibers as well as threads.
>
> *Thread Context Switching*
> Naturally, we've dome some research about the cost of thread
> context-switching. The cost of a context switch depends on many factors.
> For example, a context switch on Linux is much cheaper than a context
> switch on OS X. But even on Linux there is one important detail that
> effects scheduling (perhaps Doug or someone else could elaborate on it): if
> the thread is unblocked by the kernel (because the thread is doing a timed
> sleep or blocking on IO), then the wakeup latency is very small (we
> couldn't beat it with fibers by much). If, however, a thread is unparked by
> another application thread, then it takes its time before getting back to
> action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
> faster than a thread unpark, even on Linux.
>
> *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on
> this mailing list a few months ago, there has been a significant drop in FJ
> performance for async pools in what I think is the latest release. I
> haven't benchmarked it again recently, and Doug said he's working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better than
> external submissions to a FJPool. It doesn't matter, in practice, because
> most submissions to an FJPool are supposed to be internal (forks).
>
> *Phaser*
> At first I was a little concerned about whether a Phaser will perform well
> enough with blocked fibers, especially because unparking a fiber is so
> cheap, and so unparking lots of them would best be done in parallel. My
> concern turned out to be unfounded, because every unblocked thread/fiber
> calls releaseWaiters() when it wakes up, so the first few woken strands
> share the burden of waking the other strands. On the other hand, this also
> means that all woken strands contend on popping from Treiber stack holding
> the waiting strands.
>
> Contention in releaseWaiters is very high. A simple count showed that
> 85-90% of CASs (attempted pops) fail.
>
> Whatever effect this may have on performance is dwarfed by using a phaser
> in the first place: it basically drains the FJPool, only to re-fill it
> again, but sometimes it's a requirement.
>
> Ron
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/0690612b/attachment.html>

From ron.pressler at gmail.com  Wed Oct 16 20:51:49 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 17 Oct 2013 02:51:49 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEIEKBAA.davidcholmes@aapt.net.au>
References: <ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
	<NFBBKALFDCPFIDBNKAPCMEIEKBAA.davidcholmes@aapt.net.au>
Message-ID: <CABg6-qhrq-uC=43sfAa-cNYsHapPSLjTE3u_ULqr+YgYPoJhDA@mail.gmail.com>

Right. So here<https://github.com/puniverse/quasar/tree/master/quasar-core/src/main/java/co/paralleluniverse/fibers/io>we
implement fiber-blocking NIO on top of async NIO.


On Thu, Oct 17, 2013 at 3:47 AM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> Operations that block in the kernel eg blocking I/O, will block the thread
> not just the fiber. To just block the fiber you will still need async IO.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Niall Gallagher
> *Sent:* Thursday, 17 October 2013 10:25 AM
> *To:* concurrency-interest
> *Subject:* Re: [concurrency-interest] ForkJoinPool,Phasers and
> Lightweight Threads
>
> This sounds amazing.
>
> So at the moment, there's a push away from request-per-thread models (e.g.
> classic servlets), towards asynchronous IO in frameworks like Netty and
> actor models, FJP etc. Because number of cores per box is increasing, or
> number of persistent connections etc. is increasing, but we can't create a
> million threads.
>
> So am I understanding this correctly - could Phaser allow us to continue
> to write code for the thread-per-request model (which is definitely more
> intuitive), but yet underneath the code Quasar could intercept the point at
> which threads block or sleep etc., and swap their stacks to the heap?
>
> Could a classic-servlet-style container be written on top of this to
> provide better scalability than the thread-per-request model, but
> transparently?
>
> Thinking even further ahead, ultimately could the stacks (and referenced
> objects) of suspended fibers be serialized outside of the JVM, so number of
> suspended fibers would not even be bound by heap size?
>
> I am wondering though, how would this compare with Java's green threads
> from the old days? Unless I've misunderstood something though, this brings
> with it a huge number of possibilities/opportunities. Awesome stuff.
>
>
>  On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com> wrote:
>
>  Hi.
> I'd like to share with this community something I've been working on for
> the last six months, as well as describe some findings I've had as a result
> regarding Java concurrency.
>
> We've released an open source implementation of true Java lightweight
> threads called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
> and today we unveiled a nice demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that uses Quasar for a simulation of a big space battle.
>
> First, let me explain what I mean by lightweight threads. A lightweight
> thread (called fiber in Quasar) embodies a single flow of code execution,
> and has a stack ? just like a regular thread ? only it's scheduled and
> managed by Java code rather than by the OS. It is lightweight because it
> consumes less memory than an OS thread, and has a much shorter
> context-switch time (more on that later).
>
> A fiber is implemented as a continuation (obtained with the help of
> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
> async mode. The Fiber class implements a very similar API to the Thread
> class. Most importantly is has park and unpark methods (as well as
> getStackTrace and more).
>
> To make mixing threads and fibers easy, we have an abstraction called
> strand. A strand is simply either a fiber or a full blown Java thread. The
> strand abstraction allowed us to easily (almost automatically) retrofit
> java.util.concurrent classes to support either threads or fibers: all you
> do is replace Thread with Strand everywhere, and then replace
> LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
> (sometimes, I've removed some spinning if we're running in a fiber because
> blocking and unblocking is cheap). For example, the spaceships demo in the
> blog post today uses a Phaser to synchronize fibers as well as threads.
>
> *Thread Context Switching*
> Naturally, we've dome some research about the cost of thread
> context-switching. The cost of a context switch depends on many factors.
> For example, a context switch on Linux is much cheaper than a context
> switch on OS X. But even on Linux there is one important detail that
> effects scheduling (perhaps Doug or someone else could elaborate on it): if
> the thread is unblocked by the kernel (because the thread is doing a timed
> sleep or blocking on IO), then the wakeup latency is very small (we
> couldn't beat it with fibers by much). If, however, a thread is unparked by
> another application thread, then it takes its time before getting back to
> action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
> faster than a thread unpark, even on Linux.
>
> *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on
> this mailing list a few months ago, there has been a significant drop in FJ
> performance for async pools in what I think is the latest release. I
> haven't benchmarked it again recently, and Doug said he's working on it.
> Also, last I checked, ThreadPoolExecutorService still performs better than
> external submissions to a FJPool. It doesn't matter, in practice, because
> most submissions to an FJPool are supposed to be internal (forks).
>
> *Phaser*
> At first I was a little concerned about whether a Phaser will perform well
> enough with blocked fibers, especially because unparking a fiber is so
> cheap, and so unparking lots of them would best be done in parallel. My
> concern turned out to be unfounded, because every unblocked thread/fiber
> calls releaseWaiters() when it wakes up, so the first few woken strands
> share the burden of waking the other strands. On the other hand, this also
> means that all woken strands contend on popping from Treiber stack holding
> the waiting strands.
>
> Contention in releaseWaiters is very high. A simple count showed that
> 85-90% of CASs (attempted pops) fail.
>
> Whatever effect this may have on performance is dwarfed by using a phaser
> in the first place: it basically drains the FJPool, only to re-fill it
> again, but sometimes it's a requirement.
>
> Ron
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/fad58a95/attachment-0001.html>

From zhong.j.yu at gmail.com  Wed Oct 16 21:01:07 2013
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 17 Oct 2013 09:01:07 +0800
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <CABg6-qi5BoUqw=zOoO4+5Y3FwCyE_C0nMJvi8i3R2an1xV2sMg@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<525F1859.3090008@oracle.com>
	<CABg6-qhg6=ywLOgPwsP+gXGmLbwkACByNKj+yLGAE-HAKToRLw@mail.gmail.com>
	<525F2A6E.4070300@oracle.com>
	<CABg6-qi5BoUqw=zOoO4+5Y3FwCyE_C0nMJvi8i3R2an1xV2sMg@mail.gmail.com>
Message-ID: <CACuKZqEXvamhJ6+Gy2wYGT0brBqD_RUk0F6z-Dbzw=LEAQDJbQ@mail.gmail.com>

On Thu, Oct 17, 2013 at 8:41 AM, Ron Pressler <ron.pressler at gmail.com> wrote:
>
>> Do fibers have a sticky affinity for the core they are running on?
>
>
> You can assign a fiber to a given FJPool. If you assign affinity to the pool
> threads, then by association, it would work for the fiber. Probably won't be
> effective if you want core-affinity, but very effective for socket affinity
> on a NUMA machine.
>
>> I am trying to figure out where this could be applied.
>>
>> Does this basically eliminate application servers from using fibers?  I
>> suppose one could re-write application servers and all of the APIs to make
>> them fiber friendly.  Thus, the above 100s of method call stack would be
>> broken down into small actors.

Some of the call frames could be eliminated by tail call optimization;
semantically a method call is not necessarily to dive into a sub
process, but to jump to a sibling process.

Maybe Quasar could support TCO, which also helps to reduce the size of
fibers. (I think it's programmer's responsibility to explicitly mark a
call as tail call to permit compiler optimization)

>
>
> First, people are already breaking up their applications into small pieces
> for scalability reasons, by using actors, or stuff like JavaRx or Storm.
> Look at how LinkedIn, Netflix or Twitter structure their code. What Quasar
> tries to do is provide the concurrency while trying to maintain as much as
> possible an intuitive and familiar programming model. Second, we've used
> Quasar in application servers: much of the 100-deep call stack is actually
> part of the framework (like Tomcat); we've used fibers below that, i.e.
> starting in the servlet handler.
>
>>
>> Does this eliminate JDBC access since JDBC drivers typically have 5-10
>> methods between the API and blocking on a socket call to the DB?
>
>
> We have a JDBC layer for Quasar, and the idea is simple. All blocking IO
> calls are done in a separate thread pool. A fiber blocking on a JDBC call
> essentially dispatches the request to the IO thread pool, and then parks
> until it's unparked by the IO thread when the call complete. The fiber
> doesn't directly block on IO (we don't want the FJ worker to block on IO).
> Obviously, an RDBMS has a certain capacity, and supports a given number of
> concurrent connections ? fibers can't manufacture better DB throughput,
> (though they might allow more DB request to queue up, and let the DB driver
> or the DB benefit from a full pipeline, provided that the DB capacity
> exceeds the plain-thread capacity of the client, which I guess is quite
> possible).
>
>>
>>
>> I don't see this being terribly helpful on the client side since the core
>> count is low and hence concurrency is not as useful.  So, I figure this is
>> best for servers.  Where do you see this being used?
>>
>
> Servers seem like the natural place, but someone already wants to try it on
> Android (which I personally found surprising, but I'm not too familiar with
> mobile app development).
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From ron.pressler at gmail.com  Thu Oct 17 03:44:28 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 17 Oct 2013 09:44:28 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <CACuKZqEXvamhJ6+Gy2wYGT0brBqD_RUk0F6z-Dbzw=LEAQDJbQ@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<525F1859.3090008@oracle.com>
	<CABg6-qhg6=ywLOgPwsP+gXGmLbwkACByNKj+yLGAE-HAKToRLw@mail.gmail.com>
	<525F2A6E.4070300@oracle.com>
	<CABg6-qi5BoUqw=zOoO4+5Y3FwCyE_C0nMJvi8i3R2an1xV2sMg@mail.gmail.com>
	<CACuKZqEXvamhJ6+Gy2wYGT0brBqD_RUk0F6z-Dbzw=LEAQDJbQ@mail.gmail.com>
Message-ID: <CABg6-qjT1S1eKcitWqeyUzuF3nrQTtkBy28ahL0KBRgq5Rqrnw@mail.gmail.com>

I've thought about TCO but it's not so simple. We could do it if it's a
simple recursion (function A calls itself), provided that A blocks. But if
A calls B, and B calls A it can't be done without reflection or method
handles. TCO is best left for the JVM; Java 9, perhaps?


On Thu, Oct 17, 2013 at 4:01 AM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Thu, Oct 17, 2013 at 8:41 AM, Ron Pressler <ron.pressler at gmail.com>
> wrote:
> >
> >> Do fibers have a sticky affinity for the core they are running on?
> >
> >
> > You can assign a fiber to a given FJPool. If you assign affinity to the
> pool
> > threads, then by association, it would work for the fiber. Probably
> won't be
> > effective if you want core-affinity, but very effective for socket
> affinity
> > on a NUMA machine.
> >
> >> I am trying to figure out where this could be applied.
> >>
> >> Does this basically eliminate application servers from using fibers?  I
> >> suppose one could re-write application servers and all of the APIs to
> make
> >> them fiber friendly.  Thus, the above 100s of method call stack would be
> >> broken down into small actors.
>
> Some of the call frames could be eliminated by tail call optimization;
> semantically a method call is not necessarily to dive into a sub
> process, but to jump to a sibling process.
>
> Maybe Quasar could support TCO, which also helps to reduce the size of
> fibers. (I think it's programmer's responsibility to explicitly mark a
> call as tail call to permit compiler optimization)
>
> >
> >
> > First, people are already breaking up their applications into small
> pieces
> > for scalability reasons, by using actors, or stuff like JavaRx or Storm.
> > Look at how LinkedIn, Netflix or Twitter structure their code. What
> Quasar
> > tries to do is provide the concurrency while trying to maintain as much
> as
> > possible an intuitive and familiar programming model. Second, we've used
> > Quasar in application servers: much of the 100-deep call stack is
> actually
> > part of the framework (like Tomcat); we've used fibers below that, i.e.
> > starting in the servlet handler.
> >
> >>
> >> Does this eliminate JDBC access since JDBC drivers typically have 5-10
> >> methods between the API and blocking on a socket call to the DB?
> >
> >
> > We have a JDBC layer for Quasar, and the idea is simple. All blocking IO
> > calls are done in a separate thread pool. A fiber blocking on a JDBC call
> > essentially dispatches the request to the IO thread pool, and then parks
> > until it's unparked by the IO thread when the call complete. The fiber
> > doesn't directly block on IO (we don't want the FJ worker to block on
> IO).
> > Obviously, an RDBMS has a certain capacity, and supports a given number
> of
> > concurrent connections ? fibers can't manufacture better DB throughput,
> > (though they might allow more DB request to queue up, and let the DB
> driver
> > or the DB benefit from a full pipeline, provided that the DB capacity
> > exceeds the plain-thread capacity of the client, which I guess is quite
> > possible).
> >
> >>
> >>
> >> I don't see this being terribly helpful on the client side since the
> core
> >> count is low and hence concurrency is not as useful.  So, I figure this
> is
> >> best for servers.  Where do you see this being used?
> >>
> >
> > Servers seem like the natural place, but someone already wants to try it
> on
> > Android (which I personally found surprising, but I'm not too familiar
> with
> > mobile app development).
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/097eca22/attachment.html>

From nathan.reynolds at oracle.com  Thu Oct 17 12:12:44 2013
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 17 Oct 2013 09:12:44 -0700
Subject: [concurrency-interest] ForkJoinPool,
 Phasers and Lightweight Threads
In-Reply-To: <CABg6-qgEXpM8vKyk=6Ufnue7nGY5=OazmY1yi3MPwCyxwXi50A@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>	<ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
	<CABg6-qgEXpM8vKyk=6Ufnue7nGY5=OazmY1yi3MPwCyxwXi50A@mail.gmail.com>
Message-ID: <52600C7C.8060200@oracle.com>

On 10/16/2013 5:49 PM, Ron Pressler wrote:
>
> On Thu, Oct 17, 2013 at 3:24 AM, Niall Gallagher <niall at npgall.com 
> <mailto:niall at npgall.com>> wrote:
>
>
>     So am I understanding this correctly - could Phaser [I guess you
>     mean Quasar] allow us to continue to write code for the
>     thread-per-request model (which is definitely more intuitive), but
>     yet underneath the code Quasar could intercept the point at which
>     threads block or sleep etc., and swap their stacks to the heap?
>
>
> Yes, although we don't intercept the blocking point, but replace 
> low-level thread-blocking mechanisms with low-level fiber-blocking 
> mechanism.
>
>
>     Could a classic-servlet-style container be written on top of this
>     to provide better scalability than the thread-per-request model,
>     but transparently?
>
>
> Theoretically -- absolutely. In practice it seems that the HTTP 
> protocol is so heavyweight, that you hit your CPU limit before you hit 
> the threading limit. I.e. the IO handling overhead exceeds the thread 
> scheduling overhead.
>
>     Thinking even further ahead, ultimately could the stacks (and
>     referenced objects) of suspended fibers be serialized outside of
>     the JVM, so number of suspended fibers would not even be bound by
>     heap size?
>
>
> This is not easy to do, because you can't really store references to 
> Java objects outside the heap (they keep moving, and you need the GC 
> to fix your pointers).
The fiber's stack object has an array of references.  If using Java's 
standard serialization, the referenced objects will be serialized as 
well (if they are Serializable or Externalizable). Thus, the entire 
object graph that the fiber references will be serialized.  If this were 
doable, you could move the fiber to another JVM or even another machine.

If 2 fibers point to the same object, then both serializations will 
contain that object.  In a worst case scenario, the entire heap will be 
serialized for every fiber.  Furthermore, when loading a fiber, 
duplicate instances will be created and extra memory will be consumed.

This doesn't seem feasible.
>
>     On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com
>     <mailto:ron.pressler at gmail.com>> wrote:
>
>>     Hi.
>>     I'd like to share with this community something I've been working
>>     on for the last six months, as well as describe some findings
>>     I've had as a result regarding Java concurrency.
>>
>>     We've released an open source implementation of true Java
>>     lightweight threads called Quasar
>>     <https://github.com/puniverse/quasar>.
>>     There's an introductory blog post
>>     <http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
>>     and today we unveiled a nice demo
>>     <http://blog.paralleluniverse.co/post/64210769930/spaceships2>
>>     that uses Quasar for a simulation of a big space battle.
>>
>>     First, let me explain what I mean by lightweight threads. A
>>     lightweight thread (called fiber in Quasar) embodies a single
>>     flow of code execution, and has a stack -- just like a regular
>>     thread -- only it's scheduled and managed by Java code rather
>>     than by the OS. It is lightweight because it consumes less memory
>>     than an OS thread, and has a much shorter context-switch time
>>     (more on that later).
>>
>>     A fiber is implemented as a continuation (obtained with the help
>>     of runtime bytecode instrumentation) scheduled on top of a
>>     ForkJoinPool in async mode. The Fiber class implements a very
>>     similar API to the Thread class. Most importantly is has park and
>>     unpark methods (as well as getStackTrace and more).
>>
>>     To make mixing threads and fibers easy, we have an abstraction
>>     called strand. A strand is simply either a fiber or a full blown
>>     Java thread. The strand abstraction allowed us to easily (almost
>>     automatically) retrofit java.util.concurrent classes to support
>>     either threads or fibers: all you do is replace Thread with
>>     Strand everywhere, and then replace LockSupoort.park/unpark with
>>     Strand.park/unpark, and everything just works! (sometimes, I've
>>     removed some spinning if we're running in a fiber because
>>     blocking and unblocking is cheap). For example, the spaceships
>>     demo in the blog post today uses a Phaser to synchronize fibers
>>     as well as threads.
>>
>>     *Thread Context Switching*
>>     Naturally, we've dome some research about the cost of thread
>>     context-switching. The cost of a context switch depends on many
>>     factors. For example, a context switch on Linux is much cheaper
>>     than a context switch on OS X. But even on Linux there is one
>>     important detail that effects scheduling (perhaps Doug or someone
>>     else could elaborate on it): if the thread is unblocked by the
>>     kernel (because the thread is doing a timed sleep or blocking on
>>     IO), then the wakeup latency is very small (we couldn't beat it
>>     with fibers by much). If, however, a thread is unparked by
>>     another application thread, then it takes its time before getting
>>     back to action. A fiber context-switch (basically, a FJTask.fork)
>>     is at least 10x faster than a thread unpark, even on Linux.
>>
>>     *ForkJoinPool Performance*
>>     Fork join is awesome and performs very well. However, as I
>>     reported on this mailing list a few months ago, there has been a
>>     significant drop in FJ performance for async pools in what I
>>     think is the latest release. I haven't benchmarked it again
>>     recently, and Doug said he's working on it.
>>     Also, last I checked, ThreadPoolExecutorService still performs
>>     better than external submissions to a FJPool. It doesn't matter,
>>     in practice, because most submissions to an FJPool are supposed
>>     to be internal (forks).
>>
>>     *Phaser*
>>     At first I was a little concerned about whether a Phaser will
>>     perform well enough with blocked fibers, especially because
>>     unparking a fiber is so cheap, and so unparking lots of them
>>     would best be done in parallel. My concern turned out to be
>>     unfounded, because every unblocked thread/fiber calls
>>     releaseWaiters() when it wakes up, so the first few woken strands
>>     share the burden of waking the other strands. On the other hand,
>>     this also means that all woken strands contend on popping from
>>     Treiber stack holding the waiting strands.
>>
>>     Contention in releaseWaiters is very high. A simple count showed
>>     that 85-90% of CASs (attempted pops) fail.
>>
>>     Whatever effect this may have on performance is dwarfed by using
>>     a phaser in the first place: it basically drains the FJPool, only
>>     to re-fill it again, but sometimes it's a requirement.
>>
>>     Ron
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131017/5f95a134/attachment.html>

From niall at npgall.com  Fri Oct 18 14:10:00 2013
From: niall at npgall.com (Niall Gallagher)
Date: Fri, 18 Oct 2013 19:10:00 +0100
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <52600C7C.8060200@oracle.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
	<CABg6-qgEXpM8vKyk=6Ufnue7nGY5=OazmY1yi3MPwCyxwXi50A@mail.gmail.com>
	<52600C7C.8060200@oracle.com>
Message-ID: <CABc862JdR098YFv-P5z0GoBJF6ma-u1qhprb7woadYvun5b1Ug@mail.gmail.com>

I wouldn't say it's infeasible to swap stacks off-heap (or to move stacks
to remote machines). Also it's not always necessary to serialize the entire
stack. It would only be necessary to serialize the top stack frame(s) in
many cases.

There are already libraries which allow Java code which is executing to be
migrated between JVMs statefully (http://code.google.com/p/mobility-rpc/),
with the proviso in that case, that the code specifies a closure before the
jump/migration, which is used to resume its execution on the remote side.

Above, references from the enclosing scope - objects created earlier in the
same method invocation prior to the jump i.e. in the top stack frame, can
be captured, and referenced objects are migrated to the remote machine.

So, we have an example of a thread's top stack frame (or an approximation),
being serialized and migrated to a remote machine, and being transplanted
onto different base stack, where execution resumes.

In a managed execution environment, like a servlet container, it would not
be necessary to serialize the lower stack frames belonging to the
container. These can be recreated as above. Application code deployed to a
container, cannot access variables in lower stack frames. So lower stack
frames are effectively transient, and can be recreated when a fiber needs
to be rescheduled.

The idea that Quasar might provide us with a model of a program's own
execution which can be manipulated explicitly, is pretty interesting.

I was originally thinking of simpler cases such as a web server handling
persistent HTTP connections. Asynchronous servlets were added in servlet
3.0 to handle this, but if we had Quasar back then, explicit asynchronous
servlets might have been unnecessary. When a thread blocked waiting for a
new event to arrive, Quasar could have unscheduled it and moved its stack
to the heap.

So from there - it may become useful to persist stacks off-heap (top frames
only). The restrictions on what kinds of objects can be referenced from the
stack, would not be unlike the restrictions on what kinds of objects should
be stored in web sessions. We're talking about restrictive programming
frameworks here anyway (think JSPs). If a programmer stores a
non-serializable object in a web session, it results in an exception and
the session is not persisted. A Quasar-based web server could log a warning
if it could not serialize a stack. Programs abiding by the rules would get
better scalability.


On 17 October 2013 17:12, Nathan Reynolds <nathan.reynolds at oracle.com>wrote:

>  On 10/16/2013 5:49 PM, Ron Pressler wrote:
>
>
>  On Thu, Oct 17, 2013 at 3:24 AM, Niall Gallagher <niall at npgall.com>wrote:
>>
>>
>>  So am I understanding this correctly - could Phaser [I guess you mean
>> Quasar] allow us to continue to write code for the thread-per-request model
>> (which is definitely more intuitive), but yet underneath the code Quasar
>> could intercept the point at which threads block or sleep etc., and swap
>> their stacks to the heap?
>>
>
>  Yes, although we don't intercept the blocking point, but replace
> low-level thread-blocking mechanisms with low-level fiber-blocking
> mechanism.
>
>>
>>  Could a classic-servlet-style container be written on top of this to
>> provide better scalability than the thread-per-request model, but
>> transparently?
>>
>>
>  Theoretically ? absolutely. In practice it seems that the HTTP protocol
> is so heavyweight, that you hit your CPU limit before you hit the threading
> limit. I.e. the IO handling overhead exceeds the thread scheduling overhead.
>
>
>>  Thinking even further ahead, ultimately could the stacks (and
>> referenced objects) of suspended fibers be serialized outside of the JVM,
>> so number of suspended fibers would not even be bound by heap size?
>>
>
>  This is not easy to do, because you can't really store references to
> Java objects outside the heap (they keep moving, and you need the GC to fix
> your pointers).
>
> The fiber's stack object has an array of references.  If using Java's
> standard serialization, the referenced objects will be serialized as well
> (if they are Serializable or Externalizable).  Thus, the entire object
> graph that the fiber references will be serialized.  If this were doable,
> you could move the fiber to another JVM or even another machine.
>
> If 2 fibers point to the same object, then both serializations will
> contain that object.  In a worst case scenario, the entire heap will be
> serialized for every fiber.  Furthermore, when loading a fiber, duplicate
> instances will be created and extra memory will be consumed.
>
> This doesn't seem feasible.
>
>   On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com> wrote:
>>
>>    Hi.
>> I'd like to share with this community something I've been working on for
>> the last six months, as well as describe some findings I've had as a result
>> regarding Java concurrency.
>>
>>  We've released an open source implementation of true Java lightweight
>> threads called Quasar <https://github.com/puniverse/quasar>.
>> There's an introductory blog post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
>> and today we unveiled a nice demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that uses Quasar for a simulation of a big space battle.
>>
>>  First, let me explain what I mean by lightweight threads. A lightweight
>> thread (called fiber in Quasar) embodies a single flow of code execution,
>> and has a stack ? just like a regular thread ? only it's scheduled and
>> managed by Java code rather than by the OS. It is lightweight because it
>> consumes less memory than an OS thread, and has a much shorter
>> context-switch time (more on that later).
>>
>>  A fiber is implemented as a continuation (obtained with the help of
>> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
>> async mode. The Fiber class implements a very similar API to the Thread
>> class. Most importantly is has park and unpark methods (as well as
>> getStackTrace and more).
>>
>>  To make mixing threads and fibers easy, we have an abstraction called
>> strand. A strand is simply either a fiber or a full blown Java thread. The
>> strand abstraction allowed us to easily (almost automatically) retrofit
>> java.util.concurrent classes to support either threads or fibers: all you
>> do is replace Thread with Strand everywhere, and then replace
>> LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
>> (sometimes, I've removed some spinning if we're running in a fiber because
>> blocking and unblocking is cheap). For example, the spaceships demo in the
>> blog post today uses a Phaser to synchronize fibers as well as threads.
>>
>>  *Thread Context Switching*
>> Naturally, we've dome some research about the cost of thread
>> context-switching. The cost of a context switch depends on many factors.
>> For example, a context switch on Linux is much cheaper than a context
>> switch on OS X. But even on Linux there is one important detail that
>> effects scheduling (perhaps Doug or someone else could elaborate on it): if
>> the thread is unblocked by the kernel (because the thread is doing a timed
>> sleep or blocking on IO), then the wakeup latency is very small (we
>> couldn't beat it with fibers by much). If, however, a thread is unparked by
>> another application thread, then it takes its time before getting back to
>> action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
>> faster than a thread unpark, even on Linux.
>>
>>  *ForkJoinPool Performance*
>> Fork join is awesome and performs very well. However, as I reported on
>> this mailing list a few months ago, there has been a significant drop in FJ
>> performance for async pools in what I think is the latest release. I
>> haven't benchmarked it again recently, and Doug said he's working on it.
>> Also, last I checked, ThreadPoolExecutorService still performs better
>> than external submissions to a FJPool. It doesn't matter, in practice,
>> because most submissions to an FJPool are supposed to be internal (forks).
>>
>>  *Phaser*
>> At first I was a little concerned about whether a Phaser will perform
>> well enough with blocked fibers, especially because unparking a fiber is so
>> cheap, and so unparking lots of them would best be done in parallel. My
>> concern turned out to be unfounded, because every unblocked thread/fiber
>> calls releaseWaiters() when it wakes up, so the first few woken strands
>> share the burden of waking the other strands. On the other hand, this also
>> means that all woken strands contend on popping from Treiber stack holding
>> the waiting strands.
>>
>>  Contention in releaseWaiters is very high. A simple count showed that
>> 85-90% of CASs (attempted pops) fail.
>>
>>  Whatever effect this may have on performance is dwarfed by using a
>> phaser in the first place: it basically drains the FJPool, only to re-fill
>> it again, but sometimes it's a requirement.
>>
>>  Ron
>>   _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131018/f200e561/attachment-0001.html>

From ron.pressler at gmail.com  Fri Oct 18 16:00:47 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Fri, 18 Oct 2013 22:00:47 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <CABc862JdR098YFv-P5z0GoBJF6ma-u1qhprb7woadYvun5b1Ug@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<ECACEB7A-4C21-483D-9B23-44FB7F88DB11@npgall.com>
	<CABg6-qgEXpM8vKyk=6Ufnue7nGY5=OazmY1yi3MPwCyxwXi50A@mail.gmail.com>
	<52600C7C.8060200@oracle.com>
	<CABc862JdR098YFv-P5z0GoBJF6ma-u1qhprb7woadYvun5b1Ug@mail.gmail.com>
Message-ID: <CABg6-qhr8FGPieipykS4w0MGoO4Ub+XNQ1ty4h_8R8deO9E--A@mail.gmail.com>

>
> I was originally thinking of simpler cases such as a web server handling
> persistent HTTP connections. Asynchronous servlets were added in servlet
> 3.0 to handle this, but if we had Quasar back then, explicit asynchronous
> servlets might have been unnecessary. When a thread blocked waiting for a
> new event to arrive, Quasar could have unscheduled it and moved its stack
> to the heap.
>

We will be releasing async-servlet+web socket+Quasar integration very, very
soon (all open source). Performance and scalability-wise, the benefits are
significant for long connections (2 seconds and up), because, as I've said
before, HTTP handling has a very high overhead, that for shorter requests
you might as well let your servlet container spawn a few thousand threads.
The container's overhead will take up all of your CPU power before you
reach the OS's capability to handle this number of blocked threads.


>
> So from there - it may become useful to persist stacks off-heap (top
> frames only). The restrictions on what kinds of objects can be referenced
> from the stack, would not be unlike the restrictions on what kinds of
> objects should be stored in web sessions. We're talking about restrictive
> programming frameworks here anyway (think JSPs). If a programmer stores a
> non-serializable object in a web session, it results in an exception and
> the session is not persisted. A Quasar-based web server could log a warning
> if it could not serialize a stack. Programs abiding by the rules would get
> better scalability.
>
> Restricting which object refs could be on the stack in Quasar is trivial.
I would like to hear more about the use-case you're envisioning ? please
send me a private e-mail because I don't know if this particular discussion
belongs here.

Ron


>
> On 17 October 2013 17:12, Nathan Reynolds <nathan.reynolds at oracle.com>wrote:
>
>>  On 10/16/2013 5:49 PM, Ron Pressler wrote:
>>
>>
>>  On Thu, Oct 17, 2013 at 3:24 AM, Niall Gallagher <niall at npgall.com>wrote:
>>>
>>>
>>>  So am I understanding this correctly - could Phaser [I guess you mean
>>> Quasar] allow us to continue to write code for the thread-per-request model
>>> (which is definitely more intuitive), but yet underneath the code Quasar
>>> could intercept the point at which threads block or sleep etc., and swap
>>> their stacks to the heap?
>>>
>>
>>  Yes, although we don't intercept the blocking point, but replace
>> low-level thread-blocking mechanisms with low-level fiber-blocking
>> mechanism.
>>
>>>
>>>  Could a classic-servlet-style container be written on top of this to
>>> provide better scalability than the thread-per-request model, but
>>> transparently?
>>>
>>>
>>  Theoretically ? absolutely. In practice it seems that the HTTP protocol
>> is so heavyweight, that you hit your CPU limit before you hit the threading
>> limit. I.e. the IO handling overhead exceeds the thread scheduling overhead.
>>
>>
>>>  Thinking even further ahead, ultimately could the stacks (and
>>> referenced objects) of suspended fibers be serialized outside of the JVM,
>>> so number of suspended fibers would not even be bound by heap size?
>>>
>>
>>  This is not easy to do, because you can't really store references to
>> Java objects outside the heap (they keep moving, and you need the GC to fix
>> your pointers).
>>
>> The fiber's stack object has an array of references.  If using Java's
>> standard serialization, the referenced objects will be serialized as well
>> (if they are Serializable or Externalizable).  Thus, the entire object
>> graph that the fiber references will be serialized.  If this were doable,
>> you could move the fiber to another JVM or even another machine.
>>
>> If 2 fibers point to the same object, then both serializations will
>> contain that object.  In a worst case scenario, the entire heap will be
>> serialized for every fiber.  Furthermore, when loading a fiber, duplicate
>> instances will be created and extra memory will be consumed.
>>
>> This doesn't seem feasible.
>>
>>   On 16 Oct 2013, at 22:32, Ron Pressler <ron.pressler at gmail.com> wrote:
>>>
>>>    Hi.
>>> I'd like to share with this community something I've been working on for
>>> the last six months, as well as describe some findings I've had as a result
>>> regarding Java concurrency.
>>>
>>>  We've released an open source implementation of true Java lightweight
>>> threads called Quasar <https://github.com/puniverse/quasar>.
>>> There's an introductory blog post<http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>,
>>> and today we unveiled a nice demo<http://blog.paralleluniverse.co/post/64210769930/spaceships2>that uses Quasar for a simulation of a big space battle.
>>>
>>>  First, let me explain what I mean by lightweight threads. A
>>> lightweight thread (called fiber in Quasar) embodies a single flow of code
>>> execution, and has a stack ? just like a regular thread ? only it's
>>> scheduled and managed by Java code rather than by the OS. It is lightweight
>>> because it consumes less memory than an OS thread, and has a much shorter
>>> context-switch time (more on that later).
>>>
>>>  A fiber is implemented as a continuation (obtained with the help of
>>> runtime bytecode instrumentation) scheduled on top of a ForkJoinPool in
>>> async mode. The Fiber class implements a very similar API to the Thread
>>> class. Most importantly is has park and unpark methods (as well as
>>> getStackTrace and more).
>>>
>>>  To make mixing threads and fibers easy, we have an abstraction called
>>> strand. A strand is simply either a fiber or a full blown Java thread. The
>>> strand abstraction allowed us to easily (almost automatically) retrofit
>>> java.util.concurrent classes to support either threads or fibers: all you
>>> do is replace Thread with Strand everywhere, and then replace
>>> LockSupoort.park/unpark with Strand.park/unpark, and everything just works!
>>> (sometimes, I've removed some spinning if we're running in a fiber because
>>> blocking and unblocking is cheap). For example, the spaceships demo in the
>>> blog post today uses a Phaser to synchronize fibers as well as threads.
>>>
>>>  *Thread Context Switching*
>>> Naturally, we've dome some research about the cost of thread
>>> context-switching. The cost of a context switch depends on many factors.
>>> For example, a context switch on Linux is much cheaper than a context
>>> switch on OS X. But even on Linux there is one important detail that
>>> effects scheduling (perhaps Doug or someone else could elaborate on it): if
>>> the thread is unblocked by the kernel (because the thread is doing a timed
>>> sleep or blocking on IO), then the wakeup latency is very small (we
>>> couldn't beat it with fibers by much). If, however, a thread is unparked by
>>> another application thread, then it takes its time before getting back to
>>> action. A fiber context-switch (basically, a FJTask.fork) is at least 10x
>>> faster than a thread unpark, even on Linux.
>>>
>>>  *ForkJoinPool Performance*
>>> Fork join is awesome and performs very well. However, as I reported on
>>> this mailing list a few months ago, there has been a significant drop in FJ
>>> performance for async pools in what I think is the latest release. I
>>> haven't benchmarked it again recently, and Doug said he's working on it.
>>> Also, last I checked, ThreadPoolExecutorService still performs better
>>> than external submissions to a FJPool. It doesn't matter, in practice,
>>> because most submissions to an FJPool are supposed to be internal (forks).
>>>
>>>  *Phaser*
>>> At first I was a little concerned about whether a Phaser will perform
>>> well enough with blocked fibers, especially because unparking a fiber is so
>>> cheap, and so unparking lots of them would best be done in parallel. My
>>> concern turned out to be unfounded, because every unblocked thread/fiber
>>> calls releaseWaiters() when it wakes up, so the first few woken strands
>>> share the burden of waking the other strands. On the other hand, this also
>>> means that all woken strands contend on popping from Treiber stack holding
>>> the waiting strands.
>>>
>>>  Contention in releaseWaiters is very high. A simple count showed that
>>> 85-90% of CASs (attempted pops) fail.
>>>
>>>  Whatever effect this may have on performance is dwarfed by using a
>>> phaser in the first place: it basically drains the FJPool, only to re-fill
>>> it again, but sometimes it's a requirement.
>>>
>>>  Ron
>>>   _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131018/5af90932/attachment-0001.html>

From dl at cs.oswego.edu  Sun Oct 20 16:45:56 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 20 Oct 2013 16:45:56 -0400
Subject: [concurrency-interest] ForkJoinPool,
 Phasers and Lightweight Threads
In-Reply-To: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
Message-ID: <52644104.5050200@cs.oswego.edu>

On 10/16/2013 05:32 PM, Ron Pressler wrote:
> We've released an open source implementation of true Java lightweight threads
> called Quasar <https://github.com/puniverse/quasar>.
> There's an introductory blog post
> <http://blog.paralleluniverse.co/post/49445260575/quasar-pulsar>, and today we
> unveiled a nice demo
> <http://blog.paralleluniverse.co/post/64210769930/spaceships2> that uses Quasar
> for a simulation of a big space battle.


It's always nice to see lightweight task frameworks built on top
of FJ and related j.u.c components. That's why we make them.

>
> *ForkJoinPool Performance*
> Fork join is awesome and performs very well. However, as I reported on this
> mailing list a few months ago, there has been a significant drop in FJ
> performance for async pools in what I think is the latest release. I haven't
> benchmarked it again recently, and Doug said he's working on it.

Looking at this more, there wasn't a drop for asyncs in general after last
major update pass (about 6 months ago). Some usage patterns
(including, possibly, yours) could encounter more ramp-up overhead,
but most usages experience less delay to parallelizing
computations. It is sometimes possible to control these effects
yourself by managing granularity: All other things being equal,
a busy pool likes big tasks, an idle pool small ones. For an
example of how to arrange this, see the sample code from a paper
a few years ago where we did this for graph traversal algorithms.
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/TorusSpanningTree.java?view=log

-Doug


From kimo at webnetic.net  Sun Oct 20 17:29:41 2013
From: kimo at webnetic.net (Kimo Crossman)
Date: Sun, 20 Oct 2013 16:29:41 -0500
Subject: [concurrency-interest] "Everything You Always Wanted to Know About
 Synchronization but Were Afraid to Ask"
Message-ID: <CALV1V48PMLR+=thes5u1-qi5=DVbb5z2-n=O4SfNFdLCb-ko0Q@mail.gmail.com>

Tudor David, Rachid Guerraoui, Vasileios Trigonakis
School of Computer and Communication Sciences,
Ecole Polytechnique F ? ed? erale de Lausanne (EPFL), Switzerland

SOSP?13, Nov. 3?6, 2013, Farmington, Pennsylvania, USA

Paper:
http://sigops.org/sosp/sosp13/papers/p33-david.pdf

Software
https://github.com/tudordavid/libslock
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131020/ab0dd795/attachment.html>

From ron.pressler at gmail.com  Sun Oct 20 17:49:50 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Sun, 20 Oct 2013 23:49:50 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <52644104.5050200@cs.oswego.edu>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<52644104.5050200@cs.oswego.edu>
Message-ID: <CABg6-qizVmPE85n11JBpCZN6peNOL-29jOC8rX40FfdfS5errQ@mail.gmail.com>

On Sun, Oct 20, 2013 at 11:45 PM, Doug Lea <dl at cs.oswego.edu> wrote:

>
> Looking at this more, there wasn't a drop for asyncs in general after last
> major update pass (about 6 months ago). Some usage patterns
> (including, possibly, yours) could encounter more ramp-up overhead,
> but most usages experience less delay to parallelizing
> computations.


The problem is that async pools (that are at the core of many JVM-based
messaging/scheduling frameworks) are not parallelizing a computation, but
using FJ as a good replacement for TPExecutorService in the case that lots
of tasks fork new tasks; so it's used for concurrency rather than
parallelism, and there's no computation that's known in advance, whose
parallelism granularity you could control (if I understand what you're
saying correctly).

This is just me clumsily trying to nudge you on an issue we discussed back
in April when I hypothesized that the problem lies in the call to
signalWork() within WorkQueue.push(). Back then you said:

"The underlying issue is that the pushing task does not know that
the single worker is already available, so activates another.
(It can take a few dozen nanoseconds for workers to rescan before
idling.) So it is not so much parallelism-level as intrinsic raciness.
This turns out to be a common issue when processing small Streams
in upcoming jdk8 support, so I've been working to improve it.
Stay tuned..."

And in June, when performance dropped, you said:

"Yes, some handling for pools run in async mode (which is not common)
got a little worse in the course of improving vastly more common cases.
Most of this can be reinstated though, which on a quick check of
a quick touch-up recovers performance on your test case. Stay tuned."

(To which some members of the community replied and emphasized the
importance of the async mode.)

I guess what I'm asking is, what is the status of these changes? It's just
that FJ, due to its impressive implementation, has become the JDK's
"concurrency/parallelism engine", so even minor changes are important.

Also, any thoughts about the contention in Phaser.releaseWaiters()? I'm not
saying it's a problem, but I'd love to hear your thoughts on the matter.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131020/ddedfd29/attachment.html>

From dl at cs.oswego.edu  Sun Oct 20 18:46:57 2013
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 20 Oct 2013 18:46:57 -0400
Subject: [concurrency-interest] ForkJoinPool,
 Phasers and Lightweight Threads
In-Reply-To: <CABg6-qizVmPE85n11JBpCZN6peNOL-29jOC8rX40FfdfS5errQ@mail.gmail.com>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<52644104.5050200@cs.oswego.edu>
	<CABg6-qizVmPE85n11JBpCZN6peNOL-29jOC8rX40FfdfS5errQ@mail.gmail.com>
Message-ID: <52645D61.1020305@cs.oswego.edu>

On 10/20/2013 05:49 PM, Ron Pressler wrote:

> And in June, when performance dropped, you said:
>
> "Yes, some handling for pools run in async mode (which is not common) got a
> little worse in the course of improving vastly more common cases. Most of
> this can be reinstated though, which on a quick check of a quick touch-up
> recovers performance on your test case. Stay tuned."

These were folded into other updates that could have lost
some impact on your case; what's there now is
the best tradeoff I know of. (While frameworks like
ForkJoin seem to never become "finished", I don't
anticipate further changes for JDK8 release.)

The issues remain the same though.
We must wake up threads if we do not know that there is
already sufficient parallelism, which is a racy problem,
so must be addressed conservatively. When there is not
intrinsic parallelism in a set of tasks, some/most wakeups can be
wasted, and generate more overhead as those unneeded threads
re-block. In most use cases, this loss is outweighed by other
gains. In others, you can reduce impact to near-nothing by
submitting fewer bigger tasks (even those that just split
into smaller tasks when submitted). But if there is essentially
never any task parallelism, it might be simpler to just use a
singleton FJP for them; Or some other executor -- using
the full ForkJoin framework is not often the best way
to implement a producer-consumer design with a single consumer.
Which seems to be approximately what you do.

> Also, any thoughts about the contention in Phaser.releaseWaiters()? I'm not
> saying it's a problem, but I'd love to hear your thoughts on the matter.

Sorry; about your...

On 10/16/2013 05:32 PM, Ron Pressler wrote:
> Contention in releaseWaiters is very high. A simple count showed that 85-90%
> of CASs (attempted pops) fail.

Normally, the better throughput of parallel releases outweighs the
increased per-thread spin/fail rates. But the reason Tiered sub-phasers
are available is to allow you to split things up when contention dominates,
at the expense of some overhead (plus a little more work to set them up.)

-Doug


From andrew_nuss at yahoo.com  Sun Oct 20 23:21:08 2013
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Sun, 20 Oct 2013 20:21:08 -0700 (PDT)
Subject: [concurrency-interest] implementing reentrant locks with
	Thread.currentThread
Message-ID: <1382325668.19344.YahooMailNeo@web141101.mail.bf1.yahoo.com>

Hi,


I was wondering, if one is building a type of re-entrant lock, do you get better performance by paying the cost of Thread.currentThread() for each lock operation, or using a ThreadLocal variable.? If one chooses the latter, is there an impact by having lots of effective thread local storage bloat?

Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131020/90df4962/attachment.html>

From davidcholmes at aapt.net.au  Sun Oct 20 23:28:32 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 21 Oct 2013 13:28:32 +1000
Subject: [concurrency-interest] implementing reentrant locks
	withThread.currentThread
In-Reply-To: <1382325668.19344.YahooMailNeo@web141101.mail.bf1.yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEKAKBAA.davidcholmes@aapt.net.au>

Andy,

ThreadLocal.get has to use Thread.currentThread() itself so a ThreadLocal
always going to be more expensive than just using currentThread(). Plus
currentThread() is optimized in the VM.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andy Nuss
  Sent: Monday, 21 October 2013 1:21 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] implementing reentrant locks
withThread.currentThread


  Hi,



  I was wondering, if one is building a type of re-entrant lock, do you get
better performance by paying the cost of Thread.currentThread() for each
lock operation, or using a ThreadLocal variable.  If one chooses the latter,
is there an impact by having lots of effective thread local storage bloat?


  Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131021/1e448ac5/attachment-0001.html>

From ron.pressler at gmail.com  Mon Oct 21 04:09:29 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Mon, 21 Oct 2013 10:09:29 +0200
Subject: [concurrency-interest] ForkJoinPool,
	Phasers and Lightweight Threads
In-Reply-To: <52645D61.1020305@cs.oswego.edu>
References: <CABg6-qjUioDnFx1aWePUs2Mf14_4rCH3nz7SuCsQyEGDBUWbuA@mail.gmail.com>
	<52644104.5050200@cs.oswego.edu>
	<CABg6-qizVmPE85n11JBpCZN6peNOL-29jOC8rX40FfdfS5errQ@mail.gmail.com>
	<52645D61.1020305@cs.oswego.edu>
Message-ID: <CABg6-qhs6U4L9FJ=6kEaCVCo7FOchft6hbfAjMdgW+OGbLyVAA@mail.gmail.com>

On Mon, Oct 21, 2013 at 1:46 AM, Doug Lea <dl at cs.oswego.edu> wrote:

>
> These were folded into other updates that could have lost
> some impact on your case; what's there now is
> the best tradeoff I know of. (While frameworks like
> ForkJoin seem to never become "finished", I don't
> anticipate further changes for JDK8 release.)
>
>
Sure. All in all FJ works great.


> The issues remain the same though.
> We must wake up threads if we do not know that there is
> already sufficient parallelism, which is a racy problem,
> so must be addressed conservatively.


Maybe the waking up should be done after the task has completed? Can't we
assume that tasks are very short-lived (this should be true in the FJ pool
both in the normal and the async modes)? Just a thought.


> When there is not
> intrinsic parallelism in a set of tasks, some/most wakeups can be
> wasted, and generate more overhead as those unneeded threads
> re-block. In most use cases, this loss is outweighed by other
> gains. In others, you can reduce impact to near-nothing by
> submitting fewer bigger tasks (even those that just split
> into smaller tasks when submitted). But if there is essentially
> never any task parallelism, it might be simpler to just use a
> singleton FJP for them; Or some other executor -- using
> the full ForkJoin framework is not often the best way
> to implement a producer-consumer design with a single consumer.
> Which seems to be approximately what you do.
>
>
There is a lot of "emergent" task parallelism (a fiber wakes up other
waiting fibers, i.e. forks them), it's just that it's not known in advance.
In general, a work-stealing scheduler works very well even in the
"concurrent" case  (where the concurrency is in the domain) as opposed to
the "parallel" case (where parallelism is used to accelerate a single
computation). Go and Erlang both use a work stealing scheduler, that FJPool
outperforms in many (though not all) circumstances, BTW.

>
> Normally, the better throughput of parallel releases outweighs the
> increased per-thread spin/fail rates.


This fits well with my observations. I tried reducing contention by
spinning for a while (using your random-number-generating spin loop) after
a failed CAS (as suggested by Dave Dice in a recent paper). The result was
binary: either the busy-wait was too short, whereby the CAS failure rate
remained high, or too long and the failure rate dropped essentially to
zero, but the result was one thread (or fiber, in my case) doing all the
wakeups; I couldn't get a stable in-between mode. In the latter case, the
total performance indeed dropped. Perhaps, though, the waiting stack should
be "chunked" causing a successful CAS to wake, say, 10 waiters, instead of
fighting over each one individually.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131021/f797b3c2/attachment.html>

From madewael.mailinglists at gmail.com  Wed Oct 23 07:41:31 2013
From: madewael.mailinglists at gmail.com (Mattias De Wael)
Date: Wed, 23 Oct 2013 13:41:31 +0200
Subject: [concurrency-interest] Non-trivial software systems using juc's
	ForkJoin
Message-ID: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>

Dear all

I am a Phd-researcher currently working to understand how the Java ForkJoin framework is being used and how it is being adopted by software developers worldwide. I am conducting  a manual search in the well known source-code repositories, but I also wanted to get some input from the concurrency-community.
Concretely, I was wondering whether you are aware of non-trivial software systems (preferably open-sourced) that use the ForkJoin infrastructure of java.util.concurrent.
Any input from the experts in this field is highly appreciated!

Sincerely yours,

-- 
Mattias De Wael
Vrije Universiteit Brussel
Faculty of Sciences, DINF - SOFT
Room 10F728, Pleinlaan 2, B-1050 Brussels, Belgium
e-mail: madewael at vub.ac.be
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131023/ac831b50/attachment.html>

From radhakrishnan.mohan at gmail.com  Wed Oct 23 07:53:41 2013
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 23 Oct 2013 17:23:41 +0530
Subject: [concurrency-interest] Runnable and Callable
Message-ID: <CAOoXFP_RY-1rb0UHyh1Cu2AAGa+4jDt79086FvH_vKT7WM5w=Q@mail.gmail.com>

Hi,

                 Can't I schedule a 'Callable' to run at fixed intervals ?
Does it require a Runnable ? What is the pattern used generally ?

                 @SuppressWarnings("unchecked")
ScheduledFuture<?> scheduledFuture =
        scheduledExecutorService.schedule(new Callable<Object>() {
            public Object call() throws Exception {
             //setDiv();
             return null;
            }
        },
        5,
        TimeUnit.SECONDS);

Thanks,
Mohan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131023/31e62b06/attachment.html>

From aleksey.shipilev at oracle.com  Wed Oct 23 07:55:08 2013
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 23 Oct 2013 15:55:08 +0400
Subject: [concurrency-interest] Non-trivial software systems using juc's
 ForkJoin
In-Reply-To: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
References: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
Message-ID: <5267B91C.4030804@oracle.com>

On 10/23/2013 03:41 PM, Mattias De Wael wrote:
> *Concretely, I was wondering whether you are aware of non-trivial
> software systems (preferably open-sourced) that use the ForkJoin
> infrastructure of java.util.concurrent.*

* JDK 8 Streams use FJP as the executor for parallel ops.
* SPECjbb2013 uses FJP as the scalable workstealing executor.

-Aleksey.



From ron.pressler at gmail.com  Wed Oct 23 08:38:15 2013
From: ron.pressler at gmail.com (Ron Pressler)
Date: Wed, 23 Oct 2013 14:38:15 +0200
Subject: [concurrency-interest] Non-trivial software systems using juc's
	ForkJoin
In-Reply-To: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
References: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
Message-ID: <CABg6-qhWtHd45FK2r0J7TUL_jsRmfiUL_CcT0Amo1acoEs3x9w@mail.gmail.com>

ForkJoin is used as the scheduler in
Quasar<https://github.com/puniverse/quasar>,
a true lightweight-thread (continuation/coroutine-based) and actor library
for the JVM.


On Wed, Oct 23, 2013 at 2:41 PM, Mattias De Wael <
madewael.mailinglists at gmail.com> wrote:

> Dear all
>
> I am a Phd-researcher currently working to understand how the Java
> ForkJoin framework is being used and how it is being adopted by software
> developers worldwide. I am conducting  a manual search in the well known
> source-code repositories, but I also wanted to get some input from the
> concurrency-community.
> *Concretely, I was wondering whether you are aware of non-trivial
> software systems (preferably open-sourced) that use the ForkJoin
> infrastructure of java.util.concurrent.*
> Any input from the experts in this field is highly appreciated!
>
> Sincerely yours,
>
> --
>  Mattias De Wael
> Vrije Universiteit Brussel
> Faculty of Sciences, DINF - SOFT
> Room 10F728, Pleinlaan 2, B-1050 Brussels, Belgium
> e-mail: madewael at vub.ac.be
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131023/e393d471/attachment.html>

From davidcholmes at aapt.net.au  Wed Oct 23 18:40:48 2013
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 24 Oct 2013 08:40:48 +1000
Subject: [concurrency-interest] Runnable and Callable
In-Reply-To: <CAOoXFP_RY-1rb0UHyh1Cu2AAGa+4jDt79086FvH_vKT7WM5w=Q@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIELDKBAA.davidcholmes@aapt.net.au>

Runnable's are used for recurring scheduled tasks because with Callable you
have the problem of where the returned values get stored - you would need a
ScheduledFuture that represents a set of tasks. It is simpler for you to
wrap your "callable" plus whatever data structure you want for the results
into a Runnable.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Mohan
Radhakrishnan
  Sent: Wednesday, 23 October 2013 9:54 PM
  To: Concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Runnable and Callable


  Hi,


                   Can't I schedule a 'Callable' to run at fixed intervals ?
Does it require a Runnable ? What is the pattern used generally ?


                   @SuppressWarnings("unchecked")
  ScheduledFuture<?> scheduledFuture =
         scheduledExecutorService.schedule(new Callable<Object>() {
             public Object call() throws Exception {
              //setDiv();
              return null;
             }
         },
         5,
         TimeUnit.SECONDS);


  Thanks,
  Mohan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131024/c9f7929f/attachment.html>

From discus at kotek.net  Mon Oct 28 16:00:11 2013
From: discus at kotek.net (Jan Kotek)
Date: Mon, 28 Oct 2013 22:00:11 +0200
Subject: [concurrency-interest] Non-trivial software systems using juc's
 ForkJoin
In-Reply-To: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
References: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
Message-ID: <20131028220011.0993212b@kotek.net>

Scala Parallel Collections use Fork-Join. 

On Wed, 23 Oct 2013 13:41:31 +0200
Mattias De Wael <madewael.mailinglists at gmail.com> wrote:

> Dear all
> 
> I am a Phd-researcher currentl\y working to understand how the Java
> ForkJoin framework is being used and how it is being adopted by
> software developers worldwide. I am conducting  a manual search in
> the well known source-code repositories, but I also wanted to get
> some input from the concurrency-community. Concretely, I was
> wondering whether you are aware of non-trivial software systems
> (preferably open-sourced) that use the ForkJoin infrastructure of
> java.util.concurrent. Any input from the experts in this field is
> highly appreciated!
> 
> Sincerely yours,
> 


From viktor.klang at gmail.com  Mon Oct 28 16:24:14 2013
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 28 Oct 2013 21:24:14 +0100
Subject: [concurrency-interest] Non-trivial software systems using juc's
	ForkJoin
In-Reply-To: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
References: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
Message-ID: <CANPzfU9qhuTn1Eqrak4rAyg_DxFLjpHWn9bQ4JqkJVLS7urKFw@mail.gmail.com>

Akka <http://akka.io> has been using FJP for a long time, only in async
mode though.

Cheers,
?


On Wed, Oct 23, 2013 at 1:41 PM, Mattias De Wael <
madewael.mailinglists at gmail.com> wrote:

> Dear all
>
> I am a Phd-researcher currently working to understand how the Java
> ForkJoin framework is being used and how it is being adopted by software
> developers worldwide. I am conducting  a manual search in the well known
> source-code repositories, but I also wanted to get some input from the
> concurrency-community.
> *Concretely, I was wondering whether you are aware of non-trivial
> software systems (preferably open-sourced) that use the ForkJoin
> infrastructure of java.util.concurrent.*
> Any input from the experts in this field is highly appreciated!
>
> Sincerely yours,
>
> --
> Mattias De Wael
> Vrije Universiteit Brussel
> Faculty of Sciences, DINF - SOFT
> Room 10F728, Pleinlaan 2, B-1050 Brussels, Belgium
> e-mail: madewael at vub.ac.be
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?
*

Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20131028/c9263b28/attachment.html>

From aleksandar.prokopec at gmail.com  Mon Oct 28 16:39:53 2013
From: aleksandar.prokopec at gmail.com (Aleksandar Prokopec)
Date: Mon, 28 Oct 2013 21:39:53 +0100
Subject: [concurrency-interest] Non-trivial software systems using juc's
 ForkJoin
In-Reply-To: <20131028220011.0993212b@kotek.net>
References: <C5870DF2-436E-4F13-9B53-09F49C78CC15@gmail.com>
	<20131028220011.0993212b@kotek.net>
Message-ID: <526ECB99.7020500@gmail.com>

Scala Futures also use FJ pools:

https://github.com/scala/scala/blob/v2.10.3/src/library/scala/concurrent/impl/ExecutionContextImpl.scala

Also, fj pools were used in macro-based parallel collections:

https://www.assembla.com/code/workstealing/git/nodes/master/src/main/scala/scala/collection/parallel/workstealing/WorkstealingTreeScheduler.scala

Cheers,
Alex

--
Aleksandar Prokopec
Doctoral Assistant
LAMP, IC, EPFL
http://people.epfl.ch/aleksandar.prokopec

On 10/28/13 9:00 PM, Jan Kotek wrote:
> Scala Parallel Collections use Fork-Join.
>
> On Wed, 23 Oct 2013 13:41:31 +0200
> Mattias De Wael <madewael.mailinglists at gmail.com> wrote:
>
>> Dear all
>>
>> I am a Phd-researcher currentl\y working to understand how the Java
>> ForkJoin framework is being used and how it is being adopted by
>> software developers worldwide. I am conducting  a manual search in
>> the well known source-code repositories, but I also wanted to get
>> some input from the concurrency-community. Concretely, I was
>> wondering whether you are aware of non-trivial software systems
>> (preferably open-sourced) that use the ForkJoin infrastructure of
>> java.util.concurrent. Any input from the experts in this field is
>> highly appreciated!
>>
>> Sincerely yours,
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


