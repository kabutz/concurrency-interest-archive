From ganzhi at gmail.com  Wed Mar  3 03:55:34 2010
From: ganzhi at gmail.com (James Gan)
Date: Wed, 3 Mar 2010 16:55:34 +0800
Subject: [concurrency-interest] Is lock-free list useful?
Message-ID: <70c070d81003030055g1f7202e6ra5cebc0e98803491@mail.gmail.com>

Hi, dear all

I'm feeling interesting that there is no lock-free list in the j.u.c
package. Is there a reason behind this? The algorithm of lock-free
list is pretty simple. And list is a very useful data structure.

-- 
Best Regards
James Gan
Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com

From ganzhi at gmail.com  Wed Mar  3 03:58:16 2010
From: ganzhi at gmail.com (James Gan)
Date: Wed, 3 Mar 2010 16:58:16 +0800
Subject: [concurrency-interest] Contention on ReferenceQueue#poll()...
In-Reply-To: <DE10B00CCE0DC54883734F3060AC9ED439F4B11CE3@AUSP01VMBX06.collaborationhost.net>
References: <AQHKo1naj9q0hOzzYkaE6GYV96qZbg==>
	<DE10B00CCE0DC54883734F3060AC9ED439F4B11CE3@AUSP01VMBX06.collaborationhost.net>
Message-ID: <70c070d81003030058i1543d2caw1ce12e6202ea4f00@mail.gmail.com>

I've sent a patch to Harmony for solving this contention problem
several weeks ago. The new ReferenceQueue uses lock-free algorithm
internally.

Here is the patch that I submitted:
https://issues.apache.org/jira/browse/HARMONY-6344

On Tue, Feb 2, 2010 at 12:17 AM, Bryan Thompson <bryan at systap.com> wrote:
> Hello,
>
> I am observing contention in ReferenceQueue#poll() for the internal lock used by that class. ?Our use case is to clear entries from a weak value cache once their References have been cleared. ?We are working to minimize contention from the application by controlling which thread calls ReferenceQueue#poll(), but it seems that it would be useful to have a ReferenceQueue#drain(...) method which hands back an array of references which have been cleared, perhaps by writing them into an array provided by the caller. ?Regardless of the specific method signature, this would make it faster for a thread to consume the elements from the ReferenceQueue.
>
> Thanks,
>
> Bryan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Best Regards
James Gan
Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com


From bryan at systap.com  Wed Mar  3 07:40:06 2010
From: bryan at systap.com (Bryan Thompson)
Date: Wed, 3 Mar 2010 06:40:06 -0600
Subject: [concurrency-interest] Contention on ReferenceQueue#poll()...
In-Reply-To: <70c070d81003030058i1543d2caw1ce12e6202ea4f00@mail.gmail.com>
References: <AQHKo1naj9q0hOzzYkaE6GYV96qZbg==>
	<DE10B00CCE0DC54883734F3060AC9ED439F4B11CE3@AUSP01VMBX06.collaborationhost.net>,
	<70c070d81003030058i1543d2caw1ce12e6202ea4f00@mail.gmail.com>
Message-ID: <DE10B00CCE0DC54883734F3060AC9ED44D5C2A5C06@AUSP01VMBX06.collaborationhost.net>

James, do you know if a similar patch is making its way into the Sun JVM?  I am wondering if we should implement a workaround now or just want for a new JVM accepting some contention today.  Thanks, Bryan
________________________________________
From: James Gan [ganzhi at gmail.com]
Sent: Wednesday, March 03, 2010 3:58 AM
To: Bryan Thompson
Cc: concurrency-interest x
Subject: Re: [concurrency-interest] Contention on ReferenceQueue#poll()...

I've sent a patch to Harmony for solving this contention problem
several weeks ago. The new ReferenceQueue uses lock-free algorithm
internally.

Here is the patch that I submitted:
https://issues.apache.org/jira/browse/HARMONY-6344

On Tue, Feb 2, 2010 at 12:17 AM, Bryan Thompson <bryan at systap.com> wrote:
> Hello,
>
> I am observing contention in ReferenceQueue#poll() for the internal lock used by that class.  Our use case is to clear entries from a weak value cache once their References have been cleared.  We are working to minimize contention from the application by controlling which thread calls ReferenceQueue#poll(), but it seems that it would be useful to have a ReferenceQueue#drain(...) method which hands back an array of references which have been cleared, perhaps by writing them into an array provided by the caller.  Regardless of the specific method signature, this would make it faster for a thread to consume the elements from the ReferenceQueue.
>
> Thanks,
>
> Bryan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



--
Best Regards
James Gan
Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com


From ganzhi at gmail.com  Wed Mar  3 09:28:46 2010
From: ganzhi at gmail.com (James Gan)
Date: Wed, 3 Mar 2010 22:28:46 +0800
Subject: [concurrency-interest] Is lock-free list useful?
In-Reply-To: <1955012351.20100303153448@devexperts.com>
References: <70c070d81003030055g1f7202e6ra5cebc0e98803491@mail.gmail.com>
	<75587939.20100303121819@devexperts.com>
	<70c070d81003030407h7e00c829hd6ed9fb6d49768ae@mail.gmail.com>
	<1955012351.20100303153448@devexperts.com>
Message-ID: <70c070d81003030628l3d6f6fc8v51d5e9e7e947e0e@mail.gmail.com>

Roman,

I read following article when I was creating lock-free set and list:

http://www.research.ibm.com/people/m/michael/spaa-2002.pdf
High Performance Dynamic Lock-Free Hash Tables and List-Based Sets
Maged M. Michael

If you are interested in my implementation, here is the link:
http://amino-cbbs.svn.sourceforge.net/viewvc/amino-cbbs/trunk/amino/java/src/main/java/org/amino/ds/lockfree/LockFreeList.java?revision=555&view=markup

On Wed, Mar 3, 2010 at 8:34 PM, Roman Elizarov <elizarov at devexperts.com> wrote:
> Hello James!
>
> Right. Its underlying Michael-Scott algorithm does not support this
> operation. Then, what simple algorithm for lock-free list you are
> referring to? Can you give a reference to a paper or article about it,
> please (the name of the paper and its authors will be enough).
>
> Sincerely,
> Roman Elizarov
>
> On Wednesday, March 3, 2010 3:07:40 PM you wrote:
>
> JG> emm, ConcurrentLinkedQueue didn't support "insertion in the middle"
>
> JG> On Wed, Mar 3, 2010 at 5:18 PM, Roman Elizarov <elizarov at devexperts.com> wrote:
>>> Hello James!
>>>
>>> JG> I'm feeling interesting that there is no lock-free list in the j.u.c
>>> JG> package. Is there a reason behind this? The algorithm of lock-free
>>> JG> list is pretty simple. And list is a very useful data structure.
>>>
>>> java.util.concurrent.ConcurrentLinkedQueue
>>>
>>> Sincerely,
>>> Roman Elizarov
>>>
>>>
>
>
>
>
>
>
>



-- 
Best Regards
James Gan
Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com

From martinrb at google.com  Wed Mar  3 11:30:05 2010
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 3 Mar 2010 08:30:05 -0800
Subject: [concurrency-interest] Is lock-free list useful?
In-Reply-To: <70c070d81003030055g1f7202e6ra5cebc0e98803491@mail.gmail.com>
References: <70c070d81003030055g1f7202e6ra5cebc0e98803491@mail.gmail.com>
Message-ID: <1ccfd1c11003030830q7f7b28b1l5f1157c9cd646f7e@mail.gmail.com>

I've been working on the easier problem of lock-free deque.
http://cr.openjdk.java.net/~martin/CLD/ConcurrentLinkedDeque.java
which I hope to get into jdk7.  It supports interior removals
and does not allocate new Nodes for pointer manipulation.

Martin

On Wed, Mar 3, 2010 at 00:55, James Gan <ganzhi at gmail.com> wrote:
> Hi, dear all
>
> I'm feeling interesting that there is no lock-free list in the j.u.c
> package. Is there a reason behind this? The algorithm of lock-free
> list is pretty simple. And list is a very useful data structure.
>
> --
> Best Regards
> James Gan
> Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
> Blog: http://ganzhi.blogspot.com
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dl at cs.oswego.edu  Thu Mar  4 07:12:19 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 04 Mar 2010 07:12:19 -0500
Subject: [concurrency-interest] Is lock-free list useful?
In-Reply-To: <70c070d81003030055g1f7202e6ra5cebc0e98803491@mail.gmail.com>
References: <70c070d81003030055g1f7202e6ra5cebc0e98803491@mail.gmail.com>
Message-ID: <4B8FA3A3.2010200@cs.oswego.edu>

On 03/03/10 03:55, James Gan wrote:

> I'm feeling interesting that there is no lock-free list in the j.u.c
> package. Is there a reason behind this? The algorithm of lock-free
> list is pretty simple. And list is a very useful data structure.
>

It is only simple if you do not support indexed operations
(as seems to be the case in Amino). But if you don't support
indexed operations, then, as implied by Martin's reply,
at best you are implementing Queue or Deque interfaces, for
which j.u.c has several implementations, with another one
likely coming.

-Doug




From concurrency-interest at majumdar.org.uk  Sat Mar 13 20:09:01 2010
From: concurrency-interest at majumdar.org.uk (Dibyendu Majumdar)
Date: Sun, 14 Mar 2010 01:09:01 +0000
Subject: [concurrency-interest] Sharing threads across executors
Message-ID: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>

Hi,

I am building a system where there are many modules that need to run
background tasks. The requirement is that the tasks execute without blocking
as otherwise performance will be impacted. On the other hand I want to avoid
having too many threads sitting idle.

I may have misunderstood, but it seems to me that there is no mechanism for
sharing a single threadpool across multiple executors. Conceptually, I'd
like each executor to have its task queue, but share the thread pool with
other executors, so that the pool of threads is optimised.

I also need the ability to run certain tasks at scheduled intervals.

For now, the solution I have implemented is as follows:

I use a single ThreadPoolExecutor to run all tasks.
I use a separate ScheduledThreadPoolExecutor to manage scheduled tasks. This
executor does not run the tasks, instead it submits the tasks when ready to
the first ThreadPoolExecutor. This pool has only 1 thread allocated.

With this solution I am close to what I wanted, but I cannot avoid having
one thread (ScheduledThreadPoolExecutor) being idle most of the time.

Is there a better way of achieving this?
Why is the scheduling function tied to the threadpool management? It would
seem to me that these are separate concerns.

Thanks very much in advance for your help and advice.

Regards

Dibyendu Majumdar
http://www.simpledbm.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100314/1f7abf5b/attachment.html>

From joe.bowbeer at gmail.com  Sun Mar 14 00:25:51 2010
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 13 Mar 2010 21:25:51 -0800
Subject: [concurrency-interest] Sharing threads across executors
In-Reply-To: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>
References: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>
Message-ID: <31f2a7bd1003132125k62b21ea4t7e072514cb373dfe@mail.gmail.com>

The mechanism for sharing a single threadpool across multiple executors is
delegation, as in your implemented solution.

Since a ScheduledThreadPoolExecutor is a type of ThreadPoolExecutor, why not
make the STPE the root of your executor tree?  In which case, tasks that
need immediate execution would be submitted via execute(), and only the
delayed tasks would be be submitted via one of the schedule() methods.

If you want the idle STPE threads to die off, can you use setKeepAliveTime
and allowCoreThreadTimeOut?  Even though a STPE is constructed with a fixed
core size, I *think* these methods will still behave in their specified way.

Joe

On Sat, Mar 13, 2010 at 5:09 PM, Dibyendu Majumdar wrote:

> Hi,
>
> I am building a system where there are many modules that need to run
> background tasks. The requirement is that the tasks execute without blocking
> as otherwise performance will be impacted. On the other hand I want to avoid
> having too many threads sitting idle.
>
> I may have misunderstood, but it seems to me that there is no mechanism for
> sharing a single threadpool across multiple executors. Conceptually, I'd
> like each executor to have its task queue, but share the thread pool with
> other executors, so that the pool of threads is optimised.
>
> I also need the ability to run certain tasks at scheduled intervals.
>
> For now, the solution I have implemented is as follows:
>
> I use a single ThreadPoolExecutor to run all tasks.
> I use a separate ScheduledThreadPoolExecutor to manage scheduled tasks.
> This executor does not run the tasks, instead it submits the tasks when
> ready to the first ThreadPoolExecutor. This pool has only 1 thread
> allocated.
>
> With this solution I am close to what I wanted, but I cannot avoid having
> one thread (ScheduledThreadPoolExecutor) being idle most of the time.
>
> Is there a better way of achieving this?
> Why is the scheduling function tied to the threadpool management? It would
> seem to me that these are separate concerns.
>
> Thanks very much in advance for your help and advice.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100313/0279ce7c/attachment.html>

From gustav.trede at gmail.com  Sun Mar 14 06:17:04 2010
From: gustav.trede at gmail.com (gustav trede)
Date: Sun, 14 Mar 2010 11:17:04 +0100
Subject: [concurrency-interest] Sharing threads across executors
In-Reply-To: <31f2a7bd1003132125k62b21ea4t7e072514cb373dfe@mail.gmail.com>
References: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>
	<31f2a7bd1003132125k62b21ea4t7e072514cb373dfe@mail.gmail.com>
Message-ID: <311e0eaf1003140317l65fefd84wb0922321ffd8bc6b@mail.gmail.com>

The cost of having idle threads is not as the killer it used to be.
It tends to be the cost of the pools logic that is the problem, tracking the
queue and thread limits enforces lock/synchronized design that in general
gives sup optimal scalability unless work stealing or other tricks are used.
If your throughput needs of a pool is high and theres a need of many threads
:
Using a fixedpool based on a LinkedTransferQueue (a recent version: jdk7 or
Doug lea cvs) without queue limit can give vastly better throughput (and
hence a higher cpu usage).
Such a pool can still be resizable using poisons, it just dont resizes
itself.
For some special cases with very few threads and high contention, a lock
based like LBQ can still win albeit with a small marginal, but it just does
not scale.
Its quite implementation dependent and as LTQ and other aspects evolve, its
imo of constant interest to compare different designs in order to know whats
optimal for different usage cases.


On 14 March 2010 06:25, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> The mechanism for sharing a single threadpool across multiple executors is
> delegation, as in your implemented solution.
>
> Since a ScheduledThreadPoolExecutor is a type of ThreadPoolExecutor, why
> not make the STPE the root of your executor tree?  In which case, tasks that
> need immediate execution would be submitted via execute(), and only the
> delayed tasks would be be submitted via one of the schedule() methods.
>
> If you want the idle STPE threads to die off, can you use setKeepAliveTime
> and allowCoreThreadTimeOut?  Even though a STPE is constructed with a fixed
> core size, I *think* these methods will still behave in their specified way.
>
> Joe
>
> On Sat, Mar 13, 2010 at 5:09 PM, Dibyendu Majumdar wrote:
>
> Hi,
>>
>> I am building a system where there are many modules that need to run
>> background tasks. The requirement is that the tasks execute without blocking
>> as otherwise performance will be impacted. On the other hand I want to avoid
>> having too many threads sitting idle.
>>
>> I may have misunderstood, but it seems to me that there is no mechanism
>> for sharing a single threadpool across multiple executors. Conceptually, I'd
>> like each executor to have its task queue, but share the thread pool with
>> other executors, so that the pool of threads is optimised.
>>
>> I also need the ability to run certain tasks at scheduled intervals.
>>
>> For now, the solution I have implemented is as follows:
>>
>> I use a single ThreadPoolExecutor to run all tasks.
>> I use a separate ScheduledThreadPoolExecutor to manage scheduled tasks.
>> This executor does not run the tasks, instead it submits the tasks when
>> ready to the first ThreadPoolExecutor. This pool has only 1 thread
>> allocated.
>>
>> With this solution I am close to what I wanted, but I cannot avoid having
>> one thread (ScheduledThreadPoolExecutor) being idle most of the time.
>>
>> Is there a better way of achieving this?
>> Why is the scheduling function tied to the threadpool management? It would
>> seem to me that these are separate concerns.
>>
>> Thanks very much in advance for your help and advice.
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
regards
 gustav trede
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100314/1416690b/attachment.html>

From concurrency-interest at majumdar.org.uk  Sun Mar 14 07:41:06 2010
From: concurrency-interest at majumdar.org.uk (Dibyendu Majumdar)
Date: Sun, 14 Mar 2010 11:41:06 +0000
Subject: [concurrency-interest] Sharing threads across executors
In-Reply-To: <bb93b72b1003140437r10ca8a61pafe375c9d49fc48@mail.gmail.com>
References: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>
	<b20868901003131905t66bd8339p1bbb31042776841b@mail.gmail.com>
	<bb93b72b1003140437r10ca8a61pafe375c9d49fc48@mail.gmail.com>
Message-ID: <bb93b72b1003140441q68ea2b3dm5dd17661b2cb2886@mail.gmail.com>

Hi Enno,

Thanks for the reply.

On 14 March 2010 03:05, Enno Shioji <eshioji at gmail.com> wrote:
>
>
> You can use ScheduledThreadPoolExecutor as a ThreadPoolExecutor, so
> there is no need to let it submit tasks to another ThreadPoolExecutor
> (the queue implementation will be DelayQueue though).
>
>
As I understand it, ScheduledThreadPoolExecutor uses a fixed size pool
of threads, so if I used this, I would have to predefine the number of
threads to
the maximum I would ever need. I am trying to have a more dynamic solution
where the number of threads grow dynamically when there is load, but also
get reduced when things are quiet.


> Also, if you mix the queue (have different kinds of tasks in the
> queue), the queuing time becomes more difficult to predict, because
> there will be potentially long-running tasks and short-running tasks
> in there - that can lead to a headache.
>
>
True. My understanding is that the ThreadPoolExecutor will acquire new
threads
rather than queueing up tasks when a SynchronousQueue is used (such as
when using Executors.newCachedThreadPool()). So queueing time should be
minimal. But this can potentially lead to many threads being created ...

I have some tasks that should absolutely never be blocked, because if
these get blocked, the system will grind to a halt. Other types of tasks
are less critical, and can be queued with some negative impact on clients.
It does look like I cannot balance these two requirement with the goal of
having a single threadpool as there is no concept of prioritizing of tasks.

Regards

Dibyendu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100314/b8e22446/attachment.html>

From concurrency-interest at majumdar.org.uk  Sun Mar 14 07:55:17 2010
From: concurrency-interest at majumdar.org.uk (Dibyendu Majumdar)
Date: Sun, 14 Mar 2010 11:55:17 +0000
Subject: [concurrency-interest] Sharing threads across executors
In-Reply-To: <31f2a7bd1003132125k62b21ea4t7e072514cb373dfe@mail.gmail.com>
References: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>
	<31f2a7bd1003132125k62b21ea4t7e072514cb373dfe@mail.gmail.com>
Message-ID: <bb93b72b1003140455w7b1c5508n72484e7eeb4c27@mail.gmail.com>

On 14 March 2010 05:25, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> The mechanism for sharing a single threadpool across multiple executors is
> delegation, as in your implemented solution.
>
> Since a ScheduledThreadPoolExecutor is a type of ThreadPoolExecutor, why
> not make the STPE the root of your executor tree?  In which case, tasks that
> need immediate execution would be submitted via execute(), and only the
> delayed tasks would be be submitted via one of the schedule() methods.
>
> If you want the idle STPE threads to die off, can you use setKeepAliveTime
> and allowCoreThreadTimeOut?  Even though a STPE is constructed with a fixed
> core size, I *think* these methods will still behave in their specified way.
>
>
Hi Joe,

Thanks for the suggestion, I shall have a look that tweaking these
parameters.

Regards

Dibyendu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100314/97a18385/attachment-0001.html>

From djg at cs.washington.edu  Sun Mar 14 19:13:06 2010
From: djg at cs.washington.edu (Dan Grossman)
Date: Sun, 14 Mar 2010 16:13:06 -0700
Subject: [concurrency-interest] question from new-user/instructor: "x.fork();
	x.join()" vs. x.compute()
Message-ID: <4B9D6D82.3030403@cs.washington.edu>


 From a new user of JSR166 on Java 1.6...

Short version of question:

   Why am I seeing "x.fork(); x.join()" causing a trivial program to take about
   40x longer than the same program written using x.compute()?

Long version:

Context:

I wrote my first program using the JSR166 classes today because I am preparing 
to teach an _introductory_ data structures course.  This is a new course that 
will pair traditional material for such a course (asymptotic complexity, 
balanced trees, hashtables, etc.) with an _introduction_ to parallelism and 
concurrency.  I would like them to write some very simple fork-join 
computations (even if parallelism isn't useful for the problem size) as part 
of a project and to gain some understanding of reasoning about (nearly 
trivial) parallel algorithms.  JSR166 seem like the ideal framework; I don't 
plan on using anything fancy.

Who Should I Ask:

I apologize if my question is not appropriate for this list. If there is a 
better list for newcomers, a FAQ or other documentation, etc., just politely 
point me in the right direction.  I also apologize if my code has a stupid bug 
or I'm just a parallel-programming neophyte..  Web searches led me here.

Platform:

I am using http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar with Java 1.6, 
compiling with -cp jsr166.jar and running with -Xbootclasspath/p:jsr166.jar

I am getting roughly similar behavior with this JVM on Windows with
a 6-year-old uniprocessor:
  java version "1.6.0_12"
  Java(TM) SE Runtime Environment (build 1.6.0_12-b04)
  Java HotSpot(TM) Client VM (build 11.2-b01, mixed mode, sharing)
and this JVM on Linux with 4 processors (but I'm not the only compute job):
  java version "1.6.0_17"
  Java(TM) SE Runtime Environment (build 1.6.0_17-b04)
  Java HotSpot(TM) Server VM (build 14.3-b01, mixed mode)

I need to use Java 1.6 so that my students can stick with their standard Java 
installations in their lab, etc.

The program:

I have pasted the entire program below. All it does it initialize a large 
array and then add all the elements, making two fork-join passes over the 
array.

With FORK set to false, both passes use fork() to process the left half of the 
array and compute() to process the right half.  The performance is only 
1.5x-2x worse than the sequential algorithm (which takes about 50ms), which is 
impressive on a uniprocessor given all the extra bookkeeping the fork-join 
computation does.  Just what I wanted!

With FORK set to true, both passes use fork for both halves of the array.  The 
performance is about 80x slower than the sequential algorithm and I had to 
increase the Java max heap size.

The question:

Why is there such a difference in these two versions? Clearly "foo.fork(); 
foo.join()" is wasteful, but one could also argue it's more natural.  More 
importantly, I'd like to be able to explain to students _why_ they need to use 
foo.compute().

Thank you!

--Dan

====


import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.RecursiveAction;
import java.util.concurrent.RecursiveTask;

public class FirstFJProgram {
	static final boolean FORK = false;
	static final ForkJoinPool mainPool = new ForkJoinPool();
	static final int SEQUENTIAL_THRESHOLD = 1000;
	
	static final int ARRAY_SIZE = 5000000;
	
	static int[] array;

	static class InitializeArray extends RecursiveAction {
		int low;
		int high;
		InitializeArray(int lo, int hi) {
			low = lo;
			high = hi;
		}
		protected void compute() {
			if(high - low <= SEQUENTIAL_THRESHOLD) {
				for(int i=low; i < high; ++i)
					array[i] = i+1;
			} else {
				int mid = low + (high - low) / 2;
				InitializeArray left  = new InitializeArray(low, mid);
				InitializeArray right = new InitializeArray(mid, high);
				left.fork();
				if(FORK) {
					right.fork();
					right.join();
				} else {
					right.compute();
				}
				left.join();
			}
		}
	}
	
	static class SumArray extends RecursiveTask<Long> {
		int low;
		int high;
		SumArray(int lo, int hi) {
			low = lo;
			high = hi;
		}
		protected Long compute() {
			if(high - low <= SEQUENTIAL_THRESHOLD) {
				long sum = 0;
				for(int i=low; i < high; ++i)
					sum += array[i];
				return sum;
			} else {
				int mid = low + (high - low) / 2;
				SumArray left  = new SumArray(low, mid);
				SumArray right = new SumArray(mid, high);
				left.fork();
				if(FORK) {
					right.fork();
					return left.join() + right.join();
				} else {
					return right.compute() + left.join();
				}
			}
		}
	}
	
	static long sequential() {
		for(int i=0; i < array.length; ++i)
			array[i] = i+1;
		long sum = 0;
		for(int i=0; i < array.length; ++i)
			sum += array[i];
		return sum;
	}
	
	public static void main(String[] args) {
		array = new int[ARRAY_SIZE];
				
		System.gc();
		long sStart = System.currentTimeMillis();
		long sequential = sequential();
		long sEnd = System.currentTimeMillis();

		System.gc();
		long pStart = System.currentTimeMillis();
		mainPool.invoke(new InitializeArray(0,array.length));
		System.out.println();
		long answer = mainPool.invoke(new SumArray(0,array.length));
		long pEnd = System.currentTimeMillis();
				
		long check = ((long)ARRAY_SIZE * (ARRAY_SIZE+1)) / 2;
		
		System.out.println(answer + " " + sequential + " " + check);
		System.out.println("parallel: " + (pEnd - pStart) + " sequential: " + (sEnd 
- sStart));
	}
}

From dl at cs.oswego.edu  Sun Mar 14 19:37:41 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 14 Mar 2010 19:37:41 -0400
Subject: [concurrency-interest] question from new-user/instructor:
 "x.fork(); x.join()" vs. x.compute()
In-Reply-To: <4B9D6D82.3030403@cs.washington.edu>
References: <4B9D6D82.3030403@cs.washington.edu>
Message-ID: <4B9D7345.60605@cs.oswego.edu>

On 03/14/10 19:13, Dan Grossman wrote:
> Why am I seeing "x.fork(); x.join()" causing a trivial program to take
> about
> 40x longer than the same program written using x.compute()?
>

Short version:
(1) Because there is nothing that does this optimization for you,
So you must hand-optimize this case.
(2) Because of big warm-up effects.

> Long version:
>
> Who Should I Ask:

This list is a good place.

>
> Why is there such a difference in these two versions?

Try putting your test in a loop and repeating.
For me (using current internal snapshot on an Intel i7);
with FORK true, I get on the first iteration:
   parallel: 729 sequential: 38
and the 20th
   parallel: 26 sequential: 11
With FORK false, first:
   parallel: 177 sequential: 38
20th:
   parallel: 7 sequential: 11

Which reflects that that after warmup, "fork(); join()" is around
4X-10X the overhead of just a straight method call. But it takes a while
for a JIT to decide to compile the workstealing code, so the first
runs are terrible. Yes, this is a problem. We are working on it.
You might have seen even more extreme results because current
uncommitted version addresses some of this.

Hope this helps.

-Doug


From djg at cs.washington.edu  Sun Mar 14 20:00:11 2010
From: djg at cs.washington.edu (Dan Grossman)
Date: Sun, 14 Mar 2010 17:00:11 -0700
Subject: [concurrency-interest] question from new-user/instructor:
 "x.fork(); x.join()" vs. x.compute()
In-Reply-To: <4B9D7345.60605@cs.oswego.edu>
References: <4B9D6D82.3030403@cs.washington.edu> <4B9D7345.60605@cs.oswego.edu>
Message-ID: <4B9D788B.4080904@cs.washington.edu>


Thanks for the instant reply, Doug -- very helpful.  See below...

Doug Lea wrote:
>> Why am I seeing "x.fork(); x.join()" causing a trivial program to take
>> about 40x longer than the same program written using x.compute()?
> Short version:
> (1) Because there is nothing that does this optimization for you,
> So you must hand-optimize this case.

Makes sense; I didn't expect this optimization to be done for me -- but I was 
surprised it mattered to much.  If I understand correctly, this optimization 
eliminates half the calls to fork, which I had trouble mapping to a 40x 
performance difference.

> (2) Because of big warm-up effects.
> Try putting your test in a loop and repeating.
> For me (using current internal snapshot on an Intel i7);
> with FORK true, I get on the first iteration:
>   parallel: 729 sequential: 38
> and the 20th
>   parallel: 26 sequential: 11
> With FORK false, first:
>   parallel: 177 sequential: 38
> 20th:
>   parallel: 7 sequential: 11
> 
> Which reflects that that after warmup, "fork(); join()" is around
> 4X-10X the overhead of just a straight method call. But it takes a while
> for a JIT to decide to compile the workstealing code, so the first
> runs are terrible. 

I also see dramatic improvements after the first run, both for FORK true and 
FORK false.  In steady-state, I have numbers like
with FORK true: parallel: 781 sequential: 31
with FORK false: parallel: 31 sequential: 31

There is jitter in the numbers, for example, the sequential is sometimes 47 or 
63, but ballpark the FORK-false gets about 1.5-2x faster after warmup and the 
FORK-true gets about 3-4x faster after warmup.  So the 40x difference drops to 
about a 20x-25x difference.  That still seems like a lot -- higher than the 
overhead of the fork and join calls and not due to warmup.

> Yes, this is a problem. We are working on it.
> You might have seen even more extreme results because current
> uncommitted version addresses some of this.

If a newer version is Java 1.6 friendly and stable for these simple sorts of 
programs, I'd be happy to try it out.  I won't be unleashing my students on 
JSR166 for about 8 weeks.  Their programs will do things a bit more 
interesting than my sample program (e.g., some 2D-arrays), but not in terms of 
the JSR166 features they'll be using.

--Dan

From ramesh.mandaleeka at gmail.com  Sun Mar 14 21:22:57 2010
From: ramesh.mandaleeka at gmail.com (Ramesh Mandaleeka)
Date: Sun, 14 Mar 2010 21:22:57 -0400
Subject: [concurrency-interest] question from new-user/instructor:
	"x.fork(); x.join()" vs. x.compute()
In-Reply-To: <4B9D788B.4080904@cs.washington.edu>
References: <4B9D6D82.3030403@cs.washington.edu>
	<4B9D7345.60605@cs.oswego.edu> 
	<4B9D788B.4080904@cs.washington.edu>
Message-ID: <a55f9dae1003141822s3a7d8923k86751a762f5368a@mail.gmail.com>

I had the same situation, but I hesitated a bit to ask. :)
http://docs.google.com/View?id=dgwfjptc_146g3mw2nhc

-Ramesh


On Sun, Mar 14, 2010 at 8:00 PM, Dan Grossman <djg at cs.washington.edu> wrote:

>
> Thanks for the instant reply, Doug -- very helpful.  See below...
>
>
> Doug Lea wrote:
>
>> Why am I seeing "x.fork(); x.join()" causing a trivial program to take
>>> about 40x longer than the same program written using x.compute()?
>>>
>> Short version:
>> (1) Because there is nothing that does this optimization for you,
>> So you must hand-optimize this case.
>>
>
> Makes sense; I didn't expect this optimization to be done for me -- but I
> was surprised it mattered to much.  If I understand correctly, this
> optimization eliminates half the calls to fork, which I had trouble mapping
> to a 40x performance difference.
>
>  (2) Because of big warm-up effects.
>> Try putting your test in a loop and repeating.
>> For me (using current internal snapshot on an Intel i7);
>> with FORK true, I get on the first iteration:
>>  parallel: 729 sequential: 38
>> and the 20th
>>  parallel: 26 sequential: 11
>> With FORK false, first:
>>  parallel: 177 sequential: 38
>> 20th:
>>  parallel: 7 sequential: 11
>>
>> Which reflects that that after warmup, "fork(); join()" is around
>> 4X-10X the overhead of just a straight method call. But it takes a while
>> for a JIT to decide to compile the workstealing code, so the first
>> runs are terrible.
>>
>
> I also see dramatic improvements after the first run, both for FORK true
> and FORK false.  In steady-state, I have numbers like
> with FORK true: parallel: 781 sequential: 31
> with FORK false: parallel: 31 sequential: 31
>
> There is jitter in the numbers, for example, the sequential is sometimes 47
> or 63, but ballpark the FORK-false gets about 1.5-2x faster after warmup and
> the FORK-true gets about 3-4x faster after warmup.  So the 40x difference
> drops to about a 20x-25x difference.  That still seems like a lot -- higher
> than the overhead of the fork and join calls and not due to warmup.
>
>
>  Yes, this is a problem. We are working on it.
>> You might have seen even more extreme results because current
>> uncommitted version addresses some of this.
>>
>
> If a newer version is Java 1.6 friendly and stable for these simple sorts
> of programs, I'd be happy to try it out.  I won't be unleashing my students
> on JSR166 for about 8 weeks.  Their programs will do things a bit more
> interesting than my sample program (e.g., some 2D-arrays), but not in terms
> of the JSR166 features they'll be using.
>
> --Dan
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100314/140f35d2/attachment.html>

From matthias at mernst.org  Mon Mar 15 07:37:25 2010
From: matthias at mernst.org (Matthias Ernst)
Date: Mon, 15 Mar 2010 12:37:25 +0100
Subject: [concurrency-interest] JLS: finality of "enclosing instance" of
	inner classes
Message-ID: <22ec15241003150437u694369a4qa9c0274076101f6f@mail.gmail.com>

Hi,

does the JLS contain any language about the finality of the enclosing
instance reference? In practice, javac maps the "outer this" to a final
field "this$0", assigned in the inner class' constructor which would render
it safely published as of JLS 17.5 ("Final field semantics"). However, I
couldn't find any language in the spec regarding this.

I stumbled over this looking at how java.util.HashMap constructs its
collection views lazily:

  960       private Set<Map.Entry<K,V>> entrySet0() {
  961           Set<Map.Entry<K,V>> es = entrySet;
  962           return es != null ? es : (entrySet = new EntrySet());
  963       }

(http://www.docjar.com/html/api/java/util/HashMap.java.html)

This is only safe if final field semantics apply to enclosing instances.

Thanks
Matthias
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100315/b02874d4/attachment.html>

From dl at cs.oswego.edu  Mon Mar 15 09:24:39 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 15 Mar 2010 09:24:39 -0400
Subject: [concurrency-interest] question from new-user/instructor:
 "x.fork(); x.join()" vs. x.compute()
In-Reply-To: <4B9D788B.4080904@cs.washington.edu>
References: <4B9D6D82.3030403@cs.washington.edu> <4B9D7345.60605@cs.oswego.edu>
	<4B9D788B.4080904@cs.washington.edu>
Message-ID: <4B9E3517.2050705@cs.oswego.edu>

On 03/14/10 20:00, Dan Grossman wrote:

> There is jitter in the numbers, for example, the sequential is sometimes
> 47 or 63, but ballpark the FORK-false gets about 1.5-2x faster after
> warmup and the FORK-true gets about 3-4x faster after warmup. So the 40x
> difference drops to about a 20x-25x difference. That still seems like a
> lot -- higher than the overhead of the fork and join calls and not due
> to warmup.

About 3X of the difference is due to hotspot optimization.
With a non-opaque call to compute(), it unrolls some recursion
which can inline leaf calls. (The resulting machine code
is so different with this change that it is hard to tell it
is almost the same source code). Which gets you back to the
estimated plain fork/join vs call overhead.


>> Yes, this is a problem. We are working on it.
>> You might have seen even more extreme results because current
>> uncommitted version addresses some of this.
>
> If a newer version is Java 1.6 friendly and stable for these simple
> sorts of programs, I'd be happy to try it out.

I'll be checking in a substantial update to the "jsr166y" versions
hopefully sometime this week, which we'll let settle
before pushing it into openjdk7.

-Doug

From khilan at doc.ic.ac.uk  Mon Mar 15 11:19:09 2010
From: khilan at doc.ic.ac.uk (Khilan Gudka)
Date: Mon, 15 Mar 2010 15:19:09 +0000
Subject: [concurrency-interest] Multi-level locks
Message-ID: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com>

Dear all,

I'm looking to produce a high-performant implementation of multi-granularity
(a.k.a multi-level) locks. I'm basing my implementation on the paper
"Granularity of Locks in a Shared Data Base" by Gray et al. There are five
modes: Shared (S), Exclusive (X), Intention Shared (IS), Intention Exclusive
(IX) and Shared Intention Exclusive (SIX - this last mode can be represented
implicitly by non-zero counts for both S and IX).

I currently have an implementation whereby I use a long to represent state.
There is a global state for the lock that gives the status of the lock with
respect to all threads as well as per-thread state for a thread's count of
each of the above modes (minus the implicitly  represented mode SIX).
Determining whether a request from a thread can proceed is achieved by
subtracting the two (giving a so-called "group mode" of the other threads)
and then doing a bit-wise AND to determine compatibility of the request with
the group mode). I keep two queues (ConcurrentLinkedQueue) for upgrades and
new requests respectively. To keep the implementation simple, the lock and
unlock methods are synchronized. However, this doesn't perform very well.
For instance, 8 threads incrementing a counter 100000 times takes 10 seconds
compared with 0.2 seconds when using j.u.c.ReentrantReadWriteLock.

I've been looking at AbstractQueuedLongSynchronizer and noticed in the
javadoc comments that it's designed for this sort of thing. However, from
what I've seen it only supports the two modes S and X. Furthermore, it
doesn't seem trivial to extend the internal wait queue given that the Node
class is final? or is it?

If somebody could please give me some advice as to how to proceed, I would
be ever so grateful.

Thanks,
Khilan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100315/25a83d89/attachment.html>

From joe.bowbeer at gmail.com  Mon Mar 15 10:14:26 2010
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 15 Mar 2010 07:14:26 -0700
Subject: [concurrency-interest] JLS: finality of "enclosing instance" of
	inner classes
In-Reply-To: <22ec15241003150437u694369a4qa9c0274076101f6f@mail.gmail.com>
References: <22ec15241003150437u694369a4qa9c0274076101f6f@mail.gmail.com>
Message-ID: <31f2a7bd1003150714j7376287atd5316ae928516a42@mail.gmail.com>

The only JLS reference is 15.8.4, right?

http://java.sun.com/docs/books/jls/third_edition/html/expressions.html#15.8.4

There was some discussion on the JavaMemoryModel list in May 2004: "Are
this$x fields final?"

http://www.cs.umd.edu/~pugh/java/memoryModel/archive/2348.html

And there was more discussion in August 2007: "Guarantees for
enclosing-instance references?"

I include a snippet from this discussion below.  If you don't receive a
definitive answer here, I suggest you try posting on JMM.

-----

Jeremy Manson wrote:

Nope.  We never guarantee it.

The fact that these fields happen to be final is just an implementation
artifact.  Relying on this property is relying on the source to bytecode
transformation never changing.

Bart Jacobs wrote:

I may be missing something, but the way I read JLS3, it does guarantee this.
It seems to me that JLS3 guarantees in paragraph 15.8.4 that a qualified
this expression always evaluates to a reference to the appropriate enclosing
instance. The language of JLS3 does not seem to allow for qualified
thisexpressions evaluating to null.

Also, it would be unfortunate if JLS3 did not guarantee this, seeing how
easily it can be implemented, simply by storing the reference in a final
field?

Jeremy Manson wrote:

A qualified this expression does always evaluate to a reference to the
appropriate enclosing instance. Thinking about it, I suppose that probably
does imply that the correct value of this will be seen.  But only "this" --
it doesn't say that fields reachable from this will be seen correctly.

-----


On Mon, Mar 15, 2010 at 4:37 AM, Matthias Ernst wrote:

> Hi,
>
> does the JLS contain any language about the finality of the enclosing
> instance reference? In practice, javac maps the "outer this" to a final
> field "this$0", assigned in the inner class' constructor which would render
> it safely published as of JLS 17.5 ("Final field semantics"). However, I
> couldn't find any language in the spec regarding this.
>
> I stumbled over this looking at how java.util.HashMap constructs its
> collection views lazily:
>
>   960       private Set<Map.Entry<K,V>> entrySet0() {
>   961           Set<Map.Entry<K,V>> es = entrySet;
>   962           return es != null ? es : (entrySet = new EntrySet());
>
>   963       }
>
> (http://www.docjar.com/html/api/java/util/HashMap.java.html)
>
> This is only safe if final field semantics apply to enclosing instances.
>
> Thanks
> Matthias
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100315/a6428feb/attachment.html>

From ben_manes at yahoo.com  Mon Mar 15 14:45:40 2010
From: ben_manes at yahoo.com (Ben Manes)
Date: Mon, 15 Mar 2010 11:45:40 -0700 (PDT)
Subject: [concurrency-interest] Sharing threads across executors
In-Reply-To: <bb93b72b1003140441q68ea2b3dm5dd17661b2cb2886@mail.gmail.com>
References: <bb93b72b1003131709qc08f815wf3d2af1fb5b24940@mail.gmail.com>
	<b20868901003131905t66bd8339p1bbb31042776841b@mail.gmail.com>
	<bb93b72b1003140437r10ca8a61pafe375c9d49fc48@mail.gmail.com>
	<bb93b72b1003140441q68ea2b3dm5dd17661b2cb2886@mail.gmail.com>
Message-ID: <141935.73465.qm@web38801.mail.mud.yahoo.com>

You can use a single-threaded ScheduledThreadPoolExecutor that delegates the execution to a dynamically-sized ThreadPoolExecutor.  This worked well for me, given that I was still on JDK5 where I couldn't leverage the JDK6's additional threadpool features.




________________________________
From: Dibyendu Majumdar <concurrency-interest at majumdar.org.uk>
To: concurrency-interest at cs.oswego.edu
Sent: Sun, March 14, 2010 4:41:06 AM
Subject: Re: [concurrency-interest] Sharing threads across executors


Hi Enno,

Thanks for the reply.


On 14 March 2010 03:05, Enno Shioji <eshioji at gmail.com> wrote:
>
>
>>You can use ScheduledThreadPoolExecutor as a ThreadPoolExecutor, so
>>there is no need to let it submit tasks to another ThreadPoolExecutor
>>(the queue implementation will be DelayQueue though).
>
>
>

As I understand it, ScheduledThreadPoolExecutor uses a fixed size pool
of threads, so if I used this, I would have to predefine the number of threads to
the maximum I would ever need. I am trying to have a more dynamic solution
where the number of threads grow dynamically when there is load, but also
get reduced when things are quiet.
 
>Also, if you mix the queue (have different kinds of tasks in the
>>queue), the queuing time becomes more difficult to predict, because
>>there will be potentially long-running tasks and short-running tasks
>>in there - that can lead to a headache.
>
>

True. My understanding is that the ThreadPoolExecutor will acquire new threads
rather than queueing up tasks when a SynchronousQueue is used (such as
when using Executors.newCachedThreadPool()). So queueing time should be
minimal. But this can potentially lead to many threads being created ...

I have some tasks that should absolutely never be blocked, because if 
these get blocked, the system will grind to a halt. Other types of tasks
are less critical, and can be queued with some negative impact on clients.
It does look like I cannot balance these two requirement with the goal of 
having a single threadpool as there is no concept of prioritizing of tasks.

Regards

Dibyendu


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100315/3ef99908/attachment.html>

From neal at gafter.com  Mon Mar 15 11:04:26 2010
From: neal at gafter.com (Neal Gafter)
Date: Mon, 15 Mar 2010 08:04:26 -0700
Subject: [concurrency-interest] JLS: finality of "enclosing instance" of
	inner classes
In-Reply-To: <22ec15241003150437u694369a4qa9c0274076101f6f@mail.gmail.com>
References: <22ec15241003150437u694369a4qa9c0274076101f6f@mail.gmail.com>
Message-ID: <15e8b9d21003150804u140c1b6fj8b68b24037019ee8@mail.gmail.com>

Matthias-

The spec also omits mention of the finality of cached copies of captured
local variables. I believe these omissions in the spec are bugs.

Cheers,
Neal

On Mon, Mar 15, 2010 at 4:37 AM, Matthias Ernst <matthias at mernst.org> wrote:

> Hi,
>
> does the JLS contain any language about the finality of the enclosing
> instance reference? In practice, javac maps the "outer this" to a final
> field "this$0", assigned in the inner class' constructor which would render
> it safely published as of JLS 17.5 ("Final field semantics"). However, I
> couldn't find any language in the spec regarding this.
>
> I stumbled over this looking at how java.util.HashMap constructs its
> collection views lazily:
>
>   960       private Set<Map.Entry<K,V>> entrySet0() {
>   961           Set<Map.Entry<K,V>> es = entrySet;
>   962           return es != null ? es : (entrySet = new EntrySet());
>
>
>   963       }
>
> (http://www.docjar.com/html/api/java/util/HashMap.java.html)
>
> This is only safe if final field semantics apply to enclosing instances.
>
> Thanks
> Matthias
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100315/42d3c13d/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Mar 15 18:51:06 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 16 Mar 2010 08:51:06 +1000
Subject: [concurrency-interest] Multi-level locks
In-Reply-To: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEGBIFAA.davidcholmes@aapt.net.au>

Khilan,

AbstractQueued[Long]Synchronizer is designed for this "kind of thing", though I don't know how well it will suit this particular case. The "shared" and "exclusive" modes are conceptual and don't have to map directly to the synchronizer being implemented - for example, all five or your modes might utilize the shared mode of AQS. However, the queuing is all internalized and it is not designed for extension or modification - and there is only one queue.

If you haven't seen it, check out Doug Lea's paper on AQS:

http://gee.cs.oswego.edu/dl/papers/aqs.pdf

There's also an example on using AQS to do Room Synchronization that we presented at various places, but for which I'm having trouble finding an actual link. :( Contact me if you'd like me to dig it up. I think there should be a JavaOne presentation with it in, somewhere.

HTH.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Khilan Gudka
  Sent: Tuesday, 16 March 2010 1:19 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Multi-level locks


  Dear all,


  I'm looking to produce a high-performant implementation of multi-granularity (a.k.a multi-level) locks. I'm basing my implementation on the paper "Granularity of Locks in a Shared Data Base" by Gray et al. There are five modes: Shared (S), Exclusive (X), Intention Shared (IS), Intention Exclusive (IX) and Shared Intention Exclusive (SIX - this last mode can be represented implicitly by non-zero counts for both S and IX).


  I currently have an implementation whereby I use a long to represent state. There is a global state for the lock that gives the status of the lock with respect to all threads as well as per-thread state for a thread's count of each of the above modes (minus the implicitly  represented mode SIX). Determining whether a request from a thread can proceed is achieved by subtracting the two (giving a so-called "group mode" of the other threads) and then doing a bit-wise AND to determine compatibility of the request with the group mode). I keep two queues (ConcurrentLinkedQueue) for upgrades and new requests respectively. To keep the implementation simple, the lock and unlock methods are synchronized. However, this doesn't perform very well. For instance, 8 threads incrementing a counter 100000 times takes 10 seconds compared with 0.2 seconds when using j.u.c.ReentrantReadWriteLock.


  I've been looking at AbstractQueuedLongSynchronizer and noticed in the javadoc comments that it's designed for this sort of thing. However, from what I've seen it only supports the two modes S and X. Furthermore, it doesn't seem trivial to extend the internal wait queue given that the Node class is final? or is it?


  If somebody could please give me some advice as to how to proceed, I would be ever so grateful.


  Thanks,
  Khilan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/46e5a714/attachment.html>

From kramasundar at yahoo.com  Tue Mar 16 06:55:14 2010
From: kramasundar at yahoo.com (Ramsundar Kandasamy)
Date: Tue, 16 Mar 2010 03:55:14 -0700 (PDT)
Subject: [concurrency-interest] Merging forked tasks - Repeating because of
	some formatting problem
Message-ID: <248557.91136.qm@web113204.mail.gq1.yahoo.com>

This mail is a duplicate copy of my previous mail. There was some formatting issues in my previous mail.


Hi

I don't know whether this is a open forum where one can post his questions. If you think that this a inappropriate message please discard it.

I am playing around with this ForkJoin framework. I was trying the first sample usage of RecursiveAction given in its javaDoc page.

class SortTask extends RecursiveAction {
?? ....
?? protected void compute() {
???? if (hi - lo < THRESHOLD)
?????? sequentiallySort(array, lo, hi);
???? else {
?????? int mid = (lo + hi) >>> 1;
?????? invokeAll(new SortTask(array, lo, mid), new SortTask(array, mid, hi));
?????? merge(array, lo, hi);? //!!!!! how to do this
???? }
?? }
?}

and following is my sequentiallySort method

?private void sequentiallySort(Integer[] array, int lo, int hi) {
??????? Arrays.sort(array, lo, hi + 1);
?}

but I don't know how should I design the merge(array, lo, hi) method?

any hints?

Thanks,
Ramsundar Kandasamy





      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/5764af03/attachment.html>

From dl at cs.oswego.edu  Tue Mar 16 07:47:22 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 16 Mar 2010 07:47:22 -0400
Subject: [concurrency-interest] Merging forked tasks - Repeating because
 of	some formatting problem
In-Reply-To: <248557.91136.qm@web113204.mail.gq1.yahoo.com>
References: <248557.91136.qm@web113204.mail.gq1.yahoo.com>
Message-ID: <4B9F6FCA.6090206@cs.oswego.edu>

On 03/16/10 06:55, Ramsundar Kandasamy wrote:
>
> I am playing around with this ForkJoin framework. I was trying the first
> sample usage of RecursiveAction given in its javaDoc page.
>
> class SortTask extends RecursiveAction {
> ....
> protected void compute() {
> if (hi - lo < THRESHOLD)
> sequentiallySort(array, lo, hi);
> else {
> int mid = (lo + hi) >>> 1;
> invokeAll(new SortTask(array, lo, mid), new SortTask(array, mid, hi));
> merge(array, lo, hi); //!!!!! how to do this
> }
> }
> }
>
> and following is my sequentiallySort method
>
> private void sequentiallySort(Integer[] array, int lo, int hi) {
> Arrays.sort(array, lo, hi + 1);
> }
>
> but I don't know how should I design the merge(array, lo, hi) method?
>

While any kind of array merge will suffice,
one way to do this that enables more parallelism
(adapted from "cilksort") is included in one of
our test programs, ScalaraLongSort that you now find in CVS:
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/ScalarLongSort.java?view=log

-Doug


From bryan at systap.com  Tue Mar 16 09:16:37 2010
From: bryan at systap.com (Bryan Thompson)
Date: Tue, 16 Mar 2010 08:16:37 -0500
Subject: [concurrency-interest] Multi-level locks
In-Reply-To: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com>
References: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com>
Message-ID: <DE10B00CCE0DC54883734F3060AC9ED44D6096311A@AUSP01VMBX06.collaborationhost.net>

Khilan,

Many databases have moved away from pessimistic locking.  Are you sure that you need this in your architecture rather than an optimistic concurrency strategy with validation during the commit protocol?  This often leads to higher throughput and can have the advantage that readers never block when coupled with a MVCC.

Thanks,

Bryan

________________________________
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Khilan Gudka
Sent: Monday, March 15, 2010 11:19 AM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Multi-level locks

Dear all,

I'm looking to produce a high-performant implementation of multi-granularity (a.k.a multi-level) locks. I'm basing my implementation on the paper "Granularity of Locks in a Shared Data Base" by Gray et al. There are five modes: Shared (S), Exclusive (X), Intention Shared (IS), Intention Exclusive (IX) and Shared Intention Exclusive (SIX - this last mode can be represented implicitly by non-zero counts for both S and IX).

I currently have an implementation whereby I use a long to represent state. There is a global state for the lock that gives the status of the lock with respect to all threads as well as per-thread state for a thread's count of each of the above modes (minus the implicitly  represented mode SIX). Determining whether a request from a thread can proceed is achieved by subtracting the two (giving a so-called "group mode" of the other threads) and then doing a bit-wise AND to determine compatibility of the request with the group mode). I keep two queues (ConcurrentLinkedQueue) for upgrades and new requests respectively. To keep the implementation simple, the lock and unlock methods are synchronized. However, this doesn't perform very well. For instance, 8 threads incrementing a counter 100000 times takes 10 seconds compared with 0.2 seconds when using j.u.c.ReentrantReadWriteLock.

I've been looking at AbstractQueuedLongSynchronizer and noticed in the javadoc comments that it's designed for this sort of thing. However, from what I've seen it only supports the two modes S and X. Furthermore, it doesn't seem trivial to extend the internal wait queue given that the Node class is final? or is it?

If somebody could please give me some advice as to how to proceed, I would be ever so grateful.

Thanks,
Khilan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/b16afccd/attachment.html>

From tim at peierls.net  Tue Mar 16 09:28:21 2010
From: tim at peierls.net (Tim Peierls)
Date: Tue, 16 Mar 2010 09:28:21 -0400
Subject: [concurrency-interest] Multi-level locks
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEGBIFAA.davidcholmes@aapt.net.au>
References: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEGBIFAA.davidcholmes@aapt.net.au>
Message-ID: <63b4e4051003160628m6a7470feq797fe8738f7f3451@mail.gmail.com>

On Mon, Mar 15, 2010 at 6:51 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

>  There's also an example on using AQS to do Room Synchronization that we
> presented at various places, but for which I'm having trouble finding an
> actual link. :( Contact me if you'd like me to dig it up. I think there
> should be a JavaOne presentation with it in, somewhere.
>

I don't remember a J1 presentation, but I do remember putting together a
room synchronizer based on AQS:

https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/RoomSynchronizer.java

I can't find any test suites with it, so I'd treat this code as more of a
sketch than a real implementation. (For example, the comment for private
static method indexMask looks wrong to me. For another, the use of a map
instead of an array to hold the room locks now strikes me as an unnecessary
and expensive nicety.)

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/b72f04cb/attachment-0001.html>

From tim at peierls.net  Tue Mar 16 09:28:21 2010
From: tim at peierls.net (Tim Peierls)
Date: Tue, 16 Mar 2010 09:28:21 -0400
Subject: [concurrency-interest] Multi-level locks
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEGBIFAA.davidcholmes@aapt.net.au>
References: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEGBIFAA.davidcholmes@aapt.net.au>
Message-ID: <63b4e4051003160628m6a7470feq797fe8738f7f3451@mail.gmail.com>

On Mon, Mar 15, 2010 at 6:51 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

>  There's also an example on using AQS to do Room Synchronization that we
> presented at various places, but for which I'm having trouble finding an
> actual link. :( Contact me if you'd like me to dig it up. I think there
> should be a JavaOne presentation with it in, somewhere.
>

I don't remember a J1 presentation, but I do remember putting together a
room synchronizer based on AQS:

https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/RoomSynchronizer.java

I can't find any test suites with it, so I'd treat this code as more of a
sketch than a real implementation. (For example, the comment for private
static method indexMask looks wrong to me. For another, the use of a map
instead of an array to hold the room locks now strikes me as an unnecessary
and expensive nicety.)

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/b72f04cb/attachment-0002.html>

From khilan at doc.ic.ac.uk  Tue Mar 16 09:45:01 2010
From: khilan at doc.ic.ac.uk (Khilan Gudka)
Date: Tue, 16 Mar 2010 13:45:01 +0000
Subject: [concurrency-interest] Multi-level locks
In-Reply-To: <63b4e4051003160628m6a7470feq797fe8738f7f3451@mail.gmail.com>
References: <d376f1f51003150819o3e4d40d6n9d72c1a4bb41d8f8@mail.gmail.com> 
	<NFBBKALFDCPFIDBNKAPCMEGBIFAA.davidcholmes@aapt.net.au>
	<63b4e4051003160628m6a7470feq797fe8738f7f3451@mail.gmail.com>
Message-ID: <d376f1f51003160645i571f720dr30dff14cf5767151@mail.gmail.com>

Hi David, Bryan and Tim,

Thanks for your replies. I will read Doug's AQS paper but from David's
reply, I think I misunderstood how I could use AQS and now see the potential
perhaps of representing multiple modes within AQS's S mode given that
tryAcquireShared is called again when waking up a queued thread? I'm still
not sure how I could give priority to upgraders? The paper mentions barging?

Bryan: I absolute agree that optimistic techniques such as transactional
memory can give better throughput and scalability. I'm currently researching
lock inference techniques for implementing atomic blocks ( i.e. atomic { ...
} ) using locks. There are times when atomics might need to use locks over
TM, such as if it contains I/O.

Our current approach uses multi-granularity locks when the set of objects
accessed cannot be statically determined - in this case, we lock types
(multi-granularity locks allow us to support both type locks and instance
locks rather than reverting only to type locks), although in the future we'd
like to look into more fine-grained approaches.

Tim: thanks for the link, I'll have a look.

Thanks again,
Khilan

On 16 March 2010 13:28, Tim Peierls <tim at peierls.net> wrote:

> On Mon, Mar 15, 2010 at 6:51 PM, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>>  There's also an example on using AQS to do Room Synchronization that we
>> presented at various places, but for which I'm having trouble finding an
>> actual link. :( Contact me if you'd like me to dig it up. I think there
>> should be a JavaOne presentation with it in, somewhere.
>>
>
> I don't remember a J1 presentation, but I do remember putting together a
> room synchronizer based on AQS:
>
>
> https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/RoomSynchronizer.java
>
> I can't find any test suites with it, so I'd treat this code as more of a
> sketch than a real implementation. (For example, the comment for private
> static method indexMask looks wrong to me. For another, the use of a map
> instead of an array to hold the room locks now strikes me as an unnecessary
> and expensive nicety.)
>
> --tim
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/7ec9ce4f/attachment.html>

From khilan at doc.ic.ac.uk  Tue Mar 16 17:07:18 2010
From: khilan at doc.ic.ac.uk (Khilan Gudka)
Date: Tue, 16 Mar 2010 21:07:18 +0000
Subject: [concurrency-interest] tryAcquire vs tryAcquireShared in
	ReentrantReadWriteLock
Message-ID: <d376f1f51003161407o12f0fba4v7527f6dbf820a9de@mail.gmail.com>

Dear all,

Please excuse me if this question is trivial but I was just wondering why
tryAcquireShared in ReentrantReadWriteLock uses a loop to deal with CAS
misses whereas tryAcquire just returns false. Is this because it's most
likely that the lock is now unavailable and would therefore save a loop
iteration?

Khilan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100316/36e274ce/attachment.html>

From martinrb at google.com  Tue Mar 16 18:30:39 2010
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 16 Mar 2010 15:30:39 -0700
Subject: [concurrency-interest] tryAcquire vs tryAcquireShared in
	ReentrantReadWriteLock
In-Reply-To: <d376f1f51003161407o12f0fba4v7527f6dbf820a9de@mail.gmail.com>
References: <d376f1f51003161407o12f0fba4v7527f6dbf820a9de@mail.gmail.com>
Message-ID: <1ccfd1c11003161530qf746f46qd781268a48222e0a@mail.gmail.com>

If a cas fails in tryAcquire, you know someone else
has just acquired a lock in a way that prevents you from
also acquiring it.

In tryAcquireShared, it may be the thread winning the cas
also acquired in shared mode, and so it is worth retrying.

Martin

On Tue, Mar 16, 2010 at 14:07, Khilan Gudka <khilan at doc.ic.ac.uk> wrote:
> Dear all,
> Please excuse me if this question is trivial but I was just wondering why
> tryAcquireShared in ReentrantReadWriteLock uses a loop to deal with CAS
> misses whereas tryAcquire just returns false. Is this because it's most
> likely that the lock is now unavailable and would therefore save a loop
> iteration?
> Khilan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From kramasundar at yahoo.com  Wed Mar 17 04:09:38 2010
From: kramasundar at yahoo.com (Ramsundar Kandasamy)
Date: Wed, 17 Mar 2010 01:09:38 -0700 (PDT)
Subject: [concurrency-interest] Merging forked tasks - Repeating because
	of some formatting problem
In-Reply-To: <4B9F6FCA.6090206@cs.oswego.edu>
Message-ID: <774304.62812.qm@web113208.mail.gq1.yahoo.com>

Thanks Doug.

I will try your suggestion to use Merger from your ScalarLongSort example.

Thanks,

Ramsundar Kandasamy

kramasundar.blogspot.com???? GoogleTamil ? ?? ProjectMadurai ? ? ? ? ?

--- On Tue, 3/16/10, Doug Lea <dl at cs.oswego.edu> wrote:

From: Doug Lea <dl at cs.oswego.edu>
Subject: Re: [concurrency-interest] Merging forked tasks - Repeating because of some formatting problem
To: concurrency-interest at cs.oswego.edu
Date: Tuesday, March 16, 2010, 5:17 PM

On 03/16/10 06:55, Ramsundar Kandasamy wrote:
>
> I am playing around with this ForkJoin framework. I was trying the first
> sample usage of RecursiveAction given in its javaDoc page.
>
> class SortTask extends RecursiveAction {
> ....
> protected void compute() {
> if (hi - lo < THRESHOLD)
> sequentiallySort(array, lo, hi);
> else {
> int mid = (lo + hi) >>> 1;
> invokeAll(new SortTask(array, lo, mid), new SortTask(array, mid, hi));
> merge(array, lo, hi); //!!!!! how to do this
> }
> }
> }
>
> and following is my sequentiallySort method
>
> private void sequentiallySort(Integer[] array, int lo, int hi) {
> Arrays.sort(array, lo, hi + 1);
> }
>
> but I don't know how should I design the merge(array, lo, hi) method?
>

While any kind of array merge will suffice,
one way to do this that enables more parallelism
(adapted from "cilksort") is included in one of
our test programs, ScalaraLongSort that you now find in CVS:
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/ScalarLongSort.java?view=log

-Doug

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100317/a41083db/attachment.html>

From hanson.char at gmail.com  Wed Mar 17 12:34:39 2010
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 17 Mar 2010 09:34:39 -0700
Subject: [concurrency-interest] Unmodifiable Navigable{Set,Map} ?
Message-ID: <ca53c8f81003170934h1fe67687m9715d353b1ba16e4@mail.gmail.com>

Does it make sense to have a "non-concurrent" skip list set/map
implementation and provide a Collections.unmodifiableNaviable{Set,Map}(...)
method so clients can choose to operate on an immutable Navigable{Set,Map},
which is (by definition) both thread-safe and presumably can be a more light
weight implementation than the existing ConcurrentSkipList{Set,Map} ?  Is
the current lack of such API's an accident or by intent ?

Thanks,
Hanson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100317/39001c68/attachment.html>

From kevinb at google.com  Wed Mar 17 12:55:13 2010
From: kevinb at google.com (Kevin Bourrillion)
Date: Wed, 17 Mar 2010 09:55:13 -0700
Subject: [concurrency-interest] Unmodifiable Navigable{Set,Map} ?
In-Reply-To: <ca53c8f81003170934h1fe67687m9715d353b1ba16e4@mail.gmail.com>
References: <ca53c8f81003170934h1fe67687m9715d353b1ba16e4@mail.gmail.com>
Message-ID: <108fcdeb1003170955p2aa94816p27fa742a33cd5b8b@mail.gmail.com>

If you can make do with the older Sorted{Set,Map} interfaces, there are
array-based immutable implementations in google-collections 1.0.

http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSortedSet.html
http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSortedMap.html



On Wed, Mar 17, 2010 at 9:34 AM, Hanson Char <hanson.char at gmail.com> wrote:

> Does it make sense to have a "non-concurrent" skip list set/map
> implementation and provide a Collections.unmodifiableNaviable{Set,Map}(...)
> method so clients can choose to operate on an immutable Navigable{Set,Map},
> which is (by definition) both thread-safe and presumably can be a more light
> weight implementation than the existing ConcurrentSkipList{Set,Map} ?  Is
> the current lack of such API's an accident or by intent ?
>
> Thanks,
> Hanson
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Kevin Bourrillion @ Google
internal:  http://goto/javalibraries
external: http://guava-libraries.googlecode.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100317/a7b0ff80/attachment.html>

From hanson.char at gmail.com  Wed Mar 17 20:48:28 2010
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 17 Mar 2010 17:48:28 -0700
Subject: [concurrency-interest] Unmodifiable Navigable{Set,Map} ?
In-Reply-To: <108fcdeb1003170955p2aa94816p27fa742a33cd5b8b@mail.gmail.com>
References: <ca53c8f81003170934h1fe67687m9715d353b1ba16e4@mail.gmail.com>
	<108fcdeb1003170955p2aa94816p27fa742a33cd5b8b@mail.gmail.com>
Message-ID: <ca53c8f81003171748h769f4a0apb554a2387136f9f1@mail.gmail.com>

Actually TreeSet and TreeMap are the non-concurrent navigable Set/Map in the
jdk.  Would be nice if there is a
Collections.unmodifiableNavigable{Set,Map}(...).

Or in the google-collections case, would be nice if there is an
ImmutableNavigable{Set,Map}.

Hanson

On Wed, Mar 17, 2010 at 9:55 AM, Kevin Bourrillion <kevinb at google.com>wrote:

> If you can make do with the older Sorted{Set,Map} interfaces, there are
> array-based immutable implementations in google-collections 1.0.
>
>
> http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSortedSet.html
>
> http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSortedMap.html
>
>
>
> On Wed, Mar 17, 2010 at 9:34 AM, Hanson Char <hanson.char at gmail.com>wrote:
>
>> Does it make sense to have a "non-concurrent" skip list set/map
>> implementation and provide a Collections.unmodifiableNaviable{Set,Map}(...)
>> method so clients can choose to operate on an immutable Navigable{Set,Map},
>> which is (by definition) both thread-safe and presumably can be a more light
>> weight implementation than the existing ConcurrentSkipList{Set,Map} ?  Is
>> the current lack of such API's an accident or by intent ?
>>
>> Thanks,
>> Hanson
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Kevin Bourrillion @ Google
> internal:  http://goto/javalibraries
> external: http://guava-libraries.googlecode.com
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100317/f7cc10dd/attachment.html>

From hanson.char at gmail.com  Thu Mar 18 12:02:17 2010
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 18 Mar 2010 09:02:17 -0700
Subject: [concurrency-interest] Unmodifiable Navigable{Set,Map} ?
In-Reply-To: <ca53c8f81003171748h769f4a0apb554a2387136f9f1@mail.gmail.com>
References: <ca53c8f81003170934h1fe67687m9715d353b1ba16e4@mail.gmail.com>
	<108fcdeb1003170955p2aa94816p27fa742a33cd5b8b@mail.gmail.com>
	<ca53c8f81003171748h769f4a0apb554a2387136f9f1@mail.gmail.com>
Message-ID: <ca53c8f81003180902p6893e84dj7e42dd3ef3ec1d94@mail.gmail.com>

In general, if one can ensure a TreeMap is not modified after initialization
(with a given data set), I would expect the subsequent read-only access to
it would have better performance (both in terms of memory footprint and
latency) as compared to the use of a ConcurrentSkipListMap (which is also
not modified after initialization with the same data set).

Is this a reasonable expectation ?

Thanks,
Hanson

On Wed, Mar 17, 2010 at 5:48 PM, Hanson Char <hanson.char at gmail.com> wrote:

> Actually TreeSet and TreeMap are the non-concurrent navigable Set/Map in
> the jdk.  Would be nice if there is a
> Collections.unmodifiableNavigable{Set,Map}(...).
>
> Or in the google-collections case, would be nice if there is an
> ImmutableNavigable{Set,Map}.
>
> Hanson
>
>
> On Wed, Mar 17, 2010 at 9:55 AM, Kevin Bourrillion <kevinb at google.com>wrote:
>
>> If you can make do with the older Sorted{Set,Map} interfaces, there are
>> array-based immutable implementations in google-collections 1.0.
>>
>>
>> http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSortedSet.html
>>
>> http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSortedMap.html
>>
>>
>>
>> On Wed, Mar 17, 2010 at 9:34 AM, Hanson Char <hanson.char at gmail.com>wrote:
>>
>>> Does it make sense to have a "non-concurrent" skip list set/map
>>> implementation and provide a Collections.unmodifiableNaviable{Set,Map}(...)
>>> method so clients can choose to operate on an immutable Navigable{Set,Map},
>>> which is (by definition) both thread-safe and presumably can be a more light
>>> weight implementation than the existing ConcurrentSkipList{Set,Map} ?  Is
>>> the current lack of such API's an accident or by intent ?
>>>
>>> Thanks,
>>> Hanson
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> --
>> Kevin Bourrillion @ Google
>> internal:  http://goto/javalibraries
>> external: http://guava-libraries.googlecode.com
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100318/61a9eecd/attachment.html>

From concurrency-interest at majumdar.org.uk  Thu Mar 18 18:05:34 2010
From: concurrency-interest at majumdar.org.uk (Dibyendu Majumdar)
Date: Thu, 18 Mar 2010 22:05:34 +0000
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
Message-ID: <bb93b72b1003181505m3fc12654h749788cdf600c382@mail.gmail.com>

I am running Java 1.5 on Mac OS X Tiger - and I think that the
ThreadPoolExecutor code is a very old version. The pool is not shutting
down; by running through the debugger I can see that all idle threads are
blocked on a queue, and the shutdown sequence does not interrupt idle
threads.
Is there any way I can run a more up-to-date version with Java 1.5?
Is there a known workaround to this issue?

Many thanks

Regards
Dibyendu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100318/41a40f29/attachment.html>

From ben_manes at yahoo.com  Thu Mar 18 20:35:26 2010
From: ben_manes at yahoo.com (Ben Manes)
Date: Thu, 18 Mar 2010 17:35:26 -0700 (PDT)
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
In-Reply-To: <bb93b72b1003181505m3fc12654h749788cdf600c382@mail.gmail.com>
References: <bb93b72b1003181505m3fc12654h749788cdf600c382@mail.gmail.com>
Message-ID: <392043.937.qm@web38807.mail.mud.yahoo.com>

This sounds like you'd want to use daemon thread factory, use a shutdown hook to stop the executor, or another approach to let the VM gracefully exit.




________________________________
From: Dibyendu Majumdar <concurrency-interest at majumdar.org.uk>
To: concurrency-interest at cs.oswego.edu
Sent: Thu, March 18, 2010 3:05:34 PM
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down

I am running Java 1.5 on Mac OS X Tiger - and I think that the ThreadPoolExecutor code is a very old version. The pool is not shutting down; by running through the debugger I can see that all idle threads are blocked on a queue, and the shutdown sequence does not interrupt idle threads.
Is there any way I can run a more up-to-date version with Java 1.5?
Is there a known workaround to this issue?

Many thanks

Regards
Dibyendu


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100318/9728d14c/attachment.html>

From davidcholmes at aapt.net.au  Thu Mar 18 20:43:47 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 19 Mar 2010 10:43:47 +1000
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
In-Reply-To: <392043.937.qm@web38807.mail.mud.yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEHDIFAA.davidcholmes@aapt.net.au>

In general a ThreadPoolExecutor must be explicitly shutdown. Your
application needs to manage the TPE lifecycle. In later JDK versions you can
use the idle timeout on core threads to let all threads terminate.

A daemon thread factory will prevent the TPE from keeping the VM alive, but
at the risk of allowing submitted tasks to not be run or to be terminated in
the midst of execution - generally not a good thing.

A shutdown hook is of little help here as the hooks will only run if the VM
has decided to shutdown due to no user-threads (which can't be the case due
to the TPE), or System.exit has been called, in which case there's no need
to explicitly shutdown the TPE (it's about to get obliterated by process
termination), unless you want to manage the unfinished tasks.

HTH

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ben Manes
  Sent: Friday, 19 March 2010 10:35 AM
  To: Dibyendu Majumdar; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ThreadPoolExecutor not shutting down


  This sounds like you'd want to use daemon thread factory, use a shutdown
hook to stop the executor, or another approach to let the VM gracefully
exit.




----------------------------------------------------------------------------
--
  From: Dibyendu Majumdar <concurrency-interest at majumdar.org.uk>
  To: concurrency-interest at cs.oswego.edu
  Sent: Thu, March 18, 2010 3:05:34 PM
  Subject: [concurrency-interest] ThreadPoolExecutor not shutting down

  I am running Java 1.5 on Mac OS X Tiger - and I think that the
ThreadPoolExecutor code is a very old version. The pool is not shutting
down; by running through the debugger I can see that all idle threads are
blocked on a queue, and the shutdown sequence does not interrupt idle
threads.
  Is there any way I can run a more up-to-date version with Java 1.5?
  Is there a known workaround to this issue?

  Many thanks

  Regards
  Dibyendu





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100319/1ceba953/attachment.html>

From i30817 at gmail.com  Thu Mar 18 22:10:16 2010
From: i30817 at gmail.com (Paulo Levi)
Date: Fri, 19 Mar 2010 02:10:16 +0000
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEHDIFAA.davidcholmes@aapt.net.au>
References: <392043.937.qm@web38807.mail.mud.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOEHDIFAA.davidcholmes@aapt.net.au>
Message-ID: <212322091003181910t137b9fb0y40e5c8d56873467b@mail.gmail.com>

Actually i had a bug a few months ago where a apparently terminated jvm
(called system.exit) was still not terminating. Using a shutdownhook to
terminate all the executors i created "solved" it, i have no idea why (they
were using deamon thread factories).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100319/3551efc6/attachment.html>

From concurrency-interest at majumdar.org.uk  Sat Mar 20 07:59:29 2010
From: concurrency-interest at majumdar.org.uk (Dibyendu Majumdar)
Date: Sat, 20 Mar 2010 11:59:29 +0000
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEHDIFAA.davidcholmes@aapt.net.au>
References: <392043.937.qm@web38807.mail.mud.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOEHDIFAA.davidcholmes@aapt.net.au>
Message-ID: <bb93b72b1003200459x35e1f334r877789ece68ba551@mail.gmail.com>

David, Ben,

Thank you for responding to my query. It turns out that this problem was
because of a bug in my code; one of the pools wasn't being explicitly
shutdown.

The fact that the MAC OS X Tiger version of the concurrency library is so
old did alarm me. But I suppose that unless Apple do something about it, we
have to live with it. As far as I understand, the latest library is
incompatible with Java 5 - am I correct?

Regards

Dibyendu

On 19 March 2010 00:43, David Holmes <davidcholmes at aapt.net.au> wrote:

>  In general a ThreadPoolExecutor must be explicitly shutdown. Your
> application needs to manage the TPE lifecycle. In later JDK versions you can
> use the idle timeout on core threads to let all threads terminate.
>
> A daemon thread factory will prevent the TPE from keeping the VM alive, but
> at the risk of allowing submitted tasks to not be run or to be terminated in
> the midst of execution - generally not a good thing.
>
> A shutdown hook is of little help here as the hooks will only run if the VM
> has decided to shutdown due to no user-threads (which can't be the case due
> to the TPE), or System.exit has been called, in which case there's no need
> to explicitly shutdown the TPE (it's about to get obliterated by process
> termination), unless you want to manage the unfinished tasks.
>
> HTH
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Ben Manes
> *Sent:* Friday, 19 March 2010 10:35 AM
> *To:* Dibyendu Majumdar; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] ThreadPoolExecutor not shutting down
>
>  This sounds like you'd want to use daemon thread factory, use a shutdown
> hook to stop the executor, or another approach to let the VM gracefully
> exit.
>
>  ------------------------------
> *From:* Dibyendu Majumdar <concurrency-interest at majumdar.org.uk>
> *To:* concurrency-interest at cs.oswego.edu
> *Sent:* Thu, March 18, 2010 3:05:34 PM
> *Subject:* [concurrency-interest] ThreadPoolExecutor not shutting down
>
> I am running Java 1.5 on Mac OS X Tiger - and I think that the
> ThreadPoolExecutor code is a very old version. The pool is not shutting
> down; by running through the debugger I can see that all idle threads are
> blocked on a queue, and the shutdown sequence does not interrupt idle
> threads.
> Is there any way I can run a more up-to-date version with Java 1.5?
> Is there a known workaround to this issue?
>
> Many thanks
>
> Regards
> Dibyendu
>
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100320/d5d493f5/attachment.html>

From martinrb at google.com  Sat Mar 20 15:21:02 2010
From: martinrb at google.com (Martin Buchholz)
Date: Sat, 20 Mar 2010 12:21:02 -0700
Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
In-Reply-To: <bb93b72b1003200459x35e1f334r877789ece68ba551@mail.gmail.com>
References: <392043.937.qm@web38807.mail.mud.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOEHDIFAA.davidcholmes@aapt.net.au>
	<bb93b72b1003200459x35e1f334r877789ece68ba551@mail.gmail.com>
Message-ID: <1ccfd1c11003201221n127e723dweeedf81dfde574a0@mail.gmail.com>

There's a pretty good chance that
ThreadPoolExecutor and ScheduledThreadPoolExecutor
from a recent JDK or Doug's CVS would
Just Work with an older JDK.

Try it - you'll have to compile them and prepend to
bootclasspath using  -Xbootclasspath/p:

Martin

On Sat, Mar 20, 2010 at 04:59, Dibyendu Majumdar
<concurrency-interest at majumdar.org.uk> wrote:
> David, Ben,
> The fact that the MAC OS X Tiger version of the concurrency library is so
> old did alarm me. But I suppose that unless Apple do something about it, we
> have to live with it. As far as I understand, the latest library is
> incompatible with Java 5 - am I correct?
>
> Regards
>
> Dibyendu
>
> On 19 March 2010 00:43, David Holmes <davidcholmes at aapt.net.au> wrote:
>>
>> In general a ThreadPoolExecutor must be explicitly shutdown. Your
>> application needs to manage the TPE lifecycle.?In later JDK versions you can
>> use the idle timeout on core threads to let all threads terminate.
>>
>> A daemon thread factory will prevent the TPE from keeping the VM alive,
>> but at the risk of allowing submitted tasks to not be run or to be
>> terminated in the midst of execution - generally not a good thing.
>>
>> A shutdown hook is of?little help here as the hooks will only run if the
>> VM has decided to shutdown due to no user-threads (which can't be the case
>> due to the TPE), or System.exit has been called, in which case there's no
>> need to explicitly shutdown the TPE (it's about to get obliterated by
>> process termination), unless you want to manage the unfinished tasks.
>>
>> HTH
>>
>> David Holmes
>>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ben Manes
>> Sent: Friday, 19 March 2010 10:35 AM
>> To: Dibyendu Majumdar; concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] ThreadPoolExecutor not shutting down
>>
>> This sounds like you'd want to use daemon thread factory, use a shutdown
>> hook to stop the executor, or another approach to let the VM gracefully
>> exit.
>>
>> ________________________________
>> From: Dibyendu Majumdar <concurrency-interest at majumdar.org.uk>
>> To: concurrency-interest at cs.oswego.edu
>> Sent: Thu, March 18, 2010 3:05:34 PM
>> Subject: [concurrency-interest] ThreadPoolExecutor not shutting down
>>
>> I am running Java 1.5 on Mac OS X Tiger - and I think that the
>> ThreadPoolExecutor code is a very old version. The pool is not shutting
>> down; by running through the debugger I can see that all idle threads are
>> blocked on a queue, and the shutdown sequence does not interrupt idle
>> threads.
>> Is there any way I can run a more up-to-date version with Java 1.5?
>> Is there a known workaround to this issue?
>>
>> Many thanks
>>
>> Regards
>> Dibyendu
>>
>>
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From ramesh.mandaleeka at gmail.com  Tue Mar 23 12:53:28 2010
From: ramesh.mandaleeka at gmail.com (Ramesh Mandaleeka)
Date: Tue, 23 Mar 2010 12:53:28 -0400
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
Message-ID: <a55f9dae1003230953j1c0e1338w55f1059481a25e06@mail.gmail.com>

Hi,

May be not directly related to concurrency. But here is my question:

What is the default size of the Thread Stack and Thead Local Data. Does it
depend on OS? When I did ulimit command on my server I see stack size. Does
this related to Thread Stack in Java.

*ulimit -a
*
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 532480
max locked memory       (kbytes, -l) 32
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
*stack size              (kbytes, -s) 10240*
cpu time               (seconds, -t) unlimited
max user processes              (-u) 532480
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

Regards,
Ramesh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100323/d298cc86/attachment.html>

From kramasundar at yahoo.com  Tue Mar 23 15:55:22 2010
From: kramasundar at yahoo.com (Ramsundar Kandasamy)
Date: Tue, 23 Mar 2010 12:55:22 -0700 (PDT)
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <a55f9dae1003230953j1c0e1338w55f1059481a25e06@mail.gmail.com>
Message-ID: <368201.48039.qm@web113216.mail.gq1.yahoo.com>

Hi Ramesh

Here is part of the answer

http://java.sun.com/docs/hotspot/HotSpotFAQ.html#threads_oom

Regards
Ramsundar Kandasamy


kramasundar.blogspot.com???? GoogleTamil ? ?? ProjectMadurai ? ? ? ? ?

--- On Tue, 3/23/10, Ramesh Mandaleeka <ramesh.mandaleeka at gmail.com> wrote:

From: Ramesh Mandaleeka <ramesh.mandaleeka at gmail.com>
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
To: concurrency-interest at cs.oswego.edu
Date: Tuesday, March 23, 2010, 10:23 PM

Hi,

May be not directly related to concurrency. But here is my question:

What is the default size of the Thread Stack and Thead Local Data. Does it depend on OS? When I did ulimit command on my server I see stack size. Does this related to Thread Stack in Java.


?
ulimit -a

core file size????????? (blocks, -c) 0
data seg size?????????? (kbytes, -d) unlimited
scheduling priority???????????? (-e) 0
file size?????????????? (blocks, -f) unlimited
pending signals???????????????? (-i) 532480


max locked memory?????? (kbytes, -l) 32
max memory size???????? (kbytes, -m) unlimited
open files????????????????????? (-n) 1024
pipe size??????????? (512 bytes, -p) 8
POSIX message queues???? (bytes, -q) 819200


real-time priority????????????? (-r) 0
stack size????????????? (kbytes, -s) 10240
cpu time?????????????? (seconds, -t) unlimited
max user processes????????????? (-u) 532480
virtual memory????????? (kbytes, -v) unlimited


file locks????????????????????? (-x) unlimited

Regards,
Ramesh


-----Inline Attachment Follows-----

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100323/cec49488/attachment.html>

From davidcholmes at aapt.net.au  Tue Mar 23 18:32:48 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 24 Mar 2010 08:32:48 +1000
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <a55f9dae1003230953j1c0e1338w55f1059481a25e06@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEHNIFAA.davidcholmes@aapt.net.au>

Hi Ramesh,

The default Java thread stack size is platform specific but can be set with -Xss parameter on JVM startup (or can be set for individual threads via their constructor). This stack size is not related to that seen in ulimit because the VM explicitly sets the stack size when native threads are created.

As for "Thread Local Data" I'm not sure exactly what you mean by that.

HTH

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ramesh Mandaleeka
  Sent: Wednesday, 24 March 2010 2:53 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Thread Stack Size and Thread Local Data


  Hi,

  May be not directly related to concurrency. But here is my question:

  What is the default size of the Thread Stack and Thead Local Data. Does it depend on OS? When I did ulimit command on my server I see stack size. Does this related to Thread Stack in Java.
   
  ulimit -a

  core file size          (blocks, -c) 0
  data seg size           (kbytes, -d) unlimited
  scheduling priority             (-e) 0
  file size               (blocks, -f) unlimited
  pending signals                 (-i) 532480
  max locked memory       (kbytes, -l) 32
  max memory size         (kbytes, -m) unlimited
  open files                      (-n) 1024
  pipe size            (512 bytes, -p) 8
  POSIX message queues     (bytes, -q) 819200
  real-time priority              (-r) 0
  stack size              (kbytes, -s) 10240
  cpu time               (seconds, -t) unlimited
  max user processes              (-u) 532480
  virtual memory          (kbytes, -v) unlimited
  file locks                      (-x) unlimited

  Regards,
  Ramesh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100324/55a40ac2/attachment.html>

From ramesh.mandaleeka at gmail.com  Tue Mar 23 19:28:20 2010
From: ramesh.mandaleeka at gmail.com (Ramesh Mandaleeka)
Date: Tue, 23 Mar 2010 19:28:20 -0400
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEHNIFAA.davidcholmes@aapt.net.au>
References: <a55f9dae1003230953j1c0e1338w55f1059481a25e06@mail.gmail.com> 
	<NFBBKALFDCPFIDBNKAPCKEHNIFAA.davidcholmes@aapt.net.au>
Message-ID: <a55f9dae1003231628x581b345fi8dceec8e11908c43@mail.gmail.com>

Thank you all for the response.

David - I was referring to the data that we store in Thread Local variables.
I guess it goes on to the threads stack, right?

Regards,
Ramesh



On Tue, Mar 23, 2010 at 6:32 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

>  Hi Ramesh,
>
> The default Java thread stack size is platform specific but can be set with
> -Xss parameter on JVM startup (or can be set for individual threads via
> their constructor). This stack size is not related to that seen in ulimit
> because the VM explicitly sets the stack size when native threads are
> created.
>
> As for "Thread Local Data" I'm not sure exactly what you mean by that.
>
> HTH
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Ramesh
> Mandaleeka
> *Sent:* Wednesday, 24 March 2010 2:53 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Thread Stack Size and Thread Local Data
>
> Hi,
>
> May be not directly related to concurrency. But here is my question:
>
> What is the default size of the Thread Stack and Thead Local Data. Does it
> depend on OS? When I did ulimit command on my server I see stack size. Does
> this related to Thread Stack in Java.
>
> *ulimit -a
> *
> core file size          (blocks, -c) 0
> data seg size           (kbytes, -d) unlimited
> scheduling priority             (-e) 0
> file size               (blocks, -f) unlimited
> pending signals                 (-i) 532480
> max locked memory       (kbytes, -l) 32
> max memory size         (kbytes, -m) unlimited
> open files                      (-n) 1024
> pipe size            (512 bytes, -p) 8
> POSIX message queues     (bytes, -q) 819200
> real-time priority              (-r) 0
> *stack size              (kbytes, -s) 10240*
> cpu time               (seconds, -t) unlimited
> max user processes              (-u) 532480
> virtual memory          (kbytes, -v) unlimited
> file locks                      (-x) unlimited
>
> Regards,
> Ramesh
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100323/8477ec01/attachment-0001.html>

From crazybob at crazybob.org  Tue Mar 23 19:53:27 2010
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 23 Mar 2010 16:53:27 -0700
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <a55f9dae1003231628x581b345fi8dceec8e11908c43@mail.gmail.com>
References: <a55f9dae1003230953j1c0e1338w55f1059481a25e06@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHNIFAA.davidcholmes@aapt.net.au>
	<a55f9dae1003231628x581b345fi8dceec8e11908c43@mail.gmail.com>
Message-ID: <a74683f91003231653q6e269982v6dde948b8388111c@mail.gmail.com>

On Tue, Mar 23, 2010 at 4:28 PM, Ramesh Mandaleeka <
ramesh.mandaleeka at gmail.com> wrote:

> David - I was referring to the data that we store in Thread Local
> variables. I guess it goes on to the threads stack, right?
>

It goes in a map of Thread -> ThreadLocal -> [value] (in the heap).

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100323/abf009cd/attachment.html>

From michael.m.spiegel at gmail.com  Wed Mar 24 10:23:37 2010
From: michael.m.spiegel at gmail.com (Michael Spiegel)
Date: Wed, 24 Mar 2010 10:23:37 -0400
Subject: [concurrency-interest] cache-conscious alternative to
	ConcurrentSkipList[Set|Map]
Message-ID: <1901f69e1003240723v68fa7425s86010d4560956606@mail.gmail.com>

Hello,

I have been investigating a lock-free multiway search tree algorithm
for concurrent applications with large working set sizes.  The result
is a lock-free skip tree data structure.  Skip trees are randomized
search trees that share properties with B-trees and skip lists.
Similar to a skip list, a random number is selected on the
introduction of a key into the structure.  The random number
determines the level in the interior of the tree to place a key. In
the lock-free implementation, optimal paths through the tree are
temporarily violated by mutation operations, and eventually restored
using online node compaction.

I've placed skip-tree concurrent Set and Map implementations on
github: http://github.com/mspiegel/lockfreeskiptree.  They implement
the same interfaces as j.u.c.ConcurrentSkipList[Set|Map].  Any
feedback from the mailing list would be of tremendous value.
Preprints of the paper describing the algorithm are available on
request.

Cheers,
--Michael

From unmesh_joshi at hotmail.com  Wed Mar 24 10:24:58 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 24 Mar 2010 14:24:58 +0000
Subject: [concurrency-interest] Compiling Actors in scala and clojure to JVM
In-Reply-To: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
References: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W961FAFA0A1683ADFCE877EF250@phx.gbl>


Hi,
Is there any literature available about how actors in languages like scala and clojure are implemented on jvm? I was going through the thesis 'compiling scala for the jvm' (http://lamp.epfl.ch/~schinz/thesis-final-A4.pdf), but I could not find any mention of actors there.
Thanks,Unmesh 		 	   		  
_________________________________________________________________
What does Budget 2010 mean for you? Catch all the latest news, updates and analysis on MSN Budget Special
http://news.in.msn.com/moneyspecial/budget2010
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100324/405e7efb/attachment.html>

From unmesh_joshi at hotmail.com  Wed Mar 24 10:25:59 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 24 Mar 2010 14:25:59 +0000
Subject: [concurrency-interest] Compiling Actors in scala and clojure to JVM
In-Reply-To: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
References: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W58B45ECE755737DA8B091EF250@phx.gbl>


Hi,
Is there any literature available about how actors in languages like scala and clojure are implemented on jvm? I was going through the thesis 'compiling scala for the jvm' (http://lamp.epfl.ch/~schinz/thesis-final-A4.pdf), but I could not find any mention of actors there.
Thanks,Unmesh 		 	   		  
_________________________________________________________________
Fight for the top Test spot
http://sports.in.msn.com/cricket/ 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100324/ae2a9b98/attachment.html>

From unmesh_joshi at hotmail.com  Wed Mar 24 10:26:58 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 24 Mar 2010 14:26:58 +0000
Subject: [concurrency-interest] Compiling Actors in scala and clojure to JVM
In-Reply-To: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
References: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W12113CCA580871B3D225ECEF250@phx.gbl>


Hi,
Is there any literature available about how actors in languages like scala and clojure are implemented on jvm? I was going through the thesis 'compiling scala for the jvm' (http://lamp.epfl.ch/~schinz/thesis-final-A4.pdf), but I could not find any mention of actors there.
Thanks,Unmesh 		 	   		  
_________________________________________________________________
Fight for the top Test spot
http://sports.in.msn.com/cricket/ 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100324/2047bd9e/attachment.html>

From unmesh_joshi at hotmail.com  Wed Mar 24 10:27:58 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 24 Mar 2010 14:27:58 +0000
Subject: [concurrency-interest] Compiling Actors in scala and clojure to JVM
In-Reply-To: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
References: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W24A92242C761ED0767D88AEF250@phx.gbl>


Hi,
Is there any literature available about how actors in languages like scala and clojure are implemented on jvm? I was going through the thesis 'compiling scala for the jvm' (http://lamp.epfl.ch/~schinz/thesis-final-A4.pdf), but I could not find any mention of actors there.
Thanks,Unmesh 		 	   		  
_________________________________________________________________
The world in moving pictures
http://news.in.msn.com/gallery/archive.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100324/bae4cf29/attachment.html>

From concurrency-interest at stefan-marr.de  Wed Mar 24 11:41:13 2010
From: concurrency-interest at stefan-marr.de (Stefan Marr)
Date: Wed, 24 Mar 2010 16:41:13 +0100
Subject: [concurrency-interest] Compiling Actors in scala and clojure to
	JVM
In-Reply-To: <BAY140-W12113CCA580871B3D225ECEF250@phx.gbl>
References: <mailman.33.1269386928.3001.concurrency-interest@cs.oswego.edu>
	<BAY140-W12113CCA580871B3D225ECEF250@phx.gbl>
Message-ID: <21C03DA2-F1C7-4617-9242-2F95AC2D8118@stefan-marr.de>

Hi Unmesh:

Not exactly a detailed implementation description, but might be interesting nonetheless:

Actor Frameworks for the JVM Platform: A Comparative Analysis
by: Rajesh K. Karmani and Amin Shali and Gul Agha
In: PPPJ '09: Proceedings of the 7th International Conference on Principles and Practice of Programming in JavaNew York, NY, USA: ACM (2009), p. 11--20.

http://portal.acm.org/citation.cfm?id=1596658

Best regards
Stefan

On 24 Mar 2010, at 15:26, Unmesh joshi wrote:

> Hi,
> 
> Is there any literature available about how actors in languages like scala and clojure are implemented on jvm? I was going through the thesis 'compiling scala for the jvm' (http://lamp.epfl.ch/~schinz/thesis-final-A4.pdf), but I could not find any mention of actors there.
> 
> Thanks,
> Unmesh
> 
> The best dressed and the most admired Drag n' drop_______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
Stefan Marr
Software Languages Lab
Vrije Universiteit Brussel
Pleinlaan 2 / B-1050 Brussels / Belgium
http://soft.vub.ac.be/~smarr
Phone: +32 2 629 2974
Fax:   +32 2 629 3525



From martinrb at google.com  Wed Mar 24 11:48:08 2010
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 24 Mar 2010 08:48:08 -0700
Subject: [concurrency-interest] cache-conscious alternative to
	ConcurrentSkipList[Set|Map]
In-Reply-To: <1901f69e1003240723v68fa7425s86010d4560956606@mail.gmail.com>
References: <1901f69e1003240723v68fa7425s86010d4560956606@mail.gmail.com>
Message-ID: <1ccfd1c11003240848l35e79235g737267f089cef01c@mail.gmail.com>

Hi Michael,

Welcome to the lock-free data structure designers club.

I won't have time to do an in-depth review of your data structure,
but I do have some high-level comments:

I like very much the idea of mixing arrays and linked lists.
Java tends to have data structures implemented purely
using one or the other.

My own specialty is linked lists (we're still learning how to
implement them in the best way!).  Take a look at
our latest concurrent collections in Doug's CVS,
e.g. ConcurrentLinkedQueue and LinkedTransferQueue.
Or the ConcurrentLinkedDeque I am working on
http://cr.openjdk.java.net/~martin/CLD/

Is your data structure "GC-robust" as defined by Boehm?

Martin

On Wed, Mar 24, 2010 at 07:23, Michael Spiegel
<michael.m.spiegel at gmail.com> wrote:
> Hello,
>
> I have been investigating a lock-free multiway search tree algorithm
> for concurrent applications with large working set sizes. ?The result
> is a lock-free skip tree data structure. ?Skip trees are randomized
> search trees that share properties with B-trees and skip lists.
> Similar to a skip list, a random number is selected on the
> introduction of a key into the structure. ?The random number
> determines the level in the interior of the tree to place a key. In
> the lock-free implementation, optimal paths through the tree are
> temporarily violated by mutation operations, and eventually restored
> using online node compaction.
>
> I've placed skip-tree concurrent Set and Map implementations on
> github: http://github.com/mspiegel/lockfreeskiptree. ?They implement
> the same interfaces as j.u.c.ConcurrentSkipList[Set|Map]. ?Any
> feedback from the mailing list would be of tremendous value.
> Preprints of the paper describing the algorithm are available on
> request.
>
> Cheers,
> --Michael
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Fri Mar 26 19:15:26 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 27 Mar 2010 09:15:26 +1000
Subject: [concurrency-interest] [Javamemorymodel-discussion] How to
	interrupt a Thread Pool thread?
In-Reply-To: <4BACC712.3030901@cert.org>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEJGIFAA.davidcholmes@aapt.net.au>

Hi David,

I've redirected this to the concurrency-interest list.

One of the easiest ways to interrupt threads in a pool is to use the
interrupt() method on the ThreadGroup. But in short there are a number of
ways to get a hold of a Thread reference for a pool thread, most of which
you should not do, but there's nothing to stop you. And things you might
have done in a legacy design should not necessarily be carried over when
using an Executor.

By very strange coincidence I came across your guidelines just yesterday.

Cheers,
David Holmes

> -----Original Message-----
> From: javamemorymodel-discussion-bounces at cs.umd.edu
> [mailto:javamemorymodel-discussion-bounces at cs.umd.edu]On Behalf Of David
> Svoboda
> Sent: Saturday, 27 March 2010 12:39 AM
> To: javamemorymodel-discussion at cs.umd.edu
> Cc: David Svoboda
> Subject: [Javamemorymodel-discussion] How to interrupt a Thread Pool
> thread?
>
>
> While working on our Java Secure Coding standard rule CON35-J, we came
> across this excerpt from _Java Concurrency in Practice_, by Brian
> Goetz, Tim Peierls, Joshua Bloch, Joseph Bowbeer, David Holmes, Doug
> Lea. Addison Wesley Professional. (2006), pg 146:
>
>       You should note interrupt a pool thread directly when attempting to
>       cancel a task, because you won't know which task is running when
>       the interrupt request is delivered--do this only through the
>       task's Future.
>
> However, when studying the APIs supplied by J2SE for managing thread
> pools, such as ExecutorService, we discovered that they don't actually
> provide any API to access a Thread object that is part of a pool. So
> Java does not make it easy to interrupt a pool thread. I can think of
> only two ways to do it:
>
> (1) Have a pool thread stash its Thread.currentThread() property
>      somewhere that outside threads can access
>
> (2) Build your own thread pool that provides public access to the
>      threads in its pool
>
> Both seem quite complicated and intricate and not the type of mistake
> people are likely to make. Furthermore, if you go to the effort of
> building your own thread pool with publicly-accessible, you can also
> go to the effort of providing enough safety to interrupt your thread
> pool threads from outside the pool.
>
> So our question is, what did Goetz et al. mean by this statement? Is it
> a purely theoretical exercise and not likely to actually happen? Or is
> there some use case we haven't considered?
>
> CON35-J link: https://www.securecoding.cert.org/confluence/x/wICGAg
>
> --
> David Svoboda <svoboda at cert.org>
> Software Security Engineer
> CERT Secure Coding
> (412) 268-3965
> _______________________________________________
> Javamemorymodel-discussion mailing list
> Javamemorymodel-discussion at cs.umd.edu
> https://mailman.cs.umd.edu/mailman/listinfo/javamemorymodel-discussion


From bryan at systap.com  Tue Mar 30 07:45:53 2010
From: bryan at systap.com (Bryan Thompson)
Date: Tue, 30 Mar 2010 06:45:53 -0500
Subject: [concurrency-interest] JCJP Memoizer pattern
Message-ID: <DE10B00CCE0DC54883734F3060AC9ED44D60FC19FA@AUSP01VMBX06.collaborationhost.net>

Hello,

We've been using the "Memoizer" pattern from JCIP and run into a problem where an interrupt of the thread actually running the Computable is essentially propagated to all tasks awaiting the same Computable.  This was easy enough to fix by adding a flag indicating whether the thread awaiting the Future was the thread which actually ran the task.  If so, then we propagate the interrupt.  Otherwise we remove the FutureTask from the cache and retry, essentially discarding the interrupt for other callers.

Bryan


From tim at peierls.net  Tue Mar 30 10:53:45 2010
From: tim at peierls.net (Tim Peierls)
Date: Tue, 30 Mar 2010 10:53:45 -0400
Subject: [concurrency-interest] JCJP Memoizer pattern
In-Reply-To: <DE10B00CCE0DC54883734F3060AC9ED44D60FC19FA@AUSP01VMBX06.collaborationhost.net>
References: <DE10B00CCE0DC54883734F3060AC9ED44D60FC19FA@AUSP01VMBX06.collaborationhost.net>
Message-ID: <j2s63b4e4051003300753k265565e2zc40e52ae6e2ef43@mail.gmail.com>

MapMaker.makeComputingMap in Google Collections might also be appropriate
here.

--tim

On Tue, Mar 30, 2010 at 7:45 AM, Bryan Thompson <bryan at systap.com> wrote:

> Hello,
>
> We've been using the "Memoizer" pattern from JCIP and run into a problem
> where an interrupt of the thread actually running the Computable is
> essentially propagated to all tasks awaiting the same Computable.  This was
> easy enough to fix by adding a flag indicating whether the thread awaiting
> the Future was the thread which actually ran the task.  If so, then we
> propagate the interrupt.  Otherwise we remove the FutureTask from the cache
> and retry, essentially discarding the interrupt for other callers.
>
> Bryan
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100330/37b8f7c4/attachment.html>

From sanne.grinovero at gmail.com  Tue Mar 30 18:17:30 2010
From: sanne.grinovero at gmail.com (Sanne Grinovero)
Date: Wed, 31 Mar 2010 00:17:30 +0200
Subject: [concurrency-interest] Use of j.u.c. constructs in open source
	projects
In-Reply-To: <87E7DD0C-F2C6-488F-BA8A-F9F64C441B04@walend.net>
References: <mailman.1.1266512400.17513.concurrency-interest@cs.oswego.edu> 
	<87E7DD0C-F2C6-488F-BA8A-F9F64C441B04@walend.net>
Message-ID: <50e5f6251003301517w6b0a3e13h2f0794a12a832f90@mail.gmail.com>

Hello,
sorry for the late answer, I have a good example:

www.infinispan.org

It's definitely open source and does contain a very high density of
j.u.c. usage.

Regards,
Sanne

2010/2/20 David Walend <david at walend.net>:
>> From: kedar mhaswade <kedar.mhaswade at gmail.com>
>>
>> Someone asked me if I knew open source projects where j.u.c. constructs
>> are
>> used heavily.
>> Her intent was to check out (study thoroughly) how these constructs are
>> put
>> to (good) use.
>>
>> Does anyone on the list have any recommendation for such a project (open
>> source)?
>>
>
> SomnifugiJMS makes heavy use of BlockingQueues, a few Locks and Conditions,
> and this diabolical use of AtomicMarkableReferences that Tim Peierls
> suggested -- it does JMS message selectors without a database. I'm not sure
> I'd call it "good," but the code has been kicked around for about ten years.
> New bug reports have gotten pretty rare.
>
> https://somnifugijms.dev.java.net/
>
> Hope that helps,
>
> Dave
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

