From christianessl at googlemail.com  Sun May  6 17:58:23 2012
From: christianessl at googlemail.com (Christian Essl)
Date: Sun, 6 May 2012 23:58:23 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
Message-ID: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>

Sorry if this is a stupid question regarding fork-join pools, but I am not
sure wheter the "lightweigth future" idea would also work async http calls.
(And please also excuse my bad english)

Currently I use the ning asnyc-http-client (
https://github.com/sonatype/async-http-client) in an event-driven callback
style to do nonblocking http-calls from a servlet.

However the callback style gets a bit complicated when the program-logic
gets complex so I wonder wheter I could use ForkJoinTask to transfer the
callback style to non-thread-blocking futures.

The idea is to initialize the nonblocking HttpCall in ForkJoinTaks.exec()
and when the callback receives the http-response it calls the
ForkJoinTaks.complete() method.

Maybe someone can take a look at the following ForkJoinTask which wraps an
HttpCall and say wheter it is a reasonable use of ForkJoinPool.

import com.ning.http.client.AsyncHttpClient;
import com.ning.http.client.AsyncCompletionHandler;
import com.ning.http.client.Response;

//The forkjoin task which wraps an async-http-call
class HttpTask extends ForkJoinTask<Response> {

private Response result;
private AsyncHttpClient.BoundRequestBuilder httpRequestBuilder;
 public HttpTask(AsyncHttpClient.BoundRequestBuilder builder) {
//the httpRequestBuilder is setup up by the caller (setting the url etc)
        //and used by HttpTask to execute the http request
        this.httpRequestBuilder = builder;
}
 @Override
protected boolean exec() {
try {
//this is non blocking event-style http call
httpRequestBuilder.execute(new AsyncCompletionHandler<Response>() {

@Override
public Response onCompleted(Response resp) throws Exception {
//when the response is received complete the ForkJoinTask
HttpTask.this.complete(resp);
return resp;
}
 @Override
public void onThrowable(Throwable t) {
//wehn exception complete Exceptionally the ForkJoinTask
HttpTask.this.completeExceptionally(t);
}
 });
} catch (IOException e) {
throw new RuntimeException(e);
}
return false;
}

@Override
public Response getRawResult() {
return result;
}

@Override
protected void setRawResult(Response arg0) {
result = arg0;
}
}

I than use the HttpTask in Servelt like that:

public class FooServlet extends javax.servlet.http.HttpServlet {

private ForkJoinPool forJoinPool = new ForkJoinPool();
private AsyncHttpClient httpClient = new AsyncHttpClient();
@Override
protected void doGet(final HttpServletRequest req, final
HttpServletResponse resp)
throws ServletException, IOException {
final AsyncContext asyncCtxt = req.getAsyncContext();
RecursiveAction action = new RecursiveAction() {
 @Override
protected void compute() {
//do the http request
HttpTask t = new HttpTask(httpClient.prepareGet("http//url.to.service/"));
    Response res = t.invoke();
 }
};
}
}

My assumption here is that when the HttpTask is invoked that the
ForkJoinPool does not block the thread until the Response is received but
rather takes another RecursiveAtion to process another request until the
httpresponse arrives.

My question is wheter my assumptions are right and wheter this is a
reasonable use of ForkJoinPool.

Thanks for any responses.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120506/06945e13/attachment.html>

From viktor.klang at gmail.com  Mon May  7 07:55:06 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 7 May 2012 13:55:06 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
Message-ID: <CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>

Another prime usecase for composable futures:

//Warning pseudocode, not compiled

import akka.dispatch.{ Promise, Future }
def bridge(httpRequestBuilder: AsyncHttpClient.BoundRequestBuilder):
Future[Response] = {
  val p = Promise[Response]()
  httpRequestBuilder.execute(new AsyncCompletionHandler[Response] {
override def onCompleted(resp: Response): Response = p success resp
override def onThrowable(t: Throwable): Unit = p failure t
  })
  p.future
}

in servlet...

bridge(yourRequestBuilder) map asyncCtx.write foreach { _ => asyncCtx.close
}

Cheers,
?

On Sun, May 6, 2012 at 11:58 PM, Christian Essl <
christianessl at googlemail.com> wrote:

> Sorry if this is a stupid question regarding fork-join pools, but I am not
> sure wheter the "lightweigth future" idea would also work async http calls.
> (And please also excuse my bad english)
>
> Currently I use the ning asnyc-http-client (
> https://github.com/sonatype/async-http-client) in an event-driven
> callback style to do nonblocking http-calls from a servlet.
>
> However the callback style gets a bit complicated when the program-logic
> gets complex so I wonder wheter I could use ForkJoinTask to transfer the
> callback style to non-thread-blocking futures.
>
> The idea is to initialize the nonblocking HttpCall in ForkJoinTaks.exec()
> and when the callback receives the http-response it calls the
> ForkJoinTaks.complete() method.
>
> Maybe someone can take a look at the following ForkJoinTask which wraps an
> HttpCall and say wheter it is a reasonable use of ForkJoinPool.
>
> import com.ning.http.client.AsyncHttpClient;
> import com.ning.http.client.AsyncCompletionHandler;
> import com.ning.http.client.Response;
>
> //The forkjoin task which wraps an async-http-call
> class HttpTask extends ForkJoinTask<Response> {
>
> private Response result;
> private AsyncHttpClient.BoundRequestBuilder httpRequestBuilder;
>  public HttpTask(AsyncHttpClient.BoundRequestBuilder builder) {
> //the httpRequestBuilder is setup up by the caller (setting the url etc)
>         //and used by HttpTask to execute the http request
>         this.httpRequestBuilder = builder;
> }
>  @Override
> protected boolean exec() {
> try {
>  //this is non blocking event-style http call
> httpRequestBuilder.execute(new AsyncCompletionHandler<Response>() {
>
> @Override
> public Response onCompleted(Response resp) throws Exception {
>  //when the response is received complete the ForkJoinTask
> HttpTask.this.complete(resp);
>  return resp;
> }
>  @Override
> public void onThrowable(Throwable t) {
> //wehn exception complete Exceptionally the ForkJoinTask
>  HttpTask.this.completeExceptionally(t);
> }
>  });
> } catch (IOException e) {
> throw new RuntimeException(e);
>  }
> return false;
> }
>
> @Override
> public Response getRawResult() {
> return result;
>  }
>
> @Override
> protected void setRawResult(Response arg0) {
>  result = arg0;
> }
>  }
>
> I than use the HttpTask in Servelt like that:
>
> public class FooServlet extends javax.servlet.http.HttpServlet {
>
> private ForkJoinPool forJoinPool = new ForkJoinPool();
>  private AsyncHttpClient httpClient = new AsyncHttpClient();
> @Override
> protected void doGet(final HttpServletRequest req, final
> HttpServletResponse resp)
>  throws ServletException, IOException {
> final AsyncContext asyncCtxt = req.getAsyncContext();
>  RecursiveAction action = new RecursiveAction() {
>  @Override
>  protected void compute() {
> //do the http request
> HttpTask t = new HttpTask(httpClient.prepareGet("http//url.to.service/"));
>     Response res = t.invoke();
>  }
>  };
> }
> }
>
> My assumption here is that when the HttpTask is invoked that the
> ForkJoinPool does not block the thread until the Response is received but
> rather takes another RecursiveAtion to process another request until the
> httpresponse arrives.
>
> My question is wheter my assumptions are right and wheter this is a
> reasonable use of ForkJoinPool.
>
> Thanks for any responses.
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120507/7866c205/attachment-0001.html>

From christianessl at googlemail.com  Thu May 10 08:12:05 2012
From: christianessl at googlemail.com (Christian Essl)
Date: Thu, 10 May 2012 14:12:05 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
Message-ID: <CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>

Hi Viktor,

Thanks for your answer, and thanks for your patient discussion outside
of the mailing-list.

As said I like the akka-framework, still it would be very nice if
anybody could answer my original question whether ForkJoinTasks can
give a sort of non-blocking future also suitable for async IO, because
I am stil not sure.

Thanks,
Christian

On Mon, May 7, 2012 at 1:55 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> Another prime usecase for composable futures:
>
> //Warning pseudocode, not compiled
>
> import akka.dispatch.{ Promise, Future }
> def bridge(httpRequestBuilder:?AsyncHttpClient.BoundRequestBuilder):
> Future[Response] = {
> ? val p = Promise[Response]()
> ? httpRequestBuilder.execute(new AsyncCompletionHandler[Response] {
> override def?onCompleted(resp: Response):?Response = p success resp
> override def onThrowable(t: Throwable): Unit = p failure t
> ? })
> ? p.future
> }
>
> in servlet...
>
> bridge(yourRequestBuilder) map asyncCtx.write foreach { _ => asyncCtx.close
> }
>
> Cheers,
> ?
>
> On Sun, May 6, 2012 at 11:58 PM, Christian Essl
> <christianessl at googlemail.com> wrote:
>>
>> Sorry if this is a stupid question regarding fork-join pools, but I am not
>> sure wheter the "lightweigth future" idea would also work async http calls.
>> (And please also excuse my bad english)
>>
>> Currently I use the ning asnyc-http-client
>> (https://github.com/sonatype/async-http-client) in an event-driven callback
>> style to do nonblocking http-calls from a servlet.
>>
>> However the callback style gets a bit complicated when the program-logic
>> gets complex so I wonder wheter I could use ForkJoinTask to transfer the
>> callback style to non-thread-blocking futures.
>>
>> The idea is to initialize the nonblocking HttpCall in ForkJoinTaks.exec()
>> and when the callback receives the http-response it calls the
>> ForkJoinTaks.complete() method.
>>
>> Maybe someone can take a look at the following ForkJoinTask which wraps an
>> HttpCall and say wheter it is a reasonable use of ForkJoinPool.
>>
>> import com.ning.http.client.AsyncHttpClient;
>> import com.ning.http.client.AsyncCompletionHandler;
>> import com.ning.http.client.Response;
>>
>> //The forkjoin task which wraps an async-http-call
>> class HttpTask extends ForkJoinTask<Response> {
>>
>> private Response result;
>> private AsyncHttpClient.BoundRequestBuilder httpRequestBuilder;
>> public HttpTask(AsyncHttpClient.BoundRequestBuilder builder) {
>> //the httpRequestBuilder is setup up by the caller (setting the url etc)
>> ? ? ? ? //and used by HttpTask to execute the http request
>> ? ? ? ? this.httpRequestBuilder = builder;
>> }
>> @Override
>> protected boolean exec() {
>> try {
>> //this is non blocking event-style http call
>> httpRequestBuilder.execute(new AsyncCompletionHandler<Response>() {
>>
>> @Override
>> public Response onCompleted(Response resp) throws Exception {
>> //when the response is received complete the ForkJoinTask
>> HttpTask.this.complete(resp);
>> return resp;
>> }
>> @Override
>> public void onThrowable(Throwable t) {
>> //wehn exception complete Exceptionally the ForkJoinTask
>> HttpTask.this.completeExceptionally(t);
>> }
>> });
>> } catch (IOException e) {
>> throw new RuntimeException(e);
>> }
>> return false;
>> }
>>
>> @Override
>> public Response getRawResult() {
>> return result;
>> }
>>
>> @Override
>> protected void setRawResult(Response arg0) {
>> result = arg0;
>> }
>> }
>>
>> I than use the HttpTask in Servelt like that:
>>
>> public class FooServlet extends javax.servlet.http.HttpServlet {
>>
>> private ForkJoinPool forJoinPool = new ForkJoinPool();
>> private AsyncHttpClient httpClient = new AsyncHttpClient();
>> @Override
>> protected void doGet(final HttpServletRequest req, final
>> HttpServletResponse resp)
>> throws ServletException, IOException {
>> final AsyncContext asyncCtxt = req.getAsyncContext();
>> RecursiveAction action = new RecursiveAction() {
>> @Override
>> protected void compute() {
>> //do the http request
>> HttpTask t = new HttpTask(httpClient.prepareGet("http//url.to.service/"));
>> ? ?Response res = t.invoke();
>> }
>> };
>> }
>> }
>>
>> My assumption here is that when the HttpTask is invoked that the
>> ForkJoinPool does not block the thread until the Response is received but
>> rather takes another RecursiveAtion to process another request until the
>> httpresponse arrives.
>>
>> My question is wheter my assumptions are right and wheter this is a
>> reasonable use of ForkJoinPool.
>>
>> Thanks for any responses.
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe?- The software stack for applications that scale
>
> Twitter: @viktorklang
>


From gregg at cytetech.com  Thu May 10 08:31:52 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 10 May 2012 07:31:52 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
Message-ID: <4FABB538.6020005@cytetech.com>

On 5/10/2012 7:12 AM, Christian Essl wrote:
> Hi Viktor,
>
> Thanks for your answer, and thanks for your patient discussion outside
> of the mailing-list.
>
> As said I like the akka-framework, still it would be very nice if
> anybody could answer my original question whether ForkJoinTasks can
> give a sort of non-blocking future also suitable for async IO, because
> I am stil not sure.

I believe that ForkJoin was designed specifically for managing non-blocking, 
compute bound tasks.  Primarily, this issue of "partial failure" in the form of 
I/O failures really complicates things.  Practically, you'd like for your I/O to 
be linearly consistent, so a ForkJoin task, would need to do all the I/O for a 
particular "operation" itself.

Inside of a Servlet container, you really shouldn't be mucking about with 
threading, related to the request completion.  If you have other services to 
interact with, they should be done within a linear progression of code inside of 
the doGet, doPut, doPost etc methods.

The thread which calls doGet/doPost is, already, from a pool which the container 
is managing in some way.  Adding another thread to the mix, to perform some 
work, would require the calling thread to block and wait for it to complete 
anyway, so why not just have the calling thread do that work?

If you do have some compute bound work to do, in some cases, where the 
container, is otherwise idle, or small (not tomcat/glassfish), you might find 
some benefit in using fork/join to do the compute work.  But, again, based on 
the servlet programming model, the doGet/doPost thread, must block, and wait for 
the results, and then write back the response.

Gregg Wonderly

> Thanks,
> Christian
>
> On Mon, May 7, 2012 at 1:55 PM, ?iktor ?lang<viktor.klang at gmail.com>  wrote:
>> Another prime usecase for composable futures:
>>
>> //Warning pseudocode, not compiled
>>
>> import akka.dispatch.{ Promise, Future }
>> def bridge(httpRequestBuilder: AsyncHttpClient.BoundRequestBuilder):
>> Future[Response] = {
>>    val p = Promise[Response]()
>>    httpRequestBuilder.execute(new AsyncCompletionHandler[Response] {
>> override def onCompleted(resp: Response): Response = p success resp
>> override def onThrowable(t: Throwable): Unit = p failure t
>>    })
>>    p.future
>> }
>>
>> in servlet...
>>
>> bridge(yourRequestBuilder) map asyncCtx.write foreach { _ =>  asyncCtx.close
>> }
>>
>> Cheers,
>> ?
>>
>> On Sun, May 6, 2012 at 11:58 PM, Christian Essl
>> <christianessl at googlemail.com>  wrote:
>>>
>>> Sorry if this is a stupid question regarding fork-join pools, but I am not
>>> sure wheter the "lightweigth future" idea would also work async http calls.
>>> (And please also excuse my bad english)
>>>
>>> Currently I use the ning asnyc-http-client
>>> (https://github.com/sonatype/async-http-client) in an event-driven callback
>>> style to do nonblocking http-calls from a servlet.
>>>
>>> However the callback style gets a bit complicated when the program-logic
>>> gets complex so I wonder wheter I could use ForkJoinTask to transfer the
>>> callback style to non-thread-blocking futures.
>>>
>>> The idea is to initialize the nonblocking HttpCall in ForkJoinTaks.exec()
>>> and when the callback receives the http-response it calls the
>>> ForkJoinTaks.complete() method.
>>>
>>> Maybe someone can take a look at the following ForkJoinTask which wraps an
>>> HttpCall and say wheter it is a reasonable use of ForkJoinPool.
>>>
>>> import com.ning.http.client.AsyncHttpClient;
>>> import com.ning.http.client.AsyncCompletionHandler;
>>> import com.ning.http.client.Response;
>>>
>>> //The forkjoin task which wraps an async-http-call
>>> class HttpTask extends ForkJoinTask<Response>  {
>>>
>>> private Response result;
>>> private AsyncHttpClient.BoundRequestBuilder httpRequestBuilder;
>>> public HttpTask(AsyncHttpClient.BoundRequestBuilder builder) {
>>> //the httpRequestBuilder is setup up by the caller (setting the url etc)
>>>          //and used by HttpTask to execute the http request
>>>          this.httpRequestBuilder = builder;
>>> }
>>> @Override
>>> protected boolean exec() {
>>> try {
>>> //this is non blocking event-style http call
>>> httpRequestBuilder.execute(new AsyncCompletionHandler<Response>() {
>>>
>>> @Override
>>> public Response onCompleted(Response resp) throws Exception {
>>> //when the response is received complete the ForkJoinTask
>>> HttpTask.this.complete(resp);
>>> return resp;
>>> }
>>> @Override
>>> public void onThrowable(Throwable t) {
>>> //wehn exception complete Exceptionally the ForkJoinTask
>>> HttpTask.this.completeExceptionally(t);
>>> }
>>> });
>>> } catch (IOException e) {
>>> throw new RuntimeException(e);
>>> }
>>> return false;
>>> }
>>>
>>> @Override
>>> public Response getRawResult() {
>>> return result;
>>> }
>>>
>>> @Override
>>> protected void setRawResult(Response arg0) {
>>> result = arg0;
>>> }
>>> }
>>>
>>> I than use the HttpTask in Servelt like that:
>>>
>>> public class FooServlet extends javax.servlet.http.HttpServlet {
>>>
>>> private ForkJoinPool forJoinPool = new ForkJoinPool();
>>> private AsyncHttpClient httpClient = new AsyncHttpClient();
>>> @Override
>>> protected void doGet(final HttpServletRequest req, final
>>> HttpServletResponse resp)
>>> throws ServletException, IOException {
>>> final AsyncContext asyncCtxt = req.getAsyncContext();
>>> RecursiveAction action = new RecursiveAction() {
>>> @Override
>>> protected void compute() {
>>> //do the http request
>>> HttpTask t = new HttpTask(httpClient.prepareGet("http//url.to.service/"));
>>>     Response res = t.invoke();
>>> }
>>> };
>>> }
>>> }
>>>
>>> My assumption here is that when the HttpTask is invoked that the
>>> ForkJoinPool does not block the thread until the Response is received but
>>> rather takes another RecursiveAtion to process another request until the
>>> httpresponse arrives.
>>>
>>> My question is wheter my assumptions are right and wheter this is a
>>> reasonable use of ForkJoinPool.
>>>
>>> Thanks for any responses.
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>> Viktor Klang
>>
>> Akka Tech Lead
>> Typesafe - The software stack for applications that scale
>>
>> Twitter: @viktorklang
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From mthornton at optrak.com  Thu May 10 08:48:22 2012
From: mthornton at optrak.com (Mark Thornton)
Date: Thu, 10 May 2012 13:48:22 +0100
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FABB538.6020005@cytetech.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<4FABB538.6020005@cytetech.com>
Message-ID: <4FABB916.9010008@optrak.com>

On 10/05/12 13:31, Gregg Wonderly wrote:
> On 5/10/2012 7:12 AM, Christian Essl wrote:
>> Hi Viktor,
>>
>> Thanks for your answer, and thanks for your patient discussion outside
>> of the mailing-list.
>>
>> As said I like the akka-framework, still it would be very nice if
>> anybody could answer my original question whether ForkJoinTasks can
>> give a sort of non-blocking future also suitable for async IO, because
>> I am stil not sure.
>
> I believe that ForkJoin was designed specifically for managing 
> non-blocking, compute bound tasks.  Primarily, this issue of "partial 
> failure" in the form of I/O failures really complicates things.  
> Practically, you'd like for your I/O to be linearly consistent, so a 
> ForkJoin task, would need to do all the I/O for a particular 
> "operation" itself.
>
> Inside of a Servlet container, you really shouldn't be mucking about 
> with threading, related to the request completion.  If you have other 
> services to interact with, they should be done within a linear 
> progression of code inside of the doGet, doPut, doPost etc methods.
>
> The thread which calls doGet/doPost is, already, from a pool which the 
> container is managing in some way.  Adding another thread to the mix, 
> to perform some work, would require the calling thread to block and 
> wait for it to complete anyway, so why not just have the calling 
> thread do that work?

Not if you use the async support in the latest Servlet specification.

Mark Thornton


From dl at cs.oswego.edu  Thu May 10 08:57:50 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 10 May 2012 08:57:50 -0400
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
Message-ID: <4FABBB4E.1050707@cs.oswego.edu>

On 05/10/12 08:12, Christian Essl wrote:
> As said I like the akka-framework, still it would be very nice if
> anybody could answer my original question whether ForkJoinTasks can
> give a sort of non-blocking future also suitable for async IO, because
> I am stil not sure.

The jsr166y/jdk8 CountedCompleter and related updates are specifically
aimed to better support IO-bound and other non-computationally-bound
tasks. The javadocs and examples probably don't yet do a good enough
job in showing how. (Partly because IO examples are always too bulky
to make for simple understandable examples; suggestions would be welcome.)

The syntax and constructions for using them are not as nice as in akka/Scala.
On the other hand the ability to effectively AND completion triggers
via counts (not found yet in Scala versions) is handy.

-Doug


From gregg at cytetech.com  Thu May 10 09:08:40 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 10 May 2012 08:08:40 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FABB916.9010008@optrak.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<4FABB538.6020005@cytetech.com> <4FABB916.9010008@optrak.com>
Message-ID: <4FABBDD8.8060106@cytetech.com>

On 5/10/2012 7:48 AM, Mark Thornton wrote:
> On 10/05/12 13:31, Gregg Wonderly wrote:
>> On 5/10/2012 7:12 AM, Christian Essl wrote:
>>> Hi Viktor,
>>>
>>> Thanks for your answer, and thanks for your patient discussion outside
>>> of the mailing-list.
>>>
>>> As said I like the akka-framework, still it would be very nice if
>>> anybody could answer my original question whether ForkJoinTasks can
>>> give a sort of non-blocking future also suitable for async IO, because
>>> I am stil not sure.
>>
>> I believe that ForkJoin was designed specifically for managing non-blocking,
>> compute bound tasks. Primarily, this issue of "partial failure" in the form of
>> I/O failures really complicates things. Practically, you'd like for your I/O
>> to be linearly consistent, so a ForkJoin task, would need to do all the I/O
>> for a particular "operation" itself.
>>
>> Inside of a Servlet container, you really shouldn't be mucking about with
>> threading, related to the request completion. If you have other services to
>> interact with, they should be done within a linear progression of code inside
>> of the doGet, doPut, doPost etc methods.
>>
>> The thread which calls doGet/doPost is, already, from a pool which the
>> container is managing in some way. Adding another thread to the mix, to
>> perform some work, would require the calling thread to block and wait for it
>> to complete anyway, so why not just have the calling thread do that work?
>
> Not if you use the async support in the latest Servlet specification.

In his example code, I see the use of just doGet().  I have not used the 
async-http support from JSR-315, but I thought that doGet() was not the path for 
using that.  If he's really using the async support from the servlet container, 
then he still, does have the issue with the server thread pooling, and 
synchronization with that call/report structure, but could inject a ForkJoin 
pool I suppose, but might find limited "returns" on that depending on how the 
CPU cores area already loaded from the servlet handling inbound requests.

 From a general perspective, I expect the use of the Fork/Join pool to load the 
CPUs and create quite a bit of latency issues for non-compute requests on a 
loaded server.

Gregg Wonderly


From gregg at cytetech.com  Thu May 10 09:16:43 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 10 May 2012 08:16:43 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FABBDD8.8060106@cytetech.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<4FABB538.6020005@cytetech.com> <4FABB916.9010008@optrak.com>
	<4FABBDD8.8060106@cytetech.com>
Message-ID: <4FABBFBB.1050001@cytetech.com>

On 5/10/2012 8:08 AM, Gregg Wonderly wrote:
> On 5/10/2012 7:48 AM, Mark Thornton wrote:
>> On 10/05/12 13:31, Gregg Wonderly wrote:
>>> On 5/10/2012 7:12 AM, Christian Essl wrote:
>>>> Hi Viktor,
>>>>
>>>> Thanks for your answer, and thanks for your patient discussion outside
>>>> of the mailing-list.
>>>>
>>>> As said I like the akka-framework, still it would be very nice if
>>>> anybody could answer my original question whether ForkJoinTasks can
>>>> give a sort of non-blocking future also suitable for async IO, because
>>>> I am stil not sure.
>>>
>>> I believe that ForkJoin was designed specifically for managing non-blocking,
>>> compute bound tasks. Primarily, this issue of "partial failure" in the form of
>>> I/O failures really complicates things. Practically, you'd like for your I/O
>>> to be linearly consistent, so a ForkJoin task, would need to do all the I/O
>>> for a particular "operation" itself.
>>>
>>> Inside of a Servlet container, you really shouldn't be mucking about with
>>> threading, related to the request completion. If you have other services to
>>> interact with, they should be done within a linear progression of code inside
>>> of the doGet, doPut, doPost etc methods.
>>>
>>> The thread which calls doGet/doPost is, already, from a pool which the
>>> container is managing in some way. Adding another thread to the mix, to
>>> perform some work, would require the calling thread to block and wait for it
>>> to complete anyway, so why not just have the calling thread do that work?
>>
>> Not if you use the async support in the latest Servlet specification.
>
> In his example code, I see the use of just doGet(). I have not used the
> async-http support from JSR-315, but I thought that doGet() was not the path for
> using that. If he's really using the async support from the servlet container,
> then he still, does have the issue with the server thread pooling, and
> synchronization with that call/report structure, but could inject a ForkJoin
> pool I suppose, but might find limited "returns" on that depending on how the
> CPU cores area already loaded from the servlet handling inbound requests.
>
>  From a general perspective, I expect the use of the Fork/Join pool to load the
> CPUs and create quite a bit of latency issues for non-compute requests on a
> loaded server.

Looking over some of the spec and examples, I can see that doGet() is the path, 
if you tell the context/container that you do want to be async.  Sorry for the 
confusion for misspeaking out of ignorance here.  Thanks for the followup Mark 
to point me at actually reading the details.

Gregg

From zhong.j.yu at gmail.com  Thu May 10 10:43:26 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 10 May 2012 09:43:26 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
Message-ID: <CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>

My understanding of your question:

ForkJoinTask.invoke() appears to be a blocking action and may suspend
the current thread (by something like Object.wait()) if its exec()
returns false.

But if it is called on a fork join thread, could the system be smart
enough to execute other tasks on the same thread until the origin task
completes?

That seems to be the case. However, in your example, it may create a
very deep call stack:
...compute()...invoke()...compute()...invoke()...

Your use of blocking invoke() is quite odd in an async program; I
guess your reason is code simplicity. It's not a pleasant task to
rewrite a single threaded blocking code into delicately linked async
callbacks, when states and flows get complicated.

P.S. servlet output stream is blocking anyway, you need a dedicated
thread for every client when writing responses. My experience is that
majority of threads in a servlet app are blocked on writing
responses(big) to clients(slow). If you are really serious about async
IO, servlet programming model doesn't fit. You need a real async Java
web framework; to my knowledge today there is only Play! 2.0. (Or
netty etc. if you don't need a web framework).

Zhong Yu

On Thu, May 10, 2012 at 7:12 AM, Christian Essl
<christianessl at googlemail.com> wrote:
> Hi Viktor,
>
> Thanks for your answer, and thanks for your patient discussion outside
> of the mailing-list.
>
> As said I like the akka-framework, still it would be very nice if
> anybody could answer my original question whether ForkJoinTasks can
> give a sort of non-blocking future also suitable for async IO, because
> I am stil not sure.
>
> Thanks,
> Christian

From viktor.klang at gmail.com  Thu May 10 11:04:52 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 10 May 2012 17:04:52 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
Message-ID: <CANPzfU_sfXs9mGv2550UJ2rQHwZfgKniUEHUZ0tNmuncXUYefg@mail.gmail.com>

On Thu, May 10, 2012 at 4:43 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> My understanding of your question:
>
> ForkJoinTask.invoke() appears to be a blocking action and may suspend
> the current thread (by something like Object.wait()) if its exec()
> returns false.
>
> But if it is called on a fork join thread, could the system be smart
> enough to execute other tasks on the same thread until the origin task
> completes?
>
> That seems to be the case. However, in your example, it may create a
> very deep call stack:
> ...compute()...invoke()...compute()...invoke()...
>
> Your use of blocking invoke() is quite odd in an async program; I
> guess your reason is code simplicity. It's not a pleasant task to
> rewrite a single threaded blocking code into delicately linked async
> callbacks, when states and flows get complicated.
>
> P.S. servlet output stream is blocking anyway, you need a dedicated
> thread for every client when writing responses. My experience is that
> majority of threads in a servlet app are blocked on writing
> responses(big) to clients(slow). If you are really serious about async
> IO, servlet programming model doesn't fit. You need a real async Java
> web framework; to my knowledge today there is only Play! 2.0. (Or
> netty etc. if you don't need a web framework).
>

Also worth noting is that Play 2 uses Akka, so you have access to Akka's
non-blocking Futures.

Cheers,
?


>
> Zhong Yu
>
> On Thu, May 10, 2012 at 7:12 AM, Christian Essl
> <christianessl at googlemail.com> wrote:
> > Hi Viktor,
> >
> > Thanks for your answer, and thanks for your patient discussion outside
> > of the mailing-list.
> >
> > As said I like the akka-framework, still it would be very nice if
> > anybody could answer my original question whether ForkJoinTasks can
> > give a sort of non-blocking future also suitable for async IO, because
> > I am stil not sure.
> >
> > Thanks,
> > Christian
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/4a476557/attachment.html>

From christianessl at googlemail.com  Thu May 10 11:25:43 2012
From: christianessl at googlemail.com (Christian Essl)
Date: Thu, 10 May 2012 17:25:43 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FABBB4E.1050707@cs.oswego.edu>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<4FABBB4E.1050707@cs.oswego.edu>
Message-ID: <CADoyxFxeNxYfLrYpMMVEH1q7=euK_d4rhyfziDt=EB-Zy_tc2w@mail.gmail.com>

First thanks for this great work and its really an honor to me that
such great coders like you answer my questions.

The main reason I asked the original question is not that much about
raw performance but more about code-simplicity in the sense to code
like in a traditional blocking style but still have better performance
and less blocking (not necessarily none).

So I hoped to get a somehow sulution with my original attempt.

Regarding CountedCompleter an example usage for IO would certainly
help me, because I don't know where I should plugin the
completion-callback for async-IO or alternatively do the blocking IO.


Thanks
Christian

On Thu, May 10, 2012 at 2:57 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> On 05/10/12 08:12, Christian Essl wrote:
>>
>> As said I like the akka-framework, still it would be very nice if
>> anybody could answer my original question whether ForkJoinTasks can
>> give a sort of non-blocking future also suitable for async IO, because
>> I am stil not sure.
>
>
> The jsr166y/jdk8 CountedCompleter and related updates are specifically
> aimed to better support IO-bound and other non-computationally-bound
> tasks. The javadocs and examples probably don't yet do a good enough
> job in showing how. (Partly because IO examples are always too bulky
> to make for simple understandable examples; suggestions would be welcome.)
>
> The syntax and constructions for using them are not as nice as in
> akka/Scala.
> On the other hand the ability to effectively AND completion triggers
> via counts (not found yet in Scala versions) is handy.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From christianessl at googlemail.com  Thu May 10 11:26:32 2012
From: christianessl at googlemail.com (Christian Essl)
Date: Thu, 10 May 2012 17:26:32 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
Message-ID: <CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>

Your are right my primary concern is code-simplicity not pure
performance, basicly writing in a traditional imperative blocking
style but still having IO with (mostly) non-blocking threads (and no
callbacks, no monadic futures).

My main question therefore is as you stated:

> But if it is called on a fork join thread, could the system be smart
> enough to execute other tasks on the same thread until the origin task
> completes?

And I don't know.

Also thanks for the other hints regarding servlets

On Thu, May 10, 2012 at 4:43 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> My understanding of your question:
>
> ForkJoinTask.invoke() appears to be a blocking action and may suspend
> the current thread (by something like Object.wait()) if its exec()
> returns false.
>
> But if it is called on a fork join thread, could the system be smart
> enough to execute other tasks on the same thread until the origin task
> completes?
>
> That seems to be the case. However, in your example, it may create a
> very deep call stack:
> ...compute()...invoke()...compute()...invoke()...
>
> Your use of blocking invoke() is quite odd in an async program; I
> guess your reason is code simplicity. It's not a pleasant task to
> rewrite a single threaded blocking code into delicately linked async
> callbacks, when states and flows get complicated.
>
> P.S. servlet output stream is blocking anyway, you need a dedicated
> thread for every client when writing responses. My experience is that
> majority of threads in a servlet app are blocked on writing
> responses(big) to clients(slow). If you are really serious about async
> IO, servlet programming model doesn't fit. You need a real async Java
> web framework; to my knowledge today there is only Play! 2.0. (Or
> netty etc. if you don't need a web framework).
>
> Zhong Yu
>
> On Thu, May 10, 2012 at 7:12 AM, Christian Essl
> <christianessl at googlemail.com> wrote:
>> Hi Viktor,
>>
>> Thanks for your answer, and thanks for your patient discussion outside
>> of the mailing-list.
>>
>> As said I like the akka-framework, still it would be very nice if
>> anybody could answer my original question whether ForkJoinTasks can
>> give a sort of non-blocking future also suitable for async IO, because
>> I am stil not sure.
>>
>> Thanks,
>> Christian

From dahankzter at gmail.com  Thu May 10 11:42:32 2012
From: dahankzter at gmail.com (Henrik Johansson)
Date: Thu, 10 May 2012 17:42:32 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CADoyxFxeNxYfLrYpMMVEH1q7=euK_d4rhyfziDt=EB-Zy_tc2w@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<4FABBB4E.1050707@cs.oswego.edu>
	<CADoyxFxeNxYfLrYpMMVEH1q7=euK_d4rhyfziDt=EB-Zy_tc2w@mail.gmail.com>
Message-ID: <CAKOF694LuaJd+jPtWNfaZrF4hsZe4ooVTAyk9eOkTZFhJUoawA@mail.gmail.com>

Correct me if I am wrong here but asynchronous IO does not perform better
than it's synchrous counterpart. In order to get a performance increase you
have to think about performance in terms of throughput and scalability. If
that's the case then asynchronous IO and Play2 is the way to go. Play2 has
lots of other goodies too though...

The experts present in this mailing list can probably tell me otherwise if
I am wrong ;-)

/ Henrik
On May 10, 2012 5:31 PM, "Christian Essl" <christianessl at googlemail.com>
wrote:

> First thanks for this great work and its really an honor to me that
> such great coders like you answer my questions.
>
> The main reason I asked the original question is not that much about
> raw performance but more about code-simplicity in the sense to code
> like in a traditional blocking style but still have better performance
> and less blocking (not necessarily none).
>
> So I hoped to get a somehow sulution with my original attempt.
>
> Regarding CountedCompleter an example usage for IO would certainly
> help me, because I don't know where I should plugin the
> completion-callback for async-IO or alternatively do the blocking IO.
>
>
> Thanks
> Christian
>
> On Thu, May 10, 2012 at 2:57 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> > On 05/10/12 08:12, Christian Essl wrote:
> >>
> >> As said I like the akka-framework, still it would be very nice if
> >> anybody could answer my original question whether ForkJoinTasks can
> >> give a sort of non-blocking future also suitable for async IO, because
> >> I am stil not sure.
> >
> >
> > The jsr166y/jdk8 CountedCompleter and related updates are specifically
> > aimed to better support IO-bound and other non-computationally-bound
> > tasks. The javadocs and examples probably don't yet do a good enough
> > job in showing how. (Partly because IO examples are always too bulky
> > to make for simple understandable examples; suggestions would be
> welcome.)
> >
> > The syntax and constructions for using them are not as nice as in
> > akka/Scala.
> > On the other hand the ability to effectively AND completion triggers
> > via counts (not found yet in Scala versions) is handy.
> >
> > -Doug
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/a0e9ebd0/attachment-0001.html>

From zhong.j.yu at gmail.com  Thu May 10 13:07:53 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 10 May 2012 12:07:53 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
Message-ID: <CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>

On Thu, May 10, 2012 at 10:26 AM, Christian Essl
<christianessl at googlemail.com> wrote:
> Your are right my primary concern is code-simplicity not pure
> performance, basicly writing in a traditional imperative blocking
> style but still having IO with (mostly) non-blocking threads (and no
> callbacks, no monadic futures).

Thread is such a nice programming abstraction, it's a shame that we
are so concerned of its overhead nowadays. Replacing simple threads
with complex tasks seems to be retrogressing - aren't programming
supposed to become easier?

What are the fundamental reasons that Java Threads are expensive?

Zhong Yu

From viktor.klang at gmail.com  Thu May 10 13:13:48 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 10 May 2012 19:13:48 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
Message-ID: <CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>

On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
> <christianessl at googlemail.com> wrote:
> > Your are right my primary concern is code-simplicity not pure
> > performance, basicly writing in a traditional imperative blocking
> > style but still having IO with (mostly) non-blocking threads (and no
> > callbacks, no monadic futures).
>
> Thread is such a nice programming abstraction, it's a shame that we
> are so concerned of its overhead nowadays. Replacing simple threads
> with complex tasks seems to be retrogressing - aren't programming
> supposed to become easier?
>
> What are the fundamental reasons that Java Threads are expensive?
>

Can you give some arguments as to the greatness of proactive programming
(threads)?


>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/79fbedf1/attachment.html>

From zhong.j.yu at gmail.com  Thu May 10 13:45:25 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 10 May 2012 12:45:25 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
Message-ID: <CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>

On Thu, May 10, 2012 at 12:13 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>
>
> On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>
>> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
>> <christianessl at googlemail.com> wrote:
>> > Your are right my primary concern is code-simplicity not pure
>> > performance, basicly writing in a traditional imperative blocking
>> > style but still having IO with (mostly) non-blocking threads (and no
>> > callbacks, no monadic futures).
>>
>> Thread is such a nice programming abstraction, it's a shame that we
>> are so concerned of its overhead nowadays. Replacing simple threads
>> with complex tasks seems to be retrogressing - aren't programming
>> supposed to become easier?
>>
>> What are the fundamental reasons that Java Threads are expensive?
>
>
> Can you give some arguments as to the greatness of proactive programming
> (threads)?

It just seems straightforward to me to write and read

    for(i=0;i<10;i++)
    {
        result = db.query( q[i] );  // blocking
        s = format(result);
        out.write( s );  // blocking
    }
    out.write("done") // blocking

Now convert it to async style - it's not rocket science hard, but at
least it's quite a chore.

Zhong Yu


From viktor.klang at gmail.com  Thu May 10 14:17:07 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 10 May 2012 20:17:07 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
Message-ID: <CANPzfU8qAA50p61W3ZkMvNLp53oVFZ56q4Ny2A+Pv=DbfuOu7w@mail.gmail.com>

On Thu, May 10, 2012 at 7:45 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Thu, May 10, 2012 at 12:13 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> >
> >
> > On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> >>
> >> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
> >> <christianessl at googlemail.com> wrote:
> >> > Your are right my primary concern is code-simplicity not pure
> >> > performance, basicly writing in a traditional imperative blocking
> >> > style but still having IO with (mostly) non-blocking threads (and no
> >> > callbacks, no monadic futures).
> >>
> >> Thread is such a nice programming abstraction, it's a shame that we
> >> are so concerned of its overhead nowadays. Replacing simple threads
> >> with complex tasks seems to be retrogressing - aren't programming
> >> supposed to become easier?
> >>
> >> What are the fundamental reasons that Java Threads are expensive?
> >
> >
> > Can you give some arguments as to the greatness of proactive programming
> > (threads)?
>
> It just seems straightforward to me to write and read
>
>    for(i=0;i<10;i++)
>    {
>        result = db.query( q[i] );  // blocking
>        s = format(result);
>        out.write( s );  // blocking
>    }
>    out.write("done") // blocking
>

Something like this should work:

sequence {
  q map db.query flatMap { result => out write format(result) }
} foreach {
  _ => out write "done"
}

Cheers,
?


> Now convert it to async style - it's not rocket science hard, but at
> least it's quite a chore.
>
> Zhong Yu
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/4d2c588a/attachment.html>

From rk at rkuhn.info  Thu May 10 14:37:35 2012
From: rk at rkuhn.info (Roland Kuhn)
Date: Thu, 10 May 2012 20:37:35 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
Message-ID: <D900FDC0-9194-4490-B67A-EB6A8DE65D10@rkuhn.info>


On May 10, 2012, at 19:45 , Zhong Yu wrote:

> On Thu, May 10, 2012 at 12:13 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>> 
>> 
>> On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>> 
>>> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
>>> <christianessl at googlemail.com> wrote:
>>>> Your are right my primary concern is code-simplicity not pure
>>>> performance, basicly writing in a traditional imperative blocking
>>>> style but still having IO with (mostly) non-blocking threads (and no
>>>> callbacks, no monadic futures).
>>> 
>>> Thread is such a nice programming abstraction, it's a shame that we
>>> are so concerned of its overhead nowadays. Replacing simple threads
>>> with complex tasks seems to be retrogressing - aren't programming
>>> supposed to become easier?
>>> 
>>> What are the fundamental reasons that Java Threads are expensive?
>> 
>> 
>> Can you give some arguments as to the greatness of proactive programming
>> (threads)?
> 
> It just seems straightforward to me to write and read
> 
>    for(i=0;i<10;i++)
>    {
>        result = db.query( q[i] );  // blocking
>        s = format(result);
>        out.write( s );  // blocking
>    }
>    out.write("done") // blocking
> 
!!! caution: Scala code ahead !!!

Future.flow {
  var i = 0
  while (i < 10) {
    val resultFuture = dbActor ? Query(q(i))
    outputActor ! format(resultFuture())
    i += 1
  }
  outputActor ! "done"
}

I?ve just seen Viktor?s reply, but I think that mine (while not being idiomatic Scala) might be clearer in this context ;-)

Explanation: the flow-block will be transformed by the compiler into continuation-passing style around resultFuture(), effectively breaking it up so that at this point execution is suspended until the result of the future is ready. Imperative coding style, asynchronous execution, profit.

Regards,

Roland

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra



From william.louth at jinspired.com  Thu May 10 14:39:41 2012
From: william.louth at jinspired.com (William Louth (JINSPIRED.COM))
Date: Thu, 10 May 2012 20:39:41 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
Message-ID: <4FAC0B6D.3060600@jinspired.com>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/857e0c6c/attachment-0001.html>

From viktor.klang at gmail.com  Thu May 10 14:49:53 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 10 May 2012 20:49:53 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FAC0B6D.3060600@jinspired.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<4FAC0B6D.3060600@jinspired.com>
Message-ID: <CANPzfU-LfKZPdXK7EEiUEZ7N9L863BLoA69a6z2zOLR2BQdyMg@mail.gmail.com>

Examples please.
On May 10, 2012 8:47 PM, "William Louth (JINSPIRED.COM)" <
william.louth at jinspired.com> wrote:

>  threads they are great...they get work done...we should have more of that
> in the world ;-)
>
> on an ever so slightly more serious note they offer the nearest thing we
> have to a consistent causality and context of execution that today is able
> to span whatever framework or jvm language you are using except for of
> course...blahblah..though admittedly this is transient (but what is not)
> threads also serve as a more appropriate self observation (reflection)
> point and self regulation (constructional) mechanism though naturally you
> could re-implement (and copy) this stuff (and context) countless times up
> and down the stack in whatever inefficient manner you care for
>
> On a more serious note I refer you to
> http://bytemunch.com/post/nodejs-is-bad-ass-rock-star-tech-xtranormal/
>
> threads are the nearest thing we have to identifiable (explicit) network
> flows...we have just failed to capitalize on this and bring more dynamic
> service classification, contextual prioritization, policing,
> shaping,...that would work irrespective of VM language or library or
> fadofthedayframework http://www.infoq.com/articles/QoS-for-Applications
>
> On 10/05/2012 19:13, ?iktor ?lang wrote:
>
>
>
> On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>
>> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
>> <christianessl at googlemail.com> wrote:
>> > Your are right my primary concern is code-simplicity not pure
>> > performance, basicly writing in a traditional imperative blocking
>> > style but still having IO with (mostly) non-blocking threads (and no
>> > callbacks, no monadic futures).
>>
>>  Thread is such a nice programming abstraction, it's a shame that we
>> are so concerned of its overhead nowadays. Replacing simple threads
>> with complex tasks seems to be retrogressing - aren't programming
>> supposed to become easier?
>>
>> What are the fundamental reasons that Java Threads are expensive?
>>
>
>  Can you give some arguments as to the greatness of proactive programming
> (threads)?
>
>
>>
>> Zhong Yu
>>  _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
>  --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/6883404c/attachment.html>

From william.louth at jinspired.com  Thu May 10 15:11:37 2012
From: william.louth at jinspired.com (William Louth (JINSPIRED.COM))
Date: Thu, 10 May 2012 21:11:37 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CANPzfU-LfKZPdXK7EEiUEZ7N9L863BLoA69a6z2zOLR2BQdyMg@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<4FAC0B6D.3060600@jinspired.com>
	<CANPzfU-LfKZPdXK7EEiUEZ7N9L863BLoA69a6z2zOLR2BQdyMg@mail.gmail.com>
Message-ID: <4FAC12E9.9020600@jinspired.com>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/6f2adcb8/attachment.html>

From viktor.klang at gmail.com  Thu May 10 15:18:44 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 10 May 2012 21:18:44 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FAC12E9.9020600@jinspired.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<4FAC0B6D.3060600@jinspired.com>
	<CANPzfU-LfKZPdXK7EEiUEZ7N9L863BLoA69a6z2zOLR2BQdyMg@mail.gmail.com>
	<4FAC12E9.9020600@jinspired.com>
Message-ID: <CANPzfU8q7DTp7uZ0ca=8x4G3Eg3YyXpEbZbkTrgjcCZfoLKEqg@mail.gmail.com>

Lets pretend it isn't. Examples please.
On May 10, 2012 9:15 PM, "William Louth (JINSPIRED.COM)" <
william.louth at jinspired.com> wrote:

>
>
> It's "self" explanatory.
>
> On 10/05/2012 20:49, ?iktor ?lang wrote:
>
> Examples please.
> On May 10, 2012 8:47 PM, "William Louth (JINSPIRED.COM)" <
> william.louth at jinspired.com> wrote:
>
>>  threads they are great...they get work done...we should have more of
>> that in the world ;-)
>>
>> on an ever so slightly more serious note they offer the nearest thing we
>> have to a consistent causality and context of execution that today is able
>> to span whatever framework or jvm language you are using except for of
>> course...blahblah..though admittedly this is transient (but what is not)
>> threads also serve as a more appropriate self observation (reflection)
>> point and self regulation (constructional) mechanism though naturally you
>> could re-implement (and copy) this stuff (and context) countless times up
>> and down the stack in whatever inefficient manner you care for
>>
>> On a more serious note I refer you to
>> http://bytemunch.com/post/nodejs-is-bad-ass-rock-star-tech-xtranormal/
>>
>> threads are the nearest thing we have to identifiable (explicit) network
>> flows...we have just failed to capitalize on this and bring more dynamic
>> service classification, contextual prioritization, policing,
>> shaping,...that would work irrespective of VM language or library or
>> fadofthedayframework http://www.infoq.com/articles/QoS-for-Applications
>>
>> On 10/05/2012 19:13, ???iktor ? lang wrote:
>>
>>
>>
>> On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>
>>> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
>>> <christianessl at googlemail.com> wrote:
>>> > Your are right my primary concern is code-simplicity not pure
>>> > performance, basicly writing in a traditional imperative blocking
>>> > style but still having IO with (mostly) non-blocking threads (and no
>>> > callbacks, no monadic futures).
>>>
>>>  Thread is such a nice programming abstraction, it's a shame that we
>>> are so concerned of its overhead nowadays. Replacing simple threads
>>> with complex tasks seems to be retrogressing - aren't programming
>>> supposed to become easier?
>>>
>>> What are the fundamental reasons that Java Threads are expensive?
>>>
>>
>>  Can you give some arguments as to the greatness of proactive
>> programming (threads)?
>> ?
>>
>>>
>>> Zhong Yu
>>>  _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>>  --
>> Viktor Klang
>>
>> Akka Tech Lead
>> Typesafe <http://www.typesafe.com/>? - The software stack for
>> applications that scale
>>
>> Twitter: @viktorklang
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/0e6eae70/attachment-0001.html>

From gergg at cox.net  Thu May 10 15:30:43 2012
From: gergg at cox.net (Gregg Wonderly)
Date: Thu, 10 May 2012 14:30:43 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FAC0B6D.3060600@jinspired.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<4FAC0B6D.3060600@jinspired.com>
Message-ID: <C42F5E51-D028-465A-8FBD-48E9310FBAEE@cox.net>

In the end we need to really do data flow analysis and schedule CPU use based on the optimizations which the analysis reveals.  The EMSP project at Bell Labs which was supporting advanced image processing for submarine radar systems, during the cold war, seems to be completely lost technology in the private sector...

Who knows what's possible now with the convenience of FPGS and modern DSP systems!

Gregg Wonderly

Sent from my iPhone

On May 10, 2012, at 1:39 PM, "William Louth (JINSPIRED.COM)" <william.louth at jinspired.com> wrote:

> threads they are great...they get work done...we should have more of that in the world ;-)
> 
> on an ever so slightly more serious note they offer the nearest     thing we have to a consistent causality and context of execution     that today is able to span whatever framework or jvm language you are using except for of course...blahblah..though admittedly this is transient (but what is not) threads also serve as a more appropriate self observation (reflection) point and self regulation (constructional) mechanism though naturally you could re-implement (and copy) this stuff (and context) countless times up and down the stack in whatever inefficient manner you care for
> 
> On a more serious note I refer you to http://bytemunch.com/post/nodejs-is-bad-ass-rock-star-tech-xtranormal/
> 
> threads are the nearest thing we have to identifiable (explicit) network flows...we have just failed to capitalize on this and bring more dynamic service classification, contextual prioritization, policing, shaping,...that would work irrespective of VM language or library or fadofthedayframework http://www.infoq.com/articles/QoS-for-Applications
> 
> On 10/05/2012 19:13, ?iktor ?lang wrote:
>> 
>> 
>> 
>> On Thu, May 10, 2012 at 7:07 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
>> <christianessl at googlemail.com> wrote:
>> > Your are right my primary concern is code-simplicity not pure
>> > performance, basicly writing in a traditional imperative blocking
>> > style but still having IO with (mostly) non-blocking threads (and no
>> > callbacks, no monadic futures).
>> 
>> Thread is such a nice programming abstraction, it's a shame that we
>> are so concerned of its overhead nowadays. Replacing simple threads
>> with complex tasks seems to be retrogressing - aren't programming
>> supposed to become easier?
>> 
>> What are the fundamental reasons that Java Threads are           expensive?
>> 
>> Can you give some arguments as to the greatness of proactive programming (threads)?
>>  
>> 
>> Zhong Yu
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
>> 
>> -- 
>> Viktor Klang
>> 
>> Akka Tech Lead
>> Typesafe - The software stack for applications that scale
>> 
>> Twitter: @viktorklang
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/2d2a4998/attachment.html>

From zhong.j.yu at gmail.com  Thu May 10 16:52:55 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 10 May 2012 15:52:55 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <D900FDC0-9194-4490-B67A-EB6A8DE65D10@rkuhn.info>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
	<D900FDC0-9194-4490-B67A-EB6A8DE65D10@rkuhn.info>
Message-ID: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>

On Thu, May 10, 2012 at 1:37 PM, Roland Kuhn <rk at rkuhn.info> wrote:

> Explanation: the flow-block will be transformed by the compiler into continuation-passing style around resultFuture(), effectively breaking it up so that at this point execution is suspended until the result of the future is ready. Imperative coding style, asynchronous execution, profit.

while that is super cool, it is not as simple and elegant as thread:)

the reason we do these async stuff is because threads are "expensive".
but why are threads expensive?

> Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
> ?-- Dijkstra
>


From gregg at cytetech.com  Thu May 10 17:42:05 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 10 May 2012 16:42:05 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
Message-ID: <4FAC362D.3080703@cytetech.com>

On 5/10/2012 12:45 PM, Zhong Yu wrote:
> On Thu, May 10, 2012 at 12:13 PM, ?iktor ?lang<viktor.klang at gmail.com>  wrote:
>>
>>
>> On Thu, May 10, 2012 at 7:07 PM, Zhong Yu<zhong.j.yu at gmail.com>  wrote:
>>>
>>> On Thu, May 10, 2012 at 10:26 AM, Christian Essl
>>> <christianessl at googlemail.com>  wrote:
>>>> Your are right my primary concern is code-simplicity not pure
>>>> performance, basicly writing in a traditional imperative blocking
>>>> style but still having IO with (mostly) non-blocking threads (and no
>>>> callbacks, no monadic futures).
>>>
>>> Thread is such a nice programming abstraction, it's a shame that we
>>> are so concerned of its overhead nowadays. Replacing simple threads
>>> with complex tasks seems to be retrogressing - aren't programming
>>> supposed to become easier?
>>>
>>> What are the fundamental reasons that Java Threads are expensive?
>>
>>
>> Can you give some arguments as to the greatness of proactive programming
>> (threads)?
>
> It just seems straightforward to me to write and read
>
>      for(i=0;i<10;i++)
>      {
>          result = db.query( q[i] );  // blocking
>          s = format(result);
>          out.write( s );  // blocking
>      }
>      out.write("done") // blocking

This is completely doable in plane Java with Executor, and completely readable. 
  Annonymous, inner classes are your friend!

// This appears to be doable asynchronously, but multiple queries,
// may in fact, reduce throughput if the database is an Access
// database, or some other single threaded database, for example.
final List<String>results = new ArrayList<String>();
for( i = 0; i < q.length; ++i ) {
	final int ival = i;
	exec.execute( new Runnable() {
		public void run() {
			results.add( format( db.query( q[ival] ) ) );
		}
	});
}
exec.shutdown();

// this must be done in sequential order
for( String s : results ) {
	out.write(s);
}
out.write( "done" );

Gregg Wonderly

From gregg at cytetech.com  Thu May 10 17:58:08 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 10 May 2012 16:58:08 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>
	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>
	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>
	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>
	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>
	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>
	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>
	<CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>
	<D900FDC0-9194-4490-B67A-EB6A8DE65D10@rkuhn.info>
	<CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
Message-ID: <4FAC39F0.5050509@cytetech.com>

On 5/10/2012 3:52 PM, Zhong Yu wrote:
> On Thu, May 10, 2012 at 1:37 PM, Roland Kuhn<rk at rkuhn.info>  wrote:
>
>> Explanation: the flow-block will be transformed by the compiler into continuation-passing style around resultFuture(), effectively breaking it up so that at this point execution is suspended until the result of the future is ready. Imperative coding style, asynchronous execution, profit.
>
> while that is super cool, it is not as simple and elegant as thread:)
>
> the reason we do these async stuff is because threads are "expensive".
> but why are threads expensive?

What do you believe is the cost to which expensive is related?  The number one 
issue is that it is more "code", to do "more things".  The question in the 
optimizations of most async systems, is whether or not there is latency in an 
operation which can be hidden by some other action which can be performed in 
parallel.  Latency, the pause or in activity of "preparing" to do something, is 
the primary consideration.  In a completely sequential system, the latency for 
any particular "step", is all the steps that came before it.  Some steps use the 
output of other steps as data, or context.

So, threads are expensive only when the "latency" of using a thread in a 
particular way, can not be "removed" from the system by using another thread to 
do something, unrelated, at the same time.

Practically, thread creation is "expensive", because of the number of 
instructions and implicit "context switches" required to "make" a thread ready 
to use.  Pools of threads, try to optimize this issue, by creating threads 
"once", and then have them ready to execute a task with very little latency 
(just the time it takes to hand the thread a Runnable in a "volatile 
assignment", and then waking the thread so that it can call Runnable.run(), right?

>> Simplicity and elegance are unpopular because they require hard work and
 >> discipline to achieve and education to be appreciated.

Threading in Java, is kind of like the rash of "register" declarations which 
happened in C code in the early days of Unix.  Most compilers would not 
explicitly perform register allocation, and would instead, always use register 
indirect addressing of variables, to read and write them from/to memory.  In 
those days, it was much, much slower to access memory, than a register, as it is 
today, so math programs became extremely fast when you declared variables with 
"register".  But, you had to be able to look at a piece of code, know how many 
register variables you had, and then be able to optimize use of those variables, 
sometimes introducing new blocks with {...} and new register variables, to 
change how registerization was done, while maintaining useful variable names.

Threading is similar.  You need to understand how the code actually works, 
what's async, what has data dependencies, what doesn't, and then how many 
"cores" do you have available, so that you can use them effectively.

Unfortunately, there are perhaps 60%-70% of the "programmers" in the world now, 
who have no idea how a processor and operating system interact with their 
application, so that they can optimize every detail.

Things are so fast now, that for the size of most problems, no one cares.  If I 
need an answer in 5 hours, and you can give me results in 4 hours, I'm probably 
not going to complain much.  But, if my needs suddenly change to 15minutes, then 
the application needs to be optimizable and scalable, to a new level of 
performance, and that's where Dijkstra's comment bares down on reality.

Discipline and Education are required to get there.

Gregg Wonderly


From davidcholmes at aapt.net.au  Thu May 10 18:00:36 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 11 May 2012 08:00:36 +1000
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEGJJEAA.davidcholmes@aapt.net.au>

Zhong Yu writes:
> the reason we do these async stuff is because threads are "expensive".
> but why are threads expensive?

"expensive" may be the wrong term. There are different costs associated with
using threads (memory and other resources to be allocated; cost of context
switching and communicating between threads) and in different contexts these
costs can become greater than what can reasonably be supported. For example,
thread-per-connection designs don't scale to thousands of connections
because, generally speaking, you can't create thousands of threads. So you
use alternative designs to alleviate pressure on the "resource" you are
having issues with - be that memory or computation costs.

ForkJoin based recursive decomposition wins over direct thread-based
recursive decomposition because it has already optimized for the bottlenecks
that will occur in such designs. Per-thread queues remove a single point of
contention. Work-stealing tries to minimize idle threads and context
switches by keeping threads that are logically blocked waiting for a result,
actively participating in the computation that may ultimately lead to that
result. The implementation of work-stealing (take from the head, steal from
the tail) is also designed to minimize contention.

David


From zhong.j.yu at gmail.com  Thu May 10 23:03:00 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 10 May 2012 22:03:00 -0500
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEGJJEAA.davidcholmes@aapt.net.au>
References: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEGJJEAA.davidcholmes@aapt.net.au>
Message-ID: <CACuKZqGhOMQFu5MeCBD4efJ3NJSHOYD=+7FkmuZh5TA7v7cnHQ@mail.gmail.com>

On Thu, May 10, 2012 at 5:00 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Zhong Yu writes:
>> the reason we do these async stuff is because threads are "expensive".
>> but why are threads expensive?
>
> "expensive" may be the wrong term. There are different costs associated with
> using threads (memory and other resources to be allocated; cost of context
> switching and communicating between threads) and in different contexts these
> costs can become greater than what can reasonably be supported. For example,
> thread-per-connection designs don't scale to thousands of connections
> because, generally speaking, you can't create thousands of threads. So you

Yes thread-per-connection doesn't work, today. My question is, could
OS/VM do some optimization to make it work? Or there are reasons
prohibiting that?

> use alternative designs to alleviate pressure on the "resource" you are
> having issues with - be that memory or computation costs.
>
> ForkJoin based recursive decomposition wins over direct thread-based
> recursive decomposition because it has already optimized for the bottlenecks
> that will occur in such designs. Per-thread queues remove a single point of
> contention. Work-stealing tries to minimize idle threads and context
> switches by keeping threads that are logically blocked waiting for a result,
> actively participating in the computation that may ultimately lead to that
> result. The implementation of work-stealing (take from the head, steal from
> the tail) is also designed to minimize contention.
>
> David
>

Can't all these tricks be done to Thread itself, so that when a thread
waits for an IO completion, it costs very little (much less than what
it costs today).

From davidcholmes at aapt.net.au  Thu May 10 23:12:32 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 11 May 2012 13:12:32 +1000
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGhOMQFu5MeCBD4efJ3NJSHOYD=+7FkmuZh5TA7v7cnHQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEGLJEAA.davidcholmes@aapt.net.au>

Zhong Yu writes:
> On Thu, May 10, 2012 at 5:00 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Zhong Yu writes:
> >> the reason we do these async stuff is because threads are "expensive".
> >> but why are threads expensive?
> >
> > "expensive" may be the wrong term. There are different costs
> associated with
> > using threads (memory and other resources to be allocated; cost
> of context
> > switching and communicating between threads) and in different
> contexts these
> > costs can become greater than what can reasonably be supported.
> For example,
> > thread-per-connection designs don't scale to thousands of connections
> > because, generally speaking, you can't create thousands of
> threads. So you
>
> Yes thread-per-connection doesn't work, today. My question is, could
> OS/VM do some optimization to make it work? Or there are reasons
> prohibiting that?

Could you design an OS where threads are less resource intensive than they
are today in existing OS? Sure, but along the way you will be making various
trade-offs. Could today's OS thread support be more efficient? Probably, but
these are exceedingly complex systems with a lot of historical baggage.

> > use alternative designs to alleviate pressure on the "resource" you are
> > having issues with - be that memory or computation costs.
> >
> > ForkJoin based recursive decomposition wins over direct thread-based
> > recursive decomposition because it has already optimized for
> the bottlenecks
> > that will occur in such designs. Per-thread queues remove a
> single point of
> > contention. Work-stealing tries to minimize idle threads and context
> > switches by keeping threads that are logically blocked waiting
> for a result,
> > actively participating in the computation that may ultimately
> lead to that
> > result. The implementation of work-stealing (take from the
> head, steal from
> > the tail) is also designed to minimize contention.
> >
>
> Can't all these tricks be done to Thread itself, so that when a thread
> waits for an IO completion, it costs very little (much less than what
> it costs today).

Threads don't have work queues so I'm not sure what you mean really.

What's the cost of "waiting for an IO completion"?

These questions are just too general - there's no way to answer them in a
general way.

David


From glenn at 8950aaa.com  Fri May 11 00:53:46 2012
From: glenn at 8950aaa.com (Glenn McGregor)
Date: Thu, 10 May 2012 21:53:46 -0700
Subject: [concurrency-interest] Class striped/ordered Thread Pool
Message-ID: <4FAC9B5A.10005@8950aaa.com>

Hello all,

I'm looking for a thread pool with the following characteristics... (in 
pseudo-code)

interface StripedRunner {
     Object getStripeClass();
     void run();
}

magicPool.execute( stripedRunner );

The idea being that any StripedRunners with the same stripeClass would 
get executed in the order they were queued,
but StripedRunners with different stripedClasses could execute 
independently.

Is there a way to configure the standard concurrent pools to work this 
way (doesn't seem to be), or a way to extends
the current code?

Or perhaps some third party library implementation?

Thanks!

Glenn McGregor

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/a9fbeb4e/attachment.html>

From davidcholmes at aapt.net.au  Fri May 11 01:07:50 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 11 May 2012 15:07:50 +1000
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FAC9B5A.10005@8950aaa.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>

Not sure if this makes sense unless you use a SingleThreadExecutor per
stripeClass. Otherwise you have races in the submission of StripedRunners of
the same stripeClass, and even if you order the queue so that they start
execution in the right order, you can't guarantee what order they will
complete in. Unless it is all done by a single thread.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Glenn
McGregor
  Sent: Friday, 11 May 2012 2:54 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Class striped/ordered Thread Pool


  Hello all,

  I'm looking for a thread pool with the following characteristics... (in
pseudo-code)

  interface StripedRunner {
      Object getStripeClass();
      void run();
  }

  magicPool.execute( stripedRunner );

  The idea being that any StripedRunners with the same stripeClass would get
executed in the order they were queued,
  but StripedRunners with different stripedClasses could execute
independently.

  Is there a way to configure the standard concurrent pools to work this way
(doesn't seem to be), or a way to extends
  the current code?

  Or perhaps some third party library implementation?

  Thanks!

  Glenn McGregor

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/cd39c163/attachment.html>

From glenn at 8950aaa.com  Fri May 11 01:14:18 2012
From: glenn at 8950aaa.com (Glenn McGregor)
Date: Thu, 10 May 2012 22:14:18 -0700
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
Message-ID: <4FACA02A.5080503@8950aaa.com>

On 5/10/2012 10:07 PM, David Holmes wrote:
> Not sure if this makes sense unless you use a SingleThreadExecutor per 
> stripeClass. Otherwise you have races in the submission of 
> StripedRunners of the same stripeClass, and even if you order the 
> queue so that they start execution in the right order, you can't 
> guarantee what order they will complete in. Unless it is all done by a 
> single thread.
> David Holmes

I can guarantee that items of the same class are generated by one thread.

To expand on my particular use case...

I have a small number of threads using NIO to read multiple TCP or SCTP 
data streams.
I need to process TLS in order for a given socket.
But a given TLS stream is only read by one thread.

So what I want to hand off my TLS work to a thread pool, but need to 
keep particular streams in sequence.

Thanks


Glenn McGregor


>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Glenn McGregor
>     *Sent:* Friday, 11 May 2012 2:54 PM
>     *To:* concurrency-interest at cs.oswego.edu
>     *Subject:* [concurrency-interest] Class striped/ordered Thread Pool
>
>     Hello all,
>
>     I'm looking for a thread pool with the following
>     characteristics... (in pseudo-code)
>
>     interface StripedRunner {
>         Object getStripeClass();
>         void run();
>     }
>
>     magicPool.execute( stripedRunner );
>
>     The idea being that any StripedRunners with the same stripeClass
>     would get executed in the order they were queued,
>     but StripedRunners with different stripedClasses could execute
>     independently.
>
>     Is there a way to configure the standard concurrent pools to work
>     this way (doesn't seem to be), or a way to extends
>     the current code?
>
>     Or perhaps some third party library implementation?
>
>     Thanks!
>
>     Glenn McGregor
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120510/fee266f1/attachment.html>

From aleksey.shipilev at gmail.com  Fri May 11 01:59:19 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Fri, 11 May 2012 09:59:19 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FACA02A.5080503@8950aaa.com>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
	<4FACA02A.5080503@8950aaa.com>
Message-ID: <CA+1LWGHCjav6ww9zF7FGZBhqNAbKx9owp9jZ-UFchNTnnXtYXQ@mail.gmail.com>

Glenn,

Ditto for David Holmes comment about the guarantees for execution
order with multiple threads in thread pool. You will pay for strict
ordering with proper load balancing though. I think you should be
looking at instantiating a couple of threadpools, and multiplex
incoming StripedRunners onto them. There's no need to have 1:1
threadpool:class relationship, you need only enforce that the same
class always end up in the same executor. Like this (in pseudocode):

public class StripedExecutor {

    private static final int COUNT = 16; // better be power of two

    private final Executor[] executors = ... // instantiate each
executor with single thread;

    public void submit(StripedRunner runner) {
         int index = shuffle(runner.getStripeClass().hashCode()) & (COUNT - 1);
         executors[index].submit(runner);
    }

    private int shuffle(int value) {
         return ...; // bit-shuffle value a bit, protecting from bad hashcodes
    }

}

I think it is a good idea to extend StripedRunner from Runnable
(should it be named StripedRunnable then?). Also, your stripe class
should have stable hashcode, or some other distinguishable numerical
characteristic.

-Aleksey.

On Fri, May 11, 2012 at 9:14 AM, Glenn McGregor <glenn at 8950aaa.com> wrote:
> On 5/10/2012 10:07 PM, David Holmes wrote:
>
> Not sure if this makes sense unless you use a SingleThreadExecutor per
> stripeClass. Otherwise you have races in the submission of StripedRunners of
> the same stripeClass, and even if you order the queue so that they start
> execution in the right order, you can't guarantee what order they will
> complete in. Unless it is all done by a single thread.

From mthornton at optrak.com  Fri May 11 03:46:54 2012
From: mthornton at optrak.com (Mark Thornton)
Date: Fri, 11 May 2012 08:46:54 +0100
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqGhOMQFu5MeCBD4efJ3NJSHOYD=+7FkmuZh5TA7v7cnHQ@mail.gmail.com>
References: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEGJJEAA.davidcholmes@aapt.net.au>
	<CACuKZqGhOMQFu5MeCBD4efJ3NJSHOYD=+7FkmuZh5TA7v7cnHQ@mail.gmail.com>
Message-ID: <4FACC3EE.6050207@optrak.com>

On 11/05/12 04:03, Zhong Yu wrote:
>
> Yes thread-per-connection doesn't work, today. My question is, could
> OS/VM do some optimization to make it work? Or there are reasons
> prohibiting that?
>

There have been VMs designed to run tens of thousands of threads even in 
a 32 bit system. One of the critical resources in a VM like HotSpot is 
the address reserved for each thread's stack. Typically this is 256K in 
a 32 bit system. This clearly limits the number of threads you can have. 
I remember a VM which allocated much smaller stacks initially (8K 
perhaps) and then expanded the stack if it became full  (expensive, but 
hopefully rare). The rationale here was to permit the one thread per 
connection model to scale to very large numbers of connections.

Mark Thornton


From heinz at javaspecialists.eu  Fri May 11 04:23:31 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 11 May 2012 10:23:31 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FACA02A.5080503@8950aaa.com>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
	<4FACA02A.5080503@8950aaa.com>
Message-ID: <4FACCC83.2060704@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/a3cb93e5/attachment.html>

From davidcholmes at aapt.net.au  Fri May 11 06:38:20 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 11 May 2012 20:38:20 +1000
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FACA02A.5080503@8950aaa.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEGOJEAA.davidcholmes@aapt.net.au>

So as I said, putting them in in order doesn't guarantee they actually get
processed in that order. So you either have them all served by one thread,
or your threads have to multiplex across different queues as Heinz
suggested. The end result is that processing of any given stripe is
serialized (or it may be that you can narrow down the actual code that needs
to executed in order - but somewhere you will need to "gate" things. I'm
sure there are numerous patterns for this kind of I/O processing - take a
look at the extensive work Doug Schmidt did in this area:

http://www.cs.wustl.edu/~schmidt/patterns.html

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Glenn
McGregor
  Sent: Friday, 11 May 2012 3:14 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Class striped/ordered Thread Pool


  On 5/10/2012 10:07 PM, David Holmes wrote:

    Not sure if this makes sense unless you use a SingleThreadExecutor per
stripeClass. Otherwise you have races in the submission of StripedRunners of
the same stripeClass, and even if you order the queue so that they start
execution in the right order, you can't guarantee what order they will
complete in. Unless it is all done by a single thread.

    David Holmes

  I can guarantee that items of the same class are generated by one thread.

  To expand on my particular use case...

  I have a small number of threads using NIO to read multiple TCP or SCTP
data streams.
  I need to process TLS in order for a given socket.
  But a given TLS stream is only read by one thread.

  So what I want to hand off my TLS work to a thread pool, but need to keep
particular streams in sequence.

  Thanks


  Glenn McGregor



      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Glenn
McGregor
      Sent: Friday, 11 May 2012 2:54 PM
      To: concurrency-interest at cs.oswego.edu
      Subject: [concurrency-interest] Class striped/ordered Thread Pool


      Hello all,

      I'm looking for a thread pool with the following characteristics...
(in pseudo-code)

      interface StripedRunner {
          Object getStripeClass();
          void run();
      }

      magicPool.execute( stripedRunner );

      The idea being that any StripedRunners with the same stripeClass would
get executed in the order they were queued,
      but StripedRunners with different stripedClasses could execute
independently.

      Is there a way to configure the standard concurrent pools to work this
way (doesn't seem to be), or a way to extends
      the current code?

      Or perhaps some third party library implementation?

      Thanks!

      Glenn McGregor




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/0baa1ccb/attachment.html>

From aleksey.shipilev at gmail.com  Fri May 11 07:19:05 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Fri, 11 May 2012 15:19:05 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FACCC83.2060704@javaspecialists.eu>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
	<4FACA02A.5080503@8950aaa.com> <4FACCC83.2060704@javaspecialists.eu>
Message-ID: <CA+1LWGGrkCjJVD7p+Vm7spH40PEo6+621F3Z157ZQOVTpt8Agw@mail.gmail.com>

On Fri, May 11, 2012 at 12:23 PM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> I don't think you need to change anything in your thread pool to get this to
> work.? All you need is the right type of queue.

I have mixed feeling about this. It really depends on the work you are
feeding into this pool.

The trouble I'm seeing is scanning through these class-specific queues
would take considerable time for large amount of classes. Also, if the
classes are not known in advance, you face with the dynamic updates
(and race-free purges ;)) the Map<StripeObject, BlockingQueue>. That
gets more interesting without having out-of-the-box
ConcurrentIdentityHashMap.

I advocate that multiplexing based on hashcode (or other the
distinguishing flags) is more elegant solution. The major benefit I'm
seeing in Heinz scheme is one global thread pool, which can share
threads between different classes. However, I advocate that given the
near-uniform stream of large amount of classes provides the needed
balancing in fixed-multiplexing scheme.

> If you like, I can try and write it for you tomorrow on my travels back to
> Greece from Germany.? No charge of course.

Please do that for me as well :) It is a nice benchmark game I would
probably like to participate in.

-Aleksey.


From joe.bowbeer at gmail.com  Fri May 11 09:21:24 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 11 May 2012 06:21:24 -0700
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FACA02A.5080503@8950aaa.com>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
	<4FACA02A.5080503@8950aaa.com>
Message-ID: <CAHzJPEovJxrhCw_gsRXk7_dUmTsCwRvTgLMb4COsCru7yhzb6w@mail.gmail.com>

I think some similar problems have been discussed here and the solution I
recall is to use a SerialExecutor per stream, where each executor would
share the same ThreadPoolExecutor. The serial executor is in the javadocs.
It just wraps tasks to ensure that at most one is executing on the thread
pool at one time.
On May 11, 2012 12:17 AM, "Glenn McGregor" <glenn at 8950aaa.com> wrote:

>  On 5/10/2012 10:07 PM, David Holmes wrote:
>
> Not sure if this makes sense unless you use a SingleThreadExecutor per
> stripeClass. Otherwise you have races in the submission of StripedRunners
> of the same stripeClass, and even if you order the queue so that they start
> execution in the right order, you can't guarantee what order they will
> complete in. Unless it is all done by a single thread.
>
> David Holmes
>
>
> I can guarantee that items of the same class are generated by one thread.
>
> To expand on my particular use case...
>
> I have a small number of threads using NIO to read multiple TCP or SCTP
> data streams.
> I need to process TLS in order for a given socket.
> But a given TLS stream is only read by one thread.
>
> So what I want to hand off my TLS work to a thread pool, but need to keep
> particular streams in sequence.
>
> Thanks
>
>
> Glenn McGregor
>
>
>  -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
> ]*On Behalf Of *Glenn McGregor
> *Sent:* Friday, 11 May 2012 2:54 PM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Class striped/ordered Thread Pool
>
>  Hello all,
>
> I'm looking for a thread pool with the following characteristics... (in
> pseudo-code)
>
> interface StripedRunner {
>     Object getStripeClass();
>     void run();
> }
>
> magicPool.execute( stripedRunner );
>
> The idea being that any StripedRunners with the same stripeClass would get
> executed in the order they were queued,
> but StripedRunners with different stripedClasses could execute
> independently.
>
> Is there a way to configure the standard concurrent pools to work this way
> (doesn't seem to be), or a way to extends
> the current code?
>
> Or perhaps some third party library implementation?
>
> Thanks!
>
> Glenn McGregor
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/72cc9b5e/attachment-0001.html>

From pavel.rappo at gmail.com  Fri May 11 09:42:56 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 11 May 2012 17:42:56 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FACCC83.2060704@javaspecialists.eu>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
	<4FACA02A.5080503@8950aaa.com>
	<4FACCC83.2060704@javaspecialists.eu>
Message-ID: <FCDC57B5-5836-4898-8235-85BB2E55CE96@gmail.com>

Once I had the same problem and solved it exactly like Dr. Kabutz explained. That's pretty straightforward.
In my case there were m users connected to CCTV server with n worker threads (m >> n). Each of the users issued standard commands to cameras like:
	Left (10 deg)->Up (30 deg)->Zoom (1.5x).
Obviously I had to preserve the order of these commands.

On 11 May 2012, at 12:23, Dr Heinz M. Kabutz wrote:

> Hi Glenn,
> 
> I think your idea can be implemented fairly easily.  I wrote something similar yesterday, where I had queues of different priority and also stored them in a map of queues.
> 
> First off, you need a special type of BlockingQueue that takes your StripedRunnable class and pops it into a queue for each specific stripe object.  I don't think your stripe object needs to have a hash code function.  I would use a type of identity hash map with weak references for keys.
> 
> Inside each queue you would have a gate that would start open.  The offer() method would simply add elements to the queue without affecting the gate.  Whenever an element is removed by the thread pool, the gate would be closed.  This means that if another thread wanted to remove an element, it would skip over that queue since the gate is closed.  Once the job has been completed, the job would again open the gate.  This is easily done by wrapping the job with another Runnable that controls the gate.
> 
> I don't think you need to change anything in your thread pool to get this to work.  All you need is the right type of queue.
> 
> If you like, I can try and write it for you tomorrow on my travels back to Greece from Germany.  No charge of course.
> Regards
> 
> Heinz
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> 
> http://www.javaspecialists.eu
> 
> Tel: +30 69 75 595 262
> Skype: kabutz 
> 
> 
> 
> On 5/11/12 7:14 AM, Glenn McGregor wrote:
>> On 5/10/2012 10:07 PM, David Holmes wrote:
>>> Not sure if this makes sense unless you use a SingleThreadExecutor per stripeClass. Otherwise you have races in the submission of StripedRunners of the same stripeClass, and even if you order the queue so that they start execution in the right order, you can't guarantee what order they will complete in. Unless it is all done by a single thread.
>>>  
>>> David Holmes
>> 
>> I can guarantee that items of the same class are generated by one thread.
>> 
>> To expand on my particular use case...
>> 
>> I have a small number of threads using NIO to read multiple TCP or SCTP data streams.
>> I need to process TLS in order for a given socket.
>> But a given TLS stream is only read by one thread.
>> 
>> So what I want to hand off my TLS work to a thread pool, but need to keep particular streams in sequence.
>> 
>> Thanks
>> 
>> 
>> Glenn McGregor
>> 
>> 
>>> -----Original Message-----
>>> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Glenn McGregor
>>> Sent: Friday, 11 May 2012 2:54 PM
>>> To: concurrency-interest at cs.oswego.edu
>>> Subject: [concurrency-interest] Class striped/ordered Thread Pool
>>> 
>>> Hello all, 
>>> 
>>> I'm looking for a thread pool with the following characteristics... (in pseudo-code) 
>>> 
>>> interface StripedRunner { 
>>>     Object getStripeClass(); 
>>>     void run(); 
>>> } 
>>> 
>>> magicPool.execute( stripedRunner ); 
>>> 
>>> The idea being that any StripedRunners with the same stripeClass would get executed in the order they were queued, 
>>> but StripedRunners with different stripedClasses could execute independently. 
>>> 
>>> Is there a way to configure the standard concurrent pools to work this way (doesn't seem to be), or a way to extends 
>>> the current code? 
>>> 
>>> Or perhaps some third party library implementation? 
>>> 
>>> Thanks! 
>>> 
>>> Glenn McGregor 
>>> 
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> 
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>>   
>> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From viktor.klang at gmail.com  Fri May 11 09:57:27 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 11 May 2012 15:57:27 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <FCDC57B5-5836-4898-8235-85BB2E55CE96@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCMEGMJEAA.davidcholmes@aapt.net.au>
	<4FACA02A.5080503@8950aaa.com>
	<4FACCC83.2060704@javaspecialists.eu>
	<FCDC57B5-5836-4898-8235-85BB2E55CE96@gmail.com>
Message-ID: <CANPzfU8=SSvVxsaS0pLE0-eMLbdykrsmW75-pJ8Hb+t_=GZ5ig@mail.gmail.com>

Netty does something similar with an executor per
channel: OrderedMemoryAwareThreadPoolExecutor =>
http://netty.io/docs/stable/api/org/jboss/netty/handler/execution/OrderedMemoryAwareThreadPoolExecutor.ChildExecutor.html

Cheers,
?

On Fri, May 11, 2012 at 3:42 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> Once I had the same problem and solved it exactly like Dr. Kabutz
> explained. That's pretty straightforward.
> In my case there were m users connected to CCTV server with n worker
> threads (m >> n). Each of the users issued standard commands to cameras
> like:
>        Left (10 deg)->Up (30 deg)->Zoom (1.5x).
> Obviously I had to preserve the order of these commands.
>
> On 11 May 2012, at 12:23, Dr Heinz M. Kabutz wrote:
>
> > Hi Glenn,
> >
> > I think your idea can be implemented fairly easily.  I wrote something
> similar yesterday, where I had queues of different priority and also stored
> them in a map of queues.
> >
> > First off, you need a special type of BlockingQueue that takes your
> StripedRunnable class and pops it into a queue for each specific stripe
> object.  I don't think your stripe object needs to have a hash code
> function.  I would use a type of identity hash map with weak references for
> keys.
> >
> > Inside each queue you would have a gate that would start open.  The
> offer() method would simply add elements to the queue without affecting the
> gate.  Whenever an element is removed by the thread pool, the gate would be
> closed.  This means that if another thread wanted to remove an element, it
> would skip over that queue since the gate is closed.  Once the job has been
> completed, the job would again open the gate.  This is easily done by
> wrapping the job with another Runnable that controls the gate.
> >
> > I don't think you need to change anything in your thread pool to get
> this to work.  All you need is the right type of queue.
> >
> > If you like, I can try and write it for you tomorrow on my travels back
> to Greece from Germany.  No charge of course.
> > Regards
> >
> > Heinz
> > --
> > Dr Heinz M. Kabutz (PhD CompSci)
> > Author of "The Java(tm) Specialists' Newsletter"
> > Sun Java Champion
> > IEEE Certified Software Development Professional
> >
> > http://www.javaspecialists.eu
> >
> > Tel: +30 69 75 595 262
> > Skype: kabutz
> >
> >
> >
> > On 5/11/12 7:14 AM, Glenn McGregor wrote:
> >> On 5/10/2012 10:07 PM, David Holmes wrote:
> >>> Not sure if this makes sense unless you use a SingleThreadExecutor per
> stripeClass. Otherwise you have races in the submission of StripedRunners
> of the same stripeClass, and even if you order the queue so that they start
> execution in the right order, you can't guarantee what order they will
> complete in. Unless it is all done by a single thread.
> >>>
> >>> David Holmes
> >>
> >> I can guarantee that items of the same class are generated by one
> thread.
> >>
> >> To expand on my particular use case...
> >>
> >> I have a small number of threads using NIO to read multiple TCP or SCTP
> data streams.
> >> I need to process TLS in order for a given socket.
> >> But a given TLS stream is only read by one thread.
> >>
> >> So what I want to hand off my TLS work to a thread pool, but need to
> keep particular streams in sequence.
> >>
> >> Thanks
> >>
> >>
> >> Glenn McGregor
> >>
> >>
> >>> -----Original Message-----
> >>> From: concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Glenn McGregor
> >>> Sent: Friday, 11 May 2012 2:54 PM
> >>> To: concurrency-interest at cs.oswego.edu
> >>> Subject: [concurrency-interest] Class striped/ordered Thread Pool
> >>>
> >>> Hello all,
> >>>
> >>> I'm looking for a thread pool with the following characteristics...
> (in pseudo-code)
> >>>
> >>> interface StripedRunner {
> >>>     Object getStripeClass();
> >>>     void run();
> >>> }
> >>>
> >>> magicPool.execute( stripedRunner );
> >>>
> >>> The idea being that any StripedRunners with the same stripeClass would
> get executed in the order they were queued,
> >>> but StripedRunners with different stripedClasses could execute
> independently.
> >>>
> >>> Is there a way to configure the standard concurrent pools to work this
> way (doesn't seem to be), or a way to extends
> >>> the current code?
> >>>
> >>> Or perhaps some third party library implementation?
> >>>
> >>> Thanks!
> >>>
> >>> Glenn McGregor
> >>>
> >>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >>
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/810150d7/attachment.html>

From viktor.klang at gmail.com  Fri May 11 10:55:04 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 11 May 2012 16:55:04 +0200
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <4FACC3EE.6050207@optrak.com>
References: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEGJJEAA.davidcholmes@aapt.net.au>
	<CACuKZqGhOMQFu5MeCBD4efJ3NJSHOYD=+7FkmuZh5TA7v7cnHQ@mail.gmail.com>
	<4FACC3EE.6050207@optrak.com>
Message-ID: <CANPzfU8agqm7i1Qvga0cfy+Fm25wWYoRFLB55+fYsRZeE9R2Vg@mail.gmail.com>

On Fri, May 11, 2012 at 9:46 AM, Mark Thornton <mthornton at optrak.com> wrote:

> On 11/05/12 04:03, Zhong Yu wrote:
>
>>
>> Yes thread-per-connection doesn't work, today. My question is, could
>> OS/VM do some optimization to make it work? Or there are reasons
>> prohibiting that?
>>
>>
> There have been VMs designed to run tens of thousands of threads even in a
> 32 bit system. One of the critical resources in a VM like HotSpot is the
> address reserved for each thread's stack. Typically this is 256K in a 32
> bit system. This clearly limits the number of threads you can have. I
> remember a VM which allocated much smaller stacks initially (8K perhaps)
> and then expanded the stack if it became full  (expensive, but hopefully
> rare). The rationale here was to permit the one thread per connection model
> to scale to very large numbers of connections


10s of thousands is still a low number though. We currently run ~2.5
million Actors per GB of heap.

Cheers,
?



>
>
> Mark Thornton
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/5c661bb2/attachment-0001.html>

From viktor.klang at gmail.com  Fri May 11 11:00:21 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 11 May 2012 17:00:21 +0200
Subject: [concurrency-interest] Quest for the optimal queue
Message-ID: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>

Hey guys,

I'd like to explore alternatives to ConcurrentLinkedQueue, especially to
get a bit lower latency and perhaps even lower mem usage.

Behavior:
No locks
Unbounded
Single consumer
Multiple producers

Operations:

dequeue
enqueue
numberOfMessages // Would be nice to have as a constant, can be linear or
simply not supported, doesn't really matter
hasMessages // Just a Boolean if there's anything in there at all, only
needs to return true if something has been put in that hasn't been pulled
out yet

Is there anything out there which is better than CLQ?

Cheers,
?

-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/54246ee1/attachment.html>

From nathan.reynolds at oracle.com  Fri May 11 13:55:46 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 11 May 2012 10:55:46 -0700
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
Message-ID: <4FAD52A2.50006@oracle.com>

I've heard of disruptor and they have some results comparing it against 
ArrayBlockingQueue.  
http://code.google.com/p/disruptor/wiki/PerformanceResults  I don't know 
how it would compare against ConcurrentLinkedQueue.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 5/11/2012 8:00 AM, ?iktor ?lang wrote:
> Hey guys,
>
> I'd like to explore alternatives to ConcurrentLinkedQueue, especially 
> to get a bit lower latency and perhaps even lower mem usage.
>
> Behavior:
> No locks
> Unbounded
> Single consumer
> Multiple producers
>
> Operations:
>
> dequeue
> enqueue
> numberOfMessages // Would be nice to have as a constant, can be linear 
> or simply not supported, doesn't really matter
> hasMessages // Just a Boolean if there's anything in there at all, 
> only needs to return true if something has been put in that hasn't 
> been pulled out yet
>
> Is there anything out there which is better than CLQ?
>
> Cheers,
> ?
>
> -- 
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/>- The software stack for 
> applications that scale
>
> Twitter: @viktorklang
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/55467e2e/attachment.html>

From joe.bowbeer at gmail.com  Fri May 11 15:06:58 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 11 May 2012 12:06:58 -0700
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <4FAD52A2.50006@oracle.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<4FAD52A2.50006@oracle.com>
Message-ID: <CAHzJPErCzbkw5bFLHYychZMTwbLM7ywPSYaAwbs4EbD2W3uTxA@mail.gmail.com>

Is disruptor strictly bounded or can it be applied in unbounded contexts?
On May 11, 2012 1:00 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

>  I've heard of disruptor and they have some results comparing it against
> ArrayBlockingQueue.
> http://code.google.com/p/disruptor/wiki/PerformanceResults  I don't know
> how it would compare against ConcurrentLinkedQueue.
>
>  Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 5/11/2012 8:00 AM, ?iktor ?lang wrote:
>
> Hey guys,
>
>  I'd like to explore alternatives to ConcurrentLinkedQueue, especially to
> get a bit lower latency and perhaps even lower mem usage.
>
>  Behavior:
> No locks
> Unbounded
> Single consumer
> Multiple producers
>
>  Operations:
>
>  dequeue
> enqueue
> numberOfMessages // Would be nice to have as a constant, can be linear or
> simply not supported, doesn't really matter
> hasMessages // Just a Boolean if there's anything in there at all, only
> needs to return true if something has been put in that hasn't been pulled
> out yet
>
>  Is there anything out there which is better than CLQ?
>
>  Cheers,
> ?
>
>  --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/77649095/attachment.html>

From viktor.klang at gmail.com  Fri May 11 15:20:00 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 11 May 2012 21:20:00 +0200
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <4FAD52A2.50006@oracle.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<4FAD52A2.50006@oracle.com>
Message-ID: <CANPzfU976ccNrz=kbXmv8nqJdwiCoHcwsy7vnvVpqrg4wpL1Ew@mail.gmail.com>

On Fri, May 11, 2012 at 7:55 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  I've heard of disruptor and they have some results comparing it against
> ArrayBlockingQueue.
> http://code.google.com/p/disruptor/wiki/PerformanceResults  I don't know
> how it would compare against ConcurrentLinkedQueue.
>

Their ring buffer is a no-go since it violates the unbounded constraint.
(and also the preallocation thing will be a big no no since I need to have
million of these).

Since I do not need any other operations than the ones I listed, I was sort
of thinking there might be some optimization opportunities that might be
applicable to improve upon the latency of the CLQ.

Cheers,
?


>
>
>  Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 5/11/2012 8:00 AM, ?iktor ?lang wrote:
>
> Hey guys,
>
>  I'd like to explore alternatives to ConcurrentLinkedQueue, especially to
> get a bit lower latency and perhaps even lower mem usage.
>
>  Behavior:
> No locks
> Unbounded
> Single consumer
> Multiple producers
>
>  Operations:
>
>  dequeue
> enqueue
> numberOfMessages // Would be nice to have as a constant, can be linear or
> simply not supported, doesn't really matter
> hasMessages // Just a Boolean if there's anything in there at all, only
> needs to return true if something has been put in that hasn't been pulled
> out yet
>
>  Is there anything out there which is better than CLQ?
>
>  Cheers,
> ?
>
>  --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/c8984bab/attachment.html>

From andrew at intelerad.com  Fri May 11 15:22:27 2012
From: andrew at intelerad.com (Andrew Trumper)
Date: Fri, 11 May 2012 15:22:27 -0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FAC9B5A.10005@8950aaa.com>
References: <4FAC9B5A.10005@8950aaa.com>
Message-ID: <4FAD66F3.1030006@intelerad.com>

Hi Glenn,

If I understand what you're asking for, we do that sort of thing fairly 
frequently at Intelerad, In our case it's more like

  interface StripedRunner {
       Object getKey(); // anything that can be used as a key in a map
       Runnable getRunnable();
  }

You'd need something like:

public class PerKeyExecutor {
   private final mMap<Object, Executor> mExecutors = new HashMap<>();
   private static final Executor mThreadCache =
       new ThreadPoolExecutor( 5, Integer.MAX_VALUE, 60L,
                               TimeUnit.SECONDS,
                             new SynchronousQueue<Runnable>() )

   public synchronized void execute( StripedRunner runnable ) {
     Executor executor = mExecutors.get( runnable.getKey() );
     if ( executor == null ) {
       mExecutors.put( runnble.getKey(), createExecutor() );
       executor = mExecutors.get( runnable.getKey() );
     }
     executor.execute( runnable.getRunnable() );
   }

   private Executor createExecutor() {
      /*
       * create a wrapper that bounds the number of
       * runnables executing at once to 1
       */
     return new BoundedExecutor( 1, mThreadCache );
   }

   // clean-up methods omitted
}

BoundedExcutor is a simple wrapper that limits the number of 
concurrently running tasks to some number. It doesn't allocate any 
threads itself (unless you want it to) but uses the "mThreadCache". It's 
great because it means your whole application can use one thread cache 
but you can create little thread pools all over the place and not worry 
about having a bunch of idle threads hanggin' around. We use this all 
the time in our product.

(Note, that Joe Bowbeer has mentioned a class called SerialExecutor that 
seems to do the same thing. ?)

BoundedExecutor is part of the nuggu library, BSD license:

<http://nuggu.svn.sourceforge.net/viewvc/nuggu/HEAD/src/com/intelerad/tools/lib/concurrent/BoundedExecutor.java?revision=10&view=markup>

It would be really great to improve this class and put it in a library 
someone's actually heard of :-P.

(In our product we sometimes use a second BoundedExecutor around the 
thread cache to limit the concurrency to the number of cores/processors.)

- Andrew

On 05/11/2012 12:53 AM, Glenn McGregor wrote:
> Hello all,
>
> I'm looking for a thread pool with the following characteristics... (in
> pseudo-code)
>
> interface StripedRunner {
>      Object getStripeClass();
>      void run();
> }
>
> magicPool.execute( stripedRunner );
>
> The idea being that any StripedRunners with the same stripeClass would
> get executed in the order they were queued,
> but StripedRunners with different stripedClasses could execute
> independently.
>
> Is there a way to configure the standard concurrent pools to work this
> way (doesn't seem to be), or a way to extends
> the current code?
>
> Or perhaps some third party library implementation?

-- 

This email or any attachments may contain confidential or legally 
privileged information intended for the sole use of the addressees. Any 
use, redistribution, disclosure, or reproduction of this information, 
except as intended, is prohibited. If you received this email in error, 
please notify the sender and remove all copies of the message, including 
any attachments.


From hans.boehm at hp.com  Fri May 11 16:14:05 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Fri, 11 May 2012 20:14:05 +0000
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CANPzfU8agqm7i1Qvga0cfy+Fm25wWYoRFLB55+fYsRZeE9R2Vg@mail.gmail.com>
References: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEGJJEAA.davidcholmes@aapt.net.au>
	<CACuKZqGhOMQFu5MeCBD4efJ3NJSHOYD=+7FkmuZh5TA7v7cnHQ@mail.gmail.com>
	<4FACC3EE.6050207@optrak.com>
	<CANPzfU8agqm7i1Qvga0cfy+Fm25wWYoRFLB55+fYsRZeE9R2Vg@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235551B62@G4W3299.americas.hpqcorp.net>

FWIW ?

Most modern (64 bit) Linux distributions seems to top out at about 30000 threads in their default configuration.  The running time for simple microbenchmarks seem to increase superlinearly with the number of threads created.  Thus there seem to be some weak evidence that this is not completely fixable simply by bumping up kernel parameters.  I don?t see a reason why JVM limits should be lower.  (The C++ committee is interested in closely related issues, which prompted me to experiment a little.)

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of viktor ?lang
Sent: Friday, May 11, 2012 7:55 AM
To: Mark Thornton
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] ForkJoinPool for async http calls?


On Fri, May 11, 2012 at 9:46 AM, Mark Thornton <mthornton at optrak.com<mailto:mthornton at optrak.com>> wrote:
On 11/05/12 04:03, Zhong Yu wrote:

Yes thread-per-connection doesn't work, today. My question is, could
OS/VM do some optimization to make it work? Or there are reasons
prohibiting that?

There have been VMs designed to run tens of thousands of threads even in a 32 bit system. One of the critical resources in a VM like HotSpot is the address reserved for each thread's stack. Typically this is 256K in a 32 bit system. This clearly limits the number of threads you can have. I remember a VM which allocated much smaller stacks initially (8K perhaps) and then expanded the stack if it became full  (expensive, but hopefully rare). The rationale here was to permit the one thread per connection model to scale to very large numbers of connections

10s of thousands is still a low number though. We currently run ~2.5 million Actors per GB of heap.

Cheers,
?




Mark Thornton


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



--
Viktor Klang

Akka Tech Lead
Typesafe<http://www.typesafe.com/> - The software stack for applications that scale

Twitter: @viktorklang

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/6d671739/attachment.html>

From martinrb at google.com  Fri May 11 22:18:29 2012
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 May 2012 19:18:29 -0700
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
Message-ID: <CA+kOe085oN-5R_kJA6_Xxx7DPfJ7VAqhRPHau8db5_JkaWZAnA@mail.gmail.com>

If you remove the ability to remove from the middle via iterator.remove and
only allow single-threaded dequeue, some of the code can be simplified, and
the consumer should be much more efficient.  But I don't see a footprint
reduction.  Copy CLQ and hack away.  Only the next pointers have to be
volatile.

Martin

On Fri, May 11, 2012 at 8:00 AM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Hey guys,
>
> I'd like to explore alternatives to ConcurrentLinkedQueue, especially to
> get a bit lower latency and perhaps even lower mem usage.
>
> Behavior:
> No locks
> Unbounded
> Single consumer
> Multiple producers
>
> Operations:
>
> dequeue
> enqueue
> numberOfMessages // Would be nice to have as a constant, can be linear or
> simply not supported, doesn't really matter
> hasMessages // Just a Boolean if there's anything in there at all, only
> needs to return true if something has been put in that hasn't been pulled
> out yet
>
> Is there anything out there which is better than CLQ?
>
> Cheers,
> ?
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120511/28fd28b3/attachment.html>

From viktor.klang at gmail.com  Sat May 12 06:09:48 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 12:09:48 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FAD66F3.1030006@intelerad.com>
References: <4FAC9B5A.10005@8950aaa.com>
	<4FAD66F3.1030006@intelerad.com>
Message-ID: <CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>

Here's an implementation I threw together (haven't been tested yet so YMMV)
that should make any Executor into a striped one, for every runnable that
is put in there which is Striped.

https://gist.github.com/2665603

Only locks that are involved should be the ones in ConcurrentHashMap,I
could opt for Scala's concurrent.TrieMap but wanted to stay 100% JDK for
this exercise.

Cheers,
?

On Fri, May 11, 2012 at 9:22 PM, Andrew Trumper <andrew at intelerad.com>wrote:

> Hi Glenn,
>
> If I understand what you're asking for, we do that sort of thing fairly
> frequently at Intelerad, In our case it's more like
>
>  interface StripedRunner {
>      Object getKey(); // anything that can be used as a key in a map
>      Runnable getRunnable();
>  }
>
> You'd need something like:
>
> public class PerKeyExecutor {
>  private final mMap<Object, Executor> mExecutors = new HashMap<>();
>  private static final Executor mThreadCache =
>      new ThreadPoolExecutor( 5, Integer.MAX_VALUE, 60L,
>                              TimeUnit.SECONDS,
>                            new SynchronousQueue<Runnable>() )
>
>  public synchronized void execute( StripedRunner runnable ) {
>    Executor executor = mExecutors.get( runnable.getKey() );
>    if ( executor == null ) {
>      mExecutors.put( runnble.getKey(), createExecutor() );
>      executor = mExecutors.get( runnable.getKey() );
>    }
>    executor.execute( runnable.getRunnable() );
>  }
>
>  private Executor createExecutor() {
>     /*
>      * create a wrapper that bounds the number of
>      * runnables executing at once to 1
>      */
>    return new BoundedExecutor( 1, mThreadCache );
>  }
>
>  // clean-up methods omitted
> }
>
> BoundedExcutor is a simple wrapper that limits the number of concurrently
> running tasks to some number. It doesn't allocate any threads itself
> (unless you want it to) but uses the "mThreadCache". It's great because it
> means your whole application can use one thread cache but you can create
> little thread pools all over the place and not worry about having a bunch
> of idle threads hanggin' around. We use this all the time in our product.
>
> (Note, that Joe Bowbeer has mentioned a class called SerialExecutor that
> seems to do the same thing. ?)
>
> BoundedExecutor is part of the nuggu library, BSD license:
>
> <http://nuggu.svn.sourceforge.**net/viewvc/nuggu/HEAD/src/com/**
> intelerad/tools/lib/**concurrent/BoundedExecutor.**
> java?revision=10&view=markup<http://nuggu.svn.sourceforge.net/viewvc/nuggu/HEAD/src/com/intelerad/tools/lib/concurrent/BoundedExecutor.java?revision=10&view=markup>
> >
>
> It would be really great to improve this class and put it in a library
> someone's actually heard of :-P.
>
> (In our product we sometimes use a second BoundedExecutor around the
> thread cache to limit the concurrency to the number of cores/processors.)
>
> - Andrew
>
>
> On 05/11/2012 12:53 AM, Glenn McGregor wrote:
>
>> Hello all,
>>
>> I'm looking for a thread pool with the following characteristics... (in
>> pseudo-code)
>>
>> interface StripedRunner {
>>     Object getStripeClass();
>>     void run();
>> }
>>
>> magicPool.execute( stripedRunner );
>>
>> The idea being that any StripedRunners with the same stripeClass would
>> get executed in the order they were queued,
>> but StripedRunners with different stripedClasses could execute
>> independently.
>>
>> Is there a way to configure the standard concurrent pools to work this
>> way (doesn't seem to be), or a way to extends
>> the current code?
>>
>> Or perhaps some third party library implementation?
>>
>
> --
>
> This email or any attachments may contain confidential or legally
> privileged information intended for the sole use of the addressees. Any
> use, redistribution, disclosure, or reproduction of this information,
> except as intended, is prohibited. If you received this email in error,
> please notify the sender and remove all copies of the message, including
> any attachments.
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/318ebe09/attachment-0001.html>

From dl at cs.oswego.edu  Sat May 12 06:49:21 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 12 May 2012 06:49:21 -0400
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
Message-ID: <4FAE4031.4060101@cs.oswego.edu>

On 05/11/12 11:00, ?iktor ?lang wrote:

> I'd like to explore alternatives to ConcurrentLinkedQueue, especially to get a
> bit lower latency and perhaps even lower mem usage.

LinkedTransferQueue is often a bit faster than ConcurrentLinkedQueue,
so you should give it a try.

> No locks, Unbounded, Single consumer, Multiple producers
>
> Operations:
> dequeue, enqueue, numberOfMessages, hasMessages

In general, we can do better than CLQ/LTQ only by weakening
some specs, including:

* Relaxing strict FIFO guarantees
* Specializing for a single producer, single consumer, or both.
* Relaxing guarantees about or not supporting blocking
* Not supporting some Collection operations (in particular, as
Martin noted, supporting arbitrary remove(element) forces
very noticeable overhead on unrelated operations.)

There are a number of good algorithms that make some of
these tradeoffs (flat-combining, multi-lane, Lamport etc),
including some used internally (like the fast task queues
used inside ForkJoin). We haven't put any in j.u.c. mainly
because they seem to fall outside of the scope of kinds of
components that should ship with JDK. We ought to consider
developing and releasing some in some other way.

-Doug




From viktor.klang at gmail.com  Sat May 12 07:26:46 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 13:26:46 +0200
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <4FAE4031.4060101@cs.oswego.edu>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<4FAE4031.4060101@cs.oswego.edu>
Message-ID: <CANPzfU8y+mTUOrpqOLZwbZukL4MSj1bCzmtjJ_B4R33o4_GgZA@mail.gmail.com>

On May 12, 2012 12:52 PM, "Doug Lea" <dl at cs.oswego.edu> wrote:
>
> On 05/11/12 11:00, ?iktor ?lang wrote:
>
>> I'd like to explore alternatives to ConcurrentLinkedQueue, especially to
get a
>> bit lower latency and perhaps even lower mem usage.
>
>
> LinkedTransferQueue is often a bit faster than ConcurrentLinkedQueue,
> so you should give it a try.
>
>> No locks, Unbounded, Single consumer, Multiple producers
>>
>> Operations:
>> dequeue, enqueue, numberOfMessages, hasMessages
>
>
> In general, we can do better than CLQ/LTQ only by weakening
> some specs, including:
>
> * Relaxing strict FIFO guarantees

I only need fifo per enqueuer

> * Specializing for a single producer, single consumer, or both.

Check

> * Relaxing guarantees about or not supporting blocking

No blocking is preferrable

> * Not supporting some Collection operations (in particular, as
> Martin noted, supporting arbitrary remove(element) forces
> very noticeable overhead on unrelated operations.)

Check

>
> There are a number of good algorithms that make some of
> these tradeoffs (flat-combining, multi-lane, Lamport etc),
> including some used internally (like the fast task queues
> used inside ForkJoin). We haven't put any in j.u.c. mainly
> because they seem to fall outside of the scope of kinds of
> components that should ship with JDK. We ought to consider
> developing and releasing some in some other way.

Sounds great, I'd help out.

Cheers,
V

>
> -Doug
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/77ac66ff/attachment.html>

From aleksey.shipilev at gmail.com  Sat May 12 07:55:14 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Sat, 12 May 2012 15:55:14 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
Message-ID: <CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>

On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> Here's an implementation I threw together (haven't been tested yet so YMMV)
> that should make any Executor into a striped one, for every runnable that is
> put in there which is Striped.
>
> https://gist.github.com/2665603

Neat trick, but it is prone to memory leaks. You will have to protect
yourself from multiple stripe classes come and go, that is, there is a
garbage buildup in $stripes map, if some stripes are not being used
(from some point, forever). Getting that right in race-free manner is
tough.

-Aleksey.


From viktor.klang at gmail.com  Sat May 12 08:35:46 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 14:35:46 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
Message-ID: <CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>

It'll only be an issue if you have arbitrary stripes. Fixing that is a
great exercise to the reader!

Cheers,
V
On May 12, 2012 1:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
wrote:

> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> > Here's an implementation I threw together (haven't been tested yet so
> YMMV)
> > that should make any Executor into a striped one, for every runnable
> that is
> > put in there which is Striped.
> >
> > https://gist.github.com/2665603
>
> Neat trick, but it is prone to memory leaks. You will have to protect
> yourself from multiple stripe classes come and go, that is, there is a
> garbage buildup in $stripes map, if some stripes are not being used
> (from some point, forever). Getting that right in race-free manner is
> tough.
>
> -Aleksey.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/5db7a1e5/attachment.html>

From aleksey.shipilev at gmail.com  Sat May 12 08:47:01 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Sat, 12 May 2012 16:47:01 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
Message-ID: <CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>

You seem to have pretty generic approach for making arbitrary executor
look like striped one. I would be naturally to assume the number of
stripes is arbitrary as well. ;) The race-free purges in these
MultiMap-like cases is rather hard for inexperienced concurrency guys;
much harder than writing the baseline map-queue-based implementation.
That's why I think suggesting the baseline map-queue-based
implementation and asking to fit purges there is like selling someone
the house with a minefield in the yard.

-Aleksey.

On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> It'll only be an issue if you have arbitrary stripes. Fixing that is a great
> exercise to the reader!
>
> Cheers,
> V
>
> On May 12, 2012 1:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
> wrote:
>>
>> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> wrote:
>> > Here's an implementation I threw together (haven't been tested yet so
>> > YMMV)
>> > that should make any Executor into a striped one, for every runnable
>> > that is
>> > put in there which is Striped.
>> >
>> > https://gist.github.com/2665603
>>
>> Neat trick, but it is prone to memory leaks. You will have to protect
>> yourself from multiple stripe classes come and go, that is, there is a
>> garbage buildup in $stripes map, if some stripes are not being used
>> (from some point, forever). Getting that right in race-free manner is
>> tough.
>>
>> -Aleksey.


From viktor.klang at gmail.com  Sat May 12 08:58:58 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 14:58:58 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
Message-ID: <CANPzfU-iwLvaxeeXJ+XzPodBWcoko-XR0ViRFgGYtB-3h8cmfQ@mail.gmail.com>

It's a very valuable exercise!

Cheers,
V
On May 12, 2012 2:47 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
wrote:

> You seem to have pretty generic approach for making arbitrary executor
> look like striped one. I would be naturally to assume the number of
> stripes is arbitrary as well. ;) The race-free purges in these
> MultiMap-like cases is rather hard for inexperienced concurrency guys;
> much harder than writing the baseline map-queue-based implementation.
> That's why I think suggesting the baseline map-queue-based
> implementation and asking to fit purges there is like selling someone
> the house with a minefield in the yard.
>
> -Aleksey.
>
> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> > It'll only be an issue if you have arbitrary stripes. Fixing that is a
> great
> > exercise to the reader!
> >
> > Cheers,
> > V
> >
> > On May 12, 2012 1:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
> > wrote:
> >>
> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >> wrote:
> >> > Here's an implementation I threw together (haven't been tested yet so
> >> > YMMV)
> >> > that should make any Executor into a striped one, for every runnable
> >> > that is
> >> > put in there which is Striped.
> >> >
> >> > https://gist.github.com/2665603
> >>
> >> Neat trick, but it is prone to memory leaks. You will have to protect
> >> yourself from multiple stripe classes come and go, that is, there is a
> >> garbage buildup in $stripes map, if some stripes are not being used
> >> (from some point, forever). Getting that right in race-free manner is
> >> tough.
> >>
> >> -Aleksey.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/d8e2f11a/attachment.html>

From viktor.klang at gmail.com  Sat May 12 09:23:15 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 15:23:15 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
Message-ID: <CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>

On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev <
aleksey.shipilev at gmail.com> wrote:

> You seem to have pretty generic approach for making arbitrary executor
> look like striped one. I would be naturally to assume the number of
> stripes is arbitrary as well. ;) The race-free purges in these
> MultiMap-like cases is rather hard for inexperienced concurrency guys;
> much harder than writing the baseline map-queue-based implementation.
> That's why I think suggesting the baseline map-queue-based
> implementation and asking to fit purges there is like selling someone
> the house with a minefield in the yard.
>
>
Shared mutable state concurrency IS a minefield. If you operate at that
level you need to learn how to disarm mines.
That's why I prefer to offer people things like composable futures and
actors instead of shared mutable state concurrency.

Cheers,
?


> -Aleksey.
>
> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> > It'll only be an issue if you have arbitrary stripes. Fixing that is a
> great
> > exercise to the reader!
> >
> > Cheers,
> > V
> >
> > On May 12, 2012 1:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
> > wrote:
> >>
> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >> wrote:
> >> > Here's an implementation I threw together (haven't been tested yet so
> >> > YMMV)
> >> > that should make any Executor into a striped one, for every runnable
> >> > that is
> >> > put in there which is Striped.
> >> >
> >> > https://gist.github.com/2665603
> >>
> >> Neat trick, but it is prone to memory leaks. You will have to protect
> >> yourself from multiple stripe classes come and go, that is, there is a
> >> garbage buildup in $stripes map, if some stripes are not being used
> >> (from some point, forever). Getting that right in race-free manner is
> >> tough.
> >>
> >> -Aleksey.
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/6fb8ea54/attachment-0001.html>

From viktor.klang at gmail.com  Sat May 12 10:05:28 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 16:05:28 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
Message-ID: <CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>

Also, if you know when a stripe won't be used anymore, you can simply
disassociate the stripe, and it will finish the tasks it was scheduled to
run prior to becoming garbage collected.

On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

>
>
> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev <
> aleksey.shipilev at gmail.com> wrote:
>
>> You seem to have pretty generic approach for making arbitrary executor
>> look like striped one. I would be naturally to assume the number of
>> stripes is arbitrary as well. ;) The race-free purges in these
>> MultiMap-like cases is rather hard for inexperienced concurrency guys;
>> much harder than writing the baseline map-queue-based implementation.
>> That's why I think suggesting the baseline map-queue-based
>> implementation and asking to fit purges there is like selling someone
>> the house with a minefield in the yard.
>>
>>
> Shared mutable state concurrency IS a minefield. If you operate at that
> level you need to learn how to disarm mines.
> That's why I prefer to offer people things like composable futures and
> actors instead of shared mutable state concurrency.
>
> Cheers,
> ?
>
>
>>  -Aleksey.
>>
>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> wrote:
>> > It'll only be an issue if you have arbitrary stripes. Fixing that is a
>> great
>> > exercise to the reader!
>> >
>> > Cheers,
>> > V
>> >
>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com
>> >
>> > wrote:
>> >>
>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> >> wrote:
>> >> > Here's an implementation I threw together (haven't been tested yet so
>> >> > YMMV)
>> >> > that should make any Executor into a striped one, for every runnable
>> >> > that is
>> >> > put in there which is Striped.
>> >> >
>> >> > https://gist.github.com/2665603
>> >>
>> >> Neat trick, but it is prone to memory leaks. You will have to protect
>> >> yourself from multiple stripe classes come and go, that is, there is a
>> >> garbage buildup in $stripes map, if some stripes are not being used
>> >> (from some point, forever). Getting that right in race-free manner is
>> >> tough.
>> >>
>> >> -Aleksey.
>>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/6258031f/attachment.html>

From dl at cs.oswego.edu  Sat May 12 10:39:44 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 12 May 2012 10:39:44 -0400
Subject: [concurrency-interest] ForkJoinPool for async http calls?
In-Reply-To: <CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
References: <CADoyxFy78OYm9wse4db_DWCGtieGOEmVjRNsxNQ3Nk93toipzw@mail.gmail.com>	<CANPzfU-8WBXkDxiVj3KV6Wr1nakkt-_SiJ1zYAxejMPKorvtVA@mail.gmail.com>	<CADoyxFzWuZ3kTfmTNL85WGZ4BZ0_io3SWOCrujK4q2SyJ5J2_Q@mail.gmail.com>	<CACuKZqGzWEB7-76f6QRJv6XRMP9CyTjpKMQk9Qr6QxpCHW+pbg@mail.gmail.com>	<CADoyxFwrv1OV10H-Fg7GG0XYHDGRxG+O0M=HPqu+J_pu-Pn=WQ@mail.gmail.com>	<CACuKZqFe9RSzJaqs5Bk1oMN3aExFqKbsZ6aE0Z_Y5Xz5758PRA@mail.gmail.com>	<CANPzfU_A6H54UGCpUFSnR=xLtKrQBgahAqOZqgmcaULDaOD_zQ@mail.gmail.com>	<CACuKZqGeiDO8v5p_We5hh931APYB7p7TvpMohKqPrB+yOEMpog@mail.gmail.com>	<D900FDC0-9194-4490-B67A-EB6A8DE65D10@rkuhn.info>
	<CACuKZqE53bQ7ENGFPRahgr=jGqj-A-6vcXWP3SREXDhmu1iO6Q@mail.gmail.com>
Message-ID: <4FAE7630.1060504@cs.oswego.edu>

Trying to summarize...

On 05/10/12 16:52, Zhong Yu wrote:
> while that is super cool, it is not as simple and elegant as thread:)
>
> the reason we do these async stuff is because threads are "expensive".
> but why are threads expensive?
>

Ultimately, it is a matter of resource management.
If you'd like a lot of something, then that something ought
to be cheap to create, manage, and reclaim.
The full java.lang.Thread API is intrinsically not
all that cheap (similarly for OS-level pthreads etc).
But if you'd like something that maintains much of the
elegance of a thread but is cheap enough so that you
can usually have as many as you like without having
to make other design trade-offs, then we can help.
Hence: ForkJoinTasks, scala/akka actors, composible
completions, and so on.

All things considered, the more such components and
abstractions available that turn out to be helpful
(well, except not *too* many of them), the less people will
miss not using java.lang.Thread.

-Doug



From viktor.klang at gmail.com  Sat May 12 12:39:49 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 18:39:49 +0200
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
Message-ID: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>

Hey,

How about this for inclusion in JDK8?

/**
 * The RejectedExecutionHandler used by Akka, it improves on
CallerRunsPolicy
 * by throwing a RejectedExecutionException if the executor isShutdown.
 * (CallerRunsPolicy silently discards the runnable in this case, which is
arguably broken)
 */
class CallerRunsOrRejects extends RejectedExecutionHandler {
  def rejectedExecution(runnable: Runnable, threadPoolExecutor:
ThreadPoolExecutor): Unit = {
    if (threadPoolExecutor.isShutdown) throw new
RejectedExecutionException("Shutdown")
    else runnable.run()
  }
}

Cheers,
?

-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/43107923/attachment.html>

From viktor.klang at gmail.com  Sat May 12 12:43:33 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 18:43:33 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
Message-ID: <CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>

And removing the ExecutionStripe as soon as it's done with existing
runnables might be a bad idea, and as soon as you involve a temporal aspect
like, fade to black after 10 seconds of idleness, you need to have a timer
running. An alternative is to try out Weak/Soft references, but that ain't
a walk in the park either...

I apologize for the monologue, carry on....

Cheers,
?

On Sat, May 12, 2012 at 4:05 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Also, if you know when a stripe won't be used anymore, you can simply
> disassociate the stripe, and it will finish the tasks it was scheduled to
> run prior to becoming garbage collected.
>
>
> On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>>
>>
>> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev <
>> aleksey.shipilev at gmail.com> wrote:
>>
>>> You seem to have pretty generic approach for making arbitrary executor
>>> look like striped one. I would be naturally to assume the number of
>>> stripes is arbitrary as well. ;) The race-free purges in these
>>> MultiMap-like cases is rather hard for inexperienced concurrency guys;
>>> much harder than writing the baseline map-queue-based implementation.
>>> That's why I think suggesting the baseline map-queue-based
>>> implementation and asking to fit purges there is like selling someone
>>> the house with a minefield in the yard.
>>>
>>>
>> Shared mutable state concurrency IS a minefield. If you operate at that
>> level you need to learn how to disarm mines.
>> That's why I prefer to offer people things like composable futures and
>> actors instead of shared mutable state concurrency.
>>
>> Cheers,
>> ?
>>
>>
>>>  -Aleksey.
>>>
>>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com>
>>> wrote:
>>> > It'll only be an issue if you have arbitrary stripes. Fixing that is a
>>> great
>>> > exercise to the reader!
>>> >
>>> > Cheers,
>>> > V
>>> >
>>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev" <
>>> aleksey.shipilev at gmail.com>
>>> > wrote:
>>> >>
>>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang <viktor.klang at gmail.com
>>> >
>>> >> wrote:
>>> >> > Here's an implementation I threw together (haven't been tested yet
>>> so
>>> >> > YMMV)
>>> >> > that should make any Executor into a striped one, for every runnable
>>> >> > that is
>>> >> > put in there which is Striped.
>>> >> >
>>> >> > https://gist.github.com/2665603
>>> >>
>>> >> Neat trick, but it is prone to memory leaks. You will have to protect
>>> >> yourself from multiple stripe classes come and go, that is, there is a
>>> >> garbage buildup in $stripes map, if some stripes are not being used
>>> >> (from some point, forever). Getting that right in race-free manner is
>>> >> tough.
>>> >>
>>> >> -Aleksey.
>>>
>>
>>
>>
>> --
>> Viktor Klang
>>
>> Akka Tech Lead
>> Typesafe <http://www.typesafe.com/> - The software stack for
>> applications that scale
>>
>> Twitter: @viktorklang
>>
>>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/d615080c/attachment.html>

From aleksey.shipilev at gmail.com  Sat May 12 12:48:29 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Sat, 12 May 2012 20:48:29 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
Message-ID: <CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>

Yes, that is why I have general issue with solving this problem with
map-queue designs. Why would one mess with shared state, instantiate
queues per striped object, when tasks can just be multiplexed over
single-threaded executors? OP did not forced the constraint for the
tasks to be executed in a batch, there's only the constraint for
same-class tasks to be executed in order. That is why I believe
stateless design is better: it is much more fool-proof and as
efficient. Is there something I miss there?

-Aleksey.

On Sat, May 12, 2012 at 8:43 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> And removing the ExecutionStripe as soon as it's done with existing
> runnables might be a bad idea, and as soon as you involve a temporal aspect
> like, fade to black after 10 seconds of idleness, you need to have a timer
> running. An alternative is to try out Weak/Soft references, but that ain't a
> walk in the park either...
>
> I apologize for the monologue, carry on....
>
> Cheers,
> ?
>
>
> On Sat, May 12, 2012 at 4:05 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
>>
>> Also, if you know when a stripe won't be used anymore, you can simply
>> disassociate the stripe, and it will finish the tasks it was scheduled to
>> run prior to becoming garbage collected.
>>
>>
>> On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> wrote:
>>>
>>>
>>>
>>> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev
>>> <aleksey.shipilev at gmail.com> wrote:
>>>>
>>>> You seem to have pretty generic approach for making arbitrary executor
>>>> look like striped one. I would be naturally to assume the number of
>>>> stripes is arbitrary as well. ;) The race-free purges in these
>>>> MultiMap-like cases is rather hard for inexperienced concurrency guys;
>>>> much harder than writing the baseline map-queue-based implementation.
>>>> That's why I think suggesting the baseline map-queue-based
>>>> implementation and asking to fit purges there is like selling someone
>>>> the house with a minefield in the yard.
>>>>
>>>
>>> Shared mutable state concurrency IS a minefield. If you operate at that
>>> level you need to learn how to disarm mines.
>>> That's why I prefer to offer people things like composable futures and
>>> actors instead of shared mutable state concurrency.
>>>
>>> Cheers,
>>> ?
>>>
>>>>
>>>> -Aleksey.
>>>>
>>>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com>
>>>> wrote:
>>>> > It'll only be an issue if you have arbitrary stripes. Fixing that is a
>>>> > great
>>>> > exercise to the reader!
>>>> >
>>>> > Cheers,
>>>> > V
>>>> >
>>>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev"
>>>> > <aleksey.shipilev at gmail.com>
>>>> > wrote:
>>>> >>
>>>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang
>>>> >> <viktor.klang at gmail.com>
>>>> >> wrote:
>>>> >> > Here's an implementation I threw together (haven't been tested yet
>>>> >> > so
>>>> >> > YMMV)
>>>> >> > that should make any Executor into a striped one, for every
>>>> >> > runnable
>>>> >> > that is
>>>> >> > put in there which is Striped.
>>>> >> >
>>>> >> > https://gist.github.com/2665603
>>>> >>
>>>> >> Neat trick, but it is prone to memory leaks. You will have to protect
>>>> >> yourself from multiple stripe classes come and go, that is, there is
>>>> >> a
>>>> >> garbage buildup in $stripes map, if some stripes are not being used
>>>> >> (from some point, forever). Getting that right in race-free manner is
>>>> >> tough.
>>>> >>
>>>> >> -Aleksey.
>>>
>>>
>>>
>>>
>>> --
>>> Viktor Klang
>>>
>>> Akka Tech Lead
>>> Typesafe?- The software stack for applications that scale
>>>
>>> Twitter: @viktorklang
>>>
>>
>>
>>
>> --
>> Viktor Klang
>>
>> Akka Tech Lead
>> Typesafe?- The software stack for applications that scale
>>
>> Twitter: @viktorklang
>>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe?- The software stack for applications that scale
>
> Twitter: @viktorklang
>


From viktor.klang at gmail.com  Sat May 12 12:53:43 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 18:53:43 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
Message-ID: <CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>

On Sat, May 12, 2012 at 6:48 PM, Aleksey Shipilev <
aleksey.shipilev at gmail.com> wrote:

> Yes, that is why I have general issue with solving this problem with
> map-queue designs. Why would one mess with shared state, instantiate
> queues per striped object, when tasks can just be multiplexed over
> single-threaded executors? OP did not forced the constraint for the
> tasks to be executed in a batch, there's only the constraint for
> same-class tasks to be executed in order. That is why I believe
> stateless design is better: it is much more fool-proof and as
> efficient. Is there something I miss there?
>

A consistent-hashing approach as you described is a good one as well, the
problem is that when the stripes are unevenly distributed you end up with a
single threaded program.

Cheers,
?


>
> -Aleksey.
>
> On Sat, May 12, 2012 at 8:43 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> > And removing the ExecutionStripe as soon as it's done with existing
> > runnables might be a bad idea, and as soon as you involve a temporal
> aspect
> > like, fade to black after 10 seconds of idleness, you need to have a
> timer
> > running. An alternative is to try out Weak/Soft references, but that
> ain't a
> > walk in the park either...
> >
> > I apologize for the monologue, carry on....
> >
> > Cheers,
> > ?
> >
> >
> > On Sat, May 12, 2012 at 4:05 PM, ?iktor ?lang <viktor.klang at gmail.com>
> > wrote:
> >>
> >> Also, if you know when a stripe won't be used anymore, you can simply
> >> disassociate the stripe, and it will finish the tasks it was scheduled
> to
> >> run prior to becoming garbage collected.
> >>
> >>
> >> On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >> wrote:
> >>>
> >>>
> >>>
> >>> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev
> >>> <aleksey.shipilev at gmail.com> wrote:
> >>>>
> >>>> You seem to have pretty generic approach for making arbitrary executor
> >>>> look like striped one. I would be naturally to assume the number of
> >>>> stripes is arbitrary as well. ;) The race-free purges in these
> >>>> MultiMap-like cases is rather hard for inexperienced concurrency guys;
> >>>> much harder than writing the baseline map-queue-based implementation.
> >>>> That's why I think suggesting the baseline map-queue-based
> >>>> implementation and asking to fit purges there is like selling someone
> >>>> the house with a minefield in the yard.
> >>>>
> >>>
> >>> Shared mutable state concurrency IS a minefield. If you operate at that
> >>> level you need to learn how to disarm mines.
> >>> That's why I prefer to offer people things like composable futures and
> >>> actors instead of shared mutable state concurrency.
> >>>
> >>> Cheers,
> >>> ?
> >>>
> >>>>
> >>>> -Aleksey.
> >>>>
> >>>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com
> >
> >>>> wrote:
> >>>> > It'll only be an issue if you have arbitrary stripes. Fixing that
> is a
> >>>> > great
> >>>> > exercise to the reader!
> >>>> >
> >>>> > Cheers,
> >>>> > V
> >>>> >
> >>>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev"
> >>>> > <aleksey.shipilev at gmail.com>
> >>>> > wrote:
> >>>> >>
> >>>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang
> >>>> >> <viktor.klang at gmail.com>
> >>>> >> wrote:
> >>>> >> > Here's an implementation I threw together (haven't been tested
> yet
> >>>> >> > so
> >>>> >> > YMMV)
> >>>> >> > that should make any Executor into a striped one, for every
> >>>> >> > runnable
> >>>> >> > that is
> >>>> >> > put in there which is Striped.
> >>>> >> >
> >>>> >> > https://gist.github.com/2665603
> >>>> >>
> >>>> >> Neat trick, but it is prone to memory leaks. You will have to
> protect
> >>>> >> yourself from multiple stripe classes come and go, that is, there
> is
> >>>> >> a
> >>>> >> garbage buildup in $stripes map, if some stripes are not being used
> >>>> >> (from some point, forever). Getting that right in race-free manner
> is
> >>>> >> tough.
> >>>> >>
> >>>> >> -Aleksey.
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>> Viktor Klang
> >>>
> >>> Akka Tech Lead
> >>> Typesafe - The software stack for applications that scale
> >>>
> >>> Twitter: @viktorklang
> >>>
> >>
> >>
> >>
> >> --
> >> Viktor Klang
> >>
> >> Akka Tech Lead
> >> Typesafe - The software stack for applications that scale
> >>
> >> Twitter: @viktorklang
> >>
> >
> >
> >
> > --
> > Viktor Klang
> >
> > Akka Tech Lead
> > Typesafe - The software stack for applications that scale
> >
> > Twitter: @viktorklang
> >
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/3c99dc10/attachment-0001.html>

From viktor.klang at gmail.com  Sat May 12 12:58:55 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 18:58:55 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
Message-ID: <CANPzfU_AEhmrB2KhAPKxBjdNiuJaSs=Kv5Ws=ji_aZEt5viqrg@mail.gmail.com>

Also worth mentioning is that the map-queue approach does not need to do
batch-execution, I only added that because it was trivial and usually gives
better performance as it removes pressure from the submission queue of the
"real" Executor.

Cheers,
?

On Sat, May 12, 2012 at 6:53 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

>
>
> On Sat, May 12, 2012 at 6:48 PM, Aleksey Shipilev <
> aleksey.shipilev at gmail.com> wrote:
>
>> Yes, that is why I have general issue with solving this problem with
>> map-queue designs. Why would one mess with shared state, instantiate
>> queues per striped object, when tasks can just be multiplexed over
>> single-threaded executors? OP did not forced the constraint for the
>> tasks to be executed in a batch, there's only the constraint for
>> same-class tasks to be executed in order. That is why I believe
>> stateless design is better: it is much more fool-proof and as
>> efficient. Is there something I miss there?
>>
>
> A consistent-hashing approach as you described is a good one as well, the
> problem is that when the stripes are unevenly distributed you end up with a
> single threaded program.
>
> Cheers,
> ?
>
>
>>
>> -Aleksey.
>>
>> On Sat, May 12, 2012 at 8:43 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> wrote:
>> > And removing the ExecutionStripe as soon as it's done with existing
>> > runnables might be a bad idea, and as soon as you involve a temporal
>> aspect
>> > like, fade to black after 10 seconds of idleness, you need to have a
>> timer
>> > running. An alternative is to try out Weak/Soft references, but that
>> ain't a
>> > walk in the park either...
>> >
>> > I apologize for the monologue, carry on....
>> >
>> > Cheers,
>> > ?
>> >
>> >
>> > On Sat, May 12, 2012 at 4:05 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> > wrote:
>> >>
>> >> Also, if you know when a stripe won't be used anymore, you can simply
>> >> disassociate the stripe, and it will finish the tasks it was scheduled
>> to
>> >> run prior to becoming garbage collected.
>> >>
>> >>
>> >> On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> >> wrote:
>> >>>
>> >>>
>> >>>
>> >>> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev
>> >>> <aleksey.shipilev at gmail.com> wrote:
>> >>>>
>> >>>> You seem to have pretty generic approach for making arbitrary
>> executor
>> >>>> look like striped one. I would be naturally to assume the number of
>> >>>> stripes is arbitrary as well. ;) The race-free purges in these
>> >>>> MultiMap-like cases is rather hard for inexperienced concurrency
>> guys;
>> >>>> much harder than writing the baseline map-queue-based implementation.
>> >>>> That's why I think suggesting the baseline map-queue-based
>> >>>> implementation and asking to fit purges there is like selling someone
>> >>>> the house with a minefield in the yard.
>> >>>>
>> >>>
>> >>> Shared mutable state concurrency IS a minefield. If you operate at
>> that
>> >>> level you need to learn how to disarm mines.
>> >>> That's why I prefer to offer people things like composable futures and
>> >>> actors instead of shared mutable state concurrency.
>> >>>
>> >>> Cheers,
>> >>> ?
>> >>>
>> >>>>
>> >>>> -Aleksey.
>> >>>>
>> >>>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <
>> viktor.klang at gmail.com>
>> >>>> wrote:
>> >>>> > It'll only be an issue if you have arbitrary stripes. Fixing that
>> is a
>> >>>> > great
>> >>>> > exercise to the reader!
>> >>>> >
>> >>>> > Cheers,
>> >>>> > V
>> >>>> >
>> >>>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev"
>> >>>> > <aleksey.shipilev at gmail.com>
>> >>>> > wrote:
>> >>>> >>
>> >>>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang
>> >>>> >> <viktor.klang at gmail.com>
>> >>>> >> wrote:
>> >>>> >> > Here's an implementation I threw together (haven't been tested
>> yet
>> >>>> >> > so
>> >>>> >> > YMMV)
>> >>>> >> > that should make any Executor into a striped one, for every
>> >>>> >> > runnable
>> >>>> >> > that is
>> >>>> >> > put in there which is Striped.
>> >>>> >> >
>> >>>> >> > https://gist.github.com/2665603
>> >>>> >>
>> >>>> >> Neat trick, but it is prone to memory leaks. You will have to
>> protect
>> >>>> >> yourself from multiple stripe classes come and go, that is, there
>> is
>> >>>> >> a
>> >>>> >> garbage buildup in $stripes map, if some stripes are not being
>> used
>> >>>> >> (from some point, forever). Getting that right in race-free
>> manner is
>> >>>> >> tough.
>> >>>> >>
>> >>>> >> -Aleksey.
>> >>>
>> >>>
>> >>>
>> >>>
>> >>> --
>> >>> Viktor Klang
>> >>>
>> >>> Akka Tech Lead
>> >>> Typesafe - The software stack for applications that scale
>> >>>
>> >>> Twitter: @viktorklang
>> >>>
>> >>
>> >>
>> >>
>> >> --
>> >> Viktor Klang
>> >>
>> >> Akka Tech Lead
>> >> Typesafe - The software stack for applications that scale
>> >>
>> >> Twitter: @viktorklang
>> >>
>> >
>> >
>> >
>> > --
>> > Viktor Klang
>> >
>> > Akka Tech Lead
>> > Typesafe - The software stack for applications that scale
>> >
>> > Twitter: @viktorklang
>> >
>>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/f0f577ba/attachment.html>

From aleksey.shipilev at gmail.com  Sat May 12 12:59:56 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Sat, 12 May 2012 20:59:56 +0400
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
In-Reply-To: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
References: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
Message-ID: <CA+1LWGHTsWjX3wTTseE9iSy--CP=uPorXfP58UbPP5Gc=Q73fA@mail.gmail.com>

On Sat, May 12, 2012 at 8:39 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> How about this for inclusion in JDK8?

+1

I also sometimes miss CallerBlocks policy, which:
  - throws RejectedExecutionException when pool is shutting down
  - blocks until executor accepts the task, and returns after successful submit

This is helpful when I specifically don't want submitter to execute
tasks slated to be executed in the threadpool (i.e. CallerRuns is not
something I want). It was especially problematic when the task at hand
is rather heavy, and by the time submitter is done executing the task,
threadpool is had been long idle already, because submitter is, well,
blocked.

-Aleksey.


From viktor.klang at gmail.com  Sat May 12 13:05:35 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 19:05:35 +0200
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
In-Reply-To: <CA+1LWGHTsWjX3wTTseE9iSy--CP=uPorXfP58UbPP5Gc=Q73fA@mail.gmail.com>
References: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
	<CA+1LWGHTsWjX3wTTseE9iSy--CP=uPorXfP58UbPP5Gc=Q73fA@mail.gmail.com>
Message-ID: <CANPzfU89mCbixXX6UUMWexWn12bhFCXoSsn-rswtr+DgO7cTVA@mail.gmail.com>

On Sat, May 12, 2012 at 6:59 PM, Aleksey Shipilev <
aleksey.shipilev at gmail.com> wrote:

> On Sat, May 12, 2012 at 8:39 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> > How about this for inclusion in JDK8?
>
> +1
>
> I also sometimes miss CallerBlocks policy, which:
>  - throws RejectedExecutionException when pool is shutting down
>  - blocks until executor accepts the task, and returns after successful
> submit
>
> This is helpful when I specifically don't want submitter to execute
> tasks slated to be executed in the threadpool (i.e. CallerRuns is not
> something I want). It was especially problematic when the task at hand
> is rather heavy, and by the time submitter is done executing the task,
> threadpool is had been long idle already, because submitter is, well,
> blocked.
>

Yup, in my experience, I don't see any situation where you'd like
CallerRunsPolicy, as it just silently drops tasks when TPE isShutdown.

As a sidenote, it'd be nice to have an AsyncExecutor, which is never
allowed to do caller-runs at all. Some code might rely on the block not
being executed on submission.

Cheers,
?


>
> -Aleksey.
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/99edfa17/attachment.html>

From aleksey.shipilev at gmail.com  Sat May 12 13:39:32 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Sat, 12 May 2012 21:39:32 +0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
Message-ID: <CA+1LWGGr6Rr+tvYtCnKsjnWCmho3UmkCZXr8+93OsboWqtSdRA@mail.gmail.com>

On Sat, May 12, 2012 at 8:53 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>
>
> On Sat, May 12, 2012 at 6:48 PM, Aleksey Shipilev
> <aleksey.shipilev at gmail.com> wrote:
>>
>> Yes, that is why I have general issue with solving this problem with
>> map-queue designs. Why would one mess with shared state, instantiate
>> queues per striped object, when tasks can just be multiplexed over
>> single-threaded executors? OP did not forced the constraint for the
>> tasks to be executed in a batch, there's only the constraint for
>> same-class tasks to be executed in order. That is why I believe
>> stateless design is better: it is much more fool-proof and as
>> efficient. Is there something I miss there?
>
>
> A consistent-hashing approach as you described is a good one as well, the
> problem is that when the stripes are unevenly distributed you end up with a
> single threaded program.

Granted, I am from "thou shalt have a good hashcode" camp.

In the other case, when stripes are unevenly distributed, e.g. lots of
tasks from single class dominate the execution, map-queue design is
effectively serial as well. That's not the fault of the
implementations in both cases, it is the task stream itself does not
expose enough parallelism. One could do quick back-envelope
calculation on maximum parallelism available in incoming stream, as
well as by how far both designs can capitalize on that. I'd speculate
map-queue design would run at optimal; while hashing design would be
negligibly slower than optimal.

> Also worth mentioning is that the map-queue approach does not need to do batch-execution, I only added that because it was trivial and usually gives better performance as it removes pressure from the submission queue of the "real" Executor.

Yup, I can see that. Neat trick. That trades off stricter inter-class
FIFO a bit, but that should be the fair price for performance
advantages of batching.

-Aleksey.


From viktor.klang at gmail.com  Sat May 12 14:29:07 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 20:29:07 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CA+1LWGGr6Rr+tvYtCnKsjnWCmho3UmkCZXr8+93OsboWqtSdRA@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
	<CA+1LWGGr6Rr+tvYtCnKsjnWCmho3UmkCZXr8+93OsboWqtSdRA@mail.gmail.com>
Message-ID: <CANPzfU-sbMdvzRorcgV1OX9=EBKTiLd3QqAw0=XZSC1xuavuZg@mail.gmail.com>

On Sat, May 12, 2012 at 7:39 PM, Aleksey Shipilev <
aleksey.shipilev at gmail.com> wrote:

> On Sat, May 12, 2012 at 8:53 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> >
> >
> > On Sat, May 12, 2012 at 6:48 PM, Aleksey Shipilev
> > <aleksey.shipilev at gmail.com> wrote:
> >>
> >> Yes, that is why I have general issue with solving this problem with
> >> map-queue designs. Why would one mess with shared state, instantiate
> >> queues per striped object, when tasks can just be multiplexed over
> >> single-threaded executors? OP did not forced the constraint for the
> >> tasks to be executed in a batch, there's only the constraint for
> >> same-class tasks to be executed in order. That is why I believe
> >> stateless design is better: it is much more fool-proof and as
> >> efficient. Is there something I miss there?
> >
> >
> > A consistent-hashing approach as you described is a good one as well, the
> > problem is that when the stripes are unevenly distributed you end up
> with a
> > single threaded program.
>
> Granted, I am from "thou shalt have a good hashcode" camp.
>
> In the other case, when stripes are unevenly distributed, e.g. lots of
> tasks from single class dominate the execution, map-queue design is
> effectively serial as well. That's not the fault of the
> implementations in both cases, it is the task stream itself does not
> expose enough parallelism.


Well, the entire point is to have stripes serialized, isn't it. The problem
is that the consistent-hashing approach will make execution serial for all
stripes that hash the same. Which is slightly different.


> One could do quick back-envelope
> calculation on maximum parallelism available in incoming stream, as
> well as by how far both designs can capitalize on that. I'd speculate
> map-queue design would run at optimal; while hashing design would be
> negligibly slower than optimal.
>
> > Also worth mentioning is that the map-queue approach does not need to do
> batch-execution, I only added that because it was trivial and usually gives
> better performance as it removes pressure from the submission queue of the
> "real" Executor.
>
> Yup, I can see that. Neat trick. That trades off stricter inter-class
> FIFO a bit, but that should be the fair price for performance
> advantages of batching.
>

Exactly, thanks.

Cheers,
?


>
> -Aleksey.
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/e9cb05f5/attachment.html>

From kirk at kodewerk.com  Sat May 12 14:50:26 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Sat, 12 May 2012 20:50:26 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU_AEhmrB2KhAPKxBjdNiuJaSs=Kv5Ws=ji_aZEt5viqrg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
	<CANPzfU_AEhmrB2KhAPKxBjdNiuJaSs=Kv5Ws=ji_aZEt5viqrg@mail.gmail.com>
Message-ID: <827ABDBD-9ED6-4B4D-A81E-DB80E276C097@kodewerk.com>

Queues are not about better performance for an individual thread. It's about parking (hence adding dead time) a thread until there are enough resources to service it. Which means I'd like to reask Aleksey's question.

Regards,
Kirk

On 2012-05-12, at 6:58 PM, ?iktor ?lang wrote:

> Also worth mentioning is that the map-queue approach does not need to do batch-execution, I only added that because it was trivial and usually gives better performance as it removes pressure from the submission queue of the "real" Executor.
> 
> Cheers,
> ?
> 
> On Sat, May 12, 2012 at 6:53 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> 
> 
> On Sat, May 12, 2012 at 6:48 PM, Aleksey Shipilev <aleksey.shipilev at gmail.com> wrote:
> Yes, that is why I have general issue with solving this problem with
> map-queue designs. Why would one mess with shared state, instantiate
> queues per striped object, when tasks can just be multiplexed over
> single-threaded executors? OP did not forced the constraint for the
> tasks to be executed in a batch, there's only the constraint for
> same-class tasks to be executed in order. That is why I believe
> stateless design is better: it is much more fool-proof and as
> efficient. Is there something I miss there?
> 
> A consistent-hashing approach as you described is a good one as well, the problem is that when the stripes are unevenly distributed you end up with a single threaded program.
> 
> Cheers,
> ?
>  
> 
> -Aleksey.
> 
> On Sat, May 12, 2012 at 8:43 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> > And removing the ExecutionStripe as soon as it's done with existing
> > runnables might be a bad idea, and as soon as you involve a temporal aspect
> > like, fade to black after 10 seconds of idleness, you need to have a timer
> > running. An alternative is to try out Weak/Soft references, but that ain't a
> > walk in the park either...
> >
> > I apologize for the monologue, carry on....
> >
> > Cheers,
> > ?
> >
> >
> > On Sat, May 12, 2012 at 4:05 PM, ?iktor ?lang <viktor.klang at gmail.com>
> > wrote:
> >>
> >> Also, if you know when a stripe won't be used anymore, you can simply
> >> disassociate the stripe, and it will finish the tasks it was scheduled to
> >> run prior to becoming garbage collected.
> >>
> >>
> >> On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >> wrote:
> >>>
> >>>
> >>>
> >>> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev
> >>> <aleksey.shipilev at gmail.com> wrote:
> >>>>
> >>>> You seem to have pretty generic approach for making arbitrary executor
> >>>> look like striped one. I would be naturally to assume the number of
> >>>> stripes is arbitrary as well. ;) The race-free purges in these
> >>>> MultiMap-like cases is rather hard for inexperienced concurrency guys;
> >>>> much harder than writing the baseline map-queue-based implementation.
> >>>> That's why I think suggesting the baseline map-queue-based
> >>>> implementation and asking to fit purges there is like selling someone
> >>>> the house with a minefield in the yard.
> >>>>
> >>>
> >>> Shared mutable state concurrency IS a minefield. If you operate at that
> >>> level you need to learn how to disarm mines.
> >>> That's why I prefer to offer people things like composable futures and
> >>> actors instead of shared mutable state concurrency.
> >>>
> >>> Cheers,
> >>> ?
> >>>
> >>>>
> >>>> -Aleksey.
> >>>>
> >>>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >>>> wrote:
> >>>> > It'll only be an issue if you have arbitrary stripes. Fixing that is a
> >>>> > great
> >>>> > exercise to the reader!
> >>>> >
> >>>> > Cheers,
> >>>> > V
> >>>> >
> >>>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev"
> >>>> > <aleksey.shipilev at gmail.com>
> >>>> > wrote:
> >>>> >>
> >>>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang
> >>>> >> <viktor.klang at gmail.com>
> >>>> >> wrote:
> >>>> >> > Here's an implementation I threw together (haven't been tested yet
> >>>> >> > so
> >>>> >> > YMMV)
> >>>> >> > that should make any Executor into a striped one, for every
> >>>> >> > runnable
> >>>> >> > that is
> >>>> >> > put in there which is Striped.
> >>>> >> >
> >>>> >> > https://gist.github.com/2665603
> >>>> >>
> >>>> >> Neat trick, but it is prone to memory leaks. You will have to protect
> >>>> >> yourself from multiple stripe classes come and go, that is, there is
> >>>> >> a
> >>>> >> garbage buildup in $stripes map, if some stripes are not being used
> >>>> >> (from some point, forever). Getting that right in race-free manner is
> >>>> >> tough.
> >>>> >>
> >>>> >> -Aleksey.
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>> Viktor Klang
> >>>
> >>> Akka Tech Lead
> >>> Typesafe - The software stack for applications that scale
> >>>
> >>> Twitter: @viktorklang
> >>>
> >>
> >>
> >>
> >> --
> >> Viktor Klang
> >>
> >> Akka Tech Lead
> >> Typesafe - The software stack for applications that scale
> >>
> >> Twitter: @viktorklang
> >>
> >
> >
> >
> > --
> > Viktor Klang
> >
> > Akka Tech Lead
> > Typesafe - The software stack for applications that scale
> >
> > Twitter: @viktorklang
> >
> 
> 
> 
> -- 
> Viktor Klang
> 
> Akka Tech Lead
> Typesafe - The software stack for applications that scale
> 
> Twitter: @viktorklang
> 
> 
> 
> 
> -- 
> Viktor Klang
> 
> Akka Tech Lead
> Typesafe - The software stack for applications that scale
> 
> Twitter: @viktorklang
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/e83773f3/attachment-0001.html>

From viktor.klang at gmail.com  Sat May 12 14:55:33 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 20:55:33 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <827ABDBD-9ED6-4B4D-A81E-DB80E276C097@kodewerk.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
	<CANPzfU_AEhmrB2KhAPKxBjdNiuJaSs=Kv5Ws=ji_aZEt5viqrg@mail.gmail.com>
	<827ABDBD-9ED6-4B4D-A81E-DB80E276C097@kodewerk.com>
Message-ID: <CANPzfU_aCM9xW2Qg3SnMv0hB1wgkkhU6+i3DmR6xTKnrqJbqLQ@mail.gmail.com>

Which question precisely?
On May 12, 2012 8:50 PM, "Kirk Pepperdine" <kirk at kodewerk.com> wrote:

> Queues are not about better performance for an individual thread. It's
> about parking (hence adding dead time) a thread until there are enough
> resources to service it. Which means I'd like to reask Aleksey's question.
>
> Regards,
> Kirk
>
> On 2012-05-12, at 6:58 PM, ?iktor ?lang wrote:
>
> Also worth mentioning is that the map-queue approach does not need to do
> batch-execution, I only added that because it was trivial and usually gives
> better performance as it removes pressure from the submission queue of the
> "real" Executor.
>
> Cheers,
> ?
>
> On Sat, May 12, 2012 at 6:53 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>>
>>
>> On Sat, May 12, 2012 at 6:48 PM, Aleksey Shipilev <
>> aleksey.shipilev at gmail.com> wrote:
>>
>>> Yes, that is why I have general issue with solving this problem with
>>> map-queue designs. Why would one mess with shared state, instantiate
>>> queues per striped object, when tasks can just be multiplexed over
>>> single-threaded executors? OP did not forced the constraint for the
>>> tasks to be executed in a batch, there's only the constraint for
>>> same-class tasks to be executed in order. That is why I believe
>>> stateless design is better: it is much more fool-proof and as
>>> efficient. Is there something I miss there?
>>>
>>
>> A consistent-hashing approach as you described is a good one as well, the
>> problem is that when the stripes are unevenly distributed you end up with a
>> single threaded program.
>>
>> Cheers,
>> ?
>>
>>
>>>
>>> -Aleksey.
>>>
>>> On Sat, May 12, 2012 at 8:43 PM, ?iktor ?lang <viktor.klang at gmail.com>
>>> wrote:
>>> > And removing the ExecutionStripe as soon as it's done with existing
>>> > runnables might be a bad idea, and as soon as you involve a temporal
>>> aspect
>>> > like, fade to black after 10 seconds of idleness, you need to have a
>>> timer
>>> > running. An alternative is to try out Weak/Soft references, but that
>>> ain't a
>>> > walk in the park either...
>>> >
>>> > I apologize for the monologue, carry on....
>>> >
>>> > Cheers,
>>> > ?
>>> >
>>> >
>>> > On Sat, May 12, 2012 at 4:05 PM, ?iktor ?lang <viktor.klang at gmail.com>
>>> > wrote:
>>> >>
>>> >> Also, if you know when a stripe won't be used anymore, you can simply
>>> >> disassociate the stripe, and it will finish the tasks it was
>>> scheduled to
>>> >> run prior to becoming garbage collected.
>>> >>
>>> >>
>>> >> On Sat, May 12, 2012 at 3:23 PM, ?iktor ?lang <viktor.klang at gmail.com
>>> >
>>> >> wrote:
>>> >>>
>>> >>>
>>> >>>
>>> >>> On Sat, May 12, 2012 at 2:47 PM, Aleksey Shipilev
>>> >>> <aleksey.shipilev at gmail.com> wrote:
>>> >>>>
>>> >>>> You seem to have pretty generic approach for making arbitrary
>>> executor
>>> >>>> look like striped one. I would be naturally to assume the number of
>>> >>>> stripes is arbitrary as well. ;) The race-free purges in these
>>> >>>> MultiMap-like cases is rather hard for inexperienced concurrency
>>> guys;
>>> >>>> much harder than writing the baseline map-queue-based
>>> implementation.
>>> >>>> That's why I think suggesting the baseline map-queue-based
>>> >>>> implementation and asking to fit purges there is like selling
>>> someone
>>> >>>> the house with a minefield in the yard.
>>> >>>>
>>> >>>
>>> >>> Shared mutable state concurrency IS a minefield. If you operate at
>>> that
>>> >>> level you need to learn how to disarm mines.
>>> >>> That's why I prefer to offer people things like composable futures
>>> and
>>> >>> actors instead of shared mutable state concurrency.
>>> >>>
>>> >>> Cheers,
>>> >>> ?
>>> >>>
>>> >>>>
>>> >>>> -Aleksey.
>>> >>>>
>>> >>>> On Sat, May 12, 2012 at 4:35 PM, ?iktor ?lang <
>>> viktor.klang at gmail.com>
>>> >>>> wrote:
>>> >>>> > It'll only be an issue if you have arbitrary stripes. Fixing that
>>> is a
>>> >>>> > great
>>> >>>> > exercise to the reader!
>>> >>>> >
>>> >>>> > Cheers,
>>> >>>> > V
>>> >>>> >
>>> >>>> > On May 12, 2012 1:55 PM, "Aleksey Shipilev"
>>> >>>> > <aleksey.shipilev at gmail.com>
>>> >>>> > wrote:
>>> >>>> >>
>>> >>>> >> On Sat, May 12, 2012 at 2:09 PM, ?iktor ?lang
>>> >>>> >> <viktor.klang at gmail.com>
>>> >>>> >> wrote:
>>> >>>> >> > Here's an implementation I threw together (haven't been tested
>>> yet
>>> >>>> >> > so
>>> >>>> >> > YMMV)
>>> >>>> >> > that should make any Executor into a striped one, for every
>>> >>>> >> > runnable
>>> >>>> >> > that is
>>> >>>> >> > put in there which is Striped.
>>> >>>> >> >
>>> >>>> >> > https://gist.github.com/2665603
>>> >>>> >>
>>> >>>> >> Neat trick, but it is prone to memory leaks. You will have to
>>> protect
>>> >>>> >> yourself from multiple stripe classes come and go, that is,
>>> there is
>>> >>>> >> a
>>> >>>> >> garbage buildup in $stripes map, if some stripes are not being
>>> used
>>> >>>> >> (from some point, forever). Getting that right in race-free
>>> manner is
>>> >>>> >> tough.
>>> >>>> >>
>>> >>>> >> -Aleksey.
>>> >>>
>>> >>>
>>> >>>
>>> >>>
>>> >>> --
>>> >>> Viktor Klang
>>> >>>
>>> >>> Akka Tech Lead
>>> >>> Typesafe - The software stack for applications that scale
>>> >>>
>>> >>> Twitter: @viktorklang
>>> >>>
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Viktor Klang
>>> >>
>>> >> Akka Tech Lead
>>> >> Typesafe - The software stack for applications that scale
>>> >>
>>> >> Twitter: @viktorklang
>>> >>
>>> >
>>> >
>>> >
>>> > --
>>> > Viktor Klang
>>> >
>>> > Akka Tech Lead
>>> > Typesafe - The software stack for applications that scale
>>> >
>>> > Twitter: @viktorklang
>>> >
>>>
>>
>>
>>
>> --
>> Viktor Klang
>>
>> Akka Tech Lead
>> Typesafe <http://www.typesafe.com/> - The software stack for
>> applications that scale
>>
>> Twitter: @viktorklang
>>
>>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - The software stack for applications
> that scale
>
> Twitter: @viktorklang
>
>  _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/b97dc026/attachment.html>

From kirk at kodewerk.com  Sat May 12 15:19:10 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Sat, 12 May 2012 21:19:10 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU_aCM9xW2Qg3SnMv0hB1wgkkhU6+i3DmR6xTKnrqJbqLQ@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
	<CANPzfU_AEhmrB2KhAPKxBjdNiuJaSs=Kv5Ws=ji_aZEt5viqrg@mail.gmail.com>
	<827ABDBD-9ED6-4B4D-A81E-DB80E276C097@kodewerk.com>
	<CANPzfU_aCM9xW2Qg3SnMv0hB1wgkkhU6+i3DmR6xTKnrqJbqLQ@mail.gmail.com>
Message-ID: <0362A8B6-F867-4A5E-B758-2AAE3A2DC453@kodewerk.com>

> Why would one mess with shared state, instantiate
> queues per striped object, when tasks can just be multiplexed over
> single-threaded executors?
On 2012-05-12, at 8:55 PM, ?iktor ?lang wrote:

>> Why would one mess with shared state, instantiate
>> queues per striped object, when tasks can just be multiplexed over
>> single-threaded executors?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/71106852/attachment.html>

From viktor.klang at gmail.com  Sat May 12 17:13:57 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 12 May 2012 23:13:57 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <0362A8B6-F867-4A5E-B758-2AAE3A2DC453@kodewerk.com>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
	<CANPzfU_AEhmrB2KhAPKxBjdNiuJaSs=Kv5Ws=ji_aZEt5viqrg@mail.gmail.com>
	<827ABDBD-9ED6-4B4D-A81E-DB80E276C097@kodewerk.com>
	<CANPzfU_aCM9xW2Qg3SnMv0hB1wgkkhU6+i3DmR6xTKnrqJbqLQ@mail.gmail.com>
	<0362A8B6-F867-4A5E-B758-2AAE3A2DC453@kodewerk.com>
Message-ID: <CANPzfU8KmRRg_ea5npUYxHONg22O_V4qrVbO7fBegHS+xDdCHQ@mail.gmail.com>

On Sat, May 12, 2012 at 9:19 PM, Kirk Pepperdine <kirk at kodewerk.com> wrote:

> Why would one mess with shared state, instantiate
>>> queues per striped object, when tasks can just be multiplexed over
>>> single-threaded executors?
>>
>>
I thought that was the entire previous discussion; then you need to do
consistent hashing over N SingleThreadedExecutors, which will only use all
available threads if all buckets are occupied.



> On 2012-05-12, at 8:55 PM, ?iktor ?lang wrote:
>
> Why would one mess with shared state, instantiate
>>> queues per striped object, when tasks can just be multiplexed over
>>> single-threaded executors?
>>
>>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/771d1e29/attachment-0001.html>

From joe.bowbeer at gmail.com  Sat May 12 21:54:17 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 12 May 2012 18:54:17 -0700
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FAD66F3.1030006@intelerad.com>
References: <4FAC9B5A.10005@8950aaa.com>
	<4FAD66F3.1030006@intelerad.com>
Message-ID: <CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>

On Fri, May 11, 2012 at 12:22 PM, Andrew Trumper wrote:

>
> BoundedExecutor is a simple wrapper that limits the number of concurrently
> running tasks to some number. It doesn't allocate any threads itself
> (unless you want it to) but uses the "mThreadCache". It's great because it
> means your whole application can use one thread cache but you can create
> little thread pools all over the place and not worry about having a bunch
> of idle threads hangin' around. We use this all the time in our product.
>
> (Note, that Joe Bowbeer has mentioned a class called SerialExecutor that
> seems to do the same thing. ?)
>
> BoundedExecutor is part of the nuggu library, BSD license:
>
> <http://nuggu.svn.sourceforge.**net/viewvc/nuggu/HEAD/src/com/**
> intelerad/tools/lib/**concurrent/BoundedExecutor.**
> java?revision=10&view=markup<http://nuggu.svn.sourceforge.net/viewvc/nuggu/HEAD/src/com/intelerad/tools/lib/concurrent/BoundedExecutor.java?revision=10&view=markup>
> >
>
> It would be really great to improve this class and put it in a library
> someone's actually heard of :-P.
>
> (In our product we sometimes use a second BoundedExecutor around the
> thread cache to limit the concurrency to the number of cores/processors.)
>


The SerialExecutor that I referred to is in the Executor javadoc.

http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Executor.html

Here is a link to one of the times that a similar problem was discussed
previously on c-i:

http://cs.oswego.edu/pipermail/concurrency-interest/2010-June/007208.html

This post refers to both SerialExecutor and a (different) BoundedExecutor.

There are several different SerialExecutor and BoundedExecutor
implementations floating around.  In one way, this validates the usefulness
of the simple Executor interface!  In real world applications, I wonder if
a single BoundedExecutor implementation would be useful.  Shutdown is one
of the missing pieces in these sample implementations -- and this is
especially difficult to manage when there are multiple, delegating
executors.  I expect that different trade-offs would be chosen in different
situations, in which case it may be hard to provide a general solution.

--Joe
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120512/2c11ab50/attachment.html>

From mikeb01 at gmail.com  Sun May 13 03:40:17 2012
From: mikeb01 at gmail.com (Michael Barker)
Date: Sun, 13 May 2012 08:40:17 +0100
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CANPzfU8XVMyy5i1n_aRwhRXSEdyTYFx+3QM3OgkpbvDDcL=Q1g@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<CALwNKeRcD=Wf1Zp8yUrvddwXgf+v4FKTknP-g8huPa33PLV4ng@mail.gmail.com>
	<CANPzfU8XVMyy5i1n_aRwhRXSEdyTYFx+3QM3OgkpbvDDcL=Q1g@mail.gmail.com>
Message-ID: <CALwNKeRbsJkm72nFekghmf8jNC+75QhNSOwiGbyR55G-h=QMNA@mail.gmail.com>

>> > I'd like to explore alternatives to ConcurrentLinkedQueue, especially to
>> > get
>> > a bit lower latency and perhaps even lower mem usage.
>>
>> For which use case are you looking to improve latency; the latency
>> cost on the producing thread or latency for moving the message from
>> the publishing thread to the consuming thread?
>
>
> The latency between writers and reader. So the latter.

With most of the experimentation done on the Disruptor, the thing that
has the biggest impact on latency is how you notify the consumer
thread.  I've seen latencies as low as 180ns using
ConcurrentLinkedQueue, but required a full busy spin to get there.
That's compared to a lock/condition wake-up on ABQ of about 32 000ns.
The Disruptor has a number of different "WaitStrategies" based on the
trade off between CPU consumption and latency.

I've been meaning to explore a phased back-off strategy of busy-spin
-> spin with yield -> LockSupport.parkNanos.  Building good back-off
strategy in Java is a bit tricky as LockSupport.parkNanos is not
always predictable and you don't have fine grained access to some of
the OS timer facilities.  The latency of the LockSupport.parkNanos(1L)
tends to be somewhere in the region of 65?s on a reasonably modern
Linux kernel, which is okay, I have seen it run into milliseconds on
some revisions of MS Windows.

I'd be interested in what your consumer looks like.  You mentioned
having millions of the these queues, I'm assuming that you won't be
able to have millions of Java threads as consumers, so you'd be
consuming from multiple queues in a given thread?

Mike.


From viktor.klang at gmail.com  Sun May 13 06:19:36 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 13 May 2012 12:19:36 +0200
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CALwNKeRbsJkm72nFekghmf8jNC+75QhNSOwiGbyR55G-h=QMNA@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<CALwNKeRcD=Wf1Zp8yUrvddwXgf+v4FKTknP-g8huPa33PLV4ng@mail.gmail.com>
	<CANPzfU8XVMyy5i1n_aRwhRXSEdyTYFx+3QM3OgkpbvDDcL=Q1g@mail.gmail.com>
	<CALwNKeRbsJkm72nFekghmf8jNC+75QhNSOwiGbyR55G-h=QMNA@mail.gmail.com>
Message-ID: <CANPzfU82dowyDLYsd0zQ87BygmW46P3YQRd2kCyagT5+XW=Z8w@mail.gmail.com>

On Sun, May 13, 2012 at 9:40 AM, Michael Barker <mikeb01 at gmail.com> wrote:

> >> > I'd like to explore alternatives to ConcurrentLinkedQueue, especially
> to
> >> > get
> >> > a bit lower latency and perhaps even lower mem usage.
> >>
> >> For which use case are you looking to improve latency; the latency
> >> cost on the producing thread or latency for moving the message from
> >> the publishing thread to the consuming thread?
> >
> >
> > The latency between writers and reader. So the latter.
>
> With most of the experimentation done on the Disruptor, the thing that
> has the biggest impact on latency is how you notify the consumer
> thread.


There's no notification needed. If the consumer is currently active, i.e.
is being executed by a thread, we want handoffs to be as cheap as possible.


>  I've seen latencies as low as 180ns using
> ConcurrentLinkedQueue, but required a full busy spin to get there.
> That's compared to a lock/condition wake-up on ABQ of about 32 000ns.
> The Disruptor has a number of different "WaitStrategies" based on the
> trade off between CPU consumption and latency.
>

Disruptor doesn't map to this problem since it uses a dedicated thread for
the BLP?


>
> I've been meaning to explore a phased back-off strategy of busy-spin
> -> spin with yield -> LockSupport.parkNanos.  Building good back-off
> strategy in Java is a bit tricky as LockSupport.parkNanos is not
> always predictable and you don't have fine grained access to some of
> the OS timer facilities.  The latency of the LockSupport.parkNanos(1L)
> tends to be somewhere in the region of 65?s on a reasonably modern
> Linux kernel, which is okay, I have seen it run into milliseconds on
> some revisions of MS Windows.
>
> I'd be interested in what your consumer looks like.  You mentioned
> having millions of the these queues, I'm assuming that you won't be
> able to have millions of Java threads as consumers, so you'd be
> consuming from multiple queues in a given thread?
>

https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/dispatch/Mailbox.scala#L174

Cheers,
?


>
> Mike.
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/80a7de35/attachment.html>

From dl at cs.oswego.edu  Sun May 13 06:41:18 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 13 May 2012 06:41:18 -0400
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
In-Reply-To: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
References: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
Message-ID: <4FAF8FCE.6070700@cs.oswego.edu>

On 05/12/12 12:39, ?iktor ?lang wrote:
> How about this for inclusion in JDK8?
>
> /**
>   * The RejectedExecutionHandler used by Akka, it improves on CallerRunsPolicy
>   * by throwing a RejectedExecutionException if the executor isShutdown.
>   * (CallerRunsPolicy silently discards the runnable in this case, which is
> arguably broken)

Yes, it is arguably broken, and a candidate for a bug report.
Surely no user actually wants the task to start if the executor
is already shut down.
The TPE rejection mechanics don't distinguish these cases, so the
CallerRunsPolicy handler ought to have done this from the beginning.
But it's not clear whether we can fix/change this now.
I'll look into it.

-Doug



From viktor.klang at gmail.com  Sun May 13 06:53:54 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 13 May 2012 12:53:54 +0200
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
In-Reply-To: <4FAF8FCE.6070700@cs.oswego.edu>
References: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
	<4FAF8FCE.6070700@cs.oswego.edu>
Message-ID: <CANPzfU97q+iVHQrEJwTZOF76o92rsVFK0x4UiUriLW6Q5+-H6g@mail.gmail.com>

On Sun, May 13, 2012 at 12:41 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/12/12 12:39, ?iktor ?lang wrote:
>
>> How about this for inclusion in JDK8?
>>
>> /**
>>  * The RejectedExecutionHandler used by Akka, it improves on
>> CallerRunsPolicy
>>  * by throwing a RejectedExecutionException if the executor isShutdown.
>>  * (CallerRunsPolicy silently discards the runnable in this case, which is
>> arguably broken)
>>
>
> Yes, it is arguably broken, and a candidate for a bug report.
> Surely no user actually wants the task to start if the executor
> is already shut down.
> The TPE rejection mechanics don't distinguish these cases, so the
> CallerRunsPolicy handler ought to have done this from the beginning.
> But it's not clear whether we can fix/change this now.
> I'll look into it.
>

I don't think we can change it since it's clearly documented in the class
as the specified behavior: "A handler for rejected tasks that runs the
rejected task directly in the calling thread of the execute method, unless
the executor has been shut down, in which case the task is discarded."

So adding a new policy which improves on the situation is probably the
least intrusive solution.

Cheers,
?


>
> -Doug
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/5db8329c/attachment-0001.html>

From mikeb01 at gmail.com  Sun May 13 07:00:17 2012
From: mikeb01 at gmail.com (Michael Barker)
Date: Sun, 13 May 2012 12:00:17 +0100
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CANPzfU82dowyDLYsd0zQ87BygmW46P3YQRd2kCyagT5+XW=Z8w@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<CALwNKeRcD=Wf1Zp8yUrvddwXgf+v4FKTknP-g8huPa33PLV4ng@mail.gmail.com>
	<CANPzfU8XVMyy5i1n_aRwhRXSEdyTYFx+3QM3OgkpbvDDcL=Q1g@mail.gmail.com>
	<CALwNKeRbsJkm72nFekghmf8jNC+75QhNSOwiGbyR55G-h=QMNA@mail.gmail.com>
	<CANPzfU82dowyDLYsd0zQ87BygmW46P3YQRd2kCyagT5+XW=Z8w@mail.gmail.com>
Message-ID: <CALwNKeTK+RPxdFwz70yjssa4mK50vrFpJymy5zd+64958xKMaQ@mail.gmail.com>

>> With most of the experimentation done on the Disruptor, the thing that
>> has the biggest impact on latency is how you notify the consumer
>> thread.
>
>
> There's no notification needed. If the consumer is currently active, i.e. is
> being executed by a thread, we want handoffs to be as cheap as possible.

Cool, you get to avoid the hard problem :-).

One possible thing to try would be to have some sort of batch based
dequeue operation rather than a single element dequeue.  If you
process a mailbox and there is 10 messages in the queue then you could
remove all 10 and update the head pointer only once.  I'm assuming
that the CAS/Volatile operations will be the biggest cost.  It won't
bring much of a single message latency reduction, but will have a
better profile under a heavy load or burst conditions.

Mike.

From dl at cs.oswego.edu  Sun May 13 07:10:23 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 13 May 2012 07:10:23 -0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU-sbMdvzRorcgV1OX9=EBKTiLd3QqAw0=XZSC1xuavuZg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com>
	<4FAD66F3.1030006@intelerad.com>	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>	<CA+1LWGGr6Rr+tvYtCnKsjnWCmho3UmkCZXr8+93OsboWqtSdRA@mail.gmail.com>
	<CANPzfU-sbMdvzRorcgV1OX9=EBKTiLd3QqAw0=XZSC1xuavuZg@mail.gmail.com>
Message-ID: <4FAF969F.5040608@cs.oswego.edu>

On 05/12/12 14:29, ?iktor ?lang wrote:
> Well, the entire point is to have stripes serialized, isn't it. The problem is
> that the consistent-hashing approach will make execution serial for all stripes
> that hash the same. Which is slightly different.

If it were not for the per-producer-fifo constraint, this could
be solved by using incremental table expansion and self-adjusting
hashes, as is done in Striped64 (LongAdder etc) as well as new
Exchanger and FJ submission queues.

It is possible but not easy, and probably not fast enough,
to adapt this to preserve fifo by tracking whether any thread
has unclaimed elements, and if so, inhibiting its hash adjustment.

-Doug




From viktor.klang at gmail.com  Sun May 13 07:25:17 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 13 May 2012 13:25:17 +0200
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CALwNKeTK+RPxdFwz70yjssa4mK50vrFpJymy5zd+64958xKMaQ@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<CALwNKeRcD=Wf1Zp8yUrvddwXgf+v4FKTknP-g8huPa33PLV4ng@mail.gmail.com>
	<CANPzfU8XVMyy5i1n_aRwhRXSEdyTYFx+3QM3OgkpbvDDcL=Q1g@mail.gmail.com>
	<CALwNKeRbsJkm72nFekghmf8jNC+75QhNSOwiGbyR55G-h=QMNA@mail.gmail.com>
	<CANPzfU82dowyDLYsd0zQ87BygmW46P3YQRd2kCyagT5+XW=Z8w@mail.gmail.com>
	<CALwNKeTK+RPxdFwz70yjssa4mK50vrFpJymy5zd+64958xKMaQ@mail.gmail.com>
Message-ID: <CANPzfU-51MymW-OLK224YRtGJ6YepWQQ1Zs2Us+n-FW-1i3erA@mail.gmail.com>

On Sun, May 13, 2012 at 1:00 PM, Michael Barker <mikeb01 at gmail.com> wrote:

> >> With most of the experimentation done on the Disruptor, the thing that
> >> has the biggest impact on latency is how you notify the consumer
> >> thread.
> >
> >
> > There's no notification needed. If the consumer is currently active,
> i.e. is
> > being executed by a thread, we want handoffs to be as cheap as possible.
>
> Cool, you get to avoid the hard problem :-).
>
> One possible thing to try would be to have some sort of batch based
> dequeue operation rather than a single element dequeue.  If you
> process a mailbox and there is 10 messages in the queue then you could
> remove all 10 and update the head pointer only once.  I'm assuming
> that the CAS/Volatile operations will be the biggest cost.  It won't
> bring much of a single message latency reduction, but will have a
> better profile under a heavy load or burst conditions.
>

The problem with batch dequeues is that if one of the messages fail we need
to be at a stable state, and doing that would mean store away the remaining
batch, which would bump the processors size by atleast a reference, which
can be expensive if you have millions of them.

It's an interesting problem though. I've been thinking about how to handle
producer conflicts as cheap as possible, as there are no consumer conflicts.

Cheers,
?


> Mike.
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/2b6b4c36/attachment.html>

From viktor.klang at gmail.com  Sun May 13 07:33:06 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 13 May 2012 13:33:06 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FAF969F.5040608@cs.oswego.edu>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CANPzfU9iR+GvuyGMN+qHjhABJOs4POHtZhB0dF0uEr1oBXHJLA@mail.gmail.com>
	<CA+1LWGE075tkOxtcstY12s-3aBYz5eGqi0U2n3hmZ9GHyKiPEA@mail.gmail.com>
	<CANPzfU9iq9amOTOkQ-BCLJu9SEhr1gWaEfaoDb9sOy+Wnj29Yg@mail.gmail.com>
	<CA+1LWGGByqege-rGHMDexO4X1kNwy_nhgZOmF-UM_Qvzr1ExpA@mail.gmail.com>
	<CANPzfU9O+So_ujpMYx=Bjr2oy_rWZEWuAEeB=cBqcqLd+BKM8Q@mail.gmail.com>
	<CANPzfU8iKWbrOdEQ3qL67dKKEmnHwkFvFd=W-cRU8GLBGjuR=w@mail.gmail.com>
	<CANPzfU-EPO4FCx_tUiUtF1frK3KDqYNDXWkDoN+DzqBsiFxwzg@mail.gmail.com>
	<CA+1LWGFpeJyJB9zsRZKWX1-7Q0UeT+0NYGMw70m2uct0=fBq1Q@mail.gmail.com>
	<CANPzfU_wxnuQ9JJMVp9fK6xrBGFg77sE365hhLzRK2RmTfP3yg@mail.gmail.com>
	<CA+1LWGGr6Rr+tvYtCnKsjnWCmho3UmkCZXr8+93OsboWqtSdRA@mail.gmail.com>
	<CANPzfU-sbMdvzRorcgV1OX9=EBKTiLd3QqAw0=XZSC1xuavuZg@mail.gmail.com>
	<4FAF969F.5040608@cs.oswego.edu>
Message-ID: <CANPzfU-VQ=MHPMFOQYYXxjxwFiBRPM6GN+qSytPcuB2dQMqW1g@mail.gmail.com>

On Sun, May 13, 2012 at 1:10 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/12/12 14:29, ?iktor ?lang wrote:
>
>> Well, the entire point is to have stripes serialized, isn't it. The
>> problem is
>> that the consistent-hashing approach will make execution serial for all
>> stripes
>> that hash the same. Which is slightly different.
>>
>
> If it were not for the per-producer-fifo constraint, this could
> be solved by using incremental table expansion and self-adjusting
> hashes, as is done in Striped64 (LongAdder etc) as well as new
> Exchanger and FJ submission queues.
>
> It is possible but not easy, and probably not fast enough,
> to adapt this to preserve fifo by tracking whether any thread
> has unclaimed elements, and if so, inhibiting its hash adjustment.


I've started to strip down the most current CLQ to see what can be gained
from not supporting non-head deletes etc.

One of the issues here is that we're talking so fast operations taht doing
anything to gain speed might just end up costing more, as you say.

Cheers,
?


>
>
> -Doug
>
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/4ad99712/attachment.html>

From dawid.weiss at gmail.com  Sun May 13 16:08:31 2012
From: dawid.weiss at gmail.com (Dawid Weiss)
Date: Sun, 13 May 2012 22:08:31 +0200
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
Message-ID: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>

Hi there.

I wrote a JUnit runner that attempts to annihilate any threads that
leaked out of a given test's scope. The process starts by setting an
interrupt flag, then after some delay it just calls Thread.stop()
(let's not go into why this particular method was chosen for now, I
realize the consequences).

Anyway. I've encountered an interesting scenario where a
ThreadPoolExecutor is used in combination with
ExecutorCompletionService (in Apache Lucene). What happens is that the
thread pool's threads are first interrupted (which doesn't terminate
thread pool threads, they are reused) and then stopped, which does
seem to kill them (I see uncaught stacks:

java.lang.IllegalMonitorStateException
	at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:155)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1260)
	at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:460)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:449)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)

and then the thread pool's pool is refilled with fresh threads.

Interestingly, any subsequent use of the executor completion service
deadlocks. I would assume the problem is somewhere in my code but this
happens only on Java 1.7, on 1.6 the execution proceeds normally with
those refilled threads. A stack trace of the hung process shows all
executor service threads parked on:

"LuceneTestCase-84-thread-10" prio=6 tid=0x00000000087a3800 nid=0x19a8
waiting on condition [0x000000000e00e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000f92a0318> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)

and the main thread utilizing completion service is parked on the queue:

"TEST-TestScope-org.apache.lucene.search.TestPrefixInBooleanQuery.testTermBooleanQuery-seed#[10A1C9CC1F06B49B]"
prio=6 tid=0x0000000008798000 nid=0x1cbc waiting on condition
[0x000000000aebd000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000f94614c0> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ExecutorCompletionService.take(ExecutorCompletionService.java:193)
	at org.apache.lucene.search.IndexSearcher$ExecutionHelper.next(IndexSearcher.java:756)
        ...

The completion service has submitted tasks, they're just not executed.
This in fact is a deadlock state.

Any hints/ ideas what might have changed in between 1.6 and 1.7 that
may be causing this? I couldn't reproduce on a small example but the
above scenario is 100% reproducible (well, on my machine and Java
1.7.0_03-b05).

Thanks,
Dawid

From mr.chrisvest at gmail.com  Sun May 13 16:22:21 2012
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Sun, 13 May 2012 22:22:21 +0200
Subject: [concurrency-interest] Object finalization
Message-ID: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>

Hi,
I could not find any resources that I felt were clear and trustworthy
enough, so...

I would like to have confirmed (or busted) my assumption that the following
code is buggy, because the garbage collector might set the `a` field to
null, before this `finalize` method can read it, thus preventing the method
from attempting to cleanly dispose of the `Resource` in the `b` field ?
this all under the assertion that `safelyDispose` itself never throws:

public class SomeService {
  private final Resource a, b;

  public SomeService(Resource a, Resource b) {
    assert a != null && b != null;
    this.a = a;
    this.b = b;
  }
  @Override
  protected void finalize() throws Throwable {
    a.safelyDispose();
    b.safelyDispose();
  }
}

Cheers,
Chris
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/a893b2c7/attachment.html>

From viktor.klang at gmail.com  Sun May 13 16:34:23 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 13 May 2012 22:34:23 +0200
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
References: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
Message-ID: <CANPzfU_w4-9tBhzUrN2zs3WdTPNdfTawUaLCsukukqKBg58KRw@mail.gmail.com>

On Sun, May 13, 2012 at 10:08 PM, Dawid Weiss <dawid.weiss at gmail.com> wrote:

> Hi there.
>
> I wrote a JUnit runner that attempts to annihilate any threads that
> leaked out of a given test's scope. The process starts by setting an
> interrupt flag, then after some delay it just calls Thread.stop()
> (let's not go into why this particular method was chosen for now, I
> realize the consequences).
>
> Anyway. I've encountered an interesting scenario where a
> ThreadPoolExecutor is used in combination with
> ExecutorCompletionService (in Apache Lucene). What happens is that the
> thread pool's threads are first interrupted (which doesn't terminate
> thread pool threads, they are reused) and then stopped, which does
> seem to kill them (I see uncaught stacks:
>
> java.lang.IllegalMonitorStateException
>        at
> java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:155)
>        at
> java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1260)
>        at
> java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:460)
>        at
> java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:449)
>        at
> java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)
>        at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)
>        at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
>        at java.lang.Thread.run(Thread.java:722)
>
> and then the thread pool's pool is refilled with fresh threads.
>
> Interestingly, any subsequent use of the executor completion service
> deadlocks. I would assume the problem is somewhere in my code but this
> happens only on Java 1.7, on 1.6 the execution proceeds normally with
> those refilled threads. A stack trace of the hung process shows all
> executor service threads parked on:
>
> "LuceneTestCase-84-thread-10" prio=6 tid=0x00000000087a3800 nid=0x19a8
> waiting on condition [0x000000000e00e000]
>   java.lang.Thread.State: WAITING (parking)
>        at sun.misc.Unsafe.park(Native Method)
>        - parking to wait for  <0x00000000f92a0318> (a
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
>        at
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
>        at
> java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
>        at
> java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)
>        at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)
>        at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
>        at java.lang.Thread.run(Thread.java:722)
>
> and the main thread utilizing completion service is parked on the queue:
>
>
> "TEST-TestScope-org.apache.lucene.search.TestPrefixInBooleanQuery.testTermBooleanQuery-seed#[10A1C9CC1F06B49B]"
> prio=6 tid=0x0000000008798000 nid=0x1cbc waiting on condition
> [0x000000000aebd000]
>   java.lang.Thread.State: WAITING (parking)
>        at sun.misc.Unsafe.park(Native Method)
>        - parking to wait for  <0x00000000f94614c0> (a
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
>        at
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
>        at
> java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
>        at
> java.util.concurrent.ExecutorCompletionService.take(ExecutorCompletionService.java:193)
>        at
> org.apache.lucene.search.IndexSearcher$ExecutionHelper.next(IndexSearcher.java:756)
>        ...
>
> The completion service has submitted tasks, they're just not executed.
> This in fact is a deadlock state.
>
> Any hints/ ideas what might have changed in between 1.6 and 1.7 that
> may be causing this? I couldn't reproduce on a small example but the
> above scenario is 100% reproducible (well, on my machine and Java
> 1.7.0_03-b05).
>
>
What happens if you use thread.stop(new InterruptedException())?

Cheers,
?


> Thanks,
> Dawid
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/fdba128c/attachment.html>

From crazybob at crazybob.org  Sun May 13 16:45:43 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Sun, 13 May 2012 13:45:43 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
References: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
Message-ID: <CAGmsiP7ejKUQ85kYLOabdu0ygoYmzGRRxCOobV1ro-btAwzJQw@mail.gmail.com>

The object is considered "reachable" while the constructor is executing (JLS
12.6.1<http://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.6.1>),
and 'a' will never be set to null by the GC, so this code is safe if
assertions are enabled (they're off by default). :-)

Bob
Square is hiring! <https://squareup.com/jobs>

On Sun, May 13, 2012 at 1:22 PM, Chris Vest <mr.chrisvest at gmail.com> wrote:

> Hi,
> I could not find any resources that I felt were clear and trustworthy
> enough, so...
>
> I would like to have confirmed (or busted) my assumption that the
> following code is buggy, because the garbage collector might set the `a`
> field to null, before this `finalize` method can read it, thus preventing
> the method from attempting to cleanly dispose of the `Resource` in the `b`
> field ? this all under the assertion that `safelyDispose` itself never
> throws:
>
> public class SomeService {
>   private final Resource a, b;
>
>   public SomeService(Resource a, Resource b) {
>     assert a != null && b != null;
>     this.a = a;
>     this.b = b;
>   }
>   @Override
>   protected void finalize() throws Throwable {
>     a.safelyDispose();
>     b.safelyDispose();
>   }
> }
>
> Cheers,
> Chris
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/187a1fe1/attachment-0001.html>

From vitalyd at gmail.com  Sun May 13 17:14:19 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 13 May 2012 17:14:19 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
References: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
Message-ID: <CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>

Not sure if Bob's answer applies to your question, but if you're asking if
a or b can be null when finalize() runs, the answer is yes - you'd need to
do a null check.  To guarantee that a and b dispose cleanly when relying on
finalization, they're own finalize would have to do that instead of relying
on reach ability via SomeService.

Sent from my phone
On May 13, 2012 4:30 PM, "Chris Vest" <mr.chrisvest at gmail.com> wrote:

> Hi,
> I could not find any resources that I felt were clear and trustworthy
> enough, so...
>
> I would like to have confirmed (or busted) my assumption that the
> following code is buggy, because the garbage collector might set the `a`
> field to null, before this `finalize` method can read it, thus preventing
> the method from attempting to cleanly dispose of the `Resource` in the `b`
> field ? this all under the assertion that `safelyDispose` itself never
> throws:
>
> public class SomeService {
>   private final Resource a, b;
>
>   public SomeService(Resource a, Resource b) {
>     assert a != null && b != null;
>     this.a = a;
>     this.b = b;
>   }
>   @Override
>   protected void finalize() throws Throwable {
>     a.safelyDispose();
>     b.safelyDispose();
>   }
> }
>
> Cheers,
> Chris
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/99b4b6be/attachment.html>

From crazybob at crazybob.org  Sun May 13 17:33:07 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Sun, 13 May 2012 14:33:07 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>
References: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
	<CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>
Message-ID: <CAGmsiP4A6UkKb+wxCLWT8p2ko11Mn0G9V9bQ6mWGThtjyxzWZA@mail.gmail.com>

On Sun, May 13, 2012 at 2:14 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Not sure if Bob's answer applies to your question, but if you're asking if
> a or b can be null when finalize() runs, the answer is yes - you'd need to
> do a null check.
>
Vitaly, you're incorrect. Perhaps you could explain why you think this is
possible? (Assuming assertions are enabled or the caller didn't pass null.)

Bob
Square is hiring! <https://squareup.com/jobs>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/fbc32d18/attachment.html>

From vitalyd at gmail.com  Sun May 13 17:41:53 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 13 May 2012 17:41:53 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>
References: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
	<CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>
Message-ID: <CAHjP37GjtqFxpgbB9CECs_GwL3MjdFtZ=P-F4A=svbgnKzBfBw@mail.gmail.com>

Sorry I don't think I was clear (on my phone so trying to not type too
much).

I am unclear whether the original question is specifically about
reachability of a and b from the constructor or whether the constructor was
shown to us to indicate that a and b are never null after construction
(assuming asserts are enabled).  If it's the former, your answer is correct
(that's what I meant by saying not sure if your reply was answering the
question).  If it's the latter, then I'm pretty sure my response is correct.

Thanks

Sent from my phone
On May 13, 2012 5:33 PM, "Bob Lee" <crazybob at crazybob.org> wrote:
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/8cd89c74/attachment.html>

From davidcholmes at aapt.net.au  Sun May 13 17:44:26 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 May 2012 07:44:26 +1000
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
	ExecutorCompletionService when slave threads killed.
In-Reply-To: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEHGJEAA.davidcholmes@aapt.net.au>

Dawid,

Once you have used Thread.stop (regardless of what exception it throws) on
the thread pool then you have to discard the thread pool. The code is not
async-exception safe (and can't be) and so you can have corrupted the
internal state of the pool, leading to subsequent erroneous behaviour/hangs
etc.

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dawid
> Weiss
> Sent: Monday, 14 May 2012 6:09 AM
> To: concurrency-interest
> Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
> ExecutorCompletionService when slave threads killed.
>
>
> Hi there.
>
> I wrote a JUnit runner that attempts to annihilate any threads that
> leaked out of a given test's scope. The process starts by setting an
> interrupt flag, then after some delay it just calls Thread.stop()
> (let's not go into why this particular method was chosen for now, I
> realize the consequences).
>
> Anyway. I've encountered an interesting scenario where a
> ThreadPoolExecutor is used in combination with
> ExecutorCompletionService (in Apache Lucene). What happens is that the
> thread pool's threads are first interrupted (which doesn't terminate
> thread pool threads, they are reused) and then stopped, which does
> seem to kill them (I see uncaught stacks:
>
> java.lang.IllegalMonitorStateException
> 	at
> java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(Reentrant
> Lock.java:155)
> 	at
> java.util.concurrent.locks.AbstractQueuedSynchronizer.release(Abst
ractQueuedSynchronizer.java:1260)
> 	at
> java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:460)
> 	at
> java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.
> java:449)
> 	at
> java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor
> .java:1043)
> 	at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecut
> or.java:1103)
> 	at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecu
> tor.java:603)
> 	at java.lang.Thread.run(Thread.java:722)
>
> and then the thread pool's pool is refilled with fresh threads.
>
> Interestingly, any subsequent use of the executor completion service
> deadlocks. I would assume the problem is somewhere in my code but this
> happens only on Java 1.7, on 1.6 the execution proceeds normally with
> those refilled threads. A stack trace of the hung process shows all
> executor service threads parked on:
>
> "LuceneTestCase-84-thread-10" prio=6 tid=0x00000000087a3800 nid=0x19a8
> waiting on condition [0x000000000e00e000]
>    java.lang.Thread.State: WAITING (parking)
> 	at sun.misc.Unsafe.park(Native Method)
> 	- parking to wait for  <0x00000000f92a0318> (a
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
> 	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
> 	at
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObj
> ect.await(AbstractQueuedSynchronizer.java:2043)
> 	at
> java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.
> java:442)
> 	at
> java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor
> .java:1043)
> 	at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecut
> or.java:1103)
> 	at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecu
> tor.java:603)
> 	at java.lang.Thread.run(Thread.java:722)
>
> and the main thread utilizing completion service is parked on the queue:
>
> "TEST-TestScope-org.apache.lucene.search.TestPrefixInBooleanQuery.
> testTermBooleanQuery-seed#[10A1C9CC1F06B49B]"
> prio=6 tid=0x0000000008798000 nid=0x1cbc waiting on condition
> [0x000000000aebd000]
>    java.lang.Thread.State: WAITING (parking)
> 	at sun.misc.Unsafe.park(Native Method)
> 	- parking to wait for  <0x00000000f94614c0> (a
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
> 	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
> 	at
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObj
> ect.await(AbstractQueuedSynchronizer.java:2043)
> 	at
> java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.
> java:442)
> 	at
> java.util.concurrent.ExecutorCompletionService.take(ExecutorComple
> tionService.java:193)
> 	at
> org.apache.lucene.search.IndexSearcher$ExecutionHelper.next(IndexS
> earcher.java:756)
>         ...
>
> The completion service has submitted tasks, they're just not executed.
> This in fact is a deadlock state.
>
> Any hints/ ideas what might have changed in between 1.6 and 1.7 that
> may be causing this? I couldn't reproduce on a small example but the
> above scenario is 100% reproducible (well, on my machine and Java
> 1.7.0_03-b05).
>
> Thanks,
> Dawid
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From crazybob at crazybob.org  Sun May 13 17:54:06 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Sun, 13 May 2012 14:54:06 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37GjtqFxpgbB9CECs_GwL3MjdFtZ=P-F4A=svbgnKzBfBw@mail.gmail.com>
References: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
	<CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>
	<CAHjP37GjtqFxpgbB9CECs_GwL3MjdFtZ=P-F4A=svbgnKzBfBw@mail.gmail.com>
Message-ID: <CAGmsiP5xfHbuytOmcW1KweTVd1rLRB_VUa+qSCTAP+dX17QUNQ@mail.gmail.com>

On Sun, May 13, 2012 at 2:41 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> I am unclear whether the original question is specifically about
> reachability of a and b from the constructor or whether the constructor was
> shown to us to indicate that a and b are never null after construction
> (assuming asserts are enabled).  If it's the former, your answer is correct
> (that's what I meant by saying not sure if your reply was answering the
> question).  If it's the latter, then I'm pretty sure my response is correct
>
Again, according the JLS, you're incorrect. "a" and "b" will be non-null
when SomeService.finalize() executes. Why would you think otherwise?

Bob
Square is hiring! <https://squareup.com/jobs>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/187c5bcc/attachment.html>

From vitalyd at gmail.com  Sun May 13 18:19:46 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 13 May 2012 18:19:46 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAGmsiP5xfHbuytOmcW1KweTVd1rLRB_VUa+qSCTAP+dX17QUNQ@mail.gmail.com>
References: <CAHXi_0cwAm0Lebaiv6svPA98vhFmn=o9RJ=_Fu_5B9JUTc2_SQ@mail.gmail.com>
	<CAHjP37Eq4eXab=tYd_Wn+=GZLOxJCU8TkBnw3GBhzMaWmCAJGw@mail.gmail.com>
	<CAHjP37GjtqFxpgbB9CECs_GwL3MjdFtZ=P-F4A=svbgnKzBfBw@mail.gmail.com>
	<CAGmsiP5xfHbuytOmcW1KweTVd1rLRB_VUa+qSCTAP+dX17QUNQ@mail.gmail.com>
Message-ID: <CAHjP37EpOEKqvL7GDB21rGUjvek_h3paEicOfdMV7HPLqho-QA@mail.gmail.com>

perhaps I'm misremembering but there's no guarantee on the order in which
objects are reclaimed.  When SomeService finalizer runs and assuming a and
b were kept alive only by this instance of SomeService, I don't think
there's any guarantee that a and b have not been reclaimed at this point
already.  That's how the CLR finalization works, so perhaps I'm conflating
the two.

Sent from my phone
On May 13, 2012 5:54 PM, "Bob Lee" <crazybob at crazybob.org> wrote:

> On Sun, May 13, 2012 at 2:41 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> I am unclear whether the original question is specifically about
>> reachability of a and b from the constructor or whether the constructor was
>> shown to us to indicate that a and b are never null after construction
>> (assuming asserts are enabled).  If it's the former, your answer is correct
>> (that's what I meant by saying not sure if your reply was answering the
>> question).  If it's the latter, then I'm pretty sure my response is correct
>>
> Again, according the JLS, you're incorrect. "a" and "b" will be non-null
> when SomeService.finalize() executes. Why would you think otherwise?
>
> Bob
> Square is hiring! <https://squareup.com/jobs>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/e8261291/attachment-0001.html>

From davidcholmes at aapt.net.au  Sun May 13 18:28:26 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 May 2012 08:28:26 +1000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37EpOEKqvL7GDB21rGUjvek_h3paEicOfdMV7HPLqho-QA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEHHJEAA.davidcholmes@aapt.net.au>

The objects referred to by 'a' and 'b' will remain finalizer-reachable until
after the finalizer runs and so can not be reclaimed. If they were to be
reclaimed it would require that all references to them in finalizable
objects be found and cleared, which is not practical.

With regard to the OP, as long as the constructor completes normally, it is
guaranteed that neither 'a' nor 'b' will be null when the finalizer runs.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Vitaly
Davidovich
  Sent: Monday, 14 May 2012 8:20 AM
  To: Bob Lee
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Object finalization


  perhaps I'm misremembering but there's no guarantee on the order in which
objects are reclaimed.  When SomeService finalizer runs and assuming a and b
were kept alive only by this instance of SomeService, I don't think there's
any guarantee that a and b have not been reclaimed at this point already.
That's how the CLR finalization works, so perhaps I'm conflating the two.

  Sent from my phone

  On May 13, 2012 5:54 PM, "Bob Lee" <crazybob at crazybob.org> wrote:

    On Sun, May 13, 2012 at 2:41 PM, Vitaly Davidovich <vitalyd at gmail.com>
wrote:

      I am unclear whether the original question is specifically about
reachability of a and b from the constructor or whether the constructor was
shown to us to indicate that a and b are never null after construction
(assuming asserts are enabled).  If it's the former, your answer is correct
(that's what I meant by saying not sure if your reply was answering the
question).  If it's the latter, then I'm pretty sure my response is correct

    Again, according the JLS, you're incorrect. "a" and "b" will be non-null
when SomeService.finalize() executes. Why would you think otherwise?

    Bob
    Square is hiring!



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/8f2db91e/attachment.html>

From vitalyd at gmail.com  Sun May 13 19:10:55 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 13 May 2012 19:10:55 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEHHJEAA.davidcholmes@aapt.net.au>
References: <CAHjP37EpOEKqvL7GDB21rGUjvek_h3paEicOfdMV7HPLqho-QA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEHHJEAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37G4tEH4DKhPpSJykzJkGuzVOOnC17czLDwi78tKRhaY5g@mail.gmail.com>

Ok, thanks for the correction -- I must've remembered it being the same as
CLR.  In the CLR, it doesn't guarantee that references to 'a' and 'b' would
be null, but that they *may* be null due to undefined order of reclaimation
-- no explicit clearing of them needs to happen.

Cheers,

Vitaly


On Sun, May 13, 2012 at 6:28 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> The objects referred to by 'a' and 'b' will remain finalizer-reachable
> until after the finalizer runs and so can not be reclaimed. If they were to
> be reclaimed it would require that all references to them in finalizable
> objects be found and cleared, which is not practical.
>
> With regard to the OP, as long as the constructor completes normally, it
> is guaranteed that neither 'a' nor 'b' will be null when the finalizer
> runs.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
> Davidovich
> *Sent:* Monday, 14 May 2012 8:20 AM
> *To:* Bob Lee
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Object finalization
>
> perhaps I'm misremembering but there's no guarantee on the order in which
> objects are reclaimed.  When SomeService finalizer runs and assuming a and
> b were kept alive only by this instance of SomeService, I don't think
> there's any guarantee that a and b have not been reclaimed at this point
> already.  That's how the CLR finalization works, so perhaps I'm conflating
> the two.
>
> Sent from my phone
> On May 13, 2012 5:54 PM, "Bob Lee" <crazybob at crazybob.org> wrote:
>
>> On Sun, May 13, 2012 at 2:41 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>
>>> I am unclear whether the original question is specifically about
>>> reachability of a and b from the constructor or whether the constructor was
>>> shown to us to indicate that a and b are never null after construction
>>> (assuming asserts are enabled).  If it's the former, your answer is correct
>>> (that's what I meant by saying not sure if your reply was answering the
>>> question).  If it's the latter, then I'm pretty sure my response is correct
>>>
>> Again, according the JLS, you're incorrect. "a" and "b" will be non-null
>> when SomeService.finalize() executes. Why would you think otherwise?
>>
>> Bob
>> Square is hiring! <https://squareup.com/jobs>
>>
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120513/d9134019/attachment.html>

From zhong.j.yu at gmail.com  Sun May 13 23:34:31 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sun, 13 May 2012 22:34:31 -0500
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
References: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
Message-ID: <CACuKZqFph7cCGXUYaOEk0JsmP1JeX5yZDnjyhhodLpT=CtaOeg@mail.gmail.com>

If an exception can occur any where any time, it is impossible to
write code that can survive it and maintain invariants.

    lock
        x++;
        y++;
    unlock

If we have to worry that some exception may be thrown between x++ and
y++, we cannot write any program at all.

ThreadDeath is exactly such an exception.

Others include OutOfMemoryError and StackOverflowError - they are more
predictable, but still, we cannot afford to worry about them on every
`new` and every method call.

Zhong Yu

From heinz at javaspecialists.eu  Mon May 14 01:10:44 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 14 May 2012 08:10:44 +0300
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <CACuKZqFph7cCGXUYaOEk0JsmP1JeX5yZDnjyhhodLpT=CtaOeg@mail.gmail.com>
References: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
	<CACuKZqFph7cCGXUYaOEk0JsmP1JeX5yZDnjyhhodLpT=CtaOeg@mail.gmail.com>
Message-ID: <CACLL95rYM125cRoRJh=bgP4Te_amCVYGyQUJCauMc3mN_YvtAg@mail.gmail.com>

When you stop() a thread that has called wait(), it first reacquires
the monitor before bailing out.  The monitor is then automatically
unlocked again when you leave the scope.

However, Condition.await() does *not* reacquire the lock when you
stop() the thread.  When unlock() is then called on Lock as you exit
the scope, an IllegalMonitorStateException is then thrown.  I would
love to know if that is deliberate or a coding bug?

Anyway, my bet is that this is the culprit.  You can also see the
await() method in the stack trace.

Heinz

On 14/05/2012, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> If an exception can occur any where any time, it is impossible to
> write code that can survive it and maintain invariants.
>
>     lock
>         x++;
>         y++;
>     unlock
>
> If we have to worry that some exception may be thrown between x++ and
> y++, we cannot write any program at all.
>
> ThreadDeath is exactly such an exception.
>
> Others include OutOfMemoryError and StackOverflowError - they are more
> predictable, but still, we cannot afford to worry about them on every
> `new` and every method call.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz

From davidcholmes at aapt.net.au  Mon May 14 01:23:37 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 May 2012 15:23:37 +1000
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
	ExecutorCompletionService when slave threads killed.
In-Reply-To: <CACLL95rYM125cRoRJh=bgP4Te_amCVYGyQUJCauMc3mN_YvtAg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEHKJEAA.davidcholmes@aapt.net.au>

Heinz,

Dr Heinz M. Kabutz writes:
> When you stop() a thread that has called wait(), it first reacquires
> the monitor before bailing out.  The monitor is then automatically
> unlocked again when you leave the scope.

This is possible because the monitor reacquisition happens in the VM's
native code, not part of any Java code sequence.

> However, Condition.await() does *not* reacquire the lock when you
> stop() the thread.  When unlock() is then called on Lock as you exit
> the scope, an IllegalMonitorStateException is then thrown.  I would
> love to know if that is deliberate or a coding bug?

It is unavoidable due to the fact this is implemented in Java code. People
will say "put the lock re-acquisition in a finally block, that will fix it",
but that will only fix the case where the stop() hits while the thread is
actually blocked. If the stop() hits during any of the queue management code
you can easily get corrupt data structures.

It is impractical, if not impossible, to non-trivial write async-exception
safe code.

David
-----

> Anyway, my bet is that this is the culprit.  You can also see the
> await() method in the stack trace.
>
> Heinz
>
> On 14/05/2012, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> > If an exception can occur any where any time, it is impossible to
> > write code that can survive it and maintain invariants.
> >
> >     lock
> >         x++;
> >         y++;
> >     unlock
> >
> > If we have to worry that some exception may be thrown between x++ and
> > y++, we cannot write any program at all.
> >
> > ThreadDeath is exactly such an exception.
> >
> > Others include OutOfMemoryError and StackOverflowError - they are more
> > predictable, but still, we cannot afford to worry about them on every
> > `new` and every method call.
> >
> > Zhong Yu
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From mr.chrisvest at gmail.com  Mon May 14 02:14:58 2012
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Mon, 14 May 2012 08:14:58 +0200
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37G4tEH4DKhPpSJykzJkGuzVOOnC17czLDwi78tKRhaY5g@mail.gmail.com>
References: <CAHjP37EpOEKqvL7GDB21rGUjvek_h3paEicOfdMV7HPLqho-QA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEHHJEAA.davidcholmes@aapt.net.au>
	<CAHjP37G4tEH4DKhPpSJykzJkGuzVOOnC17czLDwi78tKRhaY5g@mail.gmail.com>
Message-ID: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>

Thanks guys,

I did indeed only include the constructor to show that neither `a` nor `b`
would be null after construction.

On 14 May 2012 01:10, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Ok, thanks for the correction -- I must've remembered it being the same as
> CLR.  In the CLR, it doesn't guarantee that references to 'a' and 'b' would
> be null, but that they *may* be null due to undefined order of reclaimation
> -- no explicit clearing of them needs to happen.
>
> Cheers,
>
> Vitaly
>
>
>
> On Sun, May 13, 2012 at 6:28 PM, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>> **
>> The objects referred to by 'a' and 'b' will remain finalizer-reachable
>> until after the finalizer runs and so can not be reclaimed. If they were to
>> be reclaimed it would require that all references to them in finalizable
>> objects be found and cleared, which is not practical.
>>
>> With regard to the OP, as long as the constructor completes normally, it
>> is guaranteed that neither 'a' nor 'b' will be null when the finalizer
>> runs.
>>
>> David
>>
>> -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Vitaly
>> Davidovich
>> *Sent:* Monday, 14 May 2012 8:20 AM
>> *To:* Bob Lee
>> *Cc:* concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Object finalization
>>
>> perhaps I'm misremembering but there's no guarantee on the order in which
>> objects are reclaimed.  When SomeService finalizer runs and assuming a and
>> b were kept alive only by this instance of SomeService, I don't think
>> there's any guarantee that a and b have not been reclaimed at this point
>> already.  That's how the CLR finalization works, so perhaps I'm conflating
>> the two.
>>
>> Sent from my phone
>> On May 13, 2012 5:54 PM, "Bob Lee" <crazybob at crazybob.org> wrote:
>>
>>> On Sun, May 13, 2012 at 2:41 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>>
>>>> I am unclear whether the original question is specifically about
>>>> reachability of a and b from the constructor or whether the constructor was
>>>> shown to us to indicate that a and b are never null after construction
>>>> (assuming asserts are enabled).  If it's the former, your answer is correct
>>>> (that's what I meant by saying not sure if your reply was answering the
>>>> question).  If it's the latter, then I'm pretty sure my response is correct
>>>>
>>> Again, according the JLS, you're incorrect. "a" and "b" will be non-null
>>> when SomeService.finalize() executes. Why would you think otherwise?
>>>
>>> Bob
>>> Square is hiring! <https://squareup.com/jobs>
>>>
>>>
>>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/88c63c64/attachment.html>

From davidcholmes at aapt.net.au  Mon May 14 02:22:28 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 May 2012 16:22:28 +1000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>

I should add the Vitaly's comments prompted me to remember that 'a' and 'b' might refer to objects that themselves have been finalized prior to the current finalizer running. This just reinforces how tricky finalization is.

David
  -----Original Message-----
  From: Chris Vest [mailto:mr.chrisvest at gmail.com]
  Sent: Monday, 14 May 2012 4:15 PM
  To: Vitaly Davidovich
  Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Object finalization


  Thanks guys,


  I did indeed only include the constructor to show that neither `a` nor `b` would be null after construction.


  On 14 May 2012 01:10, Vitaly Davidovich <vitalyd at gmail.com> wrote:

    Ok, thanks for the correction -- I must've remembered it being the same as CLR.  In the CLR, it doesn't guarantee that references to 'a' and 'b' would be null, but that they *may* be null due to undefined order of reclaimation -- no explicit clearing of them needs to happen.


    Cheers,


    Vitaly






    On Sun, May 13, 2012 at 6:28 PM, David Holmes <davidcholmes at aapt.net.au> wrote:

      The objects referred to by 'a' and 'b' will remain finalizer-reachable until after the finalizer runs and so can not be reclaimed. If they were to be reclaimed it would require that all references to them in finalizable objects be found and cleared, which is not practical.

      With regard to the OP, as long as the constructor completes normally, it is guaranteed that neither 'a' nor 'b' will be null when the finalizer runs. 

      David
        -----Original Message-----
        From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Vitaly Davidovich
        Sent: Monday, 14 May 2012 8:20 AM
        To: Bob Lee
        Cc: concurrency-interest at cs.oswego.edu
        Subject: Re: [concurrency-interest] Object finalization


        perhaps I'm misremembering but there's no guarantee on the order in which objects are reclaimed.  When SomeService finalizer runs and assuming a and b were kept alive only by this instance of SomeService, I don't think there's any guarantee that a and b have not been reclaimed at this point already.  That's how the CLR finalization works, so perhaps I'm conflating the two.

        Sent from my phone

        On May 13, 2012 5:54 PM, "Bob Lee" <crazybob at crazybob.org> wrote:

          On Sun, May 13, 2012 at 2:41 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

            I am unclear whether the original question is specifically about reachability of a and b from the constructor or whether the constructor was shown to us to indicate that a and b are never null after construction (assuming asserts are enabled).  If it's the former, your answer is correct (that's what I meant by saying not sure if your reply was answering the question).  If it's the latter, then I'm pretty sure my response is correct

          Again, according the JLS, you're incorrect. "a" and "b" will be non-null when SomeService.finalize() executes. Why would you think otherwise?

          Bob
          Square is hiring!







    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/0ad29e03/attachment.html>

From dawid.weiss at gmail.com  Mon May 14 02:59:51 2012
From: dawid.weiss at gmail.com (Dawid Weiss)
Date: Mon, 14 May 2012 08:59:51 +0200
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEHKJEAA.davidcholmes@aapt.net.au>
References: <CACLL95rYM125cRoRJh=bgP4Te_amCVYGyQUJCauMc3mN_YvtAg@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHKJEAA.davidcholmes@aapt.net.au>
Message-ID: <CAM21Rt86YRr+a=C6TYM_PKLhfAf_MRKmHyNe2z9_ugdQumsO=Q@mail.gmail.com>

Thanks for the discussion.

I was thinking much like Heinz -- that the lock should be reacquired
(and was surprised that it wasn't). David's arguments are clear to me
though.

While thread.stop() is an ugly, ugly way to fix stuff there is really
no alternative to it if you have a situation in which you run
third-party code and you don't want to allow any background threads to
survive (other than spawning a separate jvm, but that's another
issue). It is an interesting use case on its own -- what I need is a
facility like a "domain context" that could be shut down when no
longer needed. But with executors it is nearly impossible -- even if
you run in a separate class loader that could be gc-ed entirely, if an
executor is stored in a static reference, it keeps refs to slave
threads and these in turn cannot be killed (when they're interrupted
new ones fill up the thread buffer again). Of course it's also
possible to create a "chuck norris" type code which cannot (or is hard
to) be killed (catching ThreadDeath, respinning in a try-catch) but
this is rather uncommon while executors are everywhere.

There seems to be no way to clean up the slave threads and thus
somehow close the pool (interrupting them just refills the buffer with
new ones). Sure, I could override bootclasspath or do runtime bytecode
rewriting trickery to detect when executors are created (and then
shutdown them nicely) but it is so dirty and doesn't really protect
against similar situations in custom code. Eh.

Dawid



On Mon, May 14, 2012 at 7:23 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Heinz,
>
> Dr Heinz M. Kabutz writes:
>> When you stop() a thread that has called wait(), it first reacquires
>> the monitor before bailing out. ?The monitor is then automatically
>> unlocked again when you leave the scope.
>
> This is possible because the monitor reacquisition happens in the VM's
> native code, not part of any Java code sequence.
>
>> However, Condition.await() does *not* reacquire the lock when you
>> stop() the thread. ?When unlock() is then called on Lock as you exit
>> the scope, an IllegalMonitorStateException is then thrown. ?I would
>> love to know if that is deliberate or a coding bug?
>
> It is unavoidable due to the fact this is implemented in Java code. People
> will say "put the lock re-acquisition in a finally block, that will fix it",
> but that will only fix the case where the stop() hits while the thread is
> actually blocked. If the stop() hits during any of the queue management code
> you can easily get corrupt data structures.
>
> It is impractical, if not impossible, to non-trivial write async-exception
> safe code.
>
> David
> -----
>
>> Anyway, my bet is that this is the culprit. ?You can also see the
>> await() method in the stack trace.
>>
>> Heinz
>>
>> On 14/05/2012, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> > If an exception can occur any where any time, it is impossible to
>> > write code that can survive it and maintain invariants.
>> >
>> > ? ? lock
>> > ? ? ? ? x++;
>> > ? ? ? ? y++;
>> > ? ? unlock
>> >
>> > If we have to worry that some exception may be thrown between x++ and
>> > y++, we cannot write any program at all.
>> >
>> > ThreadDeath is exactly such an exception.
>> >
>> > Others include OutOfMemoryError and StackOverflowError - they are more
>> > predictable, but still, we cannot afford to worry about them on every
>> > `new` and every method call.
>> >
>> > Zhong Yu
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>>
>>
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From mikeb01 at gmail.com  Mon May 14 03:19:52 2012
From: mikeb01 at gmail.com (Michael Barker)
Date: Mon, 14 May 2012 08:19:52 +0100
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <CANPzfU-51MymW-OLK224YRtGJ6YepWQQ1Zs2Us+n-FW-1i3erA@mail.gmail.com>
References: <CANPzfU-EMjzPDzCTJfahV08dCe8J22mcZ4hQQa8EHbeCJfYJTg@mail.gmail.com>
	<CALwNKeRcD=Wf1Zp8yUrvddwXgf+v4FKTknP-g8huPa33PLV4ng@mail.gmail.com>
	<CANPzfU8XVMyy5i1n_aRwhRXSEdyTYFx+3QM3OgkpbvDDcL=Q1g@mail.gmail.com>
	<CALwNKeRbsJkm72nFekghmf8jNC+75QhNSOwiGbyR55G-h=QMNA@mail.gmail.com>
	<CANPzfU82dowyDLYsd0zQ87BygmW46P3YQRd2kCyagT5+XW=Z8w@mail.gmail.com>
	<CALwNKeTK+RPxdFwz70yjssa4mK50vrFpJymy5zd+64958xKMaQ@mail.gmail.com>
	<CANPzfU-51MymW-OLK224YRtGJ6YepWQQ1Zs2Us+n-FW-1i3erA@mail.gmail.com>
Message-ID: <CALwNKeTpgxfKcUEnkHOfggNRfnbwfSj2+-ha5aZpEBOTEcqdzw@mail.gmail.com>

> The problem with batch dequeues is that if one of the messages fail we need
> to be at a stable state, and doing that would mean store away the remaining
> batch, which would bump the processors size by atleast a reference, which
> can be expensive if you have millions of them.

If you are will to stay away from the standard Java collections API,
then I was thinking of a call with a more functional style.  E.g.
(pseudo code)

    public void foreach(Callback callback) {
        Node current = head;

        if (current.next == null) {
            return;
        }

        try {
            do {
                Object value = current.value;
                callback.onEvent(value);
                current = current.next;
            } while (current.next != null);
        } finally {
            updateHead(current);  // Do the appropriate thread-safe
                                            // update to head
        }
    }

    private static interface Callback
    {
        void onMessage(Object o);
    }

In the above case, if an exception thrown when handling the message,
then the message that caused the exception is redelivered.  The
collection is then responsible for maintaining a stable state in the
case of an exception and the definition of that behaviour is part of
the contract for the collection.

I think there is also an interesting optimisation here.  The reason
I've added the short circuit check at the top of the method is that I
think it removes the only possible case where you could have write
contention with producers and consumers.  The only time a consumer and
a producer would contend on a write would be if the queue was empty.
I.e. head == tail.  If we remove that case from the consumer then
producers and consumers should never have a write conflict.  The
updateHead() method used by the consumer may not need a CAS, it is
possible that you could get away with a lazySet, which would certainly
improve performance.  Someone should check my reasoning though.

> It's an interesting problem though. I've been thinking about how to handle
> producer conflicts as cheap as possible, as there are no consumer conflicts.

That's a tough one.  The most complicated code in the Disruptor is
dealing with this case and we've ended up with 2 strategies based on
the ratio of producer threads to available cores. With an array-backed
queue this is easier, but I think for your use case you need something
list-backed.

Mike.

From davidcholmes at aapt.net.au  Mon May 14 03:21:19 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 14 May 2012 17:21:19 +1000
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
	ExecutorCompletionService when slave threads killed.
In-Reply-To: <CAM21Rt86YRr+a=C6TYM_PKLhfAf_MRKmHyNe2z9_ugdQumsO=Q@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEHMJEAA.davidcholmes@aapt.net.au>

If it is any consolation AppContext uses a similar approach and can also hit problems because of stop(). But at least there we don't attempt to reuse any objects that were in use by the threads that got killed. I confess I'm not completely clear on your Executor usage here.

Generally Thread.stop does far more damage than incidental non-malicious threads; and malicious threads can just ignore any exception you throw at them via Thread.stop.

Aside: for a while now there's been some background thought on how to fix this for the more common cases of StackOverflowError and possibly OutOfMemoryError. Handling OOME is a somewhat more tractable problem at least in lower-level library code. StackOverflowError is rather nasty and will probably need some VM assistance.

David
-----

> -----Original Message-----
> From: Dawid Weiss [mailto:dawid.weiss at gmail.com]
> Sent: Monday, 14 May 2012 5:00 PM
> To: dholmes at ieee.org
> Cc: Dr Heinz M. Kabutz; Zhong Yu; concurrency-interest
> Subject: Re: [concurrency-interest] Hung progress in ThreadPoolExecutor
> ExecutorCompletionService when slave threads killed.
> 
> 
> Thanks for the discussion.
> 
> I was thinking much like Heinz -- that the lock should be reacquired
> (and was surprised that it wasn't). David's arguments are clear to me
> though.
> 
> While thread.stop() is an ugly, ugly way to fix stuff there is really
> no alternative to it if you have a situation in which you run
> third-party code and you don't want to allow any background threads to
> survive (other than spawning a separate jvm, but that's another
> issue). It is an interesting use case on its own -- what I need is a
> facility like a "domain context" that could be shut down when no
> longer needed. But with executors it is nearly impossible -- even if
> you run in a separate class loader that could be gc-ed entirely, if an
> executor is stored in a static reference, it keeps refs to slave
> threads and these in turn cannot be killed (when they're interrupted
> new ones fill up the thread buffer again). Of course it's also
> possible to create a "chuck norris" type code which cannot (or is hard
> to) be killed (catching ThreadDeath, respinning in a try-catch) but
> this is rather uncommon while executors are everywhere.
> 
> There seems to be no way to clean up the slave threads and thus
> somehow close the pool (interrupting them just refills the buffer with
> new ones). Sure, I could override bootclasspath or do runtime bytecode
> rewriting trickery to detect when executors are created (and then
> shutdown them nicely) but it is so dirty and doesn't really protect
> against similar situations in custom code. Eh.
> 
> Dawid
> 
> 
> 
> On Mon, May 14, 2012 at 7:23 AM, David Holmes 
> <davidcholmes at aapt.net.au> wrote:
> > Heinz,
> >
> > Dr Heinz M. Kabutz writes:
> >> When you stop() a thread that has called wait(), it first reacquires
> >> the monitor before bailing out.  The monitor is then automatically
> >> unlocked again when you leave the scope.
> >
> > This is possible because the monitor reacquisition happens in the VM's
> > native code, not part of any Java code sequence.
> >
> >> However, Condition.await() does *not* reacquire the lock when you
> >> stop() the thread.  When unlock() is then called on Lock as you exit
> >> the scope, an IllegalMonitorStateException is then thrown.  I would
> >> love to know if that is deliberate or a coding bug?
> >
> > It is unavoidable due to the fact this is implemented in Java 
> code. People
> > will say "put the lock re-acquisition in a finally block, that 
> will fix it",
> > but that will only fix the case where the stop() hits while the 
> thread is
> > actually blocked. If the stop() hits during any of the queue 
> management code
> > you can easily get corrupt data structures.
> >
> > It is impractical, if not impossible, to non-trivial write 
> async-exception
> > safe code.
> >
> > David
> > -----
> >
> >> Anyway, my bet is that this is the culprit.  You can also see the
> >> await() method in the stack trace.
> >>
> >> Heinz
> >>
> >> On 14/05/2012, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> >> > If an exception can occur any where any time, it is impossible to
> >> > write code that can survive it and maintain invariants.
> >> >
> >> >     lock
> >> >         x++;
> >> >         y++;
> >> >     unlock
> >> >
> >> > If we have to worry that some exception may be thrown between x++ and
> >> > y++, we cannot write any program at all.
> >> >
> >> > ThreadDeath is exactly such an exception.
> >> >
> >> > Others include OutOfMemoryError and StackOverflowError - 
> they are more
> >> > predictable, but still, we cannot afford to worry about them on every
> >> > `new` and every method call.
> >> >
> >> > Zhong Yu
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >>
> >>
> >> --
> >> Dr Heinz M. Kabutz (PhD CompSci)
> >> Author of "The Java(tm) Specialists' Newsletter"
> >> Sun Java Champion
> >> IEEE Certified Software Development Professional
> >> http://www.javaspecialists.eu
> >> Tel: +30 69 75 595 262
> >> Skype: kabutz
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 



From william.louth at jinspired.com  Mon May 14 04:17:39 2012
From: william.louth at jinspired.com (William Louth (JINSPIRED.COM))
Date: Mon, 14 May 2012 10:17:39 +0200
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEHMJEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEHMJEAA.davidcholmes@aapt.net.au>
Message-ID: <4FB0BFA3.3060909@jinspired.com>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/e8ffa2f5/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: supervise.pdf
Type: application/pdf
Size: 289253 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/e8ffa2f5/attachment-0001.pdf>

From dawid.weiss at gmail.com  Mon May 14 04:39:44 2012
From: dawid.weiss at gmail.com (Dawid Weiss)
Date: Mon, 14 May 2012 10:39:44 +0200
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEHMJEAA.davidcholmes@aapt.net.au>
References: <CAM21Rt86YRr+a=C6TYM_PKLhfAf_MRKmHyNe2z9_ugdQumsO=Q@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEHMJEAA.davidcholmes@aapt.net.au>
Message-ID: <CAM21Rt836Jy50bgCW53+FUTMy9vYg7cuOvENdJjwAhuYiH-iwg@mail.gmail.com>

> because of stop(). But at least there we don't attempt to reuse any objects that were in use by the threads that got killed. I confess I'm not completely clear on your Executor usage here.

If I had full control over the tested code then this wouldn't be a
problem (because I'd react to interrupt properly and shut down the
executor). The code I'm using Thread.stop() for is much like junit --
it's a test runner so it executes arbitrary code (it has no control or
knowledge of).

Like I said, it probably could be solved by weaving stuff into that
code at runtime, I just looked for something that woud avoid this. In
99% of the cases code should react properly to Thread.interrupt, the
rest is, well, badly written tests.

> Generally Thread.stop does far more damage than incidental non-malicious threads; and malicious threads can just ignore any exception you throw at them via Thread.stop.

I agree. With a test framework left over background threads can affect
other tests further down the execution path and this isn't nice
because it makes debugging really hard (failing test passes in
isolation). I thought of a few alternatives, the "safe" side of the
spectrum is to just detect thread leaks and simply ignore any tests
after that (with an appropriate message). It's a treadeoff, as always.

> Aside: for a while now there's been some background thought on how to fix this for the more common cases of StackOverflowError and possibly OutOfMemoryError. Handling OOME is a somewhat more tractable problem at least in lower-level library code. StackOverflowError is rather nasty and will probably need some VM assistance.

Ugh. Didn't even think of that. Nasty.

Dawid


From viktor.klang at gmail.com  Mon May 14 04:47:36 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 14 May 2012 10:47:36 +0200
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <CAM21Rt836Jy50bgCW53+FUTMy9vYg7cuOvENdJjwAhuYiH-iwg@mail.gmail.com>
References: <CAM21Rt86YRr+a=C6TYM_PKLhfAf_MRKmHyNe2z9_ugdQumsO=Q@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEHMJEAA.davidcholmes@aapt.net.au>
	<CAM21Rt836Jy50bgCW53+FUTMy9vYg7cuOvENdJjwAhuYiH-iwg@mail.gmail.com>
Message-ID: <CANPzfU83NPXCFxp6MSjSc5hVkSsrkif177O8S=nv3PBrfUat1A@mail.gmail.com>

On Mon, May 14, 2012 at 10:39 AM, Dawid Weiss <dawid.weiss at gmail.com> wrote:

> > because of stop(). But at least there we don't attempt to reuse any
> objects that were in use by the threads that got killed. I confess I'm not
> completely clear on your Executor usage here.
>
> If I had full control over the tested code then this wouldn't be a
> problem (because I'd react to interrupt properly and shut down the
> executor). The code I'm using Thread.stop() for is much like junit --
> it's a test runner so it executes arbitrary code (it has no control or
> knowledge of).
>
> Like I said, it probably could be solved by weaving stuff into that
> code at runtime, I just looked for something that woud avoid this. In
> 99% of the cases code should react properly to Thread.interrupt, the
> rest is, well, badly written tests.
>
> > Generally Thread.stop does far more damage than incidental non-malicious
> threads; and malicious threads can just ignore any exception you throw at
> them via Thread.stop.
>
> I agree. With a test framework left over background threads can affect
> other tests further down the execution path and this isn't nice
> because it makes debugging really hard (failing test passes in
> isolation). I thought of a few alternatives, the "safe" side of the
> spectrum is to just detect thread leaks and simply ignore any tests
> after that (with an appropriate message). It's a treadeoff, as always.
>
> > Aside: for a while now there's been some background thought on how to
> fix this for the more common cases of StackOverflowError and possibly
> OutOfMemoryError. Handling OOME is a somewhat more tractable problem at
> least in lower-level library code. StackOverflowError is rather nasty and
> will probably need some VM assistance.
>

It was a horrible mistake to make all Throwables Catchable.


>
> Ugh. Didn't even think of that. Nasty.
>
> Dawid
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/7c15871a/attachment.html>

From crazybob at crazybob.org  Mon May 14 14:01:10 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 14 May 2012 11:01:10 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
Message-ID: <CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>

On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> I should add the Vitaly's comments prompted me to remember that 'a' and
> 'b' might refer to objects that themselves have been finalized prior to the
> current finalizer running. This just reinforces how tricky finalization is.
>

Indeed, the finalizers can run in any order, independent of the structure
of the object graph.

For those who are interested in learning more, I cover that and half a
dozen other reasons not to use finalizers in this talk:
http://www.parleys.com/#id=2657&st=5

Thanks,
Bob
Square is hiring! <https://squareup.com/jobs>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/5a571555/attachment.html>

From gregg at cytetech.com  Mon May 14 16:44:00 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 14 May 2012 15:44:00 -0500
Subject: [concurrency-interest] Hung progress in ThreadPoolExecutor
 ExecutorCompletionService when slave threads killed.
In-Reply-To: <CACuKZqFph7cCGXUYaOEk0JsmP1JeX5yZDnjyhhodLpT=CtaOeg@mail.gmail.com>
References: <CAM21Rt92ep_azMKkRKh1J4AbeCmwbPLuRuCdw52=FN6rPA2pCw@mail.gmail.com>
	<CACuKZqFph7cCGXUYaOEk0JsmP1JeX5yZDnjyhhodLpT=CtaOeg@mail.gmail.com>
Message-ID: <4FB16E90.3010405@cytetech.com>

On 5/13/2012 10:34 PM, Zhong Yu wrote:
> If an exception can occur any where any time, it is impossible to
> write code that can survive it and maintain invariants.
>
>      lock
>          x++;
>          y++;
>      unlock
>
> If we have to worry that some exception may be thrown between x++ and
> y++, we cannot write any program at all.
>
> ThreadDeath is exactly such an exception.
>
> Others include OutOfMemoryError and StackOverflowError - they are more
> predictable, but still, we cannot afford to worry about them on every
> `new` and every method call.

This, for me, is why STM and other forms of transactional state management are 
needed.  It should be simple to say "All of this is an atomic view" which the VM 
will then maintain as consistent, no matter what kind of fault occurs.

Gregg Wonderly

From hans.boehm at hp.com  Mon May 14 16:49:59 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 14 May 2012 20:49:59 +0000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>

But things are considerably worse than that.  References only solve the easy problem.  The most serious problem in my mind is that finalizers can run, and references can be enqueued, while e.g. a method of the object being finalized is still running.  The fact that the method is still running does not ensure that the object itself is still reachable; the method may only need fields that have already been cached in registers to complete.  This affects finalizers and java.lang.ref equally, and explains why probably the large majority of code using either one is broken.

I gave a JavaOne talk about this many years ago (slides at http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).  It is possible, though really ugly and slow to work around the problem.  I don't believe anyone does.  I was told just after I gave the talk that this explained a problem somebody had been trying to track down, so I suspect this actually happens occasionally in the wild, though probably not on x86-32.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Bob Lee
Sent: Monday, May 14, 2012 11:01 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Object finalization

On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:
I should add the Vitaly's comments prompted me to remember that 'a' and 'b' might refer to objects that themselves have been finalized prior to the current finalizer running. This just reinforces how tricky finalization is.

Indeed, the finalizers can run in any order, independent of the structure of the object graph.

For those who are interested in learning more, I cover that and half a dozen other reasons not to use finalizers in this talk: http://www.parleys.com/#id=2657&st=5

Thanks,
Bob
Square is hiring!<https://squareup.com/jobs>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/e1cb6850/attachment.html>

From gregg at cytetech.com  Mon May 14 17:06:48 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 14 May 2012 16:06:48 -0500
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
Message-ID: <4FB173E8.4060608@cytetech.com>

On 5/14/2012 3:49 PM, Boehm, Hans wrote:
> But things are considerably worse than that. References only solve the easy
> problem. The most serious problem in my mind is that finalizers can run, and
> references can be enqueued, while e.g. a method of the object being finalized is
> still running. The fact that the method is still running does not ensure that
> the object itself is still reachable; the method may only need fields that have
> already been cached in registers to complete. This affects finalizers and
> java.lang.ref equally, and explains why probably the large majority of code
> using either one is broken.
>
> I gave a JavaOne talk about this many years ago (slides at
> http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf). It
> is possible, though really ugly and slow to work around the problem. I don?t
> believe anyone does. I was told just after I gave the talk that this explained a
> problem somebody had been trying to track down, so I suspect this actually
> happens occasionally in the wild, though probably not on x86-32.
>
> Hans
>
> *From:*concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Bob Lee
> *Sent:* Monday, May 14, 2012 11:01 AM
> *To:* dholmes at ieee.org
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Object finalization
>
> On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au
> <mailto:davidcholmes at aapt.net.au>> wrote:
>
>     I should add the Vitaly's comments prompted me to remember that 'a' and 'b'
>     might refer to objects that themselves have been finalized prior to the
>     current finalizer running. This just reinforces how tricky finalization is.
>
> Indeed, the finalizers can run in any order, independent of the structure of the
> object graph.
>
> For those who are interested in learning more, I cover that and half a dozen
> other reasons not to use finalizers in this talk:
> http://www.parleys.com/#id=2657&st=5 <http://www.parleys.com/#id=2657&st=5>

I've tried, over time, and many versions of Java, to use the class that I've 
posted here before, called ReferenceTracker.  It is intended to be similar to a 
WeakRef kind of mechanism, but includes cleanup.  So, you do

public abstract class MyTracker extends ReferenceTracker<SocketHolder,Socket> {}

MyTracker trk = new MyTracker() {
	public void released( Socket s ) {
		try {
			s.close();
		} catch( exception ex ) {
			logException(ex);
		}
	}
};

...

Socket s = ...

SocketHolder sh = new SocketHolder(s);
trk.trackReference( sh, s );

It uses a Phantom reference to 'sh', and a hard reference to 's'
Then, you can have the callback to released() when 'sh' is no longer strongly 
referenced.

This really should be possible to do.  But, as Hans says, unless you hold a 
strong reference to 'trk', and 'sh', outside of method level binding, this fails 
miserably with the Phantom reference being queued way before the end of the life 
of the object.

Gregg Wonderly

From vitalyd at gmail.com  Mon May 14 18:05:29 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 14 May 2012 18:05:29 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
Message-ID: <CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>

Raymond Chen (MSFT) has an interesting series of posts on finalization,
including this one which demonstrates your example Hans:
http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx

CLR team even added GC.KeepAlive() to try and alleviate some causes of this
race.  Then there's a whole slew of bugs that can happen due to memory
write ordering/visibility since finalizer thread is subject to same issues
as normal threads.  Then in CLR finalizer can run even if constructor fails
(I believe JVM does not?), possibly causing broken state/invariants to be
observed.  Finalizers are one of those well intentioned ideas that goes
haywire ... :)

Sent from my phone
On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

>  But things are considerably worse than that.  References only solve the
> easy problem.  The most serious problem in my mind is that finalizers can
> run, and references can be enqueued, while e.g. a method of the object
> being finalized is still running.  The fact that the method is still
> running does not ensure that the object itself is still reachable; the
> method may only need fields that have already been cached in registers to
> complete.  This affects finalizers and java.lang.ref equally, and explains
> why probably the large majority of code using either one is broken.****
>
> ** **
>
> I gave a JavaOne talk about this many years ago (slides at
> http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).
> It is possible, though really ugly and slow to work around the problem.  I
> don?t believe anyone does.  I was told just after I gave the talk that this
> explained a problem somebody had been trying to track down, so I suspect
> this actually happens occasionally in the wild, though probably not on
> x86-32.****
>
> ** **
>
> Hans****
>
> ** **
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Bob Lee
> *Sent:* Monday, May 14, 2012 11:01 AM
> *To:* dholmes at ieee.org
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Object finalization****
>
> ** **
>
> On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:****
>
>  I should add the Vitaly's comments prompted me to remember that 'a' and
> 'b' might refer to objects that themselves have been finalized prior to the
> current finalizer running. This just reinforces how tricky finalization is.
> ****
>
>  ** **
>
> Indeed, the finalizers can run in any order, independent of the structure
> of the object graph.****
>
> ** **
>
> For those who are interested in learning more, I cover that and half a
> dozen other reasons not to use finalizers in this talk:
> http://www.parleys.com/#id=2657&st=5****
>
> ** **
>
> Thanks,****
>
> Bob ****
>
> Square is hiring! <https://squareup.com/jobs>****
>
> ** **
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/256b1cab/attachment-0001.html>

From hans.boehm at hp.com  Mon May 14 20:00:20 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 15 May 2012 00:00:20 +0000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>

In my view, the hard problem is finalization while a method is running.  Fixing that the obvious way has a probably small, but nonzero optimization cost.  (Essentially no dead variable elimination on reference variables.  Guesses among the optimization experts in the C++ committee were around a 1% slowdown to support a semi-esoteric feature.  I don't know of any real measurements.)  We came up with some compromises in a C++ context in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2261.html .

I think the other issues could be solved fairly easily.  In my view Modula 3 adequately solved the ordering issue by insisting on ordered finalization, which is essentially what you now get out of java.lang.ref, though in a less direct way.  As far as I know, Modula-3 users generally agreed with that assessment, but Java and C# designers did not, and came up with what I consider to be a much worse point in the design space, at least for finalization itself.  I also don't see why, given a solution to the early finalization problem, it would be difficult to ensure that the last object access happens before finalization.  Standard garbage collectors probably have each thread stop operation synchronize with finalization anyway.

Hans

From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
Sent: Monday, May 14, 2012 3:05 PM
To: Boehm, Hans
Cc: concurrency-interest at cs.oswego.edu; Bob Lee; dholmes at ieee.org
Subject: Re: [concurrency-interest] Object finalization


Raymond Chen (MSFT) has an interesting series of posts on finalization, including this one which demonstrates your example Hans: http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx

CLR team even added GC.KeepAlive() to try and alleviate some causes of this race.  Then there's a whole slew of bugs that can happen due to memory write ordering/visibility since finalizer thread is subject to same issues as normal threads.  Then in CLR finalizer can run even if constructor fails (I believe JVM does not?), possibly causing broken state/invariants to be observed.  Finalizers are one of those well intentioned ideas that goes haywire ... :)

Sent from my phone
On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com<mailto:hans.boehm at hp.com>> wrote:
But things are considerably worse than that.  References only solve the easy problem.  The most serious problem in my mind is that finalizers can run, and references can be enqueued, while e.g. a method of the object being finalized is still running.  The fact that the method is still running does not ensure that the object itself is still reachable; the method may only need fields that have already been cached in registers to complete.  This affects finalizers and java.lang.ref equally, and explains why probably the large majority of code using either one is broken.

I gave a JavaOne talk about this many years ago (slides at http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).  It is possible, though really ugly and slow to work around the problem.  I don't believe anyone does.  I was told just after I gave the talk that this explained a problem somebody had been trying to track down, so I suspect this actually happens occasionally in the wild, though probably not on x86-32.

Hans

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Bob Lee
Sent: Monday, May 14, 2012 11:01 AM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Object finalization

On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:
I should add the Vitaly's comments prompted me to remember that 'a' and 'b' might refer to objects that themselves have been finalized prior to the current finalizer running. This just reinforces how tricky finalization is.

Indeed, the finalizers can run in any order, independent of the structure of the object graph.

For those who are interested in learning more, I cover that and half a dozen other reasons not to use finalizers in this talk: http://www.parleys.com/#id=2657&st=5

Thanks,
Bob
Square is hiring!<https://squareup.com/jobs>


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/123780c9/attachment.html>

From vitalyd at gmail.com  Mon May 14 23:04:09 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 14 May 2012 23:04:09 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
Message-ID: <CAHjP37HSx=0KEdZ0DLZSrihq-F+5jj3y=1jrPC+31Gd7uNguLg@mail.gmail.com>

It sounds like delay_finalization() in your link serves the same purpose as
GC.KeepAlive(this) in the CLR.  As you point out in that paper,
artificially extending the lifetime of the this reference would be costly
on architectures with a small register set.  In addition, under heavy load
where this race is more likely to occur you also risk an OOM if the object
graph of "this" is very large.  I'm not sure how often this race is
actually a problem in practice (people are usually encouraged to not impl a
finalized or if they do, keep it dead simple), so perhaps a developer hint
(ala delay_finalization/GC.KeepAlive) is a decent compromise.

As for mem ordering/visibility, are you suggesting that there should always
be a membar before the finalizer picks up the reference to process? Might
get kind of expensive on many core (especially NUMA) machines and if, e.g.,
multiple finalizer threads are ever used.  If multiple finalizer threads
are used, I don't see why you'd want them to synchronize with GC as
presumably they could run concurrently with either GC threads or even
mutators.  If we're saying that ease of use/correctness is more important
than performance for finalization processing, then it makes sense.  It's a
tricky problem as ultimately you'll find competing use cases (perf vs ease
of use).

Cheers

Sent from my phone
On May 14, 2012 8:01 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

>  In my view, the hard problem is finalization while a method is running.
> Fixing that the obvious way has a probably small, but nonzero optimization
> cost.  (Essentially no dead variable elimination on reference variables.
> Guesses among the optimization experts in the C++ committee were around a
> 1% slowdown to support a semi-esoteric feature.  I don?t know of any real
> measurements.)  We came up with some compromises in a C++ context in
> http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2261.html .****
>
> ** **
>
> I think the other issues could be solved fairly easily.  In my view Modula
> 3 adequately solved the ordering issue by insisting on ordered
> finalization, which is essentially what you now get out of java.lang.ref,
> though in a less direct way.  As far as I know, Modula-3 users generally
> agreed with that assessment, but Java and C# designers did not, and came up
> with what I consider to be a much worse point in the design space, at least
> for finalization itself.  I also don?t see why, given a solution to the
> early finalization problem, it would be difficult to ensure that the last
> object access happens before finalization.  Standard garbage collectors
> probably have each thread stop operation synchronize with finalization
> anyway.****
>
> ** **
>
> Hans****
>
> ** **
>
> *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com]
> *Sent:* Monday, May 14, 2012 3:05 PM
> *To:* Boehm, Hans
> *Cc:* concurrency-interest at cs.oswego.edu; Bob Lee; dholmes at ieee.org
> *Subject:* Re: [concurrency-interest] Object finalization****
>
> ** **
>
> Raymond Chen (MSFT) has an interesting series of posts on finalization,
> including this one which demonstrates your example Hans:
> http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx****
>
> CLR team even added GC.KeepAlive() to try and alleviate some causes of
> this race.  Then there's a whole slew of bugs that can happen due to memory
> write ordering/visibility since finalizer thread is subject to same issues
> as normal threads.  Then in CLR finalizer can run even if constructor fails
> (I believe JVM does not?), possibly causing broken state/invariants to be
> observed.  Finalizers are one of those well intentioned ideas that goes
> haywire ... :)****
>
> Sent from my phone****
>
> On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:****
>
> But things are considerably worse than that.  References only solve the
> easy problem.  The most serious problem in my mind is that finalizers can
> run, and references can be enqueued, while e.g. a method of the object
> being finalized is still running.  The fact that the method is still
> running does not ensure that the object itself is still reachable; the
> method may only need fields that have already been cached in registers to
> complete.  This affects finalizers and java.lang.ref equally, and explains
> why probably the large majority of code using either one is broken.****
>
>  ****
>
> I gave a JavaOne talk about this many years ago (slides at
> http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).
> It is possible, though really ugly and slow to work around the problem.  I
> don?t believe anyone does.  I was told just after I gave the talk that this
> explained a problem somebody had been trying to track down, so I suspect
> this actually happens occasionally in the wild, though probably not on
> x86-32.****
>
>  ****
>
> Hans****
>
>  ****
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Bob Lee
> *Sent:* Monday, May 14, 2012 11:01 AM
> *To:* dholmes at ieee.org
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Object finalization****
>
>  ****
>
> On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:****
>
>  I should add the Vitaly's comments prompted me to remember that 'a' and
> 'b' might refer to objects that themselves have been finalized prior to the
> current finalizer running. This just reinforces how tricky finalization is.
> ****
>
>   ****
>
> Indeed, the finalizers can run in any order, independent of the structure
> of the object graph.****
>
>  ****
>
> For those who are interested in learning more, I cover that and half a
> dozen other reasons not to use finalizers in this talk:
> http://www.parleys.com/#id=2657&st=5****
>
>  ****
>
> Thanks,****
>
> Bob ****
>
> Square is hiring! <https://squareup.com/jobs>****
>
>  ****
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest****
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/c91d38c3/attachment-0001.html>

From kimo at webnetic.net  Mon May 14 23:24:05 2012
From: kimo at webnetic.net (Kimo Crossman)
Date: Mon, 14 May 2012 20:24:05 -0700
Subject: [concurrency-interest] Garbage collection for parallel data struc
Message-ID: <CALV1V4_rg5g+gkRHd6FNHLBShH2Mu4mDqGdhJEFRKP+0-X_EJw@mail.gmail.com>

People may find this upcoming paper interesting by a notable researcher and
from a multicore research group:

Can Parallel Data Structures Rely on Automatic Memory
Managers?

Erez Petrank
Dept. of Computer Science
Technion, Israel
erez at cs.technion.ac.il

http://safari.ece.cmu.edu/MSPC2012/erez_abstract.pdf
MSPC?12, June 16, 2012, Beijing, China.

ABSTRACT
The complexity of parallel data structures is often measured
by two major factors: the throughput they provide and the
progress they guarantee. Progress guarantees are particu-
larly important for systems that require responsiveness such
as real-time systems, operating systems, interactive systems,
etc. Notions of progress guarantees such as lock-freedom,
wait-freedom, and obstruction-freedom that provide di er-
ent levels of guarantees have been proposed in the literature
[4, 6]. Concurrent access (and furthermore, optimistic ac-
cess) to shared objects makes the management of memory
one of the more complex aspects of concurrent algorithms
design. The use of automatic memory management greatly
simpli es such algorithms [11, 3, 2, 9]. However, while the
existence of lock-free garbage collection has been demon-
strated [5], the existence of a practical automatic memory
manager that supports lock-free or wait-free algorithms is
still open. Furthermore, known schemes for manual recla-
mation of unused objects are di cult to use and impose a
signi cant overhead on the execution [10].


It turns out that the memory management community
is not fully aware of how dire the need is for memory man-
agers that support progress guarantees for the design of concurrent data
structures.

Likewise, designers of concurrent
data structures are not always aware of the fact that mem-
ory management with support for progress guarantees is not
available.

Closing this gap between these two communities
is a major open problem for both communities.
In this talk we will examine the memory management
needs of concurrent algorithms.

Next, we will discuss how state-of-the-art research and practice deal with
the fact that
an important piece of technology is missing (e.g., [7, 1]). Fi-
nally, we will survey the currently available pieces in this
puzzle (e.g., [13, 12, 8]) and specify which pieces are miss-
ing.

This open problem is arguably the greatest challenge
facing the memory management community today.


Copyright 2012 ACM 978-1-4503-1219-6/12/06 ...$10.00.
Categories and Subject Descriptors
D.3.3 [Language Constructs and Features]: Dynamic
storage management, Concurrent programming structures;
D.3.4 [Processors]: Memory management (Garbage Collec-
tion); D.4.2 [Storage Management]: Garbage Collection
General Terms
Algorithms, Design, Performance, Reliability.


1. REFERENCES
[1] D. F. Bacon, P. Cheng, and V. Rajan. A real-time
garbage collector with low overhead and consistent
utilization. In POPL, 2003.
[2] F. Ellen, P. Fatourou, E. Ruppert, and F. van Breugel.
Non-blocking binary search trees. In PODC , 2010.
[3] T. L. Harris. A pragmatic implementation of
non-blocking linked-lists. In DISC, 2001.
[4] M. Herlihy. Wait-free synchronization. ACM Trans.
Program. Lang. Syst., 13(1):124{149, 1991.
[5] M. Herlihy and J. E. B. Moss. Lock-free garbage
collection for multiprocessors. IEEE Trans. Parallel
Distrib. Syst., 3(3):304{311, 1992.
[6] M. Herlihy and N. Shavit. The Art of Multiprocessor
Programming. Morgan Kaufmann, 2008.
[7] R. L. Hudson and J. E. B. Moss. Sapphire: Copying
garbage collection without stopping the world.
Concurrency and Computation: Practice and
Experience, 15(3{5):223{261, 2003.
[8] G. Kliot, E. Petrank, and B. Steensgaard. A lock-free,
concurrent, and incremental stack scanning
mechanism for garbage collectors. Operating Systems
Review, 43(3):3{13, 2009.
[9] A. Kogan and E. Petrank. Wait-free queues with
multiple enqueuers and dequeuers. In PPOPP, 2011.
[10] M. M. Michael. Hazard pointers: Safe memory
reclamation for lock-free objects. IEEE Trans. Parallel
Distrib. Syst., 15(6):491{504, 2004.
[11] M. M. Michael and M. L. Scott. Simple, fast, and
practical non-blocking and blocking concurrent queue
algorithms. In PODC, 1996.
[12] E. Petrank, M. Musuvathi, and B. Steensgaard.
Progress guarantee for parallel programs via bounded
lock-freedom. In PLDI, 2009.
[13] F. Pizlo, E. Petrank, and B. Steensgaard. A study of
concurrent real-time garbage collectors. In PLDI 2008.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120514/f66b2008/attachment.html>

From elizarov at devexperts.com  Tue May 15 03:35:09 2012
From: elizarov at devexperts.com (Roman Elizarov)
Date: Tue, 15 May 2012 07:35:09 +0000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>,
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
Message-ID: <A43565F3-1A01-4C96-A473-AC704DB1B0F4@devexperts.com>

I wonder what are the legitimate use-cases for finalization? The actual *usage* of finalization in Java runtime is deeply flawed, because finalizers that reclaim native resources don't have a chance to run before you run out of native resources. For example, the code that leaks FileInputStream objects without closing them seems to work correctly on small heaps, but crashes with different JVM options, running out of native fds.

So, are there any sound use-cases for finalizers at all?

On 15.05.2012, at 2:05, "Boehm, Hans" <hans.boehm at hp.com<mailto:hans.boehm at hp.com>> wrote:

In my view, the hard problem is finalization while a method is running.  Fixing that the obvious way has a probably small, but nonzero optimization cost.  (Essentially no dead variable elimination on reference variables.  Guesses among the optimization experts in the C++ committee were around a 1% slowdown to support a semi-esoteric feature.  I don?t know of any real measurements.)  We came up with some compromises in a C++ context in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2261.html .

I think the other issues could be solved fairly easily.  In my view Modula 3 adequately solved the ordering issue by insisting on ordered finalization, which is essentially what you now get out of java.lang.ref, though in a less direct way.  As far as I know, Modula-3 users generally agreed with that assessment, but Java and C# designers did not, and came up with what I consider to be a much worse point in the design space, at least for finalization itself.  I also don?t see why, given a solution to the early finalization problem, it would be difficult to ensure that the last object access happens before finalization.  Standard garbage collectors probably have each thread stop operation synchronize with finalization anyway.

Hans

From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
Sent: Monday, May 14, 2012 3:05 PM
To: Boehm, Hans
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>; Bob Lee; dholmes at ieee.org<mailto:dholmes at ieee.org>
Subject: Re: [concurrency-interest] Object finalization


Raymond Chen (MSFT) has an interesting series of posts on finalization, including this one which demonstrates your example Hans: http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx

CLR team even added GC.KeepAlive() to try and alleviate some causes of this race.  Then there's a whole slew of bugs that can happen due to memory write ordering/visibility since finalizer thread is subject to same issues as normal threads.  Then in CLR finalizer can run even if constructor fails (I believe JVM does not?), possibly causing broken state/invariants to be observed.  Finalizers are one of those well intentioned ideas that goes haywire ... :)

Sent from my phone
On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com<mailto:hans.boehm at hp.com>> wrote:
But things are considerably worse than that.  References only solve the easy problem.  The most serious problem in my mind is that finalizers can run, and references can be enqueued, while e.g. a method of the object being finalized is still running.  The fact that the method is still running does not ensure that the object itself is still reachable; the method may only need fields that have already been cached in registers to complete.  This affects finalizers and java.lang.ref equally, and explains why probably the large majority of code using either one is broken.

I gave a JavaOne talk about this many years ago (slides at http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).  It is possible, though really ugly and slow to work around the problem.  I don?t believe anyone does.  I was told just after I gave the talk that this explained a problem somebody had been trying to track down, so I suspect this actually happens occasionally in the wild, though probably not on x86-32.

Hans

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Bob Lee
Sent: Monday, May 14, 2012 11:01 AM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Object finalization

On Sun, May 13, 2012 at 11:22 PM, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:
I should add the Vitaly's comments prompted me to remember that 'a' and 'b' might refer to objects that themselves have been finalized prior to the current finalizer running. This just reinforces how tricky finalization is.

Indeed, the finalizers can run in any order, independent of the structure of the object graph.

For those who are interested in learning more, I cover that and half a dozen other reasons not to use finalizers in this talk: http://www.parleys.com/#id=2657&st=5

Thanks,
Bob
Square is hiring!<https://squareup.com/jobs>


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/d5ba2b79/attachment-0001.html>

From heinz at javaspecialists.eu  Tue May 15 04:06:22 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 May 2012 11:06:22 +0300
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
Message-ID: <4FB20E7E.7010908@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/d591ed9e/attachment.html>

From davidcholmes at aapt.net.au  Tue May 15 04:08:47 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 15 May 2012 18:08:47 +1000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <4FB20E7E.7010908@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEILJEAA.davidcholmes@aapt.net.au>

As long as the Object constructor completes the object will be registered
for finalization.

David
  -----Original Message-----
  From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
  Sent: Tuesday, 15 May 2012 6:06 PM
  To: Vitaly Davidovich
  Cc: Boehm, Hans; concurrency-interest at cs.oswego.edu; dholmes at ieee.org
  Subject: Re: [concurrency-interest] Object finalization


  The finalizer definitely runs even if the constructor fails (in other
words, throws an exception).  It's the trick we use to solve the Chicken and
Egg puzzle in Wouter Coekaert's blog:

  http://wouter.coekaerts.be/2012/puzzle-chicken

Regards

Heinz
--
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


  On 5/15/12 1:05 AM, Vitaly Davidovich wrote:
    Raymond Chen (MSFT) has an interesting series of posts on finalization,
including this one which demonstrates your example Hans:
http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx

    CLR team even added GC.KeepAlive() to try and alleviate some causes of
this race.  Then there's a whole slew of bugs that can happen due to memory
write ordering/visibility since finalizer thread is subject to same issues
as normal threads.  Then in CLR finalizer can run even if constructor fails
(I believe JVM does not?), possibly causing broken state/invariants to be
observed.  Finalizers are one of those well intentioned ideas that goes
haywire ... :)

    Sent from my phone

    On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

      But things are considerably worse than that.  References only solve
the easy problem.  The most serious problem in my mind is that finalizers
can run, and references can be enqueued, while e.g. a method of the object
being finalized is still running.  The fact that the method is still running
does not ensure that the object itself is still reachable; the method may
only need fields that have already been cached in registers to complete.
This affects finalizers and java.lang.ref equally, and explains why probably
the large majority of code using either one is broken.



      I gave a JavaOne talk about this many years ago (slides at
http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).
It is possible, though really ugly and slow to work around the problem.  I
don?t believe anyone does.  I was told just after I gave the talk that this
explained a problem somebody had been trying to track down, so I suspect
this actually happens occasionally in the wild, though probably not on
x86-32.



      Hans



      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Bob Lee
      Sent: Monday, May 14, 2012 11:01 AM
      To: dholmes at ieee.org
      Cc: concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Object finalization



      On Sun, May 13, 2012 at 11:22 PM, David Holmes
<davidcholmes at aapt.net.au> wrote:

        I should add the Vitaly's comments prompted me to remember that 'a'
and 'b' might refer to objects that themselves have been finalized prior to
the current finalizer running. This just reinforces how tricky finalization
is.



      Indeed, the finalizers can run in any order, independent of the
structure of the object graph.



      For those who are interested in learning more, I cover that and half a
dozen other reasons not to use finalizers in this talk:
http://www.parleys.com/#id=2657&st=5



      Thanks,

      Bob

      Square is hiring!




      _______________________________________________
      Concurrency-interest mailing list
      Concurrency-interest at cs.oswego.edu
      http://cs.oswego.edu/mailman/listinfo/concurrency-interest


----------------------------------------------------------------------------
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/4aa2df1a/attachment.html>

From heinz at javaspecialists.eu  Tue May 15 04:41:22 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 May 2012 11:41:22 +0300
Subject: [concurrency-interest] Object finalization
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEILJEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEILJEAA.davidcholmes@aapt.net.au>
Message-ID: <4FB216B2.8090007@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/99807167/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue May 15 04:58:19 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 15 May 2012 18:58:19 +1000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <4FB216B2.8090007@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEIMJEAA.davidcholmes@aapt.net.au>

Yes that is what I said: as long the Object constructor completes (not "as
long as the object's constructor completes") ;-)

Technically the subclass constructor has already been called, it just makes
a call to the super() constructor first, then continues with its own
execution. So any exception thrown before we invoke Object() means the
object is not finalizable. Object() can't throw anything (in the JDK) and
once it completes the object is finalizable regardless of whether any
subclass constructor completes abruptly by throwing an exception.

David
  -----Original Message-----
  From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
  Sent: Tuesday, 15 May 2012 6:41 PM
  To: dholmes at ieee.org
  Cc: Vitaly Davidovich; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Object finalization


  Exactly.  The question is - can the constructor ever *not* complete in
Java, if we say that an exception is also a "completion"?  I suppose it
could get stuck in a deadlock during construction.

  I would argue that the object would get finalized even if the object could
not get constructed.  AFAIK, the object would get registered for
finalization when the superclass Object is constructed, that is, before the
subclass' constructor is called.

  Here's my proof:

  import java.util.concurrent.locks.*;

  public class RegisterForFinalize {
    public static void main(String[] args) {
      final Lock lock = new ReentrantLock();
      lock.lock();
      new Thread() {
        {
          setDaemon(true);
        }
        public void run() {
          new Object() {
            {
              lock.lock(); // <-- will never return
            }
            protected void finalize() throws Throwable {
              System.out.println("Object finalized");
            }
          };
        }
      }.start();
      System.runFinalizersOnExit(true);
    }
  }

  Prints out: Object finalized.  And the constructor will never complete.

  So the essential part is that Object's constructor completes, which it
will probably always do.

  Tricky.  Bottom line - DO NOT USE FINALIZERS :-)

Regards

Heinz
--
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


  On 5/15/12 11:08 AM, David Holmes wrote:
    As long as the Object constructor completes the object will be
registered for finalization.

    David
      -----Original Message-----
      From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
      Sent: Tuesday, 15 May 2012 6:06 PM
      To: Vitaly Davidovich
      Cc: Boehm, Hans; concurrency-interest at cs.oswego.edu; dholmes at ieee.org
      Subject: Re: [concurrency-interest] Object finalization


      The finalizer definitely runs even if the constructor fails (in other
words, throws an exception).  It's the trick we use to solve the Chicken and
Egg puzzle in Wouter Coekaert's blog:

      http://wouter.coekaerts.be/2012/puzzle-chicken

Regards

Heinz
--
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


      On 5/15/12 1:05 AM, Vitaly Davidovich wrote:
        Raymond Chen (MSFT) has an interesting series of posts on
finalization, including this one which demonstrates your example Hans:
http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx

        CLR team even added GC.KeepAlive() to try and alleviate some causes
of this race.  Then there's a whole slew of bugs that can happen due to
memory write ordering/visibility since finalizer thread is subject to same
issues as normal threads.  Then in CLR finalizer can run even if constructor
fails (I believe JVM does not?), possibly causing broken state/invariants to
be observed.  Finalizers are one of those well intentioned ideas that goes
haywire ... :)

        Sent from my phone

        On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com> wrote:

          But things are considerably worse than that.  References only
solve the easy problem.  The most serious problem in my mind is that
finalizers can run, and references can be enqueued, while e.g. a method of
the object being finalized is still running.  The fact that the method is
still running does not ensure that the object itself is still reachable; the
method may only need fields that have already been cached in registers to
complete.  This affects finalizers and java.lang.ref equally, and explains
why probably the large majority of code using either one is broken.



          I gave a JavaOne talk about this many years ago (slides at
http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).
It is possible, though really ugly and slow to work around the problem.  I
don?t believe anyone does.  I was told just after I gave the talk that this
explained a problem somebody had been trying to track down, so I suspect
this actually happens occasionally in the wild, though probably not on
x86-32.



          Hans



          From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Bob Lee
          Sent: Monday, May 14, 2012 11:01 AM
          To: dholmes at ieee.org
          Cc: concurrency-interest at cs.oswego.edu
          Subject: Re: [concurrency-interest] Object finalization



          On Sun, May 13, 2012 at 11:22 PM, David Holmes
<davidcholmes at aapt.net.au> wrote:

            I should add the Vitaly's comments prompted me to remember that
'a' and 'b' might refer to objects that themselves have been finalized prior
to the current finalizer running. This just reinforces how tricky
finalization is.



          Indeed, the finalizers can run in any order, independent of the
structure of the object graph.



          For those who are interested in learning more, I cover that and
half a dozen other reasons not to use finalizers in this talk:
http://www.parleys.com/#id=2657&st=5



          Thanks,

          Bob

          Square is hiring!




          _______________________________________________
          Concurrency-interest mailing list
          Concurrency-interest at cs.oswego.edu
          http://cs.oswego.edu/mailman/listinfo/concurrency-interest


------------------------------------------------------------------------
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/4e910d0c/attachment.html>

From david.lloyd at redhat.com  Tue May 15 09:15:48 2012
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 15 May 2012 08:15:48 -0500
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A43565F3-1A01-4C96-A473-AC704DB1B0F4@devexperts.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>,
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<A43565F3-1A01-4C96-A473-AC704DB1B0F4@devexperts.com>
Message-ID: <4FB25704.6050401@redhat.com>

I've given up on finalization for native resources for just this reason; 
instead I use refcounting.  It's not great because there's a CAS on 
entry+exit but I find that I can also use the same trick to replace 
locking in many cases so I'm hoping that it'll even out in the 
benchmarks.  I almost have myself convinced that it will scale better 
than the finalizer option.  We shall see.

On 05/15/2012 02:35 AM, Roman Elizarov wrote:
> I wonder what are the legitimate use-cases for finalization? The actual
> *usage* of finalization in Java runtime is deeply flawed, because
> finalizers that reclaim native resources don't have a chance to run
> before you run out of native resources. For example, the code that leaks
> FileInputStream objects without closing them seems to work correctly on
> small heaps, but crashes with different JVM options, running out of
> native fds.
>
> So, are there any sound use-cases for finalizers at all?
>
> On 15.05.2012, at 2:05, "Boehm, Hans" <hans.boehm at hp.com
> <mailto:hans.boehm at hp.com>> wrote:
>
>> In my view, the hard problem is finalization while a method is
>> running. Fixing that the obvious way has a probably small, but nonzero
>> optimization cost. (Essentially no dead variable elimination on
>> reference variables. Guesses among the optimization experts in the C++
>> committee were around a 1% slowdown to support a semi-esoteric
>> feature. I don?t know of any real measurements.) We came up with some
>> compromises in a C++ context in
>> http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2261.html .
>>
>> I think the other issues could be solved fairly easily. In my view
>> Modula 3 adequately solved the ordering issue by insisting on ordered
>> finalization, which is essentially what you now get out of
>> java.lang.ref, though in a less direct way. As far as I know, Modula-3
>> users generally agreed with that assessment, but Java and C# designers
>> did not, and came up with what I consider to be a much worse point in
>> the design space, at least for finalization itself. I also don?t see
>> why, given a solution to the early finalization problem, it would be
>> difficult to ensure that the last object access happens before
>> finalization. Standard garbage collectors probably have each thread
>> stop operation synchronize with finalization anyway.
>>
>> Hans
>>
>> *From:*Vitaly Davidovich [mailto:vitalyd at gmail.com]
>> *Sent:* Monday, May 14, 2012 3:05 PM
>> *To:* Boehm, Hans
>> *Cc:* concurrency-interest at cs.oswego.edu
>> <mailto:concurrency-interest at cs.oswego.edu>; Bob Lee; dholmes at ieee.org
>> <mailto:dholmes at ieee.org>
>> *Subject:* Re: [concurrency-interest] Object finalization
>>
>> Raymond Chen (MSFT) has an interesting series of posts on
>> finalization, including this one which demonstrates your example Hans:
>> http://blogs.msdn.com/b/oldnewthing/archive/2010/08/13/10049634.aspx
>>
>> CLR team even added GC.KeepAlive() to try and alleviate some causes of
>> this race. Then there's a whole slew of bugs that can happen due to
>> memory write ordering/visibility since finalizer thread is subject to
>> same issues as normal threads. Then in CLR finalizer can run even if
>> constructor fails (I believe JVM does not?), possibly causing broken
>> state/invariants to be observed. Finalizers are one of those well
>> intentioned ideas that goes haywire ... :)
>>
>> Sent from my phone
>>
>> On May 14, 2012 4:58 PM, "Boehm, Hans" <hans.boehm at hp.com
>> <mailto:hans.boehm at hp.com>> wrote:
>>
>> But things are considerably worse than that. References only solve the
>> easy problem. The most serious problem in my mind is that finalizers
>> can run, and references can be enqueued, while e.g. a method of the
>> object being finalized is still running. The fact that the method is
>> still running does not ensure that the object itself is still
>> reachable; the method may only need fields that have already been
>> cached in registers to complete. This affects finalizers and
>> java.lang.ref equally, and explains why probably the large majority of
>> code using either one is broken.
>>
>> I gave a JavaOne talk about this many years ago (slides at
>> http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf).
>> It is possible, though really ugly and slow to work around the
>> problem. I don?t believe anyone does. I was told just after I gave the
>> talk that this explained a problem somebody had been trying to track
>> down, so I suspect this actually happens occasionally in the wild,
>> though probably not on x86-32.
>>
>> Hans
>>
>> *From:*concurrency-interest-bounces at cs.oswego.edu
>> <mailto:concurrency-interest-bounces at cs.oswego.edu>
>> [mailto:concurrency-interest-bounces at cs.oswego.edu
>> <mailto:concurrency-interest-bounces at cs.oswego.edu>] *On Behalf Of
>> *Bob Lee
>> *Sent:* Monday, May 14, 2012 11:01 AM
>> *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>> *Cc:* concurrency-interest at cs.oswego.edu
>> <mailto:concurrency-interest at cs.oswego.edu>
>> *Subject:* Re: [concurrency-interest] Object finalization
>>
>> On Sun, May 13, 2012 at 11:22 PM, David Holmes
>> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>     I should add the Vitaly's comments prompted me to remember that
>>     'a' and 'b' might refer to objects that themselves have been
>>     finalized prior to the current finalizer running. This just
>>     reinforces how tricky finalization is.
>>
>> Indeed, the finalizers can run in any order, independent of the
>> structure of the object graph.
>>
>> For those who are interested in learning more, I cover that and half a
>> dozen other reasons not to use finalizers in this talk:
>> http://www.parleys.com/#id=2657&st=5
>> <http://www.parleys.com/#id=2657&st=5>
>>
>> Thanks,
>>
>> Bob
>>
>> Square is hiring! <https://squareup.com/jobs>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
- DML

From gregg at cytetech.com  Tue May 15 10:39:55 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 15 May 2012 09:39:55 -0500
Subject: [concurrency-interest] Object finalization
In-Reply-To: <4FB25704.6050401@redhat.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>,
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<A43565F3-1A01-4C96-A473-AC704DB1B0F4@devexperts.com>
	<4FB25704.6050401@redhat.com>
Message-ID: <4FB26ABB.4040206@cytetech.com>

On 5/15/2012 8:15 AM, David M. Lloyd wrote:
> I've given up on finalization for native resources for just this reason; instead
> I use refcounting. It's not great because there's a CAS on entry+exit but I find
> that I can also use the same trick to replace locking in many cases so I'm
> hoping that it'll even out in the benchmarks. I almost have myself convinced
> that it will scale better than the finalizer option. We shall see.

I've done this in a lot of other places myself too.  It just simplifies so many 
things to have dependable, accurate life cycles.

Gregg

From crazybob at crazybob.org  Tue May 15 14:38:58 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 15 May 2012 11:38:58 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <4FB20E7E.7010908@javaspecialists.eu>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
	<4FB20E7E.7010908@javaspecialists.eu>
Message-ID: <CAGmsiP6zagFNar=LbrUBr=s2QP=FQSyP25=FPJxe4pZ0T-PoNA@mail.gmail.com>

On Tue, May 15, 2012 at 1:06 AM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> **
> The finalizer definitely runs even if the constructor fails (in other
> words, throws an exception).
>

The fact that the finalizer runs even when the constructor fails was a
security hole:
http://www.ibm.com/developerworks/java/library/j-fv/index.html?ca=drs-

I think it was fixed awhile ago, but the bug report isn't visible to me, I
presume for security reasons:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5092933

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/1b091de6/attachment.html>

From crazybob at crazybob.org  Tue May 15 14:43:43 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 15 May 2012 11:43:43 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
Message-ID: <CAGmsiP4bL_e5UYxEnXKO3JqQmSn+0HGLOJjFdiGBcJAr6jOOfQ@mail.gmail.com>

So there isn't any confusion, the original code is safe without null checks
in the finalizer. While the finalizer can run concurrently with other
methods, the JLS
guarantees<http://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.6>that
the constructor will finish before the finalizer runs: "The completion
of an object's constructor happens-before (?17.4.5) the execution of its
finalize method (in the formal sense of happens-before)."

Hans, I used your static volatile pinning trick in an experimental
ThreadLocal implementation I wrote. :-)

See the "pin" field:
http://code.google.com/p/google-threadlocal/source/browse/trunk/main/java/lang/ThreadLocal.java

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/b99bd728/attachment.html>

From heinz at javaspecialists.eu  Tue May 15 16:04:47 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 15 May 2012 23:04:47 +0300
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAGmsiP4bL_e5UYxEnXKO3JqQmSn+0HGLOJjFdiGBcJAr6jOOfQ@mail.gmail.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<CAGmsiP4bL_e5UYxEnXKO3JqQmSn+0HGLOJjFdiGBcJAr6jOOfQ@mail.gmail.com>
Message-ID: <CACLL95q9ycLF4cGc2yxmLFZZ-KrPq7a-23Y4-nt_Yhr3RiOQsA@mail.gmail.com>

Sure, the fields cannot be null, but would it be possible that they
have already been finalized?

On 15/05/2012, Bob Lee <crazybob at crazybob.org> wrote:
> So there isn't any confusion, the original code is safe without null checks
> in the finalizer. While the finalizer can run concurrently with other
> methods, the JLS
> guarantees<http://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.6>that
> the constructor will finish before the finalizer runs: "The completion
> of an object's constructor happens-before (?17.4.5) the execution of its
> finalize method (in the formal sense of happens-before)."
>
> Hans, I used your static volatile pinning trick in an experimental
> ThreadLocal implementation I wrote. :-)
>
> See the "pin" field:
> http://code.google.com/p/google-threadlocal/source/browse/trunk/main/java/lang/ThreadLocal.java
>
> Bob
>


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


From davidcholmes at aapt.net.au  Tue May 15 16:32:11 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 16 May 2012 06:32:11 +1000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CACLL95q9ycLF4cGc2yxmLFZZ-KrPq7a-23Y4-nt_Yhr3RiOQsA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEIPJEAA.davidcholmes@aapt.net.au>

Dr Heinz M. Kabutz writes:
> Sure, the fields cannot be null, but would it be possible that they
> have already been finalized?

Yes. That has already been mentioned a few times.

David
-----

> On 15/05/2012, Bob Lee <crazybob at crazybob.org> wrote:
> > So there isn't any confusion, the original code is safe without
> null checks
> > in the finalizer. While the finalizer can run concurrently with other
> > methods, the JLS
> >
> guarantees<http://docs.oracle.com/javase/specs/jls/se7/html/jls-12
> .html#jls-12.6>that
> > the constructor will finish before the finalizer runs: "The completion
> > of an object's constructor happens-before (?17.4.5) the execution of its
> > finalize method (in the formal sense of happens-before)."
> >
> > Hans, I used your static volatile pinning trick in an experimental
> > ThreadLocal implementation I wrote. :-)
> >
> > See the "pin" field:
> >
http://code.google.com/p/google-threadlocal/source/browse/trunk/main/java/la
ng/ThreadLocal.java
>
> Bob
>


--
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz



From vitalyd at gmail.com  Tue May 15 16:32:34 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 15 May 2012 16:32:34 -0400
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CACLL95q9ycLF4cGc2yxmLFZZ-KrPq7a-23Y4-nt_Yhr3RiOQsA@mail.gmail.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<CAGmsiP4bL_e5UYxEnXKO3JqQmSn+0HGLOJjFdiGBcJAr6jOOfQ@mail.gmail.com>
	<CACLL95q9ycLF4cGc2yxmLFZZ-KrPq7a-23Y4-nt_Yhr3RiOQsA@mail.gmail.com>
Message-ID: <CAHjP37GWwTO3kRuqHEWELqmfY7_OaEBkBzQxW5pCM4k4inf5iA@mail.gmail.com>

I would say yes as we're all in agreement that finalization order is
unspecified, so if the fields themselves are of a type with a finalized
then they could already be finalized.

As for an exception in the constructor, looks like in JDK 6 and onwards the
finalizer will not run if an exception occurs before Object's constructor
exits (from Oracle's Secure Coding Guidelines for java, guideline 4-5).

Sent from my phone
On May 15, 2012 4:06 PM, "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
wrote:

> Sure, the fields cannot be null, but would it be possible that they
> have already been finalized?
>
> On 15/05/2012, Bob Lee <crazybob at crazybob.org> wrote:
> > So there isn't any confusion, the original code is safe without null
> checks
> > in the finalizer. While the finalizer can run concurrently with other
> > methods, the JLS
> > guarantees<
> http://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.6>that
> > the constructor will finish before the finalizer runs: "The completion
> > of an object's constructor happens-before (?17.4.5) the execution of its
> > finalize method (in the formal sense of happens-before)."
> >
> > Hans, I used your static volatile pinning trick in an experimental
> > ThreadLocal implementation I wrote. :-)
> >
> > See the "pin" field:
> >
> http://code.google.com/p/google-threadlocal/source/browse/trunk/main/java/lang/ThreadLocal.java
> >
> > Bob
> >
>
>
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/a7a6ad95/attachment.html>

From davidcholmes at aapt.net.au  Tue May 15 16:38:14 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 16 May 2012 06:38:14 +1000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CAGmsiP6zagFNar=LbrUBr=s2QP=FQSyP25=FPJxe4pZ0T-PoNA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEIPJEAA.davidcholmes@aapt.net.au>

Note that the "fix" here was simply the requirement that Object's
constructor must complete. AFAIK the vulnerabilities listed may still be
possible unless the checks that are being subverted are placed into code
that executes before the super constructor is executed.

David

  -----Original Message-----
  From: crazyboblee at gmail.com [mailto:crazyboblee at gmail.com]On Behalf Of Bob
Lee
  Sent: Wednesday, 16 May 2012 4:39 AM
  To: Dr Heinz M. Kabutz
  Cc: Vitaly Davidovich; Boehm, Hans; concurrency-interest at cs.oswego.edu;
dholmes at ieee.org
  Subject: Re: [concurrency-interest] Object finalization


  On Tue, May 15, 2012 at 1:06 AM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
    The finalizer definitely runs even if the constructor fails (in other
words, throws an exception).


  The fact that the finalizer runs even when the constructor fails was a
security hole:
http://www.ibm.com/developerworks/java/library/j-fv/index.html?ca=drs-


  I think it was fixed awhile ago, but the bug report isn't visible to me, I
presume for security reasons:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5092933


  Bob


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/4fb7d25c/attachment-0001.html>

From crazybob at crazybob.org  Tue May 15 16:56:48 2012
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 15 May 2012 13:56:48 -0700
Subject: [concurrency-interest] Object finalization
In-Reply-To: <CACLL95q9ycLF4cGc2yxmLFZZ-KrPq7a-23Y4-nt_Yhr3RiOQsA@mail.gmail.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<CAGmsiP4bL_e5UYxEnXKO3JqQmSn+0HGLOJjFdiGBcJAr6jOOfQ@mail.gmail.com>
	<CACLL95q9ycLF4cGc2yxmLFZZ-KrPq7a-23Y4-nt_Yhr3RiOQsA@mail.gmail.com>
Message-ID: <CAGmsiP7gjbc9+PrBm2m4LRW1Ka7B2aBY-rdfExb5J01cUvcn8Q@mail.gmail.com>

On Tue, May 15, 2012 at 1:04 PM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> Sure, the fields cannot be null, but would it be possible that they
> have already been finalized?


If they have finalizers themselves, absolutely?it's likely even that their
finalizers would run first. The Garbage Collector would determine that the
SomeService instance, Resource a and Resource b are all unreachable at the
same time and then run their finalizers in an arbitrary order.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120515/6a7f93b4/attachment.html>

From hans.boehm at hp.com  Tue May 15 19:45:13 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 15 May 2012 23:45:13 +0000
Subject: [concurrency-interest] Object finalization
In-Reply-To: <4FB26ABB.4040206@cytetech.com>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>,
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<A43565F3-1A01-4C96-A473-AC704DB1B0F4@devexperts.com>
	<4FB25704.6050401@redhat.com> <4FB26ABB.4040206@cytetech.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD2355530CD@G4W3299.americas.hpqcorp.net>

> From: Gregg Wonderly
> 
> On 5/15/2012 8:15 AM, David M. Lloyd wrote:
> > I've given up on finalization for native resources for just this
> reason; instead
> > I use refcounting. It's not great because there's a CAS on entry+exit
> but I find
> > that I can also use the same trick to replace locking in many cases
> so I'm
> > hoping that it'll even out in the benchmarks. I almost have myself
> convinced
> > that it will scale better than the finalizer option. We shall see.
> 
> I've done this in a lot of other places myself too.  It just simplifies
> so many
> things to have dependable, accurate life cycles.
> 
> Gregg

It seems to me that, depending on the context, that may be trading one can of worms for another.
Possibly a bigger one.

To me, there are two distinct kinds of cleanup actions:

1) Logically synchronous; the programmer knows exactly where it's happening, and can make
sure that the locks acquired by the cleanup code aren't acquired in the wrong order with
respect to the calling context, etc.  C++ destructors are good at this.  Explicit cleanup
calls often aren't too bad.  Finalizers are terrible.  It seems to me that this case usually
doesn't even need reference counting, though occasionally it might.  And that may be a perfectly
good use for reference counting.

2) Logically asynchronous.  We want it to be cleaned up anytime before we run out of the resource,
whenever that may be.  This is what happens when an assignment drops the last reference to a
large data structure containing library-defined objects which I don't understand, and have
no business understanding.  Finalizers and java.lang.ref are potentially tolerable at this,
with some fixes.  Traditional reference counting with synchronous resource reclamation
is terrible at it (at least in the absence of transactional memory).  C++ destructors have
the same problem.  The problem is that a completely innocuous looking call, performing a
reference-counted assignment, may end up acquiring a huge collection of locks I don't know
about, making it essentially impossible to reliably avoid deadlocks.  (This is essentially identical
to the JDK 1.0.2 finalization bug misdescribed as a language design bug as the first
item in http://www.cs.arizona.edu/projects/sumatra/hallofshame/ )  The problem can be avoided
by queuing cleanups to be run later in a separate thread, just like finalizers.

It also seems to me that using reference counting for (2) has a tendency to infect lots of things
with reference counting, and may largely make the GC redundant.  Once we do that, we've solved a
problem that was solvable with perhaps a 1% optimization cost by adding huge overhead to every
pointer assignment.  (Not to mention garbage cycles.)

These issues are described in more detail in http://dl.acm.org/citation.cfm?doid=604131.604153 .

Hans


From heinz at javaspecialists.eu  Wed May 16 04:16:20 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 16 May 2012 11:16:20 +0300
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com>	<4FAD66F3.1030006@intelerad.com>
	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>
Message-ID: <4FB36254.4020104@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/8579e8e2/attachment.html>

From viktor.klang at gmail.com  Wed May 16 04:43:30 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 16 May 2012 10:43:30 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FB36254.4020104@javaspecialists.eu>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>
	<4FB36254.4020104@javaspecialists.eu>
Message-ID: <CANPzfU8pNznwtcHMxooamqStXkSJCcRJh9sFQ6ORm-g-JM-bMg@mail.gmail.com>

On Wed, May 16, 2012 at 10:16 AM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> **
> I've spent yesterday and part of today looking at various approaches to
> solve this problem.
>
> 1. My idea of a striped queue would not work, because tasks are not always
> enqueued before they are handed off to workers.
>

Ah, the Curse of Order!


>
> 2. I've got a nice solution utilizing the SerialExecutor approach,
> however, as Joe mentioned, shutdown is particularly challenging.  I'm still
> trying to solve that, but it is not easy.
>

Executor has no shutdown ;-)


>
> 3. Another challenge, also mentioned already in this thread, is that we
> need to carefully manage the map so that we do not get a memory leak.  The
> solution I'm trying now is to delete the SerialExecutor from the map
> whenever it is empty.  This might create a lot of objects, but at least we
> don't have to worry about a memory leak.
>

If you have the SerialExecutor extend CLQ and use a @volatile int/boolean
to keep track of "is scheduled" or not then it's essentially only 2
allocations to create the SerialExecutor:

1 for the head-node in the CLQ and one for the SerialExecutor itself, so it
shouldn't be that bad.

However, the performance will of course vary depending on how it's used.

Cheers,
?


> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professionalhttp://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 5/13/12 4:54 AM, Joe Bowbeer wrote:
>
> On Fri, May 11, 2012 at 12:22 PM, Andrew Trumper wrote:
>
>>
>> BoundedExecutor is a simple wrapper that limits the number of
>> concurrently running tasks to some number. It doesn't allocate any threads
>> itself (unless you want it to) but uses the "mThreadCache". It's great
>> because it means your whole application can use one thread cache but you
>> can create little thread pools all over the place and not worry about
>> having a bunch of idle threads hangin' around. We use this all the time in
>> our product.
>>
>> (Note, that Joe Bowbeer has mentioned a class called SerialExecutor that
>> seems to do the same thing. ?)
>>
>> BoundedExecutor is part of the nuggu library, BSD license:
>>
>> <
>> http://nuggu.svn.sourceforge.net/viewvc/nuggu/HEAD/src/com/intelerad/tools/lib/concurrent/BoundedExecutor.java?revision=10&view=markup
>> >
>>
>> It would be really great to improve this class and put it in a library
>> someone's actually heard of :-P.
>>
>> (In our product we sometimes use a second BoundedExecutor around the
>> thread cache to limit the concurrency to the number of cores/processors.)
>>
>
>
>  The SerialExecutor that I referred to is in the Executor javadoc.
>
>
> http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Executor.html
>
>  Here is a link to one of the times that a similar problem was discussed
> previously on c-i:
>
>  http://cs.oswego.edu/pipermail/concurrency-interest/2010-June/007208.html
>
>  This post refers to both SerialExecutor and a (different)
> BoundedExecutor.
>
>  There are several different SerialExecutor and BoundedExecutor
> implementations floating around.  In one way, this validates the usefulness
> of the simple Executor interface!  In real world applications, I wonder if
> a single BoundedExecutor implementation would be useful.  Shutdown is one
> of the missing pieces in these sample implementations -- and this is
> especially difficult to manage when there are multiple, delegating
> executors.  I expect that different trade-offs would be chosen in different
> situations, in which case it may be hard to provide a general solution.
>
>  --Joe
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/3e871796/attachment-0001.html>

From heinz at javaspecialists.eu  Wed May 16 04:59:31 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 16 May 2012 11:59:31 +0300
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU8pNznwtcHMxooamqStXkSJCcRJh9sFQ6ORm-g-JM-bMg@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com>	<4FAD66F3.1030006@intelerad.com>	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>	<4FB36254.4020104@javaspecialists.eu>
	<CANPzfU8pNznwtcHMxooamqStXkSJCcRJh9sFQ6ORm-g-JM-bMg@mail.gmail.com>
Message-ID: <4FB36C73.2090200@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/c6cc11e8/attachment.html>

From viktor.klang at gmail.com  Wed May 16 05:00:50 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 16 May 2012 11:00:50 +0200
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FB36C73.2090200@javaspecialists.eu>
References: <4FAC9B5A.10005@8950aaa.com> <4FAD66F3.1030006@intelerad.com>
	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>
	<4FB36254.4020104@javaspecialists.eu>
	<CANPzfU8pNznwtcHMxooamqStXkSJCcRJh9sFQ6ORm-g-JM-bMg@mail.gmail.com>
	<4FB36C73.2090200@javaspecialists.eu>
Message-ID: <CANPzfU937VfAYrh3cS=QyHsSe_=8rPCMbMCc=55di9qqqFGaoQ@mail.gmail.com>

On Wed, May 16, 2012 at 10:59 AM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> **
>
>  On Wed, May 16, 2012 at 10:16 AM, Dr Heinz M. Kabutz <
> heinz at javaspecialists.eu> wrote:
>
>
>>
>> 2. I've got a nice solution utilizing the SerialExecutor approach,
>> however, as Joe mentioned, shutdown is particularly challenging.  I'm still
>> trying to solve that, but it is not easy.
>>
>
>  Executor has no shutdown ;-)
>
> Yeah :-)  But then it is also not all that useful, as you will possibly
> have objects stuck in the queues waiting to be scheduled.  How does one
> then shut down the whole construct?  Answer: You don't ;-)
>

Let it run free!


>
>
>> 3. Another challenge, also mentioned already in this thread, is that we
>> need to carefully manage the map so that we do not get a memory leak.  The
>> solution I'm trying now is to delete the SerialExecutor from the map
>> whenever it is empty.  This might create a lot of objects, but at least we
>> don't have to worry about a memory leak.
>>
>
>  If you have the SerialExecutor extend CLQ and use a @volatile
> int/boolean to keep track of "is scheduled" or not then it's essentially
> only 2 allocations to create the SerialExecutor:
>
>  1 for the head-node in the CLQ and one for the SerialExecutor itself, so
> it shouldn't be that bad.
>
>  However, the performance will of course vary depending on how it's used.
>
> Actually, I'm not really too worried about performance.  Glenn McGregor
> was trying to solve a specific problem - that is to have his tasks execute
> in order according to a particular stripe.  Thus the requirement is not to
> be particularly lock-free or low contention.  In my current solution I've
> got a big fat ReentrantLock that governs everything.  This way I can manage
> the shared mutable state correctly.
>
> Make it run, make it right, make it fast.
>

Yeah, I implemented the version that does remove with WRL too, it's the
easiest way to solve it.

Cheers,
?


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/9cde9342/attachment.html>

From gregg at cytetech.com  Wed May 16 08:10:04 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 16 May 2012 07:10:04 -0500
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FB36254.4020104@javaspecialists.eu>
References: <4FAC9B5A.10005@8950aaa.com>	<4FAD66F3.1030006@intelerad.com>
	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>
	<4FB36254.4020104@javaspecialists.eu>
Message-ID: <4FB3991C.3060905@cytetech.com>

On 5/16/2012 3:16 AM, Dr Heinz M. Kabutz wrote:
> I've spent yesterday and part of today looking at various approaches to solve
> this problem.
>
> 1. My idea of a striped queue would not work, because tasks are not always
> enqueued before they are handed off to workers.
>
> 2. I've got a nice solution utilizing the SerialExecutor approach, however, as
> Joe mentioned, shutdown is particularly challenging. I'm still trying to solve
> that, but it is not easy.
>
> 3. Another challenge, also mentioned already in this thread, is that we need to
> carefully manage the map so that we do not get a memory leak. The solution I'm
> trying now is to delete the SerialExecutor from the map whenever it is empty.
> This might create a lot of objects, but at least we don't have to worry about a
> memory leak.

This is precisely the type of place where I use a counter to manage lifecycle 
beginning and end.  Code needs to be completely correct, before it is 
"completely efficient".  I've rarely ever had to decide to start optimizing 
these kinds of places once I have things up and running and do some 
instrumentation.  Rarely, are these the hot spots for latency injection.

Gregg

From heinz at javaspecialists.eu  Wed May 16 08:11:02 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 16 May 2012 15:11:02 +0300
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <CANPzfU937VfAYrh3cS=QyHsSe_=8rPCMbMCc=55di9qqqFGaoQ@mail.gmail.com>
References: <4FAC9B5A.10005@8950aaa.com>	<4FAD66F3.1030006@intelerad.com>	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>	<4FB36254.4020104@javaspecialists.eu>	<CANPzfU8pNznwtcHMxooamqStXkSJCcRJh9sFQ6ORm-g-JM-bMg@mail.gmail.com>	<4FB36C73.2090200@javaspecialists.eu>
	<CANPzfU937VfAYrh3cS=QyHsSe_=8rPCMbMCc=55di9qqqFGaoQ@mail.gmail.com>
Message-ID: <4FB39956.1050803@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/0658f0df/attachment.html>

From andrew at intelerad.com  Wed May 16 10:21:46 2012
From: andrew at intelerad.com (Andrew Trumper)
Date: Wed, 16 May 2012 10:21:46 -0400
Subject: [concurrency-interest] Class striped/ordered Thread Pool
In-Reply-To: <4FB36254.4020104@javaspecialists.eu>
References: <4FAC9B5A.10005@8950aaa.com>	<4FAD66F3.1030006@intelerad.com>
	<CAHzJPErxhC++_XjUoR6g3qJ+hoUvvg-3dpSNp29p-xM1jc3DCg@mail.gmail.com>
	<4FB36254.4020104@javaspecialists.eu>
Message-ID: <4FB3B7FA.1060105@intelerad.com>



On 05/16/2012 04:16 AM, Dr Heinz M. Kabutz wrote:
>
> 2. I've got a nice solution utilizing the SerialExecutor approach,
> however, as Joe mentioned, shutdown is particularly challenging.  I'm
> still trying to solve that, but it is not easy.

I'm not sure I understand the "shutdown problem".. What's the issue?

> 3. Another challenge, also mentioned already in this thread, is that we
> need to carefully manage the map so that we do not get a memory leak.
> The solution I'm trying now is to delete the SerialExecutor from the map
> whenever it is empty.  This might create a lot of objects, but at least
> we don't have to worry about a memory leak.

Or you can queue a runnable on that serial executor that goes into the 
map and cleans out its own entry. Since you're executing serially it 
will execute once everything else has finished.

Given:

  interface StripedRunner {
       Object getKey(); // anything that can be used as a key in a map
       Runnable getRunnable();
  }

and this:

public class PerKeyExecutor {
   private final mMap<Object, Executor> mExecutors = new HashMap<>();
   private static final Executor mThreadCache =
       new ThreadPoolExecutor( 5, Integer.MAX_VALUE, 60L,
                               TimeUnit.SECONDS,
                             new SynchronousQueue<Runnable>() )

   public synchronized void execute( StripedRunner runnable ) {
     Executor executor = mExecutors.get( runnable.getKey() );
     if ( executor == null ) {
       mExecutors.put( runnble.getKey(), createExecutor() );
       executor = mExecutors.get( runnable.getKey() );
     }
     executor.execute( runnable.getRunnable() );
   }

   private Executor createExecutor() {
      /*
       * create a wrapper that bounds the number of
       * runnables executing at once to 1
       */
     return new BoundedExecutor( 1, mThreadCache );
   }

   // clean-up methods omitted
}

do this:

public class PerKeyExecutor {
   //...

   public void cleanUp( final Object key ) {
     execute( new StripedRunner() {
       Object getKey() { return key; }
       Runnable getRunnable() {
         dieDieDie( key );
       }
     } );
   }

   private synchronized void dieDieDie( Object key ) {
     mExecutors.remove( key );
   }
}

You can also create a special "please clean me up" StripedRunner 
instance if you really want to pass an Executor :

Runnable remeberMeForLater = PerKeyExecutor.createCleanUpRunnable();

Combine this with a stripe and it will clean up the BoundedExecutor.

- Andrew

-- 

This email or any attachments may contain confidential or legally 
privileged information intended for the sole use of the addressees. Any 
use, redistribution, disclosure, or reproduction of this information, 
except as intended, is prohibited. If you received this email in error, 
please notify the sender and remove all copies of the message, including 
any attachments.


From zhong.j.yu at gmail.com  Wed May 16 12:55:00 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 16 May 2012 11:55:00 -0500
Subject: [concurrency-interest] a volatile bug?
Message-ID: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>

as reported on
http://stackoverflow.com/questions/10620680

basically there are

    volatile int a;
    int b;

Thread 1:

    b=1;
    a=1;

Thread 2:

    while(a==0)
        ;
    if(b==0)
        print("error");

"error" is seen printed on 32 bit JDK6 on 64bit machine

From pavel.rappo at gmail.com  Wed May 16 13:11:24 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Wed, 16 May 2012 21:11:24 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
Message-ID: <DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>

If you see some concurrent behaviour that violates JMM then what else could that be?

On 16 May 2012, at 20:55, Zhong Yu wrote:

> as reported on
> http://stackoverflow.com/questions/10620680
> 
> basically there are
> 
>    volatile int a;
>    int b;
> 
> Thread 1:
> 
>    b=1;
>    a=1;
> 
> Thread 2:
> 
>    while(a==0)
>        ;
>    if(b==0)
>        print("error");
> 
> "error" is seen printed on 32 bit JDK6 on 64bit machine
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From aleksey.shipilev at gmail.com  Wed May 16 13:58:48 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Wed, 16 May 2012 21:58:48 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
Message-ID: <CA+1LWGFVFi6cFamgZzAgt0pHCnRQEhpkHn3it0jc6nGsrsv21g@mail.gmail.com>

This could not happen under JMM. Are you able to reproduce it?

-Aleksey.

On Wed, May 16, 2012 at 8:55 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> as reported on
> http://stackoverflow.com/questions/10620680
>
> basically there are
>
> ? ?volatile int a;
> ? ?int b;
>
> Thread 1:
>
> ? ?b=1;
> ? ?a=1;
>
> Thread 2:
>
> ? ?while(a==0)
> ? ? ? ?;
> ? ?if(b==0)
> ? ? ? ?print("error");
>
> "error" is seen printed on 32 bit JDK6 on 64bit machine
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From hans.boehm at hp.com  Wed May 16 14:40:49 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 16 May 2012 18:40:49 +0000
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>

> From: Pavel Rappo
> 
> If you see some concurrent behaviour that violates JMM then what else
> could that be?
A JDK bug AND a serious test suite omission?

But is the problem real?  Can it be reproduced on a mainstream JVM?

Note that the example in the original posting also read b before the loop,
so na?ve common subexpression elimination would cause the bug.  Hopefully
nobody does CSE in cases like this.

Hans
> 
> On 16 May 2012, at 20:55, Zhong Yu wrote:
> 
> > as reported on
> > http://stackoverflow.com/questions/10620680
> >
> > basically there are
> >
> >    volatile int a;
> >    int b;
> >
> > Thread 1:
> >
> >    b=1;
> >    a=1;
> >
> > Thread 2:
> >
> >    while(a==0)
> >        ;
> >    if(b==0)
> >        print("error");
> >
> > "error" is seen printed on 32 bit JDK6 on 64bit machine
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From coyotesqrl at gmail.com  Wed May 16 14:57:27 2012
From: coyotesqrl at gmail.com (R.A. Porter)
Date: Wed, 16 May 2012 11:57:27 -0700
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
Message-ID: <CAFFMuLNH0x_9ka55W_oZuEVV7MRuXKhHCc3orCTGLEiRxV3VRg@mail.gmail.com>

I was able to duplicate this with two different versions of the HotSpot
client on my Windows 7 box:
1.6.0_31
and
1.6.0_14

-r

On Wed, May 16, 2012 at 11:40 AM, Boehm, Hans <hans.boehm at hp.com> wrote:

> > From: Pavel Rappo
> >
> > If you see some concurrent behaviour that violates JMM then what else
> > could that be?
> A JDK bug AND a serious test suite omission?
>
> But is the problem real?  Can it be reproduced on a mainstream JVM?
>
> Note that the example in the original posting also read b before the loop,
> so na?ve common subexpression elimination would cause the bug.  Hopefully
> nobody does CSE in cases like this.
>
> Hans
> >
> > On 16 May 2012, at 20:55, Zhong Yu wrote:
> >
> > > as reported on
> > > http://stackoverflow.com/questions/10620680
> > >
> > > basically there are
> > >
> > >    volatile int a;
> > >    int b;
> > >
> > > Thread 1:
> > >
> > >    b=1;
> > >    a=1;
> > >
> > > Thread 2:
> > >
> > >    while(a==0)
> > >        ;
> > >    if(b==0)
> > >        print("error");
> > >
> > > "error" is seen printed on 32 bit JDK6 on 64bit machine
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/d0f5611d/attachment.html>

From aleksey.shipilev at gmail.com  Wed May 16 15:00:24 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Wed, 16 May 2012 23:00:24 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
Message-ID: <CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>

On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com> wrote:
> A JDK bug AND a serious test suite omission?

Stress tests would probably JIT-compile the code in question. See below.

> But is the problem real? ?Can it be reproduced on a mainstream JVM?

Same question.

> Note that the example in the original posting also read b before the loop,
> so na?ve common subexpression elimination would cause the bug. ?Hopefully
> nobody does CSE in cases like this.

FWIW, the test case in SO would probably not hit any compilation
threshold in HotSpot, so it could be executed in interpreter. Then,
assuming the interpreter does not reorder Java code, and assuming
original SO poster runs Windows, and hence x86, and hence has TSO,
this bug seems very unlikely. I would be surprised if it actually
*can* be reproduced. That makes the whole story rather interesting.

-Aleksey.


From aleksey.shipilev at gmail.com  Wed May 16 15:08:39 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Wed, 16 May 2012 23:08:39 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CAFFMuLNH0x_9ka55W_oZuEVV7MRuXKhHCc3orCTGLEiRxV3VRg@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CAFFMuLNH0x_9ka55W_oZuEVV7MRuXKhHCc3orCTGLEiRxV3VRg@mail.gmail.com>
Message-ID: <CA+1LWGHh1Fb6A9QYBqJJLE=Lgtc9C2_=SPCbt9wMe-VgVX+GZg@mail.gmail.com>

Aha, now I realize how come it is reproduced on Windows. java launcher
selects -client for Windows machines.

I was able to reproduce it with -client on my i5, Linux i686:

$  ~/Install/jdk7u4/bin/java -version
java version "1.7.0_04"
Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
Java HotSpot(TM) Server VM (build 23.0-b21, mixed mode)

$  ~/Install/jdk7u4/bin/java -server Test
[empty]

$  ~/Install/jdk7u4/bin/java -client -version
java version "1.7.0_04"
Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)

$  ~/Install/jdk7u4/bin/java -client Test
error x 100

Holy macaroni, is this a bug in C1?
Digging more.

-Aleksey.

On Wed, May 16, 2012 at 10:57 PM, R.A. Porter <coyotesqrl at gmail.com> wrote:
> I was able to duplicate this with two different versions of the HotSpot
> client on my Windows 7 box:
> 1.6.0_31
> and
> 1.6.0_14
>
> -r
>
> On Wed, May 16, 2012 at 11:40 AM, Boehm, Hans <hans.boehm at hp.com> wrote:
>>
>> > From: Pavel Rappo
>> >
>> > If you see some concurrent behaviour that violates JMM then what else
>> > could that be?
>> A JDK bug AND a serious test suite omission?
>>
>> But is the problem real? ?Can it be reproduced on a mainstream JVM?
>>
>> Note that the example in the original posting also read b before the loop,
>> so na?ve common subexpression elimination would cause the bug. ?Hopefully
>> nobody does CSE in cases like this.
>>
>> Hans
>> >
>> > On 16 May 2012, at 20:55, Zhong Yu wrote:
>> >
>> > > as reported on
>> > > http://stackoverflow.com/questions/10620680
>> > >
>> > > basically there are
>> > >
>> > > ? ?volatile int a;
>> > > ? ?int b;
>> > >
>> > > Thread 1:
>> > >
>> > > ? ?b=1;
>> > > ? ?a=1;
>> > >
>> > > Thread 2:
>> > >
>> > > ? ?while(a==0)
>> > > ? ? ? ?;
>> > > ? ?if(b==0)
>> > > ? ? ? ?print("error");
>> > >
>> > > "error" is seen printed on 32 bit JDK6 on 64bit machine
>> > > _______________________________________________
>> > > Concurrency-interest mailing list
>> > > Concurrency-interest at cs.oswego.edu
>> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From vitalyd at gmail.com  Wed May 16 15:12:25 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 16 May 2012 15:12:25 -0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
Message-ID: <CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>

It can be a compiler (mis)optimization that causes this, and not x86 memory
ordering.

Someone posted the assembly output in the comments on SO and it does seem
like there's a place that loads 'b' from the stack rather than memory.
Hans' theory of CSE sounds plausible - can someone repro this without that
"int tt = b;" line?

Adding hotspot compiler guys in case they want to chime in.

Sent from my phone
On May 16, 2012 3:07 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
wrote:

> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com> wrote:
> > A JDK bug AND a serious test suite omission?
>
> Stress tests would probably JIT-compile the code in question. See below.
>
> > But is the problem real?  Can it be reproduced on a mainstream JVM?
>
> Same question.
>
> > Note that the example in the original posting also read b before the
> loop,
> > so na?ve common subexpression elimination would cause the bug.  Hopefully
> > nobody does CSE in cases like this.
>
> FWIW, the test case in SO would probably not hit any compilation
> threshold in HotSpot, so it could be executed in interpreter. Then,
> assuming the interpreter does not reorder Java code, and assuming
> original SO poster runs Windows, and hence x86, and hence has TSO,
> this bug seems very unlikely. I would be surprised if it actually
> *can* be reproduced. That makes the whole story rather interesting.
>
> -Aleksey.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/251fcb51/attachment-0001.html>

From nathan.reynolds at oracle.com  Wed May 16 15:17:36 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 16 May 2012 12:17:36 -0700
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
Message-ID: <4FB3FD50.4060705@oracle.com>

Consider dumping the assembly code.  
http://classparser.blogspot.com/2010/03/hsdis-i386dll.html  The assembly 
code should show a store (i.e. mov) to b before a in Thread 1.  It 
should also show that b is loaded (i.e. mov) after a in Thread 2.  The 
assembly code output will probably help get the bug fixed sooner.  It 
will also show us what exactly went wrong when the bytecode was 
optimized into machine code.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 5/16/2012 12:00 PM, Aleksey Shipilev wrote:
> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans<hans.boehm at hp.com>  wrote:
>> A JDK bug AND a serious test suite omission?
> Stress tests would probably JIT-compile the code in question. See below.
>
>> But is the problem real?  Can it be reproduced on a mainstream JVM?
> Same question.
>
>> Note that the example in the original posting also read b before the loop,
>> so na?ve common subexpression elimination would cause the bug.  Hopefully
>> nobody does CSE in cases like this.
> FWIW, the test case in SO would probably not hit any compilation
> threshold in HotSpot, so it could be executed in interpreter. Then,
> assuming the interpreter does not reorder Java code, and assuming
> original SO poster runs Windows, and hence x86, and hence has TSO,
> this bug seems very unlikely. I would be surprised if it actually
> *can* be reproduced. That makes the whole story rather interesting.
>
> -Aleksey.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/d2f46d03/attachment.html>

From aleksey.shipilev at gmail.com  Wed May 16 15:23:14 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Wed, 16 May 2012 23:23:14 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
Message-ID: <CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>

All right, here's what is on the table.

This bug is reproduced for me on Linux i686 with:
java version "1.7.0_04"
Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)

It reproduces immediately only with -client.
Both -server and -Xint do NOT reproduce the bug.
The code is there in original SO post
http://stackoverflow.com/questions/10620680/why-volatile-in-java-5-doesnt-synchronize-cached-copies-of-variables-with-main

C1 seems to miscompile run(), and indeed does CSE for local:

  # {method} 'run' '()V' in 'Test$1'
[Verified Entry Point]
  0xb4a91e80: mov    %eax,-0x4000(%esp)
  0xb4a91e87: push   %ebp
  0xb4a91e88: sub    $0x18,%esp         ;*invokestatic access$000
                                        ; - Test$1::run at 0 (line 11)
  0xb4a91e8b: mov    $0xa09c4270,%edx   ;   {oop(a 'java/lang/Class' = 'Test')}
>>>>>>  0xb4a91e90: mov    0x74(%edx),%edx    ;*getstatic b <<<<<---- loads $b to %edx
                                        ; - Test::access$000 at 0 (line 1)
                                        ; - Test$1::run at 0 (line 11)
  0xb4a91e93: jmp    0xb4a91e9e         ; OopMap{off=40}
                                        ;*goto
                                        ; - Test$1::run at 10 (line 13)
  0xb4a91e98: test   %eax,0xb77a9100    ;*goto
                                        ; - Test$1::run at 10 (line 13)
                                        ;   {poll}
  0xb4a91e9e: mov    $0xa09c4270,%ecx   ;   {oop(a 'java/lang/Class' = 'Test')}
>>>>>  0xb4a91ea3: mov    0x70(%ecx),%ecx    ;*getstatic a  <<<<< volatile read for $a
                                        ; - Test::access$100 at 0 (line 1)
                                        ; - Test$1::run at 4 (line 13)
  0xb4a91ea6: cmp    $0x0,%ecx     // <---- $a is at %ecx
  0xb4a91ea9: je     0xb4a91e98         ;*ifne
                                        ; - Test$1::run at 7 (line 13)
 >>>> 0xb4a91eab: cmp    $0x0,%edx     // <<<<<<---- $b is cached in %edx here
  0xb4a91eae: jne    0xb4a91ed8         ;*ifne
                                        ; - Test$1::run at 16 (line 17)
  0xb4a91eb4: nopl   0x0(%eax)
  0xb4a91eb8: jmp    0xb4a91f0e         ;   {no_reloc}
  0xb4a91ebd: xchg   %ax,%ax
  0xb4a91ec0: jmp    0xb4a91f28         ; implicit exception:
dispatches to 0xb4a91f18
  0xb4a91ec5: nop                       ;*getstatic out
                                        ; - Test$1::run at 19 (line 18)
  0xb4a91ec6: cmp    (%ecx),%eax        ; implicit exception:
dispatches to 0xb4a91f32
  0xb4a91ec8: mov    $0xa09c6488,%edx   ;*invokevirtual println
                                        ; - Test$1::run at 24 (line 18)
                                        ;   {oop("error")}


Thanks,
Aleksey.

On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> It can be a compiler (mis)optimization that causes this, and not x86 memory
> ordering.
>
> Someone posted the assembly output in the comments on SO and it does seem
> like there's a place that loads 'b' from the stack rather than memory.
> Hans' theory of CSE sounds plausible - can someone repro this without that
> "int tt = b;" line?
>
> Adding hotspot compiler guys in case they want to chime in.
>
> Sent from my phone
>
> On May 16, 2012 3:07 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
> wrote:
>>
>> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com> wrote:
>> > A JDK bug AND a serious test suite omission?
>>
>> Stress tests would probably JIT-compile the code in question. See below.
>>
>> > But is the problem real? ?Can it be reproduced on a mainstream JVM?
>>
>> Same question.
>>
>> > Note that the example in the original posting also read b before the
>> > loop,
>> > so na?ve common subexpression elimination would cause the bug.
>> > ?Hopefully
>> > nobody does CSE in cases like this.
>>
>> FWIW, the test case in SO would probably not hit any compilation
>> threshold in HotSpot, so it could be executed in interpreter. Then,
>> assuming the interpreter does not reorder Java code, and assuming
>> original SO poster runs Windows, and hence x86, and hence has TSO,
>> this bug seems very unlikely. I would be surprised if it actually
>> *can* be reproduced. That makes the whole story rather interesting.
>>
>> -Aleksey.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aleksey.shipilev at gmail.com  Wed May 16 15:55:13 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Wed, 16 May 2012 23:55:13 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
Message-ID: <CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>

Update. GVN is clearly under suspicion -XX:-UseGlobalValueNumbering
mitigates the bug in my setup. Digging through C1 codebase to see
rules for volatiles.

-Aleksey.

On Wed, May 16, 2012 at 11:23 PM, Aleksey Shipilev
<aleksey.shipilev at gmail.com> wrote:
> All right, here's what is on the table.
>
> This bug is reproduced for me on Linux i686 with:
> java version "1.7.0_04"
> Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
> Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)
>
> It reproduces immediately only with -client.
> Both -server and -Xint do NOT reproduce the bug.
> The code is there in original SO post
> http://stackoverflow.com/questions/10620680/why-volatile-in-java-5-doesnt-synchronize-cached-copies-of-variables-with-main
>
> C1 seems to miscompile run(), and indeed does CSE for local:
>
> ?# {method} 'run' '()V' in 'Test$1'
> [Verified Entry Point]
> ?0xb4a91e80: mov ? ?%eax,-0x4000(%esp)
> ?0xb4a91e87: push ? %ebp
> ?0xb4a91e88: sub ? ?$0x18,%esp ? ? ? ? ;*invokestatic access$000
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line 11)
> ?0xb4a91e8b: mov ? ?$0xa09c4270,%edx ? ; ? {oop(a 'java/lang/Class' = 'Test')}
>>>>>>> ?0xb4a91e90: mov ? ?0x74(%edx),%edx ? ?;*getstatic b <<<<<---- loads $b to %edx
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$000 at 0 (line 1)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line 11)
> ?0xb4a91e93: jmp ? ?0xb4a91e9e ? ? ? ? ; OopMap{off=40}
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?;*goto
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line 13)
> ?0xb4a91e98: test ? %eax,0xb77a9100 ? ?;*goto
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line 13)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {poll}
> ?0xb4a91e9e: mov ? ?$0xa09c4270,%ecx ? ; ? {oop(a 'java/lang/Class' = 'Test')}
>>>>>> ?0xb4a91ea3: mov ? ?0x70(%ecx),%ecx ? ?;*getstatic a ?<<<<< volatile read for $a
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$100 at 0 (line 1)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 4 (line 13)
> ?0xb4a91ea6: cmp ? ?$0x0,%ecx ? ? // <---- $a is at %ecx
> ?0xb4a91ea9: je ? ? 0xb4a91e98 ? ? ? ? ;*ifne
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 7 (line 13)
> ?>>>> 0xb4a91eab: cmp ? ?$0x0,%edx ? ? // <<<<<<---- $b is cached in %edx here
> ?0xb4a91eae: jne ? ?0xb4a91ed8 ? ? ? ? ;*ifne
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 16 (line 17)
> ?0xb4a91eb4: nopl ? 0x0(%eax)
> ?0xb4a91eb8: jmp ? ?0xb4a91f0e ? ? ? ? ; ? {no_reloc}
> ?0xb4a91ebd: xchg ? %ax,%ax
> ?0xb4a91ec0: jmp ? ?0xb4a91f28 ? ? ? ? ; implicit exception:
> dispatches to 0xb4a91f18
> ?0xb4a91ec5: nop ? ? ? ? ? ? ? ? ? ? ? ;*getstatic out
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 19 (line 18)
> ?0xb4a91ec6: cmp ? ?(%ecx),%eax ? ? ? ?; implicit exception:
> dispatches to 0xb4a91f32
> ?0xb4a91ec8: mov ? ?$0xa09c6488,%edx ? ;*invokevirtual println
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 24 (line 18)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {oop("error")}
>
>
> Thanks,
> Aleksey.
>
> On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
>> It can be a compiler (mis)optimization that causes this, and not x86 memory
>> ordering.
>>
>> Someone posted the assembly output in the comments on SO and it does seem
>> like there's a place that loads 'b' from the stack rather than memory.
>> Hans' theory of CSE sounds plausible - can someone repro this without that
>> "int tt = b;" line?
>>
>> Adding hotspot compiler guys in case they want to chime in.
>>
>> Sent from my phone
>>
>> On May 16, 2012 3:07 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
>> wrote:
>>>
>>> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com> wrote:
>>> > A JDK bug AND a serious test suite omission?
>>>
>>> Stress tests would probably JIT-compile the code in question. See below.
>>>
>>> > But is the problem real? ?Can it be reproduced on a mainstream JVM?
>>>
>>> Same question.
>>>
>>> > Note that the example in the original posting also read b before the
>>> > loop,
>>> > so na?ve common subexpression elimination would cause the bug.
>>> > ?Hopefully
>>> > nobody does CSE in cases like this.
>>>
>>> FWIW, the test case in SO would probably not hit any compilation
>>> threshold in HotSpot, so it could be executed in interpreter. Then,
>>> assuming the interpreter does not reorder Java code, and assuming
>>> original SO poster runs Windows, and hence x86, and hence has TSO,
>>> this bug seems very unlikely. I would be surprised if it actually
>>> *can* be reproduced. That makes the whole story rather interesting.
>>>
>>> -Aleksey.
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From vitalyd at gmail.com  Wed May 16 16:34:17 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 16 May 2012 16:34:17 -0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
Message-ID: <CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>

I looked at the assembly on SO again (the pastebin link) and it seems to be
correct actually: after 'a' is cmp'ed against zero, 'b' is read from
memory.  But now someone is saying there that it sometimes generates the
correct assembly and other times not - very strange.
0x025bd2b9: cmp $0x0,%edx

30. 0x025bd2bc: je 0x025bd2a8 ;

32. 0x025bd2be: mov $0x147062e8,%edx ; {oop('test/TestVolatile')}

33. 0x025bd2c3: mov 0x1c4(%edx),%edx ;*getstatic b

34. ; - test.TestVolatile::run at 10 (line 17)

35. 0x025bd2c9: cmp $0x0,%edx

Sent from my phone
On May 16, 2012 3:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
wrote:

> Update. GVN is clearly under suspicion -XX:-UseGlobalValueNumbering
> mitigates the bug in my setup. Digging through C1 codebase to see
> rules for volatiles.
>
> -Aleksey.
>
> On Wed, May 16, 2012 at 11:23 PM, Aleksey Shipilev
> <aleksey.shipilev at gmail.com> wrote:
> > All right, here's what is on the table.
> >
> > This bug is reproduced for me on Linux i686 with:
> > java version "1.7.0_04"
> > Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
> > Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)
> >
> > It reproduces immediately only with -client.
> > Both -server and -Xint do NOT reproduce the bug.
> > The code is there in original SO post
> >
> http://stackoverflow.com/questions/10620680/why-volatile-in-java-5-doesnt-synchronize-cached-copies-of-variables-with-main
> >
> > C1 seems to miscompile run(), and indeed does CSE for local:
> >
> >  # {method} 'run' '()V' in 'Test$1'
> > [Verified Entry Point]
> >  0xb4a91e80: mov    %eax,-0x4000(%esp)
> >  0xb4a91e87: push   %ebp
> >  0xb4a91e88: sub    $0x18,%esp         ;*invokestatic access$000
> >                                        ; - Test$1::run at 0 (line 11)
> >  0xb4a91e8b: mov    $0xa09c4270,%edx   ;   {oop(a 'java/lang/Class' =
> 'Test')}
> >>>>>>>  0xb4a91e90: mov    0x74(%edx),%edx    ;*getstatic b <<<<<----
> loads $b to %edx
> >                                        ; - Test::access$000 at 0 (line 1)
> >                                        ; - Test$1::run at 0 (line 11)
> >  0xb4a91e93: jmp    0xb4a91e9e         ; OopMap{off=40}
> >                                        ;*goto
> >                                        ; - Test$1::run at 10 (line 13)
> >  0xb4a91e98: test   %eax,0xb77a9100    ;*goto
> >                                        ; - Test$1::run at 10 (line 13)
> >                                        ;   {poll}
> >  0xb4a91e9e: mov    $0xa09c4270,%ecx   ;   {oop(a 'java/lang/Class' =
> 'Test')}
> >>>>>>  0xb4a91ea3: mov    0x70(%ecx),%ecx    ;*getstatic a  <<<<<
> volatile read for $a
> >                                        ; - Test::access$100 at 0 (line 1)
> >                                        ; - Test$1::run at 4 (line 13)
> >  0xb4a91ea6: cmp    $0x0,%ecx     // <---- $a is at %ecx
> >  0xb4a91ea9: je     0xb4a91e98         ;*ifne
> >                                        ; - Test$1::run at 7 (line 13)
> >  >>>> 0xb4a91eab: cmp    $0x0,%edx     // <<<<<<---- $b is cached in
> %edx here
> >  0xb4a91eae: jne    0xb4a91ed8         ;*ifne
> >                                        ; - Test$1::run at 16 (line 17)
> >  0xb4a91eb4: nopl   0x0(%eax)
> >  0xb4a91eb8: jmp    0xb4a91f0e         ;   {no_reloc}
> >  0xb4a91ebd: xchg   %ax,%ax
> >  0xb4a91ec0: jmp    0xb4a91f28         ; implicit exception:
> > dispatches to 0xb4a91f18
> >  0xb4a91ec5: nop                       ;*getstatic out
> >                                        ; - Test$1::run at 19 (line 18)
> >  0xb4a91ec6: cmp    (%ecx),%eax        ; implicit exception:
> > dispatches to 0xb4a91f32
> >  0xb4a91ec8: mov    $0xa09c6488,%edx   ;*invokevirtual println
> >                                        ; - Test$1::run at 24 (line 18)
> >                                        ;   {oop("error")}
> >
> >
> > Thanks,
> > Aleksey.
> >
> > On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
> >> It can be a compiler (mis)optimization that causes this, and not x86
> memory
> >> ordering.
> >>
> >> Someone posted the assembly output in the comments on SO and it does
> seem
> >> like there's a place that loads 'b' from the stack rather than memory.
> >> Hans' theory of CSE sounds plausible - can someone repro this without
> that
> >> "int tt = b;" line?
> >>
> >> Adding hotspot compiler guys in case they want to chime in.
> >>
> >> Sent from my phone
> >>
> >> On May 16, 2012 3:07 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com
> >
> >> wrote:
> >>>
> >>> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com>
> wrote:
> >>> > A JDK bug AND a serious test suite omission?
> >>>
> >>> Stress tests would probably JIT-compile the code in question. See
> below.
> >>>
> >>> > But is the problem real?  Can it be reproduced on a mainstream JVM?
> >>>
> >>> Same question.
> >>>
> >>> > Note that the example in the original posting also read b before the
> >>> > loop,
> >>> > so na?ve common subexpression elimination would cause the bug.
> >>> >  Hopefully
> >>> > nobody does CSE in cases like this.
> >>>
> >>> FWIW, the test case in SO would probably not hit any compilation
> >>> threshold in HotSpot, so it could be executed in interpreter. Then,
> >>> assuming the interpreter does not reorder Java code, and assuming
> >>> original SO poster runs Windows, and hence x86, and hence has TSO,
> >>> this bug seems very unlikely. I would be surprised if it actually
> >>> *can* be reproduced. That makes the whole story rather interesting.
> >>>
> >>> -Aleksey.
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120516/a006b643/attachment-0001.html>

From aleksey.shipilev at gmail.com  Wed May 16 16:41:15 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Thu, 17 May 2012 00:41:15 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
Message-ID: <CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>

In my case, there are always two compiled versions for Test$1.run, one
with cached $b, second one is with correct read for $b. I'd guess
pastebin version had the second one.

-Aleksey.

On Thu, May 17, 2012 at 12:34 AM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> I looked at the assembly on SO again (the pastebin link) and it seems to be
> correct actually: after 'a' is cmp'ed against zero, 'b' is read from
> memory.? But now someone is saying there that it sometimes generates the
> correct assembly and other times not - very strange.
> 0x025bd2b9: cmp $0x0,%edx
>
> 30. 0x025bd2bc: je 0x025bd2a8 ;
>
> 32. 0x025bd2be: mov $0x147062e8,%edx ; {oop('test/TestVolatile')}
>
> 33. 0x025bd2c3: mov 0x1c4(%edx),%edx ;*getstatic b
>
> 34. ; - test.TestVolatile::run at 10 (line 17)
>
> 35. 0x025bd2c9: cmp $0x0,%edx
>
> Sent from my phone
>
> On May 16, 2012 3:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
> wrote:
>>
>> Update. GVN is clearly under suspicion -XX:-UseGlobalValueNumbering
>> mitigates the bug in my setup. Digging through C1 codebase to see
>> rules for volatiles.
>>
>> -Aleksey.
>>
>> On Wed, May 16, 2012 at 11:23 PM, Aleksey Shipilev
>> <aleksey.shipilev at gmail.com> wrote:
>> > All right, here's what is on the table.
>> >
>> > This bug is reproduced for me on Linux i686 with:
>> > java version "1.7.0_04"
>> > Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
>> > Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)
>> >
>> > It reproduces immediately only with -client.
>> > Both -server and -Xint do NOT reproduce the bug.
>> > The code is there in original SO post
>> >
>> > http://stackoverflow.com/questions/10620680/why-volatile-in-java-5-doesnt-synchronize-cached-copies-of-variables-with-main
>> >
>> > C1 seems to miscompile run(), and indeed does CSE for local:
>> >
>> > ?# {method} 'run' '()V' in 'Test$1'
>> > [Verified Entry Point]
>> > ?0xb4a91e80: mov ? ?%eax,-0x4000(%esp)
>> > ?0xb4a91e87: push ? %ebp
>> > ?0xb4a91e88: sub ? ?$0x18,%esp ? ? ? ? ;*invokestatic access$000
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line 11)
>> > ?0xb4a91e8b: mov ? ?$0xa09c4270,%edx ? ; ? {oop(a 'java/lang/Class' =
>> > 'Test')}
>> >>>>>>> ?0xb4a91e90: mov ? ?0x74(%edx),%edx ? ?;*getstatic b <<<<<----
>> >>>>>>> loads $b to %edx
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$000 at 0 (line 1)
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line 11)
>> > ?0xb4a91e93: jmp ? ?0xb4a91e9e ? ? ? ? ; OopMap{off=40}
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?;*goto
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line 13)
>> > ?0xb4a91e98: test ? %eax,0xb77a9100 ? ?;*goto
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line 13)
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {poll}
>> > ?0xb4a91e9e: mov ? ?$0xa09c4270,%ecx ? ; ? {oop(a 'java/lang/Class' =
>> > 'Test')}
>> >>>>>> ?0xb4a91ea3: mov ? ?0x70(%ecx),%ecx ? ?;*getstatic a ?<<<<<
>> >>>>>> volatile read for $a
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$100 at 0 (line 1)
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 4 (line 13)
>> > ?0xb4a91ea6: cmp ? ?$0x0,%ecx ? ? // <---- $a is at %ecx
>> > ?0xb4a91ea9: je ? ? 0xb4a91e98 ? ? ? ? ;*ifne
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 7 (line 13)
>> > ?>>>> 0xb4a91eab: cmp ? ?$0x0,%edx ? ? // <<<<<<---- $b is cached in
>> > %edx here
>> > ?0xb4a91eae: jne ? ?0xb4a91ed8 ? ? ? ? ;*ifne
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 16 (line 17)
>> > ?0xb4a91eb4: nopl ? 0x0(%eax)
>> > ?0xb4a91eb8: jmp ? ?0xb4a91f0e ? ? ? ? ; ? {no_reloc}
>> > ?0xb4a91ebd: xchg ? %ax,%ax
>> > ?0xb4a91ec0: jmp ? ?0xb4a91f28 ? ? ? ? ; implicit exception:
>> > dispatches to 0xb4a91f18
>> > ?0xb4a91ec5: nop ? ? ? ? ? ? ? ? ? ? ? ;*getstatic out
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 19 (line 18)
>> > ?0xb4a91ec6: cmp ? ?(%ecx),%eax ? ? ? ?; implicit exception:
>> > dispatches to 0xb4a91f32
>> > ?0xb4a91ec8: mov ? ?$0xa09c6488,%edx ? ;*invokevirtual println
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 24 (line 18)
>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {oop("error")}
>> >
>> >
>> > Thanks,
>> > Aleksey.
>> >
>> > On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> > wrote:
>> >> It can be a compiler (mis)optimization that causes this, and not x86
>> >> memory
>> >> ordering.
>> >>
>> >> Someone posted the assembly output in the comments on SO and it does
>> >> seem
>> >> like there's a place that loads 'b' from the stack rather than memory.
>> >> Hans' theory of CSE sounds plausible - can someone repro this without
>> >> that
>> >> "int tt = b;" line?
>> >>
>> >> Adding hotspot compiler guys in case they want to chime in.
>> >>
>> >> Sent from my phone
>> >>
>> >> On May 16, 2012 3:07 PM, "Aleksey Shipilev"
>> >> <aleksey.shipilev at gmail.com>
>> >> wrote:
>> >>>
>> >>> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com>
>> >>> wrote:
>> >>> > A JDK bug AND a serious test suite omission?
>> >>>
>> >>> Stress tests would probably JIT-compile the code in question. See
>> >>> below.
>> >>>
>> >>> > But is the problem real? ?Can it be reproduced on a mainstream JVM?
>> >>>
>> >>> Same question.
>> >>>
>> >>> > Note that the example in the original posting also read b before the
>> >>> > loop,
>> >>> > so na?ve common subexpression elimination would cause the bug.
>> >>> > ?Hopefully
>> >>> > nobody does CSE in cases like this.
>> >>>
>> >>> FWIW, the test case in SO would probably not hit any compilation
>> >>> threshold in HotSpot, so it could be executed in interpreter. Then,
>> >>> assuming the interpreter does not reorder Java code, and assuming
>> >>> original SO poster runs Windows, and hence x86, and hence has TSO,
>> >>> this bug seems very unlikely. I would be surprised if it actually
>> >>> *can* be reproduced. That makes the whole story rather interesting.
>> >>>
>> >>> -Aleksey.
>> >>>
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From forax at univ-mlv.fr  Wed May 16 16:58:40 2012
From: forax at univ-mlv.fr (=?UTF-8?B?UsOpbWkgRm9yYXg=?=)
Date: Wed, 16 May 2012 22:58:40 +0200
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
Message-ID: <4FB41500.4000007@univ-mlv.fr>

On 05/16/2012 10:41 PM, Aleksey Shipilev wrote:
> In my case, there are always two compiled versions for Test$1.run, one
> with cached $b, second one is with correct read for $b. I'd guess
> pastebin version had the second one.
>
> -Aleksey.

one version is the OSR version,
the second one is the classical one.

R?mi


From aleksey.shipilev at gmail.com  Wed May 16 17:22:17 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Thu, 17 May 2012 01:22:17 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
Message-ID: <CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>

Well, I do not want to sound alarming, but... if I understand the C1
code correctly, then C1 GVN does not account prior volatile reads at
all. I can not find any code in C1 GVN code which actually prevents
killing second non-volatile read after volatile one, which is required
by JMM semantics.

I think I'll stop here. The impact of this issue is limited, given
most of the guys run -server (even by default on most machines), so
there is always the workaround for running with -server. Also, I would
*speculate* turning off GVN with -XX:-UseGlobalValueNumbering when
running with -client is still a workaround, but kind of insane one,
since it can *severely* degrade performance.

Words of wisdom: I'm using this command-line to print out GVN tracing:
$ ~/Install/jdk7u4/fastdebug/bin/java -XX:+PrintCompilation
-XX:+PrintDominators -XX:+PrintCompilation  -XX:+PrintValueNumbering
-Xbatch -XX:CompileOnly=Test.$1,Test -client  Test 2>&1 | tee asm.log

Can anyone more proficient in C1 code confirm this?

-Aleksey.

On Thu, May 17, 2012 at 12:41 AM, Aleksey Shipilev
<aleksey.shipilev at gmail.com> wrote:
> In my case, there are always two compiled versions for Test$1.run, one
> with cached $b, second one is with correct read for $b. I'd guess
> pastebin version had the second one.
>
> -Aleksey.
>
> On Thu, May 17, 2012 at 12:34 AM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
>> I looked at the assembly on SO again (the pastebin link) and it seems to be
>> correct actually: after 'a' is cmp'ed against zero, 'b' is read from
>> memory.? But now someone is saying there that it sometimes generates the
>> correct assembly and other times not - very strange.
>> 0x025bd2b9: cmp $0x0,%edx
>>
>> 30. 0x025bd2bc: je 0x025bd2a8 ;
>>
>> 32. 0x025bd2be: mov $0x147062e8,%edx ; {oop('test/TestVolatile')}
>>
>> 33. 0x025bd2c3: mov 0x1c4(%edx),%edx ;*getstatic b
>>
>> 34. ; - test.TestVolatile::run at 10 (line 17)
>>
>> 35. 0x025bd2c9: cmp $0x0,%edx
>>
>> Sent from my phone
>>
>> On May 16, 2012 3:55 PM, "Aleksey Shipilev" <aleksey.shipilev at gmail.com>
>> wrote:
>>>
>>> Update. GVN is clearly under suspicion -XX:-UseGlobalValueNumbering
>>> mitigates the bug in my setup. Digging through C1 codebase to see
>>> rules for volatiles.
>>>
>>> -Aleksey.
>>>
>>> On Wed, May 16, 2012 at 11:23 PM, Aleksey Shipilev
>>> <aleksey.shipilev at gmail.com> wrote:
>>> > All right, here's what is on the table.
>>> >
>>> > This bug is reproduced for me on Linux i686 with:
>>> > java version "1.7.0_04"
>>> > Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
>>> > Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)
>>> >
>>> > It reproduces immediately only with -client.
>>> > Both -server and -Xint do NOT reproduce the bug.
>>> > The code is there in original SO post
>>> >
>>> > http://stackoverflow.com/questions/10620680/why-volatile-in-java-5-doesnt-synchronize-cached-copies-of-variables-with-main
>>> >
>>> > C1 seems to miscompile run(), and indeed does CSE for local:
>>> >
>>> > ?# {method} 'run' '()V' in 'Test$1'
>>> > [Verified Entry Point]
>>> > ?0xb4a91e80: mov ? ?%eax,-0x4000(%esp)
>>> > ?0xb4a91e87: push ? %ebp
>>> > ?0xb4a91e88: sub ? ?$0x18,%esp ? ? ? ? ;*invokestatic access$000
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line 11)
>>> > ?0xb4a91e8b: mov ? ?$0xa09c4270,%edx ? ; ? {oop(a 'java/lang/Class' =
>>> > 'Test')}
>>> >>>>>>> ?0xb4a91e90: mov ? ?0x74(%edx),%edx ? ?;*getstatic b <<<<<----
>>> >>>>>>> loads $b to %edx
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$000 at 0 (line 1)
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line 11)
>>> > ?0xb4a91e93: jmp ? ?0xb4a91e9e ? ? ? ? ; OopMap{off=40}
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?;*goto
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line 13)
>>> > ?0xb4a91e98: test ? %eax,0xb77a9100 ? ?;*goto
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line 13)
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {poll}
>>> > ?0xb4a91e9e: mov ? ?$0xa09c4270,%ecx ? ; ? {oop(a 'java/lang/Class' =
>>> > 'Test')}
>>> >>>>>> ?0xb4a91ea3: mov ? ?0x70(%ecx),%ecx ? ?;*getstatic a ?<<<<<
>>> >>>>>> volatile read for $a
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$100 at 0 (line 1)
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 4 (line 13)
>>> > ?0xb4a91ea6: cmp ? ?$0x0,%ecx ? ? // <---- $a is at %ecx
>>> > ?0xb4a91ea9: je ? ? 0xb4a91e98 ? ? ? ? ;*ifne
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 7 (line 13)
>>> > ?>>>> 0xb4a91eab: cmp ? ?$0x0,%edx ? ? // <<<<<<---- $b is cached in
>>> > %edx here
>>> > ?0xb4a91eae: jne ? ?0xb4a91ed8 ? ? ? ? ;*ifne
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 16 (line 17)
>>> > ?0xb4a91eb4: nopl ? 0x0(%eax)
>>> > ?0xb4a91eb8: jmp ? ?0xb4a91f0e ? ? ? ? ; ? {no_reloc}
>>> > ?0xb4a91ebd: xchg ? %ax,%ax
>>> > ?0xb4a91ec0: jmp ? ?0xb4a91f28 ? ? ? ? ; implicit exception:
>>> > dispatches to 0xb4a91f18
>>> > ?0xb4a91ec5: nop ? ? ? ? ? ? ? ? ? ? ? ;*getstatic out
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 19 (line 18)
>>> > ?0xb4a91ec6: cmp ? ?(%ecx),%eax ? ? ? ?; implicit exception:
>>> > dispatches to 0xb4a91f32
>>> > ?0xb4a91ec8: mov ? ?$0xa09c6488,%edx ? ;*invokevirtual println
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 24 (line 18)
>>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {oop("error")}
>>> >
>>> >
>>> > Thanks,
>>> > Aleksey.
>>> >
>>> > On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich <vitalyd at gmail.com>
>>> > wrote:
>>> >> It can be a compiler (mis)optimization that causes this, and not x86
>>> >> memory
>>> >> ordering.
>>> >>
>>> >> Someone posted the assembly output in the comments on SO and it does
>>> >> seem
>>> >> like there's a place that loads 'b' from the stack rather than memory.
>>> >> Hans' theory of CSE sounds plausible - can someone repro this without
>>> >> that
>>> >> "int tt = b;" line?
>>> >>
>>> >> Adding hotspot compiler guys in case they want to chime in.
>>> >>
>>> >> Sent from my phone
>>> >>
>>> >> On May 16, 2012 3:07 PM, "Aleksey Shipilev"
>>> >> <aleksey.shipilev at gmail.com>
>>> >> wrote:
>>> >>>
>>> >>> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans <hans.boehm at hp.com>
>>> >>> wrote:
>>> >>> > A JDK bug AND a serious test suite omission?
>>> >>>
>>> >>> Stress tests would probably JIT-compile the code in question. See
>>> >>> below.
>>> >>>
>>> >>> > But is the problem real? ?Can it be reproduced on a mainstream JVM?
>>> >>>
>>> >>> Same question.
>>> >>>
>>> >>> > Note that the example in the original posting also read b before the
>>> >>> > loop,
>>> >>> > so na?ve common subexpression elimination would cause the bug.
>>> >>> > ?Hopefully
>>> >>> > nobody does CSE in cases like this.
>>> >>>
>>> >>> FWIW, the test case in SO would probably not hit any compilation
>>> >>> threshold in HotSpot, so it could be executed in interpreter. Then,
>>> >>> assuming the interpreter does not reorder Java code, and assuming
>>> >>> original SO poster runs Windows, and hence x86, and hence has TSO,
>>> >>> this bug seems very unlikely. I would be surprised if it actually
>>> >>> *can* be reproduced. That makes the whole story rather interesting.
>>> >>>
>>> >>> -Aleksey.
>>> >>>
>>> >>> _______________________________________________
>>> >>> Concurrency-interest mailing list
>>> >>> Concurrency-interest at cs.oswego.edu
>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From hans.boehm at hp.com  Wed May 16 18:01:50 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 16 May 2012 22:01:50 +0000
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>

Would it make sense to expand a test suite with a bunch of memory model tests, e.g.:

no CSE across volatile load
corresponding test for a volatile store:
	r1 = x; v = ...; r2 = x;  use r1   doesn't replace the use of r1 with r2
Dekker's example
No fusion of potentially infinite loops
Maybe IRIW/write atomicity

?

My main concern here stems from the fact that this is perhaps the most basic
test of volatiles that fails.  Is there any reason to believe the
harder-to-enforce properties of volatiles hold?

Hans

> -----Original Message-----
> From: Aleksey Shipilev [mailto:aleksey.shipilev at gmail.com]
> Sent: Wednesday, May 16, 2012 2:22 PM
> To: Vitaly Davidovich
> Cc: Boehm, Hans; hotspot compiler; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] a volatile bug?
> 
> Well, I do not want to sound alarming, but... if I understand the C1
> code correctly, then C1 GVN does not account prior volatile reads at
> all. I can not find any code in C1 GVN code which actually prevents
> killing second non-volatile read after volatile one, which is required
> by JMM semantics.
> 
> I think I'll stop here. The impact of this issue is limited, given
> most of the guys run -server (even by default on most machines), so
> there is always the workaround for running with -server. Also, I would
> *speculate* turning off GVN with -XX:-UseGlobalValueNumbering when
> running with -client is still a workaround, but kind of insane one,
> since it can *severely* degrade performance.
> 
> Words of wisdom: I'm using this command-line to print out GVN tracing:
> $ ~/Install/jdk7u4/fastdebug/bin/java -XX:+PrintCompilation
> -XX:+PrintDominators -XX:+PrintCompilation  -XX:+PrintValueNumbering
> -Xbatch -XX:CompileOnly=Test.$1,Test -client  Test 2>&1 | tee asm.log
> 
> Can anyone more proficient in C1 code confirm this?
> 
> -Aleksey.
> 
> On Thu, May 17, 2012 at 12:41 AM, Aleksey Shipilev
> <aleksey.shipilev at gmail.com> wrote:
> > In my case, there are always two compiled versions for Test$1.run,
> one
> > with cached $b, second one is with correct read for $b. I'd guess
> > pastebin version had the second one.
> >
> > -Aleksey.
> >
> > On Thu, May 17, 2012 at 12:34 AM, Vitaly Davidovich
> <vitalyd at gmail.com> wrote:
> >> I looked at the assembly on SO again (the pastebin link) and it
> seems to be
> >> correct actually: after 'a' is cmp'ed against zero, 'b' is read from
> >> memory.? But now someone is saying there that it sometimes generates
> the
> >> correct assembly and other times not - very strange.
> >> 0x025bd2b9: cmp $0x0,%edx
> >>
> >> 30. 0x025bd2bc: je 0x025bd2a8 ;
> >>
> >> 32. 0x025bd2be: mov $0x147062e8,%edx ; {oop('test/TestVolatile')}
> >>
> >> 33. 0x025bd2c3: mov 0x1c4(%edx),%edx ;*getstatic b
> >>
> >> 34. ; - test.TestVolatile::run at 10 (line 17)
> >>
> >> 35. 0x025bd2c9: cmp $0x0,%edx
> >>
> >> Sent from my phone
> >>
> >> On May 16, 2012 3:55 PM, "Aleksey Shipilev"
> <aleksey.shipilev at gmail.com>
> >> wrote:
> >>>
> >>> Update. GVN is clearly under suspicion -XX:-UseGlobalValueNumbering
> >>> mitigates the bug in my setup. Digging through C1 codebase to see
> >>> rules for volatiles.
> >>>
> >>> -Aleksey.
> >>>
> >>> On Wed, May 16, 2012 at 11:23 PM, Aleksey Shipilev
> >>> <aleksey.shipilev at gmail.com> wrote:
> >>> > All right, here's what is on the table.
> >>> >
> >>> > This bug is reproduced for me on Linux i686 with:
> >>> > java version "1.7.0_04"
> >>> > Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
> >>> > Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)
> >>> >
> >>> > It reproduces immediately only with -client.
> >>> > Both -server and -Xint do NOT reproduce the bug.
> >>> > The code is there in original SO post
> >>> >
> >>> > http://stackoverflow.com/questions/10620680/why-volatile-in-java-
> 5-doesnt-synchronize-cached-copies-of-variables-with-main
> >>> >
> >>> > C1 seems to miscompile run(), and indeed does CSE for local:
> >>> >
> >>> > ?# {method} 'run' '()V' in 'Test$1'
> >>> > [Verified Entry Point]
> >>> > ?0xb4a91e80: mov ? ?%eax,-0x4000(%esp)
> >>> > ?0xb4a91e87: push ? %ebp
> >>> > ?0xb4a91e88: sub ? ?$0x18,%esp ? ? ? ? ;*invokestatic access$000
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line
> 11)
> >>> > ?0xb4a91e8b: mov ? ?$0xa09c4270,%edx ? ; ? {oop(a
> 'java/lang/Class' =
> >>> > 'Test')}
> >>> >>>>>>> ?0xb4a91e90: mov ? ?0x74(%edx),%edx ? ?;*getstatic b <<<<<-
> ---
> >>> >>>>>>> loads $b to %edx
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$000 at 0
> (line 1)
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line
> 11)
> >>> > ?0xb4a91e93: jmp ? ?0xb4a91e9e ? ? ? ? ; OopMap{off=40}
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?;*goto
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line
> 13)
> >>> > ?0xb4a91e98: test ? %eax,0xb77a9100 ? ?;*goto
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line
> 13)
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {poll}
> >>> > ?0xb4a91e9e: mov ? ?$0xa09c4270,%ecx ? ; ? {oop(a
> 'java/lang/Class' =
> >>> > 'Test')}
> >>> >>>>>> ?0xb4a91ea3: mov ? ?0x70(%ecx),%ecx ? ?;*getstatic a ?<<<<<
> >>> >>>>>> volatile read for $a
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$100 at 0
> (line 1)
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 4 (line
> 13)
> >>> > ?0xb4a91ea6: cmp ? ?$0x0,%ecx ? ? // <---- $a is at %ecx
> >>> > ?0xb4a91ea9: je ? ? 0xb4a91e98 ? ? ? ? ;*ifne
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 7 (line
> 13)
> >>> > ?>>>> 0xb4a91eab: cmp ? ?$0x0,%edx ? ? // <<<<<<---- $b is cached
> in
> >>> > %edx here
> >>> > ?0xb4a91eae: jne ? ?0xb4a91ed8 ? ? ? ? ;*ifne
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 16 (line
> 17)
> >>> > ?0xb4a91eb4: nopl ? 0x0(%eax)
> >>> > ?0xb4a91eb8: jmp ? ?0xb4a91f0e ? ? ? ? ; ? {no_reloc}
> >>> > ?0xb4a91ebd: xchg ? %ax,%ax
> >>> > ?0xb4a91ec0: jmp ? ?0xb4a91f28 ? ? ? ? ; implicit exception:
> >>> > dispatches to 0xb4a91f18
> >>> > ?0xb4a91ec5: nop ? ? ? ? ? ? ? ? ? ? ? ;*getstatic out
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 19 (line
> 18)
> >>> > ?0xb4a91ec6: cmp ? ?(%ecx),%eax ? ? ? ?; implicit exception:
> >>> > dispatches to 0xb4a91f32
> >>> > ?0xb4a91ec8: mov ? ?$0xa09c6488,%edx ? ;*invokevirtual println
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 24 (line
> 18)
> >>> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {oop("error")}
> >>> >
> >>> >
> >>> > Thanks,
> >>> > Aleksey.
> >>> >
> >>> > On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich
> <vitalyd at gmail.com>
> >>> > wrote:
> >>> >> It can be a compiler (mis)optimization that causes this, and not
> x86
> >>> >> memory
> >>> >> ordering.
> >>> >>
> >>> >> Someone posted the assembly output in the comments on SO and it
> does
> >>> >> seem
> >>> >> like there's a place that loads 'b' from the stack rather than
> memory.
> >>> >> Hans' theory of CSE sounds plausible - can someone repro this
> without
> >>> >> that
> >>> >> "int tt = b;" line?
> >>> >>
> >>> >> Adding hotspot compiler guys in case they want to chime in.
> >>> >>
> >>> >> Sent from my phone
> >>> >>
> >>> >> On May 16, 2012 3:07 PM, "Aleksey Shipilev"
> >>> >> <aleksey.shipilev at gmail.com>
> >>> >> wrote:
> >>> >>>
> >>> >>> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans
> <hans.boehm at hp.com>
> >>> >>> wrote:
> >>> >>> > A JDK bug AND a serious test suite omission?
> >>> >>>
> >>> >>> Stress tests would probably JIT-compile the code in question.
> See
> >>> >>> below.
> >>> >>>
> >>> >>> > But is the problem real? ?Can it be reproduced on a
> mainstream JVM?
> >>> >>>
> >>> >>> Same question.
> >>> >>>
> >>> >>> > Note that the example in the original posting also read b
> before the
> >>> >>> > loop,
> >>> >>> > so na?ve common subexpression elimination would cause the
> bug.
> >>> >>> > ?Hopefully
> >>> >>> > nobody does CSE in cases like this.
> >>> >>>
> >>> >>> FWIW, the test case in SO would probably not hit any
> compilation
> >>> >>> threshold in HotSpot, so it could be executed in interpreter.
> Then,
> >>> >>> assuming the interpreter does not reorder Java code, and
> assuming
> >>> >>> original SO poster runs Windows, and hence x86, and hence has
> TSO,
> >>> >>> this bug seems very unlikely. I would be surprised if it
> actually
> >>> >>> *can* be reproduced. That makes the whole story rather
> interesting.
> >>> >>>
> >>> >>> -Aleksey.
> >>> >>>
> >>> >>> _______________________________________________
> >>> >>> Concurrency-interest mailing list
> >>> >>> Concurrency-interest at cs.oswego.edu
> >>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From heinz at javaspecialists.eu  Thu May 17 15:59:10 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 17 May 2012 22:59:10 +0300
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
Message-ID: <4FB5588E.1070409@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120517/96600f98/attachment.html>

From aleksey.shipilev at gmail.com  Thu May 17 16:22:43 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Fri, 18 May 2012 00:22:43 +0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <4FB5588E.1070409@javaspecialists.eu>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
	<4FB5588E.1070409@javaspecialists.eu>
Message-ID: <CA+1LWGGWLXQQOcSG+AuHs187CdTyJDbDNOZDadzS0SXFUEb6mg@mail.gmail.com>

Interesting but unrelated bug, is there a CR already?
Basically, if you run the test with safepoint tracing, you will see:

$ ~/Install/jdk7u4/bin/java -XX:+SafepointTimeout -server VirtualMachineLiveLock
...
temp = 34
temp = 35
temp = 36
temp = 37
temp = 38
temp = 39
# SafepointSynchronize::begin: Timeout detected:
# SafepointSynchronize::begin: Timed out while spinning to reach a safepoint.
# SafepointSynchronize::begin: Threads which did not reach the safepoint:
# "Thread-1" prio=10 tid=0x6bcff000 nid=0x117a runnable [0x00000000]
   java.lang.Thread.State: RUNNABLE

# SafepointSynchronize::begin: (End of list)

-Aleksey.

On Thu, May 17, 2012 at 11:59 PM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> That's not all.
>
> Using volatile fields, you can cause a beautiful unbreakable hard spin in
> JVM Server Hotspot since 1.6.0_14, basically livelocking the JVM.? It won't
> react to any of the usual Java tools, like jconsole, jstack, etc.? Only kill
> -9 to shut it down, plus of course the usual C tools.
>
> https://github.com/kabutz/javaspecialists/blob/master/src/main/java/eu/javaspecialists/tjsn/examples/issue188/VirtualMachineLiveLock.java
>
> and mentioned (briefly) at the end of
> http://www.javaspecialists.eu/archive/Issue188.html
>
> I discovered this in 2010 already, but have so far not managed to get it
> fixed.
>
> And this is a bug in the Server HotSpot JVM - so that is not necessarily a
> refuge where you can hide from volatile bugs!
>
> As we approach the limits with our clever concurrent code, I believe we will
> see issues like this crop up more and more.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 5/17/12 1:01 AM, Boehm, Hans wrote:
>
> Would it make sense to expand a test suite with a bunch of memory model
> tests, e.g.:
>
> no CSE across volatile load
> corresponding test for a volatile store:
> 	r1 = x; v = ...; r2 = x;  use r1   doesn't replace the use of r1 with r2
> Dekker's example
> No fusion of potentially infinite loops
> Maybe IRIW/write atomicity
>
> ?
>
> My main concern here stems from the fact that this is perhaps the most basic
> test of volatiles that fails.  Is there any reason to believe the
> harder-to-enforce properties of volatiles hold?
>
> Hans
>
>
>
> -----Original Message-----
> From: Aleksey Shipilev [mailto:aleksey.shipilev at gmail.com]
> Sent: Wednesday, May 16, 2012 2:22 PM
> To: Vitaly Davidovich
> Cc: Boehm, Hans; hotspot compiler; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] a volatile bug?
>
> Well, I do not want to sound alarming, but... if I understand the C1
> code correctly, then C1 GVN does not account prior volatile reads at
> all. I can not find any code in C1 GVN code which actually prevents
> killing second non-volatile read after volatile one, which is required
> by JMM semantics.
>
> I think I'll stop here. The impact of this issue is limited, given
> most of the guys run -server (even by default on most machines), so
> there is always the workaround for running with -server. Also, I would
> *speculate* turning off GVN with -XX:-UseGlobalValueNumbering when
> running with -client is still a workaround, but kind of insane one,
> since it can *severely* degrade performance.
>
> Words of wisdom: I'm using this command-line to print out GVN tracing:
> $ ~/Install/jdk7u4/fastdebug/bin/java -XX:+PrintCompilation
> -XX:+PrintDominators -XX:+PrintCompilation  -XX:+PrintValueNumbering
> -Xbatch -XX:CompileOnly=Test.$1,Test -client  Test 2>&1 | tee asm.log
>
> Can anyone more proficient in C1 code confirm this?
>
> -Aleksey.
>
> On Thu, May 17, 2012 at 12:41 AM, Aleksey Shipilev
> <aleksey.shipilev at gmail.com> wrote:
>
>
> In my case, there are always two compiled versions for Test$1.run,
>
>
> one
>
>
> with cached $b, second one is with correct read for $b. I'd guess
> pastebin version had the second one.
>
> -Aleksey.
>
> On Thu, May 17, 2012 at 12:34 AM, Vitaly Davidovich
>
>
> <vitalyd at gmail.com> wrote:
>
>
> I looked at the assembly on SO again (the pastebin link) and it
>
>
> seems to be
>
>
> correct actually: after 'a' is cmp'ed against zero, 'b' is read from
> memory.? But now someone is saying there that it sometimes generates
>
>
> the
>
>
> correct assembly and other times not - very strange.
> 0x025bd2b9: cmp $0x0,%edx
>
> 30. 0x025bd2bc: je 0x025bd2a8 ;
>
> 32. 0x025bd2be: mov $0x147062e8,%edx ; {oop('test/TestVolatile')}
>
> 33. 0x025bd2c3: mov 0x1c4(%edx),%edx ;*getstatic b
>
> 34. ; - test.TestVolatile::run at 10 (line 17)
>
> 35. 0x025bd2c9: cmp $0x0,%edx
>
> Sent from my phone
>
> On May 16, 2012 3:55 PM, "Aleksey Shipilev"
>
>
> <aleksey.shipilev at gmail.com>
>
>
> wrote:
>
>
> Update. GVN is clearly under suspicion -XX:-UseGlobalValueNumbering
> mitigates the bug in my setup. Digging through C1 codebase to see
> rules for volatiles.
>
> -Aleksey.
>
> On Wed, May 16, 2012 at 11:23 PM, Aleksey Shipilev
> <aleksey.shipilev at gmail.com> wrote:
>
>
> All right, here's what is on the table.
>
> This bug is reproduced for me on Linux i686 with:
> java version "1.7.0_04"
> Java(TM) SE Runtime Environment (build 1.7.0_04-b20)
> Java HotSpot(TM) Client VM (build 23.0-b21, mixed mode)
>
> It reproduces immediately only with -client.
> Both -server and -Xint do NOT reproduce the bug.
> The code is there in original SO post
>
> http://stackoverflow.com/questions/10620680/why-volatile-in-java-
>
>
> 5-doesnt-synchronize-cached-copies-of-variables-with-main
>
>
> C1 seems to miscompile run(), and indeed does CSE for local:
>
> ?# {method} 'run' '()V' in 'Test$1'
> [Verified Entry Point]
> ?0xb4a91e80: mov ? ?%eax,-0x4000(%esp)
> ?0xb4a91e87: push ? %ebp
> ?0xb4a91e88: sub ? ?$0x18,%esp ? ? ? ? ;*invokestatic access$000
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line
>
>
> 11)
>
>
> ?0xb4a91e8b: mov ? ?$0xa09c4270,%edx ? ; ? {oop(a
>
>
> 'java/lang/Class' =
>
>
> 'Test')}
>
>
> ?0xb4a91e90: mov ? ?0x74(%edx),%edx ? ?;*getstatic b <<<<<-
>
>
> ---
>
>
> loads $b to %edx
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$000 at 0
>
>
> (line 1)
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 0 (line
>
>
> 11)
>
>
> ?0xb4a91e93: jmp ? ?0xb4a91e9e ? ? ? ? ; OopMap{off=40}
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?;*goto
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line
>
>
> 13)
>
>
> ?0xb4a91e98: test ? %eax,0xb77a9100 ? ?;*goto
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 10 (line
>
>
> 13)
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {poll}
> ?0xb4a91e9e: mov ? ?$0xa09c4270,%ecx ? ; ? {oop(a
>
>
> 'java/lang/Class' =
>
>
> 'Test')}
>
>
> ?0xb4a91ea3: mov ? ?0x70(%ecx),%ecx ? ?;*getstatic a ?<<<<<
> volatile read for $a
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test::access$100 at 0
>
>
> (line 1)
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 4 (line
>
>
> 13)
>
>
> ?0xb4a91ea6: cmp ? ?$0x0,%ecx ? ? // <---- $a is at %ecx
> ?0xb4a91ea9: je ? ? 0xb4a91e98 ? ? ? ? ;*ifne
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 7 (line
>
>
> 13)
>
>
> ?>>>> 0xb4a91eab: cmp ? ?$0x0,%edx ? ? // <<<<<<---- $b is cached
>
>
> in
>
>
> %edx here
> ?0xb4a91eae: jne ? ?0xb4a91ed8 ? ? ? ? ;*ifne
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 16 (line
>
>
> 17)
>
>
> ?0xb4a91eb4: nopl ? 0x0(%eax)
> ?0xb4a91eb8: jmp ? ?0xb4a91f0e ? ? ? ? ; ? {no_reloc}
> ?0xb4a91ebd: xchg ? %ax,%ax
> ?0xb4a91ec0: jmp ? ?0xb4a91f28 ? ? ? ? ; implicit exception:
> dispatches to 0xb4a91f18
> ?0xb4a91ec5: nop ? ? ? ? ? ? ? ? ? ? ? ;*getstatic out
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 19 (line
>
>
> 18)
>
>
> ?0xb4a91ec6: cmp ? ?(%ecx),%eax ? ? ? ?; implicit exception:
> dispatches to 0xb4a91f32
> ?0xb4a91ec8: mov ? ?$0xa09c6488,%edx ? ;*invokevirtual println
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; - Test$1::run at 24 (line
>
>
> 18)
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?; ? {oop("error")}
>
>
> Thanks,
> Aleksey.
>
> On Wed, May 16, 2012 at 11:12 PM, Vitaly Davidovich
>
>
> <vitalyd at gmail.com>
>
>
> wrote:
>
>
> It can be a compiler (mis)optimization that causes this, and not
>
>
> x86
>
>
> memory
> ordering.
>
> Someone posted the assembly output in the comments on SO and it
>
>
> does
>
>
> seem
> like there's a place that loads 'b' from the stack rather than
>
>
> memory.
>
>
> Hans' theory of CSE sounds plausible - can someone repro this
>
>
> without
>
>
> that
> "int tt = b;" line?
>
> Adding hotspot compiler guys in case they want to chime in.
>
> Sent from my phone
>
> On May 16, 2012 3:07 PM, "Aleksey Shipilev"
> <aleksey.shipilev at gmail.com>
> wrote:
>
>
> On Wed, May 16, 2012 at 10:40 PM, Boehm, Hans
>
>
> <hans.boehm at hp.com>
>
>
> wrote:
>
>
> A JDK bug AND a serious test suite omission?
>
>
> Stress tests would probably JIT-compile the code in question.
>
>
> See
>
>
> below.
>
>
>
> But is the problem real? ?Can it be reproduced on a
>
>
> mainstream JVM?
>
>
> Same question.
>
>
>
> Note that the example in the original posting also read b
>
>
> before the
>
>
> loop,
> so na?ve common subexpression elimination would cause the
>
>
> bug.
>
>
> ?Hopefully
> nobody does CSE in cases like this.
>
>
> FWIW, the test case in SO would probably not hit any
>
>
> compilation
>
>
> threshold in HotSpot, so it could be executed in interpreter.
>
>
> Then,
>
>
> assuming the interpreter does not reorder Java code, and
>
>
> assuming
>
>
> original SO poster runs Windows, and hence x86, and hence has
>
>
> TSO,
>
>
> this bug seems very unlikely. I would be surprised if it
>
>
> actually
>
>
> *can* be reproduced. That makes the whole story rather
>
>
> interesting.
>
>
> -Aleksey.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From mr.chrisvest at gmail.com  Sat May 19 08:45:48 2012
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Sat, 19 May 2012 14:45:48 +0200
Subject: [concurrency-interest] Promise implementation?
Message-ID: <CAHXi_0eg8NyX47WTWZYE0cpmirK444BoZkcQiZ6544GSVpjo6Q@mail.gmail.com>

Hi,

What are the odds of getting a Promise implementation in j.u.c.? I
occasionally find myself needing something like that.

I'm thinking it could perhaps look a bit like this (to show a concrete
example of an API):
https://github.com/chrisvest/concurrency-extras/blob/master/src/main/java/javax/util/concurrent/Promise.java

Cheers,
Chris
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120519/9cb19309/attachment.html>

From dl at cs.oswego.edu  Sat May 19 08:56:36 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 19 May 2012 08:56:36 -0400
Subject: [concurrency-interest] Promise implementation?
In-Reply-To: <CAHXi_0eg8NyX47WTWZYE0cpmirK444BoZkcQiZ6544GSVpjo6Q@mail.gmail.com>
References: <CAHXi_0eg8NyX47WTWZYE0cpmirK444BoZkcQiZ6544GSVpjo6Q@mail.gmail.com>
Message-ID: <4FB79884.9090803@cs.oswego.edu>

On 05/19/12 08:45, Chris Vest wrote:
> Hi,
>
> What are the odds of getting a Promise implementation in j.u.c.? I occasionally
> find myself needing something like that.

Yes. This is identical to (and would probably be named) FutureValue,
that was last discussed on this list last month (and, as Joe pointed
out, periodically over the years) and is on the list for
possible introduction. Stay tuned.

Reminder for others: FutureValue differs from FutureTasm and
ForkJoinTask mainly in that it is not itself Runnable or
submittable to an executor. Additionally, it should support
simple but general forms of extensible completions/callbacks.

-Doug


>
> I'm thinking it could perhaps look a bit like this (to show a concrete example
> of an API):
> https://github.com/chrisvest/concurrency-extras/blob/master/src/main/java/javax/util/concurrent/Promise.java
>
> Cheers,
> Chris
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Sat May 19 09:09:26 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 19 May 2012 09:09:26 -0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
Message-ID: <4FB79B86.8070200@cs.oswego.edu>

On 05/16/12 18:01, Boehm, Hans wrote:
> Would it make sense to expand a test suite with a bunch of memory model tests, e.g.:
>
> no CSE across volatile load
> corresponding test for a volatile store:
> 	r1 = x; v = ...; r2 = x;  use r1   doesn't replace the use of r1 with r2
> Dekker's example
> No fusion of potentially infinite loops
> Maybe IRIW/write atomicity

Back during JDK5 development (for JSR 133 and 166), we did create
some such tests (some of which are available in our test/loops CVS)
but they were never collected or systematized into a  hotspot
JMM test suite. I'm not sure whether there was a test (or an
implicit one in any of our jsr166 tests) that hit this particular
case, but my guess is that this C1 (-client) bug arose after
our initial JDK5 testing. (Nearly all "routine" j.u.c tests use
C2 (-server).)  Hopefully this bug will spur more complete regression
testing.

-Doug


From viktor.klang at gmail.com  Sat May 19 09:16:28 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 19 May 2012 15:16:28 +0200
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <4FB79B86.8070200@cs.oswego.edu>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
	<4FB79B86.8070200@cs.oswego.edu>
Message-ID: <CANPzfU8-ATEgVsZCau-4n_oK8134meHMrZU0oPRCCNrokJHh_Q@mail.gmail.com>

Wait, what, there's no JMM tests? I mean even if these things are
statistical tests at best, they'd at least provide some guard rails.

Cheers,
?

On Sat, May 19, 2012 at 3:09 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/16/12 18:01, Boehm, Hans wrote:
>
>> Would it make sense to expand a test suite with a bunch of memory model
>> tests, e.g.:
>>
>> no CSE across volatile load
>> corresponding test for a volatile store:
>>        r1 = x; v = ...; r2 = x;  use r1   doesn't replace the use of r1
>> with r2
>> Dekker's example
>> No fusion of potentially infinite loops
>> Maybe IRIW/write atomicity
>>
>
> Back during JDK5 development (for JSR 133 and 166), we did create
> some such tests (some of which are available in our test/loops CVS)
> but they were never collected or systematized into a  hotspot
> JMM test suite. I'm not sure whether there was a test (or an
> implicit one in any of our jsr166 tests) that hit this particular
> case, but my guess is that this C1 (-client) bug arose after
> our initial JDK5 testing. (Nearly all "routine" j.u.c tests use
> C2 (-server).)  Hopefully this bug will spur more complete regression
> testing.
>
> -Doug
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120519/00df30bb/attachment.html>

From dl at cs.oswego.edu  Sat May 19 09:25:04 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 19 May 2012 09:25:04 -0400
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <CANPzfU8-ATEgVsZCau-4n_oK8134meHMrZU0oPRCCNrokJHh_Q@mail.gmail.com>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>	<A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>	<4FB79B86.8070200@cs.oswego.edu>
	<CANPzfU8-ATEgVsZCau-4n_oK8134meHMrZU0oPRCCNrokJHh_Q@mail.gmail.com>
Message-ID: <4FB79F30.2050309@cs.oswego.edu>

On 05/19/12 09:16, ?iktor ?lang wrote:
> Wait, what, there's no JMM tests?

There is not, to my knowledge, a "hotspot JMM Test suite"
(which is out of my scope).  But there are (three forms of)
j.u.c test suites, that together test most JMM requirements.
But there ought to be a separate one to mop up coverage holes.

-Doug




From viktor.klang at gmail.com  Sat May 19 09:29:29 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 19 May 2012 15:29:29 +0200
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <4FB79F30.2050309@cs.oswego.edu>
References: <CACuKZqGnxkb6MuWj40z9cd4f0AkHu18ubd0Jg2xHJK2o1=pRzA@mail.gmail.com>
	<DBFD3CCD-73F2-4562-9BC3-FEA68C06A1E8@gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355534EB@G4W3299.americas.hpqcorp.net>
	<CA+1LWGFahEXV-7gV+WA48eNZXtyQwVYHgVguOebdE=4CZgMd0g@mail.gmail.com>
	<CAHjP37EH=h=Qjc5-hvwR27LAhYOSXOh-D1cWj-gFLjBZX4W1OA@mail.gmail.com>
	<CA+1LWGFS5s0AZyn=P0F3GsriDt0oFm=7obNh8NwxAZAzT6pioQ@mail.gmail.com>
	<CA+1LWGGwTsfS2VRajqqM-u22S3jFvqZViXpwztDyLwJAiDnhDQ@mail.gmail.com>
	<CAHjP37F0SYoeYs9=C3pqBDPSBq4UaCY0fjjKRgeyme+DSVB+Pg@mail.gmail.com>
	<CA+1LWGEEGMPWpQW1TXNz=gu3MZmbmYtsF=GSrCmbdLa6=+TjaA@mail.gmail.com>
	<CA+1LWGFkwU-uijVg1eEYeBeWHs0WijVxut5pWRDdoi4REiy4=Q@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235553680@G4W3299.americas.hpqcorp.net>
	<4FB79B86.8070200@cs.oswego.edu>
	<CANPzfU8-ATEgVsZCau-4n_oK8134meHMrZU0oPRCCNrokJHh_Q@mail.gmail.com>
	<4FB79F30.2050309@cs.oswego.edu>
Message-ID: <CANPzfU_rOe3B7ksQP3Ky7oe+3xxc4mxbqDarU5F4GM0LBSMUyg@mail.gmail.com>

On Sat, May 19, 2012 at 3:25 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/19/12 09:16, ?iktor ?lang wrote:
>
>> Wait, what, there's no JMM tests?
>>
>
> There is not, to my knowledge, a "hotspot JMM Test suite"
> (which is out of my scope).


Absolutely, I totally agree, I was just so surprised I almost spilled my
espresso.


>  But there are (three forms of)
> j.u.c test suites, that together test most JMM requirements.
> But there ought to be a separate one to mop up coverage holes.


That's likely the reason it works at all then?

Having run into JVM concurrency bugs it's a bit annoying not to know if
it's my own code, my own test or the JVM which is broken.
Having a cohesive TCK for the JMM would atleast make me blame myself
automatically ;-)

Cheers,
?


>
>
> -Doug
>
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120519/e4a24991/attachment.html>

From davidcholmes at aapt.net.au  Sat May 19 19:12:10 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 20 May 2012 09:12:10 +1000
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <4FB79F30.2050309@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEKHJEAA.davidcholmes@aapt.net.au>

It is also very difficult to run tests in a way that tests all possible generated code from the JITs. The OSR form can be different from the "normal" form which can be different from a forced compilation via -Xcomp.

But we definitely need better coverage here.

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> Sent: Saturday, 19 May 2012 11:25 PM
> To: viktor ?lang
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] a volatile bug?
> 
> 
> On 05/19/12 09:16, ?iktor ?lang wrote:
> > Wait, what, there's no JMM tests?
> 
> There is not, to my knowledge, a "hotspot JMM Test suite"
> (which is out of my scope).  But there are (three forms of)
> j.u.c test suites, that together test most JMM requirements.
> But there ought to be a separate one to mop up coverage holes.
> 
> -Doug
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 



From hans.boehm at hp.com  Sun May 20 13:21:52 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Sun, 20 May 2012 17:21:52 +0000
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEKHJEAA.davidcholmes@aapt.net.au>
References: <4FB79F30.2050309@cs.oswego.edu>
	<NFBBKALFDCPFIDBNKAPCGEKHJEAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235554779@G4W3299.americas.hpqcorp.net>

Good point.  But especially in this area, I still think a widely available test suite would help a lot.  You might miss the problem in your test environment, but if you get everyone who has a threads-related problem and suspects their compiler to run the suite in their environment, I'd guess you would get reasonable coverage.

Hans


> From: David Holmes
> 
> It is also very difficult to run tests in a way that tests all possible generated
> code from the JITs. The OSR form can be different from the "normal" form
> which can be different from a forced compilation via -Xcomp.
> 
> But we definitely need better coverage here.
> 
> David
> 
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug
> > Lea
> > Sent: Saturday, 19 May 2012 11:25 PM
> > To: viktor ?lang
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] a volatile bug?
> >
> >
> > On 05/19/12 09:16, ?iktor ?lang wrote:
> > > Wait, what, there's no JMM tests?
> >
> > There is not, to my knowledge, a "hotspot JMM Test suite"
> > (which is out of my scope).  But there are (three forms of) j.u.c test
> > suites, that together test most JMM requirements.
> > But there ought to be a separate one to mop up coverage holes.
> >
> > -Doug
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From kirk at kodewerk.com  Sun May 20 13:34:55 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Sun, 20 May 2012 19:34:55 +0200
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235554779@G4W3299.americas.hpqcorp.net>
References: <4FB79F30.2050309@cs.oswego.edu>
	<NFBBKALFDCPFIDBNKAPCGEKHJEAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235554779@G4W3299.americas.hpqcorp.net>
Message-ID: <9CC7407D-15AC-4C66-9512-F6214BE4FC93@kodewerk.com>

I've been rooting around at the hardware level and the best testing idea I've been able to come up with is to treat this stuff as a "trait". Test coverage for this stuff is utterly impossible. I think the best one can do is as you suggested, write the tests, make them statistical in nature and then make it easily available so that the community can run the test them selves. I see this tactic as necessary evil in the future of testing.

Regards,
Kirk

On 2012-05-20, at 7:21 PM, Boehm, Hans wrote:

> Good point.  But especially in this area, I still think a widely available test suite would help a lot.  You might miss the problem in your test environment, but if you get everyone who has a threads-related problem and suspects their compiler to run the suite in their environment, I'd guess you would get reasonable coverage.
> 
> Hans
> 
> 
>> From: David Holmes
>> 
>> It is also very difficult to run tests in a way that tests all possible generated
>> code from the JITs. The OSR form can be different from the "normal" form
>> which can be different from a forced compilation via -Xcomp.
>> 
>> But we definitely need better coverage here.
>> 
>> David
>> 
>>> -----Original Message-----
>>> From: concurrency-interest-bounces at cs.oswego.edu
>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug
>>> Lea
>>> Sent: Saturday, 19 May 2012 11:25 PM
>>> To: viktor ?lang
>>> Cc: concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] a volatile bug?
>>> 
>>> 
>>> On 05/19/12 09:16, ?iktor ?lang wrote:
>>>> Wait, what, there's no JMM tests?
>>> 
>>> There is not, to my knowledge, a "hotspot JMM Test suite"
>>> (which is out of my scope).  But there are (three forms of) j.u.c test
>>> suites, that together test most JMM requirements.
>>> But there ought to be a separate one to mop up coverage holes.
>>> 
>>> -Doug
>>> 
>>> 
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From davidcholmes at aapt.net.au  Sun May 20 18:48:31 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 21 May 2012 08:48:31 +1000
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <9CC7407D-15AC-4C66-9512-F6214BE4FC93@kodewerk.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEKJJEAA.davidcholmes@aapt.net.au>

My point was that it is very difficult to write tests that trigger different compilation strategies. As it stands unless people play with the compiler strategies via -XX options then these tests will always behave the same way in that regard, so the coverage is not what you might think.

David

> -----Original Message-----
> From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
> Sent: Monday, 21 May 2012 3:35 AM
> To: Boehm, Hans
> Cc: dholmes at ieee.org; Doug Lea; viktor ?lang;
> concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] a volatile bug?
> 
> 
> I've been rooting around at the hardware level and the best 
> testing idea I've been able to come up with is to treat this 
> stuff as a "trait". Test coverage for this stuff is utterly 
> impossible. I think the best one can do is as you suggested, 
> write the tests, make them statistical in nature and then make it 
> easily available so that the community can run the test them 
> selves. I see this tactic as necessary evil in the future of testing.
> 
> Regards,
> Kirk
> 
> On 2012-05-20, at 7:21 PM, Boehm, Hans wrote:
> 
> > Good point.  But especially in this area, I still think a 
> widely available test suite would help a lot.  You might miss the 
> problem in your test environment, but if you get everyone who has 
> a threads-related problem and suspects their compiler to run the 
> suite in their environment, I'd guess you would get reasonable coverage.
> > 
> > Hans
> > 
> > 
> >> From: David Holmes
> >> 
> >> It is also very difficult to run tests in a way that tests all 
> possible generated
> >> code from the JITs. The OSR form can be different from the 
> "normal" form
> >> which can be different from a forced compilation via -Xcomp.
> >> 
> >> But we definitely need better coverage here.
> >> 
> >> David
> >> 
> >>> -----Original Message-----
> >>> From: concurrency-interest-bounces at cs.oswego.edu
> >>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug
> >>> Lea
> >>> Sent: Saturday, 19 May 2012 11:25 PM
> >>> To: viktor ?lang
> >>> Cc: concurrency-interest at cs.oswego.edu
> >>> Subject: Re: [concurrency-interest] a volatile bug?
> >>> 
> >>> 
> >>> On 05/19/12 09:16, ?iktor ?lang wrote:
> >>>> Wait, what, there's no JMM tests?
> >>> 
> >>> There is not, to my knowledge, a "hotspot JMM Test suite"
> >>> (which is out of my scope).  But there are (three forms of) j.u.c test
> >>> suites, that together test most JMM requirements.
> >>> But there ought to be a separate one to mop up coverage holes.
> >>> 
> >>> -Doug
> >>> 
> >>> 
> >>> 
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>> 
> >> 
> >> 
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 



From coderplay at gmail.com  Mon May 21 03:43:42 2012
From: coderplay at gmail.com (Min Zhou)
Date: Mon, 21 May 2012 15:43:42 +0800
Subject: [concurrency-interest] What's mean TLR?
Message-ID: <CALO_SpT6cFpUQyr-sRty3-c8TP0UrUMDrmU0ao-=aThnvFOvzA@mail.gmail.com>

Hi, all

Here is some lines of comments in ThreadLocalRandom.java

    // Padding to help avoid memory contention among seed updates in
    // different TLRs in the common case that they are located near
    // each other.

What's the above TLR short for ?

Thanks,
Min
-- 
My research interests are distributed systems, parallel computing and
bytecode based virtual machine.

My profile:
http://www.linkedin.com/in/coderplay
My blog:
http://coderplay.javaeye.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120521/4e5a1cd5/attachment.html>

From forax at univ-mlv.fr  Mon May 21 03:56:44 2012
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 21 May 2012 09:56:44 +0200
Subject: [concurrency-interest] What's mean TLR?
In-Reply-To: <CALO_SpT6cFpUQyr-sRty3-c8TP0UrUMDrmU0ao-=aThnvFOvzA@mail.gmail.com>
References: <CALO_SpT6cFpUQyr-sRty3-c8TP0UrUMDrmU0ao-=aThnvFOvzA@mail.gmail.com>
Message-ID: <4FB9F53C.7000103@univ-mlv.fr>

On 05/21/2012 09:43 AM, Min Zhou wrote:
> Hi, all
>
> Here is some lines of comments in ThreadLocalRandom.java
>
>     // Padding to help avoid memory contention among seed updates in
>     // different TLRs in the common case that they are located near
>     // each other.
>
> What's the above TLR short for ?

ThreadLocalRandom :)

>
> Thanks,
> Min

cheers,
R?mi


From kirk at kodewerk.com  Mon May 21 04:19:16 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Mon, 21 May 2012 10:19:16 +0200
Subject: [concurrency-interest] a volatile bug?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEKJJEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEKJJEAA.davidcholmes@aapt.net.au>
Message-ID: <0AEFAA1F-A569-42A4-A0CE-F8B292ABB491@kodewerk.com>

Didn't mean to imply this was going to be easy nor error prone. I fully appreciate the difficulties. But we are dealing with a class of bugs that are statistical in nature.. those stats change based on a uncontrollable number of environmental conditions which implies the problem is intractable. That said, we still must test and if the problem has moved from one of a binary (worked, didn't work) to a statistical one, it seems that the testing must move in that direction also... agreed it cannot be perfect but that's no reason for not starting.

For example, I had a biased locking bench that failed occasionally. By making numerous runs I was able to detect cases where the biased locking optimization wasn't applied. All I could sort out is there was some sort of race condition that was affected by were the JVM was loaded into memory.. pure speculation but that was one variable that differed between runs. If I could speculate more, my guess is that there was an underlying time sensitive optimization that some times won and when it did it precluded biased locking from begin applied. Most of this analysis came from a statistical treatment of the benchmarking results.

Another example though not a concurrency one. I have a bench that will readjust Java heap based on -XX:NewRatio setting. If the JVM is loaded in low RAM the JVM will adjust the heap in response to a set load. The JVM will *not* resize when the JVM is loaded in higher RAM. Again, you can't see this with a single test.. in fact, you can't see it with a number of tests unless you load the JVM in different memory segments.

Regards,
Kirk

On 2012-05-21, at 12:48 AM, David Holmes wrote:

> My point was that it is very difficult to write tests that trigger different compilation strategies. As it stands unless people play with the compiler strategies via -XX options then these tests will always behave the same way in that regard, so the coverage is not what you might think.
> 
> David
> 
>> -----Original Message-----
>> From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
>> Sent: Monday, 21 May 2012 3:35 AM
>> To: Boehm, Hans
>> Cc: dholmes at ieee.org; Doug Lea; viktor ?lang;
>> concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] a volatile bug?
>> 
>> 
>> I've been rooting around at the hardware level and the best 
>> testing idea I've been able to come up with is to treat this 
>> stuff as a "trait". Test coverage for this stuff is utterly 
>> impossible. I think the best one can do is as you suggested, 
>> write the tests, make them statistical in nature and then make it 
>> easily available so that the community can run the test them 
>> selves. I see this tactic as necessary evil in the future of testing.
>> 
>> Regards,
>> Kirk
>> 
>> On 2012-05-20, at 7:21 PM, Boehm, Hans wrote:
>> 
>>> Good point.  But especially in this area, I still think a 
>> widely available test suite would help a lot.  You might miss the 
>> problem in your test environment, but if you get everyone who has 
>> a threads-related problem and suspects their compiler to run the 
>> suite in their environment, I'd guess you would get reasonable coverage.
>>> 
>>> Hans
>>> 
>>> 
>>>> From: David Holmes
>>>> 
>>>> It is also very difficult to run tests in a way that tests all 
>> possible generated
>>>> code from the JITs. The OSR form can be different from the 
>> "normal" form
>>>> which can be different from a forced compilation via -Xcomp.
>>>> 
>>>> But we definitely need better coverage here.
>>>> 
>>>> David
>>>> 
>>>>> -----Original Message-----
>>>>> From: concurrency-interest-bounces at cs.oswego.edu
>>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug
>>>>> Lea
>>>>> Sent: Saturday, 19 May 2012 11:25 PM
>>>>> To: viktor ?lang
>>>>> Cc: concurrency-interest at cs.oswego.edu
>>>>> Subject: Re: [concurrency-interest] a volatile bug?
>>>>> 
>>>>> 
>>>>> On 05/19/12 09:16, ?iktor ?lang wrote:
>>>>>> Wait, what, there's no JMM tests?
>>>>> 
>>>>> There is not, to my knowledge, a "hotspot JMM Test suite"
>>>>> (which is out of my scope).  But there are (three forms of) j.u.c test
>>>>> suites, that together test most JMM requirements.
>>>>> But there ought to be a separate one to mop up coverage holes.
>>>>> 
>>>>> -Doug
>>>>> 
>>>>> 
>>>>> 
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
> 



From aleksey.shipilev at gmail.com  Mon May 21 13:19:09 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Mon, 21 May 2012 20:19:09 +0300
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
In-Reply-To: <CANPzfU89mCbixXX6UUMWexWn12bhFCXoSsn-rswtr+DgO7cTVA@mail.gmail.com>
References: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
	<CA+1LWGHTsWjX3wTTseE9iSy--CP=uPorXfP58UbPP5Gc=Q73fA@mail.gmail.com>
	<CANPzfU89mCbixXX6UUMWexWn12bhFCXoSsn-rswtr+DgO7cTVA@mail.gmail.com>
Message-ID: <CA+1LWGGtSTK__GRZcyah-gUHL9ZMidTGotRyR7ZP-PfUgsZ71A@mail.gmail.com>

On Sat, May 12, 2012 at 8:05 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
> As a sidenote, it'd be nice to have an AsyncExecutor, which is never allowed
> to do caller-runs at all. Some code might rely on the block not being
> executed on submission.

I had always had a feeling this is the difference between
Executor.execute() and ExecutorService.submit(). submit() should not
allow to do caller-runs unless explicitly told so by rejection policy.
I would anticipate lots of people are betting on that.

-Aleksey.


From viktor.klang at gmail.com  Mon May 21 13:43:12 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 21 May 2012 19:43:12 +0200
Subject: [concurrency-interest] CallerRunsOrRejects for JDK8?
In-Reply-To: <CA+1LWGGtSTK__GRZcyah-gUHL9ZMidTGotRyR7ZP-PfUgsZ71A@mail.gmail.com>
References: <CANPzfU-h-t5gUOB=XTAKHxrFThxymWCx=Tk59_QLNQ+vvJJ_DQ@mail.gmail.com>
	<CA+1LWGHTsWjX3wTTseE9iSy--CP=uPorXfP58UbPP5Gc=Q73fA@mail.gmail.com>
	<CANPzfU89mCbixXX6UUMWexWn12bhFCXoSsn-rswtr+DgO7cTVA@mail.gmail.com>
	<CA+1LWGGtSTK__GRZcyah-gUHL9ZMidTGotRyR7ZP-PfUgsZ71A@mail.gmail.com>
Message-ID: <CANPzfU9ry5FvjeJheF1PjfwfLPML_oxG+Z-LyWqZhpKSuejTNA@mail.gmail.com>

On Mon, May 21, 2012 at 7:19 PM, Aleksey Shipilev <
aleksey.shipilev at gmail.com> wrote:

> On Sat, May 12, 2012 at 8:05 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> > As a sidenote, it'd be nice to have an AsyncExecutor, which is never
> allowed
> > to do caller-runs at all. Some code might rely on the block not being
> > executed on submission.
>
> I had always had a feeling this is the difference between
> Executor.execute() and ExecutorService.submit(). submit() should not
> allow to do caller-runs unless explicitly told so by rejection policy.
> I would anticipate lots of people are betting on that.
>

Problem is all the baggage of ExecutorService. :/

Cheers,
?


>
> -Aleksey.
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120521/f6d34a81/attachment.html>

From rco at quartetfs.com  Tue May 22 12:20:47 2012
From: rco at quartetfs.com (Romain Colle)
Date: Tue, 22 May 2012 18:20:47 +0200
Subject: [concurrency-interest] ForkJoinPool does not achieve expected
	parallelism
Message-ID: <CAJp3eRA8wHnVxVLpzOFMVycieYTYjiOG3hd5CMfWz9PdznFbdQ@mail.gmail.com>

Hi Doug and all,

Using the latest version of the ForkJoinPool available on the jsr166y
website, we ran into an issue/regression with our existing code base.

In our code, we have a single task that scans a fairly large fact table
while applying some filtering conditions. Any row that passes this
condition must then be processed.
The pattern that we use is that the scanning task saves (in an array) the
rows that passed the condition and forks a processing task as soon as we
have enough rows to process (say 1024).
We expect that these processing tasks will be picked up (i.e. stolen) by
the other threads in the pool and executed while we continue scanning and
filtering.
Unrelated to the current issue, we have a completion phase at the end of
the scanning that ensures all the forked tasks have been executed.

To sum it up, we have a single task that scans some data and forks lots of
processing task.
Previously (with the version from a few months back without the worker
queues), this was working perfectly and all the worker threads were kept
busy and executed the processing tasks.
Now, we see that only a few threads are being kept busy with the processing
tasks (in addition to the scanning task). Dozens of threads are idle while
work is piling up.

If have put together a simple test that exhibits this issue:
http://pastebin.com/qz9uifJW

Looking at the ForkJoinPool code, it looks like the issue could be in
ForkJoinPool.WorkQueue.push().
More specifically, we have the following:
                if ((n = (top = s + 1) - base) <= 2) {
                    if ((p = pool) != null)
                        p.signalWork();
                }

If tasks are being forked quickly enough, we will only signal work twice
while the local queue is getting fairly large, and no extra help is being
made available.
I naively modified this code to the following and got back to the initial
behavior (full threads usage):
                if ((n = (top = s + 1) - base) <= pool.parallelism) {
                    if ((p = pool) != null)
                        p.signalWork();
                }

I'm not quite sure why the initial "2" was put there. Was it to avoid
flooding the threads with signals if everybody is already at work? In that
case we could do the signaling only if the AC count is < 0.
I'm sure there is a more elegant solution available, so any advice on
whether this is indeed a core issue or if there is an issue with our pool
usage would be appreciated!

Thanks,

-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120522/706c54a7/attachment.html>

From dl at cs.oswego.edu  Tue May 22 19:17:50 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 22 May 2012 19:17:50 -0400
Subject: [concurrency-interest] ForkJoinPool does not achieve expected
 parallelism
In-Reply-To: <CAJp3eRA8wHnVxVLpzOFMVycieYTYjiOG3hd5CMfWz9PdznFbdQ@mail.gmail.com>
References: <CAJp3eRA8wHnVxVLpzOFMVycieYTYjiOG3hd5CMfWz9PdznFbdQ@mail.gmail.com>
Message-ID: <4FBC1E9E.9070504@cs.oswego.edu>

On 05/22/12 12:20, Romain Colle wrote:
>

Thanks for the nicely conceived test case!
The problem was lack of a secondary signalling check
(present in previous versions) that isn't now needed
for submissions queues, but sometimes is otherwise.
This is now in updated CVS and jar files.

> I'm not quite sure why the initial "2" was put there.

It allows some parallelization of signalling, by
letting other threads help with wakeups when
they find work.

-Doug

From rco at quartetfs.com  Wed May 23 05:25:38 2012
From: rco at quartetfs.com (Romain Colle)
Date: Wed, 23 May 2012 11:25:38 +0200
Subject: [concurrency-interest] ForkJoinPool does not achieve expected
	parallelism
In-Reply-To: <4FBC1E9E.9070504@cs.oswego.edu>
References: <CAJp3eRA8wHnVxVLpzOFMVycieYTYjiOG3hd5CMfWz9PdznFbdQ@mail.gmail.com>
	<4FBC1E9E.9070504@cs.oswego.edu>
Message-ID: <CAJp3eRDVzr=Dn5dGmY=Sddi2M0mh_sanNVpr-SSadeHwiFVOsQ@mail.gmail.com>

Thanks for the explanation and the quick fix!
Romain

On Wed, May 23, 2012 at 1:17 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/22/12 12:20, Romain Colle wrote:
>
>>
>>
> Thanks for the nicely conceived test case!
> The problem was lack of a secondary signalling check
> (present in previous versions) that isn't now needed
> for submissions queues, but sometimes is otherwise.
> This is now in updated CVS and jar files.
>
>
>  I'm not quite sure why the initial "2" was put there.
>>
>
> It allows some parallelization of signalling, by
> letting other threads help with wakeups when
> they find work.
>
> -Doug
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120523/5fa1c45d/attachment.html>

From plokhotnyuk at gmail.com  Thu May 24 08:21:03 2012
From: plokhotnyuk at gmail.com (Andriy Plokhotnyuk)
Date: Thu, 24 May 2012 05:21:03 -0700 (PDT)
Subject: [concurrency-interest] Quest for the optimal queue
Message-ID: <33896981.post@talk.nabble.com>


Hi All,

Thank you, Michael, for sharing idea how to minimize access to volatile
variables.

Here is my attempt to use one of Dmitriy Vyukov's version of multi producer
/ single consumer node based queue in implementation of Scalaz actor instead
of ConcurrentLinkedQueue:
https://github.com/plokhotnyuk/actors/blob/master/src/main/scala/com/github/plokhotnyuk/actors/Actor2.scala

Your hints allowed to improve throughput in ~3x times and decrease latency
on ~20% comparing to Scalaz actor that uses CLQ, here are simple benchmarks
and their results:
https://github.com/plokhotnyuk/actors/blob/master/src/test/scala/com/github/plokhotnyuk/actors/ScalazActor2Test.scala
https://github.com/plokhotnyuk/actors/blob/master/out1.txt#L252

Also I found that the same approach cannot be easy applied for custom
implementations of Akka mailboxes:
https://github.com/plokhotnyuk/actors/blob/master/src/main/scala/com/github/plokhotnyuk/actors/UnboundedMailbox2.scala
https://github.com/plokhotnyuk/actors/blob/master/out1.txt#L48

EDIT: This and other ideas like reusing envelope as node for queue list, or
hacking of fork/join pool to automatically discard actor resheduling
requests while task still running (it will allow avoid of tracking of
running state when adding message to the queue) - can improve not only
throughput but greatly decrease latency too.

Best regards,
Andriy


Michael Barker-4 wrote:
> 
>> The problem with batch dequeues is that if one of the messages fail we
>> need
>> to be at a stable state, and doing that would mean store away the
>> remaining
>> batch, which would bump the processors size by atleast a reference, which
>> can be expensive if you have millions of them.
> 
> If you are will to stay away from the standard Java collections API,
> then I was thinking of a call with a more functional style.  E.g.
> (pseudo code)
> 
>     public void foreach(Callback callback) {
>         Node current = head;
> 
>         if (current.next == null) {
>             return;
>         }
> 
>         try {
>             do {
>                 Object value = current.value;
>                 callback.onEvent(value);
>                 current = current.next;
>             } while (current.next != null);
>         } finally {
>             updateHead(current);  // Do the appropriate thread-safe
>                                             // update to head
>         }
>     }
> 
>     private static interface Callback
>     {
>         void onMessage(Object o);
>     }
> 
> In the above case, if an exception thrown when handling the message,
> then the message that caused the exception is redelivered.  The
> collection is then responsible for maintaining a stable state in the
> case of an exception and the definition of that behaviour is part of
> the contract for the collection.
> 
> I think there is also an interesting optimisation here.  The reason
> I've added the short circuit check at the top of the method is that I
> think it removes the only possible case where you could have write
> contention with producers and consumers.  The only time a consumer and
> a producer would contend on a write would be if the queue was empty.
> I.e. head == tail.  If we remove that case from the consumer then
> producers and consumers should never have a write conflict.  The
> updateHead() method used by the consumer may not need a CAS, it is
> possible that you could get away with a lazySet, which would certainly
> improve performance.  Someone should check my reasoning though.
> 
>> It's an interesting problem though. I've been thinking about how to
>> handle
>> producer conflicts as cheap as possible, as there are no consumer
>> conflicts.
> 
> That's a tough one.  The most complicated code in the Disruptor is
> dealing with this case and we've ended up with 2 strategies based on
> the ratio of producer threads to available cores. With an array-backed
> queue this is easier, but I think for your use case you need something
> list-backed.
> 
> Mike.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
-- 
View this message in context: http://old.nabble.com/Quest-for-the-optimal-queue-tp33833783p33896981.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From viktor.klang at gmail.com  Thu May 24 08:53:20 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 24 May 2012 14:53:20 +0200
Subject: [concurrency-interest] Quest for the optimal queue
In-Reply-To: <33896981.post@talk.nabble.com>
References: <33896981.post@talk.nabble.com>
Message-ID: <CANPzfU83EA=8G=rn7EzA25ixrFCR-04pKXZ9GT=nV4jmGxRHWA@mail.gmail.com>

Hi Andriy,

On Thu, May 24, 2012 at 2:21 PM, Andriy Plokhotnyuk
<plokhotnyuk at gmail.com>wrote:

>
> Hi All,
>
> Thank you, Michael, for sharing idea how to minimize access to volatile
> variables.
>
> Here is my attempt to use one of Dmitriy Vyukov's version of multi producer
> / single consumer node based queue in implementation of Scalaz actor
> instead
> of ConcurrentLinkedQueue:
>
> https://github.com/plokhotnyuk/actors/blob/master/src/main/scala/com/github/plokhotnyuk/actors/Actor2.scala
>
> Your hints allowed to improve throughput in ~3x times and decrease latency
> on ~20% comparing to Scalaz actor that uses CLQ, here are simple benchmarks
> and their results:
>
> https://github.com/plokhotnyuk/actors/blob/master/src/test/scala/com/github/plokhotnyuk/actors/ScalazActor2Test.scala
> https://github.com/plokhotnyuk/actors/blob/master/out1.txt#L252
>
> Also I found that the same approach cannot be easy applied for custom
> implementations of Akka mailboxes:
>
> https://github.com/plokhotnyuk/actors/blob/master/src/main/scala/com/github/plokhotnyuk/actors/UnboundedMailbox2.scala
> https://github.com/plokhotnyuk/actors/blob/master/out1.txt#L48
>
> EDIT: This and other ideas like reusing envelope as node for queue list, or
> hacking of fork/join pool to automatically discard actor resheduling
> requests while task still running


The task will not be rescheduled while it is still running.

Cheers,
?


> (it will allow avoid of tracking of
> running state when adding message to the queue) - can improve not only
> throughput but greatly decrease latency too.
>
> Best regards,
> Andriy
>
>
> Michael Barker-4 wrote:
> >
> >> The problem with batch dequeues is that if one of the messages fail we
> >> need
> >> to be at a stable state, and doing that would mean store away the
> >> remaining
> >> batch, which would bump the processors size by atleast a reference,
> which
> >> can be expensive if you have millions of them.
> >
> > If you are will to stay away from the standard Java collections API,
> > then I was thinking of a call with a more functional style.  E.g.
> > (pseudo code)
> >
> >     public void foreach(Callback callback) {
> >         Node current = head;
> >
> >         if (current.next == null) {
> >             return;
> >         }
> >
> >         try {
> >             do {
> >                 Object value = current.value;
> >                 callback.onEvent(value);
> >                 current = current.next;
> >             } while (current.next != null);
> >         } finally {
> >             updateHead(current);  // Do the appropriate thread-safe
> >                                             // update to head
> >         }
> >     }
> >
> >     private static interface Callback
> >     {
> >         void onMessage(Object o);
> >     }
> >
> > In the above case, if an exception thrown when handling the message,
> > then the message that caused the exception is redelivered.  The
> > collection is then responsible for maintaining a stable state in the
> > case of an exception and the definition of that behaviour is part of
> > the contract for the collection.
> >
> > I think there is also an interesting optimisation here.  The reason
> > I've added the short circuit check at the top of the method is that I
> > think it removes the only possible case where you could have write
> > contention with producers and consumers.  The only time a consumer and
> > a producer would contend on a write would be if the queue was empty.
> > I.e. head == tail.  If we remove that case from the consumer then
> > producers and consumers should never have a write conflict.  The
> > updateHead() method used by the consumer may not need a CAS, it is
> > possible that you could get away with a lazySet, which would certainly
> > improve performance.  Someone should check my reasoning though.
> >
> >> It's an interesting problem though. I've been thinking about how to
> >> handle
> >> producer conflicts as cheap as possible, as there are no consumer
> >> conflicts.
> >
> > That's a tough one.  The most complicated code in the Disruptor is
> > dealing with this case and we've ended up with 2 strategies based on
> > the ratio of producer threads to available cores. With an array-backed
> > queue this is easier, but I think for your use case you need something
> > list-backed.
> >
> > Mike.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> --
> View this message in context:
> http://old.nabble.com/Quest-for-the-optimal-queue-tp33833783p33896981.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120524/347792ad/attachment.html>

From bheem at sbcglobal.net  Thu May 24 10:22:37 2012
From: bheem at sbcglobal.net (bhm)
Date: Thu, 24 May 2012 10:22:37 -0400
Subject: [concurrency-interest] synchronization based on a key
Message-ID: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>

I have a method that needs to be synchronized based on a key passed as
parameter, that is, for same key multiple threads shouldn't be
running. Following is what I did--


static final ConcurrentMap<String,Boolean> IN_PROGRESS =
   new ConcurrentHashMap<String,Boolean>();

void foo(String key){
    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
      // no other thread is processing this key
      try{
          // process this key
      } finally {
         // done with processing this key
         IN_PROGRESS.remove(key)
      }
    } else {
      // some other thread is running this key, discard it
    }
}

this works if I need to discard the request to process the key from
thread t1 when another thread, t2, is processing that key.

I need help to do following-
make thread t1 wait while t2 is processing the key and resume t1 when
t2 is finish processing same key.

I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
for t2 to finish anyone of these thread can wake up and start
processing the key irrespective of their order (if there is any) of
asking to process the key.

Thanks for help.

Bheem

From coyotesqrl at gmail.com  Thu May 24 11:46:53 2012
From: coyotesqrl at gmail.com (R.A. Porter)
Date: Thu, 24 May 2012 08:46:53 -0700
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
Message-ID: <CAFFMuLPBA2c4qqm7o+mbr5coEzpzdVTg+Hmu1O03Y_0acT7uxQ@mail.gmail.com>

How about a simpler approach:

void foo(String key) {
  synchronized(key.intern()) {
    // process this key
  }
}

-r


On Thu, May 24, 2012 at 7:22 AM, bhm <bheem at sbcglobal.net> wrote:

> I have a method that needs to be synchronized based on a key passed as
> parameter, that is, for same key multiple threads shouldn't be
> running. Following is what I did--
>
>
> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
>   new ConcurrentHashMap<String,Boolean>();
>
> void foo(String key){
>    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
>      // no other thread is processing this key
>      try{
>          // process this key
>      } finally {
>         // done with processing this key
>         IN_PROGRESS.remove(key)
>      }
>    } else {
>      // some other thread is running this key, discard it
>    }
> }
>
> this works if I need to discard the request to process the key from
> thread t1 when another thread, t2, is processing that key.
>
> I need help to do following-
> make thread t1 wait while t2 is processing the key and resume t1 when
> t2 is finish processing same key.
>
> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
> for t2 to finish anyone of these thread can wake up and start
> processing the key irrespective of their order (if there is any) of
> asking to process the key.
>
> Thanks for help.
>
> Bheem
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120524/518f9ccb/attachment-0001.html>

From viktor.klang at gmail.com  Thu May 24 11:56:22 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 24 May 2012 17:56:22 +0200
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CAFFMuLPBA2c4qqm7o+mbr5coEzpzdVTg+Hmu1O03Y_0acT7uxQ@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CAFFMuLPBA2c4qqm7o+mbr5coEzpzdVTg+Hmu1O03Y_0acT7uxQ@mail.gmail.com>
Message-ID: <CANPzfU8w+vU9zORbZqC-tm+7kTdqp0dFi6s8WhPfHZ+2abQb9w@mail.gmail.com>

On Thu, May 24, 2012 at 5:46 PM, R.A. Porter <coyotesqrl at gmail.com> wrote:

> How about a simpler approach:
>
> void foo(String key) {
>   synchronized(key.intern()) {
>     // process this key
>   }
> }
>

Wow, I'd never do that.
How about just having a map from String to Semaphore?

Cheers,
?


>
>
> -r
>
>
> On Thu, May 24, 2012 at 7:22 AM, bhm <bheem at sbcglobal.net> wrote:
>
>> I have a method that needs to be synchronized based on a key passed as
>> parameter, that is, for same key multiple threads shouldn't be
>> running. Following is what I did--
>>
>>
>> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
>>   new ConcurrentHashMap<String,Boolean>();
>>
>> void foo(String key){
>>    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
>>      // no other thread is processing this key
>>      try{
>>          // process this key
>>      } finally {
>>         // done with processing this key
>>         IN_PROGRESS.remove(key)
>>      }
>>    } else {
>>      // some other thread is running this key, discard it
>>    }
>> }
>>
>> this works if I need to discard the request to process the key from
>> thread t1 when another thread, t2, is processing that key.
>>
>> I need help to do following-
>> make thread t1 wait while t2 is processing the key and resume t1 when
>> t2 is finish processing same key.
>>
>> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
>> for t2 to finish anyone of these thread can wake up and start
>> processing the key irrespective of their order (if there is any) of
>> asking to process the key.
>>
>> Thanks for help.
>>
>> Bheem
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120524/e8c30e6a/attachment.html>

From jim.andreou at gmail.com  Thu May 24 12:13:16 2012
From: jim.andreou at gmail.com (Dimitris Andreou)
Date: Thu, 24 May 2012 09:13:16 -0700
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
Message-ID: <CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>

http://code.google.com/p/guava-libraries/issues/detail?id=859#c11

The file attached to the linked comment might end up in guava, and deals
with this very problem.
On May 24, 2012 7:27 AM, "bhm" <bheem at sbcglobal.net> wrote:

> I have a method that needs to be synchronized based on a key passed as
> parameter, that is, for same key multiple threads shouldn't be
> running. Following is what I did--
>
>
> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
>   new ConcurrentHashMap<String,Boolean>();
>
> void foo(String key){
>    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
>      // no other thread is processing this key
>      try{
>          // process this key
>      } finally {
>         // done with processing this key
>         IN_PROGRESS.remove(key)
>      }
>    } else {
>      // some other thread is running this key, discard it
>    }
> }
>
> this works if I need to discard the request to process the key from
> thread t1 when another thread, t2, is processing that key.
>
> I need help to do following-
> make thread t1 wait while t2 is processing the key and resume t1 when
> t2 is finish processing same key.
>
> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
> for t2 to finish anyone of these thread can wake up and start
> processing the key irrespective of their order (if there is any) of
> asking to process the key.
>
> Thanks for help.
>
> Bheem
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120524/906f71db/attachment.html>

From bheem at sbcglobal.net  Thu May 24 13:48:30 2012
From: bheem at sbcglobal.net (bhm)
Date: Thu, 24 May 2012 13:48:30 -0400
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
Message-ID: <CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>

Thanks.

If I understand this correctly, this keeps a collection of lock
objects (Lock/Semaphore/ReadWriteLock) and smear method can map
multiple keys to same index and
so same lock and amount of concurrency is contained by the size of
collection of lock objects (eager or lazy)

On Thu, May 24, 2012 at 12:13 PM, Dimitris Andreou
<jim.andreou at gmail.com> wrote:
> http://code.google.com/p/guava-libraries/issues/detail?id=859#c11
>
> The file attached to the linked comment might end up in guava, and deals
> with this very problem.
>
> On May 24, 2012 7:27 AM, "bhm" <bheem at sbcglobal.net> wrote:
>>
>> I have a method that needs to be synchronized based on a key passed as
>> parameter, that is, for same key multiple threads shouldn't be
>> running. Following is what I did--
>>
>>
>> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
>> ? new ConcurrentHashMap<String,Boolean>();
>>
>> void foo(String key){
>> ? ?if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
>> ? ? ?// no other thread is processing this key
>> ? ? ?try{
>> ? ? ? ? ?// process this key
>> ? ? ?} finally {
>> ? ? ? ? // done with processing this key
>> ? ? ? ? IN_PROGRESS.remove(key)
>> ? ? ?}
>> ? ?} else {
>> ? ? ?// some other thread is running this key, discard it
>> ? ?}
>> }
>>
>> this works if I need to discard the request to process the key from
>> thread t1 when another thread, t2, is processing that key.
>>
>> I need help to do following-
>> make thread t1 wait while t2 is processing the key and resume t1 when
>> t2 is finish processing same key.
>>
>> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
>> for t2 to finish anyone of these thread can wake up and start
>> processing the key irrespective of their order (if there is any) of
>> asking to process the key.
>>
>> Thanks for help.
>>
>> Bheem
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From jim.andreou at gmail.com  Thu May 24 14:22:00 2012
From: jim.andreou at gmail.com (Dimitris Andreou)
Date: Thu, 24 May 2012 11:22:00 -0700
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
Message-ID: <CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>

Yes. Basically you choose a point in the trade-off of "how much memory
you're willing to spend on lock stripes" vs "how many accidental collisions
(different keys mapped to the same lock) you can tolerate".

The other option is whether you want to preallocate all locks (and get a
compact representation for them; viable for small sets of stripes, but not
if you want millions of them), or allocate them dynamically (needs a
ConcurrentMap and the overhead is higher)

On Thu, May 24, 2012 at 10:48 AM, bhm <bheem at sbcglobal.net> wrote:

> Thanks.
>
> If I understand this correctly, this keeps a collection of lock
> objects (Lock/Semaphore/ReadWriteLock) and smear method can map
> multiple keys to same index and
> so same lock and amount of concurrency is contained by the size of
> collection of lock objects (eager or lazy)
>
> On Thu, May 24, 2012 at 12:13 PM, Dimitris Andreou
> <jim.andreou at gmail.com> wrote:
> > http://code.google.com/p/guava-libraries/issues/detail?id=859#c11
> >
> > The file attached to the linked comment might end up in guava, and deals
> > with this very problem.
> >
> > On May 24, 2012 7:27 AM, "bhm" <bheem at sbcglobal.net> wrote:
> >>
> >> I have a method that needs to be synchronized based on a key passed as
> >> parameter, that is, for same key multiple threads shouldn't be
> >> running. Following is what I did--
> >>
> >>
> >> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
> >>   new ConcurrentHashMap<String,Boolean>();
> >>
> >> void foo(String key){
> >>    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
> >>      // no other thread is processing this key
> >>      try{
> >>          // process this key
> >>      } finally {
> >>         // done with processing this key
> >>         IN_PROGRESS.remove(key)
> >>      }
> >>    } else {
> >>      // some other thread is running this key, discard it
> >>    }
> >> }
> >>
> >> this works if I need to discard the request to process the key from
> >> thread t1 when another thread, t2, is processing that key.
> >>
> >> I need help to do following-
> >> make thread t1 wait while t2 is processing the key and resume t1 when
> >> t2 is finish processing same key.
> >>
> >> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
> >> for t2 to finish anyone of these thread can wake up and start
> >> processing the key irrespective of their order (if there is any) of
> >> asking to process the key.
> >>
> >> Thanks for help.
> >>
> >> Bheem
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120524/6c54d3ea/attachment.html>

From heinz at javaspecialists.eu  Thu May 24 18:33:57 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 25 May 2012 01:33:57 +0300
Subject: [concurrency-interest]  Fork/Join Examples
In-Reply-To: <CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
	<CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
Message-ID: <4FBEB755.1080108@javaspecialists.eu>

In my latest newsletter, I show two examples how we can solve a problem 
faster using Fork/Join.  The first is Fibonacci, but a better recursive 
algorithm than is found in the JavaDocs.  However, this sum-of-squares 
algorithm requires us to do multiplication which is particularly bad 
with BigInteger.  I thus also implemented the Karatsuba multiplication 
algorithm, including a way to do it with the Fork/Join framework.

I also implemented a FibonacciCache.  I believe that caching should 
maybe be solved in general for the recursive decomposition approach with 
RecursiveTask.  In my cache, if one thread tries to do work with which 
another thread is already busy, then he waits until the other thread has 
completed his task.  This prevents duplication of work.  I bet that this 
is a common problem with recursive decomposition algorithms.  Have any 
of you thought of writing a cache that solves this problem in general 
and then making that available in the JDK?

Also, could we *please* change the example in the RecursiveTask 
JavaDocs.  It is embarrassing having an exponential algorithm as an 
example of how you would use RecursiveTask.  So if we add 1000x the 
number of processors, we can now solve case n+10?

Here is a direct link to the newsletter for those who are interested: 
http://www.javaspecialists.eu/archive/Issue201.html

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


From joe.bowbeer at gmail.com  Fri May 25 00:05:06 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 24 May 2012 21:05:06 -0700
Subject: [concurrency-interest] Fork/Join Examples
In-Reply-To: <4FBEB755.1080108@javaspecialists.eu>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
	<CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
	<4FBEB755.1080108@javaspecialists.eu>
Message-ID: <CAHzJPErpsD-_NM_W5WRwGjYQZwB=AzfP3ZUphnLcTr+mQJUHoQ@mail.gmail.com>

Thanks for the examples! I will certainly check them out.

Regarding a cache for recursive subdivision, search in JCiP and www for
Memoizer and you will find some of our attempts.
On May 24, 2012 3:41 PM, "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
wrote:

> In my latest newsletter, I show two examples how we can solve a problem
> faster using Fork/Join.  The first is Fibonacci, but a better recursive
> algorithm than is found in the JavaDocs.  However, this sum-of-squares
> algorithm requires us to do multiplication which is particularly bad with
> BigInteger.  I thus also implemented the Karatsuba multiplication
> algorithm, including a way to do it with the Fork/Join framework.
>
> I also implemented a FibonacciCache.  I believe that caching should maybe
> be solved in general for the recursive decomposition approach with
> RecursiveTask.  In my cache, if one thread tries to do work with which
> another thread is already busy, then he waits until the other thread has
> completed his task.  This prevents duplication of work.  I bet that this is
> a common problem with recursive decomposition algorithms.  Have any of you
> thought of writing a cache that solves this problem in general and then
> making that available in the JDK?
>
> Also, could we *please* change the example in the RecursiveTask JavaDocs.
>  It is embarrassing having an exponential algorithm as an example of how
> you would use RecursiveTask.  So if we add 1000x the number of processors,
> we can now solve case n+10?
>
> Here is a direct link to the newsletter for those who are interested:
> http://www.javaspecialists.eu/**archive/Issue201.html<http://www.javaspecialists.eu/archive/Issue201.html>
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120524/49b78d27/attachment-0001.html>

From heinz at javaspecialists.eu  Fri May 25 01:36:15 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 25 May 2012 08:36:15 +0300
Subject: [concurrency-interest] Fork/Join Examples
In-Reply-To: <CAHzJPErpsD-_NM_W5WRwGjYQZwB=AzfP3ZUphnLcTr+mQJUHoQ@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>	<CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>	<4FBEB755.1080108@javaspecialists.eu>
	<CAHzJPErpsD-_NM_W5WRwGjYQZwB=AzfP3ZUphnLcTr+mQJUHoQ@mail.gmail.com>
Message-ID: <4FBF1A4F.2060203@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120525/8d195088/attachment.html>

From peter at de.maeyer.net  Sat May 26 04:55:54 2012
From: peter at de.maeyer.net (Peter De Maeyer)
Date: Sat, 26 May 2012 10:55:54 +0200
Subject: [concurrency-interest] Some fork/join threads idle when workload is
	non-uniform
Message-ID: <4FC09A9A.2040406@de.maeyer.net>

We have a multithreaded application which relies heavily on the F/J 
framework. When threadprofiling the application we've observed that not 
all F/J threads are kept busy. Some threads spend a lot of time waiting, 
thus making suboptimal use of the available CPUs in the system.

I've discovered it may have something to do with the workload 
distribution. The tasks are being spawned according to a quad-tree 
structure. When each branch in the quad tree has roughly the same amount 
of work to do, all F/J threads are nicely occupied (uniform workload). 
When some branches however have a lot more work to do, while others 
don't, some F/J threads are waiting (non-uniform workload).

I am guessing it has something to do with a suboptimality in work 
stealing: in the case of uniform workload, there is little to no work 
stealing going on, and everything behaves nicely. In the case of 
non-uniform workload, there is (a lot?) more work stealing going on, 
which somehow results in waiting F/J threads.

I have attached the following files to illustrate my case:

  * ForkJoinWithUniformWorkload.java: illustrates the 'well-behaved'
    case where all F/J threads are busy (optimal usage of multi-core CPU)
  * ForkJoinWithNonUniformWorkload.java: illustrates the 'ill-behaved'
    case where one F/J thread is waiting all the time (suboptimal usage
    of multi-core CPU)
  * ForkJoinWithUniformWorkload.png: JVisualVM snapshot (screenshot) of
    the ForkJoinWithUniformWorkload program, where you can see all 4
    threads occupied
  * ForkJoinWithNonUniformWorkload.png: JVisualVM snapshot (screenshot)
    of the ForkJoinWithNonUniformWorkload program, where you can see 1
    thread sleeping. This is similar to what we see in our real-life
    application, although in our real-life application we've observed 3
    out of 8 threads waiting while only 5 are doing actual work. Note
    that this behavior is not 100% reproducible, but often enough to be
    investigated thoroughly
  * threaddump-*.tdump: thread dump of the case where the thread
    "ForkJoinPool-1-worker-1"
    of the 4 F/J threads is waiting (tryAwaitDone).

I would like to:

 1. Understand why the application is behaving this way
 2. Find a solution so that our application makes optimal use of all
    available CPUs in all circumstances


Best regards,

Peter De Maeyer

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120526/912d8099/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ForkJoinWithNonUniformWorkload.png
Type: image/png
Size: 96698 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120526/912d8099/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ForkJoinWithUniformWorkload.png
Type: image/png
Size: 92946 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120526/912d8099/attachment-0003.png>
-------------- next part --------------
2011-12-08 07:50:56
Full thread dump Java HotSpot(TM) Server VM (21.1-b02 mixed mode):

"RMI TCP Connection(2)-127.0.0.1" daemon prio=10 tid=0x08d93400 nid=0x4ea6 runnable [0x6ed5c000]
   java.lang.Thread.State: RUNNABLE
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.read(SocketInputStream.java:150)
	at java.net.SocketInputStream.read(SocketInputStream.java:121)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	- locked <0xa1965628> (a java.io.BufferedInputStream)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)

   Locked ownable synchronizers:
	- <0xa157d068> (a java.util.concurrent.ThreadPoolExecutor$Worker)

"JMX server connection timeout 17" daemon prio=10 tid=0x08d60000 nid=0x4ea4 in Object.wait() [0x6edad000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0xa16fa210> (a [I)
	at com.sun.jmx.remote.internal.ServerCommunicatorAdmin$Timeout.run(ServerCommunicatorAdmin.java:168)
	- locked <0xa16fa210> (a [I)
	at java.lang.Thread.run(Thread.java:722)

   Locked ownable synchronizers:
	- None

"RMI Scheduler(0)" daemon prio=10 tid=0x08d5ac00 nid=0x4ea2 waiting on condition [0x6edfe000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0xa151e960> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)

   Locked ownable synchronizers:
	- None

"RMI TCP Connection(1)-127.0.0.1" daemon prio=10 tid=0x08a70800 nid=0x4ea1 runnable [0x6f156000]
   java.lang.Thread.State: RUNNABLE
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.read(SocketInputStream.java:150)
	at java.net.SocketInputStream.read(SocketInputStream.java:121)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	- locked <0xa169ce90> (a java.io.BufferedInputStream)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)

   Locked ownable synchronizers:
	- <0xa157cc28> (a java.util.concurrent.ThreadPoolExecutor$Worker)

"RMI TCP Accept-0" daemon prio=10 tid=0x08cdc000 nid=0x4e9e runnable [0x6f1a7000]
   java.lang.Thread.State: RUNNABLE
	at java.net.PlainSocketImpl.socketAccept(Native Method)
	at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:396)
	at java.net.ServerSocket.implAccept(ServerSocket.java:522)
	at java.net.ServerSocket.accept(ServerSocket.java:490)
	at sun.management.jmxremote.LocalRMIServerSocketFactory$1.accept(LocalRMIServerSocketFactory.java:52)
	at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387)
	at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359)
	at java.lang.Thread.run(Thread.java:722)

   Locked ownable synchronizers:
	- None

"Attach Listener" daemon prio=10 tid=0x092c3800 nid=0x4e9c waiting on condition [0x00000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"ForkJoinPool-1-worker-4" daemon prio=10 tid=0x08a7b400 nid=0x4e11 runnable [0x6f6b9000]
   java.lang.Thread.State: RUNNABLE
	at java.lang.StrictMath.atan(Native Method)
	at java.lang.Math.atan(Math.java:204)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.doSomething(ForkJoinWithNonUniformWorkLoad.java:67)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:59)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:52)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:52)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:53)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:334)
	at java.util.concurrent.ForkJoinWorkerThread.helpJoinTask(ForkJoinWorkerThread.java:812)
	at java.util.concurrent.ForkJoinWorkerThread.joinTask(ForkJoinWorkerThread.java:727)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:362)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:53)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:334)
	at java.util.concurrent.ForkJoinWorkerThread.execTask(ForkJoinWorkerThread.java:604)
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:762)
	at java.util.concurrent.ForkJoinPool.work(ForkJoinPool.java:646)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:398)

   Locked ownable synchronizers:
	- None

"ForkJoinPool-1-worker-3" daemon prio=10 tid=0x08a79c00 nid=0x4e10 runnable [0x6f70a000]
   java.lang.Thread.State: RUNNABLE
	at java.lang.StrictMath.atan(Native Method)
	at java.lang.Math.atan(Math.java:204)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.doSomething(ForkJoinWithNonUniformWorkLoad.java:67)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:59)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:52)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:52)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:53)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:334)
	at java.util.concurrent.ForkJoinWorkerThread.execTask(ForkJoinWorkerThread.java:604)
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:762)
	at java.util.concurrent.ForkJoinPool.work(ForkJoinPool.java:646)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:398)

   Locked ownable synchronizers:
	- None

"ForkJoinPool-1-worker-2" daemon prio=10 tid=0x08a78000 nid=0x4e0f runnable [0x6f75b000]
   java.lang.Thread.State: RUNNABLE
	at java.lang.StrictMath.atan(Native Method)
	at java.lang.Math.atan(Math.java:204)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.doSomething(ForkJoinWithNonUniformWorkLoad.java:67)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:59)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:53)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:52)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:53)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:355)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:51)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:334)
	at java.util.concurrent.ForkJoinWorkerThread.execTask(ForkJoinWorkerThread.java:604)
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:762)
	at java.util.concurrent.ForkJoinPool.work(ForkJoinPool.java:646)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:398)

   Locked ownable synchronizers:
	- None

"ForkJoinPool-1-worker-1" daemon prio=10 tid=0x6ff40800 nid=0x4e0e in Object.wait() [0x6f7ac000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x747d4188> (a ForkJoinWithNonUniformWorkLoad$NonUniformWorkload)
	at java.util.concurrent.ForkJoinTask.tryAwaitDone(ForkJoinTask.java:264)
	- locked <0x747d4188> (a ForkJoinWithNonUniformWorkLoad$NonUniformWorkload)
	at java.util.concurrent.ForkJoinPool.tryAwaitJoin(ForkJoinPool.java:1043)
	at java.util.concurrent.ForkJoinWorkerThread.joinTask(ForkJoinWorkerThread.java:731)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:362)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at ForkJoinWithNonUniformWorkLoad$NonUniformWorkload.compute(ForkJoinWithNonUniformWorkLoad.java:52)
	at java.util.concurrent.RecursiveTask.exec(RecursiveTask.java:93)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:334)
	at java.util.concurrent.ForkJoinWorkerThread.execTask(ForkJoinWorkerThread.java:604)
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:784)
	at java.util.concurrent.ForkJoinPool.work(ForkJoinPool.java:646)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:398)

   Locked ownable synchronizers:
	- None

"Service Thread" daemon prio=10 tid=0x6ff04800 nid=0x4e0c runnable [0x00000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread1" daemon prio=10 tid=0x6ff02800 nid=0x4e0b waiting on condition [0x00000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread0" daemon prio=10 tid=0x6ff00800 nid=0x4e0a waiting on condition [0x00000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Signal Dispatcher" daemon prio=10 tid=0x089bbc00 nid=0x4e09 runnable [0x00000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Finalizer" daemon prio=10 tid=0x08982c00 nid=0x4e07 in Object.wait() [0x6fc22000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x747d2c50> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
	- locked <0x747d2c50> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:177)

   Locked ownable synchronizers:
	- None

"Reference Handler" daemon prio=10 tid=0x0897dc00 nid=0x4e06 in Object.wait() [0x6fc73000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x747d0500> (a java.lang.ref.Reference$Lock)
	at java.lang.Object.wait(Object.java:503)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
	- locked <0x747d0500> (a java.lang.ref.Reference$Lock)

   Locked ownable synchronizers:
	- None

"main" prio=10 tid=0x0886a000 nid=0x4dfc in Object.wait() [0xb697b000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x747d4160> (a ForkJoinWithNonUniformWorkLoad$NonUniformWorkload)
	at java.lang.Object.wait(Object.java:503)
	at java.util.concurrent.ForkJoinTask.externalAwaitDone(ForkJoinTask.java:287)
	- locked <0x747d4160> (a ForkJoinWithNonUniformWorkLoad$NonUniformWorkload)
	at java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:365)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:639)
	at java.util.concurrent.ForkJoinPool.invoke(ForkJoinPool.java:1521)
	at ForkJoinWithNonUniformWorkLoad.main(ForkJoinWithNonUniformWorkLoad.java:16)

   Locked ownable synchronizers:
	- None

"VM Thread" prio=10 tid=0x08978000 nid=0x4e05 runnable 

"GC task thread#0 (ParallelGC)" prio=10 tid=0x08871400 nid=0x4dfd runnable 

"GC task thread#1 (ParallelGC)" prio=10 tid=0x08872c00 nid=0x4dfe runnable 

"GC task thread#2 (ParallelGC)" prio=10 tid=0x08874000 nid=0x4dff runnable 

"GC task thread#3 (ParallelGC)" prio=10 tid=0x08875800 nid=0x4e00 runnable 

"GC task thread#4 (ParallelGC)" prio=10 tid=0x08877000 nid=0x4e01 runnable 

"GC task thread#5 (ParallelGC)" prio=10 tid=0x08878400 nid=0x4e02 runnable 

"GC task thread#6 (ParallelGC)" prio=10 tid=0x08879c00 nid=0x4e03 runnable 

"GC task thread#7 (ParallelGC)" prio=10 tid=0x0887b400 nid=0x4e04 runnable 

"VM Periodic Task Thread" prio=10 tid=0x6ff0ec00 nid=0x4e0d waiting on condition 

JNI global references: 198

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ForkJoinWithUniformWorkLoad.java
Type: text/x-java
Size: 1788 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120526/912d8099/attachment-0002.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ForkJoinWithNonUniformWorkLoad.java
Type: text/x-java
Size: 2198 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120526/912d8099/attachment-0003.bin>

From dl at cs.oswego.edu  Sat May 26 08:01:32 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 26 May 2012 08:01:32 -0400
Subject: [concurrency-interest] Some fork/join threads idle when
 workload is	non-uniform
In-Reply-To: <4FC09A9A.2040406@de.maeyer.net>
References: <4FC09A9A.2040406@de.maeyer.net>
Message-ID: <4FC0C61C.309@cs.oswego.edu>

On 05/26/12 04:55, Peter De Maeyer wrote:
> We have a multithreaded application which relies heavily on the F/J framework.
> When threadprofiling the application we've observed that not all F/J threads are
> kept busy. Some threads spend a lot of time waiting, thus making suboptimal use
> of the available CPUs in the system.

As far as I can tell by running your example code, the underlying issues
have been addressed for upcoming jdk8 version, as well as in the
standalone jsr166y version that you can use/run now by grabbing
jar file and changing imports from "java.util.concurrent" to "jsr166y".
(See http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)
Please try this and let me know if not.

The main underlying issue is that thread compensation was overly
conservative, which avoided unbounded spare thread construction
in the worst cases of misuse, but at the expense of overly limiting
parallelism in other cases.

-Doug


From gregg at cytetech.com  Sat May 26 10:52:41 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Sat, 26 May 2012 09:52:41 -0500
Subject: [concurrency-interest] Object finalization
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD2355530CD@G4W3299.americas.hpqcorp.net>
References: <CAHXi_0ccaS9qQHMzReSbJ8fkO_yDb27xHeE1gxSmuOYLz1zX2w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHLJEAA.davidcholmes@aapt.net.au>
	<CAGmsiP6c8PpR3+LurV+6gthkJzsKq8vYkvBAaLuMW6MmvnJgNQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355528AD@G4W3299.americas.hpqcorp.net>
	<CAHjP37G6TmnDqQ_TdQ0FX6_T-52ye-jj6dTAvyKV12up_=eWow@mail.gmail.com>,
	<A3E67C2071F49C4CBC4F17E6D77CDDD235552A36@G4W3299.americas.hpqcorp.net>
	<A43565F3-1A01-4C96-A473-AC704DB1B0F4@devexperts.com>
	<4FB25704.6050401@redhat.com> <4FB26ABB.4040206@cytetech.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD2355530CD@G4W3299.americas.hpqcorp.net>
Message-ID: <4FC0EE39.8040107@cytetech.com>

On 5/15/2012 6:45 PM, Boehm, Hans wrote:
>> From: Gregg Wonderly
>>
>> On 5/15/2012 8:15 AM, David M. Lloyd wrote:
>>> I've given up on finalization for native resources for just this
>> reason; instead
>>> I use refcounting. It's not great because there's a CAS on entry+exit
>> but I find
>>> that I can also use the same trick to replace locking in many cases
>> so I'm
>>> hoping that it'll even out in the benchmarks. I almost have myself
>> convinced
>>> that it will scale better than the finalizer option. We shall see.
>>
>> I've done this in a lot of other places myself too.  It just simplifies
>> so many
>> things to have dependable, accurate life cycles.
>>
>> Gregg
>
> It seems to me that, depending on the context, that may be trading one can of worms for another.
> Possibly a bigger one.
>
> To me, there are two distinct kinds of cleanup actions:
>
> 1) Logically synchronous; the programmer knows exactly where it's happening, and can make
> sure that the locks acquired by the cleanup code aren't acquired in the wrong order with
> respect to the calling context, etc.  C++ destructors are good at this.  Explicit cleanup
> calls often aren't too bad.  Finalizers are terrible.  It seems to me that this case usually
> doesn't even need reference counting, though occasionally it might.  And that may be a perfectly
> good use for reference counting.
>
> 2) Logically asynchronous.  We want it to be cleaned up anytime before we run out of the resource,
> whenever that may be.  This is what happens when an assignment drops the last reference to a
> large data structure containing library-defined objects which I don't understand, and have
> no business understanding.  Finalizers and java.lang.ref are potentially tolerable at this,
> with some fixes.  Traditional reference counting with synchronous resource reclamation
> is terrible at it (at least in the absence of transactional memory).  C++ destructors have
> the same problem.  The problem is that a completely innocuous looking call, performing a
> reference-counted assignment, may end up acquiring a huge collection of locks I don't know
> about, making it essentially impossible to reliably avoid deadlocks.  (This is essentially identical
> to the JDK 1.0.2 finalization bug misdescribed as a language design bug as the first
> item in http://www.cs.arizona.edu/projects/sumatra/hallofshame/ )  The problem can be avoided
> by queuing cleanups to be run later in a separate thread, just like finalizers.
>
> It also seems to me that using reference counting for (2) has a tendency to infect lots of things
> with reference counting, and may largely make the GC redundant.  Once we do that, we've solved a
> problem that was solvable with perhaps a 1% optimization cost by adding huge overhead to every
> pointer assignment.  (Not to mention garbage cycles.)

I have to do this for remote resources where one VM is using something on 
another VM.  Jini remote invocation, requires an exported endpoint.  These 
endpoints need to be released, when the remote end no longer needs them.  A 
leasing mechanism is the only way to manage this issue, and so I use the lease 
object as the triggered "release" to unexport the endpoint and unbind/close the 
associated socket.

Gregg Wonderly

From stanimir at riflexo.com  Sat May 26 17:42:34 2012
From: stanimir at riflexo.com (bestsss)
Date: Sat, 26 May 2012 14:42:34 -0700 (PDT)
Subject: [concurrency-interest]  Concurrent Bounded Stack
Message-ID: <33913940.post@talk.nabble.com>


Hi all,
I suppose the issue might have popped multiple times, yet I have not seen it
anywhere.

Stacks are great for object pools but the only available in JDK are either:
based on Vector or not thread safe (ArrayDeque), or don't have good size()
method (ConcurrentLinkedDeque). JSR codebase has a dead ConcurrentStack on
its own with slow size() method.
Some projects like tomcat use CLQ for object pools, combined w/ an
AtomicInteger for fast size() method. Neither queue make for proper pools,
nor unsynchronized size() is a nice option.

A few years back I thought that stacks can easily incorporate size on the
top of the head by keeping it along  w/ the data element, thus having O(1)
sync. size w/o any extra hurdle.
Below is the code I've come up and it has been in production since. It makes
a great pool for direct ByteBuffers and some other memory heavy structures.
With proper sizing the hit ratio is usually over 99%.


http://pastebin.com/GW1afBpz The Code at pastebin 

If you can share any possible problems with the implementation or the idea,
itself, it'd be great. Also I am partly interested why such stack never made
it into JSR166/JDK.

Cheers
Stanimir

-- 
View this message in context: http://old.nabble.com/Concurrent-Bounded-Stack-tp33913940p33913940.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From zhong.j.yu at gmail.com  Sun May 27 11:20:12 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sun, 27 May 2012 10:20:12 -0500
Subject: [concurrency-interest] Concurrent Bounded Stack
In-Reply-To: <33913940.post@talk.nabble.com>
References: <33913940.post@talk.nabble.com>
Message-ID: <CACuKZqEA1ue_ZasoCVhJ41Zeh=rL8mvGjVWSpYU9swZrda6UbQ@mail.gmail.com>

it is cool - but, is it really faster than java.util.Stack? by how much?

On Sat, May 26, 2012 at 4:42 PM, bestsss <stanimir at riflexo.com> wrote:
>
> Hi all,
> I suppose the issue might have popped multiple times, yet I have not seen it
> anywhere.
>
> Stacks are great for object pools but the only available in JDK are either:
> based on Vector or not thread safe (ArrayDeque), or don't have good size()
> method (ConcurrentLinkedDeque). JSR codebase has a dead ConcurrentStack on
> its own with slow size() method.
> Some projects like tomcat use CLQ for object pools, combined w/ an
> AtomicInteger for fast size() method. Neither queue make for proper pools,
> nor unsynchronized size() is a nice option.
>
> A few years back I thought that stacks can easily incorporate size on the
> top of the head by keeping it along ?w/ the data element, thus having O(1)
> sync. size w/o any extra hurdle.
> Below is the code I've come up and it has been in production since. It makes
> a great pool for direct ByteBuffers and some other memory heavy structures.
> With proper sizing the hit ratio is usually over 99%.
>
>
> http://pastebin.com/GW1afBpz The Code at pastebin
>
> If you can share any possible problems with the implementation or the idea,
> itself, it'd be great. Also I am partly interested why such stack never made
> it into JSR166/JDK.
>
> Cheers
> Stanimir
>
> --
> View this message in context: http://old.nabble.com/Concurrent-Bounded-Stack-tp33913940p33913940.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From jwesleysmith at atlassian.com  Sun May 27 21:48:18 2012
From: jwesleysmith at atlassian.com (Jed Wesley-Smith)
Date: Mon, 28 May 2012 11:48:18 +1000
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
	<CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
Message-ID: <CAKh+yi-QDcq3RLsK6kUzR7p-OZWAL8CHJZCywBtgksJqMKphHw@mail.gmail.com>

We have an implementation that can be striped according to any arbitrary
function from the key type (say a Long) to a smaller subset of the range
(say 64 elements using a modulo of the hash for instance).

https://labs.atlassian.com/wiki/display/CONCURRENT/ManagedLock

It uses the loaner pattern to avoid requiring clients to try lock /finally
unlock.

It also can use weak references to the actual locks objects, meaning the
memory overhead matches the actual locks in use at the time, at the expense
of constructing the objects as they are required.

Here's the interface:
https://labs.atlassian.com/source/browse/CONCURRENT/trunk/src/main/java/com/atlassian/util/concurrent/ManagedLock.java?hb=true

And the factory for creating an instance is here:
https://labs.atlassian.com/source/browse/CONCURRENT/trunk/src/main/java/com/atlassian/util/concurrent/ManagedLocks.java?hb=true
On 25 May 2012 04:22, Dimitris Andreou <jim.andreou at gmail.com> wrote:

> Yes. Basically you choose a point in the trade-off of "how much memory
> you're willing to spend on lock stripes" vs "how many accidental collisions
> (different keys mapped to the same lock) you can tolerate".
>
> The other option is whether you want to preallocate all locks (and get a
> compact representation for them; viable for small sets of stripes, but not
> if you want millions of them), or allocate them dynamically (needs a
> ConcurrentMap and the overhead is higher)
>
> On Thu, May 24, 2012 at 10:48 AM, bhm <bheem at sbcglobal.net> wrote:
>
>> Thanks.
>>
>> If I understand this correctly, this keeps a collection of lock
>> objects (Lock/Semaphore/ReadWriteLock) and smear method can map
>> multiple keys to same index and
>> so same lock and amount of concurrency is contained by the size of
>> collection of lock objects (eager or lazy)
>>
>> On Thu, May 24, 2012 at 12:13 PM, Dimitris Andreou
>> <jim.andreou at gmail.com> wrote:
>> > http://code.google.com/p/guava-libraries/issues/detail?id=859#c11
>> >
>> > The file attached to the linked comment might end up in guava, and deals
>> > with this very problem.
>> >
>> > On May 24, 2012 7:27 AM, "bhm" <bheem at sbcglobal.net> wrote:
>> >>
>> >> I have a method that needs to be synchronized based on a key passed as
>> >> parameter, that is, for same key multiple threads shouldn't be
>> >> running. Following is what I did--
>> >>
>> >>
>> >> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
>> >>   new ConcurrentHashMap<String,Boolean>();
>> >>
>> >> void foo(String key){
>> >>    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
>> >>      // no other thread is processing this key
>> >>      try{
>> >>          // process this key
>> >>      } finally {
>> >>         // done with processing this key
>> >>         IN_PROGRESS.remove(key)
>> >>      }
>> >>    } else {
>> >>      // some other thread is running this key, discard it
>> >>    }
>> >> }
>> >>
>> >> this works if I need to discard the request to process the key from
>> >> thread t1 when another thread, t2, is processing that key.
>> >>
>> >> I need help to do following-
>> >> make thread t1 wait while t2 is processing the key and resume t1 when
>> >> t2 is finish processing same key.
>> >>
>> >> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
>> >> for t2 to finish anyone of these thread can wake up and start
>> >> processing the key irrespective of their order (if there is any) of
>> >> asking to process the key.
>> >>
>> >> Thanks for help.
>> >>
>> >> Bheem
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120528/e0e2fbcc/attachment.html>

From aruld at acm.org  Tue May 29 15:17:46 2012
From: aruld at acm.org (Arul Dhesiaseelan)
Date: Tue, 29 May 2012 09:17:46 -1000
Subject: [concurrency-interest] Fwd: Some fork/join threads idle when
 workload is non-uniform
In-Reply-To: <CAKEXrxnGxPCXm=rQ7+rinp4+vDeurjvzg6bmP1pstwr-1OKD4w@mail.gmail.com>
References: <4FC09A9A.2040406@de.maeyer.net> <4FC0C61C.309@cs.oswego.edu>
	<CAKEXrxnGxPCXm=rQ7+rinp4+vDeurjvzg6bmP1pstwr-1OKD4w@mail.gmail.com>
Message-ID: <CAKEXrxnQao3bzkjwD_jJbzaVKJiyqVvoD0p-8V2PsTJmo20Wjg@mail.gmail.com>

Forgot to copy the list.

---------- Forwarded message ----------
From: Arul Dhesiaseelan <aruld at acm.org>
Date: Mon, May 28, 2012 at 12:37 PM
Subject: Re: [concurrency-interest] Some fork/join threads idle when
workload is non-uniform
To: Doug Lea <dl at cs.oswego.edu>


Out of curiosity, I ran the tests with jdk7 and noticed
"ForkJoinPool-1-worker-1" thread was waiting in the non-uniform workload
mode (as reported by Peter).

With jdk8 (build 1.8.0-ea-b40) on Mac OS X 10.7.4, I noticed an interesting
behavior though. Both tests were running fine until about 55 mins, the
ForkJoinWithNonUniformWorkLoad JVM was shutdown automatically while
ForkJoinWithUniformWorkLoad JVM was cruising along without any problems.
Any clues what might be happening here?

-Arul


On Sat, May 26, 2012 at 2:01 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/26/12 04:55, Peter De Maeyer wrote:
>
>> We have a multithreaded application which relies heavily on the F/J
>> framework.
>> When threadprofiling the application we've observed that not all F/J
>> threads are
>> kept busy. Some threads spend a lot of time waiting, thus making
>> suboptimal use
>> of the available CPUs in the system.
>>
>
> As far as I can tell by running your example code, the underlying issues
> have been addressed for upcoming jdk8 version, as well as in the
> standalone jsr166y version that you can use/run now by grabbing
> jar file and changing imports from "java.util.concurrent" to "jsr166y".
> (See http://gee.cs.oswego.edu/dl/**concurrency-interest/index.**html<http://gee.cs.oswego.edu/dl/concurrency-interest/index.html>
> )
> Please try this and let me know if not.
>
> The main underlying issue is that thread compensation was overly
> conservative, which avoided unbounded spare thread construction
> in the worst cases of misuse, but at the expense of overly limiting
> parallelism in other cases.
>
> -Doug
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
<http://twitter.com/aruld>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120529/806fa34c/attachment.html>

From william.louth at jinspired.com  Wed May 30 14:10:09 2012
From: william.louth at jinspired.com (William Louth (JINSPIRED.COM))
Date: Wed, 30 May 2012 20:10:09 +0200
Subject: [concurrency-interest] Using System Dynamics for Effective
 Concurrency & Consumption Control of Code
Message-ID: <4FC66281.6080302@jinspired.com>

some of you might be interested in this novel approach to concurrency (& 
consumption) control based on system dynamics, QoS and metering.

http://www.jinspired.com/site/using-system-dynamics-for-effective-concurrency-consumption-control-of-code



From bheem at sbcglobal.net  Thu May 31 11:30:53 2012
From: bheem at sbcglobal.net (bhm)
Date: Thu, 31 May 2012 11:30:53 -0400
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
	<CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
Message-ID: <CACwMgascnSS81gxKdZr1spu7UKr7x2=pB5SWxA_sTz2dxywk6Q@mail.gmail.com>

are there any testcases for this, how can I test for correctness that
is same keys are not being entered from multiple threads.

On Thu, May 24, 2012 at 2:22 PM, Dimitris Andreou <jim.andreou at gmail.com> wrote:
> Yes. Basically you choose a point in the trade-off of "how much memory
> you're willing to spend on lock stripes" vs "how many accidental collisions
> (different keys mapped to the same lock) you can tolerate".
>
> The other option is whether you want to preallocate all locks (and get a
> compact representation for them; viable for small sets of stripes, but not
> if you want millions of them), or allocate them dynamically (needs a
> ConcurrentMap and the overhead is higher)
>
> On Thu, May 24, 2012 at 10:48 AM, bhm <bheem at sbcglobal.net> wrote:
>>
>> Thanks.
>>
>> If I understand this correctly, this keeps a collection of lock
>> objects (Lock/Semaphore/ReadWriteLock) and smear method can map
>> multiple keys to same index and
>> so same lock and amount of concurrency is contained by the size of
>> collection of lock objects (eager or lazy)
>>
>> On Thu, May 24, 2012 at 12:13 PM, Dimitris Andreou
>> <jim.andreou at gmail.com> wrote:
>> > http://code.google.com/p/guava-libraries/issues/detail?id=859#c11
>> >
>> > The file attached to the linked comment might end up in guava, and deals
>> > with this very problem.
>> >
>> > On May 24, 2012 7:27 AM, "bhm" <bheem at sbcglobal.net> wrote:
>> >>
>> >> I have a method that needs to be synchronized based on a key passed as
>> >> parameter, that is, for same key multiple threads shouldn't be
>> >> running. Following is what I did--
>> >>
>> >>
>> >> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
>> >> ? new ConcurrentHashMap<String,Boolean>();
>> >>
>> >> void foo(String key){
>> >> ? ?if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
>> >> ? ? ?// no other thread is processing this key
>> >> ? ? ?try{
>> >> ? ? ? ? ?// process this key
>> >> ? ? ?} finally {
>> >> ? ? ? ? // done with processing this key
>> >> ? ? ? ? IN_PROGRESS.remove(key)
>> >> ? ? ?}
>> >> ? ?} else {
>> >> ? ? ?// some other thread is running this key, discard it
>> >> ? ?}
>> >> }
>> >>
>> >> this works if I need to discard the request to process the key from
>> >> thread t1 when another thread, t2, is processing that key.
>> >>
>> >> I need help to do following-
>> >> make thread t1 wait while t2 is processing the key and resume t1 when
>> >> t2 is finish processing same key.
>> >>
>> >> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
>> >> for t2 to finish anyone of these thread can wake up and start
>> >> processing the key irrespective of their order (if there is any) of
>> >> asking to process the key.
>> >>
>> >> Thanks for help.
>> >>
>> >> Bheem
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From jim.andreou at gmail.com  Thu May 31 12:36:47 2012
From: jim.andreou at gmail.com (Dimitris Andreou)
Date: Thu, 31 May 2012 09:36:47 -0700
Subject: [concurrency-interest] synchronization based on a key
In-Reply-To: <CACwMgascnSS81gxKdZr1spu7UKr7x2=pB5SWxA_sTz2dxywk6Q@mail.gmail.com>
References: <CACwMgasNhWJVvpi6NTVu0U_FsFJ7SgThRCf3aAhsdrU+BbUZtw@mail.gmail.com>
	<CADJdpBybwYuae96xiBg0CQ3-XvpSMbm3W4+SCpC5jpiBhQzwyQ@mail.gmail.com>
	<CACwMgauviBvtwERck5H8YZHtPZoi+NLYbhtcpjw89jS=Oyd+qw@mail.gmail.com>
	<CADJdpBytqE3mbiUVqgx_NVds4dNgwKn08cZ7ifHM0S-V8HUHcg@mail.gmail.com>
	<CACwMgascnSS81gxKdZr1spu7UKr7x2=pB5SWxA_sTz2dxywk6Q@mail.gmail.com>
Message-ID: <CADJdpBw_Ew6XztebNtqiOK5fe7Fpjp2iPKuTmxnUCRXyASYqaA@mail.gmail.com>

Equal keys -> their hashes will be the same, thus they will map to the same
bucket/stripe/lock, just like a hashtable.

Talked to guava people and we'll be releasing it soon after all (and its
tests).
On May 31, 2012 8:30 AM, "bhm" <bheem at sbcglobal.net> wrote:

> are there any testcases for this, how can I test for correctness that
> is same keys are not being entered from multiple threads.
>
> On Thu, May 24, 2012 at 2:22 PM, Dimitris Andreou <jim.andreou at gmail.com>
> wrote:
> > Yes. Basically you choose a point in the trade-off of "how much memory
> > you're willing to spend on lock stripes" vs "how many accidental
> collisions
> > (different keys mapped to the same lock) you can tolerate".
> >
> > The other option is whether you want to preallocate all locks (and get a
> > compact representation for them; viable for small sets of stripes, but
> not
> > if you want millions of them), or allocate them dynamically (needs a
> > ConcurrentMap and the overhead is higher)
> >
> > On Thu, May 24, 2012 at 10:48 AM, bhm <bheem at sbcglobal.net> wrote:
> >>
> >> Thanks.
> >>
> >> If I understand this correctly, this keeps a collection of lock
> >> objects (Lock/Semaphore/ReadWriteLock) and smear method can map
> >> multiple keys to same index and
> >> so same lock and amount of concurrency is contained by the size of
> >> collection of lock objects (eager or lazy)
> >>
> >> On Thu, May 24, 2012 at 12:13 PM, Dimitris Andreou
> >> <jim.andreou at gmail.com> wrote:
> >> > http://code.google.com/p/guava-libraries/issues/detail?id=859#c11
> >> >
> >> > The file attached to the linked comment might end up in guava, and
> deals
> >> > with this very problem.
> >> >
> >> > On May 24, 2012 7:27 AM, "bhm" <bheem at sbcglobal.net> wrote:
> >> >>
> >> >> I have a method that needs to be synchronized based on a key passed
> as
> >> >> parameter, that is, for same key multiple threads shouldn't be
> >> >> running. Following is what I did--
> >> >>
> >> >>
> >> >> static final ConcurrentMap<String,Boolean> IN_PROGRESS =
> >> >>   new ConcurrentHashMap<String,Boolean>();
> >> >>
> >> >> void foo(String key){
> >> >>    if(null == IN_PROGRESS.putIfAbsent(key, Boolean.TRUE)){
> >> >>      // no other thread is processing this key
> >> >>      try{
> >> >>          // process this key
> >> >>      } finally {
> >> >>         // done with processing this key
> >> >>         IN_PROGRESS.remove(key)
> >> >>      }
> >> >>    } else {
> >> >>      // some other thread is running this key, discard it
> >> >>    }
> >> >> }
> >> >>
> >> >> this works if I need to discard the request to process the key from
> >> >> thread t1 when another thread, t2, is processing that key.
> >> >>
> >> >> I need help to do following-
> >> >> make thread t1 wait while t2 is processing the key and resume t1 when
> >> >> t2 is finish processing same key.
> >> >>
> >> >> I'm aware that if there are multiple threads t1,t3,t4.. etc waiting
> >> >> for t2 to finish anyone of these thread can wake up and start
> >> >> processing the key irrespective of their order (if there is any) of
> >> >> asking to process the key.
> >> >>
> >> >> Thanks for help.
> >> >>
> >> >> Bheem
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120531/e32a8dc7/attachment.html>

From mydevgroup at gmail.com  Thu May 31 16:01:45 2012
From: mydevgroup at gmail.com (George Kovoor)
Date: Thu, 31 May 2012 21:01:45 +0100
Subject: [concurrency-interest] Double as a key in TreeMap
Message-ID: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>

Hello,
Could anyone please advise if using Double as a key in TreeMap is
safe, safe in the sense will it result in consistent output.
I am worried about the floating point precision, that might result in
key misses , is my understanding correct. Is using Double recommend in
Java

Any feedback is very much appreciated

Thanks
George

From pavel.rappo at gmail.com  Thu May 31 16:07:08 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Thu, 31 May 2012 21:07:08 +0100
Subject: [concurrency-interest] Double as a key in TreeMap
In-Reply-To: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>
References: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>
Message-ID: <4D4BE7D3-EC25-43A2-AE2A-D2BC090923FF@gmail.com>

Hi George,

how about you try to write to the double-interest at cs.oswego.edu mailing list?

On 31 May 2012, at 21:01, George Kovoor wrote:

> Hello,
> Could anyone please advise if using Double as a key in TreeMap is
> safe, safe in the sense will it result in consistent output.
> I am worried about the floating point precision, that might result in
> key misses , is my understanding correct. Is using Double recommend in
> Java
> 
> Any feedback is very much appreciated
> 
> Thanks
> George
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From mydevgroup at gmail.com  Thu May 31 16:16:44 2012
From: mydevgroup at gmail.com (George Kovoor)
Date: Thu, 31 May 2012 21:16:44 +0100
Subject: [concurrency-interest] Double as a key in TreeMap
In-Reply-To: <4D4BE7D3-EC25-43A2-AE2A-D2BC090923FF@gmail.com>
References: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>
	<4D4BE7D3-EC25-43A2-AE2A-D2BC090923FF@gmail.com>
Message-ID: <CA+kOh45NSA+cGTBW-4b=E8txZohJY1P5wkymty+ew03SjD2zBg@mail.gmail.com>

Unfortunately there is no such group,

On Thu, May 31, 2012 at 9:07 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:
> Hi George,
>
> how about you try to write to the double-interest at cs.oswego.edu mailing list?
>
> On 31 May 2012, at 21:01, George Kovoor wrote:
>
>> Hello,
>> Could anyone please advise if using Double as a key in TreeMap is
>> safe, safe in the sense will it result in consistent output.
>> I am worried about the floating point precision, that might result in
>> key misses , is my understanding correct. Is using Double recommend in
>> Java
>>
>> Any feedback is very much appreciated
>>
>> Thanks
>> George
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From aleksey.shipilev at gmail.com  Thu May 31 16:20:51 2012
From: aleksey.shipilev at gmail.com (Aleksey Shipilev)
Date: Fri, 01 Jun 2012 00:20:51 +0400
Subject: [concurrency-interest] Double as a key in TreeMap
In-Reply-To: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>
References: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>
Message-ID: <4FC7D2A3.9000406@gmail.com>

On 06/01/2012 12:01 AM, George Kovoor wrote:
> Hello,
> Could anyone please advise if using Double as a key in TreeMap is
> safe, safe in the sense will it result in consistent output.
> I am worried about the floating point precision, that might result in
> key misses , is my understanding correct. Is using Double recommend in
> Java
> 
> Any feedback is very much appreciated

These are generally the horrible ideas of the same class: asking the
offtopic question on the mailing list, and using floating point values
as the map keys. Doing that to order keys-value pairs is more or less
fine, but good luck get the desired element with explicit get(Double d).

-Aleksey.

From stanimir at riflexo.com  Thu May 31 16:27:47 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 31 May 2012 23:27:47 +0300
Subject: [concurrency-interest] Double as a key in TreeMap
In-Reply-To: <CA+kOh45NSA+cGTBW-4b=E8txZohJY1P5wkymty+ew03SjD2zBg@mail.gmail.com>
References: <CA+kOh45CLioiYwsLZtr_vCS8dx7HrBLy8HHX-kp-iFSdLXALyw@mail.gmail.com>
	<4D4BE7D3-EC25-43A2-AE2A-D2BC090923FF@gmail.com>
	<CA+kOh45NSA+cGTBW-4b=E8txZohJY1P5wkymty+ew03SjD2zBg@mail.gmail.com>
Message-ID: <CAEJX8oo2ZJZb1Mep8-nQ1BJQP=uRy5aqhk=m8KsCJK2PfjxAPQ@mail.gmail.com>

George,

You can always employ your own Comparator and compare the Doubles the way
you see fit (i.e. w/ some rounding). Thus, you can have full control.

On Thu, May 31, 2012 at 11:16 PM, George Kovoor <mydevgroup at gmail.com>wrote:

> Unfortunately there is no such group,
>
> On Thu, May 31, 2012 at 9:07 PM, Pavel Rappo <pavel.rappo at gmail.com>
> wrote:
> > Hi George,
> >
> > how about you try to write to the double-interest at cs.oswego.edu mailing
> list?
> >
> > On 31 May 2012, at 21:01, George Kovoor wrote:
> >
> >> Hello,
> >> Could anyone please advise if using Double as a key in TreeMap is
> >> safe, safe in the sense will it result in consistent output.
> >> I am worried about the floating point precision, that might result in
> >> key misses , is my understanding correct. Is using Double recommend in
> >> Java
> >>
> >> Any feedback is very much appreciated
> >>
> >> Thanks
> >> George
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120531/e32448a8/attachment-0001.html>

