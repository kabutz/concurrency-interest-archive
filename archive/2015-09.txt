From oleksandr.otenko at oracle.com  Thu Sep  3 14:19:29 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 3 Sep 2015 19:19:29 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
Message-ID: <55E88F31.7090107@oracle.com>

Has anyone come up with the answer about ordering for tryLock, or have I 
missed it?

It seems that tryLock can fail without attempting a CAS, but what 
guarantees are really expected by the code users, and are they in line 
with this assumption.


Alex


On 22/08/2015 19:15, Vitaly Davidovich wrote:
>
> I would hope there's no ordering difference between successful and 
> unsuccessful CAS.  On x86/64 the instruction itself provides full 
> fence irrespective of outcome; compiler doesn't know a priori whether 
> it will succeed or not.  Are there platforms where the lowering of the 
> CAS has different cpu ordering based on outcome? LL/SC can fail if 
> cacheline is modified in between (even if value is still the expected 
> one) but I'm not aware of that changing ordering semantics.  However, 
> if there are cases where this would matter, I hope the JVM ensures the 
> requested ordering irrespective of outcome.
>
> Along this line, the more "interesting" and related question is what 
> the ordering guarantees are for failed tryLock methods.
>
> sent from my phone
>
> On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com 
> <mailto:thurston at nomagicsoftware.com>> wrote:
>
>     Thanks for the prompt reply.  I guess I'll operate then from the yes
>     perspective.
>
>     What are the plans with respect to the "higher-order methods" on e.g.
>     AtomicReference, i.e.
>
>     T getAndAccumulate(T, BinaryOperator<T>)
>     T updateAndGet(UnaryOperator<T>)
>     . . .
>     etc.
>
>
>     Are you going to have:
>     T getAndAccumulateVolatilely(T, BinaryOperator<T>)
>     T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
>     etc versions?
>
>
>     That seems like a pollution of the API, IMO (and just awful
>     names).  And I'm
>     not really sure where it ends.
>
>     And then a small javadoc modification suggestion:
>     /**
>           * Returns the value, and ensures that subsequent loads and
>     stores
>           * are not reordered before this access.
>           *
>           * @apiNote Ignoring the many semantic differences from C and
>           * C++, this method has memory ordering effects compatible with
>           * memory_order_acquire ordering.
>           *
>           * @return the value
>           */
>          T getAcquire(Object owner);
>
>     I find
>     /**
>           * Returns the value, and ensures that subsequent loads and
>     stores (*in
>     the program order*)
>           * are not reordered before this access.
>           *
>           * @apiNote Ignoring the many semantic differences from C and
>           * C++, this method has memory ordering effects compatible with
>           * memory_order_acquire ordering.
>           *
>           * @return the value
>           */
>          T getAcquire(Object owner);
>
>     to be a little clearer as *subsequent* is an overloaded term when
>     it comes
>     to JMM matters.
>
>     And one final question that I've always been confused about; are there
>     different "memory ordering effects" between a successful CAS and an
>     unsuccessful one (presumably in the latter because no write actually
>     occurs)?
>     IIRC, when looking at the java 8 JVM code, I believe a fence was
>     inserted in
>     the successful case, at least on x86/64.  If so, I can take a shot at
>     producing some javadoc language to reflect that, if it would be
>     helpful.
>
>
>
>     --
>     View this message in context:
>     http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
>     Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150903/6a4140e3/attachment.html>

From aph at redhat.com  Thu Sep  3 14:45:22 2015
From: aph at redhat.com (Andrew Haley)
Date: Thu, 3 Sep 2015 19:45:22 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
Message-ID: <55E89542.4060805@redhat.com>

On 08/22/2015 07:15 PM, Vitaly Davidovich wrote:

> I would hope there's no ordering difference between successful and
> unsuccessful CAS.  On x86/64 the instruction itself provides full
> fence irrespective of outcome; compiler doesn't know a priori
> whether it will succeed or not.

Right, but that's a side-effect of the implementation, not a
specification.  The specification says it's a volatile load followed
by a volatile store, and that's all we can assume.  It should be made
plain that if the store does not happen, the store fence doesn't
happen either.  It would be an extremely strange program which relied
on a failed store to have the side-effects of a volatile store.

> Are there platforms where the lowering of the CAS has different cpu
> ordering based on outcome?

Yes.  On AArch64 (and probably every other processor) a Store-Release
Exclusive instruction only has the release semantics if the store is
successful.

> LL/SC can fail if cacheline is modified in between (even if value is
> still the expected one) but I'm not aware of that changing ordering
> semantics.  However, if there are cases where this would matter, I
> hope the JVM ensures the requested ordering irrespective of outcome.

I hope so too, but I don't want to see pointless extra memory
barriers.  I don't think that most algorithms will ever need them.

Andrew.

From davidcholmes at aapt.net.au  Thu Sep  3 16:57:47 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 4 Sep 2015 06:57:47 +1000
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55E88F31.7090107@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com>
Message-ID: <024d01d0e68b$306607a0$913216e0$@net.au>

tryLock seems a non-issue to me. If you acquire a lock you are guaranteed to
see all changes made by previous owners of the lock. If you fail to acquire
the lock then . you should not be expecting anything.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
Sent: Friday, September 4, 2015 4:19 AM
To: Vitaly Davidovich; thurston
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Has anyone come up with the answer about ordering for tryLock, or have I
missed it?

It seems that tryLock can fail without attempting a CAS, but what guarantees
are really expected by the code users, and are they in line with this
assumption.


Alex



On 22/08/2015 19:15, Vitaly Davidovich wrote:

I would hope there's no ordering difference between successful and
unsuccessful CAS.  On x86/64 the instruction itself provides full fence
irrespective of outcome; compiler doesn't know a priori whether it will
succeed or not.  Are there platforms where the lowering of the CAS has
different cpu ordering based on outcome? LL/SC can fail if cacheline is
modified in between (even if value is still the expected one) but I'm not
aware of that changing ordering semantics.  However, if there are cases
where this would matter, I hope the JVM ensures the requested ordering
irrespective of outcome.

Along this line, the more "interesting" and related question is what the
ordering guarantees are for failed tryLock methods.

sent from my phone

On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

Thanks for the prompt reply.  I guess I'll operate then from the yes
perspective.

What are the plans with respect to the "higher-order methods" on e.g.
AtomicReference, i.e.

T getAndAccumulate(T, BinaryOperator<T>)
T updateAndGet(UnaryOperator<T>)
. . .
etc.


Are you going to have:
T getAndAccumulateVolatilely(T, BinaryOperator<T>)
T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
etc versions?


That seems like a pollution of the API, IMO (and just awful names).  And I'm
not really sure where it ends.

And then a small javadoc modification suggestion:
/**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

I find
/**
      * Returns the value, and ensures that subsequent loads and stores (*in
the program order*)
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

to be a little clearer as *subsequent* is an overloaded term when it comes
to JMM matters.

And one final question that I've always been confused about;  are there
different "memory ordering effects" between a successful CAS and an
unsuccessful one (presumably in the latter because no write actually
occurs)?
IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
the successful case, at least on x86/64.  If so, I can take a shot at
producing some javadoc language to reflect that, if it would be helpful.



--
View this message in context:
http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-metho
ds-tp12666p12680.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/7d97b4c1/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  3 18:17:49 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 3 Sep 2015 23:17:49 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <024d01d0e68b$306607a0$913216e0$@net.au>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <024d01d0e68b$306607a0$913216e0$@net.au>
Message-ID: <55E8C70D.70509@oracle.com>

You should at least see everything preceding the lock acquire - since 
you see the lock acquired - and therefore everything preceding the lock 
release.

Alex


On 03/09/2015 21:57, David Holmes wrote:
>
> tryLock seems a non-issue to me. If you acquire a lock you are 
> guaranteed to see all changes made by previous owners of the lock. If 
> you fail to acquire the lock then ? you should not be expecting anything.
>
> David
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
> *Oleksandr Otenko
> *Sent:* Friday, September 4, 2015 4:19 AM
> *To:* Vitaly Davidovich; thurston
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
> Has anyone come up with the answer about ordering for tryLock, or have 
> I missed it?
>
> It seems that tryLock can fail without attempting a CAS, but what 
> guarantees are really expected by the code users, and are they in line 
> with this assumption.
>
>
> Alex
>
> On 22/08/2015 19:15, Vitaly Davidovich wrote:
>
>     I would hope there's no ordering difference between successful and
>     unsuccessful CAS.  On x86/64 the instruction itself provides full
>     fence irrespective of outcome; compiler doesn't know a priori
>     whether it will succeed or not.  Are there platforms where the
>     lowering of the CAS has different cpu ordering based on outcome?
>     LL/SC can fail if cacheline is modified in between (even if value
>     is still the expected one) but I'm not aware of that changing
>     ordering semantics.  However, if there are cases where this would
>     matter, I hope the JVM ensures the requested ordering irrespective
>     of outcome.
>
>     Along this line, the more "interesting" and related question is
>     what the ordering guarantees are for failed tryLock methods.
>
>     sent from my phone
>
>     On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com
>     <mailto:thurston at nomagicsoftware.com>> wrote:
>
>     Thanks for the prompt reply.  I guess I'll operate then from the yes
>     perspective.
>
>     What are the plans with respect to the "higher-order methods" on e.g.
>     AtomicReference, i.e.
>
>     T getAndAccumulate(T, BinaryOperator<T>)
>     T updateAndGet(UnaryOperator<T>)
>     . . .
>     etc.
>
>
>     Are you going to have:
>     T getAndAccumulateVolatilely(T, BinaryOperator<T>)
>     T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
>     etc versions?
>
>
>     That seems like a pollution of the API, IMO (and just awful
>     names).  And I'm
>     not really sure where it ends.
>
>     And then a small javadoc modification suggestion:
>     /**
>           * Returns the value, and ensures that subsequent loads and
>     stores
>           * are not reordered before this access.
>           *
>           * @apiNote Ignoring the many semantic differences from C and
>           * C++, this method has memory ordering effects compatible with
>           * memory_order_acquire ordering.
>           *
>           * @return the value
>           */
>          T getAcquire(Object owner);
>
>     I find
>     /**
>           * Returns the value, and ensures that subsequent loads and
>     stores (*in
>     the program order*)
>           * are not reordered before this access.
>           *
>           * @apiNote Ignoring the many semantic differences from C and
>           * C++, this method has memory ordering effects compatible with
>           * memory_order_acquire ordering.
>           *
>           * @return the value
>           */
>          T getAcquire(Object owner);
>
>     to be a little clearer as *subsequent* is an overloaded term when
>     it comes
>     to JMM matters.
>
>     And one final question that I've always been confused about;  are
>     there
>     different "memory ordering effects" between a successful CAS and an
>     unsuccessful one (presumably in the latter because no write actually
>     occurs)?
>     IIRC, when looking at the java 8 JVM code, I believe a fence was
>     inserted in
>     the successful case, at least on x86/64.  If so, I can take a shot at
>     producing some javadoc language to reflect that, if it would be
>     helpful.
>
>
>
>     --
>     View this message in context:
>     http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
>     Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>     _______________________________________________
>
>     Concurrency-interest mailing list
>
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150903/1382fe02/attachment.html>

From davidcholmes at aapt.net.au  Thu Sep  3 18:34:24 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 4 Sep 2015 08:34:24 +1000
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55E8C70D.70509@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>	<55E88F31.7090107@oracle.com>
	<024d01d0e68b$306607a0$913216e0$@net.au>
	<55E8C70D.70509@oracle.com>
Message-ID: <026701d0e698$b0102550$10306ff0$@net.au>

Not sure what "everything" is. If Thread A releases the lock and thread B
acquires it, then B sees everything that happened in A before the release.
If thread C now does a tryLock and sees the lock is already owned you are
suggesting it should see what thread B sees because if it had acquired the
lock then that would be the case. But it didn't acquire it, it only sees
that it is already acquired by another thread. So I don't see there is any
transitive relationship that has to be applied here. Implementation wise it
is likely but in terms of the model I think expectations and requirements
should be nil.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
Sent: Friday, September 4, 2015 8:18 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

You should at least see everything preceding the lock acquire - since you
see the lock acquired - and therefore everything preceding the lock release.

Alex



On 03/09/2015 21:57, David Holmes wrote:

tryLock seems a non-issue to me. If you acquire a lock you are guaranteed to
see all changes made by previous owners of the lock. If you fail to acquire
the lock then . you should not be expecting anything.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
Sent: Friday, September 4, 2015 4:19 AM
To: Vitaly Davidovich; thurston
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Has anyone come up with the answer about ordering for tryLock, or have I
missed it?

It seems that tryLock can fail without attempting a CAS, but what guarantees
are really expected by the code users, and are they in line with this
assumption.


Alex




On 22/08/2015 19:15, Vitaly Davidovich wrote:

I would hope there's no ordering difference between successful and
unsuccessful CAS.  On x86/64 the instruction itself provides full fence
irrespective of outcome; compiler doesn't know a priori whether it will
succeed or not.  Are there platforms where the lowering of the CAS has
different cpu ordering based on outcome? LL/SC can fail if cacheline is
modified in between (even if value is still the expected one) but I'm not
aware of that changing ordering semantics.  However, if there are cases
where this would matter, I hope the JVM ensures the requested ordering
irrespective of outcome.

Along this line, the more "interesting" and related question is what the
ordering guarantees are for failed tryLock methods.

sent from my phone

On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

Thanks for the prompt reply.  I guess I'll operate then from the yes
perspective.

What are the plans with respect to the "higher-order methods" on e.g.
AtomicReference, i.e.

T getAndAccumulate(T, BinaryOperator<T>)
T updateAndGet(UnaryOperator<T>)
. . .
etc.


Are you going to have:
T getAndAccumulateVolatilely(T, BinaryOperator<T>)
T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
etc versions?


That seems like a pollution of the API, IMO (and just awful names).  And I'm
not really sure where it ends.

And then a small javadoc modification suggestion:
/**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

I find
/**
      * Returns the value, and ensures that subsequent loads and stores (*in
the program order*)
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

to be a little clearer as *subsequent* is an overloaded term when it comes
to JMM matters.

And one final question that I've always been confused about;  are there
different "memory ordering effects" between a successful CAS and an
unsuccessful one (presumably in the latter because no write actually
occurs)?
IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
the successful case, at least on x86/64.  If so, I can take a shot at
producing some javadoc language to reflect that, if it would be helpful.



--
View this message in context:
http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-metho
ds-tp12666p12680.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest







_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/f62c85e3/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Sep  3 18:48:09 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 3 Sep 2015 23:48:09 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <026701d0e698$b0102550$10306ff0$@net.au>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <024d01d0e68b$306607a0$913216e0$@net.au>
	<55E8C70D.70509@oracle.com> <026701d0e698$b0102550$10306ff0$@net.au>
Message-ID: <55E8CE29.6030302@oracle.com>

Sure, lock acquires and releases in JMM don't guarantee ordering until 
the lock is acquired. But also they don't have a tryLock in JMM - as it 
really concerns the synchronized, doesn't it.

Alex

On 03/09/2015 23:34, David Holmes wrote:
>
> Not sure what ?everything? is. If Thread A releases the lock and 
> thread B acquires it, then B sees everything that happened in A before 
> the release. If thread C now does a tryLock and sees the lock is 
> already owned you are suggesting it should see what thread B sees 
> because if it had acquired the lock then that would be the case. But 
> it didn?t acquire it, it only sees that it is already acquired by 
> another thread. So I don?t see there is any transitive relationship 
> that has to be applied here. Implementation wise it is likely but in 
> terms of the model I think expectations and requirements should be nil.
>
> David
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
> *Oleksandr Otenko
> *Sent:* Friday, September 4, 2015 8:18 AM
> *To:* dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
> You should at least see everything preceding the lock acquire - since 
> you see the lock acquired - and therefore everything preceding the 
> lock release.
>
> Alex
>
> On 03/09/2015 21:57, David Holmes wrote:
>
>     tryLock seems a non-issue to me. If you acquire a lock you are
>     guaranteed to see all changes made by previous owners of the lock.
>     If you fail to acquire the lock then ? you should not be expecting
>     anything.
>
>     David
>
>     *From:*concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of
>     *Oleksandr Otenko
>     *Sent:* Friday, September 4, 2015 4:19 AM
>     *To:* Vitaly Davidovich; thurston
>     *Cc:* concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>     Has anyone come up with the answer about ordering for tryLock, or
>     have I missed it?
>
>     It seems that tryLock can fail without attempting a CAS, but what
>     guarantees are really expected by the code users, and are they in
>     line with this assumption.
>
>
>     Alex
>
>
>     On 22/08/2015 19:15, Vitaly Davidovich wrote:
>
>         I would hope there's no ordering difference between successful
>         and unsuccessful CAS.  On x86/64 the instruction itself
>         provides full fence irrespective of outcome; compiler doesn't
>         know a priori whether it will succeed or not.  Are there
>         platforms where the lowering of the CAS has different cpu
>         ordering based on outcome? LL/SC can fail if cacheline is
>         modified in between (even if value is still the expected one)
>         but I'm not aware of that changing ordering semantics.
>         However, if there are cases where this would matter, I hope
>         the JVM ensures the requested ordering irrespective of outcome.
>
>         Along this line, the more "interesting" and related question
>         is what the ordering guarantees are for failed tryLock methods.
>
>         sent from my phone
>
>         On Aug 22, 2015 1:41 PM, "thurstonn"
>         <thurston at nomagicsoftware.com
>         <mailto:thurston at nomagicsoftware.com>> wrote:
>
>         Thanks for the prompt reply.  I guess I'll operate then from
>         the yes
>         perspective.
>
>         What are the plans with respect to the "higher-order methods"
>         on e.g.
>         AtomicReference, i.e.
>
>         T getAndAccumulate(T, BinaryOperator<T>)
>         T updateAndGet(UnaryOperator<T>)
>         . . .
>         etc.
>
>
>         Are you going to have:
>         T getAndAccumulateVolatilely(T, BinaryOperator<T>)
>         T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
>         etc versions?
>
>
>         That seems like a pollution of the API, IMO (and just awful
>         names).  And I'm
>         not really sure where it ends.
>
>         And then a small javadoc modification suggestion:
>         /**
>               * Returns the value, and ensures that subsequent loads
>         and stores
>               * are not reordered before this access.
>               *
>               * @apiNote Ignoring the many semantic differences from C and
>               * C++, this method has memory ordering effects
>         compatible with
>               * memory_order_acquire ordering.
>               *
>               * @return the value
>               */
>              T getAcquire(Object owner);
>
>         I find
>         /**
>               * Returns the value, and ensures that subsequent loads
>         and stores (*in
>         the program order*)
>               * are not reordered before this access.
>               *
>               * @apiNote Ignoring the many semantic differences from C and
>               * C++, this method has memory ordering effects
>         compatible with
>               * memory_order_acquire ordering.
>               *
>               * @return the value
>               */
>              T getAcquire(Object owner);
>
>         to be a little clearer as *subsequent* is an overloaded term
>         when it comes
>         to JMM matters.
>
>         And one final question that I've always been confused about; 
>         are there
>         different "memory ordering effects" between a successful CAS
>         and an
>         unsuccessful one (presumably in the latter because no write
>         actually
>         occurs)?
>         IIRC, when looking at the java 8 JVM code, I believe a fence
>         was inserted in
>         the successful case, at least on x86/64.  If so, I can take a
>         shot at
>         producing some javadoc language to reflect that, if it would
>         be helpful.
>
>
>
>         --
>         View this message in context:
>         http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
>         Sent from the JSR166 Concurrency mailing list archive at
>         Nabble.com.
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>         _______________________________________________
>
>         Concurrency-interest mailing list
>
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150903/6403b0dc/attachment.html>

From davidcholmes at aapt.net.au  Thu Sep  3 19:26:45 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 4 Sep 2015 09:26:45 +1000
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55E8CE29.6030302@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>	<55E88F31.7090107@oracle.com>
	<024d01d0e68b$306607a0$913216e0$@net.au>	<55E8C70D.70509@oracle.com>
	<026701d0e698$b0102550$10306ff0$@net.au>
	<55E8CE29.6030302@oracle.com>
Message-ID: <027e01d0e69f$ffed3a70$ffc7af50$@net.au>

j.u.c also adopts the same principle:

 

Actions prior to "releasing" synchronizer methods such as Lock.unlock,
Semaphore.release, and CountDownLatch.countDown happen-before actions
subsequent to a successful "acquiring" method such as Lock.lock,
Semaphore.acquire, Condition.await, and CountDownLatch.await on the same
synchronizer object in another thread.

 

Note the use of "successful" which already indicates tryLock is not included
here.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
Sent: Friday, September 4, 2015 8:48 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Sure, lock acquires and releases in JMM don't guarantee ordering until the
lock is acquired. But also they don't have a tryLock in JMM - as it really
concerns the synchronized, doesn't it.

Alex

On 03/09/2015 23:34, David Holmes wrote:

Not sure what "everything" is. If Thread A releases the lock and thread B
acquires it, then B sees everything that happened in A before the release.
If thread C now does a tryLock and sees the lock is already owned you are
suggesting it should see what thread B sees because if it had acquired the
lock then that would be the case. But it didn't acquire it, it only sees
that it is already acquired by another thread. So I don't see there is any
transitive relationship that has to be applied here. Implementation wise it
is likely but in terms of the model I think expectations and requirements
should be nil.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
Sent: Friday, September 4, 2015 8:18 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

You should at least see everything preceding the lock acquire - since you
see the lock acquired - and therefore everything preceding the lock release.

Alex




On 03/09/2015 21:57, David Holmes wrote:

tryLock seems a non-issue to me. If you acquire a lock you are guaranteed to
see all changes made by previous owners of the lock. If you fail to acquire
the lock then . you should not be expecting anything.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
Sent: Friday, September 4, 2015 4:19 AM
To: Vitaly Davidovich; thurston
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Has anyone come up with the answer about ordering for tryLock, or have I
missed it?

It seems that tryLock can fail without attempting a CAS, but what guarantees
are really expected by the code users, and are they in line with this
assumption.


Alex





On 22/08/2015 19:15, Vitaly Davidovich wrote:

I would hope there's no ordering difference between successful and
unsuccessful CAS.  On x86/64 the instruction itself provides full fence
irrespective of outcome; compiler doesn't know a priori whether it will
succeed or not.  Are there platforms where the lowering of the CAS has
different cpu ordering based on outcome? LL/SC can fail if cacheline is
modified in between (even if value is still the expected one) but I'm not
aware of that changing ordering semantics.  However, if there are cases
where this would matter, I hope the JVM ensures the requested ordering
irrespective of outcome.

Along this line, the more "interesting" and related question is what the
ordering guarantees are for failed tryLock methods.

sent from my phone

On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

Thanks for the prompt reply.  I guess I'll operate then from the yes
perspective.

What are the plans with respect to the "higher-order methods" on e.g.
AtomicReference, i.e.

T getAndAccumulate(T, BinaryOperator<T>)
T updateAndGet(UnaryOperator<T>)
. . .
etc.


Are you going to have:
T getAndAccumulateVolatilely(T, BinaryOperator<T>)
T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
etc versions?


That seems like a pollution of the API, IMO (and just awful names).  And I'm
not really sure where it ends.

And then a small javadoc modification suggestion:
/**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

I find
/**
      * Returns the value, and ensures that subsequent loads and stores (*in
the program order*)
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

to be a little clearer as *subsequent* is an overloaded term when it comes
to JMM matters.

And one final question that I've always been confused about;  are there
different "memory ordering effects" between a successful CAS and an
unsuccessful one (presumably in the latter because no write actually
occurs)?
IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
the successful case, at least on x86/64.  If so, I can take a shot at
producing some javadoc language to reflect that, if it would be helpful.



--
View this message in context:
http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-metho
ds-tp12666p12680.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest








_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/87af338e/attachment-0001.html>

From vitalyd at gmail.com  Thu Sep  3 23:09:42 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 3 Sep 2015 23:09:42 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <027e01d0e69f$ffed3a70$ffc7af50$@net.au>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com>
	<024d01d0e68b$306607a0$913216e0$@net.au>
	<55E8C70D.70509@oracle.com>
	<026701d0e698$b0102550$10306ff0$@net.au>
	<55E8CE29.6030302@oracle.com>
	<027e01d0e69f$ffed3a70$ffc7af50$@net.au>
Message-ID: <CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>

If thread A releases a lock and threads B and C tryLock it, with one
succeeding, the failing thread may want to do something else but wants a
happens-before edge with the lock release - that's the general use case.
As a simple example, consider two threads tryLock'ing to acquire the
exclusive right to close a socket and then perform some additional actions
that require ordering of actions done by the releasing thread.  The thread
failing to acquire the lock will skip closing the socket but will proceed
to do some work that requires happens-before edge.  This is typically done
using CAS, with one thread successfully flipping the state, and the others
just skip that action that's guarded by the CAS, but can proceed with doing
subsequent work.  In other words, one may want to piggyback on the
unlock/tryLock to provide the ordering rather than introducing additional
dedicated state for this.

sent from my phone
On Sep 3, 2015 7:26 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> j.u.c also adopts the same principle:
>
>
>
> Actions prior to "releasing" synchronizer methods such as Lock.unlock,
> Semaphore.release, and CountDownLatch.countDown *happen-before* actions
> subsequent to a successful "acquiring" method such as Lock.lock,
> Semaphore.acquire, Condition.await, and CountDownLatch.await on the same
> synchronizer object in another thread.
>
>
>
> Note the use of ?successful? which already indicates tryLock is not
> included here.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Oleksandr
> Otenko
> *Sent:* Friday, September 4, 2015 8:48 AM
> *To:* dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> Sure, lock acquires and releases in JMM don't guarantee ordering until the
> lock is acquired. But also they don't have a tryLock in JMM - as it really
> concerns the synchronized, doesn't it.
>
> Alex
>
> On 03/09/2015 23:34, David Holmes wrote:
>
> Not sure what ?everything? is. If Thread A releases the lock and thread B
> acquires it, then B sees everything that happened in A before the release.
> If thread C now does a tryLock and sees the lock is already owned you are
> suggesting it should see what thread B sees because if it had acquired the
> lock then that would be the case. But it didn?t acquire it, it only sees
> that it is already acquired by another thread. So I don?t see there is any
> transitive relationship that has to be applied here. Implementation wise it
> is likely but in terms of the model I think expectations and requirements
> should be nil.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu
> <concurrency-interest-bounces at cs.oswego.edu>] *On Behalf Of *Oleksandr
> Otenko
> *Sent:* Friday, September 4, 2015 8:18 AM
> *To:* dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> You should at least see everything preceding the lock acquire - since you
> see the lock acquired - and therefore everything preceding the lock release.
>
> Alex
>
>
> On 03/09/2015 21:57, David Holmes wrote:
>
> tryLock seems a non-issue to me. If you acquire a lock you are guaranteed
> to see all changes made by previous owners of the lock. If you fail to
> acquire the lock then ? you should not be expecting anything.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu
> <concurrency-interest-bounces at cs.oswego.edu>] *On Behalf Of *Oleksandr
> Otenko
> *Sent:* Friday, September 4, 2015 4:19 AM
> *To:* Vitaly Davidovich; thurston
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> Has anyone come up with the answer about ordering for tryLock, or have I
> missed it?
>
> It seems that tryLock can fail without attempting a CAS, but what
> guarantees are really expected by the code users, and are they in line with
> this assumption.
>
>
> Alex
>
>
>
> On 22/08/2015 19:15, Vitaly Davidovich wrote:
>
> I would hope there's no ordering difference between successful and
> unsuccessful CAS.  On x86/64 the instruction itself provides full fence
> irrespective of outcome; compiler doesn't know a priori whether it will
> succeed or not.  Are there platforms where the lowering of the CAS has
> different cpu ordering based on outcome? LL/SC can fail if cacheline is
> modified in between (even if value is still the expected one) but I'm not
> aware of that changing ordering semantics.  However, if there are cases
> where this would matter, I hope the JVM ensures the requested ordering
> irrespective of outcome.
>
> Along this line, the more "interesting" and related question is what the
> ordering guarantees are for failed tryLock methods.
>
> sent from my phone
>
> On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:
>
> Thanks for the prompt reply.  I guess I'll operate then from the yes
> perspective.
>
> What are the plans with respect to the "higher-order methods" on e.g.
> AtomicReference, i.e.
>
> T getAndAccumulate(T, BinaryOperator<T>)
> T updateAndGet(UnaryOperator<T>)
> . . .
> etc.
>
>
> Are you going to have:
> T getAndAccumulateVolatilely(T, BinaryOperator<T>)
> T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
> etc versions?
>
>
> That seems like a pollution of the API, IMO (and just awful names).  And
> I'm
> not really sure where it ends.
>
> And then a small javadoc modification suggestion:
> /**
>       * Returns the value, and ensures that subsequent loads and stores
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> I find
> /**
>       * Returns the value, and ensures that subsequent loads and stores
> (*in
> the program order*)
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> to be a little clearer as *subsequent* is an overloaded term when it comes
> to JMM matters.
>
> And one final question that I've always been confused about;  are there
> different "memory ordering effects" between a successful CAS and an
> unsuccessful one (presumably in the latter because no write actually
> occurs)?
> IIRC, when looking at the java 8 JVM code, I believe a fence was inserted
> in
> the successful case, at least on x86/64.  If so, I can take a shot at
> producing some javadoc language to reflect that, if it would be helpful.
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>
> _______________________________________________
>
> Concurrency-interest mailing list
>
> Concurrency-interest at cs.oswego.edu
>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150903/de791758/attachment.html>

From davidcholmes at aapt.net.au  Thu Sep  3 23:32:09 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 4 Sep 2015 13:32:09 +1000
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>	<55E88F31.7090107@oracle.com>	<024d01d0e68b$306607a0$913216e0$@net.au>	<55E8C70D.70509@oracle.com>	<026701d0e698$b0102550$10306ff0$@net.au>	<55E8CE29.6030302@oracle.com>	<027e01d0e69f$ffed3a70$ffc7af50$@net.au>
	<CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>
Message-ID: <02b101d0e6c2$47e22030$d7a66090$@net.au>

I don?t agree that is a general use-case. You can always postulate a need for a happens-before edge between two things. I don?t think it is reasonable to expect one on a failing tryLock. Any shared state will need to be protected by a lock or else volatile ? and those should be what establishes the HB edges in my opinion.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Vitaly Davidovich
Sent: Friday, September 4, 2015 1:10 PM
To: dholmes at ieee.org
Cc: thurston; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

If thread A releases a lock and threads B and C tryLock it, with one succeeding, the failing thread may want to do something else but wants a happens-before edge with the lock release - that's the general use case.  As a simple example, consider two threads tryLock'ing to acquire the exclusive right to close a socket and then perform some additional actions that require ordering of actions done by the releasing thread.  The thread failing to acquire the lock will skip closing the socket but will proceed to do some work that requires happens-before edge.  This is typically done using CAS, with one thread successfully flipping the state, and the others just skip that action that's guarded by the CAS, but can proceed with doing subsequent work.  In other words, one may want to piggyback on the unlock/tryLock to provide the ordering rather than introducing additional dedicated state for this.

sent from my phone

On Sep 3, 2015 7:26 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

j.u.c also adopts the same principle:

 

Actions prior to "releasing" synchronizer methods such as Lock.unlock, Semaphore.release, and CountDownLatch.countDown happen-before actions subsequent to a successful "acquiring" method such as Lock.lock, Semaphore.acquire, Condition.await, and CountDownLatch.await on the same synchronizer object in another thread.

 

Note the use of ?successful? which already indicates tryLock is not included here.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Friday, September 4, 2015 8:48 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Sure, lock acquires and releases in JMM don't guarantee ordering until the lock is acquired. But also they don't have a tryLock in JMM - as it really concerns the synchronized, doesn't it.

Alex

On 03/09/2015 23:34, David Holmes wrote:

Not sure what ?everything? is. If Thread A releases the lock and thread B acquires it, then B sees everything that happened in A before the release. If thread C now does a tryLock and sees the lock is already owned you are suggesting it should see what thread B sees because if it had acquired the lock then that would be the case. But it didn?t acquire it, it only sees that it is already acquired by another thread. So I don?t see there is any transitive relationship that has to be applied here. Implementation wise it is likely but in terms of the model I think expectations and requirements should be nil.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Friday, September 4, 2015 8:18 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

You should at least see everything preceding the lock acquire - since you see the lock acquired - and therefore everything preceding the lock release.

Alex



On 03/09/2015 21:57, David Holmes wrote:

tryLock seems a non-issue to me. If you acquire a lock you are guaranteed to see all changes made by previous owners of the lock. If you fail to acquire the lock then ? you should not be expecting anything.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Friday, September 4, 2015 4:19 AM
To: Vitaly Davidovich; thurston
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Has anyone come up with the answer about ordering for tryLock, or have I missed it?

It seems that tryLock can fail without attempting a CAS, but what guarantees are really expected by the code users, and are they in line with this assumption.


Alex




On 22/08/2015 19:15, Vitaly Davidovich wrote:

I would hope there's no ordering difference between successful and unsuccessful CAS.  On x86/64 the instruction itself provides full fence irrespective of outcome; compiler doesn't know a priori whether it will succeed or not.  Are there platforms where the lowering of the CAS has different cpu ordering based on outcome? LL/SC can fail if cacheline is modified in between (even if value is still the expected one) but I'm not aware of that changing ordering semantics.  However, if there are cases where this would matter, I hope the JVM ensures the requested ordering irrespective of outcome.

Along this line, the more "interesting" and related question is what the ordering guarantees are for failed tryLock methods.

sent from my phone

On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

Thanks for the prompt reply.  I guess I'll operate then from the yes
perspective.

What are the plans with respect to the "higher-order methods" on e.g.
AtomicReference, i.e.

T getAndAccumulate(T, BinaryOperator<T>)
T updateAndGet(UnaryOperator<T>)
. . .
etc.


Are you going to have:
T getAndAccumulateVolatilely(T, BinaryOperator<T>)
T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
etc versions?


That seems like a pollution of the API, IMO (and just awful names).  And I'm
not really sure where it ends.

And then a small javadoc modification suggestion:
/**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

I find
/**
      * Returns the value, and ensures that subsequent loads and stores (*in
the program order*)
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

to be a little clearer as *subsequent* is an overloaded term when it comes
to JMM matters.

And one final question that I've always been confused about;  are there
different "memory ordering effects" between a successful CAS and an
unsuccessful one (presumably in the latter because no write actually
occurs)?
IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
the successful case, at least on x86/64.  If so, I can take a shot at
producing some javadoc language to reflect that, if it would be helpful.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest







_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/1d556baf/attachment-0001.html>

From vitalyd at gmail.com  Thu Sep  3 23:41:25 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 3 Sep 2015 23:41:25 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <02b101d0e6c2$47e22030$d7a66090$@net.au>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com>
	<024d01d0e68b$306607a0$913216e0$@net.au>
	<55E8C70D.70509@oracle.com>
	<026701d0e698$b0102550$10306ff0$@net.au>
	<55E8CE29.6030302@oracle.com>
	<027e01d0e69f$ffed3a70$ffc7af50$@net.au>
	<CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>
	<02b101d0e6c2$47e22030$d7a66090$@net.au>
Message-ID: <CAHjP37HWSp7TowAD8BQVHG8mkATODB3CdFPHP3P+7kh1nZa7gg@mail.gmail.com>

By general I meant "here's the gist of what I'm saying", not general as in
common.  However, I don't think it's that uncommon either.

Are we then going to stipulate different ordering semantics for successful
vs unsuccessful CAS? The dichotomy of these is likely to trip some people
up and may create subtle bugs on archs where there is an actual difference.

sent from my phone
On Sep 3, 2015 11:32 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> I don?t agree that is a general use-case. You can always postulate a need
> for a happens-before edge between two things. I don?t think it is
> reasonable to expect one on a failing tryLock. Any shared state will need
> to be protected by a lock or else volatile ? and those should be what
> establishes the HB edges in my opinion.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Vitaly
> Davidovich
> *Sent:* Friday, September 4, 2015 1:10 PM
> *To:* dholmes at ieee.org
> *Cc:* thurston; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> If thread A releases a lock and threads B and C tryLock it, with one
> succeeding, the failing thread may want to do something else but wants a
> happens-before edge with the lock release - that's the general use case.
> As a simple example, consider two threads tryLock'ing to acquire the
> exclusive right to close a socket and then perform some additional actions
> that require ordering of actions done by the releasing thread.  The thread
> failing to acquire the lock will skip closing the socket but will proceed
> to do some work that requires happens-before edge.  This is typically done
> using CAS, with one thread successfully flipping the state, and the others
> just skip that action that's guarded by the CAS, but can proceed with doing
> subsequent work.  In other words, one may want to piggyback on the
> unlock/tryLock to provide the ordering rather than introducing additional
> dedicated state for this.
>
> sent from my phone
>
> On Sep 3, 2015 7:26 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:
>
> j.u.c also adopts the same principle:
>
>
>
> Actions prior to "releasing" synchronizer methods such as Lock.unlock,
> Semaphore.release, and CountDownLatch.countDown *happen-before* actions
> subsequent to a successful "acquiring" method such as Lock.lock,
> Semaphore.acquire, Condition.await, and CountDownLatch.await on the same
> synchronizer object in another thread.
>
>
>
> Note the use of ?successful? which already indicates tryLock is not
> included here.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Oleksandr
> Otenko
> *Sent:* Friday, September 4, 2015 8:48 AM
> *To:* dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> Sure, lock acquires and releases in JMM don't guarantee ordering until the
> lock is acquired. But also they don't have a tryLock in JMM - as it really
> concerns the synchronized, doesn't it.
>
> Alex
>
> On 03/09/2015 23:34, David Holmes wrote:
>
> Not sure what ?everything? is. If Thread A releases the lock and thread B
> acquires it, then B sees everything that happened in A before the release.
> If thread C now does a tryLock and sees the lock is already owned you are
> suggesting it should see what thread B sees because if it had acquired the
> lock then that would be the case. But it didn?t acquire it, it only sees
> that it is already acquired by another thread. So I don?t see there is any
> transitive relationship that has to be applied here. Implementation wise it
> is likely but in terms of the model I think expectations and requirements
> should be nil.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu
> <concurrency-interest-bounces at cs.oswego.edu>] *On Behalf Of *Oleksandr
> Otenko
> *Sent:* Friday, September 4, 2015 8:18 AM
> *To:* dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> You should at least see everything preceding the lock acquire - since you
> see the lock acquired - and therefore everything preceding the lock release.
>
> Alex
>
> On 03/09/2015 21:57, David Holmes wrote:
>
> tryLock seems a non-issue to me. If you acquire a lock you are guaranteed
> to see all changes made by previous owners of the lock. If you fail to
> acquire the lock then ? you should not be expecting anything.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu
> <concurrency-interest-bounces at cs.oswego.edu>] *On Behalf Of *Oleksandr
> Otenko
> *Sent:* Friday, September 4, 2015 4:19 AM
> *To:* Vitaly Davidovich; thurston
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>
>
> Has anyone come up with the answer about ordering for tryLock, or have I
> missed it?
>
> It seems that tryLock can fail without attempting a CAS, but what
> guarantees are really expected by the code users, and are they in line with
> this assumption.
>
>
> Alex
>
>
> On 22/08/2015 19:15, Vitaly Davidovich wrote:
>
> I would hope there's no ordering difference between successful and
> unsuccessful CAS.  On x86/64 the instruction itself provides full fence
> irrespective of outcome; compiler doesn't know a priori whether it will
> succeed or not.  Are there platforms where the lowering of the CAS has
> different cpu ordering based on outcome? LL/SC can fail if cacheline is
> modified in between (even if value is still the expected one) but I'm not
> aware of that changing ordering semantics.  However, if there are cases
> where this would matter, I hope the JVM ensures the requested ordering
> irrespective of outcome.
>
> Along this line, the more "interesting" and related question is what the
> ordering guarantees are for failed tryLock methods.
>
> sent from my phone
>
> On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:
>
> Thanks for the prompt reply.  I guess I'll operate then from the yes
> perspective.
>
> What are the plans with respect to the "higher-order methods" on e.g.
> AtomicReference, i.e.
>
> T getAndAccumulate(T, BinaryOperator<T>)
> T updateAndGet(UnaryOperator<T>)
> . . .
> etc.
>
>
> Are you going to have:
> T getAndAccumulateVolatilely(T, BinaryOperator<T>)
> T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
> etc versions?
>
>
> That seems like a pollution of the API, IMO (and just awful names).  And
> I'm
> not really sure where it ends.
>
> And then a small javadoc modification suggestion:
> /**
>       * Returns the value, and ensures that subsequent loads and stores
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> I find
> /**
>       * Returns the value, and ensures that subsequent loads and stores
> (*in
> the program order*)
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> to be a little clearer as *subsequent* is an overloaded term when it comes
> to JMM matters.
>
> And one final question that I've always been confused about;  are there
> different "memory ordering effects" between a successful CAS and an
> unsuccessful one (presumably in the latter because no write actually
> occurs)?
> IIRC, when looking at the java 8 JVM code, I believe a fence was inserted
> in
> the successful case, at least on x86/64.  If so, I can take a shot at
> producing some javadoc language to reflect that, if it would be helpful.
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> _______________________________________________
>
> Concurrency-interest mailing list
>
> Concurrency-interest at cs.oswego.edu
>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150903/94a8f605/attachment.html>

From davidcholmes at aapt.net.au  Fri Sep  4 00:10:45 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 4 Sep 2015 14:10:45 +1000
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37HWSp7TowAD8BQVHG8mkATODB3CdFPHP3P+7kh1nZa7gg@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>	<55E88F31.7090107@oracle.com>	<024d01d0e68b$306607a0$913216e0$@net.au>	<55E8C70D.70509@oracle.com>	<026701d0e698$b0102550$10306ff0$@net.au>	<55E8CE29.6030302@oracle.com>	<027e01d0e69f$ffed3a70$ffc7af50$@net.au>	<CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>	<02b101d0e6c2$47e22030$d7a66090$@net.au>
	<CAHjP37HWSp7TowAD8BQVHG8mkATODB3CdFPHP3P+7kh1nZa7gg@mail.gmail.com>
Message-ID: <02cb01d0e6c7$ac767870$05636950$@net.au>

I see your point but I?d consider these at two different levels of abstraction. CAS, as a primitive, is easier to reason with if it has the ordering guarantees even on failure. I can easily imagine CAS-based algorithms that require such guarantees even if the CAS fails. The tryLock however is a higher-level API and I don?t expect, or see the need for, additional guarantees in the failure case.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Vitaly Davidovich
Sent: Friday, September 4, 2015 1:41 PM
To: dholmes at ieee.org
Cc: thurston; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

By general I meant "here's the gist of what I'm saying", not general as in common.  However, I don't think it's that uncommon either.

Are we then going to stipulate different ordering semantics for successful vs unsuccessful CAS? The dichotomy of these is likely to trip some people up and may create subtle bugs on archs where there is an actual difference.

sent from my phone

On Sep 3, 2015 11:32 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

I don?t agree that is a general use-case. You can always postulate a need for a happens-before edge between two things. I don?t think it is reasonable to expect one on a failing tryLock. Any shared state will need to be protected by a lock or else volatile ? and those should be what establishes the HB edges in my opinion.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Vitaly Davidovich
Sent: Friday, September 4, 2015 1:10 PM
To: dholmes at ieee.org
Cc: thurston; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

If thread A releases a lock and threads B and C tryLock it, with one succeeding, the failing thread may want to do something else but wants a happens-before edge with the lock release - that's the general use case.  As a simple example, consider two threads tryLock'ing to acquire the exclusive right to close a socket and then perform some additional actions that require ordering of actions done by the releasing thread.  The thread failing to acquire the lock will skip closing the socket but will proceed to do some work that requires happens-before edge.  This is typically done using CAS, with one thread successfully flipping the state, and the others just skip that action that's guarded by the CAS, but can proceed with doing subsequent work.  In other words, one may want to piggyback on the unlock/tryLock to provide the ordering rather than introducing additional dedicated state for this.

sent from my phone

On Sep 3, 2015 7:26 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

j.u.c also adopts the same principle:

 

Actions prior to "releasing" synchronizer methods such as Lock.unlock, Semaphore.release, and CountDownLatch.countDown happen-before actions subsequent to a successful "acquiring" method such as Lock.lock, Semaphore.acquire, Condition.await, and CountDownLatch.await on the same synchronizer object in another thread.

 

Note the use of ?successful? which already indicates tryLock is not included here.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Friday, September 4, 2015 8:48 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Sure, lock acquires and releases in JMM don't guarantee ordering until the lock is acquired. But also they don't have a tryLock in JMM - as it really concerns the synchronized, doesn't it.

Alex

On 03/09/2015 23:34, David Holmes wrote:

Not sure what ?everything? is. If Thread A releases the lock and thread B acquires it, then B sees everything that happened in A before the release. If thread C now does a tryLock and sees the lock is already owned you are suggesting it should see what thread B sees because if it had acquired the lock then that would be the case. But it didn?t acquire it, it only sees that it is already acquired by another thread. So I don?t see there is any transitive relationship that has to be applied here. Implementation wise it is likely but in terms of the model I think expectations and requirements should be nil.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Friday, September 4, 2015 8:18 AM
To: dholmes at ieee.org; 'Vitaly Davidovich'; 'thurston'
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

You should at least see everything preceding the lock acquire - since you see the lock acquired - and therefore everything preceding the lock release.

Alex

On 03/09/2015 21:57, David Holmes wrote:

tryLock seems a non-issue to me. If you acquire a lock you are guaranteed to see all changes made by previous owners of the lock. If you fail to acquire the lock then ? you should not be expecting anything.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Friday, September 4, 2015 4:19 AM
To: Vitaly Davidovich; thurston
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] jdk9 VarHandle and Fence methods

 

Has anyone come up with the answer about ordering for tryLock, or have I missed it?

It seems that tryLock can fail without attempting a CAS, but what guarantees are really expected by the code users, and are they in line with this assumption.


Alex



On 22/08/2015 19:15, Vitaly Davidovich wrote:

I would hope there's no ordering difference between successful and unsuccessful CAS.  On x86/64 the instruction itself provides full fence irrespective of outcome; compiler doesn't know a priori whether it will succeed or not.  Are there platforms where the lowering of the CAS has different cpu ordering based on outcome? LL/SC can fail if cacheline is modified in between (even if value is still the expected one) but I'm not aware of that changing ordering semantics.  However, if there are cases where this would matter, I hope the JVM ensures the requested ordering irrespective of outcome.

Along this line, the more "interesting" and related question is what the ordering guarantees are for failed tryLock methods.

sent from my phone

On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

Thanks for the prompt reply.  I guess I'll operate then from the yes
perspective.

What are the plans with respect to the "higher-order methods" on e.g.
AtomicReference, i.e.

T getAndAccumulate(T, BinaryOperator<T>)
T updateAndGet(UnaryOperator<T>)
. . .
etc.


Are you going to have:
T getAndAccumulateVolatilely(T, BinaryOperator<T>)
T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
etc versions?


That seems like a pollution of the API, IMO (and just awful names).  And I'm
not really sure where it ends.

And then a small javadoc modification suggestion:
/**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

I find
/**
      * Returns the value, and ensures that subsequent loads and stores (*in
the program order*)
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

to be a little clearer as *subsequent* is an overloaded term when it comes
to JMM matters.

And one final question that I've always been confused about;  are there
different "memory ordering effects" between a successful CAS and an
unsuccessful one (presumably in the latter because no write actually
occurs)?
IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
the successful case, at least on x86/64.  If so, I can take a shot at
producing some javadoc language to reflect that, if it would be helpful.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/89de0bfd/attachment-0001.html>

From timo.kinnunen at gmail.com  Fri Sep  4 00:27:21 2015
From: timo.kinnunen at gmail.com (timo.kinnunen at gmail.com)
Date: Fri, 4 Sep 2015 06:27:21 +0200
Subject: [concurrency-interest] Transformation of multiple volatile reads
 without intervening writes
Message-ID: <55e91dac.c21db50a.86fb8.7896@mx.google.com>

Hi, 

Hopefully an easy question about permitted transformations. 

Initially, q.a == q, q.x == 0, p == q and npe == null. Variables p and q.a are volatile. Thread 1 is reading and threads 2 and 3 could interfere with this with their writes.

The code for thread 1 is:
	public static void thread1() {
		REG r1 = p;
		if(r1 == null) return;
		REG r2 = p;
		if(r2 == null) throw npe;
		REG r3 = r2.a;
		if(r3 == null) return;
		REG r4 = p;
		if(r4 == null) throw npe;
		REG r5 = r4.a;
		if(r5 == null) throw npe;
		r5.x = 1;
	}
The code for threads 2 and 3 is:
	public static void thread2() {
		REG r6 = q;
		r6.a = null;
		r6.a = r6;
	}
	public static void thread3() {
		REG r7 = q;
		p = null;
		p = r7;
	}

Is a compiler permitted to transform thread 1?s code to this:
	public static void thread1b() {
		REG r4 = p;
		if(r4 == null) return;
		REG r5 = r4.a;
		if(r5 == null) return;
		r5.x = 1;
	}

Because the volatile reads r1,r2,r4 do not synchronize-with reads r3,r5 or each other r2,r4 could be grouped next to r1. Reads r1 and r2 then become unnecessary synchronization that the compiler can optimize away, along with some now dead code. The compiler repeats this same optimization with r5, which gives the final transformed code. 

Would this be a valid compiler transformation according to the JMM?



Sent from Mail for Windows 10
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/4d18c636/attachment.html>

From aph at redhat.com  Fri Sep  4 04:40:25 2015
From: aph at redhat.com (Andrew Haley)
Date: Fri, 4 Sep 2015 09:40:25 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <02cb01d0e6c7$ac767870$05636950$@net.au>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <024d01d0e68b$306607a0$913216e0$@net.au>
	<55E8C70D.70509@oracle.com> <026701d0e698$b0102550$10306ff0$@net.au>
	<55E8CE29.6030302@oracle.com> <027e01d0e69f$ffed3a70$ffc7af50$@net.au>
	<CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>
	<02b101d0e6c2$47e22030$d7a66090$@net.au>
	<CAHjP37HWSp7TowAD8BQVHG8mkATODB3CdFPHP3P+7kh1nZa7gg@mail.gmail.com>
	<02cb01d0e6c7$ac767870$05636950$@net.au>
Message-ID: <55E958F9.9020300@redhat.com>

On 09/04/2015 05:10 AM, David Holmes wrote:

> I see your point but I?d consider these at two different levels of
> abstraction. CAS, as a primitive, is easier to reason with if it has
> the ordering guarantees even on failure. I can easily imagine
> CAS-based algorithms that require such guarantees even if the CAS
> fails.

In which case it makes sense to insert them explicitly.  There's no
reason not to follow a CAS with a full fence if one is really needed
on failure.  That will make the code easier to read.

It's trivial to take out the trailing fence in the JIT if some
hardware does a full fence on a failed CAS.

Andrew.

From oleksandr.otenko at oracle.com  Fri Sep  4 05:12:05 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 4 Sep 2015 10:12:05 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <02b101d0e6c2$47e22030$d7a66090$@net.au>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <024d01d0e68b$306607a0$913216e0$@net.au>
	<55E8C70D.70509@oracle.com> <026701d0e698$b0102550$10306ff0$@net.au>
	<55E8CE29.6030302@oracle.com> <027e01d0e69f$ffed3a70$ffc7af50$@net.au>
	<CAHjP37HmX9xPkNUacqy1cFUHAEnyn=a9D8zVpNfC8iQ9CwS8Hw@mail.gmail.com>
	<02b101d0e6c2$47e22030$d7a66090$@net.au>
Message-ID: <55E96065.1030705@oracle.com>

At least you will have HB edges that preclude certain ordering.

I may still use volatiles to share my data, but use a failing tryLock to 
prove it shall be visible to anyone who releases the lock - because 
that's a reasonable thing to assume that the volatile reads following 
the release will be ordered strictly after the failing tryLock in the 
total synchronization order. Even though there is no synchronizes-with 
edge between the lock release and the failing tryLock, tryLock cannot be 
placed after the lock release, and, therefore, all subsequent volatile 
reads are also after the volatile writes preceding the failing tryLock, 
thus they are bound to synchronize-with. This, you see, still requires 
the specification how a failing tryLock is ordered with respect to 
acquires and releases. The fact that it is not specified is exactly the 
reason to bring this up.

Alex

On 04/09/2015 04:32, David Holmes wrote:
>
> I don?t agree that is a general use-case. You can always postulate a 
> need for a happens-before edge between two things. I don?t think it is 
> reasonable to expect one on a failing tryLock. Any shared state will 
> need to be protected by a lock or else volatile ? and those should be 
> what establishes the HB edges in my opinion.
>
> David
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
> *Vitaly Davidovich
> *Sent:* Friday, September 4, 2015 1:10 PM
> *To:* dholmes at ieee.org
> *Cc:* thurston; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
> If thread A releases a lock and threads B and C tryLock it, with one 
> succeeding, the failing thread may want to do something else but wants 
> a happens-before edge with the lock release - that's the general use 
> case.  As a simple example, consider two threads tryLock'ing to 
> acquire the exclusive right to close a socket and then perform some 
> additional actions that require ordering of actions done by the 
> releasing thread.  The thread failing to acquire the lock will skip 
> closing the socket but will proceed to do some work that requires 
> happens-before edge.  This is typically done using CAS, with one 
> thread successfully flipping the state, and the others just skip that 
> action that's guarded by the CAS, but can proceed with doing 
> subsequent work.  In other words, one may want to piggyback on the 
> unlock/tryLock to provide the ordering rather than introducing 
> additional dedicated state for this.
>
> sent from my phone
>
> On Sep 3, 2015 7:26 PM, "David Holmes" <davidcholmes at aapt.net.au 
> <mailto:davidcholmes at aapt.net.au>> wrote:
>
> j.u.c also adopts the same principle:
>
> Actions prior to "releasing" synchronizer methods such as 
> |Lock.unlock|, |Semaphore.release|, and |CountDownLatch.countDown| 
> /happen-before/ actions subsequent to a successful "acquiring" method 
> such as |Lock.lock|, |Semaphore.acquire|, |Condition.await|, and 
> |CountDownLatch.await| on the same synchronizer object in another thread.
>
> Note the use of ?successful? which already indicates tryLock is not 
> included here.
>
> David
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> <mailto:concurrency-interest-bounces at cs.oswego.edu> 
> [mailto:concurrency-interest-bounces at cs.oswego.edu 
> <mailto:concurrency-interest-bounces at cs.oswego.edu>] *On Behalf Of 
> *Oleksandr Otenko
> *Sent:* Friday, September 4, 2015 8:48 AM
> *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>; 'Vitaly Davidovich'; 
> 'thurston'
> *Cc:* concurrency-interest at cs.oswego.edu 
> <mailto:concurrency-interest at cs.oswego.edu>
> *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
> Sure, lock acquires and releases in JMM don't guarantee ordering until 
> the lock is acquired. But also they don't have a tryLock in JMM - as 
> it really concerns the synchronized, doesn't it.
>
> Alex
>
> On 03/09/2015 23:34, David Holmes wrote:
>
>     Not sure what ?everything? is. If Thread A releases the lock and
>     thread B acquires it, then B sees everything that happened in A
>     before the release. If thread C now does a tryLock and sees the
>     lock is already owned you are suggesting it should see what thread
>     B sees because if it had acquired the lock then that would be the
>     case. But it didn?t acquire it, it only sees that it is already
>     acquired by another thread. So I don?t see there is any transitive
>     relationship that has to be applied here. Implementation wise it
>     is likely but in terms of the model I think expectations and
>     requirements should be nil.
>
>     David
>
>     *From:*concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of
>     *Oleksandr Otenko
>     *Sent:* Friday, September 4, 2015 8:18 AM
>     *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>; 'Vitaly
>     Davidovich'; 'thurston'
>     *Cc:* concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence methods
>
>     You should at least see everything preceding the lock acquire -
>     since you see the lock acquired - and therefore everything
>     preceding the lock release.
>
>     Alex
>
>     On 03/09/2015 21:57, David Holmes wrote:
>
>         tryLock seems a non-issue to me. If you acquire a lock you are
>         guaranteed to see all changes made by previous owners of the
>         lock. If you fail to acquire the lock then ? you should not be
>         expecting anything.
>
>         David
>
>         *From:*concurrency-interest-bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>         [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf
>         Of *Oleksandr Otenko
>         *Sent:* Friday, September 4, 2015 4:19 AM
>         *To:* Vitaly Davidovich; thurston
>         *Cc:* concurrency-interest at cs.oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>
>         *Subject:* Re: [concurrency-interest] jdk9 VarHandle and Fence
>         methods
>
>         Has anyone come up with the answer about ordering for tryLock,
>         or have I missed it?
>
>         It seems that tryLock can fail without attempting a CAS, but
>         what guarantees are really expected by the code users, and are
>         they in line with this assumption.
>
>
>         Alex
>
>
>         On 22/08/2015 19:15, Vitaly Davidovich wrote:
>
>             I would hope there's no ordering difference between
>             successful and unsuccessful CAS.  On x86/64 the
>             instruction itself provides full fence irrespective of
>             outcome; compiler doesn't know a priori whether it will
>             succeed or not.  Are there platforms where the lowering of
>             the CAS has different cpu ordering based on outcome? LL/SC
>             can fail if cacheline is modified in between (even if
>             value is still the expected one) but I'm not aware of that
>             changing ordering semantics.  However, if there are cases
>             where this would matter, I hope the JVM ensures the
>             requested ordering irrespective of outcome.
>
>             Along this line, the more "interesting" and related
>             question is what the ordering guarantees are for failed
>             tryLock methods.
>
>             sent from my phone
>
>             On Aug 22, 2015 1:41 PM, "thurstonn"
>             <thurston at nomagicsoftware.com
>             <mailto:thurston at nomagicsoftware.com>> wrote:
>
>             Thanks for the prompt reply.  I guess I'll operate then
>             from the yes
>             perspective.
>
>             What are the plans with respect to the "higher-order
>             methods" on e.g.
>             AtomicReference, i.e.
>
>             T getAndAccumulate(T, BinaryOperator<T>)
>             T updateAndGet(UnaryOperator<T>)
>             . . .
>             etc.
>
>
>             Are you going to have:
>             T getAndAccumulateVolatilely(T, BinaryOperator<T>)
>             T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
>             etc versions?
>
>
>             That seems like a pollution of the API, IMO (and just
>             awful names).  And I'm
>             not really sure where it ends.
>
>             And then a small javadoc modification suggestion:
>             /**
>                   * Returns the value, and ensures that subsequent
>             loads and stores
>                   * are not reordered before this access.
>                   *
>                   * @apiNote Ignoring the many semantic differences
>             from C and
>                   * C++, this method has memory ordering effects
>             compatible with
>                   * memory_order_acquire ordering.
>                   *
>                   * @return the value
>                   */
>                  T getAcquire(Object owner);
>
>             I find
>             /**
>                   * Returns the value, and ensures that subsequent
>             loads and stores (*in
>             the program order*)
>                   * are not reordered before this access.
>                   *
>                   * @apiNote Ignoring the many semantic differences
>             from C and
>                   * C++, this method has memory ordering effects
>             compatible with
>                   * memory_order_acquire ordering.
>                   *
>                   * @return the value
>                   */
>                  T getAcquire(Object owner);
>
>             to be a little clearer as *subsequent* is an overloaded
>             term when it comes
>             to JMM matters.
>
>             And one final question that I've always been confused
>             about;  are there
>             different "memory ordering effects" between a successful
>             CAS and an
>             unsuccessful one (presumably in the latter because no
>             write actually
>             occurs)?
>             IIRC, when looking at the java 8 JVM code, I believe a
>             fence was inserted in
>             the successful case, at least on x86/64.  If so, I can
>             take a shot at
>             producing some javadoc language to reflect that, if it
>             would be helpful.
>
>
>
>             --
>             View this message in context:
>             http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
>             Sent from the JSR166 Concurrency mailing list archive at
>             Nabble.com.
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>             _______________________________________________
>
>             Concurrency-interest mailing list
>
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/d8d0d32a/attachment-0001.html>

From dl at cs.oswego.edu  Fri Sep  4 07:18:29 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 4 Sep 2015 07:18:29 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55E88F31.7090107@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com>
Message-ID: <55E97E05.6040700@cs.oswego.edu>

On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
> Has anyone come up with the answer about ordering for tryLock, or have I missed it?

You missed the dog not barking :-)

The Lock specs don't require any specific HB effects here on failed
tryLock. Even if we wanted to, we cannot retroactively impose any
considering that anyone can implement the Lock interface (not just j.u.c)
and some of these might become in violation.

As you and Vitaly pointed out, there are a few fringe cases where
users might want to impose ordering on failure. In jdk9, you'll
me able to do this with moded VarHandle accesses and/or fences. The
resulting extra fencing might be redundant here and there, but if you
cared enough, you could create and rely on custom locks with stronger
guarantees.

-Doug


From nathan.reynolds at oracle.com  Fri Sep  4 13:06:04 2015
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 4 Sep 2015 10:06:04 -0700
Subject: [concurrency-interest] Transformation of multiple volatile
 reads without intervening writes
In-Reply-To: <55e91dac.c21db50a.86fb8.7896@mx.google.com>
References: <55e91dac.c21db50a.86fb8.7896@mx.google.com>
Message-ID: <55E9CF7C.3000907@oracle.com>

Maybe everyone is still chewing on this.  One way to show if the 
compiler can transform the code is by running it and looking at the 
disassembly.  If the disassembly shows the transformation, then it is 
proven.  If not, then you may have to tweak the code until you figure 
out which line of code is preventing the compiler from doing the 
transformation.

-Nathan

On 9/3/2015 9:27 PM, timo.kinnunen at gmail.com wrote:
>
> Hi,
>
> Hopefully an easy question about permitted transformations.
>
> Initially, q.a == q, q.x == 0, p == q and npe == null. Variables p and 
> q.a are volatile. Thread 1 is reading and threads 2 and 3 could 
> interfere with this with their writes.
>
> The code for thread 1 is:
>
>                 public static void thread1() {
>
>                                 REG r1 = p;
>
>                                 if(r1 == null) return;
>
>                                 REG r2 = p;
>
>                                 if(r2 == null) throw npe;
>
>                                 REG r3 = r2.a;
>
>                                 if(r3 == null) return;
>
>                                 REG r4 = p;
>
>                                 if(r4 == null) throw npe;
>
>                                 REG r5 = r4.a;
>
>                                 if(r5 == null) throw npe;
>
>                                 r5.x = 1;
>
>                 }
>
> The code for threads 2 and 3 is:
>
>                 public static void thread2() {
>
>                                 REG r6 = q;
>
>                                 r6.a = null;
>
>                                 r6.a = r6;
>
>                 }
>
>                 public static void thread3() {
>
>                                 REG r7 = q;
>
>                                 p = null;
>
>                                 p = r7;
>
>                 }
>
> Is a compiler permitted to transform thread 1?s code to this:
>
>                 public static void thread1b() {
>
>                                 REG r4 = p;
>
>                                 if(r4 == null) return;
>
>                                 REG r5 = r4.a;
>
>                                 if(r5 == null) return;
>
>                                 r5.x = 1;
>
>                 }
>
> Because the volatile reads r1,r2,r4 do not synchronize-with reads 
> r3,r5 or each other r2,r4 could be grouped next to r1. Reads r1 and r2 
> then become unnecessary synchronization that the compiler can optimize 
> away, along with some now dead code. The compiler repeats this same 
> optimization with r5, which gives the final transformed code.
>
> Would this be a valid compiler transformation according to the JMM?
>
> Sent from Mail <http://go.microsoft.com/fwlink/?LinkId=550986> for 
> Windows 10
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/9e2956d9/attachment.html>

From boehm at acm.org  Fri Sep  4 17:54:34 2015
From: boehm at acm.org (Hans Boehm)
Date: Fri, 4 Sep 2015 14:54:34 -0700
Subject: [concurrency-interest] Transformation of multiple volatile
 reads without intervening writes
In-Reply-To: <55e91dac.c21db50a.86fb8.7896@mx.google.com>
References: <55e91dac.c21db50a.86fb8.7896@mx.google.com>
Message-ID: <CAPUmR1YOj5Q59DajaWQ+WQS_EdRVr3ZP+V9xu_ChZs8YU8fE+Q@mail.gmail.com>

Are you asking about transforming thread1() in isolation?  Or as part of a
whole program transformation?

I think the answer to the former is no.  Assume p starts out not null, p.a
starts out null, p changes to null, and then p.a changes to not null.  If
the original code doesn't return prematurely, it must throw an npe, because
p must be null the third time it's read.  The transformed code will return
successfully in this case.

The first redundant read of p can safely be eliminated.  The second cannot.

I'm not sure the answer to the second question is interesting.

On Thu, Sep 3, 2015 at 9:27 PM, <timo.kinnunen at gmail.com> wrote:

> Hi,
>
>
>
> Hopefully an easy question about permitted transformations.
>
>
>
> Initially, q.a == q, q.x == 0, p == q and npe == null. Variables p and q.a
> are volatile. Thread 1 is reading and threads 2 and 3 could interfere with
> this with their writes.
>
>
>
> The code for thread 1 is:
>
>                 public static void thread1() {
>
>                                 REG r1 = p;
>
>                                 if(r1 == null) return;
>
>                                 REG r2 = p;
>
>                                 if(r2 == null) throw npe;
>
>                                 REG r3 = r2.a;
>
>                                 if(r3 == null) return;
>
>                                 REG r4 = p;
>
>                                 if(r4 == null) throw npe;
>
>                                 REG r5 = r4.a;
>
>                                 if(r5 == null) throw npe;
>
>                                 r5.x = 1;
>
>                 }
>
> The code for threads 2 and 3 is:
>
>                 public static void thread2() {
>
>                                 REG r6 = q;
>
>                                 r6.a = null;
>
>                                 r6.a = r6;
>
>                 }
>
>                 public static void thread3() {
>
>                                 REG r7 = q;
>
>                                 p = null;
>
>                                 p = r7;
>
>                 }
>
>
>
> Is a compiler permitted to transform thread 1?s code to this:
>
>                 public static void thread1b() {
>
>                                 REG r4 = p;
>
>                                 if(r4 == null) return;
>
>                                 REG r5 = r4.a;
>
>                                 if(r5 == null) return;
>
>                                 r5.x = 1;
>
>                 }
>
>
>
> Because the volatile reads r1,r2,r4 do not synchronize-with reads r3,r5 or
> each other r2,r4 could be grouped next to r1. Reads r1 and r2 then become
> unnecessary synchronization that the compiler can optimize away, along with
> some now dead code. The compiler repeats this same optimization with r5,
> which gives the final transformed code.
>
>
>
> Would this be a valid compiler transformation according to the JMM?
>
>
>
>
>
>
>
> Sent from Mail <http://go.microsoft.com/fwlink/?LinkId=550986> for
> Windows 10
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150904/533e4890/attachment.html>

From timo.kinnunen at gmail.com  Fri Sep  4 23:45:15 2015
From: timo.kinnunen at gmail.com (timo.kinnunen at gmail.com)
Date: Sat, 5 Sep 2015 05:45:15 +0200
Subject: [concurrency-interest] Transformation of multiple volatile
 readswithout intervening writes
In-Reply-To: <CAPUmR1YOj5Q59DajaWQ+WQS_EdRVr3ZP+V9xu_ChZs8YU8fE+Q@mail.gmail.com>
References: <55e91dac.c21db50a.86fb8.7896@mx.google.com>
	<CAPUmR1YOj5Q59DajaWQ+WQS_EdRVr3ZP+V9xu_ChZs8YU8fE+Q@mail.gmail.com>
Message-ID: <55ea654f.0867b40a.d55bf.14c4@mx.google.com>

To provide some additional background information, I had found a test class named CoherenceVolatile.java here http://www.cs.umd.edu/~pugh/java/memoryModel/index.html and tested out some optimizations that I might do, if I was a compiler. Please have look. 

These are the transformations that I tested (briefly, pp==qq and pp.x is volatile):

			if(OPTIMIZED_VERSION_3) {
				j = qq.x;
				i = k = m = pp.x;
			} else if(OPTIMIZED_VERSION_2) {
				i = pp.x;
				j = qq.x;
				k = pp.x;
				i = k = m = pp.x;
			} else if(OPTIMIZED_VERSION_1) {
				do {
					i = pp.x;
					j = qq.x;
					k = pp.x;
					m = pp.x;
				} while(i != m || k != m);
			} else /* ORIGINAL_VERSION */ {
				i = pp.x;
				j = qq.x;
				k = pp.x;
				m = pp.x;
			}

On my machine all of these transformations produced executions that JMM permitted to the original version. As far as the test class could detect anyway. 

The comment in the file says ?all volatile reads and writes should have sequentially consistent semantics as viewed by any two threads?. Also that ?once a thread sees a volatile write to a variable by another thread, it cannot forget that it has seen the write.? As a corollary, after a thread has seen a write to a volatile variable it should forget old stale values it may have seen from earlier writes to that variable. After all, in Java volatile is supposed to be a tool for synchronization, rather than sampling.




Sent from Mail for Windows 10



From: Hans Boehm
Sent: Friday, September 4, 2015 23:54
To: timo.kinnunen at gmail.com
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Transformation of multiple volatile readswithout intervening writes


Are you asking about transforming thread1() in isolation?? Or as part of a whole program transformation?

I think the answer to the former is no.? Assume p starts out not null, p.a starts out null, p changes to null, and then p.a changes to not null.? If the original code doesn't return prematurely, it must throw an npe, because p must be null the third time it's read.? The transformed code will return successfully in this case.

The first redundant read of p can safely be eliminated.? The second cannot.

I'm not sure the answer to the second question is interesting.

On Thu, Sep 3, 2015 at 9:27 PM, <timo.kinnunen at gmail.com> wrote:
Hi, 
?
Hopefully an easy question about permitted transformations. 
?
Initially, q.a == q, q.x == 0, p == q and npe == null. Variables p and q.a are volatile. Thread 1 is reading and threads 2 and 3 could interfere with this with their writes.
?
The code for thread 1 is:
??????????????? public static void thread1() {
??????????????????????????????? REG r1 = p;
??????????????????????????????? if(r1 == null) return;
??????????????????????????????? REG r2 = p;
??????????????????????????????? if(r2 == null) throw npe;
??????????????????????????????? REG r3 = r2.a;
??????????????????????????????? if(r3 == null) return;
??????????????????????????????? REG r4 = p;
??????????????????????????????? if(r4 == null) throw npe;
??????????????????????????????? REG r5 = r4.a;
??????????????????????????????? if(r5 == null) throw npe;
??????????????????????????????? r5.x = 1;
??????????????? }
The code for threads 2 and 3 is:
??????????????? public static void thread2() {
??????????????????????????????? REG r6 = q;
??????????????????????????????? r6.a = null;
??????????????????????????????? r6.a = r6;
??????????????? }
??????????????? public static void thread3() {
??????????????????????????????? REG r7 = q;
??????????????????????????????? p = null;
??????????????????????????????? p = r7;
??????????????? }
?
Is a compiler permitted to transform thread 1?s code to this:
??????????????? public static void thread1b() {
??????????????????????????????? REG r4 = p;
??????????????????????????????? if(r4 == null) return;
??????????????????????????????? REG r5 = r4.a;
??????????????????????????????? if(r5 == null) return;
??????????????????????????????? r5.x = 1;
??????????????? }
?
Because the volatile reads r1,r2,r4 do not synchronize-with reads r3,r5 or each other r2,r4 could be grouped next to r1. Reads r1 and r2 then become unnecessary synchronization that the compiler can optimize away, along with some now dead code. The compiler repeats this same optimization with r5, which gives the final transformed code. 
?
Would this be a valid compiler transformation according to the JMM?
?
?
?
Sent from Mail for Windows 10

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150905/957eed35/attachment-0001.html>

From pjulien at gmail.com  Sat Sep  5 07:41:39 2015
From: pjulien at gmail.com (Patrick Julien)
Date: Sat, 5 Sep 2015 07:41:39 -0400
Subject: [concurrency-interest] AtomicLong vs AtomicLongFieldUpdater
	addAngGet
Message-ID: <CAA+0EBz+fV0U1f+Aizc+rHPf63wBSDpub9C6q8Z3hjWQM1MZ9Q@mail.gmail.com>

In Java 8, AtomicLong and AtomicInteger were modified to use the new
unsafe operations, e.g.,

public final long addAndGet(long delta) {
    return unsafe.getAndAddLong(this, valueOffset, delta) + delta;
}

but not the field updater variants which still do a compare and set

public long addAndGet(T obj, long delta) {
    long prev, next;
    do {
        prev = get(obj);
        next = prev + delta;
    } while (!compareAndSet(obj, prev, next));
    return next;
}

Is there any reason for this or is it just an omission?

From dl at cs.oswego.edu  Sat Sep  5 11:37:20 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 5 Sep 2015 11:37:20 -0400
Subject: [concurrency-interest] AtomicLong vs AtomicLongFieldUpdater
 addAngGet
In-Reply-To: <CAA+0EBz+fV0U1f+Aizc+rHPf63wBSDpub9C6q8Z3hjWQM1MZ9Q@mail.gmail.com>
References: <CAA+0EBz+fV0U1f+Aizc+rHPf63wBSDpub9C6q8Z3hjWQM1MZ9Q@mail.gmail.com>
Message-ID: <55EB0C30.2080205@cs.oswego.edu>

On 09/05/2015 07:41 AM, Patrick Julien wrote:
> In Java 8, AtomicLong and AtomicInteger were modified to use the new
> unsafe operations, e.g.,
>
> public final long addAndGet(long delta) {
>      return unsafe.getAndAddLong(this, valueOffset, delta) + delta;
> }
>
> but not the field updater variants which still do a compare and set
>
> Is there any reason for this or is it just an omission?
>

In retrospect it is an omission. There was initially
an internal snag preventing these, but it disappeared.
We should/will correct this when reconciling with Varhandles
for jdk9.

-Doug




From timo.kinnunen at gmail.com  Sun Sep  6 21:09:12 2015
From: timo.kinnunen at gmail.com (timo.kinnunen at gmail.com)
Date: Mon, 7 Sep 2015 03:09:12 +0200
Subject: [concurrency-interest] Transformation of multiple volatile
 readswithout intervening writes
In-Reply-To: <CAPUmR1YOj5Q59DajaWQ+WQS_EdRVr3ZP+V9xu_ChZs8YU8fE+Q@mail.gmail.com>
References: <55e91dac.c21db50a.86fb8.7896@mx.google.com>
	<CAPUmR1YOj5Q59DajaWQ+WQS_EdRVr3ZP+V9xu_ChZs8YU8fE+Q@mail.gmail.com>
Message-ID: <55ece3bd.c709c20a.a97e2.ffffeaeb@mx.google.com>

Thanks, I?ve re-read about sequential consistency of volatile operations couple of times and I think I got it. First I?ll get rid of the redundant read because it makes the rest significantly more straightforward. So, reorder to get this:

	public static void thread1() {
		REG r1 = p;
		REG r2 = p;
		if(r1 == null) return;
		if(r2 == null) throw npe;
		// rest //
	}
Assign r1 to r2, inline r2, remove dead throw, rename r1 to r2 to remain consistent:

	public static void thread1a() {
		REG r2 = p;    if(r2 == null) return;
		REG r3 = r2.a; if(r3 == null) return;
		REG r4 = p;    if(r4 == null) throw npe;
		REG r5 = r4.a; if(r5 == null) throw npe;
		r5.x = 1; 
	}

If thread1a returns successfully, then for all such executions, a thread1b which follows the same synchronization order and performs the same actions as thread1a also returns successfully:

	public static void thread1b() {
		REG r2 = p;    if(r2 == null) throw npe;
		REG r3 = r2.a; if(r3 == null) throw npe;
		REG r4 = p;    if(r4 == null) return;
		REG r5 = r4.a; if(r5 == null) return;
		r5.x = 1; 
	}

Otherwise, if thread1a throws, then for all such executions thread1b performs identically except it returns normally instead. 

In both cases, a thread2 executing the same synchronization actions in the same order as thread1b starting from r4 executes identically to thread1b regardless of the synchronization actions prior to r4:

	public static void thread2() {
		REG r4 = p;    if(r4 == null) return;
		REG r5 = r4.a; if(r5 == null) return;
		r5.x = 1; 
	}

Otherwise thread1a must return early. For all such executions thread2 performs identically in thread1a?s place. 

To summarize, if the original version executes without throwing then the optimized version can perform the same actions in same order without the ruse being discovered. If there is a throw then either the original thread1a is executing or the transformed thread1b is executing. Only if the thread2 completes successfully in your example case does it prove that the optimization has been done, but thread2 could have also returned normally, and so could have the original thread too. 

I don?t know if this would disqualify the transformation as such. The threads still stop their reading when they see nulls, but whether the compiler should favor custom checks against nulls or the NPEs generated by some compiler seems like it wouldn?t fall under the JMM.




Sent from Mail for Windows 10



From: Hans Boehm
Sent: Friday, September 4, 2015 23:54
To: timo.kinnunen at gmail.com
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Transformation of multiple volatile readswithout intervening writes


Are you asking about transforming thread1() in isolation?? Or as part of a whole program transformation?

I think the answer to the former is no.? Assume p starts out not null, p.a starts out null, p changes to null, and then p.a changes to not null.? If the original code doesn't return prematurely, it must throw an npe, because p must be null the third time it's read.? The transformed code will return successfully in this case.

The first redundant read of p can safely be eliminated.? The second cannot.

I'm not sure the answer to the second question is interesting.

On Thu, Sep 3, 2015 at 9:27 PM, <timo.kinnunen at gmail.com> wrote:
Hi, 
?
Hopefully an easy question about permitted transformations. 
?
Initially, q.a == q, q.x == 0, p == q and npe == null. Variables p and q.a are volatile. Thread 1 is reading and threads 2 and 3 could interfere with this with their writes.
?
The code for thread 1 is:
??????????????? public static void thread1() {
??????????????????????????????? REG r1 = p;
??????????????????????????????? if(r1 == null) return;
??????????????????????????????? REG r2 = p;
??????????????????????????????? if(r2 == null) throw npe;
??????????????????????????????? REG r3 = r2.a;
??????????????????????????????? if(r3 == null) return;
??????????????????????????????? REG r4 = p;
??????????????????????????????? if(r4 == null) throw npe;
??????????????????????????????? REG r5 = r4.a;
??????????????????????????????? if(r5 == null) throw npe;
??????????????????????????????? r5.x = 1;
??????????????? }
The code for threads 2 and 3 is:
??????????????? public static void thread2() {
??????????????????????????????? REG r6 = q;
??????????????????????????????? r6.a = null;
??????????????????????????????? r6.a = r6;
??????????????? }
??????????????? public static void thread3() {
??????????????????????????????? REG r7 = q;
??????????????????????????????? p = null;
??????????????????????????????? p = r7;
??????????????? }
?
Is a compiler permitted to transform thread 1?s code to this:
??????????????? public static void thread1b() {
??????????????????????????????? REG r4 = p;
??????????????????????????????? if(r4 == null) return;
??????????????????????????????? REG r5 = r4.a;
??????????????????????????????? if(r5 == null) return;
??????????????????????????????? r5.x = 1;
??????????????? }
?
Because the volatile reads r1,r2,r4 do not synchronize-with reads r3,r5 or each other r2,r4 could be grouped next to r1. Reads r1 and r2 then become unnecessary synchronization that the compiler can optimize away, along with some now dead code. The compiler repeats this same optimization with r5, which gives the final transformed code. 
?
Would this be a valid compiler transformation according to the JMM?
?
?
?
Sent from Mail for Windows 10

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150907/8d9c5cb8/attachment-0001.html>

From csaroff at oswego.edu  Mon Sep  7 21:34:46 2015
From: csaroff at oswego.edu (csaroff at oswego.edu)
Date: Tue, 8 Sep 2015 03:34:46 +0200
Subject: [concurrency-interest] Fw: important
Message-ID: <ae0013005d42fe03.80ae059a799377d2@oswego.edu>

Hello!

 

Important message, visit http://lifequotescollection.com/world.php?n9iy

 

csaroff at oswego.edu

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150908/a9e5431d/attachment.html>

From ilya at volvovski.com  Mon Sep  7 22:56:05 2015
From: ilya at volvovski.com (Ilya Volvovski)
Date: Mon, 7 Sep 2015 21:56:05 -0500
Subject: [concurrency-interest] B
Message-ID: <091041F0-5EE7-4728-945F-05AAAFEC9CA0@volvovski.com>



Sent from my iPhone

From thurston at nomagicsoftware.com  Tue Sep  8 05:12:45 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Tue, 8 Sep 2015 02:12:45 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
	<37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>
Message-ID: <1441703565844-12729.post@n7.nabble.com>

Thanks for the straightforward response.

On another matter, in the link you provided it looks like
Unsafe#getAndSetObject (XCHG) is now going to be intrinsified?  Is that
correct?



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12729.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From paul.sandoz at oracle.com  Thu Sep 10 11:14:00 2015
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Thu, 10 Sep 2015 17:14:00 +0200
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1441703565844-12729.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
	<37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>
	<1441703565844-12729.post@n7.nabble.com>
Message-ID: <3367B1F0-E743-40DE-90F5-3FF99D10687A@oracle.com>


On 8 Sep 2015, at 11:12, thurstonn <thurston at nomagicsoftware.com> wrote:

> Thanks for the straightforward response.
> 
> On another matter, in the link you provided it looks like
> Unsafe#getAndSetObject (XCHG) is now going to be intrinsified?  Is that
> correct?

It is already intrinsified (you may notice in recent code such intrinsic methods are annotated with @HotSpotIntrinsicCandidate).

We have yet to make intrinsic support for compareAndExchange{Volatile, Acquire, Release}.

Paul.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150910/f105ac5f/attachment.bin>

From pavel.rappo at gmail.com  Fri Sep 11 10:45:09 2015
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 11 Sep 2015 15:45:09 +0100
Subject: [concurrency-interest] j.u.c.Flow.Subscription.request
	clarification and javadoc typos
Message-ID: <CAChcVunsdjEw=5jA9r5njSv_x17tGASDc5J8=YhPPeAH-ucAvA@mail.gmail.com>

Hi, I have two questions if I may.

1. Given the spec of j.u.c.Flow.Subscription.request method:

    /**
     * Adds the given number {@code n} of items to the current
     * unfulfilled demand for this subscription.  If {@code n} is
     * negative, the Subscriber will receive an {@code onError}
     * signal with an {@link IllegalArgumentException} argument.
     * Otherwise, the Subscriber will receive up to {@code n}
     * additional {@code onNext} invocations (or fewer if
     * terminated).
     *
     * @param n the increment of demand; a value of {@code
     * Long.MAX_VALUE} may be considered as effectively unbounded
     */
    public void request(long n);

I was wondering how flexible this is. It doesn't seem to allow stating the
demand in any other units than items (or number of onNext(T) invocations, which
I assume is the same).
One of the reviewers of WebSocket API has mentioned that some people "receive a
ByteBuffer, but backpressure on the number of bytes consumed" and that the
choice of units is actually "an implementation detail" [1]. Is that so?

I can understand the situation when one would have a function f(units) that
would map a number of back-pressure units to a number of onNext() calls (or
items). So one could always know how many onNext() calls to expect. But what if
this is not the case? For example an item is a ByteBuffer of unknown size?

2. A minor thing. In the javadoc to j.u.c.SubmissionPublisher:

    * {@link Flow.Subscriber#onNext onNext}, but exceptions in methods
    * {@link Flow.Subscriber#onSubscribe onSubscribe},
    * {@link Flow.Subscriber#onError #onError} and
    * {@link Flow.Subscriber#onComplete #onComplete} are not recorded or

I believe '#' characters are typos at the end of the third and the fourth lines.
Thanks.

-Pavel

-------------------------------------------------------------------------------
[1] http://mail.openjdk.java.net/pipermail/net-dev/2015-September/009127.html

From martinrb at google.com  Fri Sep 11 12:45:18 2015
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Sep 2015 09:45:18 -0700
Subject: [concurrency-interest] j.u.c.Flow.Subscription.request
 clarification and javadoc typos
In-Reply-To: <CAChcVunsdjEw=5jA9r5njSv_x17tGASDc5J8=YhPPeAH-ucAvA@mail.gmail.com>
References: <CAChcVunsdjEw=5jA9r5njSv_x17tGASDc5J8=YhPPeAH-ucAvA@mail.gmail.com>
Message-ID: <CA+kOe09JB+M2k2SHb91YxU7+LEDDx3Yn24O4cjfg9=+puLE2=g@mail.gmail.com>

On Fri, Sep 11, 2015 at 7:45 AM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

>
> 2. A minor thing. In the javadoc to j.u.c.SubmissionPublisher:
>
>     * {@link Flow.Subscriber#onNext onNext}, but exceptions in methods
>     * {@link Flow.Subscriber#onSubscribe onSubscribe},
>     * {@link Flow.Subscriber#onError #onError} and
>     * {@link Flow.Subscriber#onComplete #onComplete} are not recorded or
>
> I believe '#' characters are typos at the end of the third and the fourth
> lines.
> Thanks.
>

Thanks - typos fixed.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/0f0daed4/attachment.html>

From viktor.klang at gmail.com  Fri Sep 11 13:42:24 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Fri, 11 Sep 2015 19:42:24 +0200
Subject: [concurrency-interest] j.u.c.Flow.Subscription.request
 clarification and javadoc typos
In-Reply-To: <CAChcVunsdjEw=5jA9r5njSv_x17tGASDc5J8=YhPPeAH-ucAvA@mail.gmail.com>
References: <CAChcVunsdjEw=5jA9r5njSv_x17tGASDc5J8=YhPPeAH-ucAvA@mail.gmail.com>
Message-ID: <CANPzfU8zE0+wRM_OarkbPEuaJPuxELN3e9LR7sjZvv-Z0Mc-XQ@mail.gmail.com>

On Fri, Sep 11, 2015 at 4:45 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> Hi, I have two questions if I may.
>
> 1. Given the spec of j.u.c.Flow.Subscription.request method:
>
>     /**
>      * Adds the given number {@code n} of items to the current
>      * unfulfilled demand for this subscription.  If {@code n} is
>      * negative, the Subscriber will receive an {@code onError}
>      * signal with an {@link IllegalArgumentException} argument.
>      * Otherwise, the Subscriber will receive up to {@code n}
>      * additional {@code onNext} invocations (or fewer if
>      * terminated).
>      *
>      * @param n the increment of demand; a value of {@code
>      * Long.MAX_VALUE} may be considered as effectively unbounded
>      */
>     public void request(long n);
>
> I was wondering how flexible this is. It doesn't seem to allow stating the
> demand in any other units than items (or number of onNext(T) invocations,
> which
> I assume is the same).
> One of the reviewers of WebSocket API has mentioned that some people
> "receive a
> ByteBuffer, but backpressure on the number of bytes consumed" and that the
> choice of units is actually "an implementation detail" [1]. Is that so?
>

The choice of the unit is in number of elements?both the Spec and TCK is
very clear about that.


>
> I can understand the situation when one would have a function f(units) that
> would map a number of back-pressure units to a number of onNext() calls (or
> items). So one could always know how many onNext() calls to expect. But
> what if
> this is not the case? For example an item is a ByteBuffer of unknown size?
>

If the element type is a chunk, then the back-pressure is in number of
chunks.
One cannot assume how items will be processed, perhaps the consumer of the
ByteBuffers is not interested in their contents but is adding more
information, turning it into a Pair<Foo, ByteBuffer>, who knows?


>
> 2. A minor thing. In the javadoc to j.u.c.SubmissionPublisher:
>
>     * {@link Flow.Subscriber#onNext onNext}, but exceptions in methods
>     * {@link Flow.Subscriber#onSubscribe onSubscribe},
>     * {@link Flow.Subscriber#onError #onError} and
>     * {@link Flow.Subscriber#onComplete #onComplete} are not recorded or
>
> I believe '#' characters are typos at the end of the third and the fourth
> lines.
> Thanks.
>
> -Pavel
>
>
> -------------------------------------------------------------------------------
> [1]
> http://mail.openjdk.java.net/pipermail/net-dev/2015-September/009127.html
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/d4e641f7/attachment.html>

From martinrb at google.com  Fri Sep 11 16:51:04 2015
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Sep 2015 13:51:04 -0700
Subject: [concurrency-interest] jigsaw vs. jsr166 CVS
Message-ID: <CA+kOe0-C6YYdynHWo2b6soXwtJRySh7vKSnOgBc4R0=a22EziQ@mail.gmail.com>

Jigsawers:

I tried to use jigsaw EA with jsr166 CVS for the first time.

On a fresh jsr166 CVS checkout (http://g.oswego.edu/dl/concurrency-interest/),
I did:
 ~/jsr166/jigsaw $ ant -v compile -Djdk9.home="$HOME/jdk/jigsaw-b80"

and got:

    [javac]
/home/martin/jsr166/jigsaw/src/main/java/util/AbstractQueue.java:7:
warning: package exists in another module: java.base
    [javac] package java.util;

and then more seriously

    [javac]
/home/martin/jsr166/jigsaw/src/main/java/util/AbstractQueue.java:36: error:
cannot find symbol
    [javac]     extends AbstractCollection<E>

I was surprised by that -- we don't fiddle with the boot environment here.
Is it not allowed to compile sources for which class files are in the same
package but another module?  Alternatively, does the compile time
environment need to include all the sources for the packages being
compiled, i.e. do I need to add sourcepath for
jdk/src/java.base/share/classes?

(Admittedly, developing jdk sources outside the jdk proper is a little bit
unusual)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/1fddaa54/attachment.html>

From martinrb at google.com  Fri Sep 11 17:51:29 2015
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Sep 2015 14:51:29 -0700
Subject: [concurrency-interest] A thread pool for servers?
Message-ID: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>

Colleague Douglas Dickinson at Google pointed out that none of the
convenience executors in Executors is truly resource bounded.

I've never run a "production Java server", but trying to bound resource
usage so that your server doesn't die with OOME or gc thrashing seems
important.  So your thread pool needs to be bounded in the number of
threads *and* in the size of the queue, and be prepared to handle task
rejection sensibly.

So it makes sense to me to add another convenience method to Executors that
will act like newFixedThreadPool but will additionally have a bounded
queue.  It's not completely obvious whether ArrayBlockingQueue or
LinkedBlockingQueue is the better choice for the bounded queue, but I
suspect for "serious servers" it's the former, because:
- modern server environments tend to like pre-allocating all their
resources at startup
- there's little GC overhead to the "dead weight" of the
ArrayBlockingQueue's backing array (a single object!)
- LinkedBlockingQueue will allocate many more small objects, and servers
don't like that
- with today's economics, "memory is cheap"

(and of course, we can try to write an actual better bounded thread pool
not based on ThreadPoolExecutor, but that's actually hard)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/0412ad83/attachment.html>

From martinrb at google.com  Fri Sep 11 19:30:37 2015
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 11 Sep 2015 16:30:37 -0700
Subject: [concurrency-interest] jigsaw vs. jsr166 CVS
In-Reply-To: <55F35A6F.7040807@oracle.com>
References: <CA+kOe0-C6YYdynHWo2b6soXwtJRySh7vKSnOgBc4R0=a22EziQ@mail.gmail.com>
	<55F35A6F.7040807@oracle.com>
Message-ID: <CA+kOe0_BAQNHvRR6bp=17SrNR69R5x_nk+55ipgJdBkRxZtqcQ@mail.gmail.com>

I tried adding -Xoverride, but it didn't help.

--- build.xml 11 Sep 2015 18:43:46 -0000 1.177
+++ build.xml 11 Sep 2015 23:17:46 -0000
@@ -347,6 +347,7 @@
            fork="true">

       <include name="**/*.java"/>
+      <compilerarg value="-Xoverride:${src.dir}"/>
       <compilerarg value="-Xprefer:source"/>
       <compilerarg value="-XDignore.symbol.file=true"/>
       <compilerarg value="-Xlint:all"/>

I can see that the compiler is being invoked like this:
$ ant -v compile -Djdk9.home="$HOME/jdk/jigsaw-b80"
...
    [javac] Compilation arguments:
    [javac] '-d'
    [javac] '/home/martin/jsr166/jigsaw/build/classes'
    [javac] '-classpath'
    [javac] '/home/martin/jsr166/jigsaw/build/classes'
    [javac] '-sourcepath'
    [javac] '/home/martin/jsr166/jigsaw/src/main'
    [javac] '-g:source,lines,vars'
    [javac] '-Xoverride:/home/martin/jsr166/jigsaw/src/main'
    [javac] '-Xprefer:source'
    [javac] '-XDignore.symbol.file=true'
    [javac] '-Xlint:all'
    [javac] '-Werror'
    [javac] '-Xdoclint:all/protected'
    [javac] '-Xmaxerrs'
    [javac] '1000'
    [javac] '-Xmaxwarns'
    [javac] '1000'

Maybe the problem is that the there is *nothing but* overriding source
files here.
Does javac check that its actual argument source files might be in the
Xoverride tree?

Can/should we make jsr166 files itself a sub-module of java.base?
Certainly, here in jsr166-developer-land, we act as if it were so.
We have independent source trees, binary artifacts, etc... must be a
module!?
(You might not allow carving up java.util along module boundaries, but the
reality as reflected in the bug system is that java.util contains portions
of several "modules")
(but oops ... circular dependencies ...)



On Fri, Sep 11, 2015 at 3:49 PM, Alex Buckley <alex.buckley at oracle.com>
wrote:

> Hi Martin,
>
> javac is compiling your classes (in the unnamed module) against all the
> named modules in the image. One of those named modules (java.base) contains
> the java.util package, so your code (in the unnamed module) cannot also
> contain that package. [That's not quite true but go with it for now.]
>
> What you want is the -Xoverride flag -- see the "Overriding module
> content" section of JEP 261. You'll have to rename 'main' to 'java.base'.
> Also note the open design issues around -Xoverride.
>
> Alex
>
>
> On 9/11/2015 1:51 PM, Martin Buchholz wrote:
>
>> Jigsawers:
>>
>> I tried to use jigsaw EA with jsr166 CVS for the first time.
>>
>> On a fresh jsr166 CVS checkout (
>> http://g.oswego.edu/dl/concurrency-interest/),
>> I did:
>>   ~/jsr166/jigsaw $ ant -v compile -Djdk9.home="$HOME/jdk/jigsaw-b80"
>>
>> and got:
>>
>>      [javac]
>> /home/martin/jsr166/jigsaw/src/main/java/util/AbstractQueue.java:7:
>> warning: package exists in another module: java.base
>>      [javac] package java.util;
>>
>> and then more seriously
>>
>>      [javac]
>> /home/martin/jsr166/jigsaw/src/main/java/util/AbstractQueue.java:36:
>> error:
>> cannot find symbol
>>      [javac]     extends AbstractCollection<E>
>>
>> I was surprised by that -- we don't fiddle with the boot environment here.
>> Is it not allowed to compile sources for which class files are in the same
>> package but another module?  Alternatively, does the compile time
>> environment need to include all the sources for the packages being
>> compiled, i.e. do I need to add sourcepath for
>> jdk/src/java.base/share/classes?
>>
>> (Admittedly, developing jdk sources outside the jdk proper is a little bit
>> unusual)
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/f1c785d3/attachment-0001.html>

From davidcholmes at aapt.net.au  Fri Sep 11 19:46:02 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 12 Sep 2015 09:46:02 +1000
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
Message-ID: <080801d0ecec$04df6290$0e9e27b0$@net.au>

Hi Martin,

 

All those requirements suggest direct use of a thread pool constructor not a ?convenience? method. You get to set the size of the pool, the type and size of queue and the rejection policy.

 

David

 

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin Buchholz
Sent: Saturday, September 12, 2015 7:51 AM
To: concurrency-interest; Douglas Dickinson
Subject: [concurrency-interest] A thread pool for servers?

 

 

Colleague Douglas Dickinson at Google pointed out that none of the convenience executors in Executors is truly resource bounded.

 

I've never run a "production Java server", but trying to bound resource usage so that your server doesn't die with OOME or gc thrashing seems important.  So your thread pool needs to be bounded in the number of threads *and* in the size of the queue, and be prepared to handle task rejection sensibly.

 

So it makes sense to me to add another convenience method to Executors that will act like newFixedThreadPool but will additionally have a bounded queue.  It's not completely obvious whether ArrayBlockingQueue or LinkedBlockingQueue is the better choice for the bounded queue, but I suspect for "serious servers" it's the former, because:

- modern server environments tend to like pre-allocating all their resources at startup

- there's little GC overhead to the "dead weight" of the ArrayBlockingQueue's backing array (a single object!)

- LinkedBlockingQueue will allocate many more small objects, and servers don't like that

- with today's economics, "memory is cheap"

 

(and of course, we can try to write an actual better bounded thread pool not based on ThreadPoolExecutor, but that's actually hard)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150912/5e14b1cd/attachment.html>

From mike at axiak.net  Fri Sep 11 19:51:15 2015
From: mike at axiak.net (Mike Axiak)
Date: Fri, 11 Sep 2015 19:51:15 -0400
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <080801d0ecec$04df6290$0e9e27b0$@net.au>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
	<080801d0ecec$04df6290$0e9e27b0$@net.au>
Message-ID: <CAKUW7qH6gcfkLCXmrWkK42moYC0AdvweJ_CdQrug_ZVW+-hpCw@mail.gmail.com>

At HubSpot, we've found the standard Executors helper methods to be a
somewhat onerous API. We provide a bounded thread pool as part of a fluent
builder that makes it clearer what you're wanting.

Rather than adding a new "newFixedThreadPool" or having people create a
"new ThreadPoolExecutor" and possibly subsequently calling
"allowCoreThreadTimeOut", would a JEP for a builder be reasonable?

Best,
Mike

On Fri, Sep 11, 2015 at 7:46 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:

> Hi Martin,
>
>
>
> All those requirements suggest direct use of a thread pool constructor not
> a ?convenience? method. You get to set the size of the pool, the type and
> size of queue and the rejection policy.
>
>
>
> David
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Martin Buchholz
> *Sent:* Saturday, September 12, 2015 7:51 AM
> *To:* concurrency-interest; Douglas Dickinson
> *Subject:* [concurrency-interest] A thread pool for servers?
>
>
>
>
>
> Colleague Douglas Dickinson at Google pointed out that none of the
> convenience executors in Executors is truly resource bounded.
>
>
>
> I've never run a "production Java server", but trying to bound resource
> usage so that your server doesn't die with OOME or gc thrashing seems
> important.  So your thread pool needs to be bounded in the number of
> threads *and* in the size of the queue, and be prepared to handle task
> rejection sensibly.
>
>
>
> So it makes sense to me to add another convenience method to Executors
> that will act like newFixedThreadPool but will additionally have a bounded
> queue.  It's not completely obvious whether ArrayBlockingQueue or
> LinkedBlockingQueue is the better choice for the bounded queue, but I
> suspect for "serious servers" it's the former, because:
>
> - modern server environments tend to like pre-allocating all their
> resources at startup
>
> - there's little GC overhead to the "dead weight" of the
> ArrayBlockingQueue's backing array (a single object!)
>
> - LinkedBlockingQueue will allocate many more small objects, and servers
> don't like that
>
> - with today's economics, "memory is cheap"
>
>
>
> (and of course, we can try to write an actual better bounded thread pool
> not based on ThreadPoolExecutor, but that's actually hard)
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/58dda7f3/attachment.html>

From lukeisandberg at gmail.com  Fri Sep 11 21:33:40 2015
From: lukeisandberg at gmail.com (Luke Sandberg)
Date: Sat, 12 Sep 2015 01:33:40 +0000
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <CAKUW7qH6gcfkLCXmrWkK42moYC0AdvweJ_CdQrug_ZVW+-hpCw@mail.gmail.com>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
	<080801d0ecec$04df6290$0e9e27b0$@net.au>
	<CAKUW7qH6gcfkLCXmrWkK42moYC0AdvweJ_CdQrug_ZVW+-hpCw@mail.gmail.com>
Message-ID: <CAO9V1MLY9XvV5Eaqd45A=BY6eObR06XrVT+bpOhW4a42zZBZKg@mail.gmail.com>

I have found the "be prepared to handle task rejection sensibly" advice to
be significantly easier said than done.  For example, few of Guava's
ListenableFuture utilities are 'hardened' against
RejectedExecutionException,  It was only about a year ago that
Futures.transform would give you a 'dead' future if these executor threw an
REE.  I have also seen a number of production deadlocks/stuck threads due
to improper REE handling.  At least in the applications I work on, the
number of places that submit tasks to thread pools is large so ensuring
consistent reasonable handling is very hard.

The strategy my teams has taken in some servers is to use fixed size thread
pools (ThreadPoolExecutor, though we are experimenting with FJP) with
unbounded queues and higher level throttling support.  In theory errant
tasks could still cause OOMEs by producing tasks too fast, but in practice
I have never observed this, while I have been involved in debugging
production issues due to REE.

On Fri, Sep 11, 2015 at 5:15 PM Mike Axiak <mike at axiak.net> wrote:

> At HubSpot, we've found the standard Executors helper methods to be a
> somewhat onerous API. We provide a bounded thread pool as part of a fluent
> builder that makes it clearer what you're wanting.
>
> Rather than adding a new "newFixedThreadPool" or having people create a
> "new ThreadPoolExecutor" and possibly subsequently calling
> "allowCoreThreadTimeOut", would a JEP for a builder be reasonable?
>
> Best,
> Mike
>
>
> On Fri, Sep 11, 2015 at 7:46 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>
>> Hi Martin,
>>
>>
>>
>> All those requirements suggest direct use of a thread pool constructor
>> not a ?convenience? method. You get to set the size of the pool, the type
>> and size of queue and the rejection policy.
>>
>>
>>
>> David
>>
>>
>>
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Martin
>> Buchholz
>> *Sent:* Saturday, September 12, 2015 7:51 AM
>> *To:* concurrency-interest; Douglas Dickinson
>> *Subject:* [concurrency-interest] A thread pool for servers?
>>
>>
>>
>>
>>
>> Colleague Douglas Dickinson at Google pointed out that none of the
>> convenience executors in Executors is truly resource bounded.
>>
>>
>>
>> I've never run a "production Java server", but trying to bound resource
>> usage so that your server doesn't die with OOME or gc thrashing seems
>> important.  So your thread pool needs to be bounded in the number of
>> threads *and* in the size of the queue, and be prepared to handle task
>> rejection sensibly.
>>
>>
>>
>> So it makes sense to me to add another convenience method to Executors
>> that will act like newFixedThreadPool but will additionally have a bounded
>> queue.  It's not completely obvious whether ArrayBlockingQueue or
>> LinkedBlockingQueue is the better choice for the bounded queue, but I
>> suspect for "serious servers" it's the former, because:
>>
>> - modern server environments tend to like pre-allocating all their
>> resources at startup
>>
>> - there's little GC overhead to the "dead weight" of the
>> ArrayBlockingQueue's backing array (a single object!)
>>
>> - LinkedBlockingQueue will allocate many more small objects, and servers
>> don't like that
>>
>> - with today's economics, "memory is cheap"
>>
>>
>>
>> (and of course, we can try to write an actual better bounded thread pool
>> not based on ThreadPoolExecutor, but that's actually hard)
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150912/a46aad64/attachment-0001.html>

From henri.tremblay at gmail.com  Fri Sep 11 23:01:24 2015
From: henri.tremblay at gmail.com (Henri Tremblay)
Date: Fri, 11 Sep 2015 23:01:24 -0400
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <CAO9V1MLY9XvV5Eaqd45A=BY6eObR06XrVT+bpOhW4a42zZBZKg@mail.gmail.com>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
	<080801d0ecec$04df6290$0e9e27b0$@net.au>
	<CAKUW7qH6gcfkLCXmrWkK42moYC0AdvweJ_CdQrug_ZVW+-hpCw@mail.gmail.com>
	<CAO9V1MLY9XvV5Eaqd45A=BY6eObR06XrVT+bpOhW4a42zZBZKg@mail.gmail.com>
Message-ID: <CADZL2=sO1ZouNc_cZf5cqDzFM62sKKs7WZec9K5Y=oPcM2VrXQ@mail.gmail.com>

I indeed have encountered this problem frequently.When trying to do basic
producer -> consumers system without having to think too much about it.

I was really surprised that nothing allowing the producer to stop producing
exists. So I usually end-up doing something like this:

*BlockingQueue<Runnable> queue = new BlockingQueue<>(10_000);
ThreadPoolExecutor pool = new ThreadPoolExecutor(
        parallelism, parallelism,
        0L, TimeUnit.MILLISECONDS,
        queue);
pool.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());*

It does the job but I would love to have something readily available in
Executors.

On 11 September 2015 at 21:33, Luke Sandberg <lukeisandberg at gmail.com>
wrote:

> I have found the "be prepared to handle task rejection sensibly" advice
> to be significantly easier said than done.  For example, few of Guava's
> ListenableFuture utilities are 'hardened' against
> RejectedExecutionException,  It was only about a year ago that
> Futures.transform would give you a 'dead' future if these executor threw an
> REE.  I have also seen a number of production deadlocks/stuck threads due
> to improper REE handling.  At least in the applications I work on, the
> number of places that submit tasks to thread pools is large so ensuring
> consistent reasonable handling is very hard.
>
> The strategy my teams has taken in some servers is to use fixed size
> thread pools (ThreadPoolExecutor, though we are experimenting with FJP)
> with unbounded queues and higher level throttling support.  In theory
> errant tasks could still cause OOMEs by producing tasks too fast, but in
> practice I have never observed this, while I have been involved in
> debugging production issues due to REE.
>
> On Fri, Sep 11, 2015 at 5:15 PM Mike Axiak <mike at axiak.net> wrote:
>
>> At HubSpot, we've found the standard Executors helper methods to be a
>> somewhat onerous API. We provide a bounded thread pool as part of a fluent
>> builder that makes it clearer what you're wanting.
>>
>> Rather than adding a new "newFixedThreadPool" or having people create a
>> "new ThreadPoolExecutor" and possibly subsequently calling
>> "allowCoreThreadTimeOut", would a JEP for a builder be reasonable?
>>
>> Best,
>> Mike
>>
>>
>> On Fri, Sep 11, 2015 at 7:46 PM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>>
>>> Hi Martin,
>>>
>>>
>>>
>>> All those requirements suggest direct use of a thread pool constructor
>>> not a ?convenience? method. You get to set the size of the pool, the type
>>> and size of queue and the rejection policy.
>>>
>>>
>>>
>>> David
>>>
>>>
>>>
>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Martin
>>> Buchholz
>>> *Sent:* Saturday, September 12, 2015 7:51 AM
>>> *To:* concurrency-interest; Douglas Dickinson
>>> *Subject:* [concurrency-interest] A thread pool for servers?
>>>
>>>
>>>
>>>
>>>
>>> Colleague Douglas Dickinson at Google pointed out that none of the
>>> convenience executors in Executors is truly resource bounded.
>>>
>>>
>>>
>>> I've never run a "production Java server", but trying to bound resource
>>> usage so that your server doesn't die with OOME or gc thrashing seems
>>> important.  So your thread pool needs to be bounded in the number of
>>> threads *and* in the size of the queue, and be prepared to handle task
>>> rejection sensibly.
>>>
>>>
>>>
>>> So it makes sense to me to add another convenience method to Executors
>>> that will act like newFixedThreadPool but will additionally have a bounded
>>> queue.  It's not completely obvious whether ArrayBlockingQueue or
>>> LinkedBlockingQueue is the better choice for the bounded queue, but I
>>> suspect for "serious servers" it's the former, because:
>>>
>>> - modern server environments tend to like pre-allocating all their
>>> resources at startup
>>>
>>> - there's little GC overhead to the "dead weight" of the
>>> ArrayBlockingQueue's backing array (a single object!)
>>>
>>> - LinkedBlockingQueue will allocate many more small objects, and servers
>>> don't like that
>>>
>>> - with today's economics, "memory is cheap"
>>>
>>>
>>>
>>> (and of course, we can try to write an actual better bounded thread pool
>>> not based on ThreadPoolExecutor, but that's actually hard)
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150911/f5e3d0e7/attachment.html>

From Alan.Bateman at oracle.com  Sat Sep 12 00:47:00 2015
From: Alan.Bateman at oracle.com (Alan Bateman)
Date: Sat, 12 Sep 2015 05:47:00 +0100
Subject: [concurrency-interest] jigsaw vs. jsr166 CVS
In-Reply-To: <CA+kOe0_BAQNHvRR6bp=17SrNR69R5x_nk+55ipgJdBkRxZtqcQ@mail.gmail.com>
References: <CA+kOe0-C6YYdynHWo2b6soXwtJRySh7vKSnOgBc4R0=a22EziQ@mail.gmail.com>	<55F35A6F.7040807@oracle.com>
	<CA+kOe0_BAQNHvRR6bp=17SrNR69R5x_nk+55ipgJdBkRxZtqcQ@mail.gmail.com>
Message-ID: <55F3AE44.9060407@oracle.com>


On 12/09/2015 00:30, Martin Buchholz wrote:
> I tried adding -Xoverride, but it didn't help.
>
You'll need to use javac -Xmodule:java.base to compile the classes, then 
use -Xoverride at run-time. As it happens, there is an example that 
compiles and uses an development version of CHM here:

   http://openjdk.java.net/projects/jigsaw/quick-start#xoverride

Hopefully it won't too much to get the build.xml to do this.

-Alan

From dl at cs.oswego.edu  Sat Sep 12 08:18:55 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 12 Sep 2015 08:18:55 -0400
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
Message-ID: <55F4182F.808@cs.oswego.edu>

On 09/11/2015 05:51 PM, Martin Buchholz wrote:
>
> Colleague Douglas Dickinson at Google pointed out that none of the convenience
> executors in Executors is truly resource bounded.

It's great that people are advocating use of the resource-control
features of TPE. Back in pre-j.u.c days when TPE was introduced,
nearly everyone complained about how many arguments were needed in
the constructor, which led to us introducing Executors convenience
methods. But in these cases "convenience" means "we are letting you
get away with default choices that you should probably someday revisit",
and the TPE javadoc includes discussion about how to make better choices.
The need to contemplate bounding, rejection, and flow control
has been increasing as containerized, resource-managed runtime
environments become more common.

But, like David, I'm not sure that we can add more Executors methods
that don't amount to just replicating the TPE constructors.
Maybe a builder, but that seems like overkill given the j.u.c audience.

Some of these issues also affect ForkJoinPool, which we addressed by
adding a configurable spare-thread limit and tolerance for bounded
thread factories. It would also be possible to add a per-thread local
queue-size limit, although the cases where it might come into play
are uncommon and preventable using FJ status methods.

People facing these issues might also consider using the new
SubmissionPublisher class, that pushes resource and flow control
up one level: Producers need to pick buffer sizes, consumers
explicitly perform requests, and you must choose per-item
whether to use block vs drop vs timeout vs handler modes
(methods submit, offer, and timed-offer, with optional drop
handlers). These can be made to work well no matter what kind
Executor you use, because the SubmissionPublisher deals with
most of them instead of the Executor.

> (and of course, we can try to write an actual better bounded thread pool not
> based on ThreadPoolExecutor, but that's actually hard)

The main use case that j.u.c. lacks explicit coverage for
is when there is known to be a single task submitter thread.
FJP's multi-laned queues add some unnecessary data structure overhead
and TPE's insistence on a queue implementation meeting the full
BlockingQueue API adds some unnecessary sync overhead.
In most usages, either choice is fine, but we might consider
addressing this.

-Doug




From viktor.klang at gmail.com  Sat Sep 12 10:06:27 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Sat, 12 Sep 2015 16:06:27 +0200
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <55F4182F.808@cs.oswego.edu>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
	<55F4182F.808@cs.oswego.edu>
Message-ID: <CANPzfU8k0GehzLT5uzbiU_HQJdORbH8WkXaFh0-sfSyjNvmNZw@mail.gmail.com>

Doug,

yes, pre prospect of making thread pools *pull* in work rather than get
*pushed* work would make for a very interesting side-effect in terms of
flow control / back pressure without having to block any threads in the
process.

On Sat, Sep 12, 2015 at 2:18 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 09/11/2015 05:51 PM, Martin Buchholz wrote:
>
>>
>> Colleague Douglas Dickinson at Google pointed out that none of the
>> convenience
>> executors in Executors is truly resource bounded.
>>
>
> It's great that people are advocating use of the resource-control
> features of TPE. Back in pre-j.u.c days when TPE was introduced,
> nearly everyone complained about how many arguments were needed in
> the constructor, which led to us introducing Executors convenience
> methods. But in these cases "convenience" means "we are letting you
> get away with default choices that you should probably someday revisit",
> and the TPE javadoc includes discussion about how to make better choices.
> The need to contemplate bounding, rejection, and flow control
> has been increasing as containerized, resource-managed runtime
> environments become more common.
>
> But, like David, I'm not sure that we can add more Executors methods
> that don't amount to just replicating the TPE constructors.
> Maybe a builder, but that seems like overkill given the j.u.c audience.
>
> Some of these issues also affect ForkJoinPool, which we addressed by
> adding a configurable spare-thread limit and tolerance for bounded
> thread factories. It would also be possible to add a per-thread local
> queue-size limit, although the cases where it might come into play
> are uncommon and preventable using FJ status methods.
>
> People facing these issues might also consider using the new
> SubmissionPublisher class, that pushes resource and flow control
> up one level: Producers need to pick buffer sizes, consumers
> explicitly perform requests, and you must choose per-item
> whether to use block vs drop vs timeout vs handler modes
> (methods submit, offer, and timed-offer, with optional drop
> handlers). These can be made to work well no matter what kind
> Executor you use, because the SubmissionPublisher deals with
> most of them instead of the Executor.
>
> (and of course, we can try to write an actual better bounded thread pool
>> not
>> based on ThreadPoolExecutor, but that's actually hard)
>>
>
> The main use case that j.u.c. lacks explicit coverage for
> is when there is known to be a single task submitter thread.
> FJP's multi-laned queues add some unnecessary data structure overhead
> and TPE's insistence on a queue implementation meeting the full
> BlockingQueue API adds some unnecessary sync overhead.
> In most usages, either choice is fine, but we might consider
> addressing this.
>
> -Doug
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150912/71359986/attachment-0001.html>

From pavel.rappo at gmail.com  Sun Sep 13 05:14:22 2015
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Sun, 13 Sep 2015 10:14:22 +0100
Subject: [concurrency-interest] j.u.c.Flow.Subscription.request
 clarification and javadoc typos
In-Reply-To: <CANPzfU8zE0+wRM_OarkbPEuaJPuxELN3e9LR7sjZvv-Z0Mc-XQ@mail.gmail.com>
References: <CAChcVunsdjEw=5jA9r5njSv_x17tGASDc5J8=YhPPeAH-ucAvA@mail.gmail.com>
	<CANPzfU8zE0+wRM_OarkbPEuaJPuxELN3e9LR7sjZvv-Z0Mc-XQ@mail.gmail.com>
Message-ID: <CAChcVu=rUSvpGa5mWxYo9XqZ5BhR9zzT8Xw+Te2HXoThBSdgEg@mail.gmail.com>

Thanks Victor. It indeed makes sense. Also, given the remark [1] ReactiveX gives
on Observable type:

    An Observable is the asynchronous/push ?dual? to the
synchronous/pull Iterable

One could immediately see a parallel between 'request(n)' and a number of
calls to 'hasNext'. In this analogy, if 'n' were able to be of any units
other than number of items, it would mean an Iterator could have a

    public boolean hasNext(n);

Which would return 'true' if some number of consecutive 'next' invocations would
deliver 'n' units of something. Which is indeed odd. Instead, iterator is about
a number of iterations, not anything else.

-Pavel


On Fri, Sep 11, 2015 at 6:42 PM, Viktor Klang <viktor.klang at gmail.com> wrote:
>
>
> On Fri, Sep 11, 2015 at 4:45 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>>
>> Hi, I have two questions if I may.
>>
>> 1. Given the spec of j.u.c.Flow.Subscription.request method:
>>
>>     /**
>>      * Adds the given number {@code n} of items to the current
>>      * unfulfilled demand for this subscription.  If {@code n} is
>>      * negative, the Subscriber will receive an {@code onError}
>>      * signal with an {@link IllegalArgumentException} argument.
>>      * Otherwise, the Subscriber will receive up to {@code n}
>>      * additional {@code onNext} invocations (or fewer if
>>      * terminated).
>>      *
>>      * @param n the increment of demand; a value of {@code
>>      * Long.MAX_VALUE} may be considered as effectively unbounded
>>      */
>>     public void request(long n);
>>
>> I was wondering how flexible this is. It doesn't seem to allow stating the
>> demand in any other units than items (or number of onNext(T) invocations,
>> which
>> I assume is the same).
>> One of the reviewers of WebSocket API has mentioned that some people
>> "receive a
>> ByteBuffer, but backpressure on the number of bytes consumed" and that the
>> choice of units is actually "an implementation detail" [1]. Is that so?
>
>
> The choice of the unit is in number of elements?both the Spec and TCK is
> very clear about that.
>
>>
>>
>> I can understand the situation when one would have a function f(units)
>> that
>> would map a number of back-pressure units to a number of onNext() calls
>> (or
>> items). So one could always know how many onNext() calls to expect. But
>> what if
>> this is not the case? For example an item is a ByteBuffer of unknown size?
>
>
> If the element type is a chunk, then the back-pressure is in number of
> chunks.
> One cannot assume how items will be processed, perhaps the consumer of the
> ByteBuffers is not interested in their contents but is adding more
> information, turning it into a Pair<Foo, ByteBuffer>, who knows?
>
>>
>>
>> 2. A minor thing. In the javadoc to j.u.c.SubmissionPublisher:
>>
>>     * {@link Flow.Subscriber#onNext onNext}, but exceptions in methods
>>     * {@link Flow.Subscriber#onSubscribe onSubscribe},
>>     * {@link Flow.Subscriber#onError #onError} and
>>     * {@link Flow.Subscriber#onComplete #onComplete} are not recorded or
>>
>> I believe '#' characters are typos at the end of the third and the fourth
>> lines.
>> Thanks.
>>
>> -Pavel
>>
>>
>> -------------------------------------------------------------------------------
>> [1]
>> http://mail.openjdk.java.net/pipermail/net-dev/2015-September/009127.html
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Cheers,
> ?


From martinrb at google.com  Sun Sep 13 14:54:43 2015
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 13 Sep 2015 11:54:43 -0700
Subject: [concurrency-interest] jigsaw vs. jsr166 CVS
In-Reply-To: <55F3AE44.9060407@oracle.com>
References: <CA+kOe0-C6YYdynHWo2b6soXwtJRySh7vKSnOgBc4R0=a22EziQ@mail.gmail.com>
	<55F35A6F.7040807@oracle.com>
	<CA+kOe0_BAQNHvRR6bp=17SrNR69R5x_nk+55ipgJdBkRxZtqcQ@mail.gmail.com>
	<55F3AE44.9060407@oracle.com>
Message-ID: <CA+kOe08oe3JMybURYZh0TnmPKmqo357vg_OqgPfP=xVAamOhaA@mail.gmail.com>

Alan, thanks for that pointer.  I succeeded at building jsr166 and running
tests with it after beating ant into submission.

People *will* write code to distinguish between a pre-module and
post-module JDK by inspecting the filesystem.
Here's one implementation in ant:

    <local name="modules"/>
    <condition property="modules">
      <available file="${jdk@{compile-target}.home}/jmods" type="dir"/>
    </condition>

Then we can have conditional ant code like this:

      <compilerarg value="-Xbootclasspath/p:@{classes}"
unless:set="modules"/>
      <compilerarg value="-Xoverride:${build.classes.dir}"
if:set="modules"/>

It's not just a matter of "porting to jigsaw".  There seems to be no way of
deploying jsr166 CVS as a directly deployable software artifact as we have
been doing with -Xbootclasspath/p.  To use -Xoverride, there must be an
exploded directory.  It would be convenient if -Xoverride was usable with
an equivalent jar file (jsr166.jar).  But y'all are trying to make module
overriding possible, not convenient?!

javadoc does not seem to have any support for -Xmodule, so I don't know how
to fix the "docs" target.

The fundamental disconnect is that from a developer point of view, jsr166
CVS contains an independently developed "module" with binary deployable
artifacts, but jigsaw disagrees about its module-ness, and that can
probably not be fixed because of circular dependencies between
java.util.concurrent and the rest of java.base?


On Fri, Sep 11, 2015 at 9:47 PM, Alan Bateman <Alan.Bateman at oracle.com>
wrote:

>
> On 12/09/2015 00:30, Martin Buchholz wrote:
>
>> I tried adding -Xoverride, but it didn't help.
>>
>> You'll need to use javac -Xmodule:java.base to compile the classes, then
> use -Xoverride at run-time. As it happens, there is an example that
> compiles and uses an development version of CHM here:
>
>   http://openjdk.java.net/projects/jigsaw/quick-start#xoverride
>
> Hopefully it won't too much to get the build.xml to do this.
>
> -Alan
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150913/3486fc03/attachment.html>

From david.lloyd at redhat.com  Mon Sep 14 08:17:33 2015
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Mon, 14 Sep 2015 07:17:33 -0500
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <CANPzfU8k0GehzLT5uzbiU_HQJdORbH8WkXaFh0-sfSyjNvmNZw@mail.gmail.com>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>	<55F4182F.808@cs.oswego.edu>
	<CANPzfU8k0GehzLT5uzbiU_HQJdORbH8WkXaFh0-sfSyjNvmNZw@mail.gmail.com>
Message-ID: <55F6BADD.8050904@redhat.com>

Where would you pull from, if not a queue?

On 09/12/2015 09:06 AM, Viktor Klang wrote:
> Doug,
>
> yes, pre prospect of making thread pools *pull* in work rather than get
> *pushed* work would make for a very interesting side-effect in terms of
> flow control / back pressure without having to block any threads in the
> process.
>
> On Sat, Sep 12, 2015 at 2:18 PM, Doug Lea <dl at cs.oswego.edu
> <mailto:dl at cs.oswego.edu>> wrote:
>
>     On 09/11/2015 05:51 PM, Martin Buchholz wrote:
>
>
>         Colleague Douglas Dickinson at Google pointed out that none of
>         the convenience
>         executors in Executors is truly resource bounded.
>
>
>     It's great that people are advocating use of the resource-control
>     features of TPE. Back in pre-j.u.c days when TPE was introduced,
>     nearly everyone complained about how many arguments were needed in
>     the constructor, which led to us introducing Executors convenience
>     methods. But in these cases "convenience" means "we are letting you
>     get away with default choices that you should probably someday revisit",
>     and the TPE javadoc includes discussion about how to make better
>     choices.
>     The need to contemplate bounding, rejection, and flow control
>     has been increasing as containerized, resource-managed runtime
>     environments become more common.
>
>     But, like David, I'm not sure that we can add more Executors methods
>     that don't amount to just replicating the TPE constructors.
>     Maybe a builder, but that seems like overkill given the j.u.c audience.
>
>     Some of these issues also affect ForkJoinPool, which we addressed by
>     adding a configurable spare-thread limit and tolerance for bounded
>     thread factories. It would also be possible to add a per-thread local
>     queue-size limit, although the cases where it might come into play
>     are uncommon and preventable using FJ status methods.
>
>     People facing these issues might also consider using the new
>     SubmissionPublisher class, that pushes resource and flow control
>     up one level: Producers need to pick buffer sizes, consumers
>     explicitly perform requests, and you must choose per-item
>     whether to use block vs drop vs timeout vs handler modes
>     (methods submit, offer, and timed-offer, with optional drop
>     handlers). These can be made to work well no matter what kind
>     Executor you use, because the SubmissionPublisher deals with
>     most of them instead of the Executor.
>
>         (and of course, we can try to write an actual better bounded
>         thread pool not
>         based on ThreadPoolExecutor, but that's actually hard)
>
>
>     The main use case that j.u.c. lacks explicit coverage for
>     is when there is known to be a single task submitter thread.
>     FJP's multi-laned queues add some unnecessary data structure overhead
>     and TPE's insistence on a queue implementation meeting the full
>     BlockingQueue API adds some unnecessary sync overhead.
>     In most usages, either choice is fine, but we might consider
>     addressing this.
>
>     -Doug
>
>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Cheers,
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-- 
- DML

From viktor.klang at gmail.com  Mon Sep 14 10:10:12 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 14 Sep 2015 16:10:12 +0200
Subject: [concurrency-interest] A thread pool for servers?
In-Reply-To: <55F6BADD.8050904@redhat.com>
References: <CA+kOe0_PyUOLEojEcp+69n1ohNDX0NvPGPoXJXz-v=XffwiMdg@mail.gmail.com>
	<55F4182F.808@cs.oswego.edu>
	<CANPzfU8k0GehzLT5uzbiU_HQJdORbH8WkXaFh0-sfSyjNvmNZw@mail.gmail.com>
	<55F6BADD.8050904@redhat.com>
Message-ID: <CANPzfU__4Q=AKnq1bRCHgsWCvhXM3vfvXo7ZmzH6HH7AEovAAA@mail.gmail.com>

A Publisher of Runnable?

On Mon, Sep 14, 2015 at 2:17 PM, David M. Lloyd <david.lloyd at redhat.com>
wrote:

> Where would you pull from, if not a queue?
>
> On 09/12/2015 09:06 AM, Viktor Klang wrote:
>
>> Doug,
>>
>> yes, pre prospect of making thread pools *pull* in work rather than get
>> *pushed* work would make for a very interesting side-effect in terms of
>> flow control / back pressure without having to block any threads in the
>> process.
>>
>> On Sat, Sep 12, 2015 at 2:18 PM, Doug Lea <dl at cs.oswego.edu
>> <mailto:dl at cs.oswego.edu>> wrote:
>>
>>     On 09/11/2015 05:51 PM, Martin Buchholz wrote:
>>
>>
>>         Colleague Douglas Dickinson at Google pointed out that none of
>>         the convenience
>>         executors in Executors is truly resource bounded.
>>
>>
>>     It's great that people are advocating use of the resource-control
>>     features of TPE. Back in pre-j.u.c days when TPE was introduced,
>>     nearly everyone complained about how many arguments were needed in
>>     the constructor, which led to us introducing Executors convenience
>>     methods. But in these cases "convenience" means "we are letting you
>>     get away with default choices that you should probably someday
>> revisit",
>>     and the TPE javadoc includes discussion about how to make better
>>     choices.
>>     The need to contemplate bounding, rejection, and flow control
>>     has been increasing as containerized, resource-managed runtime
>>     environments become more common.
>>
>>     But, like David, I'm not sure that we can add more Executors methods
>>     that don't amount to just replicating the TPE constructors.
>>     Maybe a builder, but that seems like overkill given the j.u.c
>> audience.
>>
>>     Some of these issues also affect ForkJoinPool, which we addressed by
>>     adding a configurable spare-thread limit and tolerance for bounded
>>     thread factories. It would also be possible to add a per-thread local
>>     queue-size limit, although the cases where it might come into play
>>     are uncommon and preventable using FJ status methods.
>>
>>     People facing these issues might also consider using the new
>>     SubmissionPublisher class, that pushes resource and flow control
>>     up one level: Producers need to pick buffer sizes, consumers
>>     explicitly perform requests, and you must choose per-item
>>     whether to use block vs drop vs timeout vs handler modes
>>     (methods submit, offer, and timed-offer, with optional drop
>>     handlers). These can be made to work well no matter what kind
>>     Executor you use, because the SubmissionPublisher deals with
>>     most of them instead of the Executor.
>>
>>         (and of course, we can try to write an actual better bounded
>>         thread pool not
>>         based on ThreadPoolExecutor, but that's actually hard)
>>
>>
>>     The main use case that j.u.c. lacks explicit coverage for
>>     is when there is known to be a single task submitter thread.
>>     FJP's multi-laned queues add some unnecessary data structure overhead
>>     and TPE's insistence on a queue implementation meeting the full
>>     BlockingQueue API adds some unnecessary sync overhead.
>>     In most usages, either choice is fine, but we might consider
>>     addressing this.
>>
>>     -Doug
>>
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> --
> - DML
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/f5de23fb/attachment.html>

From michael.x.mcmahon at oracle.com  Mon Sep 14 12:03:11 2015
From: michael.x.mcmahon at oracle.com (Michael McMahon)
Date: Mon, 14 Sep 2015 17:03:11 +0100
Subject: [concurrency-interest] question about j.u.c.Flow.Subscription
Message-ID: <55F6EFBF.4070908@oracle.com>

Hi,

I have a question about Flow subscribers and publishers.

Is it allowable for a j.u.c.Flow.Publisher to directly invoke a 
subscriber's methods
through its subscription object?

For example, can the implementation of Subscription.request(n)
call Subscriber.onNext() up to n times, before request() returns?

Considering that Subscriber.onNext() will often call Subscription.request()
you could easily get a recursive loop, but the question is whether
the spec allows it?

Thanks,
Michael.

From akarnokd at gmail.com  Mon Sep 14 12:39:15 2015
From: akarnokd at gmail.com (=?UTF-8?Q?D=C3=A1vid_Karnok?=)
Date: Mon, 14 Sep 2015 18:39:15 +0200
Subject: [concurrency-interest] question about j.u.c.Flow.Subscription
In-Reply-To: <55F6EFBF.4070908@oracle.com>
References: <55F6EFBF.4070908@oracle.com>
Message-ID: <CAAWwtm9S2tC2f1XZ-R9s2TRwK6cwxXPk4Q4pFWSpTgHgO7N+5g@mail.gmail.com>

Hello,

the original reactive-streams spec calls for limited recursion between
onNext() and request() which is what is the expectation in j.u.c.Flow as I
see.

There are several "schools" of implementing reentrant-safe and thread-safe
Subscriptions. I personally like to use atomic increments and separate
state flags whereas j.u.c. seems to use compact state values with CAS loops.

In fact, I can point you to a full-featuted fluent implementation of the
reactive-streams API that had to deal with this exact situation in many
forms and shapes.

2015-09-14 18:03 GMT+02:00 Michael McMahon <michael.x.mcmahon at oracle.com>:

> Hi,
>
> I have a question about Flow subscribers and publishers.
>
> Is it allowable for a j.u.c.Flow.Publisher to directly invoke a
> subscriber's methods
> through its subscription object?
>
> For example, can the implementation of Subscription.request(n)
> call Subscriber.onNext() up to n times, before request() returns?
>
> Considering that Subscriber.onNext() will often call Subscription.request()
> you could easily get a recursive loop, but the question is whether
> the spec allows it?
>
> Thanks,
> Michael.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Best regards,
David Karnok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/eb93a7dc/attachment.html>

From viktor.klang at gmail.com  Mon Sep 14 13:09:52 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 14 Sep 2015 19:09:52 +0200
Subject: [concurrency-interest] question about j.u.c.Flow.Subscription
In-Reply-To: <55F6EFBF.4070908@oracle.com>
References: <55F6EFBF.4070908@oracle.com>
Message-ID: <CANPzfU8To4JApEo69LGfrqQq2aZJQJ2RvVw-pTd4qcrj5apPaQ@mail.gmail.com>

Hi Michael,

It should be covered in the specification under the rule: 2:3

"Subscription.request MUST place an upper bound on possible synchronous
recursion between Publisherand Subscriber[1
<https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md#footnote-3-1>
]."

[1] : An example for undesirable synchronous, open recursion would be
Subscriber.onNext -> Subscription.request ->Subscriber.onNext -> ?, as it
very quickly would result in blowing the calling Thread?s stack.




The recommended upper bound would be 1, but it is of course up to the
implementation how it wants to do the "trampolining". This rule is also
tested in the TCK.

Does that cover your question?


(link to the 1.0.0 spec:
https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md
)

On Mon, Sep 14, 2015 at 6:03 PM, Michael McMahon <
michael.x.mcmahon at oracle.com> wrote:

> Hi,
>
> I have a question about Flow subscribers and publishers.
>
> Is it allowable for a j.u.c.Flow.Publisher to directly invoke a
> subscriber's methods
> through its subscription object?
>
> For example, can the implementation of Subscription.request(n)
> call Subscriber.onNext() up to n times, before request() returns?
>
> Considering that Subscriber.onNext() will often call Subscription.request()
> you could easily get a recursive loop, but the question is whether
> the spec allows it?
>
> Thanks,
> Michael.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/645a64c6/attachment.html>

From michael.x.mcmahon at oracle.com  Mon Sep 14 15:46:12 2015
From: michael.x.mcmahon at oracle.com (Michael McMahon)
Date: Mon, 14 Sep 2015 20:46:12 +0100
Subject: [concurrency-interest] question about j.u.c.Flow.Subscription
In-Reply-To: <CANPzfU8To4JApEo69LGfrqQq2aZJQJ2RvVw-pTd4qcrj5apPaQ@mail.gmail.com>
References: <55F6EFBF.4070908@oracle.com>
	<CANPzfU8To4JApEo69LGfrqQq2aZJQJ2RvVw-pTd4qcrj5apPaQ@mail.gmail.com>
Message-ID: <55F72404.1050103@oracle.com>

Thanks for the replies. The reactive streams specification seems to cover
all of these cases in quite a bit more detail than the javadoc.

Eg. rule 1.3 |onSubscribe|, |onNext|, |onError| and |onComplete| 
signaled to a |Subscriber| MUST be signaled sequentially (no concurrent 
notifications).

which suggests that onSubscribe() must return before onNext() can be 
called the first time. Otherwise,
I might have thought that onNext() could be called from a call to 
Subscription.request() inside
Subscriber.subscribe().

- Michael.

On 14/09/15 18:09, Viktor Klang wrote:
> Hi Michael,
>
> It should be covered in the specification under the rule: 2:3
>
> "|Subscription.request| MUST place an upper bound on possible 
> synchronous recursion between |Publisher|and |Subscriber|[1 
> <https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md#footnote-3-1>]."
>
> [1] : An example for undesirable synchronous, open recursion would be 
> |Subscriber.onNext| -> |Subscription.request| ->|Subscriber.onNext| -> 
> ?, as it very quickly would result in blowing the calling Thread?s stack.
>
>
>
>
> The recommended upper bound would be 1, but it is of course up to the 
> implementation how it wants to do the "trampolining". This rule is 
> also tested in the TCK.
>
> Does that cover your question?
>
>
> (link to the 1.0.0 spec: 
> https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md)
>
> On Mon, Sep 14, 2015 at 6:03 PM, Michael McMahon 
> <michael.x.mcmahon at oracle.com <mailto:michael.x.mcmahon at oracle.com>> 
> wrote:
>
>     Hi,
>
>     I have a question about Flow subscribers and publishers.
>
>     Is it allowable for a j.u.c.Flow.Publisher to directly invoke a
>     subscriber's methods
>     through its subscription object?
>
>     For example, can the implementation of Subscription.request(n)
>     call Subscriber.onNext() up to n times, before request() returns?
>
>     Considering that Subscriber.onNext() will often call
>     Subscription.request()
>     you could easily get a recursive loop, but the question is whether
>     the spec allows it?
>
>     Thanks,
>     Michael.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/920f59ee/attachment-0001.html>

From viktor.klang at gmail.com  Mon Sep 14 15:53:04 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 14 Sep 2015 21:53:04 +0200
Subject: [concurrency-interest] question about j.u.c.Flow.Subscription
In-Reply-To: <55F72404.1050103@oracle.com>
References: <55F6EFBF.4070908@oracle.com>
	<CANPzfU8To4JApEo69LGfrqQq2aZJQJ2RvVw-pTd4qcrj5apPaQ@mail.gmail.com>
	<55F72404.1050103@oracle.com>
Message-ID: <CANPzfU-+_4R0YTj7mjkRF-RxnRpuMH4fUpdL_X+7xaBPeE3wtg@mail.gmail.com>

Michael,

nested invocations does not count as concurrent (see discussion somewhere
around here
<https://github.com/reactive-streams/reactive-streams-jvm/issues/272#issuecomment-110083260>
),
it is recommended to, if demand is to be signalled from within
`onSubscribe` to put the `request` call at the end of that method.

On Mon, Sep 14, 2015 at 9:46 PM, Michael McMahon <
michael.x.mcmahon at oracle.com> wrote:

> Thanks for the replies. The reactive streams specification seems to cover
> all of these cases in quite a bit more detail than the javadoc.
>
> Eg. rule 1.3 onSubscribe, onNext, onError and onComplete signaled to a
> Subscriber MUST be signaled sequentially (no concurrent notifications).
>
> which suggests that onSubscribe() must return before onNext() can be
> called the first time. Otherwise,
> I might have thought that onNext() could be called from a call to
> Subscription.request() inside
> Subscriber.subscribe().
>
> - Michael.
>
>
> On 14/09/15 18:09, Viktor Klang wrote:
>
> Hi Michael,
>
> It should be covered in the specification under the rule: 2:3
>
> "Subscription.request MUST place an upper bound on possible synchronous
> recursion between Publisherand Subscriber[1
> <https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md#footnote-3-1>
> ]."
>
> [1] : An example for undesirable synchronous, open recursion would be
> Subscriber.onNext -> Subscription.request ->Subscriber.onNext -> ?, as it
> very quickly would result in blowing the calling Thread?s stack.
>
>
>
>
> The recommended upper bound would be 1, but it is of course up to the
> implementation how it wants to do the "trampolining". This rule is also
> tested in the TCK.
>
> Does that cover your question?
>
>
> (link to the 1.0.0 spec:
> <https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md>
> https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md
> )
>
> On Mon, Sep 14, 2015 at 6:03 PM, Michael McMahon <
> <michael.x.mcmahon at oracle.com>michael.x.mcmahon at oracle.com> wrote:
>
>> Hi,
>>
>> I have a question about Flow subscribers and publishers.
>>
>> Is it allowable for a j.u.c.Flow.Publisher to directly invoke a
>> subscriber's methods
>> through its subscription object?
>>
>> For example, can the implementation of Subscription.request(n)
>> call Subscriber.onNext() up to n times, before request() returns?
>>
>> Considering that Subscriber.onNext() will often call
>> Subscription.request()
>> you could easily get a recursive loop, but the question is whether
>> the spec allows it?
>>
>> Thanks,
>> Michael.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Cheers,
> ?
>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/49c4c383/attachment.html>

From viktor.klang at gmail.com  Mon Sep 14 15:56:57 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 14 Sep 2015 21:56:57 +0200
Subject: [concurrency-interest] question about j.u.c.Flow.Subscription
In-Reply-To: <CANPzfU-+_4R0YTj7mjkRF-RxnRpuMH4fUpdL_X+7xaBPeE3wtg@mail.gmail.com>
References: <55F6EFBF.4070908@oracle.com>
	<CANPzfU8To4JApEo69LGfrqQq2aZJQJ2RvVw-pTd4qcrj5apPaQ@mail.gmail.com>
	<55F72404.1050103@oracle.com>
	<CANPzfU-+_4R0YTj7mjkRF-RxnRpuMH4fUpdL_X+7xaBPeE3wtg@mail.gmail.com>
Message-ID: <CANPzfU-meM7Ki48MW0UMBrAKw0=jpnkPEf63ym_Q01sWEJ549A@mail.gmail.com>

And thanks to our conversation I now also remembered that I ought to
clarify that in the spec, so thank you!

On Mon, Sep 14, 2015 at 9:53 PM, Viktor Klang <viktor.klang at gmail.com>
wrote:

> Michael,
>
> nested invocations does not count as concurrent (see discussion somewhere
> around here
> <https://github.com/reactive-streams/reactive-streams-jvm/issues/272#issuecomment-110083260>
> ),
> it is recommended to, if demand is to be signalled from within
> `onSubscribe` to put the `request` call at the end of that method.
>
> On Mon, Sep 14, 2015 at 9:46 PM, Michael McMahon <
> michael.x.mcmahon at oracle.com> wrote:
>
>> Thanks for the replies. The reactive streams specification seems to cover
>> all of these cases in quite a bit more detail than the javadoc.
>>
>> Eg. rule 1.3 onSubscribe, onNext, onError and onComplete signaled to a
>> Subscriber MUST be signaled sequentially (no concurrent notifications).
>>
>> which suggests that onSubscribe() must return before onNext() can be
>> called the first time. Otherwise,
>> I might have thought that onNext() could be called from a call to
>> Subscription.request() inside
>> Subscriber.subscribe().
>>
>> - Michael.
>>
>>
>> On 14/09/15 18:09, Viktor Klang wrote:
>>
>> Hi Michael,
>>
>> It should be covered in the specification under the rule: 2:3
>>
>> "Subscription.request MUST place an upper bound on possible synchronous
>> recursion between Publisherand Subscriber[1
>> <https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md#footnote-3-1>
>> ]."
>>
>> [1] : An example for undesirable synchronous, open recursion would be
>> Subscriber.onNext -> Subscription.request ->Subscriber.onNext -> ?, as
>> it very quickly would result in blowing the calling Thread?s stack.
>>
>>
>>
>>
>> The recommended upper bound would be 1, but it is of course up to the
>> implementation how it wants to do the "trampolining". This rule is also
>> tested in the TCK.
>>
>> Does that cover your question?
>>
>>
>> (link to the 1.0.0 spec:
>> <https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md>
>> https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md
>> )
>>
>> On Mon, Sep 14, 2015 at 6:03 PM, Michael McMahon <
>> <michael.x.mcmahon at oracle.com>michael.x.mcmahon at oracle.com> wrote:
>>
>>> Hi,
>>>
>>> I have a question about Flow subscribers and publishers.
>>>
>>> Is it allowable for a j.u.c.Flow.Publisher to directly invoke a
>>> subscriber's methods
>>> through its subscription object?
>>>
>>> For example, can the implementation of Subscription.request(n)
>>> call Subscriber.onNext() up to n times, before request() returns?
>>>
>>> Considering that Subscriber.onNext() will often call
>>> Subscription.request()
>>> you could easily get a recursive loop, but the question is whether
>>> the spec allows it?
>>>
>>> Thanks,
>>> Michael.
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>>
>>
>
>
> --
> Cheers,
> ?
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/5e59dba4/attachment.html>

From thurston at nomagicsoftware.com  Mon Sep 14 18:12:55 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Mon, 14 Sep 2015 15:12:55 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <3367B1F0-E743-40DE-90F5-3FF99D10687A@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
	<37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>
	<1441703565844-12729.post@n7.nabble.com>
	<3367B1F0-E743-40DE-90F5-3FF99D10687A@oracle.com>
Message-ID: <1442268775373-12754.post@n7.nabble.com>

The reason I asked is that in JK8, Unsafe#getAndSetObject isn't even declared
native (looking at Unsafe.java) - I assume that means it isn't even eligible
for intrinsics (I was surprised that it wasn't native).

I came across some code (akka?) that was using some workaround because
(according to a comment) Unsafe#getAndSetObject wasn't intrinsified;
obviously that wasn't referring to jdk 9



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12754.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From vitalyd at gmail.com  Mon Sep 14 19:41:22 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 14 Sep 2015 19:41:22 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1442268775373-12754.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
	<37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>
	<1441703565844-12729.post@n7.nabble.com>
	<3367B1F0-E743-40DE-90F5-3FF99D10687A@oracle.com>
	<1442268775373-12754.post@n7.nabble.com>
Message-ID: <CAHjP37FHcWB2UCV6X5xpWWJ_F7mmai2CJK+NaZkJ1qGa6Nh2ZA@mail.gmail.com>

>
> The reason I asked is that in JK8, Unsafe#getAndSetObject isn't even
> declared
> native (looking at Unsafe.java) - I assume that means it isn't even
> eligible
> for intrinsics (I was surprised that it wasn't native).


Methods don't need to be native to be intrinsified.

http://bugs.java.com/bugdatabase/view_bug.do?bug_id=7023898 did the
intrinsification, which is available in java 8; just tried this on 8u40,
and getAndSetObject just emits XCHG (this is on x86_64).

On Mon, Sep 14, 2015 at 6:12 PM, thurstonn <thurston at nomagicsoftware.com>
wrote:

> The reason I asked is that in JK8, Unsafe#getAndSetObject isn't even
> declared
> native (looking at Unsafe.java) - I assume that means it isn't even
> eligible
> for intrinsics (I was surprised that it wasn't native).
>
> I came across some code (akka?) that was using some workaround because
> (according to a comment) Unsafe#getAndSetObject wasn't intrinsified;
> obviously that wasn't referring to jdk 9
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12754.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/6edc76a6/attachment-0001.html>

From thurston at nomagicsoftware.com  Mon Sep 14 19:29:43 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Mon, 14 Sep 2015 16:29:43 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37FHcWB2UCV6X5xpWWJ_F7mmai2CJK+NaZkJ1qGa6Nh2ZA@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
	<37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>
	<1441703565844-12729.post@n7.nabble.com>
	<3367B1F0-E743-40DE-90F5-3FF99D10687A@oracle.com>
	<1442268775373-12754.post@n7.nabble.com>
	<CAHjP37FHcWB2UCV6X5xpWWJ_F7mmai2CJK+NaZkJ1qGa6Nh2ZA@mail.gmail.com>
Message-ID: <1442273383774-12756.post@n7.nabble.com>

Thanks.

Uhh, nevermind.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12756.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From boehm at acm.org  Mon Sep 14 20:44:55 2015
From: boehm at acm.org (Hans Boehm)
Date: Mon, 14 Sep 2015 17:44:55 -0700
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55E97E05.6040700@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
Message-ID: <CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>

FWIW, this general issues is discussed in section 3 of
http://dl.acm.org/citation.cfm?id=1375581.1375591 .

Yet another argument against providing the stronger guarantees is that, on
many architectures, it doesn't just slow down trylock(), it more
importantly slows down lock().  In general, if your code cares about
ordering for unsuccessful trylock(), then it's not robust against, say, a
debugging thread unexpectedly acquiring the lock for a short period.  In my
view, in such a case, you're no longer using it as a lock, and you should
be using something else, e.g. an atomic object, with stronger guarantees.

On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>
>> Has anyone come up with the answer about ordering for tryLock, or have I
>> missed it?
>>
>
> You missed the dog not barking :-)
>
> The Lock specs don't require any specific HB effects here on failed
> tryLock. Even if we wanted to, we cannot retroactively impose any
> considering that anyone can implement the Lock interface (not just j.u.c)
> and some of these might become in violation.
>
> As you and Vitaly pointed out, there are a few fringe cases where
> users might want to impose ordering on failure. In jdk9, you'll
> me able to do this with moded VarHandle accesses and/or fences. The
> resulting extra fencing might be redundant here and there, but if you
> cared enough, you could create and rely on custom locks with stronger
> guarantees.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/ad8ece65/attachment.html>

From vitalyd at gmail.com  Mon Sep 14 21:41:22 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 14 Sep 2015 21:41:22 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
Message-ID: <CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>

How does it slow down lock()?

I don't necessarily disagree but I can certainly see people considering
tryLock to have same ordering effect as (failed) CAS.  It's certainly true
that a CAS is a lower level primitive than a lock, but I don't know if that
resonates immediately when thinking about this.  It's also the case that on
very popular platforms such as x86 a failing tryLock will have the same
ordering as a successful one, and no difference is observed (and JIT
doesn't do anything different).

I don't understand the debugger thread example - what's the issue there?

sent from my phone
On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:

> FWIW, this general issues is discussed in section 3 of
> http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>
> Yet another argument against providing the stronger guarantees is that, on
> many architectures, it doesn't just slow down trylock(), it more
> importantly slows down lock().  In general, if your code cares about
> ordering for unsuccessful trylock(), then it's not robust against, say, a
> debugging thread unexpectedly acquiring the lock for a short period.  In my
> view, in such a case, you're no longer using it as a lock, and you should
> be using something else, e.g. an atomic object, with stronger guarantees.
>
> On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>
>> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>
>>> Has anyone come up with the answer about ordering for tryLock, or have I
>>> missed it?
>>>
>>
>> You missed the dog not barking :-)
>>
>> The Lock specs don't require any specific HB effects here on failed
>> tryLock. Even if we wanted to, we cannot retroactively impose any
>> considering that anyone can implement the Lock interface (not just j.u.c)
>> and some of these might become in violation.
>>
>> As you and Vitaly pointed out, there are a few fringe cases where
>> users might want to impose ordering on failure. In jdk9, you'll
>> me able to do this with moded VarHandle accesses and/or fences. The
>> resulting extra fencing might be redundant here and there, but if you
>> cared enough, you could create and rely on custom locks with stronger
>> guarantees.
>>
>> -Doug
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/e880872b/attachment.html>

From boehm at acm.org  Tue Sep 15 01:16:07 2015
From: boehm at acm.org (Hans Boehm)
Date: Mon, 14 Sep 2015 22:16:07 -0700
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
Message-ID: <CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>

> How does it slow down lock()?

It depends on the precise guarantee you provide, and I suspect this thread
didn't quite agree on that.  The most natural one is that the succeeding
lock acquisition happens before the failed trylock().  That implies that if
we have

x = 1;
lock();

those can't be reordered by the hardware, since a failing trylock() would
have to see the assignment to x.  That requires a fence between them on ARM
or Power.

I think the right way to think of trylock(), at least informally, is as
allowing spurious failures. I.e. trylock() is allowed to behave as though
the lock was held when it isn't.  You thus can't conclude anything about
other threads from the fact that it failed.  In this view you don't have to
think about memory ordering issues when reasoning about correctness, you
just reason about spurious failures instead.

If your code is robust against unknown, e.g. debugger, threads acquiring
the lock now and then, then it must be robust against this sort of spurious
failure.  If the lock is really used only to provide mutual exclusion, this
should not affect correctness.

On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich <vitalyd at gmail.com>
wrote:

> How does it slow down lock()?
>
> I don't necessarily disagree but I can certainly see people considering
> tryLock to have same ordering effect as (failed) CAS.  It's certainly true
> that a CAS is a lower level primitive than a lock, but I don't know if that
> resonates immediately when thinking about this.  It's also the case that on
> very popular platforms such as x86 a failing tryLock will have the same
> ordering as a successful one, and no difference is observed (and JIT
> doesn't do anything different).
>
> I don't understand the debugger thread example - what's the issue there?
>
> sent from my phone
> On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:
>
>> FWIW, this general issues is discussed in section 3 of
>> http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>
>> Yet another argument against providing the stronger guarantees is that,
>> on many architectures, it doesn't just slow down trylock(), it more
>> importantly slows down lock().  In general, if your code cares about
>> ordering for unsuccessful trylock(), then it's not robust against, say, a
>> debugging thread unexpectedly acquiring the lock for a short period.  In my
>> view, in such a case, you're no longer using it as a lock, and you should
>> be using something else, e.g. an atomic object, with stronger guarantees.
>>
>> On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>
>>> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>>
>>>> Has anyone come up with the answer about ordering for tryLock, or have
>>>> I missed it?
>>>>
>>>
>>> You missed the dog not barking :-)
>>>
>>> The Lock specs don't require any specific HB effects here on failed
>>> tryLock. Even if we wanted to, we cannot retroactively impose any
>>> considering that anyone can implement the Lock interface (not just j.u.c)
>>> and some of these might become in violation.
>>>
>>> As you and Vitaly pointed out, there are a few fringe cases where
>>> users might want to impose ordering on failure. In jdk9, you'll
>>> me able to do this with moded VarHandle accesses and/or fences. The
>>> resulting extra fencing might be redundant here and there, but if you
>>> cared enough, you could create and rely on custom locks with stronger
>>> guarantees.
>>>
>>> -Doug
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150914/f5b904a5/attachment-0001.html>

From vitalyd at gmail.com  Tue Sep 15 08:56:21 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 15 Sep 2015 08:56:21 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
Message-ID: <CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>

Hmm, the ordering I had in mind was unlock() happens-before a failing
tryLock.  So a thread failing on tryLock sees operations preceded by last
unlock() as ordered.  This is no different than successful tryLock or
lock() in that regard.

sent from my phone
On Sep 15, 2015 1:16 AM, "Hans Boehm" <boehm at acm.org> wrote:

> > How does it slow down lock()?
>
> It depends on the precise guarantee you provide, and I suspect this thread
> didn't quite agree on that.  The most natural one is that the succeeding
> lock acquisition happens before the failed trylock().  That implies that if
> we have
>
> x = 1;
> lock();
>
> those can't be reordered by the hardware, since a failing trylock() would
> have to see the assignment to x.  That requires a fence between them on ARM
> or Power.
>
> I think the right way to think of trylock(), at least informally, is as
> allowing spurious failures. I.e. trylock() is allowed to behave as though
> the lock was held when it isn't.  You thus can't conclude anything about
> other threads from the fact that it failed.  In this view you don't have to
> think about memory ordering issues when reasoning about correctness, you
> just reason about spurious failures instead.
>
> If your code is robust against unknown, e.g. debugger, threads acquiring
> the lock now and then, then it must be robust against this sort of spurious
> failure.  If the lock is really used only to provide mutual exclusion, this
> should not affect correctness.
>
> On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
>
>> How does it slow down lock()?
>>
>> I don't necessarily disagree but I can certainly see people considering
>> tryLock to have same ordering effect as (failed) CAS.  It's certainly true
>> that a CAS is a lower level primitive than a lock, but I don't know if that
>> resonates immediately when thinking about this.  It's also the case that on
>> very popular platforms such as x86 a failing tryLock will have the same
>> ordering as a successful one, and no difference is observed (and JIT
>> doesn't do anything different).
>>
>> I don't understand the debugger thread example - what's the issue there?
>>
>> sent from my phone
>> On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:
>>
>>> FWIW, this general issues is discussed in section 3 of
>>> http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>>
>>> Yet another argument against providing the stronger guarantees is that,
>>> on many architectures, it doesn't just slow down trylock(), it more
>>> importantly slows down lock().  In general, if your code cares about
>>> ordering for unsuccessful trylock(), then it's not robust against, say, a
>>> debugging thread unexpectedly acquiring the lock for a short period.  In my
>>> view, in such a case, you're no longer using it as a lock, and you should
>>> be using something else, e.g. an atomic object, with stronger guarantees.
>>>
>>> On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>>
>>>> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>>>
>>>>> Has anyone come up with the answer about ordering for tryLock, or have
>>>>> I missed it?
>>>>>
>>>>
>>>> You missed the dog not barking :-)
>>>>
>>>> The Lock specs don't require any specific HB effects here on failed
>>>> tryLock. Even if we wanted to, we cannot retroactively impose any
>>>> considering that anyone can implement the Lock interface (not just
>>>> j.u.c)
>>>> and some of these might become in violation.
>>>>
>>>> As you and Vitaly pointed out, there are a few fringe cases where
>>>> users might want to impose ordering on failure. In jdk9, you'll
>>>> me able to do this with moded VarHandle accesses and/or fences. The
>>>> resulting extra fencing might be redundant here and there, but if you
>>>> cared enough, you could create and rely on custom locks with stronger
>>>> guarantees.
>>>>
>>>> -Doug
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150915/5468dbd3/attachment.html>

From peter.levart at gmail.com  Tue Sep 15 16:52:56 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Tue, 15 Sep 2015 22:52:56 +0200
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
	<CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>
Message-ID: <55F88528.9070503@gmail.com>



On 09/15/2015 02:56 PM, Vitaly Davidovich wrote:
>
> Hmm, the ordering I had in mind was unlock() happens-before a failing 
> tryLock.  So a thread failing on tryLock sees operations preceded by 
> last unlock() as ordered. This is no different than successful tryLock 
> or lock() in that regard.
>

How can you differentiate between:
- unlock() in thread T1 followed by unsuccessful tryLock() in thread T2 and
- unsuccessfull tryLock() in T2 followed by unlock() in T1

You want T1 to already unlock before you observe tryLock() failing in T2 
(pressumably because some T3 has already obtained the lock before T2 or 
because of spurious failure).
But T2 failing tryLock() might simply be because T1 hasn't unlocked yet. 
So regardless of memory effects, you can't reason of ordering in other 
threads by observing tryLock() failing.

Do you have an example that proves me wrong?

Regards, Peter

> sent from my phone
>
> On Sep 15, 2015 1:16 AM, "Hans Boehm" <boehm at acm.org 
> <mailto:boehm at acm.org>> wrote:
>
>     > How does it slow down lock()?
>
>     It depends on the precise guarantee you provide, and I suspect
>     this thread didn't quite agree on that.  The most natural one is
>     that the succeeding lock acquisition happens before the failed
>     trylock().  That implies that if we have
>
>     x = 1;
>     lock();
>
>     those can't be reordered by the hardware, since a failing
>     trylock() would have to see the assignment to x.  That requires a
>     fence between them on ARM or Power.
>
>     I think the right way to think of trylock(), at least informally,
>     is as allowing spurious failures. I.e. trylock() is allowed to
>     behave as though the lock was held when it isn't.  You thus can't
>     conclude anything about other threads from the fact that it
>     failed.  In this view you don't have to think about memory
>     ordering issues when reasoning about correctness, you just reason
>     about spurious failures instead.
>
>     If your code is robust against unknown, e.g. debugger, threads
>     acquiring the lock now and then, then it must be robust against
>     this sort of spurious failure.  If the lock is really used only to
>     provide mutual exclusion, this should not affect correctness.
>
>     On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich
>     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>
>         How does it slow down lock()?
>
>         I don't necessarily disagree but I can certainly see people
>         considering tryLock to have same ordering effect as (failed)
>         CAS.  It's certainly true that a CAS is a lower level
>         primitive than a lock, but I don't know if that resonates
>         immediately when thinking about this.  It's also the case that
>         on very popular platforms such as x86 a failing tryLock will
>         have the same ordering as a successful one, and no difference
>         is observed (and JIT doesn't do anything different).
>
>         I don't understand the debugger thread example - what's the
>         issue there?
>
>         sent from my phone
>
>         On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org
>         <mailto:boehm at acm.org>> wrote:
>
>             FWIW, this general issues is discussed in section 3 of
>             http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>
>             Yet another argument against providing the stronger
>             guarantees is that, on many architectures, it doesn't just
>             slow down trylock(), it more importantly slows down
>             lock().  In general, if your code cares about ordering for
>             unsuccessful trylock(), then it's not robust against, say,
>             a debugging thread unexpectedly acquiring the lock for a
>             short period.  In my view, in such a case, you're no
>             longer using it as a lock, and you should be using
>             something else, e.g. an atomic object, with stronger
>             guarantees.
>
>             On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu
>             <mailto:dl at cs.oswego.edu>> wrote:
>
>                 On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>
>                     Has anyone come up with the answer about ordering
>                     for tryLock, or have I missed it?
>
>
>                 You missed the dog not barking :-)
>
>                 The Lock specs don't require any specific HB effects
>                 here on failed
>                 tryLock. Even if we wanted to, we cannot retroactively
>                 impose any
>                 considering that anyone can implement the Lock
>                 interface (not just j.u.c)
>                 and some of these might become in violation.
>
>                 As you and Vitaly pointed out, there are a few fringe
>                 cases where
>                 users might want to impose ordering on failure. In
>                 jdk9, you'll
>                 me able to do this with moded VarHandle accesses
>                 and/or fences. The
>                 resulting extra fencing might be redundant here and
>                 there, but if you
>                 cared enough, you could create and rely on custom
>                 locks with stronger
>                 guarantees.
>
>                 -Doug
>
>
>                 _______________________________________________
>                 Concurrency-interest mailing list
>                 Concurrency-interest at cs.oswego.edu
>                 <mailto:Concurrency-interest at cs.oswego.edu>
>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150915/bd4c73a7/attachment.html>

From vitalyd at gmail.com  Tue Sep 15 21:26:17 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 15 Sep 2015 21:26:17 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55F88528.9070503@gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
	<CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>
	<55F88528.9070503@gmail.com>
Message-ID: <CAHjP37Hz4PbSE1v=VN9Z0Sh=VHDSY4DtCLFs+mwy3GDhtNVQXQ@mail.gmail.com>

You'd differentiate via whatever protocol is chosen by implementation, i.e.
some state that would be set to signal phase changes.  The closest analog
is code using CAS, successful or not, to piggyback ordering for surrounding
memory ops.  I gave an example upthread where threads compete to get
exclusive right to close a socket using tryLock; one thread wins and closes
the socket, and losers skip closing the socket but proceed to use memory
set inside unlock().  It's a semi contrived example since normally you'd
use a CAS for something like this, but it illustrates the gist of what I'm
getting at.  Of course you can solve these situations using dedicated
atomic (or otherwise threadsafe) state, but perhaps one wants to piggyback
on existing critical section's fences and not add additional ones.

sent from my phone
On Sep 15, 2015 4:52 PM, "Peter Levart" <peter.levart at gmail.com> wrote:

>
>
> On 09/15/2015 02:56 PM, Vitaly Davidovich wrote:
>
> Hmm, the ordering I had in mind was unlock() happens-before a failing
> tryLock.  So a thread failing on tryLock sees operations preceded by last
> unlock() as ordered.  This is no different than successful tryLock or
> lock() in that regard.
>
>
> How can you differentiate between:
> - unlock() in thread T1 followed by unsuccessful tryLock() in thread T2 and
> - unsuccessfull tryLock() in T2 followed by unlock() in T1
>
> You want T1 to already unlock before you observe tryLock() failing in T2
> (pressumably because some T3 has already obtained the lock before T2 or
> because of spurious failure).
> But T2 failing tryLock() might simply be because T1 hasn't unlocked yet.
> So regardless of memory effects, you can't reason of ordering in other
> threads by observing tryLock() failing.
>
> Do you have an example that proves me wrong?
>
> Regards, Peter
>
> sent from my phone
> On Sep 15, 2015 1:16 AM, "Hans Boehm" <boehm at acm.org> wrote:
>
>> > How does it slow down lock()?
>>
>> It depends on the precise guarantee you provide, and I suspect this
>> thread didn't quite agree on that.  The most natural one is that the
>> succeeding lock acquisition happens before the failed trylock().  That
>> implies that if we have
>>
>> x = 1;
>> lock();
>>
>> those can't be reordered by the hardware, since a failing trylock() would
>> have to see the assignment to x.  That requires a fence between them on ARM
>> or Power.
>>
>> I think the right way to think of trylock(), at least informally, is as
>> allowing spurious failures. I.e. trylock() is allowed to behave as though
>> the lock was held when it isn't.  You thus can't conclude anything about
>> other threads from the fact that it failed.  In this view you don't have to
>> think about memory ordering issues when reasoning about correctness, you
>> just reason about spurious failures instead.
>>
>> If your code is robust against unknown, e.g. debugger, threads acquiring
>> the lock now and then, then it must be robust against this sort of spurious
>> failure.  If the lock is really used only to provide mutual exclusion, this
>> should not affect correctness.
>>
>> On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> wrote:
>>
>>> How does it slow down lock()?
>>>
>>> I don't necessarily disagree but I can certainly see people considering
>>> tryLock to have same ordering effect as (failed) CAS.  It's certainly true
>>> that a CAS is a lower level primitive than a lock, but I don't know if that
>>> resonates immediately when thinking about this.  It's also the case that on
>>> very popular platforms such as x86 a failing tryLock will have the same
>>> ordering as a successful one, and no difference is observed (and JIT
>>> doesn't do anything different).
>>>
>>> I don't understand the debugger thread example - what's the issue there?
>>>
>>> sent from my phone
>>> On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:
>>>
>>>> FWIW, this general issues is discussed in section 3 of
>>>> http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>>>
>>>> Yet another argument against providing the stronger guarantees is that,
>>>> on many architectures, it doesn't just slow down trylock(), it more
>>>> importantly slows down lock().  In general, if your code cares about
>>>> ordering for unsuccessful trylock(), then it's not robust against, say, a
>>>> debugging thread unexpectedly acquiring the lock for a short period.  In my
>>>> view, in such a case, you're no longer using it as a lock, and you should
>>>> be using something else, e.g. an atomic object, with stronger guarantees.
>>>>
>>>> On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>>>
>>>>> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>>>>
>>>>>> Has anyone come up with the answer about ordering for tryLock, or
>>>>>> have I missed it?
>>>>>>
>>>>>
>>>>> You missed the dog not barking :-)
>>>>>
>>>>> The Lock specs don't require any specific HB effects here on failed
>>>>> tryLock. Even if we wanted to, we cannot retroactively impose any
>>>>> considering that anyone can implement the Lock interface (not just
>>>>> j.u.c)
>>>>> and some of these might become in violation.
>>>>>
>>>>> As you and Vitaly pointed out, there are a few fringe cases where
>>>>> users might want to impose ordering on failure. In jdk9, you'll
>>>>> me able to do this with moded VarHandle accesses and/or fences. The
>>>>> resulting extra fencing might be redundant here and there, but if you
>>>>> cared enough, you could create and rely on custom locks with stronger
>>>>> guarantees.
>>>>>
>>>>> -Doug
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150915/928a2aac/attachment-0001.html>

From peter.levart at gmail.com  Wed Sep 16 03:12:10 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 16 Sep 2015 09:12:10 +0200
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37Hz4PbSE1v=VN9Z0Sh=VHDSY4DtCLFs+mwy3GDhtNVQXQ@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
	<CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>
	<55F88528.9070503@gmail.com>
	<CAHjP37Hz4PbSE1v=VN9Z0Sh=VHDSY4DtCLFs+mwy3GDhtNVQXQ@mail.gmail.com>
Message-ID: <55F9164A.6020100@gmail.com>



On 09/16/2015 03:26 AM, Vitaly Davidovich wrote:
>
> You'd differentiate via whatever protocol is chosen by implementation, 
> i.e. some state that would be set to signal phase changes.  The 
> closest analog is code using CAS, successful or not, to piggyback 
> ordering for surrounding memory ops.
>

You can piggyback ordering of surrounding memory ops if you can reason 
about the phase changes using the state manipulated by CAS even in case 
of a failed CAS if that failure is guaranteed to not be spurious. It's 
the same with lock, but only if the tryLock succeeds. I argue that you 
can not reason about the phase of other thread(s) on the failed tryLock 
even if that is not a spurious failure. A non-spurious tryLock failure 
simply means that some thread has a lock, but does not tell which one.

>   I gave an example upthread where threads compete to get exclusive 
> right to close a socket using tryLock; one thread wins and closes the 
> socket, and losers skip closing the socket but proceed to use memory 
> set inside unlock().  It's a semi contrived example since normally 
> you'd use a CAS for something like this, but it illustrates the gist 
> of what I'm getting at. Of course you can solve these situations using 
> dedicated atomic (or otherwise threadsafe) state, but perhaps one 
> wants to piggyback on existing critical section's fences and not add 
> additional ones.
>

Ah, I see. The following example, right?

On 09/04/2015 05:09 AM, Vitaly Davidovich wrote:
>
> If thread A releases a lock and threads B and C tryLock it, with one 
> succeeding, the failing thread may want to do something else but wants 
> a happens-before edge with the lock release - that's the general use 
> case.  As a simple example, consider two threads tryLock'ing to 
> acquire the exclusive right to close a socket and then perform some 
> additional actions that require ordering of actions done by the 
> releasing thread.  The thread failing to acquire the lock will skip 
> closing the socket but will proceed to do some work that requires 
> happens-before edge.  This is typically done using CAS, with one 
> thread successfully flipping the state, and the others just skip that 
> action that's guarded by the CAS, but can proceed with doing 
> subsequent work.  In other words, one may want to piggyback on the 
> unlock/tryLock to provide the ordering rather than introducing 
> additional dedicated state for this.
>

That's exactly what I'm talking about. B or C failing tryLock doesn't 
mean one of them succeeded (how would any of B or C know that the other 
succeeded if there's no other communication between the two?). It could 
simply mean that both failed because A hasn't released the lock yet. If 
the later is the case, then any relaxed memory operations performed by A 
before releasing the lock can be observed in B or C failing tryLock in 
arbitrary order regardless of whether failed tryLock "guarantees" 
ordering or not, because there hasn't been an unlock in A yet. If those 
operations are not relaxed but follow some release/acquire or SC 
semantics, then they operate by themselves and don't require a failed 
tryLock to guarantee ordering.

Regards, Peter

> sent from my phone
>
> On Sep 15, 2015 4:52 PM, "Peter Levart" <peter.levart at gmail.com 
> <mailto:peter.levart at gmail.com>> wrote:
>
>
>
>     On 09/15/2015 02:56 PM, Vitaly Davidovich wrote:
>>
>>     Hmm, the ordering I had in mind was unlock() happens-before a
>>     failing tryLock.  So a thread failing on tryLock sees operations
>>     preceded by last unlock() as ordered.  This is no different than
>>     successful tryLock or lock() in that regard.
>>
>
>     How can you differentiate between:
>     - unlock() in thread T1 followed by unsuccessful tryLock() in
>     thread T2 and
>     - unsuccessfull tryLock() in T2 followed by unlock() in T1
>
>     You want T1 to already unlock before you observe tryLock() failing
>     in T2 (pressumably because some T3 has already obtained the lock
>     before T2 or because of spurious failure).
>     But T2 failing tryLock() might simply be because T1 hasn't
>     unlocked yet. So regardless of memory effects, you can't reason of
>     ordering in other threads by observing tryLock() failing.
>
>     Do you have an example that proves me wrong?
>
>     Regards, Peter
>
>>     sent from my phone
>>
>>     On Sep 15, 2015 1:16 AM, "Hans Boehm" <boehm at acm.org
>>     <mailto:boehm at acm.org>> wrote:
>>
>>         > How does it slow down lock()?
>>
>>         It depends on the precise guarantee you provide, and I
>>         suspect this thread didn't quite agree on that.  The most
>>         natural one is that the succeeding lock acquisition happens
>>         before the failed trylock().  That implies that if we have
>>
>>         x = 1;
>>         lock();
>>
>>         those can't be reordered by the hardware, since a failing
>>         trylock() would have to see the assignment to x.  That
>>         requires a fence between them on ARM or Power.
>>
>>         I think the right way to think of trylock(), at least
>>         informally, is as allowing spurious failures. I.e. trylock()
>>         is allowed to behave as though the lock was held when it
>>         isn't.  You thus can't conclude anything about other threads
>>         from the fact that it failed.  In this view you don't have to
>>         think about memory ordering issues when reasoning about
>>         correctness, you just reason about spurious failures instead.
>>
>>         If your code is robust against unknown, e.g. debugger,
>>         threads acquiring the lock now and then, then it must be
>>         robust against this sort of spurious failure.  If the lock is
>>         really used only to provide mutual exclusion, this should not
>>         affect correctness.
>>
>>         On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich
>>         <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>>
>>             How does it slow down lock()?
>>
>>             I don't necessarily disagree but I can certainly see
>>             people considering tryLock to have same ordering effect
>>             as (failed) CAS. It's certainly true that a CAS is a
>>             lower level primitive than a lock, but I don't know if
>>             that resonates immediately when thinking about this. 
>>             It's also the case that on very popular platforms such as
>>             x86 a failing tryLock will have the same ordering as a
>>             successful one, and no difference is observed (and JIT
>>             doesn't do anything different).
>>
>>             I don't understand the debugger thread example - what's
>>             the issue there?
>>
>>             sent from my phone
>>
>>             On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org
>>             <mailto:boehm at acm.org>> wrote:
>>
>>                 FWIW, this general issues is discussed in section 3
>>                 of http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>
>>                 Yet another argument against providing the stronger
>>                 guarantees is that, on many architectures, it doesn't
>>                 just slow down trylock(), it more importantly slows
>>                 down lock(). In general, if your code cares about
>>                 ordering for unsuccessful trylock(), then it's not
>>                 robust against, say, a debugging thread unexpectedly
>>                 acquiring the lock for a short period.  In my view,
>>                 in such a case, you're no longer using it as a lock,
>>                 and you should be using something else, e.g. an
>>                 atomic object, with stronger guarantees.
>>
>>                 On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea
>>                 <dl at cs.oswego.edu <mailto:dl at cs.oswego.edu>> wrote:
>>
>>                     On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>
>>                         Has anyone come up with the answer about
>>                         ordering for tryLock, or have I missed it?
>>
>>
>>                     You missed the dog not barking :-)
>>
>>                     The Lock specs don't require any specific HB
>>                     effects here on failed
>>                     tryLock. Even if we wanted to, we cannot
>>                     retroactively impose any
>>                     considering that anyone can implement the Lock
>>                     interface (not just j.u.c)
>>                     and some of these might become in violation.
>>
>>                     As you and Vitaly pointed out, there are a few
>>                     fringe cases where
>>                     users might want to impose ordering on failure.
>>                     In jdk9, you'll
>>                     me able to do this with moded VarHandle accesses
>>                     and/or fences. The
>>                     resulting extra fencing might be redundant here
>>                     and there, but if you
>>                     cared enough, you could create and rely on custom
>>                     locks with stronger
>>                     guarantees.
>>
>>                     -Doug
>>
>>
>>                     _______________________________________________
>>                     Concurrency-interest mailing list
>>                     Concurrency-interest at cs.oswego.edu
>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>                 _______________________________________________
>>                 Concurrency-interest mailing list
>>                 Concurrency-interest at cs.oswego.edu
>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150916/89b44f5a/attachment-0001.html>

From vitalyd at gmail.com  Wed Sep 16 09:53:38 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 16 Sep 2015 09:53:38 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55F9164A.6020100@gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
	<CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>
	<55F88528.9070503@gmail.com>
	<CAHjP37Hz4PbSE1v=VN9Z0Sh=VHDSY4DtCLFs+mwy3GDhtNVQXQ@mail.gmail.com>
	<55F9164A.6020100@gmail.com>
Message-ID: <CAHjP37GLR3bmAr4ViEZbG03A7urOyOAkYXH_6W+9vSBeY3b2ag@mail.gmail.com>

Yes, I agree with what you're saying.  My initial gripe was with difference
between failing tryLock and CAS, but given that a CAS is done against
communicated state, it makes sense to have different ordering semantics on
failure.  Also, given more granular fencing will be available, it's easier
and more straightforward to explicitly indicate more precise ordering when
needed.

sent from my phone
On Sep 16, 2015 3:12 AM, "Peter Levart" <peter.levart at gmail.com> wrote:

>
>
> On 09/16/2015 03:26 AM, Vitaly Davidovich wrote:
>
> You'd differentiate via whatever protocol is chosen by implementation,
> i.e. some state that would be set to signal phase changes.  The closest
> analog is code using CAS, successful or not, to piggyback ordering for
> surrounding memory ops.
>
>
> You can piggyback ordering of surrounding memory ops if you can reason
> about the phase changes using the state manipulated by CAS even in case of
> a failed CAS if that failure is guaranteed to not be spurious. It's the
> same with lock, but only if the tryLock succeeds. I argue that you can not
> reason about the phase of other thread(s) on the failed tryLock even if
> that is not a spurious failure. A non-spurious tryLock failure simply means
> that some thread has a lock, but does not tell which one.
>
>   I gave an example upthread where threads compete to get exclusive right
> to close a socket using tryLock; one thread wins and closes the socket, and
> losers skip closing the socket but proceed to use memory set inside
> unlock().  It's a semi contrived example since normally you'd use a CAS for
> something like this, but it illustrates the gist of what I'm getting at.
> Of course you can solve these situations using dedicated atomic (or
> otherwise threadsafe) state, but perhaps one wants to piggyback on existing
> critical section's fences and not add additional ones.
>
>
> Ah, I see. The following example, right?
>
> On 09/04/2015 05:09 AM, Vitaly Davidovich wrote:
>
> If thread A releases a lock and threads B and C tryLock it, with one
> succeeding, the failing thread may want to do something else but wants a
> happens-before edge with the lock release - that's the general use case.
> As a simple example, consider two threads tryLock'ing to acquire the
> exclusive right to close a socket and then perform some additional actions
> that require ordering of actions done by the releasing thread.  The thread
> failing to acquire the lock will skip closing the socket but will proceed
> to do some work that requires happens-before edge.  This is typically done
> using CAS, with one thread successfully flipping the state, and the others
> just skip that action that's guarded by the CAS, but can proceed with doing
> subsequent work.  In other words, one may want to piggyback on the
> unlock/tryLock to provide the ordering rather than introducing additional
> dedicated state for this.
>
>
> That's exactly what I'm talking about. B or C failing tryLock doesn't mean
> one of them succeeded (how would any of B or C know that the other
> succeeded if there's no other communication between the two?). It could
> simply mean that both failed because A hasn't released the lock yet. If the
> later is the case, then any relaxed memory operations performed by A before
> releasing the lock can be observed in B or C failing tryLock in arbitrary
> order regardless of whether failed tryLock "guarantees" ordering or not,
> because there hasn't been an unlock in A yet. If those operations are not
> relaxed but follow some release/acquire or SC semantics, then they operate
> by themselves and don't require a failed tryLock to guarantee ordering.
>
> Regards, Peter
>
> sent from my phone
> On Sep 15, 2015 4:52 PM, "Peter Levart" <peter.levart at gmail.com> wrote:
>
>>
>>
>> On 09/15/2015 02:56 PM, Vitaly Davidovich wrote:
>>
>> Hmm, the ordering I had in mind was unlock() happens-before a failing
>> tryLock.  So a thread failing on tryLock sees operations preceded by last
>> unlock() as ordered.  This is no different than successful tryLock or
>> lock() in that regard.
>>
>>
>> How can you differentiate between:
>> - unlock() in thread T1 followed by unsuccessful tryLock() in thread T2
>> and
>> - unsuccessfull tryLock() in T2 followed by unlock() in T1
>>
>> You want T1 to already unlock before you observe tryLock() failing in T2
>> (pressumably because some T3 has already obtained the lock before T2 or
>> because of spurious failure).
>> But T2 failing tryLock() might simply be because T1 hasn't unlocked yet.
>> So regardless of memory effects, you can't reason of ordering in other
>> threads by observing tryLock() failing.
>>
>> Do you have an example that proves me wrong?
>>
>> Regards, Peter
>>
>> sent from my phone
>> On Sep 15, 2015 1:16 AM, "Hans Boehm" <boehm at acm.org> wrote:
>>
>>> > How does it slow down lock()?
>>>
>>> It depends on the precise guarantee you provide, and I suspect this
>>> thread didn't quite agree on that.  The most natural one is that the
>>> succeeding lock acquisition happens before the failed trylock().  That
>>> implies that if we have
>>>
>>> x = 1;
>>> lock();
>>>
>>> those can't be reordered by the hardware, since a failing trylock()
>>> would have to see the assignment to x.  That requires a fence between them
>>> on ARM or Power.
>>>
>>> I think the right way to think of trylock(), at least informally, is as
>>> allowing spurious failures. I.e. trylock() is allowed to behave as though
>>> the lock was held when it isn't.  You thus can't conclude anything about
>>> other threads from the fact that it failed.  In this view you don't have to
>>> think about memory ordering issues when reasoning about correctness, you
>>> just reason about spurious failures instead.
>>>
>>> If your code is robust against unknown, e.g. debugger, threads acquiring
>>> the lock now and then, then it must be robust against this sort of spurious
>>> failure.  If the lock is really used only to provide mutual exclusion, this
>>> should not affect correctness.
>>>
>>> On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich <vitalyd at gmail.com>
>>> wrote:
>>>
>>>> How does it slow down lock()?
>>>>
>>>> I don't necessarily disagree but I can certainly see people considering
>>>> tryLock to have same ordering effect as (failed) CAS.  It's certainly true
>>>> that a CAS is a lower level primitive than a lock, but I don't know if that
>>>> resonates immediately when thinking about this.  It's also the case that on
>>>> very popular platforms such as x86 a failing tryLock will have the same
>>>> ordering as a successful one, and no difference is observed (and JIT
>>>> doesn't do anything different).
>>>>
>>>> I don't understand the debugger thread example - what's the issue there?
>>>>
>>>> sent from my phone
>>>> On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:
>>>>
>>>>> FWIW, this general issues is discussed in section 3 of
>>>>> http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>>>>
>>>>> Yet another argument against providing the stronger guarantees is
>>>>> that, on many architectures, it doesn't just slow down trylock(), it more
>>>>> importantly slows down lock().  In general, if your code cares about
>>>>> ordering for unsuccessful trylock(), then it's not robust against, say, a
>>>>> debugging thread unexpectedly acquiring the lock for a short period.  In my
>>>>> view, in such a case, you're no longer using it as a lock, and you should
>>>>> be using something else, e.g. an atomic object, with stronger guarantees.
>>>>>
>>>>> On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>>>>
>>>>>> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>>>>>
>>>>>>> Has anyone come up with the answer about ordering for tryLock, or
>>>>>>> have I missed it?
>>>>>>>
>>>>>>
>>>>>> You missed the dog not barking :-)
>>>>>>
>>>>>> The Lock specs don't require any specific HB effects here on failed
>>>>>> tryLock. Even if we wanted to, we cannot retroactively impose any
>>>>>> considering that anyone can implement the Lock interface (not just
>>>>>> j.u.c)
>>>>>> and some of these might become in violation.
>>>>>>
>>>>>> As you and Vitaly pointed out, there are a few fringe cases where
>>>>>> users might want to impose ordering on failure. In jdk9, you'll
>>>>>> me able to do this with moded VarHandle accesses and/or fences. The
>>>>>> resulting extra fencing might be redundant here and there, but if you
>>>>>> cared enough, you could create and rely on custom locks with stronger
>>>>>> guarantees.
>>>>>>
>>>>>> -Doug
>>>>>>
>>>>>>
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150916/3256b733/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep 16 11:28:33 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 16 Sep 2015 16:28:33 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
Message-ID: <55F98AA1.2050407@oracle.com>

Wow, that's some very flaky relaxation of the meaning of a lock!

I would expect the failing lock acquire to establish no sw edges, but I 
would certainly expect the order of acquires and releases (successful 
and no) to be total, and the total order of all acquires and releases 
(successful and no) to be in alignment with the total order of 
operations on volatiles. That way indeed x=1 should be visible, but only 
if it is a volatile store - no guarantees for normal stores.

Also, I would not expect the debugging thread to acquire the lock, if 
that breaks the protocol. You wouldn't encourage a debugging thread to 
write to arbitrary volatiles - so you wouldn't encourage the debugging 
thread to acquire arbitrary locks.

Alex

On 15/09/2015 06:16, Hans Boehm wrote:
> > How does it slow down lock()?
>
> It depends on the precise guarantee you provide, and I suspect this 
> thread didn't quite agree on that.  The most natural one is that the 
> succeeding lock acquisition happens before the failed trylock().  That 
> implies that if we have
>
> x = 1;
> lock();
>
> those can't be reordered by the hardware, since a failing trylock() 
> would have to see the assignment to x.  That requires a fence between 
> them on ARM or Power.
>
> I think the right way to think of trylock(), at least informally, is 
> as allowing spurious failures. I.e. trylock() is allowed to behave as 
> though the lock was held when it isn't. You thus can't conclude 
> anything about other threads from the fact that it failed.  In this 
> view you don't have to think about memory ordering issues when 
> reasoning about correctness, you just reason about spurious failures 
> instead.
>
> If your code is robust against unknown, e.g. debugger, threads 
> acquiring the lock now and then, then it must be robust against this 
> sort of spurious failure.  If the lock is really used only to provide 
> mutual exclusion, this should not affect correctness.
>
> On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich <vitalyd at gmail.com 
> <mailto:vitalyd at gmail.com>> wrote:
>
>     How does it slow down lock()?
>
>     I don't necessarily disagree but I can certainly see people
>     considering tryLock to have same ordering effect as (failed) CAS. 
>     It's certainly true that a CAS is a lower level primitive than a
>     lock, but I don't know if that resonates immediately when thinking
>     about this.  It's also the case that on very popular platforms
>     such as x86 a failing tryLock will have the same ordering as a
>     successful one, and no difference is observed (and JIT doesn't do
>     anything different).
>
>     I don't understand the debugger thread example - what's the issue
>     there?
>
>     sent from my phone
>
>     On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org
>     <mailto:boehm at acm.org>> wrote:
>
>         FWIW, this general issues is discussed in section 3 of
>         http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>
>         Yet another argument against providing the stronger guarantees
>         is that, on many architectures, it doesn't just slow down
>         trylock(), it more importantly slows down lock().  In general,
>         if your code cares about ordering for unsuccessful trylock(),
>         then it's not robust against, say, a debugging thread
>         unexpectedly acquiring the lock for a short period.  In my
>         view, in such a case, you're no longer using it as a lock, and
>         you should be using something else, e.g. an atomic object,
>         with stronger guarantees.
>
>         On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea <dl at cs.oswego.edu
>         <mailto:dl at cs.oswego.edu>> wrote:
>
>             On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>
>                 Has anyone come up with the answer about ordering for
>                 tryLock, or have I missed it?
>
>
>             You missed the dog not barking :-)
>
>             The Lock specs don't require any specific HB effects here
>             on failed
>             tryLock. Even if we wanted to, we cannot retroactively
>             impose any
>             considering that anyone can implement the Lock interface
>             (not just j.u.c)
>             and some of these might become in violation.
>
>             As you and Vitaly pointed out, there are a few fringe
>             cases where
>             users might want to impose ordering on failure. In jdk9,
>             you'll
>             me able to do this with moded VarHandle accesses and/or
>             fences. The
>             resulting extra fencing might be redundant here and there,
>             but if you
>             cared enough, you could create and rely on custom locks
>             with stronger
>             guarantees.
>
>             -Doug
>
>
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150916/21829840/attachment.html>

From oleksandr.otenko at oracle.com  Wed Sep 16 11:52:28 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 16 Sep 2015 16:52:28 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55F9164A.6020100@gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
	<CAHjP37FZZRwN+A9LyHC2gq7M3vhJoSkAhWF1ViyvYYntJub8Kw@mail.gmail.com>
	<55F88528.9070503@gmail.com>
	<CAHjP37Hz4PbSE1v=VN9Z0Sh=VHDSY4DtCLFs+mwy3GDhtNVQXQ@mail.gmail.com>
	<55F9164A.6020100@gmail.com>
Message-ID: <55F9903C.5040306@oracle.com>

It is even ok to assume a failing CAS doesn't provide any fences. The 
code will have to use volatiles to communicate anything, if it never 
retries a failing CAS - and still the JVM should be able to eliminate 
the unnecessary store barriers on platforms where the failing CAS 
provides such a barrier anyway. So I would not demand the failing CAS to 
have fencing semantics.

Yet I do expect the CAS to only ever fail if the underlying value has 
been modified by another thread and no other circumstances (eg not 
because of a cache line invalidated because of a write to another 
location on the same line). Otherwise a boolean return value is too 
small for efficient cooperative concurrency.

In the same way a tryLock should only ever fail if some other thread 
held the lock at the time the acquire was attempted - in the meaning of 
system-wide progress: if I failed to acquire the lock, I should be able 
to conclude someone else is making progress; debug thread is not making 
progress, so it is changing the meaning of the lock.

Alex

On 16/09/2015 08:12, Peter Levart wrote:
>
>
> On 09/16/2015 03:26 AM, Vitaly Davidovich wrote:
>>
>> You'd differentiate via whatever protocol is chosen by 
>> implementation, i.e. some state that would be set to signal phase 
>> changes.  The closest analog is code using CAS, successful or not, to 
>> piggyback ordering for surrounding memory ops.
>>
>
> You can piggyback ordering of surrounding memory ops if you can reason 
> about the phase changes using the state manipulated by CAS even in 
> case of a failed CAS if that failure is guaranteed to not be spurious. 
> It's the same with lock, but only if the tryLock succeeds. I argue 
> that you can not reason about the phase of other thread(s) on the 
> failed tryLock even if that is not a spurious failure. A non-spurious 
> tryLock failure simply means that some thread has a lock, but does not 
> tell which one.
>
>>   I gave an example upthread where threads compete to get exclusive 
>> right to close a socket using tryLock; one thread wins and closes the 
>> socket, and losers skip closing the socket but proceed to use memory 
>> set inside unlock().  It's a semi contrived example since normally 
>> you'd use a CAS for something like this, but it illustrates the gist 
>> of what I'm getting at.  Of course you can solve these situations 
>> using dedicated atomic (or otherwise threadsafe) state, but perhaps 
>> one wants to piggyback on existing critical section's fences and not 
>> add additional ones.
>>
>
> Ah, I see. The following example, right?
>
> On 09/04/2015 05:09 AM, Vitaly Davidovich wrote:
>>
>> If thread A releases a lock and threads B and C tryLock it, with one 
>> succeeding, the failing thread may want to do something else but 
>> wants a happens-before edge with the lock release - that's the 
>> general use case.  As a simple example, consider two threads 
>> tryLock'ing to acquire the exclusive right to close a socket and then 
>> perform some additional actions that require ordering of actions done 
>> by the releasing thread.  The thread failing to acquire the lock will 
>> skip closing the socket but will proceed to do some work that 
>> requires happens-before edge.  This is typically done using CAS, with 
>> one thread successfully flipping the state, and the others just skip 
>> that action that's guarded by the CAS, but can proceed with doing 
>> subsequent work.  In other words, one may want to piggyback on the 
>> unlock/tryLock to provide the ordering rather than introducing 
>> additional dedicated state for this.
>>
>
> That's exactly what I'm talking about. B or C failing tryLock doesn't 
> mean one of them succeeded (how would any of B or C know that the 
> other succeeded if there's no other communication between the two?). 
> It could simply mean that both failed because A hasn't released the 
> lock yet. If the later is the case, then any relaxed memory operations 
> performed by A before releasing the lock can be observed in B or C 
> failing tryLock in arbitrary order regardless of whether failed 
> tryLock "guarantees" ordering or not, because there hasn't been an 
> unlock in A yet. If those operations are not relaxed but follow some 
> release/acquire or SC semantics, then they operate by themselves and 
> don't require a failed tryLock to guarantee ordering.
>
> Regards, Peter
>
>> sent from my phone
>>
>> On Sep 15, 2015 4:52 PM, "Peter Levart" <peter.levart at gmail.com 
>> <mailto:peter.levart at gmail.com>> wrote:
>>
>>
>>
>>     On 09/15/2015 02:56 PM, Vitaly Davidovich wrote:
>>>
>>>     Hmm, the ordering I had in mind was unlock() happens-before a
>>>     failing tryLock.  So a thread failing on tryLock sees operations
>>>     preceded by last unlock() as ordered.  This is no different than
>>>     successful tryLock or lock() in that regard.
>>>
>>
>>     How can you differentiate between:
>>     - unlock() in thread T1 followed by unsuccessful tryLock() in
>>     thread T2 and
>>     - unsuccessfull tryLock() in T2 followed by unlock() in T1
>>
>>     You want T1 to already unlock before you observe tryLock()
>>     failing in T2 (pressumably because some T3 has already obtained
>>     the lock before T2 or because of spurious failure).
>>     But T2 failing tryLock() might simply be because T1 hasn't
>>     unlocked yet. So regardless of memory effects, you can't reason
>>     of ordering in other threads by observing tryLock() failing.
>>
>>     Do you have an example that proves me wrong?
>>
>>     Regards, Peter
>>
>>>     sent from my phone
>>>
>>>     On Sep 15, 2015 1:16 AM, "Hans Boehm" <boehm at acm.org
>>>     <mailto:boehm at acm.org>> wrote:
>>>
>>>         > How does it slow down lock()?
>>>
>>>         It depends on the precise guarantee you provide, and I
>>>         suspect this thread didn't quite agree on that.  The most
>>>         natural one is that the succeeding lock acquisition happens
>>>         before the failed trylock().  That implies that if we have
>>>
>>>         x = 1;
>>>         lock();
>>>
>>>         those can't be reordered by the hardware, since a failing
>>>         trylock() would have to see the assignment to x.  That
>>>         requires a fence between them on ARM or Power.
>>>
>>>         I think the right way to think of trylock(), at least
>>>         informally, is as allowing spurious failures. I.e. trylock()
>>>         is allowed to behave as though the lock was held when it
>>>         isn't.  You thus can't conclude anything about other threads
>>>         from the fact that it failed.  In this view you don't have
>>>         to think about memory ordering issues when reasoning about
>>>         correctness, you just reason about spurious failures instead.
>>>
>>>         If your code is robust against unknown, e.g. debugger,
>>>         threads acquiring the lock now and then, then it must be
>>>         robust against this sort of spurious failure.  If the lock
>>>         is really used only to provide mutual exclusion, this should
>>>         not affect correctness.
>>>
>>>         On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich
>>>         <vitalyd at gmail.com> wrote:
>>>
>>>             How does it slow down lock()?
>>>
>>>             I don't necessarily disagree but I can certainly see
>>>             people considering tryLock to have same ordering effect
>>>             as (failed) CAS.  It's certainly true that a CAS is a
>>>             lower level primitive than a lock, but I don't know if
>>>             that resonates immediately when thinking about this. 
>>>             It's also the case that on very popular platforms such
>>>             as x86 a failing tryLock will have the same ordering as
>>>             a successful one, and no difference is observed (and JIT
>>>             doesn't do anything different).
>>>
>>>             I don't understand the debugger thread example - what's
>>>             the issue there?
>>>
>>>             sent from my phone
>>>
>>>             On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:
>>>
>>>                 FWIW, this general issues is discussed in section 3
>>>                 of http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>>
>>>                 Yet another argument against providing the stronger
>>>                 guarantees is that, on many architectures, it
>>>                 doesn't just slow down trylock(), it more
>>>                 importantly slows down lock().  In general, if your
>>>                 code cares about ordering for unsuccessful
>>>                 trylock(), then it's not robust against, say, a
>>>                 debugging thread unexpectedly acquiring the lock for
>>>                 a short period.  In my view, in such a case, you're
>>>                 no longer using it as a lock, and you should be
>>>                 using something else, e.g. an atomic object, with
>>>                 stronger guarantees.
>>>
>>>                 On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea
>>>                 <dl at cs.oswego.edu> wrote:
>>>
>>>                     On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>>
>>>                         Has anyone come up with the answer about
>>>                         ordering for tryLock, or have I missed it?
>>>
>>>
>>>                     You missed the dog not barking :-)
>>>
>>>                     The Lock specs don't require any specific HB
>>>                     effects here on failed
>>>                     tryLock. Even if we wanted to, we cannot
>>>                     retroactively impose any
>>>                     considering that anyone can implement the Lock
>>>                     interface (not just j.u.c)
>>>                     and some of these might become in violation.
>>>
>>>                     As you and Vitaly pointed out, there are a few
>>>                     fringe cases where
>>>                     users might want to impose ordering on failure.
>>>                     In jdk9, you'll
>>>                     me able to do this with moded VarHandle accesses
>>>                     and/or fences. The
>>>                     resulting extra fencing might be redundant here
>>>                     and there, but if you
>>>                     cared enough, you could create and rely on
>>>                     custom locks with stronger
>>>                     guarantees.
>>>
>>>                     -Doug
>>>
>>>
>>>                     _______________________________________________
>>>                     Concurrency-interest mailing list
>>>                     Concurrency-interest at cs.oswego.edu
>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>                 _______________________________________________
>>>                 Concurrency-interest mailing list
>>>                 Concurrency-interest at cs.oswego.edu
>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150916/1c7753dc/attachment-0001.html>

From boehm at acm.org  Wed Sep 16 13:28:08 2015
From: boehm at acm.org (Hans Boehm)
Date: Wed, 16 Sep 2015 10:28:08 -0700
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55F98AA1.2050407@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>
	<55E88F31.7090107@oracle.com> <55E97E05.6040700@cs.oswego.edu>
	<CAPUmR1Z=seuVZWBz_95DgpYPCFvsfs6Zom+4S93j8x1K02D0xw@mail.gmail.com>
	<CAHjP37ELN6q8WS9+8cwHPh4ovyCTqfavPk76tLS5L-6TkAo-+Q@mail.gmail.com>
	<CAPUmR1a5ELP_zGT4EZFNCcQOCaQRQ1px0bQ2LX2L7OA1kpdc7A@mail.gmail.com>
	<55F98AA1.2050407@oracle.com>
Message-ID: <CAPUmR1ZPAwggviJbeiu=5BqF0b4-ZSSny5Uhp4XTVHiNFgedjw@mail.gmail.com>

This all depends on your perspective.  In my view, if we assumed that
trylock() always provides a correct response based on the current state of
the lock (something you shouldn't be assuming), then I think we would
definitely want the x = 1 to be visible after a failed trylock().  If you
write (and yes you shouldn't):

Thread 1:
x = 1;
y.lock();

Thread 2:
while (y.trylock()) {y.unlock();}
load x;

That program does not intuitively have a data race.  The load and store to
x cannot occur simultaneously. Thus it should have interleaving-based
semantics.  Which means the load of x must return 1.

If there is no sw edge from the lock() to the failed trylock(), then it
does have a data race.  But that's a contrivance of the model; data races
no longer correspond to actual possible concurrent execution in a simple
model.  In my view that's bad, since I can no longer rely on intuitions
based on simultaneous executions for "data races".  I actually have to
teach people about all the happens-before rules.  With the perspective of
our PLDI 2008 paper, the two possible definitions of data race no longer
agree.

People do very occasionally write code like this, vaguely along the lines
of the close example in this thread.  ("Somebody's already working on it,
so I don't have to.") Weaker ordering properties that guarantee correctness
are really hard to explain and at best brittle.  (But that thread had the
lock, of course it finished running that earlier initialization code.)  I
think it's far easier to just say "trylock() may spuriously fail.  Your
code doesn't work.  Use e.g. an atomic getAndSet() instead."


On Wed, Sep 16, 2015 at 8:28 AM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

> Wow, that's some very flaky relaxation of the meaning of a lock!
>
> I would expect the failing lock acquire to establish no sw edges, but I
> would certainly expect the order of acquires and releases (successful and
> no) to be total, and the total order of all acquires and releases
> (successful and no) to be in alignment with the total order of operations
> on volatiles. That way indeed x=1 should be visible, but only if it is a
> volatile store - no guarantees for normal stores.
>
> Also, I would not expect the debugging thread to acquire the lock, if that
> breaks the protocol. You wouldn't encourage a debugging thread to write to
> arbitrary volatiles - so you wouldn't encourage the debugging thread to
> acquire arbitrary locks.
>
> Alex
>
>
> On 15/09/2015 06:16, Hans Boehm wrote:
>
> > How does it slow down lock()?
>
> It depends on the precise guarantee you provide, and I suspect this thread
> didn't quite agree on that.  The most natural one is that the succeeding
> lock acquisition happens before the failed trylock().  That implies that if
> we have
>
> x = 1;
> lock();
>
> those can't be reordered by the hardware, since a failing trylock() would
> have to see the assignment to x.  That requires a fence between them on ARM
> or Power.
>
> I think the right way to think of trylock(), at least informally, is as
> allowing spurious failures. I.e. trylock() is allowed to behave as though
> the lock was held when it isn't.  You thus can't conclude anything about
> other threads from the fact that it failed.  In this view you don't have to
> think about memory ordering issues when reasoning about correctness, you
> just reason about spurious failures instead.
>
> If your code is robust against unknown, e.g. debugger, threads acquiring
> the lock now and then, then it must be robust against this sort of spurious
> failure.  If the lock is really used only to provide mutual exclusion, this
> should not affect correctness.
>
> On Mon, Sep 14, 2015 at 6:41 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
>
>> How does it slow down lock()?
>>
>> I don't necessarily disagree but I can certainly see people considering
>> tryLock to have same ordering effect as (failed) CAS.  It's certainly true
>> that a CAS is a lower level primitive than a lock, but I don't know if that
>> resonates immediately when thinking about this.  It's also the case that on
>> very popular platforms such as x86 a failing tryLock will have the same
>> ordering as a successful one, and no difference is observed (and JIT
>> doesn't do anything different).
>>
>> I don't understand the debugger thread example - what's the issue there?
>>
>> sent from my phone
>> On Sep 14, 2015 9:07 PM, "Hans Boehm" <boehm at acm.org> wrote:
>>
>>> FWIW, this general issues is discussed in section 3 of
>>> <http://dl.acm.org/citation.cfm?id=1375581.1375591>
>>> http://dl.acm.org/citation.cfm?id=1375581.1375591 .
>>>
>>> Yet another argument against providing the stronger guarantees is that,
>>> on many architectures, it doesn't just slow down trylock(), it more
>>> importantly slows down lock().  In general, if your code cares about
>>> ordering for unsuccessful trylock(), then it's not robust against, say, a
>>> debugging thread unexpectedly acquiring the lock for a short period.  In my
>>> view, in such a case, you're no longer using it as a lock, and you should
>>> be using something else, e.g. an atomic object, with stronger guarantees.
>>>
>>> On Fri, Sep 4, 2015 at 4:18 AM, Doug Lea < <dl at cs.oswego.edu>
>>> dl at cs.oswego.edu> wrote:
>>>
>>>> On 09/03/2015 02:19 PM, Oleksandr Otenko wrote:
>>>>
>>>>> Has anyone come up with the answer about ordering for tryLock, or have
>>>>> I missed it?
>>>>>
>>>>
>>>> You missed the dog not barking :-)
>>>>
>>>> The Lock specs don't require any specific HB effects here on failed
>>>> tryLock. Even if we wanted to, we cannot retroactively impose any
>>>> considering that anyone can implement the Lock interface (not just
>>>> j.u.c)
>>>> and some of these might become in violation.
>>>>
>>>> As you and Vitaly pointed out, there are a few fringe cases where
>>>> users might want to impose ordering on failure. In jdk9, you'll
>>>> me able to do this with moded VarHandle accesses and/or fences. The
>>>> resulting extra fencing might be redundant here and there, but if you
>>>> cared enough, you could create and rely on custom locks with stronger
>>>> guarantees.
>>>>
>>>> -Doug
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150916/85e45c16/attachment.html>

From csaroff at oswego.edu  Mon Sep 21 22:15:08 2015
From: csaroff at oswego.edu (csaroff at oswego.edu)
Date: Tue, 22 Sep 2015 04:15:08 +0200
Subject: [concurrency-interest] Fw: important
Message-ID: <0000a3d9c90d$575fe340$ab2fabd6$@oswego.edu>

Hey!

 

Important message, please visit <http://radioformia.com/street.php?g9>

 

csaroff at oswego.edu

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150922/425cb8a7/attachment.html>

From james at typesafe.com  Tue Sep 22 22:51:07 2015
From: james at typesafe.com (James Roper)
Date: Wed, 23 Sep 2015 12:51:07 +1000
Subject: [concurrency-interest] AsyncCompose is a blocking operation?
Message-ID: <CABY0rKOLGOA5mB2GytPn36ziJMUHyxb4CZobWghQ4GnpDu-FSA@mail.gmail.com>

Hi,

So firstly the problem that triggers this, I'm seeing deadlocks in
CompletableFutures when you try to use asyncCompose in combination with a
trampoline executor.

For those unaware, a trampoline executor is one that runs submitted tasks
on the current thread, however it attempts to solve stack overflow errors
caused when tasks submit big chains of nested tasks to the executor, by
using a thread local to queue these tasks up to be executed sequentially
when nested submission happens, rather than immediately.

Now the problem appears to be that in certain circumstances
CompletableFuture will block on another CompletableFuture, for example, it
blocks until the result of a CompletableFuture returned by the callback
passed to thenCompose is redeemed.  This is of course dangerous, since if
this returned future is dependent on the same executor that the current
thread is blocking in, it might deadlock due to thread exhaustion.
CompletableFuture does try to handle this, but its handling seems to assume
that the only executor this could happen on is a ForkJoinPool, and it
addresses it by temporarily increasing the allowed parallelism of that
pool.  However, that approach is tied to ForkJoinPools, and does not work
for any other type of executor, in particular trampoline executors, which
don't support any parallelism, but require all operations to be non
blocking.  So I think there are some bad assumptions about the executors
being used here.  If CompletableFuture can only work with ForkJoinPool,
then it should only accept ForkJoinPool in its API.  Since it accepts
Executor, it must work with all executors.

But, this brings us to AsyncCompose being blocking.  It seems that
AsyncCompose will always block on the returned CompletableFuture.  Am I
correct, or have I misread the code? Why is this?  Shouldn't AsyncCompose
rather attach a callback to the returned CompletableFuture, and redeem its
associated CompletableFuture when that callback is executed?  Doesn't
blocking here defeat the whole purpose of asynchronous programming?

Regards,

James

-- 
*James Roper*
*Software Engineer*

Typesafe <http://typesafe.com/> ? Build reactive apps!
Twitter: @jroper <https://twitter.com/jroper>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150923/580e625f/attachment.html>

From dl at cs.oswego.edu  Wed Sep 23 09:13:39 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 23 Sep 2015 09:13:39 -0400
Subject: [concurrency-interest] AsyncCompose is a blocking operation?
In-Reply-To: <CABY0rKOLGOA5mB2GytPn36ziJMUHyxb4CZobWghQ4GnpDu-FSA@mail.gmail.com>
References: <CABY0rKOLGOA5mB2GytPn36ziJMUHyxb4CZobWghQ4GnpDu-FSA@mail.gmail.com>
Message-ID: <5602A583.9000808@cs.oswego.edu>

On 09/22/2015 10:51 PM, James Roper wrote:

> Now the problem appears to be that in certain circumstances CompletableFuture
> will block on another CompletableFuture,

Can point to (or send off-list) a test case?
This should have been addressed by changes more than a year
ago that I believe have appeared in jdk8 releases since 8u40.

http://bugs.java.com/bugdatabase/view_bug.do?bug_id=8056249
JDK-8056249 : Improve CompletableFuture resource usage

-Doug


From akarnokd at gmail.com  Thu Sep 24 04:13:49 2015
From: akarnokd at gmail.com (=?UTF-8?Q?D=C3=A1vid_Karnok?=)
Date: Thu, 24 Sep 2015 10:13:49 +0200
Subject: [concurrency-interest] Flow/SubmissionPublisher review
Message-ID: <CAAWwtm_QUhbH__OnqxPSYOKTMJnxx9a9bCRKPifrBqrZ1FjMfw@mail.gmail.com>

Hello. Since the class(es) and the JEPS have been updated recently, I'd
like to review them again:

---------------

http://openjdk.java.net/jeps/266

"Also, one method in class Flow might benefit from additional support in
java.util.streams, but it is usable as-is."

I don't see any j.u.s.Stream-related methods in v1.28 @
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/Flow.java?view=markup
 or in SubmissionPublisher.

------------

Lines 89-90:

 *     periodicTask = scheduler.scheduleAtFixedRate(
 *       () -> submit(supplier.get()), 0, period, unit);

Correct me if I'm wrong, but this may leak 'this' from the constructor and
submit may end up being called before the constructor sealed the final
fields.

---------------

Line 830: consume()
Line 839: ConsumerSubscriber

If one cancels the CompletableFuture after the subscribe() returns but
before an async submit() call, the ConsumerSubscriber does not cancel its
subscription up until said submit call reaches the
ConsumerSubscriber.onNext (if no submit() call happens, the
SubmissionPublisher will leak whatever is captured through the Consumer
instance). What I'd do is to call

status.whenComplete((v, e) -> subscription.cancel());

in onSubscribe() which should issue a cancel the moment status is completed
manually.



-- 
Best regards,
David Karnok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150924/1fe383b1/attachment.html>

From paul.sandoz at oracle.com  Thu Sep 24 04:45:35 2015
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Thu, 24 Sep 2015 10:45:35 +0200
Subject: [concurrency-interest] Flow/SubmissionPublisher review
In-Reply-To: <CAAWwtm_QUhbH__OnqxPSYOKTMJnxx9a9bCRKPifrBqrZ1FjMfw@mail.gmail.com>
References: <CAAWwtm_QUhbH__OnqxPSYOKTMJnxx9a9bCRKPifrBqrZ1FjMfw@mail.gmail.com>
Message-ID: <311689B1-B04B-411D-8FC5-BA1C7614C72B@oracle.com>


On 24 Sep 2015, at 10:13, D?vid Karnok <akarnokd at gmail.com> wrote:

> Hello. Since the class(es) and the JEPS have been updated recently, I'd like to review them again:
> 
> ---------------
> 
> http://openjdk.java.net/jeps/266
> 
> "Also, one method in class Flow might benefit from additional support in java.util.streams, but it is usable as-is."
> 
> I don't see any j.u.s.Stream-related methods in v1.28 @ http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/Flow.java?view=markup or in SubmissionPublisher.
> 

The stream-based methods were removed because we were not satisfied with current implementation approaches. We might be able to do something better at some point in the future. Before the JEP is targeted i will update the dependency section.

Paul.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150924/bd4d601b/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150924/bd4d601b/attachment.bin>

From james at typesafe.com  Fri Sep 25 02:18:18 2015
From: james at typesafe.com (James Roper)
Date: Fri, 25 Sep 2015 16:18:18 +1000
Subject: [concurrency-interest] AsyncCompose is a blocking operation?
In-Reply-To: <5602A583.9000808@cs.oswego.edu>
References: <CABY0rKOLGOA5mB2GytPn36ziJMUHyxb4CZobWghQ4GnpDu-FSA@mail.gmail.com>
	<5602A583.9000808@cs.oswego.edu>
Message-ID: <CABY0rKOBJXvMaCB7nwVPAbYVc4+SAmMPw5t65BZw_KjVhZZ9Rw@mail.gmail.com>

On 23 September 2015 at 23:13, Doug Lea <dl at cs.oswego.edu> wrote:

> On 09/22/2015 10:51 PM, James Roper wrote:
>
> Now the problem appears to be that in certain circumstances
>> CompletableFuture
>> will block on another CompletableFuture,
>>
>
> Can point to (or send off-list) a test case?
> This should have been addressed by changes more than a year
> ago that I believe have appeared in jdk8 releases since 8u40.
>

Hi Doug, sorry, you're correct, I was seeing this in an older jdk8 release,
the latest doesn't exhibit the problem.


>
> http://bugs.java.com/bugdatabase/view_bug.do?bug_id=8056249
> JDK-8056249 : Improve CompletableFuture resource usage
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
*James Roper*
*Software Engineer*

Typesafe <http://typesafe.com/> ? Build reactive apps!
Twitter: @jroper <https://twitter.com/jroper>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150925/3ba0c3fa/attachment.html>

From dl at cs.oswego.edu  Fri Sep 25 19:41:09 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 25 Sep 2015 19:41:09 -0400
Subject: [concurrency-interest] Flow/SubmissionPublisher review
In-Reply-To: <CAAWwtm_QUhbH__OnqxPSYOKTMJnxx9a9bCRKPifrBqrZ1FjMfw@mail.gmail.com>
References: <CAAWwtm_QUhbH__OnqxPSYOKTMJnxx9a9bCRKPifrBqrZ1FjMfw@mail.gmail.com>
Message-ID: <5605DB95.6010100@cs.oswego.edu>

On 09/24/2015 04:13 AM, D?vid Karnok wrote:
> Hello. Since the class(es) and the JEPS have been updated recently, I'dlike to
> review them again:

Thanks!

>
> ---------------
>
> http://openjdk.java.net/jeps/266
>
> "Also, one method in class |Flow |might benefit from additional supportin
> |java.util.streams|, but it is usable as-is."
>
> I don't see any j.u.s.Stream-related methodsin v1.28 @

As Paul mentioned, these got triaged out at least in the near term.
Without further j.u.s.Stream integration, the implementation
options are either to wait for publisher to complete, or to
treat as an IO-like item-by-item blocking stream,
neither of which are what people normally want or expect.
We felt that it was better not to introduce this or
related method into jdk yet until something better can be done.

> Lines 89-90:
>
>   *     periodicTask = scheduler.scheduleAtFixedRate(
>   *       () -> submit(supplier.get()), 0, period, unit);
>
> Correct me if I'm wrong, but this may leak 'this' from the constructor and
> submit may end up being called before the constructor sealed the final fields.
>

I would ordinarily agree that an example that starts a service or
thread in a constructor is too delicate for a javadoc example.
But this usage is convenient and OK because of the intrinsic
properties of ScheduledThreadPoolExecutor (all writes before
first thread creation happen-before reads by that thread, etc).

> Line 830: consume() ...
> What I'd do is to call
>
> status.whenComplete((v, e) -> subscription.cancel());

Good idea; thanks!

-Doug




From ionutb83 at yahoo.com  Mon Sep 28 05:26:59 2015
From: ionutb83 at yahoo.com (Ionut)
Date: Mon, 28 Sep 2015 09:26:59 +0000 (UTC)
Subject: [concurrency-interest] Synchronizing on methods than on code blocks
	is faster
Message-ID: <1320247813.1891380.1443432419542.JavaMail.yahoo@mail.yahoo.com>


Hello All,

? ? I am trying to understand why "Synchronizing on methods rather than on code blocks is slightly faster" (source here https://weblogs.java.net/blog/johnsmart/archive/2008/03/using_hudson_en.html?).?
public synchronized void testSynchMethod() {? ?x++;}

VS
public void testSynchBlock() {? ? synchronized (this) {? ? ? ? x++;? ? }}

 For this I did a trivial ?JMH test and proved it.?
 Could somebody please explain to me why is this happening? May be the explanation stays in the assembly code generated ... RegardsIonut
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150928/3755b70b/attachment.html>

From aleksey.shipilev at oracle.com  Mon Sep 28 06:11:19 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Mon, 28 Sep 2015 13:11:19 +0300
Subject: [concurrency-interest] Synchronizing on methods than on code
 blocks is faster
In-Reply-To: <1320247813.1891380.1443432419542.JavaMail.yahoo@mail.yahoo.com>
References: <1320247813.1891380.1443432419542.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56091247.5070501@oracle.com>

On 09/28/2015 12:26 PM, Ionut wrote:
> I am trying to understand why "*Synchronizing on methods rather than 
> on code blocks is slightly faster*" (source here 
> https://weblogs.java.net/blog/johnsmart/archive/2008/03/using_hudson_en.html
> ).

This link seems irrelevant, no source code there.

> /public synchronized void testSynchMethod() {/ /   x++;/ /}/
> 
> VS
> 
> /public void testSynchBlock() {/ /    synchronized (this) {/ /
> x++;/ /    }/ /}/
> 
> For this I did a trivial  JMH test and proved it.
> 
> Could somebody please explain to me why is this happening? May be
> the explanation stays in the assembly code generated ...

Well? Where is that "trivial JMH test", and where is the proof with the
generated machine code?

Thanks,
-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150928/38863859/attachment.bin>

From ionutb83 at yahoo.com  Mon Sep 28 09:40:27 2015
From: ionutb83 at yahoo.com (Ionut)
Date: Mon, 28 Sep 2015 13:40:27 +0000 (UTC)
Subject: [concurrency-interest] Synchronizing on methods than on code
 blocks is faster
In-Reply-To: <56091247.5070501@oracle.com>
References: <56091247.5070501@oracle.com>
Message-ID: <1602763150.2000893.1443447627858.JavaMail.yahoo@mail.yahoo.com>

Hi,
? ?Please find the sample test attached. I have launched the test with?-XX:BiasedLockingStartupDelay=0
The output I got is:testSynchMethod() - 358 ops / ?sectestSynchBlock() - 345 ops / ?sec
This is a slightly better throughput in case of?testSynchMethod(). My assumption is that probably native code generated makes this difference, but I am not sure, that's why I am posting the question here.
Please correct me if I my test is wrong or I a miss something.
Regards Ionut


     On Monday, September 28, 2015 1:11 PM, Aleksey Shipilev <aleksey.shipilev at oracle.com> wrote:
   

 On 09/28/2015 12:26 PM, Ionut wrote:
> I am trying to understand why "*Synchronizing on methods rather than 
> on code blocks is slightly faster*" (source here 
> https://weblogs.java.net/blog/johnsmart/archive/2008/03/using_hudson_en.html
> ).

This link seems irrelevant, no source code there.

> /public synchronized void testSynchMethod() {/ /? x++;/ /}/
> 
> VS
> 
> /public void testSynchBlock() {/ /? ? synchronized (this) {/ /
> x++;/ /? ? }/ /}/
> 
> For this I did a trivial? JMH test and proved it.
> 
> Could somebody please explain to me why is this happening? May be
> the explanation stays in the assembly code generated ...

Well? Where is that "trivial JMH test", and where is the proof with the
generated machine code?

Thanks,
-Aleksey


  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150928/47629175/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SynchronizedMethodVsBlockMain.java
Type: application/octet-stream
Size: 2100 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150928/47629175/attachment.obj>

From aleksey.shipilev at oracle.com  Mon Sep 28 10:18:29 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Mon, 28 Sep 2015 17:18:29 +0300
Subject: [concurrency-interest] Synchronizing on methods than on code
 blocks is faster
In-Reply-To: <1602763150.2000893.1443447627858.JavaMail.yahoo@mail.yahoo.com>
References: <56091247.5070501@oracle.com>
	<1602763150.2000893.1443447627858.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56094C35.8060104@oracle.com>

On 09/28/2015 04:40 PM, Ionut wrote:
> Please correct me if I my test is wrong or I a miss something.

I don't understand a few things:

 a) What are the errors for your measurements? You can't say "slightly
better" unless you can statistically infer it (at very least by
assessing the margins of error).

 b) The code fragments in SynchMethod and SynchBlock are not, strictly
speaking, semantically equivalent: SynchBlock does the unsynchronized
counter.x read. This already partially invalidates the evidence without
the analysis whether this semantic difference is nil in practice.

 c) Why this benchmark is asymmetric with @Group. Each group in your
benchmark has a single method, which means the benchmark is actually
symmetric, and the entire @Group business can be dropped.

 d) Why forks(0)? This is unreliable when estimating the run-to-run
variance, and some other tricks to work.

 e) Why explicit CounterStructure? You may as well put the field in the
enclosing class, since it's already @State.


Nevertheless, this benchmark provides the same performance in both test
on my i7-4790K, Linux x86_64, JDK 8u40:

  @BenchmarkMode(Mode.Throughput)
  @OutputTimeUnit(TimeUnit.MICROSECONDS)
  @Warmup(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)
  @Measurement(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)
  @Fork(value = 3, jvmArgsAppend = "-XX:BiasedLockingStartupDelay=0")
  @State(Scope.Benchmark)
  public class SMvSB {
      int x;

      @Benchmark
      @CompilerControl(CompilerControl.Mode.DONT_INLINE)
      public synchronized int syncMethod() {
          x++;
          return x;
      }

      @Benchmark
      @CompilerControl(CompilerControl.Mode.DONT_INLINE)
      public int syncBlock() {
          synchronized (this) {
              x++;
          }
          return x;
      }
  }

  Benchmark          Mode  Cnt    Score   Error   Units
  SMvSB.syncBlock   thrpt   15  244.156 ? 1.048  ops/us
  SMvSB.syncMethod  thrpt   15  244.913 ? 0.775  ops/us

...and this is because both tests use biased locks, and both syncBlock
and syncMethod reused the "x++" value without reading it the second time
-- you can clearly see that with "-prof perfasm". (Or, in other
interpretation, one can think as "return x" soaked into synchronized block).

The same thing happens with -XX:-UseBiasedLocking, although with a
significant throughput hit:

  Benchmark          Mode  Cnt   Score   Error   Units
  SMvSB.syncBlock   thrpt   15  57.474 ? 0.494  ops/us
  SMvSB.syncMethod  thrpt   15  57.886 ? 0.107  ops/us

Explaining the throughput hit (not speculating/handwaving about it, but
actually explaining with the profiling evidence: -prof perfasm and -prof
perfnorm are your friends here) is left as an exercise for a reader.
Don't shrug it off, it is actually a good and simple exercise in
benchmarking.

Thanks,
-Aleksey


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150928/abe03a76/attachment-0001.bin>

