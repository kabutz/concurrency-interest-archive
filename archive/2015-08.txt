From dl at cs.oswego.edu  Mon Aug  3 14:10:35 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 03 Aug 2015 14:10:35 -0400
Subject: [concurrency-interest] Upcoming jdk9 j.u.c JEP
In-Reply-To: <55B0F8D5.4050100@cs.oswego.edu>
References: <55B0F8D5.4050100@cs.oswego.edu>
Message-ID: <55BFAE9B.7080803@cs.oswego.edu>

On 07/23/2015 10:23 AM, Doug Lea wrote:
> API specs: http://gee.cs.oswego.edu/dl/jsr166/dist/docs/
> jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar (compiled using
>  Java8 javac).
> Browsable CVS sources:
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/
>

Thanks to those sending comments and suggestions! A few follow-ups:

>
> * If you are trying out updates with jdk9 early access,
> (https://jdk9.java.net/download/) notice that as of b73 last week, it by
> default uses the G1 collector, which is (currently, but hopefully just
> transiently) not usually the best choice for high-throughput concurrency. You
> probably want to use switches -XX:+UseParallelGC -XX:+UseCondCardMark
> -XX:-UseBiasedLocking

To elaborate a little: The G1 collector sometimes places memory
fences after reference writes. These tend to be most common where
they are least desirable in concurrent applications; for example
during producer-consumer element handoffs, which can significantly
impact performance. Some GC developers are looking into alternatives.

>
> ForkJoinPool ...  "Async" FJP mode is now probabilistically fair;

Thanks especially to Viktor Klang and Ron Pressler for helping
to refine this, and tease apart into two aspects (both of which
might be subject to further updates).

(1) Introducing a failsafe bound to avoid indefinite starvation
with unbounded loopy recursive tasks like ...
   class MyTask { ... void compute() { ... new MyTask().fork(); ...} }

The bound (of 1K tasks) forces worker threads to eventually try
looking elsewhere for tasks to execute.
By intent, eventually can be a long time.
The motivation is similar to spare-thread bounds -- to reduce
or avoid unbounded long-term resource issues without impacting
performance of well-behaved usages. There doesn't seem to be
a good reason to expose the bound as a tunable parameter.

(2) Providing a way to define tasks that might sometimes
prefer to poll external submissions rather than internal actions
like those in the above recursive loop. This amounts to exposing
ForkJoinPool.pollSubmission in ForkJoinTask, which in retrospect
was an oversight: pollSubmission is "protected" in ForkJoinPool,
but by Java protection rules was inaccessible from ForkJoinTask
subclasses, so needs an explicit relay method.

On 07/24/2015 02:52 PM, Doug Lea wrote:
> On 07/23/2015 02:55 PM, D?vid Karnok wrote:
>> Line 230: In RxJava, if the Subject is terminated with an exception, late
>> Subscribers will receive the exception but here, they just get completed.
>> Maybe it is worth considering this exception-replaying behavior.
>
> Thanks. I'm going to sit on this for the moment. One alternative is to add
> method isClosedExceptionally so that only those new Subscribers that care
> how it was closed need to arrange special handling.

I added the exception-replay -- it simplifies the closeExceptionally spec.
I also added an accessor for the exception for use in other contexts.

On 07/24/2015 04:26 PM, Doug Lea wrote:
> On 07/23/2015 06:35 PM, Greg Wilkins wrote:
>> Specifically that it is asymmetric and an error in the middle of a chain of
>> processors ....
>
> So should there be a SubmissionPublisher method along the lines of:
>
> onSubscriberException(Consumer<? extends Throwable> handler);
>

Actually, the handler (with two arguments) must be provided in
the constructor to be effective. Added.

I know that Greg still doesn't love some of the reactive-stream error
protocols, but adding this method covers the cases where a Publisher
or Processor knows how to cope with an onNext exception.

-Doug



From bayinamine at gmail.com  Tue Aug  4 23:55:09 2015
From: bayinamine at gmail.com (luo.fucong)
Date: Wed, 5 Aug 2015 11:55:09 +0800
Subject: [concurrency-interest] Understanding volatile in DCL
Message-ID: <6321D9C5-E46C-4A3B-92EE-6D5BAFD6E045@gmail.com>

It is mentioned in the wiki of double-checked locking idiom(https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java <https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java>) that DCL without introducing ?volatile? keyword is broken:

// Broken multithreaded version
// "Double-Checked Locking" idiom
class Foo {
    private Helper helper;

    public Helper getHelper() {
        if (helper == null) {    
            synchronized(this) {    
                if (helper == null) {    
                    helper = new Helper();
                }
            }
        }    
        return helper;
    }

    // other functions and members?
}

It?s broken because a thread may obtain a partially constructed object (the variable ?helper? may be initialized before constructor ?new Helper()? finished due to reordering).

I am wondering is there another possible of why that is broken that, the ?helper? may be initialized more than once?

Say Thread1 and Thread2 are now concurrently trying to get the helper instance, and T1 obtains the monitor(enter the synchronized block) while T2 waits.

Then T1 initialized the helper and returned, T2 entered the synchronized block. However, without the ?volatile? keyword, T2 may not see the update of the helper variable that were made by T1. So T2 may think that "helper == null? is true, and thus initialize the helper again.

Is the above possible? Thanks in advance!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150805/aec98bc8/attachment.html>

From sam.munkes at gmail.com  Wed Aug  5 01:15:32 2015
From: sam.munkes at gmail.com (Sam Munkes)
Date: Tue, 4 Aug 2015 22:15:32 -0700
Subject: [concurrency-interest] Understanding volatile in DCL
In-Reply-To: <6321D9C5-E46C-4A3B-92EE-6D5BAFD6E045@gmail.com>
References: <6321D9C5-E46C-4A3B-92EE-6D5BAFD6E045@gmail.com>
Message-ID: <CABjcb6X+Sq8j9uNOFctkfRVXRN9Ns8C4on8WC+M4chst5O3__g@mail.gmail.com>

writes cannot be reordered after the synchronized block (MonitorExit), so
by the time T2 acquires the monitor it will see the fully published helper.
the problem would be with other threads that do not acquire the lock.


On Tue, Aug 4, 2015 at 8:55 PM, luo.fucong <bayinamine at gmail.com> wrote:

> It is mentioned in the wiki of double-checked locking idiom(
> https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java) that
> DCL without introducing ?volatile? keyword is broken:
>
> // Broken multithreaded version
> // "Double-Checked Locking" idiom
> class Foo {
>     private Helper helper;
>
>     public Helper getHelper() {
>         if (helper == null) {
>             synchronized(this) {
>                 if (helper == null) {
>                     helper = new Helper();
>                 }
>             }
>         }
>         return helper;
>     }
>
>     // other functions and members?
> }
>
> It?s broken because a thread may obtain a partially constructed object
> (the variable ?helper? may be initialized before constructor ?new Helper()?
> finished due to reordering).
>
> I am wondering is there another possible of why that is broken that, the
> ?helper? may be initialized more than once?
>
> Say Thread1 and Thread2 are now concurrently trying to get the helper
> instance, and T1 obtains the monitor(enter the synchronized block) while T2
> waits.
>
> Then T1 initialized the helper and returned, T2 entered the synchronized
> block. However, without the ?volatile? keyword, T2 may not see the update
> of the helper variable that were made by T1. So T2 may think that "helper
> == null? is true, and thus initialize the helper again.
>
> Is the above possible? Thanks in advance!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150804/ac371948/attachment.html>

From joe.bowbeer at gmail.com  Wed Aug  5 04:27:12 2015
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 5 Aug 2015 01:27:12 -0700
Subject: [concurrency-interest] Understanding volatile in DCL
In-Reply-To: <6321D9C5-E46C-4A3B-92EE-6D5BAFD6E045@gmail.com>
References: <6321D9C5-E46C-4A3B-92EE-6D5BAFD6E045@gmail.com>
Message-ID: <CAHzJPErVHz5LJ1jf_rut62yKu6Zsc1hWwbs6EbKrpT4EvPRgig@mail.gmail.com>

Double init is not possible *because* of the synchronized block, which
provides a critical section and visibility.

If double init were possible in this code snippet, it would also be
possible without the initial null check.

The volatile is only needed because of the introduction of the initial null
check.

On Tue, Aug 4, 2015 at 8:55 PM, luo.fucong <bayinamine at gmail.com> wrote:

> It is mentioned in the wiki of double-checked locking idiom(
> https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java) that
> DCL without introducing ?volatile? keyword is broken:
>
> // Broken multithreaded version
> // "Double-Checked Locking" idiom
> class Foo {
>     private Helper helper;
>
>     public Helper getHelper() {
>         if (helper == null) {
>             synchronized(this) {
>                 if (helper == null) {
>                     helper = new Helper();
>                 }
>             }
>         }
>         return helper;
>     }
>
>     // other functions and members?
> }
>
> It?s broken because a thread may obtain a partially constructed object
> (the variable ?helper? may be initialized before constructor ?new Helper()?
> finished due to reordering).
>
> I am wondering is there another possible of why that is broken that, the
> ?helper? may be initialized more than once?
>
> Say Thread1 and Thread2 are now concurrently trying to get the helper
> instance, and T1 obtains the monitor(enter the synchronized block) while T2
> waits.
>
> Then T1 initialized the helper and returned, T2 entered the synchronized
> block. However, without the ?volatile? keyword, T2 may not see the update
> of the helper variable that were made by T1. So T2 may think that "helper
> == null? is true, and thus initialize the helper again.
>
> Is the above possible? Thanks in advance!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150805/acea0f68/attachment.html>

From oleksandr.otenko at oracle.com  Mon Aug 10 06:00:04 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 10 Aug 2015 11:00:04 +0100
Subject: [concurrency-interest] Upcoming jdk9 j.u.c JEP
In-Reply-To: <201125F7-B117-43A2-A1F8-04BD71A71189@rkuhn.info>
References: <55B0F8D5.4050100@cs.oswego.edu>
	<CAAPGdfFAb=bTHRs3smUQ_JefCA7ev=zvo+oLCHBf2zx843QHKg@mail.gmail.com>
	<EB1867BB-C1FB-4723-AE40-6771917D9387@rkuhn.info>
	<CAAPGdfEHoAgMQ2n8vMy=-si8=piEU+-4EiNnTtEtoDOeNJ219A@mail.gmail.com>
	<201125F7-B117-43A2-A1F8-04BD71A71189@rkuhn.info>
Message-ID: <55C87624.9030602@oracle.com>

The direction of the data flow is not important, so upstream vs 
downstream are irrelevant. The important aspect is the control flow.

There are push-streams and there are pull-streams. The error should 
propagate to the initiator.

Alex

On 24/07/2015 08:12, Roland Kuhn wrote:
> Hi Greg,
>
> my reply has obviously opened two different discussions (namely ?why 
> are things as they are?? and ?what is the suggested change all 
> about?), I think it would be most fruitful if we stash the first one 
> for now and come back to it after the second one has been understood 
> better?at least by myself. That will put us into a better situation 
> for judging the big picture.
>
> Considering the flow of data from the DB via application and framework 
> processors into the Servlet container, at any point along this line 
> failures can happen. The component emitting the failure will use 
> whatever means it has outside of Reactive Streams to log/audit/monitor 
> and provide metrics, I assume that that is just part of all reasonable 
> code; the database will do that, the application will do it, the 
> framework will probably allow the application to configure how to do 
> that, and the application server will be configured how to do that. 
> This means that everyone can debug their own failures.
>
> Data are flowing towards the Servlet (destined for whichever client 
> made the request) and it is important to signal abnormal termination 
> differently from normal termination, hence the onError propagation in 
> this direction. This also allows downstream components to see failures 
> coming from upstream, but this is a byproduct of needing to generate 
> the right kind of final response to the external client. Now the 
> interesting question is: why would the database need to know that some 
> downstream component choked on the data it emitted? How exactly would 
> this information be used by the database or its operators/programmers? 
> Arguably the data exist and are ?correct? by definition, guarded by 
> Java types, and any validation errors that occur are not stream 
> failures (cf. this definition 
> <http://www.reactivemanifesto.org/glossary#Failure>) and should be 
> treated as normal data elements and sent downstream (or filtered out, 
> depending on the requirements & protocol).
>
> I am deliberately painting with high contrast colors here in order to 
> better understand what exactly it is that you want to achieve instead 
> of just discussing the proposed solution, thanks for your patience!
>
> Regards,
>
> Roland
>
>> 24 jul 2015 kl. 08:31 skrev Greg Wilkins <gregw at webtide.com 
>> <mailto:gregw at webtide.com>>:
>>
>> Roland,
>>
>> thanks for the response.
>>
>> But I don't understand why you consider a terminal exception being 
>> notified upstream as a data flow?   It is data, but it is not a flow 
>> because it is terminal and cannot be used as a back channel.
>>
>> Implementations of the API are already required to send data 
>> upstream:  Cancellation is a terminal boolean data state that must be 
>> sent upstream, and request(int) is a flow of integers that must be 
>> sent upstream [and as an aside, it is not beyond imagination that 
>> request(int) will be misused as a back channel for data - hey it 
>> might even get used to send an error code immediately prior/post to a 
>> cancel! ]
>>
>> Thus I don't see that there is any significant additional complexity 
>> with that cancellation having a reason associated with it.   
>> Implementations must already support upward bound data and any 
>> sequencing and/or race conditions that exist with cancel(Throwable) 
>> also exist with just cancel().
>>
>> I also dispute that a Subscriber will be under the control of the 
>> Publisher.     In the example cited and application is providing a 
>> Processor, that is using a Publisher provided by a 3rd party database 
>> and an Subscriber provided by the Servlet container, with perhaps 
>> some framework provided Processors for serialization.   In this 
>> example there is the possibility of components from at least 4 
>> difference code sources being combined in a chain that crosses 
>> deployment administration boundaries of: database, application and 
>> server.     The log & cancel handling of errors is going to be very 
>> difficult because many different log mechanism may be in use and 
>> access may not be easily achieved.  ie applications developers may 
>> not have full viability of database logs or servlet container logs.
>>
>> The type of error I'm concerned about are all terminal style errors 
>> and not intended to be a back flow of data, nor acknowledgement of 
>> messages sent.   It is probably that the implementers of 
>> cancel(Throwable) would just log, cancel themselves and pass on the 
>> cancel(Throwable) to any of their Subscripions.   However the point 
>> being that would allow the reason for the failure to cross the 
>> administrative boundaries so that it can be known to all.
>>
>> I think that any argument that can be made for not sending a 
>> Throwable upstream can equally be made for not sending one downstream 
>> (or for not having any exceptions in the java language).   Exceptions 
>> are very rarely handled in any meaningful way, but are extremely 
>> useful for passing details of a failure so that they may be known to 
>> all who may need to know.
>>
>> Without exceptions  I'm imagining many many  stack over flow 
>> questions like "Why was my Subscription cancelled?" followed by 
>> obligatory "RTFLog Stupid!" responses!
>>
>> cheers
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On 24 July 2015 at 15:55, Roland Kuhn <rk at rkuhn.info 
>> <mailto:rk at rkuhn.info>> wrote:
>>
>>     Hi Greg,
>>
>>     the reasoning behind the asymmetric RS design is that this
>>     communication primitive targets unidirectional communication,
>>     bidirectional conversations would utilize two such streams
>>     running in opposite directions. This means that for a single
>>     stream data elements (of which onError is but a special one) flow
>>     downstream and only demand flows upstream. Publishers only need
>>     to know about when and if to produce the next element(s), hence
>>     we didn?t see a use-case for propagating more information than ?N
>>     elements needed? and ?no more elements needed?.
>>
>>     If a single Reactive Stream could transport data upstream then we
>>     would need to implement back-pressure on that back channel as
>>     well, leading to the same complexity as having two RS running in
>>     opposite directions. Another reason why we made this separation
>>     lies in not burdening the API designers of conforming
>>     implementations with an impossible task: the combinators offered
>>     on stream transformation APIs flow with the (English) language
>>     from left to right and describe sequences of transformation
>>     stages but with data flowing upstream there would be the need for
>>     also describing how to handle that?even if it is ?only? an error
>>     channel?and since these data flow in the opposite direction there
>>     would be no natural way to write this down.
>>
>>     Learning about the reason behind cancellation seems geared
>>     towards recovery in the sense that the Publisher would then
>>     construct and attach a different Subscriber afterwards?please let
>>     me know if you have something else in mind?and if you want to do
>>     that then the Subscriber will in any case be under the
>>     Publisher?s control and can use a different channel to
>>     communicate the onError signal back to the data source. Since
>>     that channel would transport data it would be a separate one
>>     flowing in the opposite direction as mentioned above, at least
>>     conceptually; with a single element like you describe it could
>>     well be a simpler callback mechanism and might not need full
>>     back-pressure.
>>
>>     I hope this clarifies some of the background behind the RS
>>     design. Please share more of your intended use of an error
>>     back-channel so that we can understand what exactly the upstream
>>     components would do with that data in the example case you mention.
>>
>>     Regards,
>>
>>     Roland
>>
>>>     24 jul 2015 kl. 00:35 skrev Greg Wilkins <gregw at webtide.com
>>>     <mailto:gregw at webtide.com>>:
>>>
>>>
>>>
>>>     On 24 July 2015 at 00:23, Doug Lea <dl at cs.oswego.edu
>>>     <mailto:dl at cs.oswego.edu>> wrote:
>>>
>>>
>>>         * Reactive-stream users may be disappointed that we do not
>>>         include any
>>>         net/IO-based Flow.Publisher/Subscriber classes, considering that
>>>         reactive-streams are mainly motivated by net-based
>>>         frameworks.  The
>>>         reasons for triaging these out are that (1) IO generally
>>>         falls outside
>>>         of java.util.concurrent (2) Most net-based frameworks seem
>>>         to use
>>>         custom data representation etc (e.g., JSON) that are even
>>>         further out
>>>         of scope.  However class SubmissionPublisher can be used as
>>>         an adaptor
>>>         to turn just about any kind of source into a Publisher, so
>>>         provides a
>>>         nearly universal way of constructing a good non-custom
>>>         Publisher even
>>>         from IO-based sources.  (Also notice that
>>>         SubmissionPublisher can
>>>         serve as the basis of other actor-like frameworks, including
>>>         those
>>>         turning off back-pressure by calling
>>>         subscription.request(Long.MAX_VALUE) in onSubscribe).
>>>
>>>
>>>
>>>     Doug et al,
>>>
>>>     The Jetty project has been experimenting with the reactive
>>>     streams API: https://github.com/jetty-project/jetty-reactive
>>>     albiet not with the JDK-9 version of it, but inspired by the
>>>     proposed inclusion of it.
>>>
>>>     We very much like the API and what it can bring to our space. 
>>>     We don't see that it needs direct IO support and that it's power
>>>     is actually bridging domains with a good asynchronous model that
>>>     supports flow control.
>>>
>>>     We've also begun some preliminary discussions about developing
>>>     RS based proposal for the Servlet 4.0 specification.   
>>>     Currently the Servlet API does well support asynchronous IO and
>>>     behaviour, but the API is deceptively difficult to use correctly
>>>     and gives no support for back pressure.   With RS's we can
>>>     envisage solutions that look like:
>>>
>>>       * A database provides a RS Producer that provides the large
>>>         results of a query asynchronously from a remote database server
>>>       * Some business logic is encapsulated as a RS Processor
>>>         subscribed to the database producer
>>>       * Some framework provided  Porocessors subscribe to the
>>>         business logic Processor to perform a chain of functions
>>>         such as serialization, compression
>>>       * A container provided Subscriber terminates the chain and
>>>         sends the resulting byte out over HTTP/HTTP2 or Websocket.  
>>>         The flow control mechanisms of these protocols would be the
>>>         basis of the RS back pressure.
>>>
>>>     In such solutions, a full HTTP/2 flow control window would
>>>     result in back pressure on the remote database server, allowing
>>>     threadless waiting without unlimited queuing of data.
>>>
>>>     However, we have a significant concern with the API in that we
>>>     do not like it's error handling design. Specifically that it is
>>>     asymmetric and an error in the middle of a chain of processors
>>>     can be propagated downstream with onError(Throwable) but can
>>>     only be propagated upstream with cancel().
>>>
>>>     We believe that cancel without reason is an insufficient
>>>     semantic to build a robust ecosystem of RS Processors that can
>>>     be used to build applications.   Consider the above example, it
>>>     would be ideal if the object serialization was handled by a 3rd
>>>     party Processor (let's say JSONEncodingProcessor). If the
>>>     business logic erroneously sent an non-jsonable object, or if
>>>     the JSON converter was incorrectly configured then the
>>>     JSONEcondiingProcessor could encounter an error during its
>>>     onNext(Object item) handling and it's only permitted handling of
>>>     that is to cancel the stream, without explanation.
>>>
>>>     I have raised this as an issue on the RS github and it the
>>>     current recommendation is to log and cancel:
>>>     https://github.com/reactive-streams/reactive-streams-jvm/issues/271#issuecomment-121974544
>>>     However I believe that log and cancel is a insufficient
>>>     semantic.   Logging in assembled applications is often fraught
>>>     as each component provider will fight over which logging
>>>     framework is best.  RS chains may cross jurisdictional
>>>     boundaries and logs may not even be readily available.
>>>
>>>     The solution we see is to replace/augment cancel() with either
>>>     cancel(Throwable reason) or an upstream onError(Throwable
>>>     reason).  I acknowledge that the passed reason may not always be
>>>     meaningful to the upstream processors and publishers, but it is
>>>     better to ignore a meaningless reason than to be ignorant of a
>>>     meaningful one.
>>>
>>>     When considering this API, we have to look beyond usages that
>>>     work well and consider usages that will fail well also!
>>>
>>>     cheers
>>>
>>>     -- 
>>>     Greg Wilkins <gregw at webtide.com <mailto:gregw at webtide.com>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>     --
>>     I'm a physicist: I have a basic working knowledge of the universe
>>     and everything it contains!
>>         - Sheldon Cooper (The Big Bang Theory)
>>
>>
>
> --
> I'm a physicist: I have a basic working knowledge of the universe and 
> everything it contains!
>     - Sheldon Cooper (The Big Bang Theory)
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150810/8f01e9f5/attachment-0001.html>

From viktor.klang at gmail.com  Mon Aug 10 07:38:57 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 10 Aug 2015 13:38:57 +0200
Subject: [concurrency-interest] Upcoming jdk9 j.u.c JEP
In-Reply-To: <55C87624.9030602@oracle.com>
References: <55B0F8D5.4050100@cs.oswego.edu>
	<CAAPGdfFAb=bTHRs3smUQ_JefCA7ev=zvo+oLCHBf2zx843QHKg@mail.gmail.com>
	<EB1867BB-C1FB-4723-AE40-6771917D9387@rkuhn.info>
	<CAAPGdfEHoAgMQ2n8vMy=-si8=piEU+-4EiNnTtEtoDOeNJ219A@mail.gmail.com>
	<201125F7-B117-43A2-A1F8-04BD71A71189@rkuhn.info>
	<55C87624.9030602@oracle.com>
Message-ID: <CANPzfU8oH30fs64An3F+2AYGQV6isTXt1cz8Azsjp=GQmCdoFA@mail.gmail.com>

#define initiator

On Mon, Aug 10, 2015 at 12:00 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

> The direction of the data flow is not important, so upstream vs downstream
> are irrelevant. The important aspect is the control flow.
>
> There are push-streams and there are pull-streams. The error should
> propagate to the initiator.
>
> Alex
>
>
> On 24/07/2015 08:12, Roland Kuhn wrote:
>
> Hi Greg,
>
> my reply has obviously opened two different discussions (namely ?why are
> things as they are?? and ?what is the suggested change all about?), I think
> it would be most fruitful if we stash the first one for now and come back
> to it after the second one has been understood better?at least by myself.
> That will put us into a better situation for judging the big picture.
>
> Considering the flow of data from the DB via application and framework
> processors into the Servlet container, at any point along this line
> failures can happen. The component emitting the failure will use whatever
> means it has outside of Reactive Streams to log/audit/monitor and provide
> metrics, I assume that that is just part of all reasonable code; the
> database will do that, the application will do it, the framework will
> probably allow the application to configure how to do that, and the
> application server will be configured how to do that. This means that
> everyone can debug their own failures.
>
> Data are flowing towards the Servlet (destined for whichever client made
> the request) and it is important to signal abnormal termination differently
> from normal termination, hence the onError propagation in this direction.
> This also allows downstream components to see failures coming from
> upstream, but this is a byproduct of needing to generate the right kind of
> final response to the external client. Now the interesting question is: why
> would the database need to know that some downstream component choked on
> the data it emitted? How exactly would this information be used by the
> database or its operators/programmers? Arguably the data exist and are
> ?correct? by definition, guarded by Java types, and any validation errors
> that occur are not stream failures (cf. this definition
> <http://www.reactivemanifesto.org/glossary#Failure>) and should be
> treated as normal data elements and sent downstream (or filtered out,
> depending on the requirements & protocol).
>
> I am deliberately painting with high contrast colors here in order to
> better understand what exactly it is that you want to achieve instead of
> just discussing the proposed solution, thanks for your patience!
>
> Regards,
>
> Roland
>
> 24 jul 2015 kl. 08:31 skrev Greg Wilkins < <gregw at webtide.com>
> gregw at webtide.com>:
>
> Roland,
>
> thanks for the response.
>
> But I don't understand why you consider a terminal exception being
> notified upstream as a data flow?   It is data, but it is not a flow
> because it is terminal and cannot be used as a back channel.
>
> Implementations of the API are already required to send data upstream:
> Cancellation is a terminal boolean data state that must be sent upstream,
> and request(int) is a flow of integers that must be sent upstream [and as
> an aside, it is not beyond imagination that request(int) will be misused as
> a back channel for data - hey it might even get used to send an error code
> immediately prior/post to a cancel! ]
>
> Thus I don't see that there is any significant additional complexity with
> that cancellation having a reason associated with it.   Implementations
> must already support upward bound data and any sequencing and/or race
> conditions that exist with cancel(Throwable) also exist with just cancel().
>
> I also dispute that a Subscriber will be under the control of the
> Publisher.     In the example cited and application is providing a
> Processor, that is using a Publisher provided by a 3rd party database and
> an Subscriber provided by the Servlet container, with perhaps some
> framework provided Processors for serialization.   In this example there is
> the possibility of components from at least 4 difference code sources being
> combined in a chain that crosses deployment administration boundaries of:
> database, application and server.     The log & cancel handling of errors
> is going to be very difficult because many different log mechanism may be
> in use and access may not be easily achieved.  ie applications developers
> may not have full viability of database logs or servlet container logs.
>
> The type of error I'm concerned about are all terminal style errors and
> not intended to be a back flow of data, nor acknowledgement of messages
> sent.   It is probably that the implementers of cancel(Throwable) would
> just log, cancel themselves and pass on the cancel(Throwable) to any of
> their Subscripions.   However the point being that would allow the reason
> for the failure to cross the administrative boundaries so that it can be
> known to all.
>
> I think that any argument that can be made for not sending a Throwable
> upstream can equally be made for not sending one downstream (or for not
> having any exceptions in the java language).   Exceptions are very rarely
> handled in any meaningful way, but are extremely useful for passing details
> of a failure so that they may be known to all who may need to know.
>
> Without exceptions  I'm imagining many many  stack over flow questions
> like "Why was my Subscription cancelled?" followed by obligatory "RTFLog
> Stupid!" responses!
>
> cheers
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> On 24 July 2015 at 15:55, Roland Kuhn < <rk at rkuhn.info>rk at rkuhn.info>
> wrote:
>
>> Hi Greg,
>>
>> the reasoning behind the asymmetric RS design is that this communication
>> primitive targets unidirectional communication, bidirectional conversations
>> would utilize two such streams running in opposite directions. This means
>> that for a single stream data elements (of which onError is but a special
>> one) flow downstream and only demand flows upstream. Publishers only need
>> to know about when and if to produce the next element(s), hence we didn?t
>> see a use-case for propagating more information than ?N elements needed?
>> and ?no more elements needed?.
>>
>> If a single Reactive Stream could transport data upstream then we would
>> need to implement back-pressure on that back channel as well, leading to
>> the same complexity as having two RS running in opposite directions.
>> Another reason why we made this separation lies in not burdening the API
>> designers of conforming implementations with an impossible task: the
>> combinators offered on stream transformation APIs flow with the (English)
>> language from left to right and describe sequences of transformation stages
>> but with data flowing upstream there would be the need for also describing
>> how to handle that?even if it is ?only? an error channel?and since these
>> data flow in the opposite direction there would be no natural way to write
>> this down.
>>
>> Learning about the reason behind cancellation seems geared towards
>> recovery in the sense that the Publisher would then construct and attach a
>> different Subscriber afterwards?please let me know if you have something
>> else in mind?and if you want to do that then the Subscriber will in any
>> case be under the Publisher?s control and can use a different channel to
>> communicate the onError signal back to the data source. Since that channel
>> would transport data it would be a separate one flowing in the opposite
>> direction as mentioned above, at least conceptually; with a single element
>> like you describe it could well be a simpler callback mechanism and might
>> not need full back-pressure.
>>
>> I hope this clarifies some of the background behind the RS design. Please
>> share more of your intended use of an error back-channel so that we can
>> understand what exactly the upstream components would do with that data in
>> the example case you mention.
>>
>> Regards,
>>
>> Roland
>>
>> 24 jul 2015 kl. 00:35 skrev Greg Wilkins < <gregw at webtide.com>
>> gregw at webtide.com>:
>>
>>
>>
>> On 24 July 2015 at 00:23, Doug Lea < <dl at cs.oswego.edu>dl at cs.oswego.edu>
>> wrote:
>>
>>>
>>> * Reactive-stream users may be disappointed that we do not include any
>>> net/IO-based Flow.Publisher/Subscriber classes, considering that
>>> reactive-streams are mainly motivated by net-based frameworks.  The
>>> reasons for triaging these out are that (1) IO generally falls outside
>>> of java.util.concurrent (2) Most net-based frameworks seem to use
>>> custom data representation etc (e.g., JSON) that are even further out
>>> of scope.  However class SubmissionPublisher can be used as an adaptor
>>> to turn just about any kind of source into a Publisher, so provides a
>>> nearly universal way of constructing a good non-custom Publisher even
>>> from IO-based sources.  (Also notice that SubmissionPublisher can
>>> serve as the basis of other actor-like frameworks, including those
>>> turning off back-pressure by calling
>>> subscription.request(Long.MAX_VALUE) in onSubscribe).
>>>
>>>
>>
>> Doug et al,
>>
>> The Jetty project has been experimenting with the reactive streams API:
>> <https://github.com/jetty-project/jetty-reactive>
>> https://github.com/jetty-project/jetty-reactive albiet not with the
>> JDK-9 version of it, but inspired by the proposed inclusion of it.
>>
>> We very much like the API and what it can bring to our space.  We don't
>> see that it needs direct IO support and that it's power is actually
>> bridging domains with a good asynchronous model that supports flow
>> control.
>>
>> We've also begun some preliminary discussions about developing RS based
>> proposal for the Servlet 4.0 specification.    Currently the Servlet API
>> does well support asynchronous IO and behaviour, but the API is deceptively
>> difficult to use correctly and gives no support for back pressure.   With
>> RS's we can envisage solutions that look like:
>>
>>    - A database provides a RS Producer that provides the large results
>>    of a query asynchronously from a remote database server
>>    - Some business logic is encapsulated as a RS Processor subscribed to
>>    the database producer
>>    - Some framework provided  Porocessors subscribe to the business
>>    logic Processor to perform a chain of functions such as serialization,
>>    compression
>>    - A container provided Subscriber terminates the chain and sends the
>>    resulting byte out over HTTP/HTTP2 or Websocket.   The flow control
>>    mechanisms of these protocols would be the basis of the RS back pressure.
>>
>> In such solutions, a full HTTP/2 flow control window would result in back
>> pressure on the remote database server, allowing threadless waiting without
>> unlimited queuing of data.
>>
>> However, we have a significant concern with the API in that we do not
>> like it's error handling design.  Specifically that it is asymmetric and an
>> error in the middle of a chain of processors can be propagated downstream
>> with onError(Throwable) but can only be propagated upstream with cancel().
>>
>> We believe that cancel without reason is an insufficient semantic to
>> build a robust ecosystem of RS Processors that can be used to build
>> applications.   Consider the above example, it would be ideal if the object
>> serialization was handled by a 3rd party Processor (let's say
>> JSONEncodingProcessor). If the business logic erroneously sent an
>> non-jsonable object, or if the JSON converter was incorrectly configured
>> then the JSONEcondiingProcessor could encounter an error during its
>> onNext(Object item) handling and it's only permitted handling of that is to
>> cancel the stream, without explanation.
>>
>> I have raised this as an issue on the RS github and it the current
>> recommendation is to log and cancel:
>> <https://github.com/reactive-streams/reactive-streams-jvm/issues/271#issuecomment-121974544>
>> https://github.com/reactive-streams/reactive-streams-jvm/issues/271#issuecomment-121974544
>> However I believe that log and cancel is a insufficient semantic.   Logging
>> in assembled applications is often fraught as each component provider will
>> fight over which logging framework is best.  RS chains may cross
>> jurisdictional boundaries and logs may not even be readily available.
>>
>> The solution we see is to replace/augment cancel() with either
>> cancel(Throwable reason) or an upstream onError(Throwable reason).  I
>> acknowledge that the passed reason may not always be meaningful to the
>> upstream processors and publishers, but it is better to ignore a
>> meaningless reason than to be ignorant of a meaningful one.
>>
>> When considering this API, we have to look beyond usages that work well
>> and consider usages that will fail well also!
>>
>> cheers
>>
>> --
>> Greg Wilkins < <gregw at webtide.com>gregw at webtide.com>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> --
>> I'm a physicist: I have a basic working knowledge of the universe and
>> everything it contains!
>>     - Sheldon Cooper (The Big Bang Theory)
>>
>>
>
> --
> I'm a physicist: I have a basic working knowledge of the universe and
> everything it contains!
>     - Sheldon Cooper (The Big Bang Theory)
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150810/5d06675d/attachment-0001.html>

From oleksandr.otenko at oracle.com  Mon Aug 10 08:13:17 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 10 Aug 2015 13:13:17 +0100
Subject: [concurrency-interest] Upcoming jdk9 j.u.c JEP
In-Reply-To: <CANPzfU8oH30fs64An3F+2AYGQV6isTXt1cz8Azsjp=GQmCdoFA@mail.gmail.com>
References: <55B0F8D5.4050100@cs.oswego.edu>
	<CAAPGdfFAb=bTHRs3smUQ_JefCA7ev=zvo+oLCHBf2zx843QHKg@mail.gmail.com>
	<EB1867BB-C1FB-4723-AE40-6771917D9387@rkuhn.info>
	<CAAPGdfEHoAgMQ2n8vMy=-si8=piEU+-4EiNnTtEtoDOeNJ219A@mail.gmail.com>
	<201125F7-B117-43A2-A1F8-04BD71A71189@rkuhn.info>
	<55C87624.9030602@oracle.com>
	<CANPzfU8oH30fs64An3F+2AYGQV6isTXt1cz8Azsjp=GQmCdoFA@mail.gmail.com>
Message-ID: <55C8955D.5040602@oracle.com>

The initiator of the next data transfer. Push-stream - the producer 
initiates the transfer of the next portion of the data. Pull-stream - 
the consumer initiates the transfer of the next portion of the data. 
There are mixes of these, too (parser: token detected - producer pushes; 
now the token handling code pulls the rest of expression, but only the 
expression - the producer can't do that, because it doesn't know what 
the expression is).


Alex

On 10/08/2015 12:38, Viktor Klang wrote:
> #define initiator
>
> On Mon, Aug 10, 2015 at 12:00 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     The direction of the data flow is not important, so upstream vs
>     downstream are irrelevant. The important aspect is the control flow.
>
>     There are push-streams and there are pull-streams. The error
>     should propagate to the initiator.
>
>     Alex
>
>
>     On 24/07/2015 08:12, Roland Kuhn wrote:
>>     Hi Greg,
>>
>>     my reply has obviously opened two different discussions (namely
>>     ?why are things as they are?? and ?what is the suggested change
>>     all about?), I think it would be most fruitful if we stash the
>>     first one for now and come back to it after the second one has
>>     been understood better?at least by myself. That will put us into
>>     a better situation for judging the big picture.
>>
>>     Considering the flow of data from the DB via application and
>>     framework processors into the Servlet container, at any point
>>     along this line failures can happen. The component emitting the
>>     failure will use whatever means it has outside of Reactive
>>     Streams to log/audit/monitor and provide metrics, I assume that
>>     that is just part of all reasonable code; the database will do
>>     that, the application will do it, the framework will probably
>>     allow the application to configure how to do that, and the
>>     application server will be configured how to do that. This means
>>     that everyone can debug their own failures.
>>
>>     Data are flowing towards the Servlet (destined for whichever
>>     client made the request) and it is important to signal abnormal
>>     termination differently from normal termination, hence the
>>     onError propagation in this direction. This also allows
>>     downstream components to see failures coming from upstream, but
>>     this is a byproduct of needing to generate the right kind of
>>     final response to the external client. Now the interesting
>>     question is: why would the database need to know that some
>>     downstream component choked on the data it emitted? How exactly
>>     would this information be used by the database or its
>>     operators/programmers? Arguably the data exist and are ?correct?
>>     by definition, guarded by Java types, and any validation errors
>>     that occur are not stream failures (cf. this definition
>>     <http://www.reactivemanifesto.org/glossary#Failure>) and should
>>     be treated as normal data elements and sent downstream (or
>>     filtered out, depending on the requirements & protocol).
>>
>>     I am deliberately painting with high contrast colors here in
>>     order to better understand what exactly it is that you want to
>>     achieve instead of just discussing the proposed solution, thanks
>>     for your patience!
>>
>>     Regards,
>>
>>     Roland
>>
>>>     24 jul 2015 kl. 08:31 skrev Greg Wilkins <gregw at webtide.com
>>>     <mailto:gregw at webtide.com>>:
>>>
>>>     Roland,
>>>
>>>     thanks for the response.
>>>
>>>     But I don't understand why you consider a terminal exception
>>>     being notified upstream as a data flow?   It is data, but it is
>>>     not a flow because it is terminal and cannot be used as a back
>>>     channel.
>>>
>>>     Implementations of the API are already required to send data
>>>     upstream: Cancellation is a terminal boolean data state that
>>>     must be sent upstream, and request(int) is a flow of integers
>>>     that must be sent upstream [and as an aside, it is not beyond
>>>     imagination that request(int) will be misused as a back channel
>>>     for data - hey it might even get used to send an error code
>>>     immediately prior/post to a cancel! ]
>>>
>>>     Thus I don't see that there is any significant additional
>>>     complexity with that cancellation having a reason associated
>>>     with it.   Implementations must already support upward bound
>>>     data and any sequencing and/or race conditions that exist with
>>>     cancel(Throwable) also exist with just cancel().
>>>
>>>     I also dispute that a Subscriber will be under the control of
>>>     the Publisher.     In the example cited and application is
>>>     providing a Processor, that is using a Publisher provided by a
>>>     3rd party database and an Subscriber provided by the Servlet
>>>     container, with perhaps some framework provided Processors for
>>>     serialization.   In this example there is the possibility of
>>>     components from at least 4 difference code sources being
>>>     combined in a chain that crosses deployment administration
>>>     boundaries of: database, application and server.     The log &
>>>     cancel handling of errors is going to be very difficult because
>>>     many different log mechanism may be in use and access may not be
>>>     easily achieved.  ie applications developers may not have full
>>>     viability of database logs or servlet container logs.
>>>
>>>     The type of error I'm concerned about are all terminal style
>>>     errors and not intended to be a back flow of data, nor
>>>     acknowledgement of messages sent.   It is probably that the
>>>     implementers of cancel(Throwable) would just log, cancel
>>>     themselves and pass on the cancel(Throwable) to any of their
>>>     Subscripions.   However the point being that would allow the
>>>     reason for the failure to cross the administrative boundaries so
>>>     that it can be known to all.
>>>
>>>     I think that any argument that can be made for not sending a
>>>     Throwable upstream can equally be made for not sending one
>>>     downstream (or for not having any exceptions in the java
>>>     language).   Exceptions are very rarely handled in any
>>>     meaningful way, but are extremely useful for passing details of
>>>     a failure so that they may be known to all who may need to know.
>>>
>>>     Without exceptions  I'm imagining many many  stack over flow
>>>     questions like "Why was my Subscription cancelled?" followed by
>>>     obligatory "RTFLog Stupid!" responses!
>>>
>>>     cheers
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>     On 24 July 2015 at 15:55, Roland Kuhn <rk at rkuhn.info
>>>     <mailto:rk at rkuhn.info>> wrote:
>>>
>>>         Hi Greg,
>>>
>>>         the reasoning behind the asymmetric RS design is that this
>>>         communication primitive targets unidirectional
>>>         communication, bidirectional conversations would utilize two
>>>         such streams running in opposite directions. This means that
>>>         for a single stream data elements (of which onError is but a
>>>         special one) flow downstream and only demand flows upstream.
>>>         Publishers only need to know about when and if to produce
>>>         the next element(s), hence we didn?t see a use-case for
>>>         propagating more information than ?N elements needed? and
>>>         ?no more elements needed?.
>>>
>>>         If a single Reactive Stream could transport data upstream
>>>         then we would need to implement back-pressure on that back
>>>         channel as well, leading to the same complexity as having
>>>         two RS running in opposite directions. Another reason why we
>>>         made this separation lies in not burdening the API designers
>>>         of conforming implementations with an impossible task: the
>>>         combinators offered on stream transformation APIs flow with
>>>         the (English) language from left to right and describe
>>>         sequences of transformation stages but with data flowing
>>>         upstream there would be the need for also describing how to
>>>         handle that?even if it is ?only? an error channel?and since
>>>         these data flow in the opposite direction there would be no
>>>         natural way to write this down.
>>>
>>>         Learning about the reason behind cancellation seems geared
>>>         towards recovery in the sense that the Publisher would then
>>>         construct and attach a different Subscriber
>>>         afterwards?please let me know if you have something else in
>>>         mind?and if you want to do that then the Subscriber will in
>>>         any case be under the Publisher?s control and can use a
>>>         different channel to communicate the onError signal back to
>>>         the data source. Since that channel would transport data it
>>>         would be a separate one flowing in the opposite direction as
>>>         mentioned above, at least conceptually; with a single
>>>         element like you describe it could well be a simpler
>>>         callback mechanism and might not need full back-pressure.
>>>
>>>         I hope this clarifies some of the background behind the RS
>>>         design. Please share more of your intended use of an error
>>>         back-channel so that we can understand what exactly the
>>>         upstream components would do with that data in the example
>>>         case you mention.
>>>
>>>         Regards,
>>>
>>>         Roland
>>>
>>>>         24 jul 2015 kl. 00:35 skrev Greg Wilkins <gregw at webtide.com
>>>>         <mailto:gregw at webtide.com>>:
>>>>
>>>>
>>>>
>>>>         On 24 July 2015 at 00:23, Doug Lea <dl at cs.oswego.edu
>>>>         <mailto:dl at cs.oswego.edu>> wrote:
>>>>
>>>>
>>>>             * Reactive-stream users may be disappointed that we do
>>>>             not include any
>>>>             net/IO-based Flow.Publisher/Subscriber classes,
>>>>             considering that
>>>>             reactive-streams are mainly motivated by net-based
>>>>             frameworks.  The
>>>>             reasons for triaging these out are that (1) IO
>>>>             generally falls outside
>>>>             of java.util.concurrent (2) Most net-based frameworks
>>>>             seem to use
>>>>             custom data representation etc (e.g., JSON) that are
>>>>             even further out
>>>>             of scope. However class SubmissionPublisher can be used
>>>>             as an adaptor
>>>>             to turn just about any kind of source into a Publisher,
>>>>             so provides a
>>>>             nearly universal way of constructing a good non-custom
>>>>             Publisher even
>>>>             from IO-based sources.  (Also notice that
>>>>             SubmissionPublisher can
>>>>             serve as the basis of other actor-like frameworks,
>>>>             including those
>>>>             turning off back-pressure by calling
>>>>             subscription.request(Long.MAX_VALUE) in onSubscribe).
>>>>
>>>>
>>>>
>>>>         Doug et al,
>>>>
>>>>         The Jetty project has been experimenting with the reactive
>>>>         streams API:
>>>>         https://github.com/jetty-project/jetty-reactive albiet not
>>>>         with the JDK-9 version of it, but inspired by the proposed
>>>>         inclusion of it.
>>>>
>>>>         We very much like the API and what it can bring to our
>>>>         space.  We don't see that it needs direct IO support and
>>>>         that it's power is actually bridging domains with a good
>>>>         asynchronous model that supports flow control.
>>>>
>>>>         We've also begun some preliminary discussions about
>>>>         developing RS based proposal for the Servlet 4.0
>>>>         specification. Currently the Servlet API does well support
>>>>         asynchronous IO and behaviour, but the API is deceptively
>>>>         difficult to use correctly and gives no support for back
>>>>         pressure.   With RS's we can envisage solutions that look like:
>>>>
>>>>           * A database provides a RS Producer that provides the
>>>>             large results of a query asynchronously from a remote
>>>>             database server
>>>>           * Some business logic is encapsulated as a RS Processor
>>>>             subscribed to the database producer
>>>>           * Some framework provided Porocessors subscribe to the
>>>>             business logic Processor to perform a chain of
>>>>             functions such as serialization, compression
>>>>           * A container provided Subscriber terminates the chain
>>>>             and sends the resulting byte out over HTTP/HTTP2 or
>>>>             Websocket. The flow control mechanisms of these
>>>>             protocols would be the basis of the RS back pressure.
>>>>
>>>>         In such solutions, a full HTTP/2 flow control window would
>>>>         result in back pressure on the remote database server,
>>>>         allowing threadless waiting without unlimited queuing of data.
>>>>
>>>>         However, we have a significant concern with the API in that
>>>>         we do not like it's error handling design. Specifically
>>>>         that it is asymmetric and an error in the middle of a chain
>>>>         of processors can be propagated downstream with
>>>>         onError(Throwable) but can only be propagated upstream with
>>>>         cancel().
>>>>
>>>>         We believe that cancel without reason is an insufficient
>>>>         semantic to build a robust ecosystem of RS Processors that
>>>>         can be used to build applications. Consider the above
>>>>         example, it would be ideal if the object serialization was
>>>>         handled by a 3rd party Processor (let's say
>>>>         JSONEncodingProcessor). If the business logic erroneously
>>>>         sent an non-jsonable object, or if the JSON converter was
>>>>         incorrectly configured then the JSONEcondiingProcessor
>>>>         could encounter an error during its onNext(Object item)
>>>>         handling and it's only permitted handling of that is to
>>>>         cancel the stream, without explanation.
>>>>
>>>>         I have raised this as an issue on the RS github and it the
>>>>         current recommendation is to log and cancel:
>>>>         https://github.com/reactive-streams/reactive-streams-jvm/issues/271#issuecomment-121974544
>>>>         However I believe that log and cancel is a insufficient
>>>>         semantic. Logging in assembled applications is often
>>>>         fraught as each component provider will fight over which
>>>>         logging framework is best.  RS chains may cross
>>>>         jurisdictional boundaries and logs may not even be readily
>>>>         available.
>>>>
>>>>         The solution we see is to replace/augment cancel() with
>>>>         either cancel(Throwable reason) or an upstream
>>>>         onError(Throwable reason).  I acknowledge that the passed
>>>>         reason may not always be meaningful to the upstream
>>>>         processors and publishers, but it is better to ignore a
>>>>         meaningless reason than to be ignorant of a meaningful one.
>>>>
>>>>         When considering this API, we have to look beyond usages
>>>>         that work well and consider usages that will fail well also!
>>>>
>>>>         cheers
>>>>
>>>>         -- 
>>>>         Greg Wilkins <gregw at webtide.com <mailto:gregw at webtide.com>>
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu
>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>         --
>>>         I'm a physicist: I have a basic working knowledge of the
>>>         universe and everything it contains!
>>>             - Sheldon Cooper (The Big Bang Theory)
>>>
>>>
>>
>>     --
>>     I'm a physicist: I have a basic working knowledge of the universe
>>     and everything it contains!
>>         - Sheldon Cooper (The Big Bang Theory)
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150810/505ce8a2/attachment-0001.html>

From viktor.klang at gmail.com  Mon Aug 10 08:44:22 2015
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 10 Aug 2015 14:44:22 +0200
Subject: [concurrency-interest] Upcoming jdk9 j.u.c JEP
In-Reply-To: <55C8955D.5040602@oracle.com>
References: <55B0F8D5.4050100@cs.oswego.edu>
	<CAAPGdfFAb=bTHRs3smUQ_JefCA7ev=zvo+oLCHBf2zx843QHKg@mail.gmail.com>
	<EB1867BB-C1FB-4723-AE40-6771917D9387@rkuhn.info>
	<CAAPGdfEHoAgMQ2n8vMy=-si8=piEU+-4EiNnTtEtoDOeNJ219A@mail.gmail.com>
	<201125F7-B117-43A2-A1F8-04BD71A71189@rkuhn.info>
	<55C87624.9030602@oracle.com>
	<CANPzfU8oH30fs64An3F+2AYGQV6isTXt1cz8Azsjp=GQmCdoFA@mail.gmail.com>
	<55C8955D.5040602@oracle.com>
Message-ID: <CANPzfU9kb5orBY+BfOsFe0v0BrV_WBX01_oWGy=Bz3rKBfAARw@mail.gmail.com>

Ok, then everything is as it should.
The exception travels towards the direction of the entity which requests
the transfer.

-- 
Cheers,
?
On 10 Aug 2015 14:13, "Oleksandr Otenko" <oleksandr.otenko at oracle.com>
wrote:

> The initiator of the next data transfer. Push-stream - the producer
> initiates the transfer of the next portion of the data. Pull-stream - the
> consumer initiates the transfer of the next portion of the data. There are
> mixes of these, too (parser: token detected - producer pushes; now the
> token handling code pulls the rest of expression, but only the expression -
> the producer can't do that, because it doesn't know what the expression is).
>
>
> Alex
>
> On 10/08/2015 12:38, Viktor Klang wrote:
>
> #define initiator
>
> On Mon, Aug 10, 2015 at 12:00 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>> The direction of the data flow is not important, so upstream vs
>> downstream are irrelevant. The important aspect is the control flow.
>>
>> There are push-streams and there are pull-streams. The error should
>> propagate to the initiator.
>>
>> Alex
>>
>>
>> On 24/07/2015 08:12, Roland Kuhn wrote:
>>
>> Hi Greg,
>>
>> my reply has obviously opened two different discussions (namely ?why are
>> things as they are?? and ?what is the suggested change all about?), I think
>> it would be most fruitful if we stash the first one for now and come back
>> to it after the second one has been understood better?at least by myself.
>> That will put us into a better situation for judging the big picture.
>>
>> Considering the flow of data from the DB via application and framework
>> processors into the Servlet container, at any point along this line
>> failures can happen. The component emitting the failure will use whatever
>> means it has outside of Reactive Streams to log/audit/monitor and provide
>> metrics, I assume that that is just part of all reasonable code; the
>> database will do that, the application will do it, the framework will
>> probably allow the application to configure how to do that, and the
>> application server will be configured how to do that. This means that
>> everyone can debug their own failures.
>>
>> Data are flowing towards the Servlet (destined for whichever client made
>> the request) and it is important to signal abnormal termination differently
>> from normal termination, hence the onError propagation in this direction.
>> This also allows downstream components to see failures coming from
>> upstream, but this is a byproduct of needing to generate the right kind of
>> final response to the external client. Now the interesting question is: why
>> would the database need to know that some downstream component choked on
>> the data it emitted? How exactly would this information be used by the
>> database or its operators/programmers? Arguably the data exist and are
>> ?correct? by definition, guarded by Java types, and any validation errors
>> that occur are not stream failures (cf. this definition
>> <http://www.reactivemanifesto.org/glossary#Failure>) and should be
>> treated as normal data elements and sent downstream (or filtered out,
>> depending on the requirements & protocol).
>>
>> I am deliberately painting with high contrast colors here in order to
>> better understand what exactly it is that you want to achieve instead of
>> just discussing the proposed solution, thanks for your patience!
>>
>> Regards,
>>
>> Roland
>>
>> 24 jul 2015 kl. 08:31 skrev Greg Wilkins <gregw at webtide.com>:
>>
>> Roland,
>>
>> thanks for the response.
>>
>> But I don't understand why you consider a terminal exception being
>> notified upstream as a data flow?   It is data, but it is not a flow
>> because it is terminal and cannot be used as a back channel.
>>
>> Implementations of the API are already required to send data upstream:
>> Cancellation is a terminal boolean data state that must be sent upstream,
>> and request(int) is a flow of integers that must be sent upstream [and as
>> an aside, it is not beyond imagination that request(int) will be misused as
>> a back channel for data - hey it might even get used to send an error code
>> immediately prior/post to a cancel! ]
>>
>> Thus I don't see that there is any significant additional complexity with
>> that cancellation having a reason associated with it.   Implementations
>> must already support upward bound data and any sequencing and/or race
>> conditions that exist with cancel(Throwable) also exist with just cancel().
>>
>> I also dispute that a Subscriber will be under the control of the
>> Publisher.     In the example cited and application is providing a
>> Processor, that is using a Publisher provided by a 3rd party database and
>> an Subscriber provided by the Servlet container, with perhaps some
>> framework provided Processors for serialization.   In this example there is
>> the possibility of components from at least 4 difference code sources being
>> combined in a chain that crosses deployment administration boundaries of:
>> database, application and server.     The log & cancel handling of errors
>> is going to be very difficult because many different log mechanism may be
>> in use and access may not be easily achieved.  ie applications developers
>> may not have full viability of database logs or servlet container logs.
>>
>> The type of error I'm concerned about are all terminal style errors and
>> not intended to be a back flow of data, nor acknowledgement of messages
>> sent.   It is probably that the implementers of cancel(Throwable) would
>> just log, cancel themselves and pass on the cancel(Throwable) to any of
>> their Subscripions.   However the point being that would allow the reason
>> for the failure to cross the administrative boundaries so that it can be
>> known to all.
>>
>> I think that any argument that can be made for not sending a Throwable
>> upstream can equally be made for not sending one downstream (or for not
>> having any exceptions in the java language).   Exceptions are very rarely
>> handled in any meaningful way, but are extremely useful for passing details
>> of a failure so that they may be known to all who may need to know.
>>
>> Without exceptions  I'm imagining many many  stack over flow questions
>> like "Why was my Subscription cancelled?" followed by obligatory "RTFLog
>> Stupid!" responses!
>>
>> cheers
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On 24 July 2015 at 15:55, Roland Kuhn <rk at rkuhn.info> wrote:
>>
>>> Hi Greg,
>>>
>>> the reasoning behind the asymmetric RS design is that this communication
>>> primitive targets unidirectional communication, bidirectional conversations
>>> would utilize two such streams running in opposite directions. This means
>>> that for a single stream data elements (of which onError is but a special
>>> one) flow downstream and only demand flows upstream. Publishers only need
>>> to know about when and if to produce the next element(s), hence we didn?t
>>> see a use-case for propagating more information than ?N elements needed?
>>> and ?no more elements needed?.
>>>
>>> If a single Reactive Stream could transport data upstream then we would
>>> need to implement back-pressure on that back channel as well, leading to
>>> the same complexity as having two RS running in opposite directions.
>>> Another reason why we made this separation lies in not burdening the API
>>> designers of conforming implementations with an impossible task: the
>>> combinators offered on stream transformation APIs flow with the (English)
>>> language from left to right and describe sequences of transformation stages
>>> but with data flowing upstream there would be the need for also describing
>>> how to handle that?even if it is ?only? an error channel?and since these
>>> data flow in the opposite direction there would be no natural way to write
>>> this down.
>>>
>>> Learning about the reason behind cancellation seems geared towards
>>> recovery in the sense that the Publisher would then construct and attach a
>>> different Subscriber afterwards?please let me know if you have something
>>> else in mind?and if you want to do that then the Subscriber will in any
>>> case be under the Publisher?s control and can use a different channel to
>>> communicate the onError signal back to the data source. Since that channel
>>> would transport data it would be a separate one flowing in the opposite
>>> direction as mentioned above, at least conceptually; with a single element
>>> like you describe it could well be a simpler callback mechanism and might
>>> not need full back-pressure.
>>>
>>> I hope this clarifies some of the background behind the RS design.
>>> Please share more of your intended use of an error back-channel so that we
>>> can understand what exactly the upstream components would do with that data
>>> in the example case you mention.
>>>
>>> Regards,
>>>
>>> Roland
>>>
>>> 24 jul 2015 kl. 00:35 skrev Greg Wilkins <gregw at webtide.com>:
>>>
>>>
>>>
>>> On 24 July 2015 at 00:23, Doug Lea <dl at cs.oswego.edu> wrote:
>>>
>>>>
>>>> * Reactive-stream users may be disappointed that we do not include any
>>>> net/IO-based Flow.Publisher/Subscriber classes, considering that
>>>> reactive-streams are mainly motivated by net-based frameworks.  The
>>>> reasons for triaging these out are that (1) IO generally falls outside
>>>> of java.util.concurrent (2) Most net-based frameworks seem to use
>>>> custom data representation etc (e.g., JSON) that are even further out
>>>> of scope.  However class SubmissionPublisher can be used as an adaptor
>>>> to turn just about any kind of source into a Publisher, so provides a
>>>> nearly universal way of constructing a good non-custom Publisher even
>>>> from IO-based sources.  (Also notice that SubmissionPublisher can
>>>> serve as the basis of other actor-like frameworks, including those
>>>> turning off back-pressure by calling
>>>> subscription.request(Long.MAX_VALUE) in onSubscribe).
>>>>
>>>>
>>>
>>> Doug et al,
>>>
>>> The Jetty project has been experimenting with the reactive streams API:
>>> https://github.com/jetty-project/jetty-reactive albiet not with the
>>> JDK-9 version of it, but inspired by the proposed inclusion of it.
>>>
>>> We very much like the API and what it can bring to our space.  We don't
>>> see that it needs direct IO support and that it's power is actually
>>> bridging domains with a good asynchronous model that supports flow
>>> control.
>>>
>>> We've also begun some preliminary discussions about developing RS based
>>> proposal for the Servlet 4.0 specification.    Currently the Servlet API
>>> does well support asynchronous IO and behaviour, but the API is deceptively
>>> difficult to use correctly and gives no support for back pressure.   With
>>> RS's we can envisage solutions that look like:
>>>
>>>    - A database provides a RS Producer that provides the large results
>>>    of a query asynchronously from a remote database server
>>>    - Some business logic is encapsulated as a RS Processor subscribed
>>>    to the database producer
>>>    - Some framework provided  Porocessors subscribe to the business
>>>    logic Processor to perform a chain of functions such as serialization,
>>>    compression
>>>    - A container provided Subscriber terminates the chain and sends the
>>>    resulting byte out over HTTP/HTTP2 or Websocket.   The flow control
>>>    mechanisms of these protocols would be the basis of the RS back pressure.
>>>
>>> In such solutions, a full HTTP/2 flow control window would result in
>>> back pressure on the remote database server, allowing threadless waiting
>>> without unlimited queuing of data.
>>>
>>> However, we have a significant concern with the API in that we do not
>>> like it's error handling design.  Specifically that it is asymmetric and an
>>> error in the middle of a chain of processors can be propagated downstream
>>> with onError(Throwable) but can only be propagated upstream with cancel().
>>>
>>> We believe that cancel without reason is an insufficient semantic to
>>> build a robust ecosystem of RS Processors that can be used to build
>>> applications.   Consider the above example, it would be ideal if the object
>>> serialization was handled by a 3rd party Processor (let's say
>>> JSONEncodingProcessor). If the business logic erroneously sent an
>>> non-jsonable object, or if the JSON converter was incorrectly configured
>>> then the JSONEcondiingProcessor could encounter an error during its
>>> onNext(Object item) handling and it's only permitted handling of that is to
>>> cancel the stream, without explanation.
>>>
>>> I have raised this as an issue on the RS github and it the current
>>> recommendation is to log and cancel:
>>> https://github.com/reactive-streams/reactive-streams-jvm/issues/271#issuecomment-121974544
>>> However I believe that log and cancel is a insufficient semantic.   Logging
>>> in assembled applications is often fraught as each component provider will
>>> fight over which logging framework is best.  RS chains may cross
>>> jurisdictional boundaries and logs may not even be readily available.
>>>
>>> The solution we see is to replace/augment cancel() with either
>>> cancel(Throwable reason) or an upstream onError(Throwable reason).  I
>>> acknowledge that the passed reason may not always be meaningful to the
>>> upstream processors and publishers, but it is better to ignore a
>>> meaningless reason than to be ignorant of a meaningful one.
>>>
>>> When considering this API, we have to look beyond usages that work well
>>> and consider usages that will fail well also!
>>>
>>> cheers
>>>
>>> --
>>> Greg Wilkins <gregw at webtide.com>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> --
>>> I'm a physicist: I have a basic working knowledge of the universe and
>>> everything it contains!
>>>     - Sheldon Cooper (The Big Bang Theory)
>>>
>>>
>>
>> --
>> I'm a physicist: I have a basic working knowledge of the universe and
>> everything it contains!
>>     - Sheldon Cooper (The Big Bang Theory)
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Cheers,
> ?
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150810/138c2836/attachment-0001.html>

From oleksandr.otenko at oracle.com  Mon Aug 10 08:58:57 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 10 Aug 2015 13:58:57 +0100
Subject: [concurrency-interest] Upcoming jdk9 j.u.c JEP
In-Reply-To: <CANPzfU9kb5orBY+BfOsFe0v0BrV_WBX01_oWGy=Bz3rKBfAARw@mail.gmail.com>
References: <55B0F8D5.4050100@cs.oswego.edu>
	<CAAPGdfFAb=bTHRs3smUQ_JefCA7ev=zvo+oLCHBf2zx843QHKg@mail.gmail.com>
	<EB1867BB-C1FB-4723-AE40-6771917D9387@rkuhn.info>
	<CAAPGdfEHoAgMQ2n8vMy=-si8=piEU+-4EiNnTtEtoDOeNJ219A@mail.gmail.com>
	<201125F7-B117-43A2-A1F8-04BD71A71189@rkuhn.info>
	<55C87624.9030602@oracle.com>
	<CANPzfU8oH30fs64An3F+2AYGQV6isTXt1cz8Azsjp=GQmCdoFA@mail.gmail.com>
	<55C8955D.5040602@oracle.com>
	<CANPzfU9kb5orBY+BfOsFe0v0BrV_WBX01_oWGy=Bz3rKBfAARw@mail.gmail.com>
Message-ID: <55C8A011.8070605@oracle.com>

Yes, I believe so. I was only adding another angle to that "why would 
upstream..." question.

Alex

On 10/08/2015 13:44, Viktor Klang wrote:
>
> Ok, then everything is as it should.
> The exception travels towards the direction of the entity which 
> requests the transfer.
>
> -- 
> Cheers,
> ?
>
> On 10 Aug 2015 14:13, "Oleksandr Otenko" <oleksandr.otenko at oracle.com 
> <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     The initiator of the next data transfer. Push-stream - the
>     producer initiates the transfer of the next portion of the data.
>     Pull-stream - the consumer initiates the transfer of the next
>     portion of the data. There are mixes of these, too (parser: token
>     detected - producer pushes; now the token handling code pulls the
>     rest of expression, but only the expression - the producer can't
>     do that, because it doesn't know what the expression is).
>
>
>     Alex
>
>     On 10/08/2015 12:38, Viktor Klang wrote:
>>     #define initiator
>>
>>     On Mon, Aug 10, 2015 at 12:00 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         The direction of the data flow is not important, so upstream
>>         vs downstream are irrelevant. The important aspect is the
>>         control flow.
>>
>>         There are push-streams and there are pull-streams. The error
>>         should propagate to the initiator.
>>
>>         Alex
>>
>>
>>         On 24/07/2015 08:12, Roland Kuhn wrote:
>>>         Hi Greg,
>>>
>>>         my reply has obviously opened two different discussions
>>>         (namely ?why are things as they are?? and ?what is the
>>>         suggested change all about?), I think it would be most
>>>         fruitful if we stash the first one for now and come back to
>>>         it after the second one has been understood better?at least
>>>         by myself. That will put us into a better situation for
>>>         judging the big picture.
>>>
>>>         Considering the flow of data from the DB via application and
>>>         framework processors into the Servlet container, at any
>>>         point along this line failures can happen. The component
>>>         emitting the failure will use whatever means it has outside
>>>         of Reactive Streams to log/audit/monitor and provide
>>>         metrics, I assume that that is just part of all reasonable
>>>         code; the database will do that, the application will do it,
>>>         the framework will probably allow the application to
>>>         configure how to do that, and the application server will be
>>>         configured how to do that. This means that everyone can
>>>         debug their own failures.
>>>
>>>         Data are flowing towards the Servlet (destined for whichever
>>>         client made the request) and it is important to signal
>>>         abnormal termination differently from normal termination,
>>>         hence the onError propagation in this direction. This also
>>>         allows downstream components to see failures coming from
>>>         upstream, but this is a byproduct of needing to generate the
>>>         right kind of final response to the external client. Now the
>>>         interesting question is: why would the database need to know
>>>         that some downstream component choked on the data it
>>>         emitted? How exactly would this information be used by the
>>>         database or its operators/programmers? Arguably the data
>>>         exist and are ?correct? by definition, guarded by Java
>>>         types, and any validation errors that occur are not stream
>>>         failures (cf. this definition
>>>         <http://www.reactivemanifesto.org/glossary#Failure>) and
>>>         should be treated as normal data elements and sent
>>>         downstream (or filtered out, depending on the requirements &
>>>         protocol).
>>>
>>>         I am deliberately painting with high contrast colors here in
>>>         order to better understand what exactly it is that you want
>>>         to achieve instead of just discussing the proposed solution,
>>>         thanks for your patience!
>>>
>>>         Regards,
>>>
>>>         Roland
>>>
>>>>         24 jul 2015 kl. 08:31 skrev Greg Wilkins <gregw at webtide.com
>>>>         <mailto:gregw at webtide.com>>:
>>>>
>>>>         Roland,
>>>>
>>>>         thanks for the response.
>>>>
>>>>         But I don't understand why you consider a terminal
>>>>         exception being notified upstream as a data flow?   It is
>>>>         data, but it is not a flow because it is terminal and
>>>>         cannot be used as a back channel.
>>>>
>>>>         Implementations of the API are already required to send
>>>>         data upstream:  Cancellation is a terminal boolean data
>>>>         state that must be sent upstream, and request(int) is a
>>>>         flow of integers that must be sent upstream [and as an
>>>>         aside, it is not beyond imagination that request(int) will
>>>>         be misused as a back channel for data - hey it might even
>>>>         get used to send an error code immediately prior/post to a
>>>>         cancel! ]
>>>>
>>>>         Thus I don't see that there is any significant additional
>>>>         complexity with that cancellation having a reason
>>>>         associated with it. Implementations must already support
>>>>         upward bound data and any sequencing and/or race conditions
>>>>         that exist with cancel(Throwable) also exist with just
>>>>         cancel().
>>>>
>>>>         I also dispute that a Subscriber will be under the control
>>>>         of the Publisher.     In the example cited and application
>>>>         is providing a Processor, that is using a Publisher
>>>>         provided by a 3rd party database and an Subscriber provided
>>>>         by the Servlet container, with perhaps some framework
>>>>         provided Processors for serialization.   In this example
>>>>         there is the possibility of components from at least 4
>>>>         difference code sources being combined in a chain that
>>>>         crosses deployment administration boundaries of: database,
>>>>         application and server.     The log & cancel handling of
>>>>         errors is going to be very difficult because many different
>>>>         log mechanism may be in use and access may not be easily
>>>>         achieved.  ie applications developers may not have full
>>>>         viability of database logs or servlet container logs.
>>>>
>>>>         The type of error I'm concerned about are all terminal
>>>>         style errors and not intended to be a back flow of data,
>>>>         nor acknowledgement of messages sent.   It is probably that
>>>>         the implementers of cancel(Throwable) would just log,
>>>>         cancel themselves and pass on the cancel(Throwable) to any
>>>>         of their Subscripions.   However the point being that would
>>>>         allow the reason for the failure to cross the
>>>>         administrative boundaries so that it can be known to all.
>>>>
>>>>         I think that any argument that can be made for not sending
>>>>         a Throwable upstream can equally be made for not sending
>>>>         one downstream (or for not having any exceptions in the
>>>>         java language).   Exceptions are very rarely handled in any
>>>>         meaningful way, but are extremely useful for passing
>>>>         details of a failure so that they may be known to all who
>>>>         may need to know.
>>>>
>>>>         Without exceptions  I'm imagining many many  stack over
>>>>         flow questions like "Why was my Subscription cancelled?"
>>>>         followed by obligatory "RTFLog Stupid!" responses!
>>>>
>>>>         cheers
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>         On 24 July 2015 at 15:55, Roland Kuhn <rk at rkuhn.info
>>>>         <mailto:rk at rkuhn.info>> wrote:
>>>>
>>>>             Hi Greg,
>>>>
>>>>             the reasoning behind the asymmetric RS design is that
>>>>             this communication primitive targets unidirectional
>>>>             communication, bidirectional conversations would
>>>>             utilize two such streams running in opposite
>>>>             directions. This means that for a single stream data
>>>>             elements (of which onError is but a special one) flow
>>>>             downstream and only demand flows upstream. Publishers
>>>>             only need to know about when and if to produce the next
>>>>             element(s), hence we didn?t see a use-case for
>>>>             propagating more information than ?N elements needed?
>>>>             and ?no more elements needed?.
>>>>
>>>>             If a single Reactive Stream could transport data
>>>>             upstream then we would need to implement back-pressure
>>>>             on that back channel as well, leading to the same
>>>>             complexity as having two RS running in opposite
>>>>             directions. Another reason why we made this separation
>>>>             lies in not burdening the API designers of conforming
>>>>             implementations with an impossible task: the
>>>>             combinators offered on stream transformation APIs flow
>>>>             with the (English) language from left to right and
>>>>             describe sequences of transformation stages but with
>>>>             data flowing upstream there would be the need for also
>>>>             describing how to handle that?even if it is ?only? an
>>>>             error channel?and since these data flow in the opposite
>>>>             direction there would be no natural way to write this down.
>>>>
>>>>             Learning about the reason behind cancellation seems
>>>>             geared towards recovery in the sense that the Publisher
>>>>             would then construct and attach a different Subscriber
>>>>             afterwards?please let me know if you have something
>>>>             else in mind?and if you want to do that then the
>>>>             Subscriber will in any case be under the Publisher?s
>>>>             control and can use a different channel to communicate
>>>>             the onError signal back to the data source. Since that
>>>>             channel would transport data it would be a separate one
>>>>             flowing in the opposite direction as mentioned above,
>>>>             at least conceptually; with a single element like you
>>>>             describe it could well be a simpler callback mechanism
>>>>             and might not need full back-pressure.
>>>>
>>>>             I hope this clarifies some of the background behind the
>>>>             RS design. Please share more of your intended use of an
>>>>             error back-channel so that we can understand what
>>>>             exactly the upstream components would do with that data
>>>>             in the example case you mention.
>>>>
>>>>             Regards,
>>>>
>>>>             Roland
>>>>
>>>>>             24 jul 2015 kl. 00:35 skrev Greg Wilkins
>>>>>             <gregw at webtide.com <mailto:gregw at webtide.com>>:
>>>>>
>>>>>
>>>>>
>>>>>             On 24 July 2015 at 00:23, Doug Lea <dl at cs.oswego.edu
>>>>>             <mailto:dl at cs.oswego.edu>> wrote:
>>>>>
>>>>>
>>>>>                 * Reactive-stream users may be disappointed that
>>>>>                 we do not include any
>>>>>                 net/IO-based Flow.Publisher/Subscriber classes,
>>>>>                 considering that
>>>>>                 reactive-streams are mainly motivated by net-based
>>>>>                 frameworks. The
>>>>>                 reasons for triaging these out are that (1) IO
>>>>>                 generally falls outside
>>>>>                 of java.util.concurrent (2) Most net-based
>>>>>                 frameworks seem to use
>>>>>                 custom data representation etc (e.g., JSON) that
>>>>>                 are even further out
>>>>>                 of scope. However class SubmissionPublisher can be
>>>>>                 used as an adaptor
>>>>>                 to turn just about any kind of source into a
>>>>>                 Publisher, so provides a
>>>>>                 nearly universal way of constructing a good
>>>>>                 non-custom Publisher even
>>>>>                 from IO-based sources. (Also notice that
>>>>>                 SubmissionPublisher can
>>>>>                 serve as the basis of other actor-like frameworks,
>>>>>                 including those
>>>>>                 turning off back-pressure by calling
>>>>>                 subscription.request(Long.MAX_VALUE) in onSubscribe).
>>>>>
>>>>>
>>>>>
>>>>>             Doug et al,
>>>>>
>>>>>             The Jetty project has been experimenting with the
>>>>>             reactive streams API:
>>>>>             https://github.com/jetty-project/jetty-reactive albiet
>>>>>             not with the JDK-9 version of it, but inspired by the
>>>>>             proposed inclusion of it.
>>>>>
>>>>>             We very much like the API and what it can bring to our
>>>>>             space. We don't see that it needs direct IO support
>>>>>             and that it's power is actually bridging domains with
>>>>>             a good asynchronous model that supports flow control.
>>>>>
>>>>>             We've also begun some preliminary discussions about
>>>>>             developing RS based proposal for the Servlet 4.0
>>>>>             specification. Currently the Servlet API does well
>>>>>             support asynchronous IO and behaviour, but the API is
>>>>>             deceptively difficult to use correctly and gives no
>>>>>             support for back pressure. With RS's we can envisage
>>>>>             solutions that look like:
>>>>>
>>>>>               * A database provides a RS Producer that provides
>>>>>                 the large results of a query asynchronously from a
>>>>>                 remote database server
>>>>>               * Some business logic is encapsulated as a RS
>>>>>                 Processor subscribed to the database producer
>>>>>               * Some framework provided Porocessors subscribe to
>>>>>                 the business logic Processor to perform a chain of
>>>>>                 functions such as serialization, compression
>>>>>               * A container provided Subscriber terminates the
>>>>>                 chain and sends the resulting byte out over
>>>>>                 HTTP/HTTP2 or Websocket. The flow control
>>>>>                 mechanisms of these protocols would be the basis
>>>>>                 of the RS back pressure.
>>>>>
>>>>>             In such solutions, a full HTTP/2 flow control window
>>>>>             would result in back pressure on the remote database
>>>>>             server, allowing threadless waiting without unlimited
>>>>>             queuing of data.
>>>>>
>>>>>             However, we have a significant concern with the API in
>>>>>             that we do not like it's error handling design.
>>>>>             Specifically that it is asymmetric and an error in the
>>>>>             middle of a chain of processors can be propagated
>>>>>             downstream with onError(Throwable) but can only be
>>>>>             propagated upstream with cancel().
>>>>>
>>>>>             We believe that cancel without reason is an
>>>>>             insufficient semantic to build a robust ecosystem of
>>>>>             RS Processors that can be used to build applications.
>>>>>             Consider the above example, it would be ideal if the
>>>>>             object serialization was handled by a 3rd party
>>>>>             Processor (let's say JSONEncodingProcessor). If the
>>>>>             business logic erroneously sent an non-jsonable
>>>>>             object, or if the JSON converter was incorrectly
>>>>>             configured then the JSONEcondiingProcessor could
>>>>>             encounter an error during its onNext(Object item)
>>>>>             handling and it's only permitted handling of that is
>>>>>             to cancel the stream, without explanation.
>>>>>
>>>>>             I have raised this as an issue on the RS github and it
>>>>>             the current recommendation is to log and cancel:
>>>>>             https://github.com/reactive-streams/reactive-streams-jvm/issues/271#issuecomment-121974544
>>>>>             However I believe that log and cancel is a
>>>>>             insufficient semantic. Logging in assembled
>>>>>             applications is often fraught as each component
>>>>>             provider will fight over which logging framework is
>>>>>             best.  RS chains may cross jurisdictional boundaries
>>>>>             and logs may not even be readily available.
>>>>>
>>>>>             The solution we see is to replace/augment cancel()
>>>>>             with either cancel(Throwable reason) or an upstream
>>>>>             onError(Throwable reason).  I acknowledge that the
>>>>>             passed reason may not always be meaningful to the
>>>>>             upstream processors and publishers, but it is better
>>>>>             to ignore a meaningless reason than to be ignorant of
>>>>>             a meaningful one.
>>>>>
>>>>>             When considering this API, we have to look beyond
>>>>>             usages that work well and consider usages that will
>>>>>             fail well also!
>>>>>
>>>>>             cheers
>>>>>
>>>>>             -- 
>>>>>             Greg Wilkins <gregw at webtide.com
>>>>>             <mailto:gregw at webtide.com>>
>>>>>
>>>>>             _______________________________________________
>>>>>             Concurrency-interest mailing list
>>>>>             Concurrency-interest at cs.oswego.edu
>>>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>             --
>>>>             I'm a physicist: I have a basic working knowledge of
>>>>             the universe and everything it contains!
>>>>                 - Sheldon Cooper (The Big Bang Theory)
>>>>
>>>>
>>>
>>>         --
>>>         I'm a physicist: I have a basic working knowledge of the
>>>         universe and everything it contains!
>>>             - Sheldon Cooper (The Big Bang Theory)
>>>
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     -- 
>>     Cheers,
>>     ?
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150810/ed015fc8/attachment-0001.html>

From chris.purcell.39 at gmail.com  Fri Aug 14 06:48:54 2015
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Fri, 14 Aug 2015 10:48:54 +0000
Subject: [concurrency-interest] CompletableFuture improvements
Message-ID: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>

Hi everyone,

I have a few suggestions for changes that could be made to
CompletableFuture, and wondered what everyone thought about them. To prove
they work, I have coded them up into an alternative CompletionStage
implementation, which you can find (along with a longer discussion) at
https://github.com/cjp39/j8stages

To summarize:

(1) Internally, CompletableFuture's fluent API constructs a work queue of
callbacks to execute, to avoid StackOverflowErrors caused by callback
recursion, but there is no way to add custom tasks to it. If we create a
ThreadLocal work queue instead, we can transform recursive listener
callbacks into iteration even if arbitrary user code intervenes. This lets
the user interoperate with other future implementations (like
ListenableFutures
<http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/util/concurrent/ListenableFuture.html>),
and use complete()/completeExceptionally() in callbacks, without risking
StackOverflowErrors. It also simplifies CompletableFuture, and removes the
requirement that other CompletionStages implement
toCompletableFuture(). Since ThreadLocal is tied into the JVM, it's pretty
efficient, so performance shouldn't be an issue. (For implementation
details, see the GitHub repo <https://github.com/cjp39/j8stages>.)

What do people think of this idea?

(2) CompletionStage.whenComplete discards exceptions if both input stage
and action fail. It would be less surprising if, like try/finally, it added
the action exception to the input exception as a suppressed exception. This
can be done safely by cloning the input exception (all Throwables are
Serializable). I don't think performance should be a blocker, as this is a
rare edge case, and we are providing a very useful service for the cost.

Are there any other issues with doing this that I haven't thought about?

(3) CompletableFuture uses concurrent assistance to execute its callback
queue. I suspect this is to give a parallelism speedup. However, I don't
think this particular problem will scale. If we drop the assistance
algorithm, we can drop the extra queue field and store callbacks in the
main result field (currently set to null before the future completes),
giving a simpler implementation, and avoiding overhead from cacheline
conflicts. (Again, for implementation details, see the GitHub repo
<https://github.com/cjp39/j8stages>.)

My assumption may be way off-base here, though. Are there other reasons for
the two-field approach of CompletableFuture?

Cheers,
Chris
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150814/8f675ca8/attachment.html>

From dl at cs.oswego.edu  Fri Aug 14 11:33:11 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 14 Aug 2015 11:33:11 -0400
Subject: [concurrency-interest] CompletableFuture improvements
In-Reply-To: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>
References: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>
Message-ID: <55CE0A37.5000608@cs.oswego.edu>

On 08/14/2015 06:48 AM, Chris Purcell wrote:
>
> I have a few suggestions for changes that could be made to CompletableFuture,

Thanks! Answering out of order...

> (2) CompletionStage.whenComplete discards exceptions if both input stage and
> action fail. It would be less surprising if, like try/finally, it added the
> action exception to the input exception as a suppressed exception.

This seems like a good idea, that we would have done if it had
crossed anyone's mind!  And it can be done now without any
loss of compatibility. Pending any near-term objections, I'll
try incorporating this.

>
> (1) Internally, CompletableFuture's fluent API constructs a work queue of
> callbacks to execute, to avoid StackOverflowErrors caused by callback
> recursion, but there is no way to add custom tasks to it.

I think I'm missing the underlying functionality requirement here.
Can you sketch out some use cases, and how they should be handled?

>
> (3) CompletableFuture uses concurrent assistance to execute its callback
> queue.

Which some users do exploit by creating multiple independent continuation
tasks. (In fact CompletableFuture is computationally complete as a
concurrency primitive -- you can in principle write any concurrent
program only using it). We can't remove this functionality. But
it would be fine to have other CompletionStage implementation classes
that don't support branching parallelism. Especially one that helps
bridge guava ListenableFuture.

>
> My assumption may be way off-base here, though. Are there other reasons for
> the two-field approach of CompletableFuture?

Notice that Signallers for threads blocked waiting for completion are
also held in the linked stack. There may be some good alternative.

-Doug


From martinrb at google.com  Fri Aug 14 13:53:38 2015
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 14 Aug 2015 10:53:38 -0700
Subject: [concurrency-interest] CompletableFuture improvements
In-Reply-To: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>
References: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>
Message-ID: <CA+kOe08fUEqcS8e1SV2q1Cobo0mQgA-t+qP_hKAu5thS_-WUzA@mail.gmail.com>

A lot of effort has been put into writing tests for CompletableFuture in
the jsr166 CVS.
I suggest copying your version of CompletableFuture into that and trying
"ant tck".
(some config required; see "ant -p")
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150814/07c7ff38/attachment.html>

From joe.bowbeer at gmail.com  Fri Aug 14 18:19:46 2015
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 14 Aug 2015 15:19:46 -0700
Subject: [concurrency-interest] ConTest and similar concurrency test tools?
Message-ID: <CAHzJPEq=6HFb9ZYsEqbrLdKLT5y7OwAuq0ziZq2BnNBeHEaxyQ@mail.gmail.com>

In Appendix A of Clean Code (2008, by Robert C. Martin), Brett Schuchert
recommends the use of IBM's ConTest testing tool for shaking out
concurrency-related bugs.

If one were to update this appendix today, are there some newer tools worth
mentioning that are now used for this purpose?


https://www.research.ibm.com/haifa/projects/verification/contest/

"ConTest is an advanced testing solution from IBM, whose main use is to
expose and eliminate concurrency-related bugs in parallel and distributed
software. [...] ConTest systematically and transparently schedules the
execution of program threads such that program scenarios which are likely
to contain race conditions, deadlocks and other intermittent bugs -
collectively called synchronization problems - are forced to appear with
high frequency. In doing so, ConTest dramatically improves the quality of
testing and reduces development expense, as bugs are found earlier in the
testing process."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150814/b0bd91ca/attachment.html>

From henri.tremblay at gmail.com  Fri Aug 14 22:24:17 2015
From: henri.tremblay at gmail.com (Henri Tremblay)
Date: Fri, 14 Aug 2015 22:24:17 -0400
Subject: [concurrency-interest] ConTest and similar concurrency test
	tools?
In-Reply-To: <CAHzJPEq=6HFb9ZYsEqbrLdKLT5y7OwAuq0ziZq2BnNBeHEaxyQ@mail.gmail.com>
References: <CAHzJPEq=6HFb9ZYsEqbrLdKLT5y7OwAuq0ziZq2BnNBeHEaxyQ@mail.gmail.com>
Message-ID: <CADZL2=unG5hzd_QhOkDpRS+khWSZkTJYfWT-oqC7rC=cQD5n1g@mail.gmail.com>

Possibly JCStress

http://openjdk.java.net/projects/code-tools/jcstress/


On 14 August 2015 at 18:19, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> In Appendix A of Clean Code (2008, by Robert C. Martin), Brett Schuchert
> recommends the use of IBM's ConTest testing tool for shaking out
> concurrency-related bugs.
>
> If one were to update this appendix today, are there some newer tools
> worth mentioning that are now used for this purpose?
>
>
> https://www.research.ibm.com/haifa/projects/verification/contest/
>
> "ConTest is an advanced testing solution from IBM, whose main use is to
> expose and eliminate concurrency-related bugs in parallel and distributed
> software. [...] ConTest systematically and transparently schedules the
> execution of program threads such that program scenarios which are likely
> to contain race conditions, deadlocks and other intermittent bugs -
> collectively called synchronization problems - are forced to appear with
> high frequency. In doing so, ConTest dramatically improves the quality of
> testing and reduces development expense, as bugs are found earlier in the
> testing process."
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150814/ac179eac/attachment.html>

From kirk at kodewerk.com  Sat Aug 15 02:43:28 2015
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Sat, 15 Aug 2015 08:43:28 +0200
Subject: [concurrency-interest] ConTest and similar concurrency test
	tools?
In-Reply-To: <CADZL2=unG5hzd_QhOkDpRS+khWSZkTJYfWT-oqC7rC=cQD5n1g@mail.gmail.com>
References: <CAHzJPEq=6HFb9ZYsEqbrLdKLT5y7OwAuq0ziZq2BnNBeHEaxyQ@mail.gmail.com>
	<CADZL2=unG5hzd_QhOkDpRS+khWSZkTJYfWT-oqC7rC=cQD5n1g@mail.gmail.com>
Message-ID: <74015A09-4DC7-4C97-82A0-C5F016019B70@kodewerk.com>

My recommended way to expose concurrency bugs is to use more cores. Fewer cores will hide the problem where as more will help make them visible.

Regards,
Kirk

> On Aug 15, 2015, at 4:24 AM, Henri Tremblay <henri.tremblay at gmail.com> wrote:
> 
> Possibly JCStress
> 
> http://openjdk.java.net/projects/code-tools/jcstress/ <http://openjdk.java.net/projects/code-tools/jcstress/>
> 
> 
> On 14 August 2015 at 18:19, Joe Bowbeer <joe.bowbeer at gmail.com <mailto:joe.bowbeer at gmail.com>> wrote:
> In Appendix A of Clean Code (2008, by Robert C. Martin), Brett Schuchert recommends the use of IBM's ConTest testing tool for shaking out concurrency-related bugs.
> 
> If one were to update this appendix today, are there some newer tools worth mentioning that are now used for this purpose?
> 
> 
> https://www.research.ibm.com/haifa/projects/verification/contest/ <https://www.research.ibm.com/haifa/projects/verification/contest/>
> 
> "ConTest is an advanced testing solution from IBM, whose main use is to expose and eliminate concurrency-related bugs in parallel and distributed software. [...] ConTest systematically and transparently schedules the execution of program threads such that program scenarios which are likely to contain race conditions, deadlocks and other intermittent bugs - collectively called synchronization problems - are forced to appear with high frequency. In doing so, ConTest dramatically improves the quality of testing and reduces development expense, as bugs are found earlier in the testing process."
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150815/7ddb435a/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150815/7ddb435a/attachment.bin>

From chris.purcell.39 at gmail.com  Mon Aug 17 14:27:27 2015
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Mon, 17 Aug 2015 19:27:27 +0100
Subject: [concurrency-interest] CompletableFuture improvements
In-Reply-To: <55CE0A37.5000608@cs.oswego.edu>
References: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>
	<55CE0A37.5000608@cs.oswego.edu>
Message-ID: <CAJUoZVaYtEcxH2rHs67i4mMOwco5639Mu01=7qXGQsSFSMqMhQ@mail.gmail.com>

Thanks, Doug!

This seems like a good idea, that we would have done if it had
> crossed anyone's mind!  And it can be done now without any
> loss of compatibility. Pending any near-term objections, I'll
> try incorporating this.


Fantastic, thanks!


> (1) Internally, CompletableFuture's fluent API constructs a work queue of
>> callbacks to execute, to avoid StackOverflowErrors caused by callback
>> recursion, but there is no way to add custom tasks to it.
>>
>
> I think I'm missing the underlying functionality requirement here.
> Can you sketch out some use cases, and how they should be handled


I may be way off-base on *why* CompletableFuture has a work queue of
callbacks. I assumed it was because, if you have a long chain (a couple of
thousand) of dependent futures, and you call dependent callbacks
recursively within the upstream future's completion handler, then the call
stack will overflow. You can easily demonstrate this with
CompletableFutures:

    @Test
    public void recursive_callbacks_overflow() {
        CompletableFuture<Integer> head = new CompletableFuture<>();
        CompletableFuture<Integer> tail = head;
        for (int i = 0; i < 2_000; i++) {

            CompletableFuture<Integer> newTail = new CompletableFuture<>();
            tail.thenAccept(v -> newTail.complete(v + 1));
            tail = newTail;
        }
        head.complete(7);
        // This should return 2_007, but the stack overflows during
        // the recursion, the error is silently discarded, and the
        // downstream futures remain unset.
        assertEquals(-1, (int) tail.getNow(-1));
    }
However, thanks to the way CompletableFuture uses a work stack internally,
if you use the fluent API, this is not an issue even for hundreds of
thousands of dependent stages:

    @Test
    public void a_hundred_thousand_dependent_completion_stages() {
        CompletableFuture<Integer> head = new CompletableFuture<>();
        CompletableFuture<Integer> tail = head;
        for (int i = 0; i < 100_000; i++) {
            tail = tail.thenApply(v -> v + 1);
        }
        head.complete(7);
        assertEquals(100_007, (int) tail.getNow(-1));
    }

Is it merely fortuitous the fluent API has this feature? If so, my
apologies for coming out of left-field :) I assumed it was intentional,
then figured out how to get the first example to work without overflows:

    @Test
    public void
a_hundred_thousand_recursive_style_callbacks_with_MyFuture() {
        MyFuture<Integer> head = new MyFuture<>();
        MyFuture<Integer> tail = head;
        for (int i = 0; i < 100_000; i++) {
            MyFuture<Integer> newTail = new MyFuture<>();
            tail.thenAccept(v -> newTail.complete(v + 1));
            tail = newTail;
        }
        head.complete(7);
        assertEquals(100_007, (int) tail.getNow(-1));
    }
Aside from silly examples like this, calling complete from callbacks is
necessary for things like

   1. wrapping non-CompletableFuture futures, like arbitrary
   CompletionStages, or ListenableFutures
   2. implementing thenCombine to short-circuit when either input fails

It would be great if we could get this functionality in CompletableFuture.

(3) CompletableFuture uses concurrent assistance to execute its callback
>> queue.
>>
>
> Which some users do exploit by creating multiple independent continuation
> tasks. We can't remove this functionality.


I'm a bit surprised this isn't viewed as the job of the executor, but as
you say, it can't be removed now.

Thanks!
Chris
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150817/adb14f6c/attachment.html>

From dl at cs.oswego.edu  Tue Aug 18 09:14:49 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 18 Aug 2015 09:14:49 -0400
Subject: [concurrency-interest] CompletableFuture improvements
In-Reply-To: <CAJUoZVaYtEcxH2rHs67i4mMOwco5639Mu01=7qXGQsSFSMqMhQ@mail.gmail.com>
References: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>	<55CE0A37.5000608@cs.oswego.edu>
	<CAJUoZVaYtEcxH2rHs67i4mMOwco5639Mu01=7qXGQsSFSMqMhQ@mail.gmail.com>
Message-ID: <55D32FC9.1080604@cs.oswego.edu>

On 08/17/2015 02:27 PM, Chris Purcell wrote:

> I may be way off-base on /why/ CompletableFuture has a work queue of callbacks.
> I assumed it was because, if you have a long chain (a couple of thousand) of
> dependent futures, and you call dependent callbacks recursively within the
> upstream future's completion handler, then the call stack will overflow. You can
> easily demonstrate this with CompletableFutures:

CompletableFuture uses a Treiber-stack-like completion list for
several related reasons: it is non-blocking, atomically resolves
races (like when adding to a CF that is in the midst of completing),
allows helping across threads, and helps avoids stack-overflow
(especially with the 8u update to do so even across threads).

As discussed last year, we'd like to catch as many of these
cases as possible, because StackOverflowError is otherwise
so problematic on JVMs -- some are never caught or handled.
This is not special to completion designs but more common with them.
(Aside: it is an odd state of affairs that you need to emulate
stacks on heaps, with greater peak total memory overhead,
to avoid stack overflow.) Without some JVM-level tail-recursion
support (and maybe even with it), the options are limited in cases
where the recursion occurs in the bodies of lambdas where we
cannot see it. That's the main difference in your two examples:

               CompletableFuture<Integer> newTail = new CompletableFuture<>();
               tail.thenAccept(v -> newTail.complete(v + 1));
               tail = newTail;
vs

               tail = tail.thenApply(v -> v + 1);

We can "trampoline" thenAccept and thenApply, but we don't
even see the newTail.complete(v + 1) because it is inside a
lambda. On the other hand, if the first usage were async, the
cross-thread mechanisms kick in to prevent SOE:

     public void async_recursive_callbacks() {
         CompletableFuture<Integer> head = new CompletableFuture<>();
         CompletableFuture<Integer> tail = head;
         for (int i = 0; i < 2_000; i++) {
             CompletableFuture<Integer> newTail = new CompletableFuture<>();
             tail.thenAcceptAsync(v -> newTail.complete(v + 1));
             tail = newTail;
         }
         head.complete(7);
         assertEquals(2007, (int) tail.join());
     }

It is possible that we could do better here. I'll investigate.
Your thread-local back-channel approach handles some cases,
but I don't think can coexist with other support.

-Doug

From aph at redhat.com  Thu Aug 20 13:50:46 2015
From: aph at redhat.com (Andrew Haley)
Date: Thu, 20 Aug 2015 18:50:46 +0100
Subject: [concurrency-interest] Fences and card tables
Message-ID: <55D61376.9060600@redhat.com>

Just to reassure me: a card table write in a generational collector
only needs a StoreStore fence, not a release.  Is that right?

Thanks,
Andrew.

From dl at cs.oswego.edu  Fri Aug 21 09:16:19 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 21 Aug 2015 09:16:19 -0400
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <55D61376.9060600@redhat.com>
References: <55D61376.9060600@redhat.com>
Message-ID: <55D724A3.4090309@cs.oswego.edu>

On 08/20/2015 01:50 PM, Andrew Haley wrote:
> Just to reassure me: a card table write in a generational collector
> only needs a StoreStore fence, not a release.  Is that right?
>

Definitive answers might be collector-specific.
So you might try asking on hotspot-gc-dev?
   http://mail.openjdk.java.net/mailman/listinfo/hotspot-gc-dev

-Doug


From dl at cs.oswego.edu  Fri Aug 21 09:44:15 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 21 Aug 2015 09:44:15 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
Message-ID: <55D72B2F.70901@cs.oswego.edu>


For those of you who haven't been following this on the jmm-dev list:

We are NOT planning a full JMM memory model update for jdk9 -- there
are still unresolved issues in revising the formal core model.
However, jdk9 will include APIs for VarHandles (a scaled-down version of
the "enhanced volatiles" JEP), that together with some other
support replaces the need to use of Unsafe to obtain these
effects and does so compatibly with C/C++11 atomics. To do this, we
must, until the next full JMM update, provide specs that are
clear to readers (at least those familiar with the underlying
concepts) but not formally tied to a base model, (Which limits
how much we can say in them.)

The tentative methods are pasted below and also at
   http://gee.cs.oswego.edu/dl/wwwtmp/Fodder.java
The javadocs currently do not include any examples helping to
explain why you would ever want to use any of these methods.

The actual VarHandle class will look a bit different because
it will rely on specializations of polymorphic signatures.
(Current versions can be found in the openjdk mercurial
"jdk9/sandbox" repo.) And the "Fences" method may end up
in a different java.lang.* utility class. We'd also retrofit
j.u.c.atomic.Atomic* classes to use compatible methods/names.

Comments welcome.

...

/**
  * Stand-in for spec purposes of jdk9 java.lang.invoke.VarHandle
  */
abstract class NotReallyVarHandle<T> {
     // Load

     /**
      * Returns the value, with memory semantics of reading a
      * non-volatile variable.
      *
      * @return the value
      */
     T getRelaxed(Object owner);

     /**
      * Returns the value, with memory semantics of reading a volatile
      * variable.
      *
      * @return the value
      */
     T getVolatile(Object owner);

     /**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner);

     /**
      * Returns the value, accessed in program order, but with no
      * assurance of memory ordering effects with respect to other
      * threads.
      *
      * @return the value
      */
     T getOpaque(Object owner);

     // Store

     /**
      * Sets the value, with memory semantics of setting a non-volatile
      * variable.
      *
      * @param val the new value
      */
     void setRelaxed(Object owner, T val);

     /**
      * Sets the value, with memory semantics of setting a volatile
      * variable.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_seq_cst.
      *
      * @param val the new value
      */
     void setVolatile(Object owner, T val);

     /**
      * Sets the value, and ensures that prior loads and stores are not
      * reordered after this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_release ordering.
      *
      * @param val the new value
      */
     void setRelease(Object owner, T val);

     /**
      * Sets the value, in program order, but with no assurance of
      * memory ordering effects with respect to other threads.
      *
      * @param val the new value
      */
     void setOpaque(Object owner, T val);

     // CAS

     /**
      * Atomically sets the value to the given updated value with the
      * memory semantics of setVolatile if the current value {@code ==}
      * the expected value, as accessed with the memory semantics of
      * getVolatile.
      *
      * @param expected the expected value
      * @param val the new value
      * @return {@code true} if successful. False return indicates that
      * the actual value was not equal to the expected value.
      */
     boolean compareAndSet(Object owner, T expected, T val);

     // Value-returning compare and exchange

     /**
      * Atomically sets the value to the given updated value with the
      * memory semantics of setVolatile if the current value {@code ==}
      * the expected value, as accessed with the memory semantics of
      * getVolatile.
      *
      * @param expected the expected value
      * @param val the new value
      * @return the current value, which will be the same as {@code val} if
      * successful.
      */
     T compareAndExchangeVolatile(Object owner, T expected, T val);

     /**
      * Atomically sets the value to the given updated value with the
      * memory semantics of setRelaxed if the current value {@code ==}
      * the expected value, as accessed with the memory semantics of
      * getAcquire.
      *
      * @param expected the expected value
      * @param val the new value
      * @return the current value, which will be the same as {@code val} if
      * successful.
      */
     T compareAndExchangeAcquire(Object owner, T expected, T val);

     /**
      * Atomically sets the value to the given updated value with the
      * memory semantics of setRelease if the current value {@code ==}
      * the expected value, as accessed with the memory samantics of
      * getRelease.
      *
      * @param expected the expected value
      * @param val the new value
      * @return the current value, which will be the same as {@code val} if
      * successful.
      */
     T compareAndExchangeRelease(Object owner, T expected, T val);

     // Weak (spurious failures allowed)

     /**
      * Possibly atomically sets the value to the given updated value
      * with the semantics of setRelaxed if the current value {@code
      * ==} the expected value, as as accessed with the memory
      * semantics of getRelaxed.  This operation may fail spuriously
      * (typically, due to memory contention) even if the current value
      * does match the expected value.
      *
      * @param expected the expected value
      * @param val the new value
      * @return {@code true} if successful
      */
     boolean weakCompareAndSetRelaxed(Object owner, T expected, T val);

     /**
      * Possibly atomically sets the value to the given updated value
      * with the memory semantics of setRelaxed if the current value
      * {@code ==} the expected value, as as accessed with the memory
      * semantics of getAcquire.  This operation may fail spuriously
      * (typically, due to memory contention) even if the current value
      * does match the expected value.
      *
      * @param expected the expected value
      * @param val the new value
      * @return {@code true} if successful
      */
     boolean weakCompareAndSetAcquire(Object owner, T expected, T val);

     /**
      * Possibly atomically sets the value to the given updated value
      * with the memory semantics of setRelease if the current value
      * {@code ==} the expected value, as as accessed with the memory
      * semantics of getRelaxed.  This operation may fail spuriously
      * (typically, due to memory contention) even if the current value
      * does match the expected value.
      *
      * @param expected the expected value
      * @param val the new value
      * @return {@code true} if successful
      */
     boolean weakCompareAndSetRelease(Object owner, T expected, T val);

     // special RMW

     /**
      * Atomically sets to the given value with the memory semantics of
      * setVolatile and returns the old value.
      *
      * @param newValue the new value
      * @return the previous value
      */
     T getAndSet(Object owner, T val);

     /**
      * Atomically adds the given value to the current value with the
      * memory semantics of setVolatile.
      *
      * @param delta the value to add
      * @return the previous value
      */
     T getAndAdd(Object owner, T delta);

     /**
      * Atomically adds the given value to the current value with the
      * memory semantics of setVolatile.
      *
      * @param delta the value to add
      * @return the current value
      */
     T addAndGet(Object owner, T delta);
}

/**
  * A set of methods providing fine-grained control of memory ordering.
  *
  * <p>The Java Language Specification permits operations to be
  * executed in orders different than are apparent in program source
  * code, subject to constraints mainly arising from the use of locks
  * and volatile fields. The methods of this class can also be used to
  * impose constraints. Their specifications are phrased in terms of
  * the lack of "reorderings" -- observable ordering effects that might
  * otherwise occur if the fence were not present.
  *
  * @apiNote More precise phrasing of these specifications may
  * accompany future updates of the Java Language Specification.
  */
public class Fences {

     /**
      * Ensures that loads and stores before the fence will not be
      * reordered with loads and stores after the fence.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * atomic_thread_fence(memory_order_seq_cst)
      */
     public static void fullFence() {}

     /**
      * Ensures that loads before the fence will not be reordered with
      * loads and stores after the fence.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * atomic_thread_fence(memory_order_acquire)
      */
     public static void acquireFence() {}

     /**
      * Ensures that loads and stores before the fence will not be
      * reordered with stores after the fence.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * atomic_thread_fence(memory_order_release)
      */
     public static void releaseFence() {}

     /**
      * Ensures that loads before the fence will not be reordered with
      * loads after the fence.
      */
     public static void loadLoadFence() {}

     /**
      * Ensures that stores before the fence will not be reordered with
      * stores after the fence.
      */
     public static void storeStoreFence() {}

}

class java.lang.ref.Reference {
     // add:

     /**
      * Ensures that the object referenced by the given reference
      * remains <em>strongly reachable</em> (as defined in the {@link
      * java.lang.ref} package documentation), regardless of any prior
      * actions of the program that might otherwise cause the object to
      * become unreachable; thus, the referenced object is not
      * reclaimable by garbage collection at least until after the
      * invocation of this method. Invocation of this method does not
      * itself initiate garbage collection or finalization.
      *
      * @param ref the reference. If null, this method has no effect.
      */
     public static void reachabilityFence(Object ref) {}

}

From nathan.reynolds at oracle.com  Fri Aug 21 12:39:43 2015
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 21 Aug 2015 09:39:43 -0700
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D72B2F.70901@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
Message-ID: <55D7544F.9030001@oracle.com>

What is the difference between getRelaxed() and getOpaque()?  I realize 
that specifies the semantics of reading a non-volatile variable and the 
other has no guarantees what so ever.   What's up with reading a 
non-volatile variable?

getOpaque() versus setVolatile() - Which one wins?  getOpaque() kind of 
says it can be re-ordered but setVolatile() forces an ordering. Does 
getOpaque() get to be re-ordered with respect to a setVolatile()?  How 
about the Fence APIs?

For compareAndSet____() methods, should the variable names be (Object 
owner, T expect, T update) to match that of Atomic___ classes?

Are you going to supply a web page similar to JSR 133 Cookbook? 
http://g.oswego.edu/dl/jmm/cookbook.html  I find this page extremely 
helpful.

I missed the conversation on reachabilityFence().  How do I use this?

-Nathan

On 8/21/2015 6:44 AM, Doug Lea wrote:
>
> For those of you who haven't been following this on the jmm-dev list:
>
> We are NOT planning a full JMM memory model update for jdk9 -- there
> are still unresolved issues in revising the formal core model.
> However, jdk9 will include APIs for VarHandles (a scaled-down version of
> the "enhanced volatiles" JEP), that together with some other
> support replaces the need to use of Unsafe to obtain these
> effects and does so compatibly with C/C++11 atomics. To do this, we
> must, until the next full JMM update, provide specs that are
> clear to readers (at least those familiar with the underlying
> concepts) but not formally tied to a base model, (Which limits
> how much we can say in them.)
>
> The tentative methods are pasted below and also at
>   http://gee.cs.oswego.edu/dl/wwwtmp/Fodder.java
> The javadocs currently do not include any examples helping to
> explain why you would ever want to use any of these methods.
>
> The actual VarHandle class will look a bit different because
> it will rely on specializations of polymorphic signatures.
> (Current versions can be found in the openjdk mercurial
> "jdk9/sandbox" repo.) And the "Fences" method may end up
> in a different java.lang.* utility class. We'd also retrofit
> j.u.c.atomic.Atomic* classes to use compatible methods/names.
>
> Comments welcome.
>
> ...
>
> /**
>  * Stand-in for spec purposes of jdk9 java.lang.invoke.VarHandle
>  */
> abstract class NotReallyVarHandle<T> {
>     // Load
>
>     /**
>      * Returns the value, with memory semantics of reading a
>      * non-volatile variable.
>      *
>      * @return the value
>      */
>     T getRelaxed(Object owner);
>
>     /**
>      * Returns the value, with memory semantics of reading a volatile
>      * variable.
>      *
>      * @return the value
>      */
>     T getVolatile(Object owner);
>
>     /**
>      * Returns the value, and ensures that subsequent loads and stores
>      * are not reordered before this access.
>      *
>      * @apiNote Ignoring the many semantic differences from C and
>      * C++, this method has memory ordering effects compatible with
>      * memory_order_acquire ordering.
>      *
>      * @return the value
>      */
>     T getAcquire(Object owner);
>
>     /**
>      * Returns the value, accessed in program order, but with no
>      * assurance of memory ordering effects with respect to other
>      * threads.
>      *
>      * @return the value
>      */
>     T getOpaque(Object owner);
>
>     // Store
>
>     /**
>      * Sets the value, with memory semantics of setting a non-volatile
>      * variable.
>      *
>      * @param val the new value
>      */
>     void setRelaxed(Object owner, T val);
>
>     /**
>      * Sets the value, with memory semantics of setting a volatile
>      * variable.
>      *
>      * @apiNote Ignoring the many semantic differences from C and
>      * C++, this method has memory ordering effects compatible with
>      * memory_order_seq_cst.
>      *
>      * @param val the new value
>      */
>     void setVolatile(Object owner, T val);
>
>     /**
>      * Sets the value, and ensures that prior loads and stores are not
>      * reordered after this access.
>      *
>      * @apiNote Ignoring the many semantic differences from C and
>      * C++, this method has memory ordering effects compatible with
>      * memory_order_release ordering.
>      *
>      * @param val the new value
>      */
>     void setRelease(Object owner, T val);
>
>     /**
>      * Sets the value, in program order, but with no assurance of
>      * memory ordering effects with respect to other threads.
>      *
>      * @param val the new value
>      */
>     void setOpaque(Object owner, T val);
>
>     // CAS
>
>     /**
>      * Atomically sets the value to the given updated value with the
>      * memory semantics of setVolatile if the current value {@code ==}
>      * the expected value, as accessed with the memory semantics of
>      * getVolatile.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return {@code true} if successful. False return indicates that
>      * the actual value was not equal to the expected value.
>      */
>     boolean compareAndSet(Object owner, T expected, T val);
>
>     // Value-returning compare and exchange
>
>     /**
>      * Atomically sets the value to the given updated value with the
>      * memory semantics of setVolatile if the current value {@code ==}
>      * the expected value, as accessed with the memory semantics of
>      * getVolatile.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return the current value, which will be the same as {@code 
> val} if
>      * successful.
>      */
>     T compareAndExchangeVolatile(Object owner, T expected, T val);
>
>     /**
>      * Atomically sets the value to the given updated value with the
>      * memory semantics of setRelaxed if the current value {@code ==}
>      * the expected value, as accessed with the memory semantics of
>      * getAcquire.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return the current value, which will be the same as {@code 
> val} if
>      * successful.
>      */
>     T compareAndExchangeAcquire(Object owner, T expected, T val);
>
>     /**
>      * Atomically sets the value to the given updated value with the
>      * memory semantics of setRelease if the current value {@code ==}
>      * the expected value, as accessed with the memory samantics of
>      * getRelease.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return the current value, which will be the same as {@code 
> val} if
>      * successful.
>      */
>     T compareAndExchangeRelease(Object owner, T expected, T val);
>
>     // Weak (spurious failures allowed)
>
>     /**
>      * Possibly atomically sets the value to the given updated value
>      * with the semantics of setRelaxed if the current value {@code
>      * ==} the expected value, as as accessed with the memory
>      * semantics of getRelaxed.  This operation may fail spuriously
>      * (typically, due to memory contention) even if the current value
>      * does match the expected value.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return {@code true} if successful
>      */
>     boolean weakCompareAndSetRelaxed(Object owner, T expected, T val);
>
>     /**
>      * Possibly atomically sets the value to the given updated value
>      * with the memory semantics of setRelaxed if the current value
>      * {@code ==} the expected value, as as accessed with the memory
>      * semantics of getAcquire.  This operation may fail spuriously
>      * (typically, due to memory contention) even if the current value
>      * does match the expected value.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return {@code true} if successful
>      */
>     boolean weakCompareAndSetAcquire(Object owner, T expected, T val);
>
>     /**
>      * Possibly atomically sets the value to the given updated value
>      * with the memory semantics of setRelease if the current value
>      * {@code ==} the expected value, as as accessed with the memory
>      * semantics of getRelaxed.  This operation may fail spuriously
>      * (typically, due to memory contention) even if the current value
>      * does match the expected value.
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return {@code true} if successful
>      */
>     boolean weakCompareAndSetRelease(Object owner, T expected, T val);
>
>     // special RMW
>
>     /**
>      * Atomically sets to the given value with the memory semantics of
>      * setVolatile and returns the old value.
>      *
>      * @param newValue the new value
>      * @return the previous value
>      */
>     T getAndSet(Object owner, T val);
>
>     /**
>      * Atomically adds the given value to the current value with the
>      * memory semantics of setVolatile.
>      *
>      * @param delta the value to add
>      * @return the previous value
>      */
>     T getAndAdd(Object owner, T delta);
>
>     /**
>      * Atomically adds the given value to the current value with the
>      * memory semantics of setVolatile.
>      *
>      * @param delta the value to add
>      * @return the current value
>      */
>     T addAndGet(Object owner, T delta);
> }
>
> /**
>  * A set of methods providing fine-grained control of memory ordering.
>  *
>  * <p>The Java Language Specification permits operations to be
>  * executed in orders different than are apparent in program source
>  * code, subject to constraints mainly arising from the use of locks
>  * and volatile fields. The methods of this class can also be used to
>  * impose constraints. Their specifications are phrased in terms of
>  * the lack of "reorderings" -- observable ordering effects that might
>  * otherwise occur if the fence were not present.
>  *
>  * @apiNote More precise phrasing of these specifications may
>  * accompany future updates of the Java Language Specification.
>  */
> public class Fences {
>
>     /**
>      * Ensures that loads and stores before the fence will not be
>      * reordered with loads and stores after the fence.
>      *
>      * @apiNote Ignoring the many semantic differences from C and
>      * C++, this method has memory ordering effects compatible with
>      * atomic_thread_fence(memory_order_seq_cst)
>      */
>     public static void fullFence() {}
>
>     /**
>      * Ensures that loads before the fence will not be reordered with
>      * loads and stores after the fence.
>      *
>      * @apiNote Ignoring the many semantic differences from C and
>      * C++, this method has memory ordering effects compatible with
>      * atomic_thread_fence(memory_order_acquire)
>      */
>     public static void acquireFence() {}
>
>     /**
>      * Ensures that loads and stores before the fence will not be
>      * reordered with stores after the fence.
>      *
>      * @apiNote Ignoring the many semantic differences from C and
>      * C++, this method has memory ordering effects compatible with
>      * atomic_thread_fence(memory_order_release)
>      */
>     public static void releaseFence() {}
>
>     /**
>      * Ensures that loads before the fence will not be reordered with
>      * loads after the fence.
>      */
>     public static void loadLoadFence() {}
>
>     /**
>      * Ensures that stores before the fence will not be reordered with
>      * stores after the fence.
>      */
>     public static void storeStoreFence() {}
>
> }
>
> class java.lang.ref.Reference {
>     // add:
>
>     /**
>      * Ensures that the object referenced by the given reference
>      * remains <em>strongly reachable</em> (as defined in the {@link
>      * java.lang.ref} package documentation), regardless of any prior
>      * actions of the program that might otherwise cause the object to
>      * become unreachable; thus, the referenced object is not
>      * reclaimable by garbage collection at least until after the
>      * invocation of this method. Invocation of this method does not
>      * itself initiate garbage collection or finalization.
>      *
>      * @param ref the reference. If null, this method has no effect.
>      */
>     public static void reachabilityFence(Object ref) {}
>
> }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150821/1c857257/attachment-0001.html>

From ben_manes at yahoo.com  Fri Aug 21 13:56:49 2015
From: ben_manes at yahoo.com (Ben Manes)
Date: Fri, 21 Aug 2015 17:56:49 +0000 (UTC)
Subject: [concurrency-interest] threadLocalRandomProbe
Message-ID: <633019837.5096085.1440179809198.JavaMail.yahoo@mail.yahoo.com>

Are there any plans on providing a handle or abstraction for?threadLocalRandomProbe (as a thread-specific hash, e.g. Striped64)? It is quite useful for striping [1] and back-off arenas [2, 3]. It would be nice to not lose this optimization when transitioning away from Unsafe.

[1]?https://github.com/ben-manes/caffeine/blob/master/caffeine/src/main/java/com/github/benmanes/caffeine/cache/StripedBuffer.java[2]?https://github.com/ben-manes/caffeine/wiki/SingleConsumerQueue[3]?https://github.com/ben-manes/caffeine/wiki/ConcurrentLinkedStack
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150821/5f39371c/attachment.html>

From dl at cs.oswego.edu  Fri Aug 21 14:58:32 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 21 Aug 2015 14:58:32 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D7544F.9030001@oracle.com>
References: <55D72B2F.70901@cs.oswego.edu> <55D7544F.9030001@oracle.com>
Message-ID: <55D774D8.5030200@cs.oswego.edu>

For some similar questions and answers, see today's archives of
   jmm-dev:   http://mail.openjdk.java.net/mailman/listinfo/jmm-dev
   valhalla-dev: http://mail.openjdk.java.net/mailman/listinfo/valhalla-dev

On 08/21/2015 12:39 PM, Nathan Reynolds wrote:
> What is the difference between getRelaxed() and getOpaque()?  I realize that
> specifies the semantics of reading a non-volatile variable and the other has no
> guarantees what so ever.   What's up with reading a non-volatile variable?

getRelaxed is a plain ordinary read with rules specified by the JMM.
These APIs don't say what those rules are, allowing them to be revised.
But many reorderings and  transformations are allowed.

getOpaque is the same, but with the further constraint that the read
must actually occur even if other JMM rules would allow it to be
optimized away (for example due to common subexpression evaluation).
Usage is rare. Think IO.

>
> getOpaque() versus setVolatile() - Which one wins?

In the case I think you have in mind:  getX (X=relaxed, acquire, ...)
is a load. A preceding setVolatile entails what amount to a trailing
storeLoad fence, so cannot be reordered downward.

>
> For compareAndSet____() methods, should the variable names be (Object owner, T
> expect, T update) to match that of Atomic___ classes?

Probably so; thanks!

>
> Are you going to supply a web page similar to JSR 133 Cookbook?

Yes, that's the plan.

>
> I missed the conversation on reachabilityFence().  How do I use this?
>

You might glance through August 2014 jmm-dev mail with
"finalization" in subject.
   http://mail.openjdk.java.net/pipermail/jmm-dev/2014-August/thread.html

Also, here's a paste of draft javadocs from the last time we
considered this (5+ years ago):

Avoiding premature finalization. Finalization may occur whenever a Java Virtual 
Machine detects that no reference to an object will ever be stored in the heap: 
A garbage collector may reclaim an object even if the fields of that object are 
still in use, so long as the object has otherwise become unreachable. This may 
have surprising and undesirable effects in cases such as the following example 
in which the bookkeeping associated with a class is managed through array 
indices. Here, method action uses a reachabilityFence to ensure that the 
Resource object is not reclaimed before bookkeeping on an associated 
ExternalResource has been performed; in particular here, to ensure that the 
array slot holding the ExternalResource is not nulled out in method 
Object.finalize(), which may otherwise run concurrently.


  class Resource {
    private static ExternalResource[] externalResourceArray = ...

    int myIndex;
    Resource(...) {
      myIndex = ...
      externalResourceArray[myIndex] = ...;
      ...
    }
    protected void finalize() {
      externalResourceArray[myIndex] = null;
      ...
    }
    public void action() {
      try {
        // ...
        int i = myIndex;
        Resource.update(externalResourceArray[i]);
      } finally {
        Fences.reachabilityFence(this);
      }
    }
    private static void update(ExternalResource ext) {
      ext.status = ...;
    }
  }

Here, the call to reachabilityFence is nonintuitively placed after the call to 
update, to ensure that the array slot is not nulled out by Object.finalize() 
before the update, even if the call to action was the last use of this object. 
This might be the case if for example a usage in a user program had the form new 
Resource().action(); which retains no other reference to this Resource. While 
probably overkill here, reachabilityFence is placed in a finally block to ensure 
that it is invoked across all paths in the method. In a method with more complex 
control paths, you might need further precautions to ensure that 
reachabilityFence is encountered along all of them.

It is sometimes possible to better encapsulate use of reachabilityFence. 
Continuing the above example, if it were OK for the call to method update to 
proceed even if the finalizer had already executed (nulling out slot), then you 
could localize use of reachabilityFence:


  public void action2() {
    // ...
    Resource.update(getExternalResource());
  }
  private ExternalResource getExternalResource() {
    ExternalResource ext = externalResourceArray[myIndex];
    Fences.reachabilityFence(this);
    return ext;
  }

Method reachabilityFence is not required in constructions that themselves ensure 
reachability. For example, because objects that are locked cannot in general be 
reclaimed, it would suffice if all accesses of the object, in all methods of 
class Resource (including finalize) were enclosed in synchronized (this) blocks. 
(Further, such blocks must not include infinite loops, or themselves be 
unreachable, which fall into the corner case exceptions to the "in general" 
disclaimer.) However, method reachabilityFence remains a better option in cases 
where this approach is not as efficient, desirable, or possible; for example 
because it would encounter deadlock.



From thurston at nomagicsoftware.com  Fri Aug 21 16:01:46 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Fri, 21 Aug 2015 13:01:46 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D72B2F.70901@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
Message-ID: <1440187306402-12670.post@n7.nabble.com>

I'm especially glad to see the T compareAndExchangeXXX(Object owner, T
expected, T val) versions (assuming they're implemented via intrinsics of
course).
Is the lack of code examples deliberate (can of worms), or are you
soliciting some?



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12670.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From peter.levart at gmail.com  Fri Aug 21 16:47:55 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Fri, 21 Aug 2015 22:47:55 +0200
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D72B2F.70901@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
Message-ID: <55D78E7B.1010904@gmail.com>

Hi Doug,

On 08/21/2015 03:44 PM, Doug Lea wrote:
> /**
>      * Atomically sets the value to the given updated value with the
>      * memory semantics of setRelease if the current value {@code ==}
>      * the expected value, as accessed with the memory samantics of
>      * getRelease.
             ^^^^
Should that be getRelaxed or more probably getAcquire ?

> *
>      * @param expected the expected value
>      * @param val the new value
>      * @return the current value, which will be the same as {@code 
> val} if
>      * successful.
>      */
>     T compareAndExchangeRelease(Object owner, T expected, T val); 

Suppose the value is currently 1 and two threads do the following 
concurrently:

Thread1:

v1 = compareAndExchangeRelease(owner, 1, 2);

Thread2:

v2 = compareAndExchangeRelease(owner, 1, 3);



Can the outcome be: v1 == 2, v2 == 3 ?

If it is getAcquire then probably not, but if it is getRelaxed then It 
might be or not?


Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150821/c4d10258/attachment.html>

From vitalyd at gmail.com  Fri Aug 21 18:04:55 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 21 Aug 2015 18:04:55 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D78E7B.1010904@gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<55D78E7B.1010904@gmail.com>
Message-ID: <CAHjP37GgFEUH5ZERD2rzNfM1MGLZzoYH2zog-RwZKw7SSgQSKg@mail.gmail.com>

That wouldn't be a CAS if that outcome were possible.  My understanding is
the ordering in those CAS variants dictates ordering of memory accesses
before and after the CAS with respect to the CAS itself.

sent from my phone
On Aug 21, 2015 5:09 PM, "Peter Levart" <peter.levart at gmail.com> wrote:

> Hi Doug,
>
> On 08/21/2015 03:44 PM, Doug Lea wrote:
>
>     /**
>      * Atomically sets the value to the given updated value with the
>      * memory semantics of setRelease if the current value {@code ==}
>      * the expected value, as accessed with the memory samantics of
>      * getRelease.
>
>             ^^^^
> Should that be getRelaxed or more probably getAcquire ?
>
>      *
>      * @param expected the expected value
>      * @param val the new value
>      * @return the current value, which will be the same as {@code val} if
>      * successful.
>      */
>     T compareAndExchangeRelease(Object owner, T expected, T val);
>
>
> Suppose the value is currently 1 and two threads do the following
> concurrently:
>
> Thread1:
>
> v1 = compareAndExchangeRelease(owner, 1, 2);
>
> Thread2:
>
> v2 = compareAndExchangeRelease(owner, 1, 3);
>
>
>
> Can the outcome be: v1 == 2, v2 == 3 ?
>
> If it is getAcquire then probably not, but if it is getRelaxed then It
> might be or not?
>
>
> Regards, Peter
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150821/13a73494/attachment.html>

From dl at cs.oswego.edu  Fri Aug 21 18:58:38 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 21 Aug 2015 18:58:38 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D78E7B.1010904@gmail.com>
References: <55D72B2F.70901@cs.oswego.edu> <55D78E7B.1010904@gmail.com>
Message-ID: <55D7AD1E.4070203@cs.oswego.edu>

On 08/21/2015 04:47 PM, Peter Levart wrote:
> Hi Doug,
>
> On 08/21/2015 03:44 PM, Doug Lea wrote:
>> /**
>>      * Atomically sets the value to the given updated value with the
>>      * memory semantics of setRelease if the current value {@code ==}
>>      * the expected value, as accessed with the memory samantics of
>>      * getRelease.
>              ^^^^
> Should that be getRelaxed or more probably getAcquire ?

Thanks; fixed. It should say getRelaxed.

>
>> *
>>      * @param expected the expected value
>>      * @param val the new value
>>      * @return the current value, which will be the same as {@code val} if
>>      * successful.
>>      */
>>     T compareAndExchangeRelease(Object owner, T expected, T val);
>
> Suppose the value is currently 1 and two threads do the following concurrently:
>
> Thread1:
>
> v1 = compareAndExchangeRelease(owner, 1, 2);
>
> Thread2:
>
> v2 = compareAndExchangeRelease(owner, 1, 3);
>
>
>
> Can the outcome be: v1 == 2, v2 == 3 ?
>
> If it is getAcquire then probably not, but if it is getRelaxed then It might be
> or not?

No; the CAS "confirms" the value. As Vitaly noted, the modes are
there for finer-grained control of what happens before/after the CAS.
(Note: on X86 and Sparc, all flavors of CAS map to the same instruction,
but they may all differ on ARM and POWER.)

-Doug


From dl at cs.oswego.edu  Fri Aug 21 19:23:25 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 21 Aug 2015 19:23:25 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440187306402-12670.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
Message-ID: <55D7B2ED.4030507@cs.oswego.edu>

On 08/21/2015 04:01 PM, thurstonn wrote:

> Is the lack of code examples deliberate (can of worms), or are you
> soliciting some?
>

Candidate javadoc examples would be welcome. Although
I imagine that external articles, blogs, etc will do a better
job at conveying when these methods are applicable than we can do
in javadocs.

-Doug





From thurston at nomagicsoftware.com  Fri Aug 21 19:39:48 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Fri, 21 Aug 2015 16:39:48 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D72B2F.70901@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
Message-ID: <1440200388242-12675.post@n7.nabble.com>

So the current Java 8 JavaDoc has the following in the atomic package:

"compareAndSet and all other read-and-update operations such as
getAndIncrement have the memory effects of both reading and writing volatile
variables."

So it's been decided to essentially replace that with the  following?:

 /**
      * Atomically sets the value to the given updated value with the
      * memory semantics of setVolatile if the current value {@code ==}
      * the expected value, *as accessed with the memory semantics of
      * getVolatile.  *

I find that confusing/awkward (maybe it's just me), but I realize it's
tricky, and so if others don't then fine

Also, 
"(Note: on X86 and Sparc, all flavors of CAS map to the same *instruction*,
but they may all differ on ARM and POWER.) "

Just to be clear, that instruction is (LOCK) CMPXCHG and requires no before
or after fences, right?



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12675.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From dl at cs.oswego.edu  Sat Aug 22 08:56:53 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 22 Aug 2015 08:56:53 -0400
Subject: [concurrency-interest] threadLocalRandomProbe
In-Reply-To: <633019837.5096085.1440179809198.JavaMail.yahoo@mail.yahoo.com>
References: <633019837.5096085.1440179809198.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55D87195.9040406@cs.oswego.edu>

On 08/21/2015 01:56 PM, Ben Manes wrote:
> Are there any plans on providing a handle or abstraction for
> threadLocalRandomProbe (as a thread-specific hash, e.g. Striped64)? It is quite
> useful for striping [1] and back-off arenas [2, 3]. It would be nice to not lose
> this optimization when transitioning away from Unsafe.

This is among a few cases where Unsafe is currently the only way
to access a jdk-private field that wouldn't be "unsafe" to export
(at least read-only), but no one has come up with a good way to expose.
In fact, the main reason they use Unsafe internally is that people
didn't want to expose fringe methods with only jdk-internal known
usages in commonly used classes; in particular class Thread.
Other examples include park/unpark mechanics for maintaining the
"parkBlocker" field used for monitoring and debugging.

I think Paul Sandoz (currently on vacation) has had some thoughts
on these, but I don't think there are any plans about them. And for
jdk9 at least, within-jdk use of Unsafe is allowed.

The case of threadLocalRandomProbe is hard to accommodate because
it is part of a particular algorithm: When you have collisions among
threads in a hash-table with size bounded by #cores, then upon
collision, move the hash code. This a dynamic analog of "perfect
hashing" that works extremely well in Striped64 and elsewhere.
Even though they use different tables, a collision in one implies
collisions in others, so any usage can move the code with generally
positive effect on other usages, but only if they follow that rule.
So while we could expose read-only, it would be a bad idea to export
the update method.

-Doug


From thurston at nomagicsoftware.com  Sat Aug 22 09:06:59 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Sat, 22 Aug 2015 06:06:59 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D72B2F.70901@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
Message-ID: <1440248819913-12677.post@n7.nabble.com>

I have a couple of questions, but first I wanted to make sure that I'm not
missing something basic.

This sentence:
"We are NOT planning a full JMM memory model update for jdk9"

should *not *be taken to mean that (for jdk9), 
<code>
T getVolatile(Object owner) and
T getAcquire(Object owner)
</code>
have the exact same "memory order effects", right?

i.e. they are not just placeholders "until a full JMM is agreed upon"?



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12677.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From dl at cs.oswego.edu  Sat Aug 22 09:58:30 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 22 Aug 2015 09:58:30 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440248819913-12677.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
Message-ID: <55D88006.8030906@cs.oswego.edu>

On 08/22/2015 09:06 AM, thurstonn wrote:
> I have a couple of questions, but first I wanted to make sure that I'm not
> missing something basic.
>
> This sentence:
> "We are NOT planning a full JMM memory model update for jdk9"
>
> should *not *be taken to mean that (for jdk9),
> <code>
> T getVolatile(Object owner) and
> T getAcquire(Object owner)
> </code>
> have the exact same "memory order effects", right?

Yes and no. They currently have the same implementation, and
any future changes will be compatible with this, but future
specs need not be identical. Although probably they will differ
at most in uninteresting ways, for example any wording needed to
continue to allow volatile fields that never escape threads to
be treated (essentially) as if non-volatile.

-Doug


From dl at cs.oswego.edu  Sat Aug 22 10:01:45 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 22 Aug 2015 10:01:45 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440200388242-12675.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440200388242-12675.post@n7.nabble.com>
Message-ID: <55D880C9.1040809@cs.oswego.edu>

On 08/21/2015 07:39 PM, thurstonn wrote:
> So the current Java 8 JavaDoc has the following in the atomic package:
>
> "compareAndSet and all other read-and-update operations such as
> getAndIncrement have the memory effects of both reading and writing volatile
> variables."

Thanks for the reminder that j.u.c.atomic package docs will need
some touch-up when we adapt methods/names for the Atomic* classes.

> Also,
> "(Note: on X86 and Sparc, all flavors of CAS map to the same *instruction*,
> but they may all differ on ARM and POWER.) "
>
> Just to be clear, that instruction is (LOCK) CMPXCHG and requires no before
> or after fences, right?

Yes. (Actually more than one instruction because of different widths for
int vs long etc.)

-Doug


From thurston at nomagicsoftware.com  Sat Aug 22 12:47:47 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Sat, 22 Aug 2015 09:47:47 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D88006.8030906@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
Message-ID: <1440262067408-12680.post@n7.nabble.com>

Thanks for the prompt reply.  I guess I'll operate then from the yes
perspective.

What are the plans with respect to the "higher-order methods" on e.g.
AtomicReference, i.e.

T getAndAccumulate(T, BinaryOperator<T>)
T updateAndGet(UnaryOperator<T>)
. . .
etc.


Are you going to have:
T getAndAccumulateVolatilely(T, BinaryOperator<T>)
T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
etc versions?


That seems like a pollution of the API, IMO (and just awful names).  And I'm
not really sure where it ends.

And then a small javadoc modification suggestion:
/**
      * Returns the value, and ensures that subsequent loads and stores
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner); 

I find
/**
      * Returns the value, and ensures that subsequent loads and stores (*in
the program order*)
      * are not reordered before this access.
      *
      * @apiNote Ignoring the many semantic differences from C and
      * C++, this method has memory ordering effects compatible with
      * memory_order_acquire ordering.
      *
      * @return the value
      */
     T getAcquire(Object owner); 

to be a little clearer as *subsequent* is an overloaded term when it comes
to JMM matters.

And one final question that I've always been confused about;  are there
different "memory ordering effects" between a successful CAS and an
unsuccessful one (presumably in the latter because no write actually
occurs)?
IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
the successful case, at least on x86/64.  If so, I can take a shot at
producing some javadoc language to reflect that, if it would be helpful.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From blake.meike+concurrency at gmail.com  Sat Aug 22 13:53:41 2015
From: blake.meike+concurrency at gmail.com (Blake Meike)
Date: Sat, 22 Aug 2015 10:53:41 -0700
Subject: [concurrency-interest] Seeking tech reviewer
In-Reply-To: <74015A09-4DC7-4C97-82A0-C5F016019B70@kodewerk.com>
References: <CAHzJPEq=6HFb9ZYsEqbrLdKLT5y7OwAuq0ziZq2BnNBeHEaxyQ@mail.gmail.com>
	<CADZL2=unG5hzd_QhOkDpRS+khWSZkTJYfWT-oqC7rC=cQD5n1g@mail.gmail.com>
	<74015A09-4DC7-4C97-82A0-C5F016019B70@kodewerk.com>
Message-ID: <ADAE2DE2-3843-4D39-B251-252DD2A1BDF2@gmail.com>

Hi,
 Please pardon a quick sales pitch.  I?ve followed this list for years and would be really honored if someone here would take me up on this offer.

 I?m writing a book on concurrent programming for Android and I need a tech review.  The book is part of a curated series of Android books, each of which will address a specific topic.  Because of that it is focused (on concurrency) and fairly short (~200 pages).  There is some code to test but, because this is not a project-centered book, not a great deal.

 I?d like to enlist the aid of someone with a good understanding of concurrency and some familiarity with Android who is willing to read the book with a find toothed comb and give honest feedback and, perhaps, try out some of the code.  I estimate something around 20 hours to read and another 10-20 to test things.  Under 40hrs total.

 For this you get $350 from Pearson (yeah, I know), a copy of the book, and, with luck, some notoriety.  I?m obviously prejudiced, but I think it?s an enjoyable read, too.

 Please e-mail me directly if you are interested.

Thanks
 Blake Meike

From vitalyd at gmail.com  Sat Aug 22 14:15:40 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sat, 22 Aug 2015 14:15:40 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440262067408-12680.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
Message-ID: <CAHjP37HY_fcSCW94absDikjwAs290QqMX5X2QdTJCh5bYKhrDw@mail.gmail.com>

I would hope there's no ordering difference between successful and
unsuccessful CAS.  On x86/64 the instruction itself provides full fence
irrespective of outcome; compiler doesn't know a priori whether it will
succeed or not.  Are there platforms where the lowering of the CAS has
different cpu ordering based on outcome? LL/SC can fail if cacheline is
modified in between (even if value is still the expected one) but I'm not
aware of that changing ordering semantics.  However, if there are cases
where this would matter, I hope the JVM ensures the requested ordering
irrespective of outcome.

Along this line, the more "interesting" and related question is what the
ordering guarantees are for failed tryLock methods.

sent from my phone
On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

> Thanks for the prompt reply.  I guess I'll operate then from the yes
> perspective.
>
> What are the plans with respect to the "higher-order methods" on e.g.
> AtomicReference, i.e.
>
> T getAndAccumulate(T, BinaryOperator<T>)
> T updateAndGet(UnaryOperator<T>)
> . . .
> etc.
>
>
> Are you going to have:
> T getAndAccumulateVolatilely(T, BinaryOperator<T>)
> T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
> etc versions?
>
>
> That seems like a pollution of the API, IMO (and just awful names).  And
> I'm
> not really sure where it ends.
>
> And then a small javadoc modification suggestion:
> /**
>       * Returns the value, and ensures that subsequent loads and stores
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> I find
> /**
>       * Returns the value, and ensures that subsequent loads and stores
> (*in
> the program order*)
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> to be a little clearer as *subsequent* is an overloaded term when it comes
> to JMM matters.
>
> And one final question that I've always been confused about;  are there
> different "memory ordering effects" between a successful CAS and an
> unsuccessful one (presumably in the latter because no write actually
> occurs)?
> IIRC, when looking at the java 8 JVM code, I believe a fence was inserted
> in
> the successful case, at least on x86/64.  If so, I can take a shot at
> producing some javadoc language to reflect that, if it would be helpful.
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150822/e32fe71c/attachment.html>

From vitalyd at gmail.com  Sat Aug 22 14:17:32 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sat, 22 Aug 2015 14:17:32 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440262067408-12680.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
Message-ID: <CAHjP37H=iex2+57t+DYf+3Jy2fJiTp8xCwgFPOMnQsW5vYme9g@mail.gmail.com>

As for higher order variants, I'd vote to keep them out unless they can be
done more cheaply by virtue of being backed by some intrinsics.  Otherwise,
anyone can build them on top of the lower level functionality.

sent from my phone
On Aug 22, 2015 1:41 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

> Thanks for the prompt reply.  I guess I'll operate then from the yes
> perspective.
>
> What are the plans with respect to the "higher-order methods" on e.g.
> AtomicReference, i.e.
>
> T getAndAccumulate(T, BinaryOperator<T>)
> T updateAndGet(UnaryOperator<T>)
> . . .
> etc.
>
>
> Are you going to have:
> T getAndAccumulateVolatilely(T, BinaryOperator<T>)
> T getAndAccumulateAcquiredly(T, BinaryOperator<T>)
> etc versions?
>
>
> That seems like a pollution of the API, IMO (and just awful names).  And
> I'm
> not really sure where it ends.
>
> And then a small javadoc modification suggestion:
> /**
>       * Returns the value, and ensures that subsequent loads and stores
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> I find
> /**
>       * Returns the value, and ensures that subsequent loads and stores
> (*in
> the program order*)
>       * are not reordered before this access.
>       *
>       * @apiNote Ignoring the many semantic differences from C and
>       * C++, this method has memory ordering effects compatible with
>       * memory_order_acquire ordering.
>       *
>       * @return the value
>       */
>      T getAcquire(Object owner);
>
> to be a little clearer as *subsequent* is an overloaded term when it comes
> to JMM matters.
>
> And one final question that I've always been confused about;  are there
> different "memory ordering effects" between a successful CAS and an
> unsuccessful one (presumably in the latter because no write actually
> occurs)?
> IIRC, when looking at the java 8 JVM code, I believe a fence was inserted
> in
> the successful case, at least on x86/64.  If so, I can take a shot at
> producing some javadoc language to reflect that, if it would be helpful.
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12680.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150822/59c546fb/attachment.html>

From aph at redhat.com  Sun Aug 23 04:58:36 2015
From: aph at redhat.com (Andrew Haley)
Date: Sun, 23 Aug 2015 09:58:36 +0100
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <55D724A3.4090309@cs.oswego.edu>
References: <55D61376.9060600@redhat.com> <55D724A3.4090309@cs.oswego.edu>
Message-ID: <55D98B3C.20002@redhat.com>

On 08/21/2015 02:16 PM, Doug Lea wrote:
> On 08/20/2015 01:50 PM, Andrew Haley wrote:
>> Just to reassure me: a card table write in a generational collector
>> only needs a StoreStore fence, not a release.  Is that right?
>>
> 
> Definitive answers might be collector-specific.
> So you might try asking on hotspot-gc-dev?
>    http://mail.openjdk.java.net/mailman/listinfo/hotspot-gc-dev

Sure, I understand that.  My question was more general, following
Hans's sometimes surprising observations of the failures of StoreStore
fences.  A card table store is merely a constant written into a table,
and that constant is fixed.  All that is required is that the
preceding reference store and the card table store are observable to
all threads in the order they were written.  Hence a StoreStore fence.

Andrew.

From gil at azulsystems.com  Sun Aug 23 06:34:28 2015
From: gil at azulsystems.com (Gil Tene)
Date: Sun, 23 Aug 2015 10:34:28 +0000
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <55D98B3C.20002@redhat.com>
References: <55D61376.9060600@redhat.com>
	<55D724A3.4090309@cs.oswego.edu>,<55D98B3C.20002@redhat.com>
Message-ID: <F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>

Andrew,

For generational collection the ordering required by a collector's reference store barrier depends on the collector mechanisms. The purpose of the reference store barrier in generational collectors is to maintain remembered sets from older to younger generations. A card table is a good example of such a remembered set.

When the collector performs younger generation collections in monolithic stop-the-world pauses, the only ordering requirement between a card mark store and the associated reference store is that they cannot be separated by a safepoint. They can occur in any order as long as that requirement is maintained. This describes the situation for all current young generation collectors in HotSpot (AFAIK Zing's C4 is still the only non-STW young generation collector in a shipping JVM).

When the young generation collection can run concurrently with mutator execution the typical ordering requirement would be for the recording of generational remembered set information (e.g. a card table store) to be visible to GC threads before the reference store itself. Hence a logical StoreStore fence exists between the two, and must be enforced by all code generation and executing CPUs. Note that the requirement for the two stores to not be separated by a safepoint is usually still there as well (and that requirement is not satisfied by a StoreStore barrier). Also note that I use "typically" and "usually" above, because correct concurrent card scanning algorithms that do not carry these specific requirements certainly exist. As noted, this is not relevant for HotSpot's generational behavior because the younggens are all STW. But in the specific example of Zing/C4 we do use a card table, we do scan it concurrently, and we do require both the StoreStore order and the not-separated-but-safepoint requirement.

Beyond generational collection, It is VERY important to remember that some collectors use reference store barriers for purposes other than generational remembered set tracking.

E.g. to my understanding CMS uses the same card table store to *also* track mutations during concurrent marking of the oldgen. So while the generational part of the collector has no concurrency or ordering issues, the oldgen marking functionality does require the StoreStore ordering in addition to the not-separated-by-safepoint requirement.

Similarly, G1 uses a reference store barrier (not just a card table store) to enforce its mostly concurrent marker's snapshot-at-the-beginning (SATB) invariants (in addition to doing reference set tracking). As such, it too *might* need the StoreStore order. I'm less sure about that one, because I think SATB might do fine without the orderinggucen the information captured by the barrier.

HTH.

Sent from Gil's iPhone

> On Aug 23, 2015, at 2:23 AM, Andrew Haley <aph at redhat.com> wrote:
> 
>> On 08/21/2015 02:16 PM, Doug Lea wrote:
>>> On 08/20/2015 01:50 PM, Andrew Haley wrote:
>>> Just to reassure me: a card table write in a generational collector
>>> only needs a StoreStore fence, not a release.  Is that right?
>> 
>> Definitive answers might be collector-specific.
>> So you might try asking on hotspot-gc-dev?
>>   http://mail.openjdk.java.net/mailman/listinfo/hotspot-gc-dev
> 
> Sure, I understand that.  My question was more general, following
> Hans's sometimes surprising observations of the failures of StoreStore
> fences.  A card table store is merely a constant written into a table,
> and that constant is fixed.  All that is required is that the
> preceding reference store and the card table store are observable to
> all threads in the order they were written.  Hence a StoreStore fence.
> 
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Sun Aug 23 07:16:09 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 23 Aug 2015 07:16:09 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440262067408-12680.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
Message-ID: <55D9AB79.4010006@cs.oswego.edu>

On 08/22/2015 12:47 PM, thurstonn wrote:

> What are the plans with respect to the "higher-order methods" on e.g.
> AtomicReference, i.e.
>
> T getAndAccumulate(T, BinaryOperator<T>)
> T updateAndGet(UnaryOperator<T>)

No plans; basically for the reasons you noted: There are too many
possibilities to support, all of them can be done on top of what
we do provide, and they don't fit well with the polymorphic
signature mechanics.

> And one final question that I've always been confused about;  are there
> different "memory ordering effects" between a successful CAS and an
> unsuccessful one (presumably in the latter because no write actually
> occurs)?

The memory ordering effects are the same regardless of outcome.
Ensuring this sometimes takes some thought on ARM -- see some
exchanges on this list last fall(?).

> IIRC, when looking at the java 8 JVM code, I believe a fence was inserted in
> the successful case, at least on x86/64.  If so, I can take a shot at
> producing some javadoc language to reflect that, if it would be helpful.

There is no extra fence on x86. (Hotspot sometimes prevents
internal IR reorderings using the (misnamed) MemBarCPUOrder
just for internal reasons. This might be what you were seeing.)

-Doug


From gil at azulsystems.com  Sun Aug 23 12:12:01 2015
From: gil at azulsystems.com (Gil Tene)
Date: Sun, 23 Aug 2015 16:12:01 +0000
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
References: <55D61376.9060600@redhat.com> <55D724A3.4090309@cs.oswego.edu>
	<55D98B3C.20002@redhat.com>
	<F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
Message-ID: <8F748F9E-DF0C-4FF5-902E-00F8EC574925@azulsystems.com>

To add/amend the below a bit:

Depending on the collector implementation, a StoreStore fence between a card table store and the related reference store may be an alternative to the requirement for the two stores to not be separated by a safepoint: If the StoreStore order is maintained and the reference value being stored remains live in registers, and the collector mechanism scans the stacks at a safepoint before completing the card scanning, then having the two stores separated by a safepoint is acceptable.

In checking on the HotSpot younggen collectors, I believe this means that a StoreStore fence is sufficient in itself. I.e. that you need either a StoreStore fence *or* no-safepoint-between-the-stores, but not both.

? Gil.

> On Aug 23, 2015, at 3:34 AM, Gil Tene <gil at azulsystems.com> wrote:
> 
> Andrew,
> 
> For generational collection the ordering required by a collector's reference store barrier depends on the collector mechanisms. The purpose of the reference store barrier in generational collectors is to maintain remembered sets from older to younger generations. A card table is a good example of such a remembered set.
> 
> When the collector performs younger generation collections in monolithic stop-the-world pauses, the only ordering requirement between a card mark store and the associated reference store is that they cannot be separated by a safepoint. They can occur in any order as long as that requirement is maintained. This describes the situation for all current young generation collectors in HotSpot (AFAIK Zing's C4 is still the only non-STW young generation collector in a shipping JVM).
> 
> When the young generation collection can run concurrently with mutator execution the typical ordering requirement would be for the recording of generational remembered set information (e.g. a card table store) to be visible to GC threads before the reference store itself. Hence a logical StoreStore fence exists between the two, and must be enforced by all code generation and executing CPUs. Note that the requirement for the two stores to not be separated by a safepoint is usually still there as well (and that requirement is not satisfied by a StoreStore barrier). Also note that I use "typically" and "usually" above, because correct concurrent card scanning algorithms that do not carry these specific requirements certainly exist. As noted, this is not relevant for HotSpot's generational behavior because the younggens are all STW. But in the specific example of Zing/C4 we do use a card table, we do scan it concurrently, and we do require both the StoreStore order and the not-s!
> eparated-but-safepoint requirement.
> 
> Beyond generational collection, It is VERY important to remember that some collectors use reference store barriers for purposes other than generational remembered set tracking.
> 
> E.g. to my understanding CMS uses the same card table store to *also* track mutations during concurrent marking of the oldgen. So while the generational part of the collector has no concurrency or ordering issues, the oldgen marking functionality does require the StoreStore ordering in addition to the not-separated-by-safepoint requirement.
> 
> Similarly, G1 uses a reference store barrier (not just a card table store) to enforce its mostly concurrent marker's snapshot-at-the-beginning (SATB) invariants (in addition to doing reference set tracking). As such, it too *might* need the StoreStore order. I'm less sure about that one, because I think SATB might do fine without the orderinggucen the information captured by the barrier.
> 
> HTH.
> 
> Sent from Gil's iPhone
> 
>> On Aug 23, 2015, at 2:23 AM, Andrew Haley <aph at redhat.com> wrote:
>> 
>>> On 08/21/2015 02:16 PM, Doug Lea wrote:
>>>> On 08/20/2015 01:50 PM, Andrew Haley wrote:
>>>> Just to reassure me: a card table write in a generational collector
>>>> only needs a StoreStore fence, not a release.  Is that right?
>>> 
>>> Definitive answers might be collector-specific.
>>> So you might try asking on hotspot-gc-dev?
>>>  http://mail.openjdk.java.net/mailman/listinfo/hotspot-gc-dev
>> 
>> Sure, I understand that.  My question was more general, following
>> Hans's sometimes surprising observations of the failures of StoreStore
>> fences.  A card table store is merely a constant written into a table,
>> and that constant is fixed.  All that is required is that the
>> preceding reference store and the card table store are observable to
>> all threads in the order they were written.  Hence a StoreStore fence.
>> 
>> Andrew.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150823/bdc5d21e/attachment.bin>

From thurston at nomagicsoftware.com  Sun Aug 23 12:17:32 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Sun, 23 Aug 2015 09:17:32 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D9AB79.4010006@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<55D9AB79.4010006@cs.oswego.edu>
Message-ID: <1440346652365-12688.post@n7.nabble.com>

from unsafe.cpp:

UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapObject(JNIEnv *env, jobject
unsafe, jobject obj, jlong offset, jobject e_h, jobject x_h))

  UnsafeWrapper("Unsafe_CompareAndSwapObject");

  oop x = JNIHandles::resolve(x_h);

  oop e = JNIHandles::resolve(e_h);

  oop p = JNIHandles::resolve(obj);

  HeapWord* addr = (HeapWord *)index_oop_from_field_offset_long(p, offset);

  oop res = oopDesc::atomic_compare_exchange_oop(x, addr, e, true);

  jboolean success  = (res == e);

 * if (success)

    update_barrier_set((void*)addr, x);*

  return success;

UNSAFE_END

That's what I was referring to; I  presumed update_barrier_set resulted in
some sort of store fence



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12688.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From vitalyd at gmail.com  Sun Aug 23 13:30:36 2015
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 23 Aug 2015 13:30:36 -0400
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440346652365-12688.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<55D9AB79.4010006@cs.oswego.edu>
	<1440346652365-12688.post@n7.nabble.com>
Message-ID: <CAHjP37EUspT5arLxNc_5E0q=BAcW7s2wZ_Fn9dmWfPtbQAeQ7Q@mail.gmail.com>

That's likely a store/write barrier for GC (i.e. card mark).

sent from my phone
On Aug 23, 2015 1:17 PM, "thurstonn" <thurston at nomagicsoftware.com> wrote:

> from unsafe.cpp:
>
> UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapObject(JNIEnv *env, jobject
> unsafe, jobject obj, jlong offset, jobject e_h, jobject x_h))
>
>   UnsafeWrapper("Unsafe_CompareAndSwapObject");
>
>   oop x = JNIHandles::resolve(x_h);
>
>   oop e = JNIHandles::resolve(e_h);
>
>   oop p = JNIHandles::resolve(obj);
>
>   HeapWord* addr = (HeapWord *)index_oop_from_field_offset_long(p, offset);
>
>   oop res = oopDesc::atomic_compare_exchange_oop(x, addr, e, true);
>
>   jboolean success  = (res == e);
>
>  * if (success)
>
>     update_barrier_set((void*)addr, x);*
>
>   return success;
>
> UNSAFE_END
>
> That's what I was referring to; I  presumed update_barrier_set resulted in
> some sort of store fence
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12688.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150823/953f8e47/attachment.html>

From thurston at nomagicsoftware.com  Sun Aug 23 13:42:29 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Sun, 23 Aug 2015 10:42:29 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55D72B2F.70901@cs.oswego.edu>
References: <55D72B2F.70901@cs.oswego.edu>
Message-ID: <1440351749487-12690.post@n7.nabble.com>

As far as a code sample for the compareAndExchangeXXX variants:


//An improved updateAndGet
Object owner = . . .
VarHandle<T> referent = . . .
UnaryOperator<T> identity = it -> it;

T expected = referent.getXXX();
T updated = identity.apply(expected);


for (; (expected = referent.compareAndExchangeXXX(owner, expected, updated))
!= updated; updated = identity.apply(expected)) {}

return updated; //updated == expected


Not exactly sure whether AtomicReference will use VarHandles or not, but all
of the "higher order methods" should be rewritten similarly




--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12690.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From aph at redhat.com  Mon Aug 24 04:39:24 2015
From: aph at redhat.com (Andrew Haley)
Date: Mon, 24 Aug 2015 09:39:24 +0100
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
References: <55D61376.9060600@redhat.com> <55D724A3.4090309@cs.oswego.edu>,
	<55D98B3C.20002@redhat.com>
	<F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
Message-ID: <55DAD83C.1060502@redhat.com>

OK, thanks for a very insightful and detailed answer.

I will raise this one on the gc-dev lists.  My best guess ATM is that
it's only CMS which requires a StoreStore (G1 has entirely separate
code) but I'll reserve judgement until I've had that discussion.

Thanks again,

Andrew.

From aleksey.shipilev at oracle.com  Mon Aug 24 05:07:51 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Mon, 24 Aug 2015 12:07:51 +0300
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CAHjP37EUspT5arLxNc_5E0q=BAcW7s2wZ_Fn9dmWfPtbQAeQ7Q@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<55D9AB79.4010006@cs.oswego.edu>	<1440346652365-12688.post@n7.nabble.com>
	<CAHjP37EUspT5arLxNc_5E0q=BAcW7s2wZ_Fn9dmWfPtbQAeQ7Q@mail.gmail.com>
Message-ID: <55DADEE7.7020104@oracle.com>

That *is* a GC write barrier. While it may have an internal memory
semantics that affects the actual semantics of reference CAS, its
effects are not advertised.

-Aleksey

P.S. Somewhat amusingly, C2 intrinsic for reference CAS implemented a
success-only GC write barrier only recently:
  https://bugs.openjdk.java.net/browse/JDK-8019968


On 08/23/2015 08:30 PM, Vitaly Davidovich wrote:
> That's likely a store/write barrier for GC (i.e. card mark).
> 
> sent from my phone
> 
> On Aug 23, 2015 1:17 PM, "thurstonn" <thurston at nomagicsoftware.com
> <mailto:thurston at nomagicsoftware.com>> wrote:
> 
>     from unsafe.cpp:
> 
>     UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapObject(JNIEnv *env, jobject
>     unsafe, jobject obj, jlong offset, jobject e_h, jobject x_h))
> 
>       UnsafeWrapper("Unsafe_CompareAndSwapObject");
> 
>       oop x = JNIHandles::resolve(x_h);
> 
>       oop e = JNIHandles::resolve(e_h);
> 
>       oop p = JNIHandles::resolve(obj);
> 
>       HeapWord* addr = (HeapWord *)index_oop_from_field_offset_long(p,
>     offset);
> 
>       oop res = oopDesc::atomic_compare_exchange_oop(x, addr, e, true);
> 
>       jboolean success  = (res == e);
> 
>      * if (success)
> 
>         update_barrier_set((void*)addr, x);*
> 
>       return success;
> 
>     UNSAFE_END
> 
>     That's what I was referring to; I  presumed update_barrier_set
>     resulted in
>     some sort of store fence
> 
> 
> 
>     --
>     View this message in context:
>     http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12688.html
>     Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150824/53f4705d/attachment.bin>

From aph at redhat.com  Mon Aug 24 05:53:00 2015
From: aph at redhat.com (Andrew Haley)
Date: Mon, 24 Aug 2015 10:53:00 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440346652365-12688.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<55D9AB79.4010006@cs.oswego.edu>
	<1440346652365-12688.post@n7.nabble.com>
Message-ID: <55DAE97C.6060800@redhat.com>

On 08/23/2015 05:17 PM, thurstonn wrote:
> That's what I was referring to; I  presumed update_barrier_set resulted in
> some sort of store fence

As others have said, that's a GC write barrier.  This confusion is one
reason why we try to talk about "fence" instructions on this list, and
GC "barriers."

Andrew.


From chris.purcell.39 at gmail.com  Mon Aug 24 07:36:23 2015
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Mon, 24 Aug 2015 11:36:23 +0000
Subject: [concurrency-interest] CompletableFuture improvements
In-Reply-To: <55D32FC9.1080604@cs.oswego.edu>
References: <CAJUoZVY3WRe-BJ76CNKQ6SeQyYm7ZW3aaPAffm+mTfrjivxw2g@mail.gmail.com>
	<55CE0A37.5000608@cs.oswego.edu>
	<CAJUoZVaYtEcxH2rHs67i4mMOwco5639Mu01=7qXGQsSFSMqMhQ@mail.gmail.com>
	<55D32FC9.1080604@cs.oswego.edu>
Message-ID: <CAJUoZVaoWqQTcrqzWDUo9qgvxz8wOqBrNuKKiB+suARJm3fLPQ@mail.gmail.com>

Thanks for the context, Doug. It seems like cross-thread helping *is* the
only thing my design loses (it's still non-blocking, atomic and avoids
stack-overflow), which is nice to confirm in case I do decide my library is
worth releasing properly.

I'm pretty confident the thread-local back-channel approach can be adapted
to "pull up" work to the thread's current CompletableFuture handler without
throwing away the trampoline/assistance feature. I look forward to hearing
if it works out for you!

Cheers,
Chris


P.S. java.util.concurrent has been a great example of cutting-edge
concurrent algorithms in the real world since my PhD, a horrifyingly long
time ago. Thanks for all your inspiring work!

On Tue, 18 Aug 2015 at 14:14 Doug Lea <dl at cs.oswego.edu> wrote:

> On 08/17/2015 02:27 PM, Chris Purcell wrote:
>
> > I may be way off-base on /why/ CompletableFuture has a work queue of
> callbacks.
> > I assumed it was because, if you have a long chain (a couple of
> thousand) of
> > dependent futures, and you call dependent callbacks recursively within
> the
> > upstream future's completion handler, then the call stack will overflow.
> You can
> > easily demonstrate this with CompletableFutures:
>
> CompletableFuture uses a Treiber-stack-like completion list for
> several related reasons: it is non-blocking, atomically resolves
> races (like when adding to a CF that is in the midst of completing),
> allows helping across threads, and helps avoids stack-overflow
> (especially with the 8u update to do so even across threads).
>
> As discussed last year, we'd like to catch as many of these
> cases as possible, because StackOverflowError is otherwise
> so problematic on JVMs -- some are never caught or handled.
> This is not special to completion designs but more common with them.
> (Aside: it is an odd state of affairs that you need to emulate
> stacks on heaps, with greater peak total memory overhead,
> to avoid stack overflow.) Without some JVM-level tail-recursion
> support (and maybe even with it), the options are limited in cases
> where the recursion occurs in the bodies of lambdas where we
> cannot see it. That's the main difference in your two examples:
>
>                CompletableFuture<Integer> newTail = new
> CompletableFuture<>();
>                tail.thenAccept(v -> newTail.complete(v + 1));
>                tail = newTail;
> vs
>
>                tail = tail.thenApply(v -> v + 1);
>
> We can "trampoline" thenAccept and thenApply, but we don't
> even see the newTail.complete(v + 1) because it is inside a
> lambda. On the other hand, if the first usage were async, the
> cross-thread mechanisms kick in to prevent SOE:
>
>      public void async_recursive_callbacks() {
>          CompletableFuture<Integer> head = new CompletableFuture<>();
>          CompletableFuture<Integer> tail = head;
>          for (int i = 0; i < 2_000; i++) {
>              CompletableFuture<Integer> newTail = new
> CompletableFuture<>();
>              tail.thenAcceptAsync(v -> newTail.complete(v + 1));
>              tail = newTail;
>          }
>          head.complete(7);
>          assertEquals(2007, (int) tail.join());
>      }
>
> It is possible that we could do better here. I'll investigate.
> Your thread-local back-channel approach handles some cases,
> but I don't think can coexist with other support.
>
> -Doug
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150824/998e12b8/attachment-0001.html>

From thurston at nomagicsoftware.com  Mon Aug 24 08:43:38 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Mon, 24 Aug 2015 05:43:38 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440351749487-12690.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440351749487-12690.post@n7.nabble.com>
Message-ID: <1440420218839-12695.post@n7.nabble.com>

I have to laugh.  
(it) -> it 
as an example UnaryOperator is a particularly bad example when illustrating
CAS.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12695.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From thurston at nomagicsoftware.com  Mon Aug 24 08:45:59 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Mon, 24 Aug 2015 05:45:59 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <55DAE97C.6060800@redhat.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<55D9AB79.4010006@cs.oswego.edu>
	<1440346652365-12688.post@n7.nabble.com>
	<55DAE97C.6060800@redhat.com>
Message-ID: <1440420359617-12696.post@n7.nabble.com>

Thanks for the clarification.
I generally had considered "memory fence" and "memory barrier" as more or
less interchangeable.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12696.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From martinrb at google.com  Mon Aug 24 12:59:38 2015
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 24 Aug 2015 09:59:38 -0700
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440420359617-12696.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440248819913-12677.post@n7.nabble.com>
	<55D88006.8030906@cs.oswego.edu>
	<1440262067408-12680.post@n7.nabble.com>
	<55D9AB79.4010006@cs.oswego.edu>
	<1440346652365-12688.post@n7.nabble.com>
	<55DAE97C.6060800@redhat.com>
	<1440420359617-12696.post@n7.nabble.com>
Message-ID: <CA+kOe0_U1c1ubVwQuv=-tjL=1PbOf1ZQGP4beuxb9h5GrpESRA@mail.gmail.com>

On Mon, Aug 24, 2015 at 5:45 AM, thurstonn <thurston at nomagicsoftware.com>
wrote:

> Thanks for the clarification.
> I generally had considered "memory fence" and "memory barrier" as more or
> less interchangeable.
>

It's even more confusing, I think, since "memory barrier" and "gc barrier"
seem to be different things.  "memory fence" and "memory barrier" may be
the same thing, but the word "fence" is more likely to be used with actual
machine instructions ... except that sparc has a "membar" instruction, and
sparc strongly influenced hotspot?!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150824/c2c71cdb/attachment.html>

From aph at redhat.com  Mon Aug 24 13:26:15 2015
From: aph at redhat.com (Andrew Haley)
Date: Mon, 24 Aug 2015 18:26:15 +0100
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <CA+kOe0_U1c1ubVwQuv=-tjL=1PbOf1ZQGP4beuxb9h5GrpESRA@mail.gmail.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440248819913-12677.post@n7.nabble.com>	<55D88006.8030906@cs.oswego.edu>	<1440262067408-12680.post@n7.nabble.com>	<55D9AB79.4010006@cs.oswego.edu>	<1440346652365-12688.post@n7.nabble.com>	<55DAE97C.6060800@redhat.com>	<1440420359617-12696.post@n7.nabble.com>
	<CA+kOe0_U1c1ubVwQuv=-tjL=1PbOf1ZQGP4beuxb9h5GrpESRA@mail.gmail.com>
Message-ID: <55DB53B7.6040304@redhat.com>

On 08/24/2015 05:59 PM, Martin Buchholz wrote:
> 
> 
> On Mon, Aug 24, 2015 at 5:45 AM, thurstonn <thurston at nomagicsoftware.com <mailto:thurston at nomagicsoftware.com>> wrote:
> 
>     Thanks for the clarification.
>     I generally had considered "memory fence" and "memory barrier" as more or
>     less interchangeable.
> 
> 
> It's even more confusing, I think, since "memory barrier" and "gc
> barrier" seem to be different things.  "memory fence" and "memory
> barrier" may be the same thing, but the word "fence" is more likely
> to be used with actual machine instructions ... except that sparc
> has a "membar" instruction, and sparc strongly influenced hotspot?!

Well, yes.  But we are trying.  :-)

Andrew.

From gil at azulsystems.com  Thu Aug 27 20:27:25 2015
From: gil at azulsystems.com (Gil Tene)
Date: Fri, 28 Aug 2015 00:27:25 +0000
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <8F748F9E-DF0C-4FF5-902E-00F8EC574925@azulsystems.com>
References: <55D61376.9060600@redhat.com> <55D724A3.4090309@cs.oswego.edu>
	<55D98B3C.20002@redhat.com>
	<F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
	<8F748F9E-DF0C-4FF5-902E-00F8EC574925@azulsystems.com>
Message-ID: <F2EEE23C-28B4-4326-A16B-E1CED85E1FAB@azulsystems.com>

To re-ammend (de-ammend?) my below ammendment: After some more checking and conversations, I'm going back to my original assertions: A reference store and it's associated card table store must not be separated by a safepoint. Several "bad things" can happen if they do, and a StoreStore fence alone is not enough to avoid those "bad things".

For two specific "bad thing" examples:

1) Imagine the sequence was: ref_store; StoreStore_fence; card_store;

The ref_store is free to float back across a previous safepoint polling opportunity. And the card_store is free to float forward past a following safepoint polling opportunity. Either of these can result in a possible safepoint occurring with a newgen root in oldgen that is not identified in the card table (boom).

2) Imagine the sequence was: card_store; StoreStore_fence; ref_store;

The card_store is free to float back across a previous safepoint polling opportunity. And the ref_store is free to float forward past a following safepoint polling opportunity. Either of these can result in a possible safepoint occurring with an "already dirtied card" that will have an associated reference stored into only after the safepoint is completed. If the safepoint cleans the card table (which can commonly happen), the reference store that follows the safepoint will not be tracked in the card table examined by future safepoints (boom).

This makes the StoreStore_fence useless for generational card table marking safety. It may not be needed at all as a result (depending on what else the card mark and the collector algorithms are doing), but the safepoint-crossing scheduling rules are absolutely required.

? Gil.

> On Aug 23, 2015, at 9:12 AM, Gil Tene <gil at azulsystems.com> wrote:
> 
> To add/amend the below a bit:
> 
> Depending on the collector implementation, a StoreStore fence between a card table store and the related reference store may be an alternative to the requirement for the two stores to not be separated by a safepoint: If the StoreStore order is maintained and the reference value being stored remains live in registers, and the collector mechanism scans the stacks at a safepoint before completing the card scanning, then having the two stores separated by a safepoint is acceptable.
> 
> In checking on the HotSpot younggen collectors, I believe this means that a StoreStore fence is sufficient in itself. I.e. that you need either a StoreStore fence *or* no-safepoint-between-the-stores, but not both.
> 
> ? Gil.
> 
>> On Aug 23, 2015, at 3:34 AM, Gil Tene <gil at azulsystems.com> wrote:
>> 
>> Andrew,
>> 
>> For generational collection the ordering required by a collector's reference store barrier depends on the collector mechanisms. The purpose of the reference store barrier in generational collectors is to maintain remembered sets from older to younger generations. A card table is a good example of such a remembered set.
>> 
>> When the collector performs younger generation collections in monolithic stop-the-world pauses, the only ordering requirement between a card mark store and the associated reference store is that they cannot be separated by a safepoint. They can occur in any order as long as that requirement is maintained. This describes the situation for all current young generation collectors in HotSpot (AFAIK Zing's C4 is still the only non-STW young generation collector in a shipping JVM).
>> 
>> When the young generation collection can run concurrently with mutator execution the typical ordering requirement would be for the recording of generational remembered set information (e.g. a card table store) to be visible to GC threads before the reference store itself. Hence a logical StoreStore fence exists between the two, and must be enforced by all code generation and executing CPUs. Note that the requirement for the two stores to not be separated by a safepoint is usually still there as well (and that requirement is not satisfied by a StoreStore barrier). Also note that I use "typically" and "usually" above, because correct concurrent card scanning algorithms that do not carry these specific requirements certainly exist. As noted, this is not relevant for HotSpot's generational behavior because the younggens are all STW. But in the specific example of Zing/C4 we do use a card table, we do scan it concurrently, and we do require both the StoreStore order and the not-s!
>> eparated-but-safepoint requirement.
>> 
>> Beyond generational collection, It is VERY important to remember that some collectors use reference store barriers for purposes other than generational remembered set tracking.
>> 
>> E.g. to my understanding CMS uses the same card table store to *also* track mutations during concurrent marking of the oldgen. So while the generational part of the collector has no concurrency or ordering issues, the oldgen marking functionality does require the StoreStore ordering in addition to the not-separated-by-safepoint requirement.
>> 
>> Similarly, G1 uses a reference store barrier (not just a card table store) to enforce its mostly concurrent marker's snapshot-at-the-beginning (SATB) invariants (in addition to doing reference set tracking). As such, it too *might* need the StoreStore order. I'm less sure about that one, because I think SATB might do fine without the orderinggucen the information captured by the barrier.
>> 
>> HTH.
>> 
>> Sent from Gil's iPhone
>> 
>>> On Aug 23, 2015, at 2:23 AM, Andrew Haley <aph at redhat.com> wrote:
>>> 
>>>> On 08/21/2015 02:16 PM, Doug Lea wrote:
>>>>> On 08/20/2015 01:50 PM, Andrew Haley wrote:
>>>>> Just to reassure me: a card table write in a generational collector
>>>>> only needs a StoreStore fence, not a release.  Is that right?
>>>> 
>>>> Definitive answers might be collector-specific.
>>>> So you might try asking on hotspot-gc-dev?
>>>> http://mail.openjdk.java.net/mailman/listinfo/hotspot-gc-dev
>>> 
>>> Sure, I understand that.  My question was more general, following
>>> Hans's sometimes surprising observations of the failures of StoreStore
>>> fences.  A card table store is merely a constant written into a table,
>>> and that constant is fixed.  All that is required is that the
>>> preceding reference store and the card table store are observable to
>>> all threads in the order they were written.  Hence a StoreStore fence.
>>> 
>>> Andrew.
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150828/da24434f/attachment.bin>

From aph at redhat.com  Fri Aug 28 04:13:37 2015
From: aph at redhat.com (Andrew Haley)
Date: Fri, 28 Aug 2015 09:13:37 +0100
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <F2EEE23C-28B4-4326-A16B-E1CED85E1FAB@azulsystems.com>
References: <55D61376.9060600@redhat.com> <55D724A3.4090309@cs.oswego.edu>
	<55D98B3C.20002@redhat.com>
	<F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
	<8F748F9E-DF0C-4FF5-902E-00F8EC574925@azulsystems.com>
	<F2EEE23C-28B4-4326-A16B-E1CED85E1FAB@azulsystems.com>
Message-ID: <55E01831.40607@redhat.com>

On 08/28/2015 01:27 AM, Gil Tene wrote:
> For two specific "bad thing" examples:
> 
> 1) Imagine the sequence was: ref_store; StoreStore_fence; card_store;
> 
> The ref_store is free to float back across a previous safepoint polling opportunity.

I don't see how.  Any safepoint poll which actually traps is a full barrier; if
it doesn't trap it doesn't matter.  I must be missing something...

Andrew.


From gil at azulsystems.com  Fri Aug 28 11:01:17 2015
From: gil at azulsystems.com (Gil Tene)
Date: Fri, 28 Aug 2015 15:01:17 +0000
Subject: [concurrency-interest] Fences and card tables
In-Reply-To: <55E01831.40607@redhat.com>
References: <55D61376.9060600@redhat.com> <55D724A3.4090309@cs.oswego.edu>
	<55D98B3C.20002@redhat.com>
	<F7D7EF0A-CFA9-417E-87E7-BF76AEADCAA9@azulsystems.com>
	<8F748F9E-DF0C-4FF5-902E-00F8EC574925@azulsystems.com>
	<F2EEE23C-28B4-4326-A16B-E1CED85E1FAB@azulsystems.com>,
	<55E01831.40607@redhat.com>
Message-ID: <F1C9ADC1-9462-4783-8143-258FCDB57CC8@azulsystems.com>

The compiler doesn't treat safepoint polling opportunities as a fence at all (at least in the normal store & load ordering sense). Unless otherwise prevented, loads and stores are free to float across safepoint polling opportunities even when they are preceded or followed by the various fences (acquire/release/StoreStore/etc.).

While an actually taken safepoint poll does apply a full fence from the CPU's point of view the ref_store in the example below could have floated back across that safepoint and show up (in the CPUs instruction stream) before the safepoint poll was made (if all that was ordering it was the StoreStore in the example).

To safely avoid separating a ref store and its related card table store with a safepoint, additional "safepoint related fencing" capabilities are needed in the JIT. Note that these never apply to program semantics, and only to the JVM's internal implementation of bytecode sub-parts. So only Runtime and JIT implementers need to be aware of them.

The simplest way to handle this is/was for JITs to consider the entire sequence (ref store and card mark store) to be inseparable from scheduling point of view. Often by using a single IR node to represent the combo. But as scheduling benefits for the two parts are sought (and there are some) and the sequence is split into separate IR nodes, scheduling rules relating to those nodes' ability to cross safepoints apply. 

One way to achieve this ordering restriction is for the JIT to treat all safepoint polling opportunities as if they both consume and potentially modify all references stored to memory, as well as all cards stored to memory. This then prevents them from being reordered with either regardless of fences. Unfortunately, this strong approach prevents some useful optimizations. As you weaken the restriction (allowing e.g. hoisting repeated reference loads out of loops that have safepoints in their back edge), stating the actual ordering needed for things like card marks becomes more specific.

Sent from Gil's iPhone

> On Aug 28, 2015, at 1:13 AM, Andrew Haley <aph at redhat.com> wrote:
> 
>> On 08/28/2015 01:27 AM, Gil Tene wrote:
>> For two specific "bad thing" examples:
>> 
>> 1) Imagine the sequence was: ref_store; StoreStore_fence; card_store;
>> 
>> The ref_store is free to float back across a previous safepoint polling opportunity.
> 
> I don't see how.  Any safepoint poll which actually traps is a full barrier; if
> it doesn't trap it doesn't matter.  I must be missing something...
> 
> Andrew.
> 


From discus at kotek.net  Fri Aug 28 15:50:02 2015
From: discus at kotek.net (Jan Kotek)
Date: Fri, 28 Aug 2015 22:50:02 +0300
Subject: [concurrency-interest] MapDB benchmarks
Message-ID: <20883494.vR7X9uvoLJ@artemis>

Hi, 

Most of you probably know MapDB. It is alternative java collection 
implementation.

I ran some benchmarks on recent version. It compares ConcurrentHashMap and 
ConcurrentSkipListMap with HTreeMap and BTreeMap from MapDB. I would like to 
know your opinion. My collections are only 10x slower in some cases :-) 

Results: 
http://www.mapdb.org/benchmarks.html 

Sources:
https://github.com/jankotek/mapdb-benchmarks 


I posted other benchmarks about a year ago, those were broken because of 
java.util.Random overhead. I think similar problem is not here.

Current bench is single-threaded. I have some problems with lock overlaps etc, 
but it is under control. Final MapDB 2.0 should be linearly scalable to 4 cpu 
cores, I will add tests once its done. 

Regards,
Jan Kotek






From thurston at nomagicsoftware.com  Mon Aug 31 07:02:56 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Mon, 31 Aug 2015 04:02:56 -0700 (MST)
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1440187306402-12670.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
Message-ID: <1441018976422-12703.post@n7.nabble.com>

So I'm still not clear on the implementation of VarHandles, et al.

1.  Do each of the methods have a corresponding Unsafe method?

2.  Is each method "marked intrinsic"?  

Looking at  this
<http://hg.openjdk.java.net/jdk9/jdk9/hotspot/file/tip/src/share/vm/classfile/vmSymbols.hpp> 
, I don't see compareAndExchangeXXX, e.g. listed



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12703.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From aleksey.shipilev at oracle.com  Mon Aug 31 08:02:12 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Mon, 31 Aug 2015 15:02:12 +0300
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1441018976422-12703.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
Message-ID: <55E44244.1090501@oracle.com>

That's because your are <strike>barking up the wrong tree</strike>
looking at a wrong forest. See the reference to the actual VarHandles
development forest here:
  https://bugs.openjdk.java.net/browse/JDK-8080588

Thanks,
-Aleksey

On 08/31/2015 02:02 PM, thurstonn wrote:
> So I'm still not clear on the implementation of VarHandles, et al.
> 
> 1.  Do each of the methods have a corresponding Unsafe method?
> 
> 2.  Is each method "marked intrinsic"?  
> 
> Looking at  this
> <http://hg.openjdk.java.net/jdk9/jdk9/hotspot/file/tip/src/share/vm/classfile/vmSymbols.hpp> 
> , I don't see compareAndExchangeXXX, e.g. listed
> 
> 
> 
> --
> View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/jdk9-VarHandle-and-Fence-methods-tp12666p12703.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150831/9050d9fd/attachment.bin>

From paul.sandoz at oracle.com  Mon Aug 31 08:12:03 2015
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Mon, 31 Aug 2015 14:12:03 +0200
Subject: [concurrency-interest] jdk9 VarHandle and Fence methods
In-Reply-To: <1441018976422-12703.post@n7.nabble.com>
References: <55D72B2F.70901@cs.oswego.edu>
	<1440187306402-12670.post@n7.nabble.com>
	<1441018976422-12703.post@n7.nabble.com>
Message-ID: <37C0C49B-5CFA-40DF-AE36-FB7F79D6A6BB@oracle.com>


On 31 Aug 2015, at 13:02, thurstonn <thurston at nomagicsoftware.com> wrote:

> So I'm still not clear on the implementation of VarHandles, et al.
> 
> 1.  Do each of the methods have a corresponding Unsafe method?
> 

Yes, they will.


> 2.  Is each method "marked intrinsic"?
> 
> Looking at  this
> <http://hg.openjdk.java.net/jdk9/jdk9/hotspot/file/tip/src/share/vm/classfile/vmSymbols.hpp>
> , I don't see compareAndExchangeXXX, e.g. listed
> 

We need to update the sandbox branch implementation to support the agreed set of methods.

  http://hg.openjdk.java.net/jdk9/sandbox/hotspot/file/1c261c6f6c3d/src/share/vm/classfile/vmSymbols.hpp

(You can see some already, such as _weakCompareAndSwapObjectAcquire.)

At some point what is in the sandbox branch implementation will wind it?s way into the JDK 9 dev repo.

Paul.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150831/5e7bf207/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150831/5e7bf207/attachment.bin>

