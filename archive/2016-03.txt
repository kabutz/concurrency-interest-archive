From nader at aeinehchi.com  Tue Mar  1 03:15:22 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Tue, 1 Mar 2016 09:15:22 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
In-Reply-To: <56D4AA9C.6040900@oracle.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
Message-ID: <CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>

Hello everyone

Thank you very much for the good comments.

As stated earlier, I found this pattern on an open source project.  For the
courtesy, I "intentionally" made the code anonymous (called it Foo).

Firstly, The original code contains "static" modifier.  The example that
Christian provided, contains no static modifier.  Would it still be
orthogonal to add volatile to a static instance variable, in this case?

Secondly, given that code does not have a volatile modifier, is it still
thread safe? [I have my doubts, therefore I ask]

Thirdly, suppose Foo is a singleton which is asked by almost every single
call to a server.  Would this code have good performance (with/without
"volatile" modifier)?

In advance, thank you very much

Best regards
Nader

On Mon, Feb 29, 2016 at 9:31 PM, Aleksey Shipilev <
aleksey.shipilev at oracle.com> wrote:

> On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
> > I saw this pattern on an open source project, and wonder if it is thread
> > safe?  If so, would it scale?
>
> See:
>  http://shipilev.net/blog/2014/safe-public-construction/
>
> -Aleksey
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160301/23cea5e8/attachment.html>

From concurrency at kuli.org  Tue Mar  1 03:56:31 2016
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Tue, 1 Mar 2016 09:56:31 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
Message-ID: <56D5593F.8070701@kuli.org>

Hi Nader!> Firstly, The original code contains "static" modifier.  The
example that
> Christian provided, contains no static modifier.  Would it still be
> orthogonal to add volatile to a static instance variable, in this case?

Yes, that will work as well.

> Secondly, given that code does not have a volatile modifier, is it still
> thread safe? [I have my doubts, therefore I ask]

It will be thread safe if Foo is immutable, or more precise, if it
itself has at least one instance variable that is declared as final.

Otherwise, it won't be thread safe without the volatile modifier.

> Thirdly, suppose Foo is a singleton which is asked by almost every
> single call to a server.  Would this code have good performance
> (with/without "volatile" modifier)?

In general, most often you can avoid double checked patterns completely.

When Foo is asked so often anyway, what benefit will you gain from the
lazy initialization then? Nothing.

Double checked locking is only useful when Foo itself is heavy-weight,
or the creation cost is high, and if it's not unlikely that it will
probably never be used. Then you can avoid that cost in some cases, and
when it's necessary, it will be there.

In other cases, esp. when it's used anyway, you better run with a
singleton in a constant field.

But even if you want to load lazily, there's a better and fast approach.
Use a holder class for it like this:

public class Foo {
    private static class Holder {
        static final Foo INSTANCE = new Foo();
    }

    public static Foo getInstance() {
        return Holder.INSTANCE;
    }
    ....
}


Then the class loader will be used to instantiate Foo lazily because the
holder class will only be initialized on the first call to
getInstance(), but all subsequent calls will work directly on the
constant which is the fastest access method anyway.

Best,
Michael


From arno.haase at haase-consulting.com  Tue Mar  1 04:05:29 2016
From: arno.haase at haase-consulting.com (Arno Haase)
Date: Tue, 1 Mar 2016 10:05:29 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
Message-ID: <56D55B59.7010206@haase-consulting.com>

> Firstly, The original code contains "static" modifier.  The example that
> Christian provided, contains no static modifier.  Would it still be
> orthogonal to add volatile to a static instance variable, in this case?

The two are entirely independent.

> Secondly, given that code does not have a volatile modifier, is it still
> thread safe? [I have my doubts, therefore I ask]

No, it is not, in the sense that it does not conform to the Java Memory
Model.

> Thirdly, suppose Foo is a singleton which is asked by almost every
> single call to a server.  Would this code have good performance
> (with/without "volatile" modifier)?

The correct version (with volatile) adds the overhead of a volatile read
for every access. That may or may not be a noticeable overhead,
depending on your use case. If you want to avoid that, there are
alternatives, see the links posted by Christian and Aleksey.

- Arno

From Sebastian.Millies at softwareag.com  Tue Mar  1 04:40:42 2016
From: Sebastian.Millies at softwareag.com (Millies, Sebastian)
Date: Tue, 1 Mar 2016 09:40:42 +0000
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <56D5593F.8070701@kuli.org>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
	<56D5593F.8070701@kuli.org>
Message-ID: <32F15738E8E5524DA4F01A0FA4A8E4900102E3E89E@HQMBX5.eur.ad.sag>

Especially if Foo is heavyweight, using the holder pattern has the drawback that you'll never get rid of the object. Also, the holder pattern is not as amenable for passing in a supplier. It really depends on your use case. When I need a static singleton, I usually find myself using an Enum (something that is not discussed by Aleksey, I wonder why not, as it is also a form of safe publication), otherwise I tend to use double checked locking with a local variable. Generally, I try to avoid the need for either.

-- Sebastian

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Michael Kuhlmann
Sent: Tuesday, March 01, 2016 9:57 AM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?
[snip]

Double checked locking is only useful when Foo itself is heavy-weight, or the creation cost is high, and if it's not unlikely that it will probably never be used. Then you can avoid that cost in some cases, and when it's necessary, it will be there.

In other cases, esp. when it's used anyway, you better run with a singleton in a constant field.

But even if you want to load lazily, there's a better and fast approach.
Use a holder class for it like this:

public class Foo {
    private static class Holder {
        static final Foo INSTANCE = new Foo();
    }

    public static Foo getInstance() {
        return Holder.INSTANCE;
    }
    ....
}


Then the class loader will be used to instantiate Foo lazily because the holder class will only be initialized on the first call to getInstance(), but all subsequent calls will work directly on the constant which is the fastest access method anyway.

Best,
Michael

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt, Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com



From nader at aeinehchi.com  Tue Mar  1 05:38:28 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Tue, 1 Mar 2016 11:38:28 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
In-Reply-To: <56D5593F.8070701@kuli.org>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
	<56D5593F.8070701@kuli.org>
Message-ID: <CAMjJYB=AMs7PFJ4w1uuhUMFOk6u4GsiZNNJmOhfHxgfZgRZ0yw@mail.gmail.com>

Thank you very much for the good response Michael.

In the original author's code, the Foo class is not immutable.  There is no
"volatile" modifier.  Therefore, we can draw the conclusion that the code
is not thread safe.  As such patterns often appear in code, perhaps it
should be marked as "antipattern"?

Personally, I never use double checked locking as it complicates things...

In general, my impression is that people exaggerate the cost of object
initialization.  Therefore, they often go for lazy initialization.  In
particular in singletons upon an application's or server's  startup, there
is often no reason to write lazy initialization whereas there is a huge
penalty for writing not-thread-safe code.

I like the Holder pattern, as in Concurrency in Practice book, that you
propose.

All in all thanks a lot for good comments on this topic.

On Tue, Mar 1, 2016 at 9:56 AM, Michael Kuhlmann <concurrency at kuli.org>
wrote:

> Hi Nader!> Firstly, The original code contains "static" modifier.  The
> example that
> > Christian provided, contains no static modifier.  Would it still be
> > orthogonal to add volatile to a static instance variable, in this case?
>
> Yes, that will work as well.
>
> > Secondly, given that code does not have a volatile modifier, is it still
> > thread safe? [I have my doubts, therefore I ask]
>
> It will be thread safe if Foo is immutable, or more precise, if it
> itself has at least one instance variable that is declared as final.
>
> Otherwise, it won't be thread safe without the volatile modifier.
>
> > Thirdly, suppose Foo is a singleton which is asked by almost every
> > single call to a server.  Would this code have good performance
> > (with/without "volatile" modifier)?
>
> In general, most often you can avoid double checked patterns completely.
>
> When Foo is asked so often anyway, what benefit will you gain from the
> lazy initialization then? Nothing.
>
> Double checked locking is only useful when Foo itself is heavy-weight,
> or the creation cost is high, and if it's not unlikely that it will
> probably never be used. Then you can avoid that cost in some cases, and
> when it's necessary, it will be there.
>
> In other cases, esp. when it's used anyway, you better run with a
> singleton in a constant field.
>
> But even if you want to load lazily, there's a better and fast approach.
> Use a holder class for it like this:
>
> public class Foo {
>     private static class Holder {
>         static final Foo INSTANCE = new Foo();
>     }
>
>     public static Foo getInstance() {
>         return Holder.INSTANCE;
>     }
>     ....
> }
>
>
> Then the class loader will be used to instantiate Foo lazily because the
> holder class will only be initialized on the first call to
> getInstance(), but all subsequent calls will work directly on the
> constant which is the fastest access method anyway.
>
> Best,
> Michael
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160301/0c197557/attachment.html>

From nader at aeinehchi.com  Tue Mar  1 05:39:22 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Tue, 1 Mar 2016 11:39:22 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
In-Reply-To: <56D55B59.7010206@haase-consulting.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
	<56D55B59.7010206@haase-consulting.com>
Message-ID: <CAMjJYB=_RE3=RJUjhOEHZYDjEcWDQ_9eQEqOHRaJS01TCDbJ+w@mail.gmail.com>

Thank you Arno for confirming that this class -as it stands - is not thread
safe.

On Tue, Mar 1, 2016 at 10:05 AM, Arno Haase <arno.haase at haase-consulting.com
> wrote:

> > Firstly, The original code contains "static" modifier.  The example that
> > Christian provided, contains no static modifier.  Would it still be
> > orthogonal to add volatile to a static instance variable, in this case?
>
> The two are entirely independent.
>
> > Secondly, given that code does not have a volatile modifier, is it still
> > thread safe? [I have my doubts, therefore I ask]
>
> No, it is not, in the sense that it does not conform to the Java Memory
> Model.
>
> > Thirdly, suppose Foo is a singleton which is asked by almost every
> > single call to a server.  Would this code have good performance
> > (with/without "volatile" modifier)?
>
> The correct version (with volatile) adds the overhead of a volatile read
> for every access. That may or may not be a noticeable overhead,
> depending on your use case. If you want to avoid that, there are
> alternatives, see the links posted by Christian and Aleksey.
>
> - Arno
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160301/7d77cfd6/attachment.html>

From viktor.klang at gmail.com  Tue Mar  1 05:45:31 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Tue, 1 Mar 2016 11:45:31 +0100
Subject: [concurrency-interest] Flow API tools for working with cold
	observables
In-Reply-To: <CAChcVu=_XPHg86b3-ChPDPiYE2zbnnTtPC=-xgogTWk49QK7nQ@mail.gmail.com>
References: <CAChcVumWR3_4yi5skwiejy8-XdLb85NQJ56LjD=J-D5d6MGkdw@mail.gmail.com>
	<CAAWwtm8PW1DGAtcB1xiUhgT7kCjoB4wMMs3VB4sU+GeGpm9XDw@mail.gmail.com>
	<CAChcVu=_XPHg86b3-ChPDPiYE2zbnnTtPC=-xgogTWk49QK7nQ@mail.gmail.com>
Message-ID: <CANPzfU9DAvfQEjp892vrMwCB7AY==fgq8XYd+qpQj2jxVm-ZCQ@mail.gmail.com>

Implementing a `Processor` is non-trivial, and also depends on what
semantics it is expected to have (i.e. does it support fan-out, i.e.
multiple Subscribers or not).

If/When the JDK also gets Flow integration with existing NIO APIs I'd
expect it to need to at the very least create some internal constructs to
handle your use-case.

On Wed, Feb 24, 2016 at 5:47 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> Thanks D?vid, I don't have a luxury of using 3rd party libraries. I
> wonder what would others say? Is the "coupling" I've described is
> essential enough to become a part of Flow API along with
> SubmissionPublisher or I am missing something and it could *easily* be
> assembled from already existing java.util.concurrent objects?
>
> -Pavel
>
> On Wed, Feb 24, 2016 at 11:48 AM, D?vid Karnok <akarnokd at gmail.com> wrote:
> > Popular reactive libraries have converters / ports to j.u.c.Flow already
> so
> > you have the option to work with a plethora of operators over cold
> sources:
> >
> > https://github.com/akarnokd/RxJavaUtilConcurrentFlow
> >
> https://github.com/reactor/reactor-core/blob/master/src/main/java/reactor/core/converter/FlowPublisherConverter.java
> >
> >
> >
> >
> > 2016-02-24 12:29 GMT+01:00 Pavel Rappo <pavel.rappo at gmail.com>:
> >>
> >> Hi,
> >>
> >> I wonder if there are any plans on creating some intermediary working
> >> between a
> >> publisher and a subscriber that would take care of buffering? I believe
> it
> >> might
> >> become a common need for Flow API adopters as it seems to represent a
> >> highly
> >> reusable component. As I understand, j.u.c.SubmissionPublisher is not
> >> particularly good for working with "cold" observables. It provides
> >> buffering but
> >> for a different reason and it also relies on "drop handling and/or
> >> blocking" for
> >> flow control. I don't think any of these options are particularly good
> >> when
> >> working with cold observables in a non-blocking fashion.
> >>
> >> What is needed in its essence is a some kind of "elastic coupling"
> working
> >> between 2 subscribers that effectively manages a steady flow of items
> >> prefetching them (if stock drops below some level) from the input side
> and
> >> transferring them to the output side.
> >>
> >> -Pavel
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> >
> > --
> > Best regards,
> > David Karnok
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160301/17718d43/attachment-0001.html>

From concurrency at kuli.org  Tue Mar  1 06:11:50 2016
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Tue, 1 Mar 2016 12:11:50 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <CAMjJYB=AMs7PFJ4w1uuhUMFOk6u4GsiZNNJmOhfHxgfZgRZ0yw@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
	<56D5593F.8070701@kuli.org>
	<CAMjJYB=AMs7PFJ4w1uuhUMFOk6u4GsiZNNJmOhfHxgfZgRZ0yw@mail.gmail.com>
Message-ID: <56D578F6.5040903@kuli.org>

Am 01.03.2016 um 11:38 schrieb Nader Aeinehchi:
> Thank you very much for the good response Michael.
> 
> In the original author's code, the Foo class is not immutable.  There is
> no "volatile" modifier.  Therefore, we can draw the conclusion that the
> code is not thread safe.  As such patterns often appear in code, perhaps
> it should be marked as "antipattern"?

Yes, at least I would say so.

Misunderstanding the complexity of the double checked pattern is a
common mistake. I remember that in my former company, we used that
pattern a lot; the people already knew that it was broken, but nobody
fixed it. The problem is that as long as it works, nobody will complain.
And it most often works.

BTW, it was *always* broken in versions before Java5 - even with the
volatile modifier.

And I totally agree that in most cases, the cost of object
initialization is insignificant.

Best,
Michael

From aph at redhat.com  Tue Mar  1 08:59:35 2016
From: aph at redhat.com (Andrew Haley)
Date: Tue, 1 Mar 2016 13:59:35 +0000
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <56D578F6.5040903@kuli.org>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
	<56D5593F.8070701@kuli.org>
	<CAMjJYB=AMs7PFJ4w1uuhUMFOk6u4GsiZNNJmOhfHxgfZgRZ0yw@mail.gmail.com>
	<56D578F6.5040903@kuli.org>
Message-ID: <56D5A047.4080104@redhat.com>

On 03/01/2016 11:11 AM, Michael Kuhlmann wrote:
> Am 01.03.2016 um 11:38 schrieb Nader Aeinehchi:
>> > Thank you very much for the good response Michael.
>> > 
>> > In the original author's code, the Foo class is not immutable.  There is
>> > no "volatile" modifier.  Therefore, we can draw the conclusion that the
>> > code is not thread safe.  As such patterns often appear in code, perhaps
>> > it should be marked as "antipattern"?
<
> Yes, at least I would say so.

And this antipattern has even got a name: "Broken double-checked
locking."

Andrew.


From nader at aeinehchi.com  Tue Mar  1 10:57:21 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Tue, 1 Mar 2016 16:57:21 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
In-Reply-To: <56D5A047.4080104@redhat.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<CAMjJYBmTJBr+Z2-mDUCBDFJb2oPUqX-Ay9reqDgMt2fb8VbCQQ@mail.gmail.com>
	<56D5593F.8070701@kuli.org>
	<CAMjJYB=AMs7PFJ4w1uuhUMFOk6u4GsiZNNJmOhfHxgfZgRZ0yw@mail.gmail.com>
	<56D578F6.5040903@kuli.org> <56D5A047.4080104@redhat.com>
Message-ID: <CAMjJYBnGJmL-k4k6qmb7-K8bFJYBO3vCPrpbJgY+swQxJbFztw@mail.gmail.com>

+1

On Tue, Mar 1, 2016 at 2:59 PM, Andrew Haley <aph at redhat.com> wrote:

> On 03/01/2016 11:11 AM, Michael Kuhlmann wrote:
> > Am 01.03.2016 um 11:38 schrieb Nader Aeinehchi:
> >> > Thank you very much for the good response Michael.
> >> >
> >> > In the original author's code, the Foo class is not immutable.  There
> is
> >> > no "volatile" modifier.  Therefore, we can draw the conclusion that
> the
> >> > code is not thread safe.  As such patterns often appear in code,
> perhaps
> >> > it should be marked as "antipattern"?
> <
> > Yes, at least I would say so.
>
> And this antipattern has even got a name: "Broken double-checked
> locking."
>
> Andrew.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160301/7b200a90/attachment.html>

From jeffhain at rocketmail.com  Wed Mar  2 14:50:27 2016
From: jeffhain at rocketmail.com (Jeff Hain)
Date: Wed, 2 Mar 2016 19:50:27 +0000 (UTC)
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
References: <685328936.3831652.1456948227425.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <685328936.3831652.1456948227425.JavaMail.yahoo@mail.yahoo.com>

Hi.



>When Foo is asked so often anyway, what benefit will you gain from the
>lazy initialization then? Nothing.
>
>Double checked locking is only useful when Foo itself is heavy-weight,
>or the creation cost is high, and if it's not unlikely that it will
>probably never be used. Then you can avoid that cost in some cases, and
>when it's necessary, it will be there.



In some cases the Foo instance to use is only known after some point,
so you need some laziness.

What I would do then is use the holder pattern, and throw if the instance
is not yet known at the time it's loaded.



But in my book Singletons are mostly an anti-pattern, and if possible
I would try to avoid them completely, and have nothing that is both
static and mutable, especially when dealing with concurrency.

Not giving an exhaustive list of reason why here
(if you want some you can start there:
?https://www.michaelsafyan.com/tech/design/patterns/singleton),
but just a personal example:
On some project I used a dummy instance of my app in background
for JIT warm-up, so that the "real" one would start quickly when
needed (and possibly while the dummy one was still running).
With even just one singleton that would not have been possible.



-Jeff

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160302/a2ce3ecb/attachment.html>

From jini at zeus.net.au  Wed Mar  2 18:31:02 2016
From: jini at zeus.net.au (Peter)
Date: Thu, 3 Mar 2016 09:31:02 +1000 (AEST)
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
Message-ID: <cce8c7cc1cb1c680166d9b408a6f454c@org.tizen.email>

?There's an example of unsafe publication in java.security.Permissions, on occassion this class cannot resolve UnresolvedPermission, because the field hasUnresolved on line 96 is accessed under race conditions.

This class was written as a work around:

https://github.com/pfirmstone/river-internet/blob/trunk/src/org/apache/river/api/security/ConcurrentPermissions.java

There's a number of similar bugs in the ?security infrastructure, most are masked by external synchronization.

We have our own policy provider that works around 95% of these issues by thread confining all PermissionCollection instances.

The policy provider relies on final fields for safe publication of Permission instances (after lazy initialisers are deliberately invoked).

PermissionCollection instances are created and discarded within method local scope.

CPU consumption of this policy provider is about 0.1% and is highly scalable in comparison the standard policy provider that consumes 10% cpu and limits scalability of applications.

https://github.com/pfirmstone/river-internet/blob/trunk/src/org/apache/river/api/security/ConcurrentPolicyFile.java

I can donate the policy provider and some required classes under the gpl, but cannot donate the policy file parser as it includes AL2 code written by others. ?I've signed a contributor agreement.

Regards,

Peter.


Sent from my Samsung device.
?
??Include original message
---- Original message ----
From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
Sent: 01/03/2016 06:31:24 am
To: Nader Aeinehchi <nader at aeinehchi.com>; concurrency-interest <concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?

On?02/29/2016?10:17?PM,?Nader?Aeinehchi?wrote: 
>?I?saw?this?pattern?on?an?open?source?project,?and?wonder?if?it?is?thread 
>?safe???If?so,?would?it?scale? 

See: 
?http://shipilev.net/blog/2014/safe-public-construction/ 

-Aleksey 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160303/26717609/attachment.html>

From jini at zeus.net.au  Wed Mar  2 19:14:33 2016
From: jini at zeus.net.au (Peter)
Date: Thu, 3 Mar 2016 10:14:33 +1000 (AEST)
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
Message-ID: <a8a0d77c4d074ee66d6cf44cc48aabd0@org.tizen.email>

To clarify, I'd have to separate the code I've authored, or contact the other author, in order to donate the entire works under the gpl.

Sent from my Samsung device.
?
??Include original message
---- Original message ----
From: Peter <jini at zeus.net.au>
Sent: 03/03/2016 09:31:02 am
To: AlekseyShipilev <aleksey.shipilev at oracle.com>; NaderAeinehchi <nader at aeinehchi.com>; concurrency-interest <concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?

?There's an example of unsafe publication in java.security.Permissions, on occassion this class cannot resolve UnresolvedPermission, because the field hasUnresolved on line 96 is accessed under race conditions.

This class was written as a work around:

https://github.com/pfirmstone/river-internet/blob/trunk/src/org/apache/river/api/security/ConcurrentPermissions.java

There's a number of similar bugs in the ?security infrastructure, most are masked by external synchronization.

We have our own policy provider that works around 95% of these issues by thread confining all PermissionCollection instances.

The policy provider relies on final fields for safe publication of Permission instances (after lazy initialisers are deliberately invoked).

PermissionCollection instances are created and discarded within method local scope.

CPU consumption of this policy provider is about 0.1% and is highly scalable in comparison the standard policy provider that consumes 10% cpu and limits scalability of applications.

https://github.com/pfirmstone/river-internet/blob/trunk/src/org/apache/river/api/security/ConcurrentPolicyFile.java

I can donate the policy provider and some required classes under the gpl, but cannot donate the policy file parser as it includes AL2 code written by others. ?I've signed a contributor agreement.

Regards,

Peter.


Sent from my Samsung device.
?
---- Original message ----
From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
Sent: 01/03/2016 06:31:24 am
To: Nader Aeinehchi <nader at aeinehchi.com>; concurrency-interest <concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?

On?02/29/2016?10:17?PM,?Nader?Aeinehchi?wrote: 
>?I?saw?this?pattern?on?an?open?source?project,?and?wonder?if?it?is?thread 
>?safe???If?so,?would?it?scale? 

See: 
?http://shipilev.net/blog/2014/safe-public-construction/ 

-Aleksey 





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160303/377cc801/attachment.html>

From pettermahlen at gmail.com  Thu Mar  3 07:17:41 2016
From: pettermahlen at gmail.com (=?UTF-8?B?UGV0dGVyIE3DpWhsw6lu?=)
Date: Thu, 03 Mar 2016 12:17:41 +0000
Subject: [concurrency-interest] CompletionStage.handle() with function
 returning CompletionStage
In-Reply-To: <CAEvq2no8iiyKS6RgTSFM0B01tyMr=9buETwUz2=mHT5EMU_kiw@mail.gmail.com>
References: <CAGpHYSUkVw_0aGZGMhs49Kd_xDK+zpqc4zrFQBFpFH3tJiJOow@mail.gmail.com>
	<CAEvq2no8iiyKS6RgTSFM0B01tyMr=9buETwUz2=mHT5EMU_kiw@mail.gmail.com>
Message-ID: <CAGpHYSXuofmANLCaVT1_s+Z7ANmY-cQKC8JUVTf+15XOo0So5g@mail.gmail.com>

Not much activity on this thread - I'm not sure what conclusions to draw
from that. We did find a need for these versions inhouse at Spotify, and
apparently also in Google, though unlike us, they have numbers to quantify
their need. :)

We'll keep using our static versions. If it turns out that fluent analogues
appear in some future version of CompletionStage, that would be great for
us.

On Mon, 22 Feb 2016 at 22:15 Chris Povirk <cpovirk at google.com> wrote:

> FWIW, some data from Guava:
>
> Our Futures class used to have the opposite problem: It had *only* the
> CompletionState version of exceptionally(). (In our terms, this was withFallback(...,
> FutureFallback), where FutureFallback returns a Future or throws). We
> found that ~15% of users needed that power.
>
> There's an asterisk on that "15%": While I *think* my notes mean "15% of
> users need to return a Future," they might mean something else: Because we
> were evaluating a switch to Function<Throwable, V>, we needed to consider
> what would happen to users who threw a checked exception. It's possible
> that I lumped them into the "15%" along with the users who needed to return
> a Future. I probably didn't, but I can't guarantee it. And
> CompletionStage.exceptionallCompose wouldn't be offering the ability to
> throw a checked exception.
>
> We ended up deciding to provide both
> <http://google.github.io/guava/releases/19.0/api/docs/com/google/common/util/concurrent/Futures.html#catching(com.google.common.util.concurrent.ListenableFuture,%20java.lang.Class,%20com.google.common.base.Function,%20java.util.concurrent.Executor)>.
> But it's possible that our users differ from CompletionStage's. For
> example, maybe we slant more toward application developers and less toward
> tool developers. Or maybe we just hate checked exceptions marginally less
> than other people :)
>
> (RE: handle(): We don't have anything like it.)
>
> (Ideally I would have provided this information 10 days ago or, better
> yet, during the review of CompletableFuture. Sorry. We didn't get around
> to reviewing our method until last year.)
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160303/82d46a8d/attachment-0001.html>

From Sebastian.Millies at softwareag.com  Fri Mar  4 08:02:04 2016
From: Sebastian.Millies at softwareag.com (Millies, Sebastian)
Date: Fri, 4 Mar 2016 13:02:04 +0000
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <56D4AA9C.6040900@oracle.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
Message-ID: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>

Here's a variation on the SafeLocalDCLFactory, where the synchronization has been replaced with CAS:

public class LockfreeFactory<T> {

    private AtomicReference<T> instance = new AtomicReference<>(null);

    public T getInstance(Supplier<T> s) {
        T i = instance.get();
        if (i == null) {
            i = s.get();
            if (!instance.weakCompareAndSet(null, i)) {
                i = instance.get();
            }
        }
        return i;
    }
}

Would this count as safe publication? I haven't mastered jcstress, but I'd be curious if it's faster than DCL.

-- Sebastian

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
Sent: Monday, February 29, 2016 9:31 PM
To: Nader Aeinehchi; concurrency-interest
Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?

On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
> I saw this pattern on an open source project, and wonder if it is
> thread safe?  If so, would it scale?

See:
 http://shipilev.net/blog/2014/safe-public-construction/

-Aleksey


Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt, Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com



From Sebastian.Millies at softwareag.com  Fri Mar  4 08:10:11 2016
From: Sebastian.Millies at softwareag.com (Millies, Sebastian)
Date: Fri, 4 Mar 2016 13:10:11 +0000
Subject: [concurrency-interest] FW: Is this a pattern or an anti-pattern for
 check-and-act?
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com> 
Message-ID: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>

Sorry, I think I was a bit hasty. The problem with this version it may happen that the code that actually constructs an object - s.get() - is called more than once. Laziness, however, is most useful if the object is a) perhaps not used and b) difficult to construct. So although the publication is safe, and the code will always return the same instance, in view of point b), this version does not really make sense as a singleton pattern. Right? -- Sebastian

> -----Original Message-----
> From: Millies, Sebastian
> Sent: Friday, March 04, 2016 2:02 PM
> To: concurrency-interest
> Cc: 'Aleksey Shipilev'; Nader Aeinehchi
> Subject: RE: [concurrency-interest] Is this a pattern or an anti-pattern for
> check-and-act?
>
> Here's a variation on the SafeLocalDCLFactory, where the synchronization has
> been replaced with CAS:
>
> public class LockfreeFactory<T> {
>
>     private AtomicReference<T> instance = new AtomicReference<>(null);
>
>     public T getInstance(Supplier<T> s) {
>         T i = instance.get();
>         if (i == null) {
>             i = s.get();
>             if (!instance.weakCompareAndSet(null, i)) {
>                 i = instance.get();
>             }
>         }
>         return i;
>     }
> }
>
> Would this count as safe publication? I haven't mastered jcstress, but I'd be
> curious if it's faster than DCL.
>
> -- Sebastian
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
> Sent: Monday, February 29, 2016 9:31 PM
> To: Nader Aeinehchi; concurrency-interest
> Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for
> check-and-act?
>
> On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
> > I saw this pattern on an open source project, and wonder if it is
> > thread safe?  If so, would it scale?
>
> See:
>  http://shipilev.net/blog/2014/safe-public-construction/
>
> -Aleksey


Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt, Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com



From nader at aeinehchi.com  Fri Mar  4 09:10:59 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Fri, 4 Mar 2016 15:10:59 +0100
Subject: [concurrency-interest] FW: Is this a pattern or an anti-pattern
 for check-and-act?
In-Reply-To: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
Message-ID: <CAMjJYBkbasO4iHnCky+q4u4Fs4SuRP0FcP0BSjKK9KJ4nO4qhw@mail.gmail.com>

Hi

I have just created a repository on Github to document
"common-mistakes-in-Java-concurrency".  I have thought to document the
mistake, the solution(s) and possibly the code that breaks the mistake.

What do you think?  Any contribution is highly appreciated.

Best regards
Nader

On Fri, Mar 4, 2016 at 2:10 PM, Millies, Sebastian <
Sebastian.Millies at softwareag.com> wrote:

> Sorry, I think I was a bit hasty. The problem with this version it may
> happen that the code that actually constructs an object - s.get() - is
> called more than once. Laziness, however, is most useful if the object is
> a) perhaps not used and b) difficult to construct. So although the
> publication is safe, and the code will always return the same instance, in
> view of point b), this version does not really make sense as a singleton
> pattern. Right? -- Sebastian
>
> > -----Original Message-----
> > From: Millies, Sebastian
> > Sent: Friday, March 04, 2016 2:02 PM
> > To: concurrency-interest
> > Cc: 'Aleksey Shipilev'; Nader Aeinehchi
> > Subject: RE: [concurrency-interest] Is this a pattern or an anti-pattern
> for
> > check-and-act?
> >
> > Here's a variation on the SafeLocalDCLFactory, where the synchronization
> has
> > been replaced with CAS:
> >
> > public class LockfreeFactory<T> {
> >
> >     private AtomicReference<T> instance = new AtomicReference<>(null);
> >
> >     public T getInstance(Supplier<T> s) {
> >         T i = instance.get();
> >         if (i == null) {
> >             i = s.get();
> >             if (!instance.weakCompareAndSet(null, i)) {
> >                 i = instance.get();
> >             }
> >         }
> >         return i;
> >     }
> > }
> >
> > Would this count as safe publication? I haven't mastered jcstress, but
> I'd be
> > curious if it's faster than DCL.
> >
> > -- Sebastian
> >
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> > interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
> > Sent: Monday, February 29, 2016 9:31 PM
> > To: Nader Aeinehchi; concurrency-interest
> > Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern
> for
> > check-and-act?
> >
> > On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
> > > I saw this pattern on an open source project, and wonder if it is
> > > thread safe?  If so, would it scale?
> >
> > See:
> >  http://shipilev.net/blog/2014/safe-public-construction/
> >
> > -Aleksey
>
>
> Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt,
> Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 -
> Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman),
> Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; -
> Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas
> Bereczky - http://www.softwareag.com
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160304/b936b787/attachment.html>

From aleksey.shipilev at oracle.com  Fri Mar  4 09:14:03 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 4 Mar 2016 17:14:03 +0300
Subject: [concurrency-interest] FW: Is this a pattern or an anti-pattern
 for check-and-act?
In-Reply-To: <CAMjJYBkbasO4iHnCky+q4u4Fs4SuRP0FcP0BSjKK9KJ4nO4qhw@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
	<CAMjJYBkbasO4iHnCky+q4u4Fs4SuRP0FcP0BSjKK9KJ4nO4qhw@mail.gmail.com>
Message-ID: <56D9982B.1000107@oracle.com>

On 03/04/2016 05:10 PM, Nader Aeinehchi wrote:
> I have just created a repository on Github to document
> "common-mistakes-in-Java-concurrency".  I have thought to document the
> mistake, the solution(s) and possibly the code that breaks the mistake.
> 
> What do you think?  Any contribution is highly appreciated.

Documenting "bad" cases gets much better exposure with CERT:

https://www.securecoding.cert.org/confluence/display/java/LCK10-J.+Use+a+correct+form+of+the+double-checked+locking+idiom

The maintainers there seem open to additions and corrections.

Thanks,
-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 836 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160304/725194c9/attachment.bin>

From aleksey.shipilev at oracle.com  Fri Mar  4 09:21:31 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 4 Mar 2016 17:21:31 +0300
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
Message-ID: <56D999EB.80909@oracle.com>

On 03/04/2016 04:02 PM, Millies, Sebastian wrote:
> Here's a variation on the SafeLocalDCLFactory, where the synchronization has been replaced with CAS:
> 
> public class LockfreeFactory<T> {
> 
>     private AtomicReference<T> instance = new AtomicReference<>(null);
> 
>     public T getInstance(Supplier<T> s) {
>         T i = instance.get();
>         if (i == null) {
>             i = s.get();
>             if (!instance.weakCompareAndSet(null, i)) {
>                 i = instance.get();
>             }
>         }
>         return i;
>     }
> }
> 
> Would this count as safe publication? 

No, weakCompareAndSet is not specified with release semantics, even
though current implementation does delegate to stronger CAS (upcoming
VarHandles would change that). Therefore, the successful weakCAS-ing of
new instance is broken in the same way test-and-set on a non-volatile
field is.

> I haven't mastered jcstress, but I'd be curious if it's faster than DCL.

I think you mean JMH. I would imagine this version is subtly slower,
since it stores the instance in a box -- getting dereferences in a
picture. Although it would probably be hard to produce in an isolated
testcase.

Thanks,
-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 836 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160304/f230ca83/attachment-0001.bin>

From nader at aeinehchi.com  Fri Mar  4 09:29:03 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Fri, 4 Mar 2016 15:29:03 +0100
Subject: [concurrency-interest] FW: Is this a pattern or an anti-pattern
 for check-and-act?
In-Reply-To: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
Message-ID: <CAMjJYBnCMTOHNWAHQOKxXBnoNB9F0g=BOaYdEDsOFYMSYqibHw@mail.gmail.com>

My experience with CAS algorithms is limited.  Is this solution 100%
correct?

On Fri, Mar 4, 2016 at 2:10 PM, Millies, Sebastian <
Sebastian.Millies at softwareag.com> wrote:

> Sorry, I think I was a bit hasty. The problem with this version it may
> happen that the code that actually constructs an object - s.get() - is
> called more than once. Laziness, however, is most useful if the object is
> a) perhaps not used and b) difficult to construct. So although the
> publication is safe, and the code will always return the same instance, in
> view of point b), this version does not really make sense as a singleton
> pattern. Right? -- Sebastian
>
> > -----Original Message-----
> > From: Millies, Sebastian
> > Sent: Friday, March 04, 2016 2:02 PM
> > To: concurrency-interest
> > Cc: 'Aleksey Shipilev'; Nader Aeinehchi
> > Subject: RE: [concurrency-interest] Is this a pattern or an anti-pattern
> for
> > check-and-act?
> >
> > Here's a variation on the SafeLocalDCLFactory, where the synchronization
> has
> > been replaced with CAS:
> >
> > public class LockfreeFactory<T> {
> >
> >     private AtomicReference<T> instance = new AtomicReference<>(null);
> >
> >     public T getInstance(Supplier<T> s) {
> >         T i = instance.get();
> >         if (i == null) {
> >             i = s.get();
> >             if (!instance.weakCompareAndSet(null, i)) {
> >                 i = instance.get();
> >             }
> >         }
> >         return i;
> >     }
> > }
> >
> > Would this count as safe publication? I haven't mastered jcstress, but
> I'd be
> > curious if it's faster than DCL.
> >
> > -- Sebastian
> >
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> > interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
> > Sent: Monday, February 29, 2016 9:31 PM
> > To: Nader Aeinehchi; concurrency-interest
> > Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern
> for
> > check-and-act?
> >
> > On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
> > > I saw this pattern on an open source project, and wonder if it is
> > > thread safe?  If so, would it scale?
> >
> > See:
> >  http://shipilev.net/blog/2014/safe-public-construction/
> >
> > -Aleksey
>
>
> Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt,
> Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 -
> Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman),
> Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; -
> Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas
> Bereczky - http://www.softwareag.com
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160304/05dea7d5/attachment.html>

From Sebastian.Millies at softwareag.com  Fri Mar  4 09:33:18 2016
From: Sebastian.Millies at softwareag.com (Millies, Sebastian)
Date: Fri, 4 Mar 2016 14:33:18 +0000
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <56D999EB.80909@oracle.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
	<56D999EB.80909@oracle.com>
Message-ID: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F85E@HQMBX5.eur.ad.sag>

Thanks for the correction. Somehow, I was under the impression (don't remember where I may have read that), that weakCompareAndSet does not establish happens-before relationships for any variables EXCEPT the target of weakCompareAndSet itself. -- Sebastian

-----Original Message-----
From: Aleksey Shipilev [mailto:aleksey.shipilev at oracle.com]
Sent: Friday, March 04, 2016 3:22 PM
To: Millies, Sebastian; concurrency-interest
Cc: Nader Aeinehchi
Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?

* PGP Signed by an unknown key

On 03/04/2016 04:02 PM, Millies, Sebastian wrote:
> Here's a variation on the SafeLocalDCLFactory, where the synchronization has been replaced with CAS:
>
> public class LockfreeFactory<T> {
>
>     private AtomicReference<T> instance = new AtomicReference<>(null);
>
>     public T getInstance(Supplier<T> s) {
>         T i = instance.get();
>         if (i == null) {
>             i = s.get();
>             if (!instance.weakCompareAndSet(null, i)) {
>                 i = instance.get();
>             }
>         }
>         return i;
>     }
> }
>
> Would this count as safe publication?

No, weakCompareAndSet is not specified with release semantics, even though current implementation does delegate to stronger CAS (upcoming VarHandles would change that). Therefore, the successful weakCAS-ing of new instance is broken in the same way test-and-set on a non-volatile field is.

> I haven't mastered jcstress, but I'd be curious if it's faster than DCL.

I think you mean JMH. I would imagine this version is subtly slower, since it stores the instance in a box -- getting dereferences in a picture. Although it would probably be hard to produce in an isolated testcase.

Thanks,
-Aleksey


* Unknown Key
* 0x62A119A7

Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt, Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com



From nader at aeinehchi.com  Fri Mar  4 09:39:52 2016
From: nader at aeinehchi.com (Nader Aeinehchi)
Date: Fri, 4 Mar 2016 15:39:52 +0100
Subject: [concurrency-interest] FW: Is this a pattern or an anti-pattern
 for check-and-act?
In-Reply-To: <CAMjJYBnCMTOHNWAHQOKxXBnoNB9F0g=BOaYdEDsOFYMSYqibHw@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
	<CAMjJYBnCMTOHNWAHQOKxXBnoNB9F0g=BOaYdEDsOFYMSYqibHw@mail.gmail.com>
Message-ID: <CAMjJYBnWjyPKyzSeTCup0HGyUxRY8TKN7BUdEt9a9i=mbjNTzQ@mail.gmail.com>

The link to the repository for Common Mistakes in Java Concurrency:

https://github.com/nader-aeinehchi/java-concurrency-mistakes

On Fri, Mar 4, 2016 at 3:29 PM, Nader Aeinehchi <nader at aeinehchi.com> wrote:

> My experience with CAS algorithms is limited.  Is this solution 100%
> correct?
>
> On Fri, Mar 4, 2016 at 2:10 PM, Millies, Sebastian <
> Sebastian.Millies at softwareag.com> wrote:
>
>> Sorry, I think I was a bit hasty. The problem with this version it may
>> happen that the code that actually constructs an object - s.get() - is
>> called more than once. Laziness, however, is most useful if the object is
>> a) perhaps not used and b) difficult to construct. So although the
>> publication is safe, and the code will always return the same instance, in
>> view of point b), this version does not really make sense as a singleton
>> pattern. Right? -- Sebastian
>>
>> > -----Original Message-----
>> > From: Millies, Sebastian
>> > Sent: Friday, March 04, 2016 2:02 PM
>> > To: concurrency-interest
>> > Cc: 'Aleksey Shipilev'; Nader Aeinehchi
>> > Subject: RE: [concurrency-interest] Is this a pattern or an
>> anti-pattern for
>> > check-and-act?
>> >
>> > Here's a variation on the SafeLocalDCLFactory, where the
>> synchronization has
>> > been replaced with CAS:
>> >
>> > public class LockfreeFactory<T> {
>> >
>> >     private AtomicReference<T> instance = new AtomicReference<>(null);
>> >
>> >     public T getInstance(Supplier<T> s) {
>> >         T i = instance.get();
>> >         if (i == null) {
>> >             i = s.get();
>> >             if (!instance.weakCompareAndSet(null, i)) {
>> >                 i = instance.get();
>> >             }
>> >         }
>> >         return i;
>> >     }
>> > }
>> >
>> > Would this count as safe publication? I haven't mastered jcstress, but
>> I'd be
>> > curious if it's faster than DCL.
>> >
>> > -- Sebastian
>> >
>> > -----Original Message-----
>> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
>> > interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>> > Sent: Monday, February 29, 2016 9:31 PM
>> > To: Nader Aeinehchi; concurrency-interest
>> > Subject: Re: [concurrency-interest] Is this a pattern or an
>> anti-pattern for
>> > check-and-act?
>> >
>> > On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
>> > > I saw this pattern on an open source project, and wonder if it is
>> > > thread safe?  If so, would it scale?
>> >
>> > See:
>> >  http://shipilev.net/blog/2014/safe-public-construction/
>> >
>> > -Aleksey
>>
>>
>> Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt,
>> Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 -
>> Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman),
>> Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; -
>> Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas
>> Bereczky - http://www.softwareag.com
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160304/1ab7a3d1/attachment.html>

From arno.haase at haase-consulting.com  Fri Mar  4 10:23:45 2016
From: arno.haase at haase-consulting.com (Arno Haase)
Date: Fri, 4 Mar 2016 16:23:45 +0100
Subject: [concurrency-interest] FW: Is this a pattern or an anti-pattern
 for check-and-act?
In-Reply-To: <CAMjJYBnCMTOHNWAHQOKxXBnoNB9F0g=BOaYdEDsOFYMSYqibHw@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F814@HQMBX5.eur.ad.sag>
	<CAMjJYBnCMTOHNWAHQOKxXBnoNB9F0g=BOaYdEDsOFYMSYqibHw@mail.gmail.com>
Message-ID: <56D9A881.6070502@haase-consulting.com>

* This code has a race that can cause several instances to be created,
since the call to s.get() is not guarded by a lock.

* As Aleksey pointed out, weakCompareAndSet does not guarantee publication.

But most importantly, this code incurs a volatile read for every read
access, which is where performance counts. So it is not faster for reads
than regular DCL.

Optimizing the code branch that creates a new instance looks irrelevant
to me.

- Arno


Am 04.03.2016 um 15:29 schrieb Nader Aeinehchi:
> My experience with CAS algorithms is limited.  Is this solution 100%
> correct?
> 
> On Fri, Mar 4, 2016 at 2:10 PM, Millies, Sebastian
> <Sebastian.Millies at softwareag.com
> <mailto:Sebastian.Millies at softwareag.com>> wrote:
> 
>     Sorry, I think I was a bit hasty. The problem with this version it
>     may happen that the code that actually constructs an object -
>     s.get() - is called more than once. Laziness, however, is most
>     useful if the object is a) perhaps not used and b) difficult to
>     construct. So although the publication is safe, and the code will
>     always return the same instance, in view of point b), this version
>     does not really make sense as a singleton pattern. Right? -- Sebastian
> 
>     > -----Original Message-----
>     > From: Millies, Sebastian
>     > Sent: Friday, March 04, 2016 2:02 PM
>     > To: concurrency-interest
>     > Cc: 'Aleksey Shipilev'; Nader Aeinehchi
>     > Subject: RE: [concurrency-interest] Is this a pattern or an anti-pattern for
>     > check-and-act?
>     >
>     > Here's a variation on the SafeLocalDCLFactory, where the synchronization has
>     > been replaced with CAS:
>     >
>     > public class LockfreeFactory<T> {
>     >
>     >     private AtomicReference<T> instance = new AtomicReference<>(null);
>     >
>     >     public T getInstance(Supplier<T> s) {
>     >         T i = instance.get();
>     >         if (i == null) {
>     >             i = s.get();
>     >             if (!instance.weakCompareAndSet(null, i)) {
>     >                 i = instance.get();
>     >             }
>     >         }
>     >         return i;
>     >     }
>     > }
>     >
>     > Would this count as safe publication? I haven't mastered jcstress, but I'd be
>     > curious if it's faster than DCL.
>     >
>     > -- Sebastian
>     >
>     > -----Original Message-----
>     > From: concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     [mailto:concurrency- <mailto:concurrency->
>     > interest-bounces at cs.oswego.edu
>     <mailto:interest-bounces at cs.oswego.edu>] On Behalf Of Aleksey Shipilev
>     > Sent: Monday, February 29, 2016 9:31 PM
>     > To: Nader Aeinehchi; concurrency-interest
>     > Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for
>     > check-and-act?
>     >
>     > On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
>     > > I saw this pattern on an open source project, and wonder if it is
>     > > thread safe?  If so, would it scale?
>     >
>     > See:
>     >  http://shipilev.net/blog/2014/safe-public-construction/
>     >
>     > -Aleksey
> 
> 
>     Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297
>     Darmstadt, Germany ? Registergericht/Commercial register: Darmstadt
>     HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich
>     (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd
>     Zinnhardt; - Aufsichtsratsvorsitzender/Chairman of the Supervisory
>     Board: Dr. Andreas Bereczky - http://www.softwareag.com
> 
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From aaron.grunthal at infinite-source.de  Fri Mar  4 10:26:41 2016
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Fri, 4 Mar 2016 16:26:41 +0100
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
 check-and-act?
In-Reply-To: <32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
Message-ID: <56D9A931.3090806@infinite-source.de>

CAS in the slow path gains you practically nothing since it will only
happen a few times at most. what's important is that the fast path is
cheap and yet safe. A volatile read usually is cheap enough, in the few
cases where it's not you start with the final holders or similar
optimizations.

I think yet another alternative not covered by Aleksey's blog post would
be method handle and switchpoint invalidation trickery that could get
you similar results by exploiting the memory ordering around safepoints.

- Aaron

On 04.03.2016 14:02, Millies, Sebastian wrote:
> Here's a variation on the SafeLocalDCLFactory, where the synchronization has been replaced with CAS:
> 
> public class LockfreeFactory<T> {
> 
>     private AtomicReference<T> instance = new AtomicReference<>(null);
> 
>     public T getInstance(Supplier<T> s) {
>         T i = instance.get();
>         if (i == null) {
>             i = s.get();
>             if (!instance.weakCompareAndSet(null, i)) {
>                 i = instance.get();
>             }
>         }
>         return i;
>     }
> }
> 
> Would this count as safe publication? I haven't mastered jcstress, but I'd be curious if it's faster than DCL.
> 
> -- Sebastian
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
> Sent: Monday, February 29, 2016 9:31 PM
> To: Nader Aeinehchi; concurrency-interest
> Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern for check-and-act?
> 
> On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
>> I saw this pattern on an open source project, and wonder if it is
>> thread safe?  If so, would it scale?
> 
> See:
>  http://shipilev.net/blog/2014/safe-public-construction/
> 
> -Aleksey
> 
> 
> Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt, Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From vitalyd at gmail.com  Fri Mar  4 11:06:34 2016
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 4 Mar 2016 11:06:34 -0500
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
In-Reply-To: <56D9A931.3090806@infinite-source.de>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
	<56D9A931.3090806@infinite-source.de>
Message-ID: <CAHjP37Fsav_GrXZ68=TgXmpLdkGmNS-cRo34eRgs6bdWaoc66g@mail.gmail.com>

On Friday, March 4, 2016, Aaron Grunthal <aaron.grunthal at infinite-source.de>
wrote:

> CAS in the slow path gains you practically nothing since it will only
> happen a few times at most. what's important is that the fast path is
> cheap and yet safe. A volatile read usually is cheap enough, in the few
> cases where it's not you start with the final holders or similar
> optimizations.

I would actually start with final holders because you get the added benefit
of the static final instance in the holder being a JIT constant; if you
then add TrustNonStaticFinalFields you can get some additional constant
folding.

>
> I think yet another alternative not covered by Aleksey's blog post would
> be method handle and switchpoint invalidation trickery that could get
> you similar results by exploiting the memory ordering around safepoints.
>
> - Aaron
>
> On 04.03.2016 14:02, Millies, Sebastian wrote:
> > Here's a variation on the SafeLocalDCLFactory, where the synchronization
> has been replaced with CAS:
> >
> > public class LockfreeFactory<T> {
> >
> >     private AtomicReference<T> instance = new AtomicReference<>(null);
> >
> >     public T getInstance(Supplier<T> s) {
> >         T i = instance.get();
> >         if (i == null) {
> >             i = s.get();
> >             if (!instance.weakCompareAndSet(null, i)) {
> >                 i = instance.get();
> >             }
> >         }
> >         return i;
> >     }
> > }
> >
> > Would this count as safe publication? I haven't mastered jcstress, but
> I'd be curious if it's faster than DCL.
> >
> > -- Sebastian
> >
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu <javascript:;> [mailto:
> concurrency-interest-bounces at cs.oswego.edu <javascript:;>] On Behalf Of
> Aleksey Shipilev
> > Sent: Monday, February 29, 2016 9:31 PM
> > To: Nader Aeinehchi; concurrency-interest
> > Subject: Re: [concurrency-interest] Is this a pattern or an anti-pattern
> for check-and-act?
> >
> > On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
> >> I saw this pattern on an open source project, and wonder if it is
> >> thread safe?  If so, would it scale?
> >
> > See:
> >  http://shipilev.net/blog/2014/safe-public-construction/
> >
> > -Aleksey
> >
> >
> > Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt,
> Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 -
> Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman),
> Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; -
> Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas
> Bereczky - http://www.softwareag.com
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <javascript:;>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <javascript:;>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Sent from my phone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160304/f604e17c/attachment.html>

From alarmnummer at gmail.com  Tue Mar  8 04:20:52 2016
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 8 Mar 2016 11:20:52 +0200
Subject: [concurrency-interest] Question regarding usage of
	LockSupprt.park/unpark in custom queue implementation
Message-ID: <CAGuAWdC3=CcGhEyVDWD_ba9fKtC4srju0MZNjxe6yui4HrYFTQ@mail.gmail.com>

Hi,

I have a question regarding a multi producer single consumer queue
implementation. The queue works on the principle of 2 stacks; when threads
put an item it is put in a stack (single linked list nodes) so the items
are in reverse. When an item is taken, the whole stack can be removed using
a simple cas and in reverse order the items are put in an array. So the
original order is being restored.

I know this MPSC-queue isn't the most efficient one and also it generates
litter. The main question is regarding the correctness of the park/unpark.
For example can it happen that the consumer isn't unparked.

I have had a long look at this code and I had a few more experienced guys
looks at this code as well. Till so far we could not shoot a hole in the
approach, but the underbelly feeling is still there. Could someone have a
look at it and tell if this queue is broken or not?


public final class MPSCQueue<E> extends AbstractQueue<E> implements
BlockingQueue<E> {
    private static final Node BLOCKED = new Node();
    private static final int INITIAL_ARRAY_SIZE = 512;

    private final AtomicReference<Node> putStackHead = new
AtomicReference<Node>();

    private final Thread owningThread;

    // will only be used by the owningThread.
    private Object[] array;
    private int arrayIndex = -1;

    public MPSCQueue(Thread owningThread) {
        this.owningThread = owningThread;
        this.array = new Object[INITIAL_ARRAY_SIZE];
    }

    @Override
    public void clear() {
        putStackHead.set(null);
    }

    @Override
    public boolean offer(E value) {
        if (value == null) {
            throw new IllegalArgumentException("value can't be null");
        }

        AtomicReference<Node> head = putStackHead;
        Node newHead = new Node();
        newHead.value = value;

        for (; ; ) {
            Node oldHead = head.get();
            if (oldHead == null || oldHead == BLOCKED) {
                newHead.next = null;
                newHead.size = 1;
            } else {
                newHead.next = oldHead;
                newHead.size = oldHead.size + 1;
            }

            if (!head.compareAndSet(oldHead, newHead)) {
                continue;
            }

            if (oldHead == BLOCKED) {
                unpark(owningThread);
            }

            return true;
        }
    }

    @Override
    public E take() throws InterruptedException {
        E item = next();
        if (item != null) {
            return item;
        }

        takeAll();
        assert arrayIndex == 0;
        assert array[arrayIndex] != null;

        return next();
    }

    @Override
    public E poll() {
        E item = next();

        if (item != null) {
            return item;
        }

        if (!pollAll()) {
            return null;
        }

        return next();
    }

    private E next() {
        if (arrayIndex == -1) {
            return null;
        }

        if (arrayIndex == array.length) {
            arrayIndex = -1;
            return null;
        }

        E item = (E) array[arrayIndex];
        if (item == null) {
            arrayIndex = -1;
            return null;
        }
        array[arrayIndex] = null;
        arrayIndex++;
        return item;
    }

    public void takeAll() throws InterruptedException {
        long iteration = 0;
        AtomicReference<Node> head = putStackHead;
        for (; ; ) {
            if (owningThread.isInterrupted()) {
                head.compareAndSet(BLOCKED, null);
                throw new InterruptedException();
            }

            Node currentHead = head.get();

            if (currentHead == null) {

                // there is nothing to be take, so lets block.
                if (!head.compareAndSet(null, BLOCKED)) {
                    continue;
                }

                park();
            } else if (currentHead == BLOCKED) {
                park();
            } else {
                if (!head.compareAndSet(currentHead, null)) {
                    continue;
                }

                initArray(currentHead);
                break;
            }
            iteration++;
        }
    }

    public boolean pollAll() {
        AtomicReference<Node> head = putStackHead;
        for (; ; ) {
            Node headNode = head.get();
            if (headNode == null) {
                return false;
            }

            if (head.compareAndSet(headNode, null)) {
                initArray(headNode);
                return true;
            }
        }
    }

    private void initArray(Node head) {
        int size = head.size;

        assert head != BLOCKED;
        assert size != 0;

        Object[] drain = this.array;
        if (size > drain.length) {
            drain = new Object[head.size * 2];
            this.array = drain;
        }

        for (int i = size - 1; i >= 0; i--) {
            drain[i] = head.value;
            head = head.next;
        }

        for (int k = 0; k < array.length; k++) {
            if (array[k] == null) {
                break;
            }
        }

        arrayIndex = 0;
        assert array[0] != null;
    }

    @Override
    public int size() {
        //todo: size can't be relied upon because this items which
have been copied into the array, are not visible apart
        //to the owning thread.
        Node h = putStackHead.get();
        return h == null ? 0 : h.size;
    }

    @Override
    public boolean isEmpty() {
        return size() == 0;
        //  throw new UnsupportedOperationException();
    }

    @Override
    public void put(E e) throws InterruptedException {
        offer(e);
    }

    @Override
    public boolean offer(E e, long timeout, TimeUnit unit) throws
InterruptedException {
        throw new UnsupportedOperationException();
    }

    @Override
    public E poll(long timeout, TimeUnit unit) throws InterruptedException {
        throw new UnsupportedOperationException();
    }

    @Override
    public int remainingCapacity() {
        throw new UnsupportedOperationException();
    }

    @Override
    public int drainTo(Collection<? super E> c) {
        throw new UnsupportedOperationException();
    }

    @Override
    public int drainTo(Collection<? super E> c, int maxElements) {
        throw new UnsupportedOperationException();
    }

    @Override
    public Iterator<E> iterator() {
        throw new UnsupportedOperationException();
    }

    @Override
    public E peek() {
        throw new UnsupportedOperationException();
    }

    private static final class Node<E> {
        Node next;
        E value;
        int size;
    }
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160308/2937a1e5/attachment-0001.html>

From niranjan.nanda at gmail.com  Tue Mar  8 10:12:39 2016
From: niranjan.nanda at gmail.com (Niranjan Nanda)
Date: Tue, 8 Mar 2016 20:42:39 +0530
Subject: [concurrency-interest] Is this a pattern or an anti-pattern for
	check-and-act?
In-Reply-To: <CAHjP37Fsav_GrXZ68=TgXmpLdkGmNS-cRo34eRgs6bdWaoc66g@mail.gmail.com>
References: <CAMjJYBmW+VzbOqa86uCgEudMAJAhXkS194Xq-GcQEUyP5h41_g@mail.gmail.com>
	<56D4AA9C.6040900@oracle.com>
	<32F15738E8E5524DA4F01A0FA4A8E4900102E3F7F8@HQMBX5.eur.ad.sag>
	<56D9A931.3090806@infinite-source.de>
	<CAHjP37Fsav_GrXZ68=TgXmpLdkGmNS-cRo34eRgs6bdWaoc66g@mail.gmail.com>
Message-ID: <CALHGB=m844RFrTBFPWcCPmgsYt+zpgV_OqshptD1JmLzRaFfZA@mail.gmail.com>

Hello Nader,

I checked the GitHub repo you created for concurrency
https://github.com/nader-aeinehchi/java-concurrency-mistakes. It is
definitely helpful. I think it will be more helpful if you can add some
documentation saying why something is wrong.

Thank you.

Warm Regards,
Niranjan

Warm Regards,
Niranjan

On Fri, Mar 4, 2016 at 9:36 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

>
>
> On Friday, March 4, 2016, Aaron Grunthal <
> aaron.grunthal at infinite-source.de> wrote:
>
>> CAS in the slow path gains you practically nothing since it will only
>> happen a few times at most. what's important is that the fast path is
>> cheap and yet safe. A volatile read usually is cheap enough, in the few
>> cases where it's not you start with the final holders or similar
>> optimizations.
>
> I would actually start with final holders because you get the added
> benefit of the static final instance in the holder being a JIT constant; if
> you then add TrustNonStaticFinalFields you can get some additional constant
> folding.
>
>>
>> I think yet another alternative not covered by Aleksey's blog post would
>> be method handle and switchpoint invalidation trickery that could get
>> you similar results by exploiting the memory ordering around safepoints.
>>
>> - Aaron
>>
>> On 04.03.2016 14:02, Millies, Sebastian wrote:
>> > Here's a variation on the SafeLocalDCLFactory, where the
>> synchronization has been replaced with CAS:
>> >
>> > public class LockfreeFactory<T> {
>> >
>> >     private AtomicReference<T> instance = new AtomicReference<>(null);
>> >
>> >     public T getInstance(Supplier<T> s) {
>> >         T i = instance.get();
>> >         if (i == null) {
>> >             i = s.get();
>> >             if (!instance.weakCompareAndSet(null, i)) {
>> >                 i = instance.get();
>> >             }
>> >         }
>> >         return i;
>> >     }
>> > }
>> >
>> > Would this count as safe publication? I haven't mastered jcstress, but
>> I'd be curious if it's faster than DCL.
>> >
>> > -- Sebastian
>> >
>> > -----Original Message-----
>> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>> > Sent: Monday, February 29, 2016 9:31 PM
>> > To: Nader Aeinehchi; concurrency-interest
>> > Subject: Re: [concurrency-interest] Is this a pattern or an
>> anti-pattern for check-and-act?
>> >
>> > On 02/29/2016 10:17 PM, Nader Aeinehchi wrote:
>> >> I saw this pattern on an open source project, and wonder if it is
>> >> thread safe?  If so, would it scale?
>> >
>> > See:
>> >  http://shipilev.net/blog/2014/safe-public-construction/
>> >
>> > -Aleksey
>> >
>> >
>> > Software AG ? Sitz/Registered office: Uhlandstra?e 12, 64297 Darmstadt,
>> Germany ? Registergericht/Commercial register: Darmstadt HRB 1562 -
>> Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman),
>> Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt; -
>> Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas
>> Bereczky - http://www.softwareag.com
>> >
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> --
> Sent from my phone
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160308/95304ebe/attachment.html>

From martinrb at google.com  Tue Mar  8 12:17:27 2016
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 8 Mar 2016 09:17:27 -0800
Subject: [concurrency-interest] Question regarding usage of
 LockSupprt.park/unpark in custom queue implementation
In-Reply-To: <CAGuAWdC3=CcGhEyVDWD_ba9fKtC4srju0MZNjxe6yui4HrYFTQ@mail.gmail.com>
References: <CAGuAWdC3=CcGhEyVDWD_ba9fKtC4srju0MZNjxe6yui4HrYFTQ@mail.gmail.com>
Message-ID: <CA+kOe08gwcCsm9k-3px2e0mutPauMDryYBkV4ybSCeDZp5t9Lg@mail.gmail.com>

We now put this into every class that uses park/unpark

        // Reduce the risk of rare disastrous classloading in first call to
        // LockSupport.park: https://bugs.openjdk.java.net/browse/JDK-8074773
        Class<?> ensureLoaded = LockSupport.class;

From gbloisi at gmail.com  Tue Mar  8 14:26:23 2016
From: gbloisi at gmail.com (Giambattista Bloisi)
Date: Tue, 8 Mar 2016 20:26:23 +0100
Subject: [concurrency-interest] Question regarding usage of
 LockSupprt.park/unpark in custom queue implementation
In-Reply-To: <CAGuAWdC3=CcGhEyVDWD_ba9fKtC4srju0MZNjxe6yui4HrYFTQ@mail.gmail.com>
References: <CAGuAWdC3=CcGhEyVDWD_ba9fKtC4srju0MZNjxe6yui4HrYFTQ@mail.gmail.com>
Message-ID: <CAKO_+HywoLZ+P5A3jxn-_8zmcHrEDNXSY=NsC9Jkp=01HXzZLA@mail.gmail.com>

Hi,
     the only problem I can spot so far is that an offer after a clear
could not wake up a parked consumer. So in the clear method it would be
better to put BLOCKED reference in head field rather than null.

Regards,
Il 08/mar/2016 10:45 AM, "Peter Veentjer" <alarmnummer at gmail.com> ha
scritto:

> Hi,
>
> I have a question regarding a multi producer single consumer queue
> implementation. The queue works on the principle of 2 stacks; when threads
> put an item it is put in a stack (single linked list nodes) so the items
> are in reverse. When an item is taken, the whole stack can be removed using
> a simple cas and in reverse order the items are put in an array. So the
> original order is being restored.
>
> I know this MPSC-queue isn't the most efficient one and also it generates
> litter. The main question is regarding the correctness of the park/unpark.
> For example can it happen that the consumer isn't unparked.
>
> I have had a long look at this code and I had a few more experienced guys
> looks at this code as well. Till so far we could not shoot a hole in the
> approach, but the underbelly feeling is still there. Could someone have a
> look at it and tell if this queue is broken or not?
>
>
> public final class MPSCQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {
>     private static final Node BLOCKED = new Node();
>     private static final int INITIAL_ARRAY_SIZE = 512;
>
>     private final AtomicReference<Node> putStackHead = new AtomicReference<Node>();
>
>     private final Thread owningThread;
>
>     // will only be used by the owningThread.
>     private Object[] array;
>     private int arrayIndex = -1;
>
>     public MPSCQueue(Thread owningThread) {
>         this.owningThread = owningThread;
>         this.array = new Object[INITIAL_ARRAY_SIZE];
>     }
>
>     @Override
>     public void clear() {
>         putStackHead.set(null);
>     }
>
>     @Override
>     public boolean offer(E value) {
>         if (value == null) {
>             throw new IllegalArgumentException("value can't be null");
>         }
>
>         AtomicReference<Node> head = putStackHead;
>         Node newHead = new Node();
>         newHead.value = value;
>
>         for (; ; ) {
>             Node oldHead = head.get();
>             if (oldHead == null || oldHead == BLOCKED) {
>                 newHead.next = null;
>                 newHead.size = 1;
>             } else {
>                 newHead.next = oldHead;
>                 newHead.size = oldHead.size + 1;
>             }
>
>             if (!head.compareAndSet(oldHead, newHead)) {
>                 continue;
>             }
>
>             if (oldHead == BLOCKED) {
>                 unpark(owningThread);
>             }
>
>             return true;
>         }
>     }
>
>     @Override
>     public E take() throws InterruptedException {
>         E item = next();
>         if (item != null) {
>             return item;
>         }
>
>         takeAll();
>         assert arrayIndex == 0;
>         assert array[arrayIndex] != null;
>
>         return next();
>     }
>
>     @Override
>     public E poll() {
>         E item = next();
>
>         if (item != null) {
>             return item;
>         }
>
>         if (!pollAll()) {
>             return null;
>         }
>
>         return next();
>     }
>
>     private E next() {
>         if (arrayIndex == -1) {
>             return null;
>         }
>
>         if (arrayIndex == array.length) {
>             arrayIndex = -1;
>             return null;
>         }
>
>         E item = (E) array[arrayIndex];
>         if (item == null) {
>             arrayIndex = -1;
>             return null;
>         }
>         array[arrayIndex] = null;
>         arrayIndex++;
>         return item;
>     }
>
>     public void takeAll() throws InterruptedException {
>         long iteration = 0;
>         AtomicReference<Node> head = putStackHead;
>         for (; ; ) {
>             if (owningThread.isInterrupted()) {
>                 head.compareAndSet(BLOCKED, null);
>                 throw new InterruptedException();
>             }
>
>             Node currentHead = head.get();
>
>             if (currentHead == null) {
>
>                 // there is nothing to be take, so lets block.
>                 if (!head.compareAndSet(null, BLOCKED)) {
>                     continue;
>                 }
>
>                 park();
>             } else if (currentHead == BLOCKED) {
>                 park();
>             } else {
>                 if (!head.compareAndSet(currentHead, null)) {
>                     continue;
>                 }
>
>                 initArray(currentHead);
>                 break;
>             }
>             iteration++;
>         }
>     }
>
>     public boolean pollAll() {
>         AtomicReference<Node> head = putStackHead;
>         for (; ; ) {
>             Node headNode = head.get();
>             if (headNode == null) {
>                 return false;
>             }
>
>             if (head.compareAndSet(headNode, null)) {
>                 initArray(headNode);
>                 return true;
>             }
>         }
>     }
>
>     private void initArray(Node head) {
>         int size = head.size;
>
>         assert head != BLOCKED;
>         assert size != 0;
>
>         Object[] drain = this.array;
>         if (size > drain.length) {
>             drain = new Object[head.size * 2];
>             this.array = drain;
>         }
>
>         for (int i = size - 1; i >= 0; i--) {
>             drain[i] = head.value;
>             head = head.next;
>         }
>
>         for (int k = 0; k < array.length; k++) {
>             if (array[k] == null) {
>                 break;
>             }
>         }
>
>         arrayIndex = 0;
>         assert array[0] != null;
>     }
>
>     @Override
>     public int size() {
>         //todo: size can't be relied upon because this items which have been copied into the array, are not visible apart
>         //to the owning thread.
>         Node h = putStackHead.get();
>         return h == null ? 0 : h.size;
>     }
>
>     @Override
>     public boolean isEmpty() {
>         return size() == 0;
>         //  throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public void put(E e) throws InterruptedException {
>         offer(e);
>     }
>
>     @Override
>     public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException {
>         throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public E poll(long timeout, TimeUnit unit) throws InterruptedException {
>         throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public int remainingCapacity() {
>         throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public int drainTo(Collection<? super E> c) {
>         throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public int drainTo(Collection<? super E> c, int maxElements) {
>         throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public Iterator<E> iterator() {
>         throw new UnsupportedOperationException();
>     }
>
>     @Override
>     public E peek() {
>         throw new UnsupportedOperationException();
>     }
>
>     private static final class Node<E> {
>         Node next;
>         E value;
>         int size;
>     }
> }
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160308/b60f3c97/attachment-0001.html>

From dl at cs.oswego.edu  Mon Mar 14 09:56:00 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 14 Mar 2016 09:56:00 -0400
Subject: [concurrency-interest] Customized ForkJoinPool constructor
Message-ID: <56E6C2F0.1020600@cs.oswego.edu>


As usage contexts of ForkJoinPool increase, it's becoming harder to
ensure that internal settings and policies are equally good across all
of them. The defaults generally work well (especially for the common pool),
but it's a bad omen that advanced users are resorting to clever and
weird hacks; even including using Unsafe or reflection to modify internals.
(For a disconcertingly cool example, see the APGAS framework at
https://github.com/x10-lang/x10/tree/master/apgas)

The only model for pool customization in j.u.c is ThreadPoolExecutor.
The proposed new ForkJoinPool constructor accepts parameters that are
mostly identical to TPE. (It took a fair amount of internal rework to
enable this.) Unlike TPE, these settings cannot be changed dynamically.

Comments would be welcome. The javadoc is pasted below, and at
http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/ForkJoinPool.html

Experience reports would be even more welcome.
You can run on either jdk8 or early-access jdk9 by getting jar
(http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar)
or building (see http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)
Warning: soon we will need to split jdk8 and jdk9 repos to cope with jigsaw etc.

... pasting ...


         public ForkJoinPool(int parallelism,
                             ForkJoinPool.ForkJoinWorkerThreadFactory factory,
                             Thread.UncaughtExceptionHandler handler,
                             boolean asyncMode,
                             int corePoolSize,
                             int maximumPoolSize,
                             int minimumRunnable,
                             boolean rejectOnSaturation,
                             long keepAliveTime,
                             TimeUnit unit)

         Creates a ForkJoinPool with the given parameters.

         Parameters:
             parallelism - the parallelism level. For default value, use 
Runtime.availableProcessors().
             factory - the factory for creating new threads. For default value, 
use defaultForkJoinWorkerThreadFactory.
             handler - the handler for internal worker threads that terminate 
due to unrecoverable errors encountered while executing tasks. For default 
value, use null.
             asyncMode - if true, establishes local first-in-first-out 
scheduling mode for forked tasks that are never joined. This mode may be more 
appropriate than default locally stack-based mode in applications in which 
worker threads only process event-style asynchronous tasks. For default value, 
use false.
             corePoolSize - the number of threads to keep in the pool (unless 
timed out after an elapsed keep-alive). Normally (and by default) this is the 
same value as the parallelism level, but may be set to a larger value to reduce 
dynamic overhead if tasks regularly block. Using a smaller value (for example 0) 
has the same effect as the default.
             maximumPoolSize - the maximum number of threads allowed. When the 
maximum is reached, attempts to replace blocked threads fail. (However, because 
creation and termination of different threads may overlap, and may be managed by 
the given thread factory, this value may be transiently exceeded.) The default 
for the common pool is 256 plus the parallelism level. Using a value (for 
example Integer.MAX_VALUE) larger than the implementation's total thread limit 
has the same effect as using this limit.
             minimumRunnable - the minimum allowed number of core threads not 
blocked by a join or ForkJoinPool.ManagedBlocker. To ensure progress, when too 
few unblocked threads exist and unexecuted tasks may exist, new threads are 
constructed, up to the given maximumPoolSize. For the default value, use 1, that 
ensures liveness. A larger value might improve throughput in the presence of 
blocked activities, but might not, due to increased overhead. A value of zero 
may be acceptable when submitted tasks cannot have dependencies requiring 
additional threads.
             rejectOnSaturation - if true, attempts to create more than the 
maximum total allowed threads throw RejectedExecutionException. Otherwise, the 
pool continues to operate, but with fewer than the target number of runnable 
threads, so might not ensure progress. For default value, use true.
             keepAliveTime - the elapsed time since last use before a thread is 
terminated (and then later replaced if needed). For the default value, use 60, 
TimeUnit.SECONDS.
             unit - the time unit for the keepAliveTime argument
         Throws:
             IllegalArgumentException - if parallelism is less than or equal to 
zero, or is greater than implementation limit, or if maximumPoolSize is less 
than parallelism, of if the keepAliveTime is less than or equal to zero.
             NullPointerException - if the factory is null
             SecurityException - if a security manager exists and the caller is 
not permitted to modify threads because it does not hold 
RuntimePermission("modifyThread")

From roger.riggs at oracle.com  Mon Mar 14 10:48:30 2016
From: roger.riggs at oracle.com (Roger Riggs)
Date: Mon, 14 Mar 2016 10:48:30 -0400
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E6C2F0.1020600@cs.oswego.edu>
References: <56E6C2F0.1020600@cs.oswego.edu>
Message-ID: <56E6CF3E.4000206@oracle.com>

Hi Doug,

Is there any chance I can nudge/encourage you to switch the two 
arguments for keepAliveTime
to a single argument using java.time.Duration?  Though it was not 
introduced until JDK 8 it
is a much nicer packaging of a duration.

Roger


On 3/14/16 9:56 AM, Doug Lea wrote:
>
> As usage contexts of ForkJoinPool increase, it's becoming harder to
> ensure that internal settings and policies are equally good across all
> of them. The defaults generally work well (especially for the common 
> pool),
> but it's a bad omen that advanced users are resorting to clever and
> weird hacks; even including using Unsafe or reflection to modify 
> internals.
> (For a disconcertingly cool example, see the APGAS framework at
> https://github.com/x10-lang/x10/tree/master/apgas)
>
> The only model for pool customization in j.u.c is ThreadPoolExecutor.
> The proposed new ForkJoinPool constructor accepts parameters that are
> mostly identical to TPE. (It took a fair amount of internal rework to
> enable this.) Unlike TPE, these settings cannot be changed dynamically.
>
> Comments would be welcome. The javadoc is pasted below, and at
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/ForkJoinPool.html 
>
>
> Experience reports would be even more welcome.
> You can run on either jdk8 or early-access jdk9 by getting jar
> (http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar)
> or building (see 
> http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)
> Warning: soon we will need to split jdk8 and jdk9 repos to cope with 
> jigsaw etc.
>
> ... pasting ...
>
>
>         public ForkJoinPool(int parallelism,
> ForkJoinPool.ForkJoinWorkerThreadFactory factory,
>                             Thread.UncaughtExceptionHandler handler,
>                             boolean asyncMode,
>                             int corePoolSize,
>                             int maximumPoolSize,
>                             int minimumRunnable,
>                             boolean rejectOnSaturation,
>                             long keepAliveTime,
>                             TimeUnit unit)
>
>         Creates a ForkJoinPool with the given parameters.
>
>         Parameters:
>             parallelism - the parallelism level. For default value, 
> use Runtime.availableProcessors().
>             factory - the factory for creating new threads. For 
> default value, use defaultForkJoinWorkerThreadFactory.
>             handler - the handler for internal worker threads that 
> terminate due to unrecoverable errors encountered while executing 
> tasks. For default value, use null.
>             asyncMode - if true, establishes local first-in-first-out 
> scheduling mode for forked tasks that are never joined. This mode may 
> be more appropriate than default locally stack-based mode in 
> applications in which worker threads only process event-style 
> asynchronous tasks. For default value, use false.
>             corePoolSize - the number of threads to keep in the pool 
> (unless timed out after an elapsed keep-alive). Normally (and by 
> default) this is the same value as the parallelism level, but may be 
> set to a larger value to reduce dynamic overhead if tasks regularly 
> block. Using a smaller value (for example 0) has the same effect as 
> the default.
>             maximumPoolSize - the maximum number of threads allowed. 
> When the maximum is reached, attempts to replace blocked threads fail. 
> (However, because creation and termination of different threads may 
> overlap, and may be managed by the given thread factory, this value 
> may be transiently exceeded.) The default for the common pool is 256 
> plus the parallelism level. Using a value (for example 
> Integer.MAX_VALUE) larger than the implementation's total thread limit 
> has the same effect as using this limit.
>             minimumRunnable - the minimum allowed number of core 
> threads not blocked by a join or ForkJoinPool.ManagedBlocker. To 
> ensure progress, when too few unblocked threads exist and unexecuted 
> tasks may exist, new threads are constructed, up to the given 
> maximumPoolSize. For the default value, use 1, that ensures liveness. 
> A larger value might improve throughput in the presence of blocked 
> activities, but might not, due to increased overhead. A value of zero 
> may be acceptable when submitted tasks cannot have dependencies 
> requiring additional threads.
>             rejectOnSaturation - if true, attempts to create more than 
> the maximum total allowed threads throw RejectedExecutionException. 
> Otherwise, the pool continues to operate, but with fewer than the 
> target number of runnable threads, so might not ensure progress. For 
> default value, use true.
>             keepAliveTime - the elapsed time since last use before a 
> thread is terminated (and then later replaced if needed). For the 
> default value, use 60, TimeUnit.SECONDS.
>             unit - the time unit for the keepAliveTime argument
>         Throws:
>             IllegalArgumentException - if parallelism is less than or 
> equal to zero, or is greater than implementation limit, or if 
> maximumPoolSize is less than parallelism, of if the keepAliveTime is 
> less than or equal to zero.
>             NullPointerException - if the factory is null
>             SecurityException - if a security manager exists and the 
> caller is not permitted to modify threads because it does not hold 
> RuntimePermission("modifyThread")
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dahankzter at gmail.com  Mon Mar 14 11:35:23 2016
From: dahankzter at gmail.com (Henrik Johansson)
Date: Mon, 14 Mar 2016 15:35:23 +0000
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E6CF3E.4000206@oracle.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E6CF3E.4000206@oracle.com>
Message-ID: <CAKOF695jRc_qVSJE797aryH5NuU31iEqbYLGGR2jvK3BWXAy1g@mail.gmail.com>

Hi,

As a casual user but with occasionally complex needs a builder would be
extremely nice to have.

I understand that stdlib may not be the place but if some frequent usage
patterns can be found perhaps it can be included as well?

On Mon, Mar 14, 2016 at 3:57 PM Roger Riggs <roger.riggs at oracle.com> wrote:

Hi Doug,
>
> Is there any chance I can nudge/encourage you to switch the two
> arguments for keepAliveTime
> to a single argument using java.time.Duration?  Though it was not
> introduced until JDK 8 it
> is a much nicer packaging of a duration.
>
> Roger
>
>
> On 3/14/16 9:56 AM, Doug Lea wrote:
> >
> > As usage contexts of ForkJoinPool increase, it's becoming harder to
> > ensure that internal settings and policies are equally good across all
> > of them. The defaults generally work well (especially for the common
> > pool),
> > but it's a bad omen that advanced users are resorting to clever and
> > weird hacks; even including using Unsafe or reflection to modify
> > internals.
> > (For a disconcertingly cool example, see the APGAS framework at
> > https://github.com/x10-lang/x10/tree/master/apgas)
> >
> > The only model for pool customization in j.u.c is ThreadPoolExecutor.
> > The proposed new ForkJoinPool constructor accepts parameters that are
> > mostly identical to TPE. (It took a fair amount of internal rework to
> > enable this.) Unlike TPE, these settings cannot be changed dynamically.
> >
> > Comments would be welcome. The javadoc is pasted below, and at
> >
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/ForkJoinPool.html
> >
> >
> > Experience reports would be even more welcome.
> > You can run on either jdk8 or early-access jdk9 by getting jar
> > (http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar)
> > or building (see
> > http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)
> > Warning: soon we will need to split jdk8 and jdk9 repos to cope with
> > jigsaw etc.
> >
> > ... pasting ...
> >
> >
> >         public ForkJoinPool(int parallelism,
> > ForkJoinPool.ForkJoinWorkerThreadFactory factory,
> >                             Thread.UncaughtExceptionHandler handler,
> >                             boolean asyncMode,
> >                             int corePoolSize,
> >                             int maximumPoolSize,
> >                             int minimumRunnable,
> >                             boolean rejectOnSaturation,
> >                             long keepAliveTime,
> >                             TimeUnit unit)
> >
> >         Creates a ForkJoinPool with the given parameters.
> >
> >         Parameters:
> >             parallelism - the parallelism level. For default value,
> > use Runtime.availableProcessors().
> >             factory - the factory for creating new threads. For
> > default value, use defaultForkJoinWorkerThreadFactory.
> >             handler - the handler for internal worker threads that
> > terminate due to unrecoverable errors encountered while executing
> > tasks. For default value, use null.
> >             asyncMode - if true, establishes local first-in-first-out
> > scheduling mode for forked tasks that are never joined. This mode may
> > be more appropriate than default locally stack-based mode in
> > applications in which worker threads only process event-style
> > asynchronous tasks. For default value, use false.
> >             corePoolSize - the number of threads to keep in the pool
> > (unless timed out after an elapsed keep-alive). Normally (and by
> > default) this is the same value as the parallelism level, but may be
> > set to a larger value to reduce dynamic overhead if tasks regularly
> > block. Using a smaller value (for example 0) has the same effect as
> > the default.
> >             maximumPoolSize - the maximum number of threads allowed.
> > When the maximum is reached, attempts to replace blocked threads fail.
> > (However, because creation and termination of different threads may
> > overlap, and may be managed by the given thread factory, this value
> > may be transiently exceeded.) The default for the common pool is 256
> > plus the parallelism level. Using a value (for example
> > Integer.MAX_VALUE) larger than the implementation's total thread limit
> > has the same effect as using this limit.
> >             minimumRunnable - the minimum allowed number of core
> > threads not blocked by a join or ForkJoinPool.ManagedBlocker. To
> > ensure progress, when too few unblocked threads exist and unexecuted
> > tasks may exist, new threads are constructed, up to the given
> > maximumPoolSize. For the default value, use 1, that ensures liveness.
> > A larger value might improve throughput in the presence of blocked
> > activities, but might not, due to increased overhead. A value of zero
> > may be acceptable when submitted tasks cannot have dependencies
> > requiring additional threads.
> >             rejectOnSaturation - if true, attempts to create more than
> > the maximum total allowed threads throw RejectedExecutionException.
> > Otherwise, the pool continues to operate, but with fewer than the
> > target number of runnable threads, so might not ensure progress. For
> > default value, use true.
> >             keepAliveTime - the elapsed time since last use before a
> > thread is terminated (and then later replaced if needed). For the
> > default value, use 60, TimeUnit.SECONDS.
> >             unit - the time unit for the keepAliveTime argument
> >         Throws:
> >             IllegalArgumentException - if parallelism is less than or
> > equal to zero, or is greater than implementation limit, or if
> > maximumPoolSize is less than parallelism, of if the keepAliveTime is
> > less than or equal to zero.
> >             NullPointerException - if the factory is null
> >             SecurityException - if a security manager exists and the
> > caller is not permitted to modify threads because it does not hold
> > RuntimePermission("modifyThread")
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160314/ab86f8a0/attachment-0001.html>

From martinrb at google.com  Mon Mar 14 12:18:13 2016
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 14 Mar 2016 09:18:13 -0700
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E6CF3E.4000206@oracle.com>
References: <56E6C2F0.1020600@cs.oswego.edu>
	<56E6CF3E.4000206@oracle.com>
Message-ID: <CA+kOe0-WKRPM4x=10Nq--crsrxs69abf4wOi00__4b5UmRDsmw@mail.gmail.com>

On Mon, Mar 14, 2016 at 7:48 AM, Roger Riggs <roger.riggs at oracle.com> wrote:
> Hi Doug,
>
> Is there any chance I can nudge/encourage you to switch the two arguments
> for keepAliveTime
> to a single argument using java.time.Duration?  Though it was not introduced
> until JDK 8 it
> is a much nicer packaging of a duration.

Perhaps, but there is a long tradition of using (long, TimeUnit)
parameter pairs, an engineering compromise; and one is tempted to wait
for value types to be added in jdkN+1.  But it looks like Duration is
"value-type-ready".

From kirk at kodewerk.com  Mon Mar 14 12:54:31 2016
From: kirk at kodewerk.com (kirk at kodewerk.com)
Date: Mon, 14 Mar 2016 17:54:31 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <CAKOF695jRc_qVSJE797aryH5NuU31iEqbYLGGR2jvK3BWXAy1g@mail.gmail.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E6CF3E.4000206@oracle.com>
	<CAKOF695jRc_qVSJE797aryH5NuU31iEqbYLGGR2jvK3BWXAy1g@mail.gmail.com>
Message-ID: <23458D06-3CA9-45C0-A891-A391B94B9FA6@kodewerk.com>

Hi,

A number of us have had discussions with Stuart Marks regarding the usability of parallel streams in general compute environments. IMHO, F-J and hence parallel streams have been completely unusable in these types of environments even for problems that are a good fit for F-J. At issue is that there doesn?t exist any means to have the workload describe the parameters under which is should function and have it adapt to changing conditions in the runtime. IME, to blindly throw a workload at F-J (via parallel streams) has been a recipe for disaster. In December I suggested to Stuart that we be allowed to attach some sort of policy to the job so that there is some control or ability to adapt after the job has been launched. Stuart, being much smarter than me, rejected that solution but it did get him thinking that something more is needed to help workloads be able to have more control over their own fate after beng submitted to F-J (again via parallel streams). We get to talk to him to see what type of progress has been made at jCrete. That said, I?m wondering if there is some cross-over here between the usability issues I?m seeing and the problems that are trying to be hacked around frameworks such as APGAS.

Kind regards,
Kirk Pepperdine

> On Mar 14, 2016, at 4:35 PM, Henrik Johansson <dahankzter at gmail.com> wrote:
> 
> Hi,
> 
> As a casual user but with occasionally complex needs a builder would be extremely nice to have.
> 
> I understand that stdlib may not be the place but if some frequent usage patterns can be found perhaps it can be included as well?
> 
> On Mon, Mar 14, 2016 at 3:57 PM Roger Riggs <roger.riggs at oracle.com <mailto:roger.riggs at oracle.com>> wrote:
> 
> Hi Doug,
> 
> Is there any chance I can nudge/encourage you to switch the two
> arguments for keepAliveTime
> to a single argument using java.time.Duration?  Though it was not
> introduced until JDK 8 it
> is a much nicer packaging of a duration.
> 
> Roger
> 
> 
> On 3/14/16 9:56 AM, Doug Lea wrote:
> >
> > As usage contexts of ForkJoinPool increase, it's becoming harder to
> > ensure that internal settings and policies are equally good across all
> > of them. The defaults generally work well (especially for the common
> > pool),
> > but it's a bad omen that advanced users are resorting to clever and
> > weird hacks; even including using Unsafe or reflection to modify
> > internals.
> > (For a disconcertingly cool example, see the APGAS framework at
> > https://github.com/x10-lang/x10/tree/master/apgas <https://github.com/x10-lang/x10/tree/master/apgas>)
> >
> > The only model for pool customization in j.u.c is ThreadPoolExecutor.
> > The proposed new ForkJoinPool constructor accepts parameters that are
> > mostly identical to TPE. (It took a fair amount of internal rework to
> > enable this.) Unlike TPE, these settings cannot be changed dynamically.
> >
> > Comments would be welcome. The javadoc is pasted below, and at
> > http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/ForkJoinPool.html <http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/ForkJoinPool.html>
> >
> >
> > Experience reports would be even more welcome.
> > You can run on either jdk8 or early-access jdk9 by getting jar
> > (http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar <http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar>)
> > or building (see
> > http://gee.cs.oswego.edu/dl/concurrency-interest/index.html <http://gee.cs.oswego.edu/dl/concurrency-interest/index.html>)
> > Warning: soon we will need to split jdk8 and jdk9 repos to cope with
> > jigsaw etc.
> >
> > ... pasting ...
> >
> >
> >         public ForkJoinPool(int parallelism,
> > ForkJoinPool.ForkJoinWorkerThreadFactory factory,
> >                             Thread.UncaughtExceptionHandler handler,
> >                             boolean asyncMode,
> >                             int corePoolSize,
> >                             int maximumPoolSize,
> >                             int minimumRunnable,
> >                             boolean rejectOnSaturation,
> >                             long keepAliveTime,
> >                             TimeUnit unit)
> >
> >         Creates a ForkJoinPool with the given parameters.
> >
> >         Parameters:
> >             parallelism - the parallelism level. For default value,
> > use Runtime.availableProcessors().
> >             factory - the factory for creating new threads. For
> > default value, use defaultForkJoinWorkerThreadFactory.
> >             handler - the handler for internal worker threads that
> > terminate due to unrecoverable errors encountered while executing
> > tasks. For default value, use null.
> >             asyncMode - if true, establishes local first-in-first-out
> > scheduling mode for forked tasks that are never joined. This mode may
> > be more appropriate than default locally stack-based mode in
> > applications in which worker threads only process event-style
> > asynchronous tasks. For default value, use false.
> >             corePoolSize - the number of threads to keep in the pool
> > (unless timed out after an elapsed keep-alive). Normally (and by
> > default) this is the same value as the parallelism level, but may be
> > set to a larger value to reduce dynamic overhead if tasks regularly
> > block. Using a smaller value (for example 0) has the same effect as
> > the default.
> >             maximumPoolSize - the maximum number of threads allowed.
> > When the maximum is reached, attempts to replace blocked threads fail.
> > (However, because creation and termination of different threads may
> > overlap, and may be managed by the given thread factory, this value
> > may be transiently exceeded.) The default for the common pool is 256
> > plus the parallelism level. Using a value (for example
> > Integer.MAX_VALUE) larger than the implementation's total thread limit
> > has the same effect as using this limit.
> >             minimumRunnable - the minimum allowed number of core
> > threads not blocked by a join or ForkJoinPool.ManagedBlocker. To
> > ensure progress, when too few unblocked threads exist and unexecuted
> > tasks may exist, new threads are constructed, up to the given
> > maximumPoolSize. For the default value, use 1, that ensures liveness.
> > A larger value might improve throughput in the presence of blocked
> > activities, but might not, due to increased overhead. A value of zero
> > may be acceptable when submitted tasks cannot have dependencies
> > requiring additional threads.
> >             rejectOnSaturation - if true, attempts to create more than
> > the maximum total allowed threads throw RejectedExecutionException.
> > Otherwise, the pool continues to operate, but with fewer than the
> > target number of runnable threads, so might not ensure progress. For
> > default value, use true.
> >             keepAliveTime - the elapsed time since last use before a
> > thread is terminated (and then later replaced if needed). For the
> > default value, use 60, TimeUnit.SECONDS.
> >             unit - the time unit for the keepAliveTime argument
> >         Throws:
> >             IllegalArgumentException - if parallelism is less than or
> > equal to zero, or is greater than implementation limit, or if
> > maximumPoolSize is less than parallelism, of if the keepAliveTime is
> > less than or equal to zero.
> >             NullPointerException - if the factory is null
> >             SecurityException - if a security manager exists and the
> > caller is not permitted to modify threads because it does not hold
> > RuntimePermission("modifyThread")
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160314/03fe7328/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160314/03fe7328/attachment.bin>

From mail at florian-schoppmann.net  Mon Mar 14 19:47:57 2016
From: mail at florian-schoppmann.net (Florian Schoppmann)
Date: Mon, 14 Mar 2016 16:47:57 -0700
Subject: [concurrency-interest] Library with CompletableFuture utility
	methods
Message-ID: <1mk40mp.1l93ifn1xvfc7qN%mail@florian-schoppmann.net>

Hi all,

In light of previous related discussions of
CompletionStage/CompletableFuture on this list [1-4], there may be
interest in a very small library of mine that helps with several common
use cases that come up in practice (checked exceptions, combining
multiple futures, asynchronous try-with-resources, etc.).

  https://github.com/fschopp/java-futures

Available in Central, BSD license, virtually full code coverage,
extensive JavaDoc, and no dirty hacks :) -- hopefully of use for some
readers.

Florian


[1] "CompletableFuture",
http://cs.oswego.edu/pipermail/concurrency-interest/2012-December/010486.html
[2] "Layered exception handling with CompletableFuture",
http://cs.oswego.edu/pipermail/concurrency-interest/2014-August/012911.html
[3] "Candidate jdk9 CompletableFuture additions",
http://cs.oswego.edu/pipermail/concurrency-interest/2015-January/013600.html
[4] "CompletableFuture.whenComplete survey",
http://cs.oswego.edu/pipermail/concurrency-interest/2015-December/014779.html


From valentin.male.kovalenko at gmail.com  Tue Mar 15 01:37:01 2016
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Tue, 15 Mar 2016 08:37:01 +0300
Subject: [concurrency-interest] Library with CompletableFuture utility
	methods
Message-ID: <CAO-wXwJ=Kc4oo5F8a1uvxTnfCi5SVTpGmjTMcm_sMrSGiJjMMg@mail.gmail.com>

Finally we have a method that converts a collection of futures into a
future of collection of results :) Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/efbf2315/attachment.html>

From christian.schudt at gmx.de  Tue Mar 15 02:37:33 2016
From: christian.schudt at gmx.de (Christian Schudt)
Date: Tue, 15 Mar 2016 07:37:33 +0100
Subject: [concurrency-interest] Library with CompletableFuture utility
	methods
In-Reply-To: <1mk40mp.1l93ifn1xvfc7qN%mail@florian-schoppmann.net>
References: <1mk40mp.1l93ifn1xvfc7qN%mail@florian-schoppmann.net>
Message-ID: <FB7DB2EA-AF5F-4754-BDF2-135D96EF6C93@gmx.de>

Hi,

you might be interested in my attempt:
https://bitbucket.org/sco0ter/babbler/src/3dcb590b3c92f2ceb80a1498b623e035fb59c227/xmpp-core/src/main/java/rocks/xmpp/util/concurrent/CompletionStages.java?at=master&fileviewer=file-view-default

allOf() is very similar as your collect() I think (except that it also flatMaps).

I also found withFallback() useful (composing two stages and if the first one fails, executes the second one, and only if this fails, too, completes exceptionally).

I?ve got the feeling, that at least some of them could fit well in the JDK.
un/wrapInCompletionException is useful, too. I?ve used a few times as one liner.

? Christian


> Am 15.03.2016 um 00:47 schrieb Florian Schoppmann <mail at florian-schoppmann.net>:
> 
> Hi all,
> 
> In light of previous related discussions of
> CompletionStage/CompletableFuture on this list [1-4], there may be
> interest in a very small library of mine that helps with several common
> use cases that come up in practice (checked exceptions, combining
> multiple futures, asynchronous try-with-resources, etc.).
> 
>  https://github.com/fschopp/java-futures
> 
> Available in Central, BSD license, virtually full code coverage,
> extensive JavaDoc, and no dirty hacks :) -- hopefully of use for some
> readers.
> 
> Florian
> 
> 
> [1] "CompletableFuture",
> http://cs.oswego.edu/pipermail/concurrency-interest/2012-December/010486.html
> [2] "Layered exception handling with CompletableFuture",
> http://cs.oswego.edu/pipermail/concurrency-interest/2014-August/012911.html
> [3] "Candidate jdk9 CompletableFuture additions",
> http://cs.oswego.edu/pipermail/concurrency-interest/2015-January/013600.html
> [4] "CompletableFuture.whenComplete survey",
> http://cs.oswego.edu/pipermail/concurrency-interest/2015-December/014779.html
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From dl at cs.oswego.edu  Tue Mar 15 11:57:02 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 15 Mar 2016 11:57:02 -0400
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E6C2F0.1020600@cs.oswego.edu>
References: <56E6C2F0.1020600@cs.oswego.edu>
Message-ID: <56E830CE.2080308@cs.oswego.edu>


A few notes and replies...

Thanks to Viktor for complaining about just using a boolean for saturation
control. Now changed to accept a predicate that also provides a callback for
arbitrary processing on saturation:

      * @param saturate if nonnull, a predicate invoked upon attempts
      * to create more than the maximum total allowed threads.  By
      * default, when a thread is about to block on a join or {@link
      * ManagedBlocker}, but cannot be replaced because the
      * maximumPoolSize would be exceeded, a {@link
      * RejectedExecutionException} is thrown.  But if this predicate
      * returns {@code true}, then no exception is thrown, so the pool
      * continues to operate with fewer than the target number of
      * runnable threads, which might not ensure progress.
      *

> On 03/14/2016 10:48 AM, Roger Riggs wrote:
>> Is there any chance I can nudge/encourage you to switch the two arguments
>> for keepAliveTime to a single argument using java.time.Duration?  Though it
>> was not introduced until JDK 8 it is a much nicer packaging of a duration.
>>

As Martin mentioned, the initial main rationale for TimeUnit was to avoid
allocation and GC when dealing with small durations used in timeouts and
timings. When value types appear, we'll definitely want to revisit this.
But for now left alone for uniformity with all other j.u.c APIs.

> On 03/14/2016 10:54 AM, Chris Purcell wrote:
>> Wouldn't a builder be appropriate here?
>>

Maybe, but the convention is to use factories for all common cases in
class Executors, leaving only advanced users to deal with plain
constructors in concrete classes. And done here for cowardly uniformity
as well.

-Doug




From markus at headcrashing.eu  Tue Mar 15 13:12:11 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Tue, 15 Mar 2016 18:12:11 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E830CE.2080308@cs.oswego.edu>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
Message-ID: <E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>

Sorry if I chime in or this already was discussed, but I did not follow the thread from the beginning: I think it would be great if a work stealing executor could be configured for a maximum global queue length, so when adding more work it will throw RejectedExecutionException in case the global queue length is exceeded but no more workers may be allocated.

-Markus

Von: Doug Lea
Gesendet: Dienstag, 15. M?rz 2016 17:07
An: concurrency-interest at cs.oswego.edu
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor


A few notes and replies...

Thanks to Viktor for complaining about just using a boolean for saturation
control. Now changed to accept a predicate that also provides a callback for
arbitrary processing on saturation:

      * @param saturate if nonnull, a predicate invoked upon attempts
      * to create more than the maximum total allowed threads.  By
      * default, when a thread is about to block on a join or {@link
      * ManagedBlocker}, but cannot be replaced because the
      * maximumPoolSize would be exceeded, a {@link
      * RejectedExecutionException} is thrown.  But if this predicate
      * returns {@code true}, then no exception is thrown, so the pool
      * continues to operate with fewer than the target number of
      * runnable threads, which might not ensure progress.
      *

> On 03/14/2016 10:48 AM, Roger Riggs wrote:
>> Is there any chance I can nudge/encourage you to switch the two arguments
>> for keepAliveTime to a single argument using java.time.Duration?  Though it
>> was not introduced until JDK 8 it is a much nicer packaging of a duration.
>>

As Martin mentioned, the initial main rationale for TimeUnit was to avoid
allocation and GC when dealing with small durations used in timeouts and
timings. When value types appear, we'll definitely want to revisit this.
But for now left alone for uniformity with all other j.u.c APIs.

> On 03/14/2016 10:54 AM, Chris Purcell wrote:
>> Wouldn't a builder be appropriate here?
>>

Maybe, but the convention is to use factories for all common cases in
class Executors, leaving only advanced users to deal with plain
constructors in concrete classes. And done here for cowardly uniformity
as well.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/45d76aac/attachment.html>

From dl at cs.oswego.edu  Tue Mar 15 13:23:33 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 15 Mar 2016 13:23:33 -0400
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
Message-ID: <56E84515.7030304@cs.oswego.edu>

On 03/15/2016 01:12 PM, Markus KARG wrote:
> Sorry if I chime in or this already was discussed, but I did not follow the
> thread from the beginning: I think it would be great if a work stealing executor
> could be configured for a maximum global queue length, so when adding more work
> it will throw RejectedExecutionException in case the global queue length is
> exceeded but no more workers may be allocated.
>

There is no global queue, so no global length.
But you can layer similar control by invoking
ForkJoinTask.getQueuedTaskCount and checking
per-submitter count before invoking fork, execute, etc.

-Doug







From markus at headcrashing.eu  Tue Mar 15 14:30:07 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Tue, 15 Mar 2016 19:30:07 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E84515.7030304@cs.oswego.edu>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
Message-ID: <E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>

Doug, with ?global Queue length? I did not mean ?length of the global Queue? but ?sum of lenghts of all queues?. ??

So do you propose to _wrap_ the Executor by the application programmer, or  is this a use case for the discussed Predicate?

Thanks
-Markus

Von: Doug Lea
Gesendet: Dienstag, 15. M?rz 2016 18:23
An: Markus KARG; concurrency-interest at cs.oswego.edu
Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool constructor

On 03/15/2016 01:12 PM, Markus KARG wrote:
> Sorry if I chime in or this already was discussed, but I did not follow the
> thread from the beginning: I think it would be great if a work stealing executor
> could be configured for a maximum global queue length, so when adding more work
> it will throw RejectedExecutionException in case the global queue length is
> exceeded but no more workers may be allocated.
>

There is no global queue, so no global length.
But you can layer similar control by invoking
ForkJoinTask.getQueuedTaskCount and checking
per-submitter count before invoking fork, execute, etc.

-Doug







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/8c0c25dc/attachment.html>

From mail at florian-schoppmann.net  Tue Mar 15 14:31:11 2016
From: mail at florian-schoppmann.net (Florian Schoppmann)
Date: Tue, 15 Mar 2016 11:31:11 -0700
Subject: [concurrency-interest] Library with CompletableFuture utility
	methods
References: <1mk40mp.1l93ifn1xvfc7qN%mail@florian-schoppmann.net>
	<FB7DB2EA-AF5F-4754-BDF2-135D96EF6C93@gmx.de>
Message-ID: <1mk5fpa.19oho8c1gc8kr0N%mail@florian-schoppmann.net>

Christian Schudt <christian.schudt at gmx.de> wrote:

> you might be interested in my attempt:
> https://bitbucket.org/sco0ter/babbler/src/3dcb590b3c92f2ceb80a1498b623e035
> fb59c227/xmpp-core/src/main/java/rocks/xmpp/util/concurrent/CompletionStag
> es.java?at=master&fileviewer=file-view-default
>
> allOf() is very similar as your collect() I think (except that it also
> flatMaps).

I looked over your code briefly, allOf() is indeed equivalent in effect
to my Futures#collect().

The use of CompletableFuture#join() in your code may be considered
undesirable by some (including static code analyis) because it is a
blocking function -- even though it is guaranteed not to block in that
context.

In any case, the Futures class in project java-futures also provides
Futures#shortCircuitCollect(). This is similar to Akka's
Futures#sequence(), which also has short-circuit semantics:
<http://doc.akka.io/api/akka/2.4.2/index.html#akka.dispatch.Futures$@sequence[A](in:Iterable[scala.concurrent.Future[A]],executor:scala.concurrent.ExecutionContext):scala.concurrent.Future[Iterable[A]]>

> I also found withFallback() useful (composing two stages and if the first
> one fails, executes the second one, and only if this fails, too,
> completes exceptionally).

I don't see the use of this method, given
CompletionStage#exceptionally()?

> I've got the feeling, that at least some of them could fit well in the JDK.

Ditto. Though a few additions are already in the current JDK9 code base.

Florian


From viktor.klang at gmail.com  Tue Mar 15 15:18:06 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Tue, 15 Mar 2016 20:18:06 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
Message-ID: <CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>

?
On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu> wrote:
>
> Doug, with ?global Queue length? I did not mean ?length of the global
Queue? but ?sum of lenghts of all queues?. ??

But there is no such thing. Think about it. :-)

>
>
> So do you propose to _wrap_ the Executor by the application programmer,
or  is this a use case for the discussed Predicate?
>
>
>
> Thanks
>
> -Markus
>
>
>
> Von: Doug Lea
> Gesendet: Dienstag, 15. M?rz 2016 18:23
> An: Markus KARG; concurrency-interest at cs.oswego.edu
> Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool
constructor
>
>
>
> On 03/15/2016 01:12 PM, Markus KARG wrote:
>
> > Sorry if I chime in or this already was discussed, but I did not follow
the
>
> > thread from the beginning: I think it would be great if a work stealing
executor
>
> > could be configured for a maximum global queue length, so when adding
more work
>
> > it will throw RejectedExecutionException in case the global queue
length is
>
> > exceeded but no more workers may be allocated.
>
> >
>
>
>
> There is no global queue, so no global length.
>
> But you can layer similar control by invoking
>
> ForkJoinTask.getQueuedTaskCount and checking
>
> per-submitter count before invoking fork, execute, etc.
>
>
>
> -Doug
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/1afdf578/attachment-0001.html>

From kensipe at gmail.com  Tue Mar 15 16:21:30 2016
From: kensipe at gmail.com (Ken Sipe)
Date: Tue, 15 Mar 2016 15:21:30 -0500
Subject: [concurrency-interest] multi JVM on a node / JVM in a container
Message-ID: <B253B26A-97AE-4548-8928-FED63BDAE769@gmail.com>

I?m looking into the consequence of a JRE sharing a multi-core node but not owning the full resource space.   

GIVEN:  A node with 16 cores.

SCENARIO 1:  4 JVMs

All JREs will see 16 cores and have an internal setup for 16 cores? 16 GC threads for old parallel gc.  The target parallelism level of fork join, etc.  However with 4 JREs running their processes will be scheduled and prioritized such that under idealistic conditions they ?realize? 4 cores of time each.   Questions that come to mind.

1. Does this have a negative consequence?  such as the time to safe point? 
2. Any other consequences?
3. Any recommendations to reduce any negative impact?  


SCENARIO 2:   the REAL reason for the question? 1 JVM in a container under cgroup CPU-Shares with a weighted value of 4 cores

I?m troubled with the fact that cpu-share (vs cpu-sets) is the common / default option for containers.   The result is a situation where in a heterogeneous datacenter where my container lands (16 core, 32 core, 4 core) setups on the JVM with different levels of efficiencies.   It?s been on my mind for over 1 year old and I would love to discuss it with this group. 

SCENARO 3: 1 JVM in a container with CPU-Sets set to 1 core

Now the JRE ?sees? only 1 core regardless of node it lands on? and is setup for client mode? awesome! NOT.

Thoughts?

ken

From chris.purcell.39 at gmail.com  Tue Mar 15 16:33:39 2016
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Tue, 15 Mar 2016 20:33:39 +0000
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56E830CE.2080308@cs.oswego.edu>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
Message-ID: <CAJUoZVYbLgArxW8b0QVfCqq6XTvYMLz7vnnD1uSrOLB6WnFB6Q@mail.gmail.com>

Won't it be easier to add more parameters in future without ending up with
a random set of constructors, though? This API in particular seems very
likely to need refinement in future.

On Tue, 15 Mar 2016, 16:13 Doug Lea, <dl at cs.oswego.edu> wrote:

>
> > On 03/14/2016 10:54 AM, Chris Purcell wrote:
> >> Wouldn't a builder be appropriate here?
> >>
>
> Maybe, but the convention is to use factories for all common cases in
> class Executors, leaving only advanced users to deal with plain
> constructors in concrete classes. And done here for cowardly uniformity
> as well.
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/e6480b93/attachment.html>

From davidcholmes at aapt.net.au  Tue Mar 15 16:47:41 2016
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 16 Mar 2016 06:47:41 +1000
Subject: [concurrency-interest] multi JVM on a node / JVM in a container
In-Reply-To: <B253B26A-97AE-4548-8928-FED63BDAE769@gmail.com>
References: <B253B26A-97AE-4548-8928-FED63BDAE769@gmail.com>
Message-ID: <001c01d17efb$eb4d7c70$c1e87550$@aapt.net.au>

Ken Sipe writes:
> I?m looking into the consequence of a JRE sharing a multi-core node but not
> owning the full resource space.
> 
> GIVEN:  A node with 16 cores.
> 
> SCENARIO 1:  4 JVMs
> 
> All JREs will see 16 cores and have an internal setup for 16 cores? 16 GC
> threads for old parallel gc.  The target parallelism level of fork join, etc.
> However with 4 JREs running their processes will be scheduled and prioritized
> such that under idealistic conditions they ?realize? 4 cores of time each.
> Questions that come to mind.
> 
> 1. Does this have a negative consequence?  such as the time to safe point?
> 2. Any other consequences?
> 3. Any recommendations to reduce any negative impact?

If each JVM would quite fully utilize the entire machine then obviously have four run concurrently will effectively overload the machine.

Ergonomic selection assumes an ideal world and what the VM sees by way of resources is what it can expect to have. In this scenario where you know you are deploying multiple JVMs onto shared resources you should configure each appropriately - number of GC threads, number of compiler threads, and limit the maximum concurrency of the default FJPool.
 
> 
> SCENARIO 2:   the REAL reason for the question? 1 JVM in a container under
> cgroup CPU-Shares with a weighted value of 4 cores
> 
> I?m troubled with the fact that cpu-share (vs cpu-sets) is the common /
> default option for containers.   The result is a situation where in a
> heterogeneous datacenter where my container lands (16 core, 32 core, 4
> core) setups on the JVM with different levels of efficiencies.   It?s been on
> my mind for over 1 year old and I would love to discuss it with this group.

I don't really see any way to deal with this. You want the JVM to utilize all available processors, even if the "share" on any given processor is limited.
 
> SCENARO 3: 1 JVM in a container with CPU-Sets set to 1 core
> 
> Now the JRE ?sees? only 1 core regardless of node it lands on? and is setup
> for client mode? awesome! NOT.

Again you need to override the ergonomic selection - either with command-line options or environment variables. But running a server VM one a 1 processor system is not going to be awesome either.
 
> Thoughts?

It is a problem trying to balance overall productivity, with transparent operation when running in resource constrained environments. It is only the latest JDK 9 that will even see cpusets on Linux. And dealing with memory constraints in containers is still an unresolved issue. When the environment lies to the VM about what is available it makes it very hard for the VM to try to adjust.

Cheers,
David

> 
> ken
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From kensipe at gmail.com  Tue Mar 15 16:57:32 2016
From: kensipe at gmail.com (Ken Sipe)
Date: Tue, 15 Mar 2016 15:57:32 -0500
Subject: [concurrency-interest] multi JVM on a node / JVM in a container
In-Reply-To: <001c01d17efb$eb4d7c70$c1e87550$@aapt.net.au>
References: <B253B26A-97AE-4548-8928-FED63BDAE769@gmail.com>
	<001c01d17efb$eb4d7c70$c1e87550$@aapt.net.au>
Message-ID: <E041FC7B-965F-4EB4-9B92-B4B69D4D6EEC@gmail.com>

thx david.. this is what I was expecting? checking to see I wasn?t missing something.  more notes below?


> On Mar 15, 2016, at 3:47 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> 
> Ken Sipe writes:
>> I?m looking into the consequence of a JRE sharing a multi-core node but not
>> owning the full resource space.
>> 
>> GIVEN:  A node with 16 cores.
>> 
>> SCENARIO 1:  4 JVMs
>> 
>> All JREs will see 16 cores and have an internal setup for 16 cores? 16 GC
>> threads for old parallel gc.  The target parallelism level of fork join, etc.
>> However with 4 JREs running their processes will be scheduled and prioritized
>> such that under idealistic conditions they ?realize? 4 cores of time each.
>> Questions that come to mind.
>> 
>> 1. Does this have a negative consequence?  such as the time to safe point?
>> 2. Any other consequences?
>> 3. Any recommendations to reduce any negative impact?
> 
> If each JVM would quite fully utilize the entire machine then obviously have four run concurrently will effectively overload the machine.
> 
> Ergonomic selection assumes an ideal world and what the VM sees by way of resources is what it can expect to have. In this scenario where you know you are deploying multiple JVMs onto shared resources you should configure each appropriately - number of GC threads, number of compiler threads, and limit the maximum concurrency of the default FJPool.
> 
>> 
>> SCENARIO 2:   the REAL reason for the question? 1 JVM in a container under
>> cgroup CPU-Shares with a weighted value of 4 cores
>> 
>> I?m troubled with the fact that cpu-share (vs cpu-sets) is the common /
>> default option for containers.   The result is a situation where in a
>> heterogeneous datacenter where my container lands (16 core, 32 core, 4
>> core) setups on the JVM with different levels of efficiencies.   It?s been on
>> my mind for over 1 year old and I would love to discuss it with this group.
> 
> I don't really see any way to deal with this. You want the JVM to utilize all available processors, even if the "share" on any given processor is limited.
> 
>> SCENARO 3: 1 JVM in a container with CPU-Sets set to 1 core
>> 
>> Now the JRE ?sees? only 1 core regardless of node it lands on? and is setup
>> for client mode? awesome! NOT.
> 
> Again you need to override the ergonomic selection - either with command-line options or environment variables. But running a server VM one a 1 processor system is not going to be awesome either.
> 
>> Thoughts?
> 
> It is a problem trying to balance overall productivity, with transparent operation when running in resource constrained environments. It is only the latest JDK 9 that will even see cpusets on Linux. And dealing with memory constraints in containers is still an unresolved issue.

I?m not sure what you mean here? The JRE 7/8 runtime ?sees? all cores in shares mode and just assigned number of cores in set mode.  I?m not familiar with the changes in 9.. but very interested.

> When the environment lies to the VM about what is available it makes it very hard for the VM to try to adjust.

This is my favorite part of your request?  the JVM expects to ?own? the platform.   The world of lies is spiking.   micro-services + containers + JVM are the new norm.  The problem is few understand the consequences.     We can expect that the environment the JVM is running on is not detectable in the ?old? ways.   We need a way to provide platform ?profiles? to the JVM.  The oracle java team is very against setting every effected flag for the environment (lessons learned from the Sun days).   The only alternative is to provide a mechanism to inform the JVM of the truth.

> 
> Cheers,
> David
> 
>> 
>> ken
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/81d476e5/attachment-0001.html>

From markus at headcrashing.eu  Tue Mar 15 17:12:13 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Tue, 15 Mar 2016 22:12:13 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
Message-ID: <E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>


Well? each thread has a queue, so we could sum up the number of task in each. What point do I miss?


Von: Viktor Klang
Gesendet: Dienstag, 15. M?rz 2016 20:18
An: Markus KARG
Cc: Doug Lea; concurrency-interest
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor

?
On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu> wrote:
>
> Doug, with ?global Queue length? I did not mean ?length of the global Queue? but ?sum of lenghts of all queues?. ??
But there is no such thing. Think about it. :-)
> ?
>
> So do you propose to _wrap_ the Executor by the application programmer, or ?is this a use case for the discussed Predicate?
>
> ?
>
> Thanks
>
> -Markus
>
> ?
>
> Von: Doug Lea
> Gesendet: Dienstag, 15. M?rz 2016 18:23
> An: Markus KARG; concurrency-interest at cs.oswego.edu
> Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool constructor
>
> ?
>
> On 03/15/2016 01:12 PM, Markus KARG wrote:
>
> > Sorry if I chime in or this already was discussed, but I did not follow the
>
> > thread from the beginning: I think it would be great if a work stealing executor
>
> > could be configured for a maximum global queue length, so when adding more work
>
> > it will throw RejectedExecutionException in case the global queue length is
>
> > exceeded but no more workers may be allocated.
>
> >?
>
> ?
>
> There is no global queue, so no global length.
>
> But you can layer similar control by invoking
>
> ForkJoinTask.getQueuedTaskCount and checking
>
> per-submitter count before invoking fork, execute, etc.
>
> ?
>
> -Doug
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160315/7a045b4e/attachment.html>

From davidcholmes at aapt.net.au  Tue Mar 15 19:46:48 2016
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 16 Mar 2016 09:46:48 +1000
Subject: [concurrency-interest] multi JVM on a node / JVM in a container
In-Reply-To: <E041FC7B-965F-4EB4-9B92-B4B69D4D6EEC@gmail.com>
References: <B253B26A-97AE-4548-8928-FED63BDAE769@gmail.com>	<001c01d17efb$eb4d7c70$c1e87550$@aapt.net.au>
	<E041FC7B-965F-4EB4-9B92-B4B69D4D6EEC@gmail.com>
Message-ID: <002f01d17f14$f2a295f0$d7e7c1d0$@aapt.net.au>

Ken Sipe writes:
> thx david.. this is what I was expecting? checking to see I wasn?t missing something.  more notes below?
>
>
> On Mar 15, 2016, at 3:47 PM, David Holmes <mailto:davidcholmes at aapt.net.au> wrote:
>> 
>> Ken Sipe writes:
>>> 
>>> I?m looking into the consequence of a JRE sharing a multi-core node but not owning the full resource space.
>>>
>>> GIVEN:  A node with 16 cores.
>>> 
>>> SCENARIO 1:  4 JVMs
>>> 
>>> All JREs will see 16 cores and have an internal setup for 16 cores? 16 GC threads for old parallel gc.  The target parallelism level of fork join, etc.
>>> However with 4 JREs running their processes will be scheduled and prioritized such that under idealistic conditions they ?realize? 4 cores of time >>> each. Questions that come to mind.
>>>
>>> 1. Does this have a negative consequence?  such as the time to safe point?
>>> 2. Any other consequences?
>>> 3. Any recommendations to reduce any negative impact?
>>>
>> If each JVM would quite fully utilize the entire machine then obviously have four run concurrently will effectively overload the machine.
>>
>> Ergonomic selection assumes an ideal world and what the VM sees by way of resources is what it can expect to have. In this scenario where you 
>> know you are deploying multiple JVMs onto shared resources you should configure each appropriately - number of GC threads, number of compiler 
>> threads, and limit the maximum concurrency of the default FJPool.
>>
>>
>>> SCENARIO 2:   the REAL reason for the question? 1 JVM in a container under cgroup CPU-Shares with a weighted value of 4 cores
>>>
>>> I?m troubled with the fact that cpu-share (vs cpu-sets) is the common /default option for containers.   The result is a situation where in a
>>> heterogeneous datacenter where my container lands (16 core, 32 core, 4 core) setups on the JVM with different levels of efficiencies.   
>>> It?s been on my mind for over 1 year old and I would love to discuss it with this group.
>>>
>> I don't really see any way to deal with this. You want the JVM to utilize all available processors, even if the "share" on any given processor is limited.
>>
>>>
>>> SCENARO 3: 1 JVM in a container with CPU-Sets set to 1 core
>>>
>>> Now the JRE ?sees? only 1 core regardless of node it lands on? and is setup for client mode? awesome! NOT.
>>>
>> Again you need to override the ergonomic selection - either with command-line options or environment variables. But running a server VM one a 1 processor system is not going to be awesome either.
>>
>>>  Thoughts?
>>
>> It is a problem trying to balance overall productivity, with transparent operation when running in resource constrained environments. It is only the 
>> latest JDK 9 that will even see cpusets on Linux. And dealing with memory constraints in containers is still an unresolved issue. 
>
> I?m not sure what you mean here? The JRE 7/8 runtime ?sees? all cores in shares mode and just assigned number of cores in set mode.  I?m not 
> familiar with the changes in 9.. but very interested.

On Linux, JDK 7, 8 and until recently 9, will report the number of  online processors as reported by sysconf. That doesn't account for cpusets reducing the number of online processors that are actually available for the JVM to use. Now in 9 we use sched_getaffinity, which does account for cpusets.

>> When the environment lies to the VM about what is available it makes it very hard for the VM to try to adjust.
>>
> This is my favorite part of your request?  the JVM expects to ?own? the platform.   The world of lies is spiking.   micro-services + containers + JVM are 
> the new norm.  The problem is few understand the consequences.     We can expect that the environment the JVM is running on is not detectable in 
> the ?old? ways.   We need a way to provide platform ?profiles? to the JVM.  The oracle java team is very against setting every effected flag for the 
> environment (lessons learned from the Sun days).   The only alternative is to provide a mechanism to inform the JVM of the truth.

The interaction between containers and the underlying OS and the impact on API's exposed by the OS has not been clearly thought out in my opinion in many cases. Solaris zones at least look like a separate OS instance and all the API's report the right values. But Solaris also has resource pools, and similar to Linux cgroups, these don't modify (in general) what the OS API's report - so the VM has to become aware of these specialized environments and that is very painful. We resisted making the JVM resource pool aware on Solaris and that turned out to be a win because Zones became dominant. But now we face a similar problem with cgroups on Linux and environments like Docker. We were lucky that cpusets are reflected in the output of sched_getaffinity - a nice simple change. But memory constraints are far more problematic and may not even be queryable in general. If there are no API's to tell the VM the real resource story what is the VM supposed to do? I don't have any answers to that.

Cheers,
David



From dl at cs.oswego.edu  Tue Mar 15 19:58:56 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 15 Mar 2016 19:58:56 -0400
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <23458D06-3CA9-45C0-A891-A391B94B9FA6@kodewerk.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E6CF3E.4000206@oracle.com>
	<CAKOF695jRc_qVSJE797aryH5NuU31iEqbYLGGR2jvK3BWXAy1g@mail.gmail.com>
	<23458D06-3CA9-45C0-A891-A391B94B9FA6@kodewerk.com>
Message-ID: <56E8A1C0.2040601@cs.oswego.edu>

On 03/14/2016 12:54 PM, kirk at kodewerk.com wrote:

> A number of us have had discussions with Stuart Marks regarding the usability
> of parallel streams in general compute environments.... At issue is that
> there doesn?t exist any means to have the workload describe the parameters
> under which is should function and have it adapt to changing conditions in
> the runtime.

Thanks to David for addressing this in the course of his helpful reply to Ken
Sipe:

On 03/15/2016 04:47 PM, David Holmes wrote:
>> When the environment lies to the VM about what is available it makes it
>> very hard for the VM to try to adjust.
>>

In other words, we don't have any idea about what to do beyond collecting
experience reports from people trying to cope.

-Doug




From viktor.klang at gmail.com  Wed Mar 16 08:09:33 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Wed, 16 Mar 2016 13:09:33 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
Message-ID: <CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>

On Tue, Mar 15, 2016 at 10:12 PM, Markus KARG <markus at headcrashing.eu>
wrote:

>
>
> Well? each thread has a queue, so we could sum up the number of task in
> each. What point do I miss?
>

That you can only observe one queue at a time, and unless you pause all
consumers and producers, you
'll never be able to get a consistent number unless by chance. (Remembering
the old Queuing Theory point that queues spend most of their time either
full or empty)


>
>
>
>
> *Von: *Viktor Klang <viktor.klang at gmail.com>
> *Gesendet: *Dienstag, 15. M?rz 2016 20:18
> *An: *Markus KARG <markus at headcrashing.eu>
> *Cc: *Doug Lea <dl at cs.oswego.edu>; concurrency-interest
> <concurrency-interest at cs.oswego.edu>
> *Betreff: *Re: [concurrency-interest] Customized ForkJoinPool constructor
>
>
>
> ?
>
> On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu> wrote:
> >
> > Doug, with ?global Queue length? I did not mean ?length of the global
> Queue? but ?sum of lenghts of all queues?. ??
>
> But there is no such thing. Think about it. :-)
>
> >
> >
> > So do you propose to _wrap_ the Executor by the application programmer,
> or  is this a use case for the discussed Predicate?
> >
> >
> >
> > Thanks
> >
> > -Markus
> >
> >
> >
> > Von: Doug Lea
> > Gesendet: Dienstag, 15. M?rz 2016 18:23
> > An: Markus KARG; concurrency-interest at cs.oswego.edu
> > Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool
> constructor
> >
> >
> >
> > On 03/15/2016 01:12 PM, Markus KARG wrote:
> >
> > > Sorry if I chime in or this already was discussed, but I did not
> follow the
> >
> > > thread from the beginning: I think it would be great if a work
> stealing executor
> >
> > > could be configured for a maximum global queue length, so when adding
> more work
> >
> > > it will throw RejectedExecutionException in case the global queue
> length is
> >
> > > exceeded but no more workers may be allocated.
> >
> > >
> >
> >
> >
> > There is no global queue, so no global length.
> >
> > But you can layer similar control by invoking
> >
> > ForkJoinTask.getQueuedTaskCount and checking
> >
> > per-submitter count before invoking fork, execute, etc.
> >
> >
> >
> > -Doug
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160316/43298dbb/attachment-0001.html>

From markus at headcrashing.eu  Thu Mar 17 17:08:41 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Thu, 17 Mar 2016 22:08:41 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
	<CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
Message-ID: <E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>

I don?t want to _monitor_ queues, but my proposal was to _query_ for their current lengths at time of task submission.

Von: Viktor Klang
Gesendet: Mittwoch, 16. M?rz 2016 13:09
An: Markus KARG
Cc: concurrency-interest
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor



On Tue, Mar 15, 2016 at 10:12 PM, Markus KARG <markus at headcrashing.eu> wrote:
?
Well? each thread has a queue, so we could sum up the number of task in each. What point do I miss?

That you can only observe one queue at a time, and unless you pause all consumers and producers, you
'll never be able to get a consistent number unless by chance. (Remembering the old Queuing Theory point that queues spend most of their time either full or empty)
?
?
?
Von: Viktor Klang
Gesendet: Dienstag, 15. M?rz 2016 20:18
An: Markus KARG
Cc: Doug Lea; concurrency-interest
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor
?
?

On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu> wrote:
>
> Doug, with ?global Queue length? I did not mean ?length of the global Queue? but ?sum of lenghts of all queues?. ??
But there is no such thing. Think about it. :-)
> ?
>
> So do you propose to _wrap_ the Executor by the application programmer, or ?is this a use case for the discussed Predicate?
>
> ?
>
> Thanks
>
> -Markus
>
> ?
>
> Von: Doug Lea
> Gesendet: Dienstag, 15. M?rz 2016 18:23
> An: Markus KARG; concurrency-interest at cs.oswego.edu
> Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool constructor
>
> ?
>
> On 03/15/2016 01:12 PM, Markus KARG wrote:
>
> > Sorry if I chime in or this already was discussed, but I did not follow the
>
> > thread from the beginning: I think it would be great if a work stealing executor
>
> > could be configured for a maximum global queue length, so when adding more work
>
> > it will throw RejectedExecutionException in case the global queue length is
>
> > exceeded but no more workers may be allocated.
>
> >?
>
> ?
>
> There is no global queue, so no global length.
>
> But you can layer similar control by invoking
>
> ForkJoinTask.getQueuedTaskCount and checking
>
> per-submitter count before invoking fork, execute, etc.
>
> ?
>
> -Doug
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
?




-- 
Cheers,
?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160317/b60dda5c/attachment.html>

From rk at rkuhn.info  Thu Mar 17 17:32:48 2016
From: rk at rkuhn.info (Roland Kuhn)
Date: Thu, 17 Mar 2016 22:32:48 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
	<CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
	<E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
Message-ID: <51CA7948-D22D-43F4-A2CE-DC4CA41ABB99@rkuhn.info>

The point of discussion is that ?time of task submission? is not nearly as absolute as you make it sound: even counting a single queue?s elements only gives an estimate of the queue length at some unspecified time in the past, and across CPU cores the situation does not get better. What this boils down to is that formulating an absolute upper bound is not possible without heavy coordination overhead (basically removing scalability), an upper bound would always need to be imprecise?and even then it would have quite some impact on overall performance.

Regards,

Roland

> 17 mar 2016 kl. 22:08 skrev Markus KARG <markus at headcrashing.eu>:
> 
> I don?t want to _monitor_ queues, but my proposal was to _query_ for their current lengths at time of task submission.
>  
> Von: Viktor Klang <mailto:viktor.klang at gmail.com>
> Gesendet: Mittwoch, 16. M?rz 2016 13:09
> An: Markus KARG <mailto:markus at headcrashing.eu>
> Cc: concurrency-interest <mailto:concurrency-interest at cs.oswego.edu>
> Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor
>  
>  
>  
> On Tue, Mar 15, 2016 at 10:12 PM, Markus KARG <markus at headcrashing.eu <mailto:markus at headcrashing.eu>> wrote:
>  
> Well? each thread has a queue, so we could sum up the number of task in each. What point do I miss?
>  
> That you can only observe one queue at a time, and unless you pause all consumers and producers, you
> 'll never be able to get a consistent number unless by chance. (Remembering the old Queuing Theory point that queues spend most of their time either full or empty)
>  
>  
>  
> Von: Viktor Klang <mailto:viktor.klang at gmail.com>
> Gesendet: Dienstag, 15. M?rz 2016 20:18
> An: Markus KARG <mailto:markus at headcrashing.eu>
> Cc: Doug Lea <mailto:dl at cs.oswego.edu>; concurrency-interest <mailto:concurrency-interest at cs.oswego.edu>
> Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor
>  
> ?
> 
> 
> On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu <mailto:markus at headcrashing.eu>> wrote:
> >
> > Doug, with ?global Queue length? I did not mean ?length of the global Queue? but ?sum of lenghts of all queues?. ??
> But there is no such thing. Think about it. :-)
> 
> >  
> >
> > So do you propose to _wrap_ the Executor by the application programmer, or  is this a use case for the discussed Predicate?
> >
> >  
> >
> > Thanks
> >
> > -Markus
> >
> >  
> >
> > Von: Doug Lea
> > Gesendet: Dienstag, 15. M?rz 2016 18:23
> > An: Markus KARG; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
> > Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool constructor
> >
> >  
> >
> > On 03/15/2016 01:12 PM, Markus KARG wrote:
> >
> > > Sorry if I chime in or this already was discussed, but I did not follow the
> >
> > > thread from the beginning: I think it would be great if a work stealing executor
> >
> > > could be configured for a maximum global queue length, so when adding more work
> >
> > > it will throw RejectedExecutionException in case the global queue length is
> >
> > > exceeded but no more workers may be allocated.
> >
> > > 
> >
> >  
> >
> > There is no global queue, so no global length.
> >
> > But you can layer similar control by invoking
> >
> > ForkJoinTask.getQueuedTaskCount and checking
> >
> > per-submitter count before invoking fork, execute, etc.
> >
> >  
> >
> > -Doug
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> >
> 
>  
> 
> 
>  
> -- 
> Cheers,
> ?
>  
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160317/c9f5c8fb/attachment-0001.html>

From markus at headcrashing.eu  Thu Mar 17 18:04:22 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Thu, 17 Mar 2016 23:04:22 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <51CA7948-D22D-43F4-A2CE-DC4CA41ABB99@rkuhn.info>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
	<CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
	<E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
	<51CA7948-D22D-43F4-A2CE-DC4CA41ABB99@rkuhn.info>
Message-ID: <E1agg1k-00032z-2N@smtprelay05.ispgateway.de>

I see a strong difference between ?impossible? and ?inaccurate? or ?having performance impacts? actually.

Von: Roland Kuhn
Gesendet: Donnerstag, 17. M?rz 2016 22:32
An: Markus KARG
Cc: ?iktor Klang; concurrency-interest
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor

The point of discussion is that ?time of task submission? is not nearly as absolute as you make it sound: even counting a single queue?s elements only gives an estimate of the queue length at some unspecified time in the past, and across CPU cores the situation does not get better. What this boils down to is that formulating an absolute upper bound is not possible without heavy coordination overhead (basically removing scalability), an upper bound would always need to be imprecise?and even then it would have quite some impact on overall performance.

Regards,

Roland

17 mar 2016 kl. 22:08 skrev Markus KARG <markus at headcrashing.eu>:

I don?t want to _monitor_ queues, but my proposal was to _query_ for their current lengths at time of task submission.
?
Von:?Viktor Klang
Gesendet:?Mittwoch, 16. M?rz 2016 13:09
An:?Markus KARG
Cc:?concurrency-interest
Betreff:?Re: [concurrency-interest] Customized ForkJoinPool constructor
?
?
?
On Tue, Mar 15, 2016 at 10:12 PM, Markus KARG <markus at headcrashing.eu> wrote:
?
Well? each thread has a queue, so we could sum up the number of task in each. What point do I miss?
?
That you can only observe one queue at a time, and unless you pause all consumers and producers, you
'll never be able to get a consistent number unless by chance. (Remembering the old Queuing Theory point that queues spend most of their time either full or empty)
?
?
?
Von:?Viktor Klang
Gesendet:?Dienstag, 15. M?rz 2016 20:18
An:?Markus KARG
Cc:?Doug Lea;?concurrency-interest
Betreff:?Re: [concurrency-interest] Customized ForkJoinPool constructor
?
?

On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu> wrote:
>
> Doug, with ?global Queue length? I did not mean ?length of the global Queue? but ?sum of lenghts of all queues?.???
But there is no such thing. Think about it. :-)
> ?
>
> So do you propose to _wrap_ the Executor by the application programmer, or ?is this a use case for the discussed Predicate?
>
> ?
>
> Thanks
>
> -Markus
>
> ?
>
> Von: Doug Lea
> Gesendet: Dienstag, 15. M?rz 2016 18:23
> An: Markus KARG;?concurrency-interest at cs.oswego.edu
> Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool constructor
>
> ?
>
> On 03/15/2016 01:12 PM, Markus KARG wrote:
>
> > Sorry if I chime in or this already was discussed, but I did not follow the
>
> > thread from the beginning: I think it would be great if a work stealing executor
>
> > could be configured for a maximum global queue length, so when adding more work
>
> > it will throw RejectedExecutionException in case the global queue length is
>
> > exceeded but no more workers may be allocated.
>
> >?
>
> ?
>
> There is no global queue, so no global length.
>
> But you can layer similar control by invoking
>
> ForkJoinTask.getQueuedTaskCount and checking
>
> per-submitter count before invoking fork, execute, etc.
>
> ?
>
> -Doug
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
>?Concurrency-interest at cs.oswego.edu
>?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
?



?
--?
Cheers,
?
?
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
?? ?- Sheldon Cooper (The Big Bang Theory)


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160317/13ab0020/attachment.html>

From rk at rkuhn.info  Fri Mar 18 02:47:44 2016
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 18 Mar 2016 07:47:44 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1agg1k-00032z-2N@smtprelay05.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
	<CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
	<E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
	<51CA7948-D22D-43F4-A2CE-DC4CA41ABB99@rkuhn.info>
	<E1agg1k-00032z-2N@smtprelay05.ispgateway.de>
Message-ID: <644BF36E-EC50-4E57-95EF-4390162EEC8D@rkuhn.info>

What you neglect in this ?argument? is that that depends very much on the boundary conditions: in the context of the ForkJoinPool the global count is not available (so it is impossible). Making it available would completely alter the performance and in particular the scalability characteristics, making the hypothetical result something that is no longer described by the name ForkJoinPool?it would be an entirely different thread pool. Implementing something that scales across CPU sockets requires this precise trade-off, this is inherent to the problem that is being solved.

Regards,

Roland

> 17 mar 2016 kl. 23:04 skrev Markus KARG <markus at headcrashing.eu>:
> 
> I see a strong difference between ?impossible? and ?inaccurate? or ?having performance impacts? actually.
>  
> Von: Roland Kuhn <mailto:rk at rkuhn.info>
> Gesendet: Donnerstag, 17. M?rz 2016 22:32
> An: Markus KARG <mailto:markus at headcrashing.eu>
> Cc: ?iktor Klang <mailto:viktor.klang at gmail.com>; concurrency-interest <mailto:concurrency-interest at cs.oswego.edu>
> Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor
>  
> The point of discussion is that ?time of task submission? is not nearly as absolute as you make it sound: even counting a single queue?s elements only gives an estimate of the queue length at some unspecified time in the past, and across CPU cores the situation does not get better. What this boils down to is that formulating an absolute upper bound is not possible without heavy coordination overhead (basically removing scalability), an upper bound would always need to be imprecise?and even then it would have quite some impact on overall performance.
>  
> Regards,
>  
> Roland
>  
> 17 mar 2016 kl. 22:08 skrev Markus KARG <markus at headcrashing.eu <mailto:markus at headcrashing.eu>>:
>  
> I don?t want to _monitor_ queues, but my proposal was to _query_ for their current lengths at time of task submission.
>  
> Von: Viktor Klang <mailto:viktor.klang at gmail.com>
> Gesendet: Mittwoch, 16. M?rz 2016 13:09
> An: Markus KARG <mailto:markus at headcrashing.eu>
> Cc: concurrency-interest <mailto:concurrency-interest at cs.oswego.edu>
> Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor
>  
>  
>  
> On Tue, Mar 15, 2016 at 10:12 PM, Markus KARG <markus at headcrashing.eu <mailto:markus at headcrashing.eu>> wrote:
>  
> Well? each thread has a queue, so we could sum up the number of task in each. What point do I miss?
>  
> That you can only observe one queue at a time, and unless you pause all consumers and producers, you
> 'll never be able to get a consistent number unless by chance. (Remembering the old Queuing Theory point that queues spend most of their time either full or empty)
>  
>  
>  
> Von: Viktor Klang <mailto:viktor.klang at gmail.com>
> Gesendet: Dienstag, 15. M?rz 2016 20:18
> An: Markus KARG <mailto:markus at headcrashing.eu>
> Cc: Doug Lea <mailto:dl at cs.oswego.edu>; concurrency-interest <mailto:concurrency-interest at cs.oswego.edu>
> Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor
>  
> ?
> 
> On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu <mailto:markus at headcrashing.eu>> wrote:
> >
> > Doug, with ?global Queue length? I did not mean ?length of the global Queue? but ?sum of lenghts of all queues?. ??
> But there is no such thing. Think about it. :-)
> >  
> >
> > So do you propose to _wrap_ the Executor by the application programmer, or  is this a use case for the discussed Predicate?
> >
> >  
> >
> > Thanks
> >
> > -Markus
> >
> >  
> >
> > Von: Doug Lea
> > Gesendet: Dienstag, 15. M?rz 2016 18:23
> > An: Markus KARG; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
> > Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool constructor
> >
> >  
> >
> > On 03/15/2016 01:12 PM, Markus KARG wrote:
> >
> > > Sorry if I chime in or this already was discussed, but I did not follow the
> >
> > > thread from the beginning: I think it would be great if a work stealing executor
> >
> > > could be configured for a maximum global queue length, so when adding more work
> >
> > > it will throw RejectedExecutionException in case the global queue length is
> >
> > > exceeded but no more workers may be allocated.
> >
> > > 
> >
> >  
> >
> > There is no global queue, so no global length.
> >
> > But you can layer similar control by invoking
> >
> > ForkJoinTask.getQueuedTaskCount and checking
> >
> > per-submitter count before invoking fork, execute, etc.
> >
> >  
> >
> > -Doug
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >  
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> >
>  
> 
> 
>  
> -- 
> Cheers,
> ?
>  
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>  
> --
> I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
>     - Sheldon Cooper (The Big Bang Theory)

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160318/fb01930b/attachment-0001.html>

From viktor.klang at gmail.com  Fri Mar 18 04:30:52 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Fri, 18 Mar 2016 09:30:52 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
	<CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
	<E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
Message-ID: <CANPzfU92kYWXkJmr9TAqLkbzDj=CE07U7yPaX2MD5hO=EAPs0A@mail.gmail.com>

I didn't say anything about monitoring.

-- 
Cheers,
?
On Mar 17, 2016 10:08 PM, "Markus KARG" <markus at headcrashing.eu> wrote:

> I don?t want to _*monitor*_ queues, but my proposal was to _*query*_ for
> their current lengths at time of task submission.
>
>
>
> *Von: *Viktor Klang <viktor.klang at gmail.com>
> *Gesendet: *Mittwoch, 16. M?rz 2016 13:09
> *An: *Markus KARG <markus at headcrashing.eu>
> *Cc: *concurrency-interest <concurrency-interest at cs.oswego.edu>
> *Betreff: *Re: [concurrency-interest] Customized ForkJoinPool constructor
>
>
>
>
>
>
>
> On Tue, Mar 15, 2016 at 10:12 PM, Markus KARG <markus at headcrashing.eu>
> wrote:
>
>
>
> Well? each thread has a queue, so we could sum up the number of task in
> each. What point do I miss?
>
>
>
> That you can only observe one queue at a time, and unless you pause all
> consumers and producers, you
>
> 'll never be able to get a consistent number unless by chance.
> (Remembering the old Queuing Theory point that queues spend most of their
> time either full or empty)
>
>
>
>
>
>
>
> *Von: *Viktor Klang <viktor.klang at gmail.com>
> *Gesendet: *Dienstag, 15. M?rz 2016 20:18
> *An: *Markus KARG <markus at headcrashing.eu>
> *Cc: *Doug Lea <dl at cs.oswego.edu>; concurrency-interest
> <concurrency-interest at cs.oswego.edu>
> *Betreff: *Re: [concurrency-interest] Customized ForkJoinPool constructor
>
>
>
> ?
>
>
> On Mar 15, 2016 7:57 PM, "Markus KARG" <markus at headcrashing.eu> wrote:
> >
> > Doug, with ?global Queue length? I did not mean ?length of the global
> Queue? but ?sum of lenghts of all queues?. ??
>
> But there is no such thing. Think about it. :-)
>
> >
> >
> > So do you propose to _wrap_ the Executor by the application programmer,
> or  is this a use case for the discussed Predicate?
> >
> >
> >
> > Thanks
> >
> > -Markus
> >
> >
> >
> > Von: Doug Lea
> > Gesendet: Dienstag, 15. M?rz 2016 18:23
> > An: Markus KARG; concurrency-interest at cs.oswego.edu
> > Betreff: Re: AW: [concurrency-interest] Customized ForkJoinPool
> constructor
> >
> >
> >
> > On 03/15/2016 01:12 PM, Markus KARG wrote:
> >
> > > Sorry if I chime in or this already was discussed, but I did not
> follow the
> >
> > > thread from the beginning: I think it would be great if a work
> stealing executor
> >
> > > could be configured for a maximum global queue length, so when adding
> more work
> >
> > > it will throw RejectedExecutionException in case the global queue
> length is
> >
> > > exceeded but no more workers may be allocated.
> >
> > >
> >
> >
> >
> > There is no global queue, so no global length.
> >
> > But you can layer similar control by invoking
> >
> > ForkJoinTask.getQueuedTaskCount and checking
> >
> > per-submitter count before invoking fork, execute, etc.
> >
> >
> >
> > -Doug
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
>
>
>
>
> --
>
> Cheers,
>
> ?
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160318/dbf8da9d/attachment.html>

From william.louth at jinspired.com  Fri Mar 18 06:31:45 2016
From: william.louth at jinspired.com (William Louth (JINSPIRED.COM))
Date: Fri, 18 Mar 2016 11:31:45 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <CANPzfU92kYWXkJmr9TAqLkbzDj=CE07U7yPaX2MD5hO=EAPs0A@mail.gmail.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56E84515.7030304@cs.oswego.edu>
	<E1aftjJ-0000AG-Gr@smtprelay02.ispgateway.de>
	<CANPzfU9W_WntELYeZTQ06xKrZD6kyjpnsqQYsjdQrsR+qwq=tg@mail.gmail.com>
	<E1afwGC-0005Zi-0s@smtprelay06.ispgateway.de>
	<CANPzfU-OLOG_VoHWy0YmEsZ8aeASe7cbFeJEduRCDXWrMuzNvA@mail.gmail.com>
	<E1agf9r-0004rq-Qi@smtprelay05.ispgateway.de>
	<CANPzfU92kYWXkJmr9TAqLkbzDj=CE07U7yPaX2MD5hO=EAPs0A@mail.gmail.com>
Message-ID: <56EBD911.7090303@jinspired.com>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160318/d9bcfb65/attachment-0001.html>

From dl at cs.oswego.edu  Fri Mar 18 09:08:58 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 18 Mar 2016 09:08:58 -0400
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
Message-ID: <56EBFDEA.5020900@cs.oswego.edu>


Backing up to re-answer your initial question more constructively:

On 03/15/2016 01:12 PM, Markus KARG wrote:
> I think it would be great if a work stealing executor
> could be configured for a maximum global queue length,

If you need this kind of global control, you could use ThreadPoolExecutor.
TPE uses a single submission queue, and is thus more controllable,
but less scalable than FJP.

That's the main tradeoff. As threads/cores increase, consistently
maintaining any global state becomes (super-linearly) more costly,
so FJP minimizes central bookkeeping. In some applications, you might
want better control rather than better scalability.

-Doug



From markus at headcrashing.eu  Fri Mar 18 13:29:10 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Fri, 18 Mar 2016 18:29:10 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <56EBFDEA.5020900@cs.oswego.edu>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56EBFDEA.5020900@cs.oswego.edu>
Message-ID: <E1agyCy-0008Rq-AR@smtprelay04.ispgateway.de>

Doug, thank you for this idea. Indeed for our needs (controlling the load induced by particular subsystems hence prevent further task subsmissions into that executor) scalability is not the top priority and a single-queue executor will do. So are there plans to limit the queue length or is there an API that allows us to simply provide something like this without subclassing the executor?

Von: Doug Lea
Gesendet: Freitag, 18. M?rz 2016 14:21
An: concurrency-interest at cs.oswego.edu
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor


Backing up to re-answer your initial question more constructively:

On 03/15/2016 01:12 PM, Markus KARG wrote:
> I think it would be great if a work stealing executor
> could be configured for a maximum global queue length,

If you need this kind of global control, you could use ThreadPoolExecutor.
TPE uses a single submission queue, and is thus more controllable,
but less scalable than FJP.

That's the main tradeoff. As threads/cores increase, consistently
maintaining any global state becomes (super-linearly) more costly,
so FJP minimizes central bookkeeping. In some applications, you might
want better control rather than better scalability.

-Doug


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160318/eb1af19b/attachment.html>

From kasperni at gmail.com  Fri Mar 18 15:04:39 2016
From: kasperni at gmail.com (Kasper Nielsen)
Date: Fri, 18 Mar 2016 20:04:39 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <E1agyCy-0008Rq-AR@smtprelay04.ispgateway.de>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56EBFDEA.5020900@cs.oswego.edu>
	<E1agyCy-0008Rq-AR@smtprelay04.ispgateway.de>
Message-ID: <CAPs6153S3bw_0nqFP+F=c7petM_toVaJO3GQtac__WaugcMfSQ@mail.gmail.com>

On 18 March 2016 at 18:29, Markus KARG <markus at headcrashing.eu> wrote:
> Doug, thank you for this idea. Indeed for our needs (controlling the load
> induced by particular subsystems hence prevent further task subsmissions
> into that executor) scalability is not the top priority and a single-queue
> executor will do. So are there plans to limit the queue length or is there
> an API that allows us to simply provide something like this without
> subclassing the executor?

No need to subclass ThreadPoolExecutor

Use one of the constructors that take a blocking queue such as

> new ThreadPoolExecutor(x,x,x,x, new ArrayBlockingQueue(queueLimit))

- Kasper

From dl at cs.oswego.edu  Sat Mar 19 07:20:49 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 19 Mar 2016 07:20:49 -0400
Subject: [concurrency-interest] jdk9 Candidate classes Flow and
 SubmissionPublisher
In-Reply-To: <CAFQxnpHVHRPQBbNSf9raY7okSyUOC85h85pGC9NZc7pNWkg3Hg@mail.gmail.com>
References: <CAFQxnpHVHRPQBbNSf9raY7okSyUOC85h85pGC9NZc7pNWkg3Hg@mail.gmail.com>
Message-ID: <56ED3611.7070205@cs.oswego.edu>

On 03/18/2016 02:22 PM, Marcos Boyington wrote:
> Hi Doug,
>
> So I'm a big fan of the new reactive streams interfaces coming in java9, and I
> know I'm a little bit late to the party as it's already been ratified; but we've
> been playing with the interfaces from http://www.reactive-streams.org/ (on which
> the java9 stuff is based), and we've come up with a couple of interesting issues
> which I wanted to discuss with you.

... and with other reactive-stream contributors on this list.

>
> I see the Flow classes as the equivalent of multi-value ListenableFuture's (or
> CompletableFuture, in java8 terms), with the difference being that it's of
> course multi-valued.  Much like futures, a Processor<T1> can be transformed
> (element-by-element) to Processor<T2>, etc.
>
> The multi-value aspect of course brings some complications, which is where we've
> run into some problems.
>
> The first being value retainment: unlike a future, you can't just cache the
> value of a transformation, because the stream could be very large.

I think you are asking for backlog control? (see below.)

>
> The second being stream cancellation: as you probably know, ListenableFuture
> propagates cancellations (I haven't played with CompletableFuture yet so unsure
> what it does).  This means that if I cancel the result of a transformation, it
> propagates to the original source stream.
>
> Flow.Publisher of course does not have any way to do this, because there is no
> way to "cancel" the stream, only unsubscribe from it. (Cancellations are useful,
> for example, if we have transformToX -> transformToY -> make an RPC to some
> service, and we cancel transformToX).

Not all Publishers will be able to support this, but the
SubmissionPublisher utility class does, so you could use it
as a basis for classes that do this.

>
> A colleague of mine came up with a novel solution to both of these: in essence
> adding a method ~like this to Flow.Publisher:
>
> CompletableFuture<Void> start();
>
> Which solves both problems: it removes the need for caching, because one can
> make certain that all subscribers are added before calling start() (with an
> exception being thrown if a subscriber is added after start()), and it allows
> the stream to be cancelled by calling cancel() on the resulting future.

There are several policy issues here surrounding submissions that occur
before start() is invoked.

Unless you are content with throwing an exception, the publisher must
maintain a replay backlog.

I contemplated also including a ReplayablePublisher utility class that
could be used along with a SubmissionPublisher to deal with many of
these scenarios. But we didn't yet have enough experience about the
range of forms that might be needed: full replay on subscribe?
Bounded caching? Batched catchup? Ideas would be welcome.

-Doug

>
> Of course I understand this wouldn't make it to java9; perhaps it doesn't even
> make sense to add it directly to Publisher, but rather have a new
> ControllablePublisher interface for this.
>
> What are your thoughts?
> Thanks,
> Marcos


From dl at cs.oswego.edu  Sat Mar 19 08:21:50 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 19 Mar 2016 08:21:50 -0400
Subject: [concurrency-interest] CHM replaceAll
In-Reply-To: <619503465.7638117.1456162165970.JavaMail.yahoo@mail.yahoo.com>
References: <619503465.7638117.1456162165970.JavaMail.yahoo.ref@mail.yahoo.com>
	<619503465.7638117.1456162165970.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56ED445E.10208@cs.oswego.edu>


Sorry; I let this sit as an issue about which I didn't have much
of an opinion, to see if anyone else did, but then forgot to
revisit it until now...

On 02/22/2016 12:29 PM, Ben Manes wrote:
> ConcurrentHashMap#replaceAll(bifunction) performs the computation
> optimistically per key, retrying until successful. This is a valid
> implementation, but slightly surprising due to the map's ability to perform
> the per-key operations pessimistically. In the case of a map holding a
> resource that should be explicitly closed, these races could result in a
> leak. That of course is a user error, but one that I think is easily
> corrected without a negative loss for the hash table. This of course is more
> important for my case of a cache, where I provide a custom implementation for
> a variety of reasons.

One minor argument against this is that doing so would make it subtly
incompatible with similar operations on Streams (java.util.stream).

>
> The request is to use computeIfPresent per key. The function would have to be
>  decorated with a lambda that disallows null values.

So, if you care about this issue, you could instead use compute or
computeIfPresent in a loop instead of replaceAll.

> I suspect this single allocation is preferable to the cost of retrying on a
> conflict. That allocation could be removed with a more complex replacement,
> but that is probably unnecessary.
>

If there were a compelling case to do this, we'd probably want to do it
as efficiently as possible, unlayering it as another variant of the "compute"
code.

-Doug


From akarnokd at gmail.com  Sat Mar 19 08:30:11 2016
From: akarnokd at gmail.com (=?UTF-8?Q?D=C3=A1vid_Karnok?=)
Date: Sat, 19 Mar 2016 13:30:11 +0100
Subject: [concurrency-interest] jdk9 Candidate classes Flow and
	SubmissionPublisher
In-Reply-To: <56ED3611.7070205@cs.oswego.edu>
References: <CAFQxnpHVHRPQBbNSf9raY7okSyUOC85h85pGC9NZc7pNWkg3Hg@mail.gmail.com>
	<56ED3611.7070205@cs.oswego.edu>
Message-ID: <CAAWwtm9Rm1giODPj-4E0b4Z4+cWVmaJND4=hhYuSg2fLhQL3Sg@mail.gmail.com>

Hi Marcos,

2016-03-19 12:20 GMT+01:00 Doug Lea <dl at cs.oswego.edu>:

> On 03/18/2016 02:22 PM, Marcos Boyington wrote:
>
>> Hi Doug,
>>
>> So I'm a big fan of the new reactive streams interfaces coming in java9,
>> and I
>> know I'm a little bit late to the party as it's already been ratified;
>> but we've
>> been playing with the interfaces from http://www.reactive-streams.org/
>> (on which
>> the java9 stuff is based), and we've come up with a couple of interesting
>> issues
>> which I wanted to discuss with you.
>>
>
> ... and with other reactive-stream contributors on this list.
>
> such as myself.


>
>> I see the Flow classes as the equivalent of multi-value
>> ListenableFuture's (or
>> CompletableFuture, in java8 terms), with the difference being that it's of
>> course multi-valued.
>
>
It's a bit of a stretch but okay.


> Much like futures, a Processor<T1> can be transformed
>> (element-by-element) to Processor<T2>, etc
>
>
Processor itself is some sort of transformation from T to U, element-wise.
But transforming Processor<T1, T2> to Processor<T3, T4> is more involved as
it requires a mapping from T3 to T1 and T2 to T4.

>
>>
>
The multi-value aspect of course brings some complications, which is where
>> we've
>> run into some problems.
>
> The first being value retainment: unlike a future, you can't just cache the
>> value of a transformation, because the stream could be very large.
>>
>
> I think you are asking for backlog control? (see below.)
>
> I guess you mean caching where some source is evaluated once and then
replayed to subscribers online/offline without triggering the evaluation
all over again. Caching long streams or large data needs consideration and
handling, such as bounded caching (fixed amount, fixed timespan, etc.)


>
>> The second being stream cancellation: as you probably know,
>> ListenableFuture
>> propagates cancellations (I haven't played with CompletableFuture yet so
>> unsure
>> what it does).  This means that if I cancel the result of a
>> transformation, it
>> propagates to the original source stream.
>>
>
Yes.

>
>> Flow.Publisher of course does not have any way to do this, because there
>> is no
>> way to "cancel" the stream, only unsubscribe from it. (Cancellations are
>> useful,
>> for example, if we have transformToX -> transformToY -> make an RPC to
>> some
>> service, and we cancel transformToX).
>>
>
This is what the Subscription interface is for. A Publisher creates a
Subscription, calls onSubscribe on the Subscriber and then the Publisher
watches its Subscription (which usually a subclass with extra behavior) to
see if the downstream Subscriber had enough. The downstream subscriber then
can call cancel() at any time. Of course, if you chain operations, the
cancellation has to be chained as well.



> Not all Publishers will be able to support this, but the
> SubmissionPublisher utility class does, so you could use it
> as a basis for classes that do this.
>
>
>> A colleague of mine came up with a novel solution to both of these: in
>> essence
>> adding a method ~like this to Flow.Publisher:
>>
>> CompletableFuture<Void> start();
>>
>> No. I feel you misunderstand the Publisher. It represents a deferred
emission of values and if you have a Publisher (usually) nothing happens
until you subscribe to it. Thus, there is no sense cancelling just a
Publisher.


> Which solves both problems: it removes the need for caching, because one
>> can
>> make certain that all subscribers are added before calling start() (with
>> an
>> exception being thrown if a subscriber is added after start()), and it
>> allows
>> the stream to be cancelled by calling cancel() on the resulting future.
>>
>
>
What you describe here is a cold-hot Publisher conversion indeed may use an
extra imperative method to establish the connection. But not all Publishers
need this feature. In addition, your method returns a future which doesn't
work with synchronous cancellation in a multicast use.


> There are several policy issues here surrounding submissions that occur
> before start() is invoked.
>
> Unless you are content with throwing an exception, the publisher must
> maintain a replay backlog.
>
> I contemplated also including a ReplayablePublisher utility class that
> could be used along with a SubmissionPublisher to deal with many of
> these scenarios. But we didn't yet have enough experience about the
> range of forms that might be needed: full replay on subscribe?
> Bounded caching? Batched catchup? Ideas would be welcome.
>
> -Doug
>
> Just use Reactor-Core or RxJava 2.x (as inspiration). The issues mentioned
so far are neatly handled in them. (Plus, there is also
https://github.com/akarnokd/RxJavaUtilConcurrentFlow )


>> Of course I understand this wouldn't make it to java9; perhaps it doesn't
>> even
>> make sense to add it directly to Publisher, but rather have a new
>> ControllablePublisher interface for this.
>>
> What are your thoughts?
>>
>
I don't think Java 9 should have too many utilities over Flow for two
reasons: 1) it may take years to improve upon them whereas libraries allow
much frequent updates 2) reuse vs. performance where I'm afraid many start
thinking in chains of SubmissionPublishers with mandatory async boundaries,
queues and blocking.


> Thanks,
>> Marcos
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Best regards,
David Karnok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160319/e74a7289/attachment-0001.html>

From rk at rkuhn.info  Sat Mar 19 09:13:00 2016
From: rk at rkuhn.info (Roland Kuhn)
Date: Sat, 19 Mar 2016 14:13:00 +0100
Subject: [concurrency-interest] jdk9 Candidate classes Flow and
	SubmissionPublisher
In-Reply-To: <CAAWwtm9Rm1giODPj-4E0b4Z4+cWVmaJND4=hhYuSg2fLhQL3Sg@mail.gmail.com>
References: <CAFQxnpHVHRPQBbNSf9raY7okSyUOC85h85pGC9NZc7pNWkg3Hg@mail.gmail.com>
	<56ED3611.7070205@cs.oswego.edu>
	<CAAWwtm9Rm1giODPj-4E0b4Z4+cWVmaJND4=hhYuSg2fLhQL3Sg@mail.gmail.com>
Message-ID: <53DD4921-0D78-493D-8C5B-8A1126D11B7E@rkuhn.info>


> 19 mar 2016 kl. 13:30 skrev D?vid Karnok <akarnokd at gmail.com>:
> 
> Hi Marcos,
> 
> 2016-03-19 12:20 GMT+01:00 Doug Lea <dl at cs.oswego.edu <mailto:dl at cs.oswego.edu>>:
> On 03/18/2016 02:22 PM, Marcos Boyington wrote:
> Hi Doug,
> 
> So I'm a big fan of the new reactive streams interfaces coming in java9, and I
> know I'm a little bit late to the party as it's already been ratified; but we've
> been playing with the interfaces from http://www.reactive-streams.org/ <http://www.reactive-streams.org/> (on which
> the java9 stuff is based), and we've come up with a couple of interesting issues
> which I wanted to discuss with you.
> 
> ... and with other reactive-stream contributors on this list.
> 
> such as myself.
>  
> 
> I see the Flow classes as the equivalent of multi-value ListenableFuture's (or
> CompletableFuture, in java8 terms), with the difference being that it's of
> course multi-valued.  

This is not a helpful way to look at this abstraction, you will find yourself disappointed and confused if you insist on setting out from this starting point.

A Publisher represents the ability to create a stream of elements that can be obtained asynchronously. A Subscriber represents an element stream receiver that is in full control of its incoming data rate. The Subscription is the link between these two via which the data exchange is mediated.

This means that Reactive Streams are inherently about a communication protocol, whereas composable Futures model dependency-driven evaluation of computation chains for a single value?these are very different abstractions with very different goals.

> 
> It's a bit of a stretch but okay.
>  
> Much like futures, a Processor<T1> can be transformed
> (element-by-element) to Processor<T2>, etc
> 
> Processor itself is some sort of transformation from T to U, element-wise.

Small correction: a Processor consumes elements of one type (by virtue of being a Subscriber) and it produces elements of a possibly different type (by virtue of being a Publisher), but there is no prescription about the relationship between the ingested and emitted data streams?they could be entirely unrelated and they often are not 1:1 element transformations (for a very simple example consider the `filter()` combinator of any stream processing library near you).

> But transforming Processor<T1, T2> to Processor<T3, T4> is more involved as it requires a mapping from T3 to T1 and T2 to T4. 
>  
> 
> The multi-value aspect of course brings some complications, which is where we've
> run into some problems. 
> The first being value retainment: unlike a future, you can't just cache the
> value of a transformation, because the stream could be very large.
> 
> I think you are asking for backlog control? (see below.)
> 
> I guess you mean caching where some source is evaluated once and then replayed to subscribers online/offline without triggering the evaluation all over again. Caching long streams or large data needs consideration and handling, such as bounded caching (fixed amount, fixed timespan, etc.)
>  
> 
> The second being stream cancellation: as you probably know, ListenableFuture
> propagates cancellations (I haven't played with CompletableFuture yet so unsure
> what it does).  This means that if I cancel the result of a transformation, it
> propagates to the original source stream.
> 
> Yes. 
> 
> Flow.Publisher of course does not have any way to do this, because there is no
> way to "cancel" the stream, only unsubscribe from it. (Cancellations are useful,
> for example, if we have transformToX -> transformToY -> make an RPC to some
> service, and we cancel transformToX).
> 
> This is what the Subscription interface is for. A Publisher creates a Subscription, calls onSubscribe on the Subscriber and then the Publisher watches its Subscription (which usually a subclass with extra behavior) to see if the downstream Subscriber had enough. The downstream subscriber then can call cancel() at any time. Of course, if you chain operations, the cancellation has to be chained as well.

Exactly: the propagation of cancellation goes beyond the pure Publisher?Subscriber relationship that is specified for Reactive Streams, but by common sense all known implementations that support chains of Processors also make sure to pass along cancellation?just like completion or failure are passed in the other direction.

> 
>  
> Not all Publishers will be able to support this, but the
> SubmissionPublisher utility class does, so you could use it
> as a basis for classes that do this.
> 
> 
> A colleague of mine came up with a novel solution to both of these: in essence
> adding a method ~like this to Flow.Publisher:
> 
> CompletableFuture<Void> start();
> 
> No. I feel you misunderstand the Publisher. It represents a deferred emission of values and if you have a Publisher (usually) nothing happens until you subscribe to it. Thus, there is no sense cancelling just a Publisher.
>  
> Which solves both problems: it removes the need for caching, because one can
> make certain that all subscribers are added before calling start() (with an
> exception being thrown if a subscriber is added after start()), and it allows
> the stream to be cancelled by calling cancel() on the resulting future.
> 
> 
> What you describe here is a cold-hot Publisher conversion indeed may use an extra imperative method to establish the connection. But not all Publishers need this feature. In addition, your method returns a future which doesn't work with synchronous cancellation in a multicast use.
>  
> There are several policy issues here surrounding submissions that occur
> before start() is invoked.
> 
> Unless you are content with throwing an exception, the publisher must
> maintain a replay backlog.
> 
> I contemplated also including a ReplayablePublisher utility class that
> could be used along with a SubmissionPublisher to deal with many of
> these scenarios. But we didn't yet have enough experience about the
> range of forms that might be needed: full replay on subscribe?
> Bounded caching? Batched catchup? Ideas would be welcome.
> 
> -Doug
> 
> Just use Reactor-Core or RxJava 2.x (as inspiration). The issues mentioned so far are neatly handled in them. (Plus, there is also https://github.com/akarnokd/RxJavaUtilConcurrentFlow <https://github.com/akarnokd/RxJavaUtilConcurrentFlow> )

Since this list has been started: you may want to look at Akka Streams <http://doc.akka.io/docs/akka/2.4.2/scala/stream/stream-introduction.html> (possible also the design goals <http://doc.akka.io/docs/akka/2.4.2/general/stream/stream-design.html> or the quickstart guide <http://doc.akka.io/docs/akka/2.4.2/scala/stream/stream-quickstart.html>) for a rather different interpretation of the user-level API that still is solidly grounded in the Reactive Streams contract.

Regards,

Roland

> 
> 
> Of course I understand this wouldn't make it to java9; perhaps it doesn't even
> make sense to add it directly to Publisher, but rather have a new
> ControllablePublisher interface for this.
> What are your thoughts?
> 
> I don't think Java 9 should have too many utilities over Flow for two reasons: 1) it may take years to improve upon them whereas libraries allow much frequent updates 2) reuse vs. performance where I'm afraid many start thinking in chains of SubmissionPublishers with mandatory async boundaries, queues and blocking.
>  
> Thanks,
> Marcos
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> 
> -- 
> Best regards,
> David Karnok
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160319/d971493c/attachment-0001.html>

From godmar at gmail.com  Sat Mar 19 10:04:46 2016
From: godmar at gmail.com (Godmar Back)
Date: Sat, 19 Mar 2016 10:04:46 -0400
Subject: [concurrency-interest] Why don't FJP workers steal safe but
	unrelated tasks during Task.join?
Message-ID: <CAB4+JYLAgnFXOgrJ491pBat8W3kPN=KD_baDOZeYuEmgLAnz6A@mail.gmail.com>

Hi, this is question about the FJP implementation.

I noticed that worker threads will help only certain other tasks when they
are joining a task that is currently in progress before blocking on the
task being joined.  I understand that this is, in part, for safety reasons
- it is simply unsafe to help with certain tasks when such attempts could
lead to execution deadlock (starting to work on a task that then attempts
to join a task the helping thread has commenced, but not finished).

But there are unrelated tasks that would be safe to work on while waiting
for a to-be-joined task to complete, yet the FJP workers do not attempt to
steal them.  My question is why.

In my own threadpool implementation, I made the observation that a strategy
in which workers will steal any safe task instead of blocking on a
to-be-joined task leads to very poor performance (and to make matters
worse, creates widely varying performance even with the very same task
workload in multiple runs). Specifically, if unrelated tasks are stolen, a
chain of task execution/joining/helping/... occurs in which most worker
threads will eventually run out of tasks to steal, resulting in a tail of
serial execution to untangle these tasks. This is for a fully-strict
implementation of quicksort, btw. It's a tail of serial execution because
my pool does not employ compensatory threads - if it did, I'd likely see
their numbers go up rapidly.

My question is: how did we learn that helping with tasks that are unrelated
to the task being joined is a bad idea, or is there a way to do that? I
believe it is not addressed in the implementation notes in the FJP
implementation, which focus only on the safety aspect.

 - Godmar
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160319/d6a1e351/attachment.html>

From markus at headcrashing.eu  Sun Mar 20 03:50:45 2016
From: markus at headcrashing.eu (Markus KARG)
Date: Sun, 20 Mar 2016 08:50:45 +0100
Subject: [concurrency-interest] Customized ForkJoinPool constructor
In-Reply-To: <CAPs6153S3bw_0nqFP+F=c7petM_toVaJO3GQtac__WaugcMfSQ@mail.gmail.com>
References: <56E6C2F0.1020600@cs.oswego.edu> <56E830CE.2080308@cs.oswego.edu>
	<E1afsVt-0000lt-HM@smtprelay05.ispgateway.de>
	<56EBFDEA.5020900@cs.oswego.edu>
	<E1agyCy-0008Rq-AR@smtprelay04.ispgateway.de>
	<CAPs6153S3bw_0nqFP+F=c7petM_toVaJO3GQtac__WaugcMfSQ@mail.gmail.com>
Message-ID: <E1ahY8J-0007UH-0C@smtprelay01.ispgateway.de>

Great! ??
-Markus

Von: Kasper Nielsen
Gesendet: Freitag, 18. M?rz 2016 20:04
An: Markus KARG
Cc: concurrency-interest at cs.oswego.edu
Betreff: Re: [concurrency-interest] Customized ForkJoinPool constructor

On 18 March 2016 at 18:29, Markus KARG <markus at headcrashing.eu> wrote:
> Doug, thank you for this idea. Indeed for our needs (controlling the load
> induced by particular subsystems hence prevent further task subsmissions
> into that executor) scalability is not the top priority and a single-queue
> executor will do. So are there plans to limit the queue length or is there
> an API that allows us to simply provide something like this without
> subclassing the executor?

No need to subclass ThreadPoolExecutor

Use one of the constructors that take a blocking queue such as

> new ThreadPoolExecutor(x,x,x,x, new ArrayBlockingQueue(queueLimit))

- Kasper

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160320/fe1966aa/attachment.html>

From dl at cs.oswego.edu  Sun Mar 20 08:09:11 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 20 Mar 2016 08:09:11 -0400 (EDT)
Subject: [concurrency-interest] Why don't FJP workers steal safe but
 unrelated tasks during Task.join?
In-Reply-To: <CAB4+JYLAgnFXOgrJ491pBat8W3kPN=KD_baDOZeYuEmgLAnz6A@mail.gmail.com>
References: <CAB4+JYLAgnFXOgrJ491pBat8W3kPN=KD_baDOZeYuEmgLAnz6A@mail.gmail.com>
Message-ID: <46760.69.193.130.195.1458475751.squirrel@altair.cs.oswego.edu>


> My question is: how did we learn that helping with tasks that are
> unrelated
> to the task being joined is a bad idea, or is there a way to do that?

Wait-for paths are in general shortest if joiners only try to steal
back from their stealers; this also avoids deadlock scenarios.
Which is what FJP does (and sounds like what you do as well).

The precise effects are hard to characterize in the presence of randomness,
arbitrary stalls, etc. There has not been much analytic work on this
beyond showing worst cases (wrt deadlock and/or time-space), and to
note that some issues can be evaded by using explicit completions (as in
CountedCompleter that identify tasks that can be performed next without
blocking or search) at the price of more task objects and less pleasant
programming. (These are used inside jdk8 parallel Streams.)

If you are interested in pursuing this, you might read through
the few papers discussing it, starting with the "leap-frogging"
paper in the FJP docs.

-Doug





From dl at cs.oswego.edu  Tue Mar 22 10:49:42 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 22 Mar 2016 10:49:42 -0400
Subject: [concurrency-interest] jdk9 Candidate classes Flow and
 SubmissionPublisher
In-Reply-To: <CAFQxnpG3yV1RFR+nmJADtxse=FuWZTwh5w_7-TPddJpjrDPxrw@mail.gmail.com>
References: <CAFQxnpHVHRPQBbNSf9raY7okSyUOC85h85pGC9NZc7pNWkg3Hg@mail.gmail.com>
	<56ED3611.7070205@cs.oswego.edu>
	<CAFQxnpG3yV1RFR+nmJADtxse=FuWZTwh5w_7-TPddJpjrDPxrw@mail.gmail.com>
Message-ID: <56F15B86.4020001@cs.oswego.edu>

On 03/21/2016 01:50 PM, Marcos Boyington wrote:

>
> Thanks! That makes a lot of sense; but when combining SubmissionPublisher
> with Processor is where things get interesting (and this is ~ what we're
> doing). If we transform a SubmissionPublisher<T> with a Processor<T, T2>, it
> would be nice to call close() on the resulting Processor and have it
> propagate to the source SubmissionPublisher.  Unfortunately, there's no
> shared interface which we can use here.
>
> That is ~ what I was suggesting with ControllablePublisher; an interface
> which is in essence Publisher + AutoCloseable, so that we have a shared
> interface between SubmissionPublisher and any other Publishers which are
> closeable.

As others mentioned, subscription.cancel propagates so that you
(eventually) stop getting items. I gather that you want to close here
to free up resources, but only if the source supports close().
Since you'd need to do type-testing anyway, adding an interface
wouldn't be better than:
   void closeIfCloseable(Object p) {
     if (p instanceof AutoCloseable) ((AutoCloseable)p).close();
   }

And even then, I'm not sure when you'd call this, because there may be
multiple subscribers or potential future subscribers.

>
>
> I contemplated also including a ReplayablePublisher utility class that could
> be used along with a SubmissionPublisher to deal with many of these
> scenarios. But we didn't yet have enough experience about the range of forms
> that might be needed: full replay on subscribe? Bounded caching? Batched
> catchup? Ideas would be welcome.
>
>
> Heh, yah we're having the same type of difficulties - unfortunately I don't
> have any ideas; we've played around with full replay as well as bounded
> caching, but of course each has its disadvantages.

Right. If we knew of a single good API/class that would cover enough
of this ground, we'd probably include it, in the spirit of providing
components that do hard things well. But not.

Also...

On 03/19/2016 08:30 AM, D?vid Karnok wrote:
>
> I don't think Java 9 should have too many utilities over Flow for two
> reasons: 1) it may take years to improve upon them whereas libraries allow
> much frequent updates 2) reuse vs. performance where I'm afraid many start
> thinking in chains of SubmissionPublishers with mandatory async boundaries,
> queues and blocking.

Right. The goal was to include only what j.u.c can do best:
basic async/queueing components that others can build on.
(We even triaged out backlog support and interop with Streams etc.)
Doing only this encounters the usual j.u.c issues about exposing components
that most application programmers will not want to use directly.

-Doug




From viktor.klang at gmail.com  Thu Mar 24 05:47:37 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 24 Mar 2016 10:47:37 +0100
Subject: [concurrency-interest] jdk9 Candidate classes Flow and
	SubmissionPublisher
In-Reply-To: <56F15B86.4020001@cs.oswego.edu>
References: <CAFQxnpHVHRPQBbNSf9raY7okSyUOC85h85pGC9NZc7pNWkg3Hg@mail.gmail.com>
	<56ED3611.7070205@cs.oswego.edu>
	<CAFQxnpG3yV1RFR+nmJADtxse=FuWZTwh5w_7-TPddJpjrDPxrw@mail.gmail.com>
	<56F15B86.4020001@cs.oswego.edu>
Message-ID: <CANPzfU-ApPZDqdSCUA5dWc=pCNTppr=3DFuw1iX6Ezbv_EC6jw@mail.gmail.com>

A great conversation, I hope all questions were answered by previous
posters.

On Tue, Mar 22, 2016 at 3:49 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 03/21/2016 01:50 PM, Marcos Boyington wrote:
>
>
>> Thanks! That makes a lot of sense; but when combining SubmissionPublisher
>> with Processor is where things get interesting (and this is ~ what we're
>> doing). If we transform a SubmissionPublisher<T> with a Processor<T, T2>,
>> it
>> would be nice to call close() on the resulting Processor and have it
>> propagate to the source SubmissionPublisher.  Unfortunately, there's no
>> shared interface which we can use here.
>>
>> That is ~ what I was suggesting with ControllablePublisher; an interface
>> which is in essence Publisher + AutoCloseable, so that we have a shared
>> interface between SubmissionPublisher and any other Publishers which are
>> closeable.
>>
>
> As others mentioned, subscription.cancel propagates so that you
> (eventually) stop getting items. I gather that you want to close here
> to free up resources, but only if the source supports close().
> Since you'd need to do type-testing anyway, adding an interface
> wouldn't be better than:
>   void closeIfCloseable(Object p) {
>     if (p instanceof AutoCloseable) ((AutoCloseable)p).close();
>   }
>
> And even then, I'm not sure when you'd call this, because there may be
> multiple subscribers or potential future subscribers.
>
>
>>
>> I contemplated also including a ReplayablePublisher utility class that
>> could
>> be used along with a SubmissionPublisher to deal with many of these
>> scenarios. But we didn't yet have enough experience about the range of
>> forms
>> that might be needed: full replay on subscribe? Bounded caching? Batched
>> catchup? Ideas would be welcome.
>>
>>
>> Heh, yah we're having the same type of difficulties - unfortunately I
>> don't
>> have any ideas; we've played around with full replay as well as bounded
>> caching, but of course each has its disadvantages.
>>
>
> Right. If we knew of a single good API/class that would cover enough
> of this ground, we'd probably include it, in the spirit of providing
> components that do hard things well. But not.
>
> Also...
>
> On 03/19/2016 08:30 AM, D?vid Karnok wrote:
>
>>
>> I don't think Java 9 should have too many utilities over Flow for two
>> reasons: 1) it may take years to improve upon them whereas libraries allow
>> much frequent updates 2) reuse vs. performance where I'm afraid many start
>> thinking in chains of SubmissionPublishers with mandatory async
>> boundaries,
>> queues and blocking.
>>
>
> Right. The goal was to include only what j.u.c can do best:
> basic async/queueing components that others can build on.
> (We even triaged out backlog support and interop with Streams etc.)
> Doing only this encounters the usual j.u.c issues about exposing components
> that most application programmers will not want to use directly.
>
> -Doug
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160324/62f49a3b/attachment.html>

From dl at cs.oswego.edu  Sat Mar 26 09:45:49 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 26 Mar 2016 09:45:49 -0400
Subject: [concurrency-interest] jdk9 split
Message-ID: <56F6928D.7060200@cs.oswego.edu>


As promised for a while, we split jdk8 vs jdk9 sources in jsr166 CVS;
jdk-9+111 with initial jigsaw support makes it impractical to do
otherwise from here on out.

The concurrency-interest page has updated links and instructions.
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html

Note that if you have been using -Xbootclasspath/p:jsr166.jar,
you will need to instead get jsr166.jar, then jar xf jsr166.jar,
then run java with -Xpatch:jsr166 (using full paths as needed).

Similarly to what we've done in the past, we will keep jdk8-compatible
files in src/jdk8 reconciled with jdk9 updates when possible, at least
until jdk9 release. These still include jdk8 versions of jdk9 additions
(Flow, SubmissionPublisher, CompletableFuture updates), that
you can run on jdk8 with -Xbootclasspath/p:jsr166.jar

You can also get the full source tar.gz, and follow instructions in
build.xml (http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166.tar.gz?view=tar)
There seem to be some glitches with jdk9-jigsaw in jdk-9+111,
including a javadoc problem we temporarily worked around by
posting the jdk8 version of API docs until this is fixed.

Thanks as always to Martin for carrying out most of the logistics.

-Doug

From ppozerov at gmail.com  Sat Mar 26 17:32:31 2016
From: ppozerov at gmail.com (Vladimir Ozerov)
Date: Sun, 27 Mar 2016 00:32:31 +0300
Subject: [concurrency-interest] Can ordered store be reordered with
	subsequent volatile load?
Message-ID: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>

Hi,

I am trying to wrap my head around the following problem. Consider we have
a kind of lightweight locking algorithm between two threads which somewhat
resembles classical Peterson's lock. One thread declares intent to acquire
a lock and then checks whether state of another thread allows it.

The question is: provided very subtle "putOrdered" semantics and no data
dependency between "a" and "b", do I have any guarantees that store and
load will not be reordered in the code below?

int a, b;

boolean tryLock() {
    UNSAFE.putOrdered(a, 1); // Declare intent.

    // No StoreLoad here as store is not volatile.

    if (UNSAFE.getVolatile(b) == 1)) {
        // Reset intent and return false;
    }

    return true;
}

My hope is that ordering could be enforced by the fact that both store and
load in this example are synchronization actions (see old comment from
Doug:
http://cs.oswego.edu/pipermail/concurrency-interest/2011-October/008324.html
).

Vladimir.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160327/6b6ccfd7/attachment.html>

From aleksey.shipilev at oracle.com  Sun Mar 27 06:42:39 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Sun, 27 Mar 2016 13:42:39 +0300
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
Message-ID: <56F7B91F.4000406@oracle.com>

On 03/27/2016 12:32 AM, Vladimir Ozerov wrote:
> I am trying to wrap my head around the following problem. Consider we
> have a kind of lightweight locking algorithm between two threads which
> somewhat resembles classical Peterson's lock. One thread declares intent
> to acquire a lock and then checks whether state of another thread allows it.
> 
> The question is: provided very subtle "putOrdered" semantics and no data
> dependency between "a" and "b", do I have any guarantees that store and
> load will not be reordered in the code below?

No, you don't have these guarantees. acquire/release-es (putOrdered is a
release in disguise) are not sequentially consistent.

In other words, you cannot freely change volatiles to acquire/releases
and hope it does not break code. Famous example: replace volatiles with
acq/rel in IRIW. I think Dekker/Peterson locks require the same
guarantees that IRIW validates.

> int a, b;
> 
> boolean tryLock() {
>     UNSAFE.putOrdered(a, 1); // Declare intent.
> 
>     // No StoreLoad here as store is not volatile.
> 
>     if (UNSAFE.getVolatile(b) == 1)) {
>         // Reset intent and return false;
>     }
> 
>     return true;
> }

Even in the naive barrier interpretation that usually gives stronger
answers, you have:

 [LoadStore|StoreStore]
 a = 1;

 r1 = b;
 [LoadLoad|LoadStore]

Oops.

> My hope is that ordering could be enforced by the fact that both 
> store and load in this example are synchronization actions

Acq/rels are weird in the way they effectively induce synchronizes-with,
but have limited ties in total synchronization order. (This is at odds
with JMM spec as stated, and there is no easy way out: either you relax
SW is-suborder-of SO, and allow acq/rel in SW; or you push acq/rel into
SO and by extension into SW, effectively making them indistinguishable
from volatiles).

My personal rule of thumb is that acq/rel is okay in producer/consumer
scenarios where you can get away with only partial ordering. But in
locks, where you want to reason about multiple threads communicating in
both directions, you nominally need full SC, and the correctness of any
relaxation should be rigorously proved.

Thanks,
-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 836 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160327/390d8a8a/attachment.bin>

From oleksandr.otenko at gmail.com  Mon Mar 28 07:49:40 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 28 Mar 2016 12:49:40 +0100
Subject: [concurrency-interest] Can ordered store be reordered with
	subsequent volatile load?
In-Reply-To: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
Message-ID: <BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>

I think the answer comes from the meaning of ?Ordered? - the store is ordered with respect to what?

This store is underspecified - JMM doesn?t refer to it. Yet, given Aleksey?s answer, it seems to mean you have an hb edge between the store and the preceding operations, but no new edges with the succeeding operations.

To make matters worse, JMM requires synchronizes-with edges, for the observed order of operations to be transitively closed - that is the only way to make conclusions about the order of events observed in two different threads. This means that for putOrdered to make sense one would need an edge between a load of that value and the store. However, the current JMM only talks about synchronization operations that are always part of (total) synchronization order. If you make putOrdered part of synchronization order, it becomes no different from a volatile store. If you make putOrdered not part of synchronization order, you need to modify JMM to allow to synchronize-with operations that are not totally ordered, and specify what orders are not allowed (basically, the difficulty with specifying this in the JMM).

So, whereas Aleksey?s answer explains that volatile load of b can be reordered with putOrdered store of a, there?s still a question of whether the volatile load of b is observed in a deterministic order with the other operations preceding putOrdered store of a. In other words, does putOrdered create edges between all preceding operations and all succeeding operations, or does it only create an order between that single store and the preceding operations.


Alex


> On 26 Mar 2016, at 21:32, Vladimir Ozerov <ppozerov at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to wrap my head around the following problem. Consider we have a kind of lightweight locking algorithm between two threads which somewhat resembles classical Peterson's lock. One thread declares intent to acquire a lock and then checks whether state of another thread allows it.
> 
> The question is: provided very subtle "putOrdered" semantics and no data dependency between "a" and "b", do I have any guarantees that store and load will not be reordered in the code below?
> 
> int a, b;
> 
> boolean tryLock() {
>     UNSAFE.putOrdered(a, 1); // Declare intent.
> 
>     // No StoreLoad here as store is not volatile.
> 
>     if (UNSAFE.getVolatile(b) == 1)) {
>         // Reset intent and return false;
>     }
> 
>     return true;
> }
> 
> My hope is that ordering could be enforced by the fact that both store and load in this example are synchronization actions (see old comment from Doug: http://cs.oswego.edu/pipermail/concurrency-interest/2011-October/008324.html <http://cs.oswego.edu/pipermail/concurrency-interest/2011-October/008324.html>).
> 
> Vladimir.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160328/37689b9a/attachment.html>

From arno.haase at haase-consulting.com  Mon Mar 28 20:50:23 2016
From: arno.haase at haase-consulting.com (Arno Haase)
Date: Tue, 29 Mar 2016 02:50:23 +0200
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
Message-ID: <56F9D14F.9040406@haase-consulting.com>

Here's my understanding of putOrdered - hope it helps.

* putOrdered is outside the JMM in the sense that its guarantees can not
be expressed in terms of hb or sw.

* But both putOrdered and the JMM can be expressed in terms of barriers
- see JSR-133 cookbook. As I understand it, in order to reason about
'putOrdered' you need to reason in terms of barriers, even for things
like volatile access that are covered in the JMM.

* Hotspot does two things for a volatile write.

Firstly, it emits a StoreStore barrier before it, ensuring that no other
write happening before the volatile write will be visible after the
volatile write.

Secondly, it emits a StoreLoad barrier after it, ensuring that no read
operation occurring after the volatile write will be executed before the
volatile write.

* putOrdered requires only the StoreStore barrier to be emitted. Since
the StoreStore barrier colloqually corresponds to 'ordering' and the
StoreLoad barrier to 'visibility' guarantees, one way to look at
putOrdered is that it ensures ordering - hence the name - but not
(immediate) visibility of written values. They are guaranteed to become
visible eventually, but not in the strict sense proscribed by the JMM
for volatile writes.

* Both StoreStore and StoreLoad barriers are superfluous on Intel
processors because they guarantee the corresponding restrictions for all
store operations anyway. But removing the StoreLoad barrier supposedly
makes for speedups on some other architectures.


- Arno


Am 28.03.2016 um 13:49 schrieb Alex Otenko:
> I think the answer comes from the meaning of ?Ordered? - the store is
> ordered with respect to what?
> 
> This store is underspecified - JMM doesn?t refer to it. Yet, given
> Aleksey?s answer, it seems to mean you have an hb edge between the store
> and the preceding operations, but no new edges with the succeeding
> operations.
> 
> To make matters worse, JMM requires synchronizes-with edges, for the
> observed order of operations to be transitively closed - that is the
> only way to make conclusions about the order of events observed in two
> different threads. This means that for putOrdered to make sense one
> would need an edge between a load of that value and the store. However,
> the current JMM only talks about synchronization operations that are
> always part of (total) synchronization order. If you make putOrdered
> part of synchronization order, it becomes no different from a volatile
> store. If you make putOrdered not part of synchronization order, you
> need to modify JMM to allow to synchronize-with operations that are not
> totally ordered, and specify what orders are not allowed (basically, the
> difficulty with specifying this in the JMM).
> 
> So, whereas Aleksey?s answer explains that volatile load of b can be
> reordered with putOrdered store of a, there?s still a question of
> whether the volatile load of b is observed in a deterministic order with
> the other operations preceding putOrdered store of a. In other words,
> does putOrdered create edges between all preceding operations and all
> succeeding operations, or does it only create an order between that
> single store and the preceding operations.
> 
> 
> Alex
> 
> 
>> On 26 Mar 2016, at 21:32, Vladimir Ozerov <ppozerov at gmail.com
>> <mailto:ppozerov at gmail.com>> wrote:
>>
>> Hi,
>>
>> I am trying to wrap my head around the following problem. Consider we
>> have a kind of lightweight locking algorithm between two threads which
>> somewhat resembles classical Peterson's lock. One thread declares
>> intent to acquire a lock and then checks whether state of another
>> thread allows it.
>>
>> The question is: provided very subtle "putOrdered" semantics and no
>> data dependency between "a" and "b", do I have any guarantees that
>> store and load will not be reordered in the code below?
>>
>> int a, b;
>>
>> boolean tryLock() {
>>     UNSAFE.putOrdered(a, 1); // Declare intent.
>>
>>     // No StoreLoad here as store is not volatile.
>>
>>     if (UNSAFE.getVolatile(b) == 1)) {
>>         // Reset intent and return false;
>>     }
>>
>>     return true;
>> }
>>
>> My hope is that ordering could be enforced by the fact that both store
>> and load in this example are synchronization actions (see old comment
>> from
>> Doug: http://cs.oswego.edu/pipermail/concurrency-interest/2011-October/008324.html).
>>
>> Vladimir.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From vitalyd at gmail.com  Mon Mar 28 21:46:06 2016
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 28 Mar 2016 21:46:06 -0400
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <56F9D14F.9040406@haase-consulting.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
	<56F9D14F.9040406@haase-consulting.com>
Message-ID: <CAHjP37FdJ+Z9sMOQJyTxuFMGWFYciWaKMmNiwJ+L0SzHY292xg@mail.gmail.com>

On Monday, March 28, 2016, Arno Haase <arno.haase at haase-consulting.com>
wrote:

> Here's my understanding of putOrdered - hope it helps.
>
> * putOrdered is outside the JMM in the sense that its guarantees can not
> be expressed in terms of hb or sw.
>
> * But both putOrdered and the JMM can be expressed in terms of barriers
> - see JSR-133 cookbook. As I understand it, in order to reason about
> 'putOrdered' you need to reason in terms of barriers, even for things
> like volatile access that are covered in the JMM.
>
> * Hotspot does two things for a volatile write.
>
> Firstly, it emits a StoreStore barrier before it, ensuring that no other
> write happening before the volatile write will be visible after the
> volatile write.
>
> Secondly, it emits a StoreLoad barrier after it, ensuring that no read
> operation occurring after the volatile write will be executed before the
> volatile write.
>
> * putOrdered requires only the StoreStore barrier to be emitted. Since
> the StoreStore barrier colloqually corresponds to 'ordering' and the
> StoreLoad barrier to 'visibility' guarantees, one way to look at
> putOrdered is that it ensures ordering - hence the name - but not
> (immediate) visibility of written values. They are guaranteed to become
> visible eventually, but not in the strict sense proscribed by the JMM
> for volatile writes.

Compiler can move loads before ordered store, changing ordering; it's not
just about CPU.

>
> * Both StoreStore and StoreLoad barriers are superfluous on Intel
> processors because they guarantee the corresponding restrictions for all
> store operations anyway. But removing the StoreLoad barrier supposedly
> makes for speedups on some other architectures.

I think you have this backwards.  StoreLoad is not superfluous on Intel,
it's reorderable there (due to store buffers).  StoreStore (amongst the
others) is nop but may have performance implications on weaker memory order
CPUs.

>
>
> - Arno
>
>
> Am 28.03.2016 um 13:49 schrieb Alex Otenko:
> > I think the answer comes from the meaning of ?Ordered? - the store is
> > ordered with respect to what?
> >
> > This store is underspecified - JMM doesn?t refer to it. Yet, given
> > Aleksey?s answer, it seems to mean you have an hb edge between the store
> > and the preceding operations, but no new edges with the succeeding
> > operations.
> >
> > To make matters worse, JMM requires synchronizes-with edges, for the
> > observed order of operations to be transitively closed - that is the
> > only way to make conclusions about the order of events observed in two
> > different threads. This means that for putOrdered to make sense one
> > would need an edge between a load of that value and the store. However,
> > the current JMM only talks about synchronization operations that are
> > always part of (total) synchronization order. If you make putOrdered
> > part of synchronization order, it becomes no different from a volatile
> > store. If you make putOrdered not part of synchronization order, you
> > need to modify JMM to allow to synchronize-with operations that are not
> > totally ordered, and specify what orders are not allowed (basically, the
> > difficulty with specifying this in the JMM).
> >
> > So, whereas Aleksey?s answer explains that volatile load of b can be
> > reordered with putOrdered store of a, there?s still a question of
> > whether the volatile load of b is observed in a deterministic order with
> > the other operations preceding putOrdered store of a. In other words,
> > does putOrdered create edges between all preceding operations and all
> > succeeding operations, or does it only create an order between that
> > single store and the preceding operations.
> >
> >
> > Alex
> >
> >
> >> On 26 Mar 2016, at 21:32, Vladimir Ozerov <ppozerov at gmail.com
> <javascript:;>
> >> <mailto:ppozerov at gmail.com <javascript:;>>> wrote:
> >>
> >> Hi,
> >>
> >> I am trying to wrap my head around the following problem. Consider we
> >> have a kind of lightweight locking algorithm between two threads which
> >> somewhat resembles classical Peterson's lock. One thread declares
> >> intent to acquire a lock and then checks whether state of another
> >> thread allows it.
> >>
> >> The question is: provided very subtle "putOrdered" semantics and no
> >> data dependency between "a" and "b", do I have any guarantees that
> >> store and load will not be reordered in the code below?
> >>
> >> int a, b;
> >>
> >> boolean tryLock() {
> >>     UNSAFE.putOrdered(a, 1); // Declare intent.
> >>
> >>     // No StoreLoad here as store is not volatile.
> >>
> >>     if (UNSAFE.getVolatile(b) == 1)) {
> >>         // Reset intent and return false;
> >>     }
> >>
> >>     return true;
> >> }
> >>
> >> My hope is that ordering could be enforced by the fact that both store
> >> and load in this example are synchronization actions (see old comment
> >> from
> >> Doug:
> http://cs.oswego.edu/pipermail/concurrency-interest/2011-October/008324.html
> ).
> >>
> >> Vladimir.
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu <javascript:;>
> >> <mailto:Concurrency-interest at cs.oswego.edu <javascript:;>>
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <javascript:;>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <javascript:;>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Sent from my phone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160328/14a48138/attachment.html>

From oleksandr.otenko at gmail.com  Tue Mar 29 04:09:49 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 29 Mar 2016 09:09:49 +0100
Subject: [concurrency-interest] Can ordered store be reordered with
	subsequent volatile load?
In-Reply-To: <56F9D14F.9040406@haase-consulting.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
	<56F9D14F.9040406@haase-consulting.com>
Message-ID: <9AA6CA80-C7F8-4827-853B-F4622B03710D@gmail.com>

There are different kinds of barriers, too, (some providing local ordering, some being in a total global order) so you cannot easily reason about the barriers.

StoreLoad is not superfluous on Intel. Loads are allowed to go ahead of Stores, if the store is to a different location - just like in this case.

I don?t think it is easy to reason about ?immediacy? of visibility when there is some distance between the observers. In a distributed system it is more productive to talk about agreement on the order of certain events between the observers. What people usually mean by ?immediate? visibility can be described in terms of that agreement on the order of events. The fewer things are ordered, the further it is from a total order of all events, the more relaxed the model is, and the better it scales.

Alex

> On 29 Mar 2016, at 01:50, Arno Haase <arno.haase at haase-consulting.com> wrote:
> 
> Here's my understanding of putOrdered - hope it helps.
> 
> * putOrdered is outside the JMM in the sense that its guarantees can not
> be expressed in terms of hb or sw.
> 
> * But both putOrdered and the JMM can be expressed in terms of barriers
> - see JSR-133 cookbook. As I understand it, in order to reason about
> 'putOrdered' you need to reason in terms of barriers, even for things
> like volatile access that are covered in the JMM.
> 
> * Hotspot does two things for a volatile write.
> 
> Firstly, it emits a StoreStore barrier before it, ensuring that no other
> write happening before the volatile write will be visible after the
> volatile write.
> 
> Secondly, it emits a StoreLoad barrier after it, ensuring that no read
> operation occurring after the volatile write will be executed before the
> volatile write.
> 
> * putOrdered requires only the StoreStore barrier to be emitted. Since
> the StoreStore barrier colloqually corresponds to 'ordering' and the
> StoreLoad barrier to 'visibility' guarantees, one way to look at
> putOrdered is that it ensures ordering - hence the name - but not
> (immediate) visibility of written values. They are guaranteed to become
> visible eventually, but not in the strict sense proscribed by the JMM
> for volatile writes.
> 
> * Both StoreStore and StoreLoad barriers are superfluous on Intel
> processors because they guarantee the corresponding restrictions for all
> store operations anyway. But removing the StoreLoad barrier supposedly
> makes for speedups on some other architectures.
> 
> 
> - Arno
> 
> 
> Am 28.03.2016 um 13:49 schrieb Alex Otenko:
>> I think the answer comes from the meaning of ?Ordered? - the store is
>> ordered with respect to what?
>> 
>> This store is underspecified - JMM doesn?t refer to it. Yet, given
>> Aleksey?s answer, it seems to mean you have an hb edge between the store
>> and the preceding operations, but no new edges with the succeeding
>> operations.
>> 
>> To make matters worse, JMM requires synchronizes-with edges, for the
>> observed order of operations to be transitively closed - that is the
>> only way to make conclusions about the order of events observed in two
>> different threads. This means that for putOrdered to make sense one
>> would need an edge between a load of that value and the store. However,
>> the current JMM only talks about synchronization operations that are
>> always part of (total) synchronization order. If you make putOrdered
>> part of synchronization order, it becomes no different from a volatile
>> store. If you make putOrdered not part of synchronization order, you
>> need to modify JMM to allow to synchronize-with operations that are not
>> totally ordered, and specify what orders are not allowed (basically, the
>> difficulty with specifying this in the JMM).
>> 
>> So, whereas Aleksey?s answer explains that volatile load of b can be
>> reordered with putOrdered store of a, there?s still a question of
>> whether the volatile load of b is observed in a deterministic order with
>> the other operations preceding putOrdered store of a. In other words,
>> does putOrdered create edges between all preceding operations and all
>> succeeding operations, or does it only create an order between that
>> single store and the preceding operations.
>> 
>> 
>> Alex
>> 
>> 
>>> On 26 Mar 2016, at 21:32, Vladimir Ozerov <ppozerov at gmail.com
>>> <mailto:ppozerov at gmail.com <mailto:ppozerov at gmail.com>>> wrote:
>>> 
>>> Hi,
>>> 
>>> I am trying to wrap my head around the following problem. Consider we
>>> have a kind of lightweight locking algorithm between two threads which
>>> somewhat resembles classical Peterson's lock. One thread declares
>>> intent to acquire a lock and then checks whether state of another
>>> thread allows it.
>>> 
>>> The question is: provided very subtle "putOrdered" semantics and no
>>> data dependency between "a" and "b", do I have any guarantees that
>>> store and load will not be reordered in the code below?
>>> 
>>> int a, b;
>>> 
>>> boolean tryLock() {
>>>    UNSAFE.putOrdered(a, 1); // Declare intent.
>>> 
>>>    // No StoreLoad here as store is not volatile.
>>> 
>>>    if (UNSAFE.getVolatile(b) == 1)) {
>>>        // Reset intent and return false;
>>>    }
>>> 
>>>    return true;
>>> }
>>> 
>>> My hope is that ordering could be enforced by the fact that both store
>>> and load in this example are synchronization actions (see old comment
>>> from
>>> Doug: http://cs.oswego.edu/pipermail/concurrency-interest/2011-October/008324.html).
>>> 
>>> Vladimir.
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>> <mailto:Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160329/80bddeb7/attachment-0001.html>

From aph at redhat.com  Tue Mar 29 05:43:52 2016
From: aph at redhat.com (Andrew Haley)
Date: Tue, 29 Mar 2016 10:43:52 +0100
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <56F9D14F.9040406@haase-consulting.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
	<56F9D14F.9040406@haase-consulting.com>
Message-ID: <56FA4E58.5030807@redhat.com>

On 29/03/16 01:50, Arno Haase wrote:
> * Hotspot does two things for a volatile write.
> 
> Firstly, it emits a StoreStore barrier before it, ensuring that no other
> write happening before the volatile write will be visible after the
> volatile write.
> 
> Secondly, it emits a StoreLoad barrier after it, ensuring that no read
> operation occurring after the volatile write will be executed before the
> volatile write.

It depends on the architecture.  AArch64 has an instruction (stlr)
which does everything we need for a volatile write.  We certainly
don't need a StoreLoad barrier.

Andrew.


From aph at redhat.com  Tue Mar 29 05:48:58 2016
From: aph at redhat.com (Andrew Haley)
Date: Tue, 29 Mar 2016 10:48:58 +0100
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <56F9D14F.9040406@haase-consulting.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
	<56F9D14F.9040406@haase-consulting.com>
Message-ID: <56FA4F8A.5050607@redhat.com>

On 29/03/16 01:50, Arno Haase wrote:
> * putOrdered requires only the StoreStore barrier to be emitted. Since
> the StoreStore barrier colloqually corresponds to 'ordering' and the
> StoreLoad barrier to 'visibility' guarantees, one way to look at
> putOrdered is that it ensures ordering - hence the name - but not
> (immediate) visibility of written values. They are guaranteed to become
> visible eventually, but not in the strict sense proscribed by the JMM
> for volatile writes.

If putOrdered really is a release store (I hate that name!) then
it's StoreStore|LoadStore.  StoreStore, as Hans Boehm has told us
many times, isn't much use on its own.

Andrew.


From ppozerov at gmail.com  Wed Mar 30 15:37:35 2016
From: ppozerov at gmail.com (Vladimir Ozerov)
Date: Wed, 30 Mar 2016 22:37:35 +0300
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <56F7B91F.4000406@oracle.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<56F7B91F.4000406@oracle.com>
Message-ID: <CAJJmzpVqnnZT8NZ6xR4aiZrLO1wYtmUoi1s3DhCW1uVp7khROw@mail.gmail.com>

Aleksey,

> My personal rule of thumb is that acq/rel is okay in producer/consumer
> scenarios where you can get away with only partial ordering. But in
> locks, where you want to reason about multiple threads communicating in
> both directions, you nominally need full SC, and the correctness of any
> relaxation should be rigorously proved.

True. Though, it looks like relaxed store could still be a viable option
for unlock routine in some very specific cases.
Thanks for explanation.

Vladimir.

2016-03-27 13:42 GMT+03:00 Aleksey Shipilev <aleksey.shipilev at oracle.com>:

> On 03/27/2016 12:32 AM, Vladimir Ozerov wrote:
> > I am trying to wrap my head around the following problem. Consider we
> > have a kind of lightweight locking algorithm between two threads which
> > somewhat resembles classical Peterson's lock. One thread declares intent
> > to acquire a lock and then checks whether state of another thread allows
> it.
> >
> > The question is: provided very subtle "putOrdered" semantics and no data
> > dependency between "a" and "b", do I have any guarantees that store and
> > load will not be reordered in the code below?
>
> No, you don't have these guarantees. acquire/release-es (putOrdered is a
> release in disguise) are not sequentially consistent.
>
> In other words, you cannot freely change volatiles to acquire/releases
> and hope it does not break code. Famous example: replace volatiles with
> acq/rel in IRIW. I think Dekker/Peterson locks require the same
> guarantees that IRIW validates.
>
> > int a, b;
> >
> > boolean tryLock() {
> >     UNSAFE.putOrdered(a, 1); // Declare intent.
> >
> >     // No StoreLoad here as store is not volatile.
> >
> >     if (UNSAFE.getVolatile(b) == 1)) {
> >         // Reset intent and return false;
> >     }
> >
> >     return true;
> > }
>
> Even in the naive barrier interpretation that usually gives stronger
> answers, you have:
>
>  [LoadStore|StoreStore]
>  a = 1;
>
>  r1 = b;
>  [LoadLoad|LoadStore]
>
> Oops.
>
> > My hope is that ordering could be enforced by the fact that both
> > store and load in this example are synchronization actions
>
> Acq/rels are weird in the way they effectively induce synchronizes-with,
> but have limited ties in total synchronization order. (This is at odds
> with JMM spec as stated, and there is no easy way out: either you relax
> SW is-suborder-of SO, and allow acq/rel in SW; or you push acq/rel into
> SO and by extension into SW, effectively making them indistinguishable
> from volatiles).
>
> My personal rule of thumb is that acq/rel is okay in producer/consumer
> scenarios where you can get away with only partial ordering. But in
> locks, where you want to reason about multiple threads communicating in
> both directions, you nominally need full SC, and the correctness of any
> relaxation should be rigorously proved.
>
> Thanks,
> -Aleksey
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160330/0eacf30c/attachment.html>

From martinrb at google.com  Wed Mar 30 16:23:28 2016
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 30 Mar 2016 13:23:28 -0700
Subject: [concurrency-interest] Can ordered store be reordered with
 subsequent volatile load?
In-Reply-To: <56FA4F8A.5050607@redhat.com>
References: <CAJJmzpW=X1xMpRdVNN34+t1t9bpQ6hbwk+aRqDSRup-PggZEkA@mail.gmail.com>
	<BD0563D7-8456-4CB9-BB14-DF784C48CF25@gmail.com>
	<56F9D14F.9040406@haase-consulting.com>
	<56FA4F8A.5050607@redhat.com>
Message-ID: <CA+kOe0-VkPA9QeALZV8Wjhm+9Ta=PxzOajVCekRbiRSxwmx4TQ@mail.gmail.com>

Recent versions of putOrdered spec documents the "memory_order_release".

    /**
     * Version of {@link #putObjectVolatile(Object, long, Object)}
     * that does not guarantee immediate visibility of the store to
     * other threads. This method is generally only useful if the
     * underlying field is a Java volatile (or if an array cell, one
     * that is otherwise only accessed using volatile accesses).
     *
     * Corresponds to C11 atomic_store_explicit(..., memory_order_release).
     */
    @ForceInline
    public void putOrderedObject(Object o, long offset, Object x) {

On Tue, Mar 29, 2016 at 2:48 AM, Andrew Haley <aph at redhat.com> wrote:
> On 29/03/16 01:50, Arno Haase wrote:
>> * putOrdered requires only the StoreStore barrier to be emitted. Since
>> the StoreStore barrier colloqually corresponds to 'ordering' and the
>> StoreLoad barrier to 'visibility' guarantees, one way to look at
>> putOrdered is that it ensures ordering - hence the name - but not
>> (immediate) visibility of written values. They are guaranteed to become
>> visible eventually, but not in the strict sense proscribed by the JMM
>> for volatile writes.
>
> If putOrdered really is a release store (I hate that name!) then
> it's StoreStore|LoadStore.  StoreStore, as Hans Boehm has told us
> many times, isn't much use on its own.

