From alarmnummer at gmail.com  Thu Mar  1 07:27:27 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 1 Mar 2007 13:27:27 +0100
Subject: [concurrency-interest] dealing with people
	thatquestionvisibility problems
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEINHFAA.dcholmes@optusnet.com.au>
References: <BDA38860DCFD334EAEA905E44EE8E7EF7BAB5C@G3W0067.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCOEINHFAA.dcholmes@optusnet.com.au>
Message-ID: <1466c1d60703010427s73afad1es860163fb6a87959f@mail.gmail.com>

To keep you posted: I have made a few small changes to the blogentry
and have placed it on the company website:

http://blog.xebia.com/2007/03/01/spring-and-visibility-problems/

From matthias.ernst at coremedia.com  Thu Mar  1 07:53:36 2007
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Thu, 1 Mar 2007 13:53:36 +0100
Subject: [concurrency-interest] dealing with
	peoplethatquestionvisibility problems
References: <BDA38860DCFD334EAEA905E44EE8E7EF7BAB5C@G3W0067.americas.hpqcorp.net><NFBBKALFDCPFIDBNKAPCOEINHFAA.dcholmes@optusnet.com.au>
	<1466c1d60703010427s73afad1es860163fb6a87959f@mail.gmail.com>
Message-ID: <AE2A8E488D9B26438919DF3C9C95528D168E80@hermes.coremedia.com>

> I have made a few small changes to the blogentry

Peter,

two remarks:

as I understand "action2" comes before "action1". Construction also happens under the lock of the application context.
And I don't understand why you say this is only safe since 1.5. If the following is not safe in 1.4 what is?

T1:
synchronized(map) {
  manager = map.get("manager");
  if(manager == null) {
    manager = new Manager();
    manager.setDao(dao);
    map.put("manager", manager);
  }
}

T2:
synchronized(map) {
  manager = map.get("manager");
  // not null
}
manager.fire(...);



Matthias


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070301/197848af/attachment.html 

From alarmnummer at gmail.com  Thu Mar  1 09:19:18 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 1 Mar 2007 15:19:18 +0100
Subject: [concurrency-interest] dealing with
	peoplethatquestionvisibility problems
In-Reply-To: <AE2A8E488D9B26438919DF3C9C95528D168E80@hermes.coremedia.com>
References: <BDA38860DCFD334EAEA905E44EE8E7EF7BAB5C@G3W0067.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCOEINHFAA.dcholmes@optusnet.com.au>
	<1466c1d60703010427s73afad1es860163fb6a87959f@mail.gmail.com>
	<AE2A8E488D9B26438919DF3C9C95528D168E80@hermes.coremedia.com>
Message-ID: <1466c1d60703010619x5a820edrbf1871f080c671cf@mail.gmail.com>

Hi Matthias,

>>as I understand "action2" comes before "action1". Construction also
happens >> under the lock of the application context.

It is corrected. It appears I did non drink enough coffee. Thank you.

>> And I don't understand why you say this is only safe
>> since 1.5. If the following is not safe in 1.4 what is?

If the dao is not final (and final even doesn't work correctly under
older virtual machines because of reordenings that are forbidden under
Java 5 and higher), or volatile, or used in a synchronized context,
then I don't know a way to safely publish that variable under 1.4.

I probably will work because most cpu's have a very strong cache coherence.

On 3/1/07, Ernst, Matthias <matthias.ernst at coremedia.com> wrote:
>
>
>
> > I have made a few small changes to the blogentry
>
>  Peter,
>
>  two remarks:
>
>  as I understand "action2" comes before "action1". Construction also happens
> under the lock of the application context.
>  And I don't understand why you say this is only safe since 1.5. If the
> following is not safe in 1.4 what is?
>
>  T1:
>  synchronized(map) {
>    manager = map.get("manager");
>    if(manager == null) {
>      manager = new Manager();
>      manager.setDao(dao);
>      map.put("manager", manager);
>    }
>  }
>
>  T2:
>  synchronized(map) {
>    manager = map.get("manager");
>    // not null
>  }
>  manager.fire(...);
>
>
>
>  Matthias
>
>
>

From peter.kovacs.1.0rc at gmail.com  Thu Mar  1 11:01:20 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Thu, 1 Mar 2007 17:01:20 +0100
Subject: [concurrency-interest] Calling Future.get() after calling
	Future.cancel() returned false
Message-ID: <b6e8f2e80703010801o501f78f5uea93bf9d9ff77500@mail.gmail.com>

Hi,

Does it make sense to call Future.get() after calling Future.cancel()
returned false? My purpose is to reap any potential exception that may
have been thrown during task execution. Is Future.cancel() and
idempotent operation on Future instances already completed (before
cancel() was called on them)?

Thanks
Peter

From peter.kovacs.1.0rc at gmail.com  Thu Mar  1 11:03:38 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Thu, 1 Mar 2007 17:03:38 +0100
Subject: [concurrency-interest] Calling Future.get() after calling
	Future.cancel() returned false
In-Reply-To: <b6e8f2e80703010801o501f78f5uea93bf9d9ff77500@mail.gmail.com>
References: <b6e8f2e80703010801o501f78f5uea93bf9d9ff77500@mail.gmail.com>
Message-ID: <b6e8f2e80703010803y67285a60pa7ecc726d4837605@mail.gmail.com>

Please, ignore my second question. It is utter nonsense.

Thanks
Peter

On 3/1/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> Hi,
>
> Does it make sense to call Future.get() after calling Future.cancel()
> returned false? My purpose is to reap any potential exception that may
> have been thrown during task execution. Is Future.cancel() and
> idempotent operation on Future instances already completed (before
> cancel() was called on them)?
>
> Thanks
> Peter
>

From jason_mehrens at hotmail.com  Thu Mar  1 14:20:11 2007
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Thu, 01 Mar 2007 13:20:11 -0600
Subject: [concurrency-interest] Calling Future.get() after
 callingFuture.cancel() returned false
Message-ID: <BAY105-F264F7E0B492808A566E56B83800@phx.gbl>

>Does it make sense to call Future.get() after calling Future.cancel()
>returned false?

Not for the FutureTask implementation.  After cancel() is called, get() will 
always throw a CancellationException (with no execution exception chain).  
You could create a custom Future or Callable proxy to trap any Throwable 
that occurs.  In JDK7 (post 6464365), you can override 
FutureTask.setException()

Regards,

Jason Mehrens

_________________________________________________________________
Rates near 39yr lows!  $430K Loan for $1,399/mo - Paying Too Much? Calculate 
new payment 
http://www.lowermybills.com/lre/index.jsp?sourceid=lmb-9632-18226&moid=7581


From peter.kovacs.1.0rc at gmail.com  Thu Mar  1 16:08:15 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Thu, 1 Mar 2007 22:08:15 +0100
Subject: [concurrency-interest] Calling Future.get() after
	callingFuture.cancel() returned false
In-Reply-To: <BAY105-F264F7E0B492808A566E56B83800@phx.gbl>
References: <BAY105-F264F7E0B492808A566E56B83800@phx.gbl>
Message-ID: <b6e8f2e80703011308q5dc91263w948fdc8a7bbd6a33@mail.gmail.com>

:-(

It would have made life too easy.

P.

On 3/1/07, Jason Mehrens <jason_mehrens at hotmail.com> wrote:
> >Does it make sense to call Future.get() after calling Future.cancel()
> >returned false?
>
> Not for the FutureTask implementation.  After cancel() is called, get() will
> always throw a CancellationException (with no execution exception chain).
> You could create a custom Future or Callable proxy to trap any Throwable
> that occurs.  In JDK7 (post 6464365), you can override
> FutureTask.setException()
>
> Regards,
>
> Jason Mehrens
>
> _________________________________________________________________
> Rates near 39yr lows!  $430K Loan for $1,399/mo - Paying Too Much? Calculate
> new payment
> http://www.lowermybills.com/lre/index.jsp?sourceid=lmb-9632-18226&moid=7581
>
>

From joe.bowbeer at gmail.com  Thu Mar  1 16:54:13 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 1 Mar 2007 13:54:13 -0800
Subject: [concurrency-interest] Calling Future.get() after calling
	Future.cancel() returned false
In-Reply-To: <b6e8f2e80703010801o501f78f5uea93bf9d9ff77500@mail.gmail.com>
References: <b6e8f2e80703010801o501f78f5uea93bf9d9ff77500@mail.gmail.com>
Message-ID: <31f2a7bd0703011354n5ede483aoea150a1440f06571@mail.gmail.com>

On 3/1/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
>
> Does it make sense to call Future.get() after calling Future.cancel()
> returned false?
>

Yes.  (I disagree with Jason's statement.)

If the task has already completed, then cancel returns false.

In particular, if the task has finished then a subsequent cancel()
will be ignored and a subsequent get() will return the result or
exception generated by the task.

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/
  java/util/concurrent/FutureTask.java

    boolean innerCancel(boolean mayInterruptIfRunning) {
        for (;;) {
            int s = getState();
            if (ranOrCancelled(s))
                return false;
            if (compareAndSetState(s, CANCELLED))
                break;
        }
        /* ... */
        return true;
    }

--Joe

From jason_mehrens at hotmail.com  Fri Mar  2 10:56:14 2007
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 02 Mar 2007 09:56:14 -0600
Subject: [concurrency-interest] Calling Future.get() after
 callingFuture.cancel() returned false
Message-ID: <BAY105-F10E54E10C039A4C540BB6F83870@phx.gbl>

>If the task has already completed, then cancel returns false.
My understanding is false could also mean already cancelled and get could 
throw the CancellationException then.  True could mean in progress, in which 
case an exception still might occur.  I would assume that these exceptions 
would be of interest too.

>In particular, if the task has finished then a subsequent cancel()
>will be ignored and a subsequent get() will return the result or
>exception generated by the task.
Thanks for clearing that up.  My misunderstanding.


Here is a WOMBAT question: What if cancel throws an exception?  The 
documentation does not list the possible SecurityException or the possible 
RuntimeException/Error from done().  Should a subsequent cancel be allowed 
to interrupt the runner if the first attempt was by a thread with out thread 
modify permission?

Jason


//Test case for Future fun.
import java.util.concurrent.*;
import java.util.*;
public class Cancel implements Callable<Void> {
    private final long sleep_ms;

    public static void main(String[] args) {
        cancelBeforeRun();
        cancelAfterRun();
        cancelCancelRun();
        lateArrivingGet(false);
        lateArrivingGet(true);
        securityCancel(false);
        securityCancel(true);
        evilDone();
        exit();
    }

    private static void cancelAfterRun() {
        System.err.println("cancelAfterRun");
        FutureTask task = new FutureTask(new Cancel(0L));
        task.run();
        testGoldenRule(task, false);
    }

    private static void cancelBeforeRun() {
        System.err.println("cancelBeforeRun");
        FutureTask task = new FutureTask(new Cancel(0L));
        testGoldenRule(task, false);
    }

    private static void cancelCancelRun() {
        System.err.println("cancelCancelRun");
        FutureTask task = new FutureTask(new Cancel(0L));
        task.cancel(false);
        testGoldenRule(task, false);
    }

    private static void lateArrivingGet(boolean mi) {
        System.err.println("lateArrivingGet("+ mi +')');
        FutureTask task = new FutureTask(new Cancel(15 * 1000L)) {
            public void run() {
                super.run();
                exit();
            }
        };
        new Thread(task).start();
        try {
            Thread.sleep(1000L);
        }
        catch(InterruptedException IE) {
            throw new AssertionError(IE);
        }
        testGoldenRule(task, mi);
    }

    private static void evilDone() {
        System.err.println("evilDone");
        FutureTask task = new FutureTask(new Cancel(15 * 1000L)) {
            protected void done() {
                if(super.isCancelled()) {
                    throw new InternalError();
                }
            }
        };
        testGoldenRule(task, false);
    }

    public static void securityCancel(boolean mi) {
            FutureTask task = new FutureTask(new Cancel(15 * 1000L)) {
                public void run() {
                    super.run();
                    exit();
                }
            };

            new Thread(task).start();
            try {
                Thread.sleep(1000L);
            }
            catch(InterruptedException IE) {
                throw new AssertionError(IE);
            }

       try {
            System.setSecurityManager(new SecurityManager() {
             public void checkAccess(Thread t) {
                 throw new SecurityException(t.toString());
             }
            });
            testGoldenRule(task, mi);
        }
        finally {
            System.setSecurityManager(null);
        }
    }


    private static void testGoldenRule(Future task, boolean mi) {
        try {
            if(!task.cancel(mi)) {
                try {
                    try {
                        task.get(0L, TimeUnit.NANOSECONDS);
                        throw new AssertionError("Get returned.");
                    }
                    catch(TimeoutException TE) {
                       if(task.isCancelled() && !task.isDone()) {
                            new AssertionError("Cancelled but not done.")
                            .initCause(TE).printStackTrace();
                       }
                       else {
                           task.get();
                           throw new AssertionError("Get returned.");
                       }
                    }
                }
                catch(InterruptedException IE) {
                    throw new AssertionError(IE);
                }
                catch(ExecutionException EE) {
                    EE.printStackTrace();
                }
                catch(CancellationException CE) {
                    new 
AssertionError(CE.toString()).initCause(CE).printStackTrace();
                }
            }
            else {
                System.err.println("Pass (cancel was true).");
            }
        }
        catch(SecurityException SE) {
            SE.printStackTrace();
            try {
                testGoldenRule(task, mi);
            }
            catch(SecurityException again) {
                System.err.println("Pass (failed twice).");
            }
        }
        catch(InternalError IE) {
            IE.printStackTrace();
            testGoldenRule(task, mi);
        }
    }

    private static void exit() {
        System.err.println(new Date(System.currentTimeMillis()) +", "+
                Thread.currentThread());

    }

    public Cancel(final long sleep_ms) {
        this.sleep_ms = sleep_ms;
    }

    public Void call() throws Exception {
        Thread.sleep(sleep_ms);
        throw new Exception("Pass");
    }
}

_________________________________________________________________
Mortgage rates as low as 4.625% - Refinance $150,000 loan for $579 a month. 
Intro*Terms  
https://www2.nextag.com/goto.jsp?product=100000035&url=%2fst.jsp&tm=y&search=mortgage_text_links_88_h27f6&disc=y&vers=743&s=4056&p=5117


From joe.bowbeer at gmail.com  Fri Mar  2 13:37:07 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 2 Mar 2007 10:37:07 -0800
Subject: [concurrency-interest] Calling Future.get() after
	callingFuture.cancel() returned false
In-Reply-To: <BAY105-F10E54E10C039A4C540BB6F83870@phx.gbl>
References: <BAY105-F10E54E10C039A4C540BB6F83870@phx.gbl>
Message-ID: <31f2a7bd0703021037o3dfaab83qcfda080fdec59297@mail.gmail.com>

On 3/2/07, Jason Mehrens <jason_mehrens at hotmail.com> wrote:
> >If the task has already completed, then cancel returns false.
>
> My understanding is false could also mean already cancelled and get could
> throw the CancellationException then.  True could mean in progress, in which
> case an exception still might occur.  I would assume that these exceptions
> would be of interest too.
>

Right. I was using "completed" to mean "ran or canceled", which is the
check made by the inner cancel method.

Note that I've only addressed the question about calling get() after
cancel() returns false.

Is there also a question about exceptions thrown by FutureTask methods
that may be masked by cancellation?  This makes my head spin.  What is
the motivation?

For insight into what happened before and during (and after)
cancellation, I would implement a task listener to report progress
and/or add a lot of logging.

I prescribe to the view that if a task's final state was canceled then
"canceled" is what should appear on its tombstone:-)

--Joe

From joe.bowbeer at gmail.com  Fri Mar  2 15:14:54 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 2 Mar 2007 12:14:54 -0800
Subject: [concurrency-interest] Calling Future.get() after
	callingFuture.cancel() returned false
In-Reply-To: <31f2a7bd0703021037o3dfaab83qcfda080fdec59297@mail.gmail.com>
References: <BAY105-F10E54E10C039A4C540BB6F83870@phx.gbl>
	<31f2a7bd0703021037o3dfaab83qcfda080fdec59297@mail.gmail.com>
Message-ID: <31f2a7bd0703021214j7f9d9328r4f2cb705b64d1c13@mail.gmail.com>

Correction:

I "subscribe" to the view -- but I also "prescribe" it...

On 3/2/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
>
> Is there also a question about exceptions thrown by FutureTask
> methods, which may be masked by cancellation?  [...]
>
> I prescribe to the view that if a task's final state was canceled then
> "canceled" is what should appear on its tombstone:-)
>

From peter.kovacs.1.0rc at gmail.com  Sat Mar  3 06:14:58 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Sat, 3 Mar 2007 12:14:58 +0100
Subject: [concurrency-interest] Differences in "optimized" versions of
	backport
Message-ID: <b6e8f2e80703030314u71666dfdx8c163fb538d8399e@mail.gmail.com>

Hi,

What are the main differences between versions of the backport
optimized for Java 1.4 and Java 1.5. One of them is using "native" CAS
support in Java 1.5 and using some lock-based CAS-proxy in Java 1.4, I
presume. Any other notable differences?

Thanks
Peter

From dawidk at mathcs.emory.edu  Sat Mar  3 09:39:42 2007
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Sat, 03 Mar 2007 09:39:42 -0500
Subject: [concurrency-interest] Differences in "optimized" versions of
 backport
In-Reply-To: <b6e8f2e80703030314u71666dfdx8c163fb538d8399e@mail.gmail.com>
References: <b6e8f2e80703030314u71666dfdx8c163fb538d8399e@mail.gmail.com>
Message-ID: <45E988AE.5000500@mathcs.emory.edu>

Peter Kovacs wrote:
> Hi,
>
> What are the main differences between versions of the backport
> optimized for Java 1.4 and Java 1.5. One of them is using "native" CAS
> support in Java 1.5 and using some lock-based CAS-proxy in Java 1.4, I
> presume. Any other notable differences?
>   

1. use of native CAS etc. in atomic variables,
2. use of native park/unpark (and CAS) in locks.

This results in a lot faster atomics (circa an order of magnitude), and 
also faster locks (circa 2-5 times). Since atomics and locks are used 
all over the API, performance gains are propagated (although they may be 
less dramatic) to queues, concurrent collections, thread pools, etc.

Disclaimer: I haven't done a comprehensive benchmark; only some sketchy 
comparisons based on stress test timings.

Regards,
Dawid



From dawidk at mathcs.emory.edu  Sat Mar  3 15:45:04 2007
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Sat, 03 Mar 2007 15:45:04 -0500
Subject: [concurrency-interest] weakCompareAndSet in atomics - incompatible
	class change?
Message-ID: <45E9DE50.3090106@mathcs.emory.edu>

Hi all,

Question: isn't adding a final method to a non-final class an 
incompatible class change? It breaks subclasses containing a method with 
the same signature. What's the official view on this?

This is what happened with Atomic* classes: in 6.0, weakCompareAndSet() 
method was added. As a result, the backport-util-concurrent optimized 
for 5.0, in which the "backport" atomics extend native atomics, does not 
work on 6.0. (I always thought that Atomic* classes should have been 
made final :P )


Regards,
Dawid



From jseigh_cp00 at xemaps.com  Sat Mar  3 16:36:15 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Sat, 03 Mar 2007 16:36:15 -0500
Subject: [concurrency-interest] Yet another Java STM implementation
Message-ID: <45E9EA4F.2080909@xemaps.com>

I put a hopefully working prototype Java STM package out on
SourceForge.net: Lock-free synchronization primitives 
<http://sourceforge.net/projects/atomic-ptr-plus/>
in the xmem_0-0-0 release.

It uses a proxy collector to manage object versions.  This means
it can be ported to C using other proxy collectors such as RCU
or other proxy collectors based on SMR hazard pointers or
reference counting subject a few additional considerations.

It's mainly a practice implementation (in case I have to do
a real one) with attention to api issues.  E.g. I wll probably
make a distinction between read only transactions and write
transactions to allow the optional use of a conventional
rwlock to handle forward progress on too many retries.
I.e.  write transactions get a read lock to work in parallel
and get a write lock to guarantee forward progress if
necessary.   Stuff like that.

--
Joe Seigh

From pfeiffer at tzi.de  Sun Mar  4 07:49:50 2007
From: pfeiffer at tzi.de (Oliver Pfeiffer)
Date: Sun, 4 Mar 2007 13:49:50 +0100
Subject: [concurrency-interest] Disposing a BlockingQueue with capacity?
Message-ID: <000001c75e5b$9955f250$4201a8c0@olli>

How should a BlockingQueue with a fixed capacity be disposed to release all
waiting submitter threads?

Assuming we have a black-box service sequentially processing items. The
items can be submitted to the black-box by 1..n threads in parallel. The box
uses a LinkedBlockingQueue with a fixed capacity of 10. When the queue
becomes full there could be more than 10 (e.g. 1000) blocked threads waiting
to submit further items.

How can this black-box safely be terminated by releasing all submitter
threads? Unfortunately the capacity can't be set to infinity after
construction and a BlockingQueue#clear() does only clear the currently
queued items. Thus in the example above we will release 10 threads
(successful submit) but will still have 990 threads blocked.

-- 
Gr??e - Regards
Oliver Pfeiffer
ICQ-ID 84320006



From alarmnummer at gmail.com  Sun Mar  4 11:59:12 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Sun, 4 Mar 2007 17:59:12 +0100
Subject: [concurrency-interest] Disposing a BlockingQueue with capacity?
In-Reply-To: <000001c75e5b$9955f250$4201a8c0@olli>
References: <000001c75e5b$9955f250$4201a8c0@olli>
Message-ID: <1466c1d60703040859v4c570153g7c8135e2031a7938@mail.gmail.com>

Hi Oliver,

what you could do is the following;

add a check before an item is put on the queue. when the structure
shuts down, the check doesn';t allow any items being put by throwing
an illegalstateexception for example, or
thisstructureisshutdownexception.

Now for the waiting threads. When the structure is shut down, just
take all items that are going to be put.

object item;
do{
    item = queue.poll(1,TimeUnit.SECOND)
while(item1=null)

This make sure that pending threads (for putting) are allowed to run.

queue's are great structures, but I don't expose them directly in a
lot of situations because the contract they provide can be
restrictive.

You also have to watch out for discarding items, in some situations
you don't want this to happen.

Another solution would be to interrupt all pending threads. But you
need to have access to the pending threads.

On 3/4/07, Oliver Pfeiffer <pfeiffer at tzi.de> wrote:
> How should a BlockingQueue with a fixed capacity be disposed to release all
> waiting submitter threads?
>
> Assuming we have a black-box service sequentially processing items. The
> items can be submitted to the black-box by 1..n threads in parallel. The box
> uses a LinkedBlockingQueue with a fixed capacity of 10. When the queue
> becomes full there could be more than 10 (e.g. 1000) blocked threads waiting
> to submit further items.
>
> How can this black-box safely be terminated by releasing all submitter
> threads? Unfortunately the capacity can't be set to infinity after
> construction and a BlockingQueue#clear() does only clear the currently
> queued items. Thus in the example above we will release 10 threads
> (successful submit) but will still have 990 threads blocked.
>
> --
> Gr??e - Regards
> Oliver Pfeiffer
> ICQ-ID 84320006
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From pfeiffer at tzi.de  Sun Mar  4 12:14:46 2007
From: pfeiffer at tzi.de (Oliver Pfeiffer)
Date: Sun, 4 Mar 2007 18:14:46 +0100
Subject: [concurrency-interest] Disposing a BlockingQueue with capacity?
In-Reply-To: <13086732.1173027575972.JavaMail.pfeiffer@mailhost>
References: <000001c75e5b$9955f250$4201a8c0@olli>
	<13086732.1173027575972.JavaMail.pfeiffer@mailhost>
Message-ID: <000501c75e80$9bf5cab0$4201a8c0@olli>

Hi Peter,

your solution isn't safe, since there is no reliable timeout value. If some
parts of the heap were swapped as virtual memory and the garbage collection
performs an intermediate run on a very slow and busy system it may need
seconds until the waiting threads become active again. Certainly this would
never happen under normal conditions but however it isn't bullet proof.

Actually I put all submitting threads to a HashSet and decouple the queue
from the black-box during shutdown. Then I can safely interrupt all threads
that are still waiting on the queue after the black-box was shut down to
avoid a black hole for submitter threads. :)

But I really prefer a more obvious solution provided by the queue itself,
since this is a very common use-case that must be handled by all APIs using
producer/consumer services based on blocking queues in a multithreaded
environment (where no assurances are met about the number of submitting
threads).

-- 
Gr??e - Regards
Oliver Pfeiffer
ICQ-ID 84320006 

> -----Original Message-----
> From: Peter Veentjer [mailto:alarmnummer at gmail.com] 
> Sent: Sunday, March 04, 2007 5:59 PM
> To: Oliver Pfeiffer
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Disposing a BlockingQueue 
> with capacity?
> 
> Hi Oliver,
> 
> what you could do is the following;
> 
> add a check before an item is put on the queue. when the structure
> shuts down, the check doesn';t allow any items being put by throwing
> an illegalstateexception for example, or
> thisstructureisshutdownexception.
> 
> Now for the waiting threads. When the structure is shut down, just
> take all items that are going to be put.
> 
> object item;
> do{
>     item = queue.poll(1,TimeUnit.SECOND)
> while(item1=null)
> 
> This make sure that pending threads (for putting) are allowed to run.
> 
> queue's are great structures, but I don't expose them directly in a
> lot of situations because the contract they provide can be
> restrictive.
> 
> You also have to watch out for discarding items, in some situations
> you don't want this to happen.
> 
> Another solution would be to interrupt all pending threads. But you
> need to have access to the pending threads.
> 
> On 3/4/07, Oliver Pfeiffer <pfeiffer at tzi.de> wrote:
> > How should a BlockingQueue with a fixed capacity be 
> disposed to release all
> > waiting submitter threads?
> >
> > Assuming we have a black-box service sequentially 
> processing items. The
> > items can be submitted to the black-box by 1..n threads in 
> parallel. The box
> > uses a LinkedBlockingQueue with a fixed capacity of 10. 
> When the queue
> > becomes full there could be more than 10 (e.g. 1000) 
> blocked threads waiting
> > to submit further items.
> >
> > How can this black-box safely be terminated by releasing 
> all submitter
> > threads? Unfortunately the capacity can't be set to infinity after
> > construction and a BlockingQueue#clear() does only clear 
> the currently
> > queued items. Thus in the example above we will release 10 threads
> > (successful submit) but will still have 990 threads blocked.
> >
> > --
> > Gr??e - Regards
> > Oliver Pfeiffer
> > ICQ-ID 84320006
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >



From alarmnummer at gmail.com  Sun Mar  4 12:37:56 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Sun, 4 Mar 2007 18:37:56 +0100
Subject: [concurrency-interest] Disposing a BlockingQueue with capacity?
In-Reply-To: <000501c75e80$9bf5cab0$4201a8c0@olli>
References: <000001c75e5b$9955f250$4201a8c0@olli>
	<13086732.1173027575972.JavaMail.pfeiffer@mailhost>
	<000501c75e80$9bf5cab0$4201a8c0@olli>
Message-ID: <1466c1d60703040937k30865f4did69bc2fd1d98731@mail.gmail.com>

> your solution isn'It safe, since there is no reliable timeout value. If some
> parts of the heap were swapped as virtual memory and the garbage collection
> performs an intermediate run on a very slow and busy system it may need
> seconds until the waiting threads become active again. Certainly this would
> never happen under normal conditions but however it isn't bullet proof.
It depends on the environment it is being used in.

> But I really prefer a more obvious solution provided by the queue itself,
> since this is a very common use-case that must be handled by all APIs using
> producer/consumer services based on blocking queues in a multithreaded
> environment (where no assurances are met about the number of submitting
> threads).

You could create a blockingqueue decorator that can be 'shutdown' (by
interrupting pending puts)

>
> --
> Gr??e - Regards
> Oliver Pfeiffer
> ICQ-ID 84320006
>
> > -----Original Message-----
> > From: Peter Veentjer [mailto:alarmnummer at gmail.com]
> > Sent: Sunday, March 04, 2007 5:59 PM
> > To: Oliver Pfeiffer
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Disposing a BlockingQueue
> > with capacity?
> >
> > Hi Oliver,
> >
> > what you could do is the following;
> >
> > add a check before an item is put on the queue. when the structure
> > shuts down, the check doesn';t allow any items being put by throwing
> > an illegalstateexception for example, or
> > thisstructureisshutdownexception.
> >
> > Now for the waiting threads. When the structure is shut down, just
> > take all items that are going to be put.
> >
> > object item;
> > do{
> >     item = queue.poll(1,TimeUnit.SECOND)
> > while(item1=null)
> >
> > This make sure that pending threads (for putting) are allowed to run.
> >
> > queue's are great structures, but I don't expose them directly in a
> > lot of situations because the contract they provide can be
> > restrictive.
> >
> > You also have to watch out for discarding items, in some situations
> > you don't want this to happen.
> >
> > Another solution would be to interrupt all pending threads. But you
> > need to have access to the pending threads.
> >
> > On 3/4/07, Oliver Pfeiffer <pfeiffer at tzi.de> wrote:
> > > How should a BlockingQueue with a fixed capacity be
> > disposed to release all
> > > waiting submitter threads?
> > >
> > > Assuming we have a black-box service sequentially
> > processing items. The
> > > items can be submitted to the black-box by 1..n threads in
> > parallel. The box
> > > uses a LinkedBlockingQueue with a fixed capacity of 10.
> > When the queue
> > > becomes full there could be more than 10 (e.g. 1000)
> > blocked threads waiting
> > > to submit further items.
> > >
> > > How can this black-box safely be terminated by releasing
> > all submitter
> > > threads? Unfortunately the capacity can't be set to infinity after
> > > construction and a BlockingQueue#clear() does only clear
> > the currently
> > > queued items. Thus in the example above we will release 10 threads
> > > (successful submit) but will still have 990 threads blocked.
> > >
> > > --
> > > Gr??e - Regards
> > > Oliver Pfeiffer
> > > ICQ-ID 84320006
> > >
> > >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
>
>


From tackline at tackline.plus.com  Sun Mar  4 14:41:34 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Sun, 04 Mar 2007 19:41:34 +0000
Subject: [concurrency-interest] weakCompareAndSet in atomics -
 incompatible class change?
In-Reply-To: <45E9DE50.3090106@mathcs.emory.edu>
References: <45E9DE50.3090106@mathcs.emory.edu>
Message-ID: <45EB20EE.2000003@tackline.plus.com>

Dawid Kurzyniec wrote:
> 
> Question: isn't adding a final method to a non-final class an 
> incompatible class change? It breaks subclasses containing a method with 
> the same signature. What's the official view on this?

It's done all the time in the Java library. It an break things, but 
rarely. SocketImpl even had an abstract method added in 1.4.

> work on 6.0. (I always thought that Atomic* classes should have been 
> made final :P )

I see the atomic lasses as primarily there for low-level optimisation. 
One such optimisation is opportunistic inheritance.

Tom Hawtin

From dcholmes at optusnet.com.au  Sun Mar  4 16:54:53 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 5 Mar 2007 07:54:53 +1000
Subject: [concurrency-interest] weakCompareAndSet in atomics -
	incompatibleclass change?
In-Reply-To: <45E9DE50.3090106@mathcs.emory.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEKOHFAA.dcholmes@optusnet.com.au>

Dawid,

> Question: isn't adding a final method to a non-final class an
> incompatible class change? It breaks subclasses containing a method with
> the same signature. What's the official view on this?

It is an incompatabilty, so you have to weigh the potential gain against the
potential damage. But changes like this are quite common when going from one
major rev to another.

The possibility that someone had added a weakCompareAndSet method to an
atomics subclass seemed remote.

> This is what happened with Atomic* classes: in 6.0, weakCompareAndSet()
> method was added. As a result, the backport-util-concurrent optimized
> for 5.0, in which the "backport" atomics extend native atomics, does not
> work on 6.0. (I always thought that Atomic* classes should have been
> made final :P )

Having the classes be non-final has some minor advantages for reducing
memory use in some cases eg defining a node class that IS-A
AtomicReferenceField.

I'm afraid you'll need a modified version to work on 6.0 - though that is
the backport adding on 6.0?

David Holmes


From dcholmes at optusnet.com.au  Sun Mar  4 17:10:19 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 5 Mar 2007 08:10:19 +1000
Subject: [concurrency-interest] Disposing a BlockingQueue with capacity?
In-Reply-To: <000501c75e80$9bf5cab0$4201a8c0@olli>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEKOHFAA.dcholmes@optusnet.com.au>

Oliver,

> But I really prefer a more obvious solution provided by the queue itself,
> since this is a very common use-case that must be handled by all
> APIs using
> producer/consumer services based on blocking queues in a multithreaded
> environment (where no assurances are met about the number of submitting
> threads).

A "queue" is not really a service, so it would be up to the service using
the queue to have the API and implementation to handle this. For example
ThreadPoolExecutor's shutdown protocol takes care of pool thread's taking
from the queue, and client threads submitting to the queue.

It would have been possible to define BlockingQueue to have a close() method
that asynchronously shuts down the queue and releases all waiters - and of
course your own implementation of BlockingQueue could add this. The decision
not to have a close() method was a deliberate one, as per the docs:

"A BlockingQueue does not intrinsically support any kind of "close" or
"shutdown" operation to indicate that no more items will be added. The needs
and usage of such features tend to be implementation-dependent. For example,
a common tactic is for producers to insert special end-of-stream or poison
objects, that are interpreted accordingly when taken by consumers. "

Cheers,
David Holmes


From brian at quiotix.com  Sun Mar  4 17:38:57 2007
From: brian at quiotix.com (Brian Goetz)
Date: Sun, 04 Mar 2007 17:38:57 -0500
Subject: [concurrency-interest] Disposing a BlockingQueue with capacity?
In-Reply-To: <000001c75e5b$9955f250$4201a8c0@olli>
References: <000001c75e5b$9955f250$4201a8c0@olli>
Message-ID: <45EB4A81.4080209@quiotix.com>

See JCiP 7.2.1.

Oliver Pfeiffer wrote:
> How should a BlockingQueue with a fixed capacity be disposed to release all
> waiting submitter threads?
> 
> Assuming we have a black-box service sequentially processing items. The
> items can be submitted to the black-box by 1..n threads in parallel. The box
> uses a LinkedBlockingQueue with a fixed capacity of 10. When the queue
> becomes full there could be more than 10 (e.g. 1000) blocked threads waiting
> to submit further items.
> 
> How can this black-box safely be terminated by releasing all submitter
> threads? Unfortunately the capacity can't be set to infinity after
> construction and a BlockingQueue#clear() does only clear the currently
> queued items. Thus in the example above we will release 10 threads
> (successful submit) but will still have 990 threads blocked.
> 

From hlship at gmail.com  Mon Mar  5 12:23:00 2007
From: hlship at gmail.com (Howard Lewis Ship)
Date: Mon, 5 Mar 2007 09:23:00 -0800
Subject: [concurrency-interest] Initializing a map inside a constructor
Message-ID: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>

I'm seeing some very strange effects in my code under load.  I've been
reviewing Brian Goetz's concurrency book, but I have a scenario I
frequently use that I have come to suspect:

I often have classes with a final field of type Map.

I initialize the Map, loading values inside the constructor.  I never
change the contents
of the Map outside of the constructor.

I don't use a guard (i.e. synchronized) to access the map from other code.

Is this thread safe, or do I need to synchronize the methods (or wrap
the map in a synchronzing wrapper)?

-- 
Howard M. Lewis Ship
TWD Consulting, Inc.
Independent J2EE / Open-Source Java Consultant
Creator and PMC Chair, Apache Tapestry
Creator, Apache HiveMind

Professional Tapestry training, mentoring, support
and project work.  http://howardlewisship.com

From crazybob at crazybob.org  Mon Mar  5 12:56:35 2007
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 5 Mar 2007 09:56:35 -0800
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
Message-ID: <a74683f90703050956p7532728we7005d540798710d@mail.gmail.com>

On 3/5/07, Howard Lewis Ship <hlship at gmail.com> wrote:
>
> I'm seeing some very strange effects in my code under load.  I've been
> reviewing Brian Goetz's concurrency book, but I have a scenario I
> frequently use that I have come to suspect:
>
> I often have classes with a final field of type Map.
>
> I initialize the Map, loading values inside the constructor.  I never
> change the contents
> of the Map outside of the constructor.
>
> I don't use a guard (i.e. synchronized) to access the map from other code.
>
> Is this thread safe, or do I need to synchronize the methods (or wrap
> the map in a synchronzing wrapper)?


You should be fine so long as you don't let the "this" reference escape from
the constructor (I assume this is the case), and if you create the enclosing
object in one thread and access it from another, you must pass the object
off in a thread safe manner.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070305/71de452e/attachment.html 

From brian at quiotix.com  Mon Mar  5 14:00:54 2007
From: brian at quiotix.com (Brian Goetz)
Date: Mon, 05 Mar 2007 14:00:54 -0500
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
Message-ID: <45EC68E6.8050602@quiotix.com>

This code is thread-safe:

public class Foo {
     private final Map m = new HashMap();

     public Foo() {
         m.put("foo", "bar");
     }

     public isKnown(String s) {
         return m.containsKey(s);
     }

     // no other modification to m
}

and this code is not:

public class Foo {
     private Map m = new HashMap();

     public Foo() {
         m.put("foo", "bar");
     }

     public isKnown(String s) {
         return m.containsKey(s);
     }

     // no other modification to m
}

The difference is the final keyword.  If the map is effectively 
immutable, and the reference to it is final, and the values are set in 
the constructor, and the 'this' reference doesn't escape construction, 
you're OK.

Howard Lewis Ship wrote:
> I'm seeing some very strange effects in my code under load.  I've been
> reviewing Brian Goetz's concurrency book, but I have a scenario I
> frequently use that I have come to suspect:
> 
> I often have classes with a final field of type Map.
> 
> I initialize the Map, loading values inside the constructor.  I never
> change the contents
> of the Map outside of the constructor.
> 
> I don't use a guard (i.e. synchronized) to access the map from other code.
> 
> Is this thread safe, or do I need to synchronize the methods (or wrap
> the map in a synchronzing wrapper)?
> 

From hlship at gmail.com  Mon Mar  5 14:29:51 2007
From: hlship at gmail.com (Howard Lewis Ship)
Date: Mon, 5 Mar 2007 11:29:51 -0800
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <481031b40703051126v2e8f9301o5474780089a115a5@mail.gmail.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
	<45EC68E6.8050602@quiotix.com>
	<481031b40703051126v2e8f9301o5474780089a115a5@mail.gmail.com>
Message-ID: <ecd0e3310703051129i7e8a0a34r4283c008b3695bd4@mail.gmail.com>

I kind of interpreted this as: the JVM "flushes out" changes at the
end of the constructor, much as it would at the end of a synchronized
block.

On 3/5/07, Robert Konigsberg <konigsberg at gmail.com> wrote:
> I'm not sure I follow you. How is m not effectively immutable? I presume
> that 'no other modifications to 'm'' refers to both to reassigning the
> reference as well as mutating the contents.
>
> It's also my assumption that any difference in compiler optimizations
> between your two examples are effectively irrelevant. Is it possible that
> I'm wrong about that?
>
> Thanks, Robert
>
> On 3/5/07, Brian Goetz <brian at quiotix.com> wrote:
> >
> > This code is thread-safe:
> >
> > public class Foo {
> >      private final Map m = new HashMap();
> >
> >      public Foo() {
> >          m.put("foo", "bar");
> >      }
> >
> >      public isKnown(String s) {
> >          return m.containsKey(s);
> >      }
> >
> >      // no other modification to m
> > }
> >
> > and this code is not:
> >
> > public class Foo {
> >      private Map m = new HashMap();
> >
> >      public Foo() {
> >          m.put("foo", "bar");
> >      }
> >
> >      public isKnown(String s) {
> >          return m.containsKey(s);
> >      }
> >
> >      // no other modification to m
> > }
> >
> > The difference is the final keyword.  If the map is effectively
> > immutable, and the reference to it is final, and the values are set in
> > the constructor, and the 'this' reference doesn't escape construction,
> > you're OK.
> >
> > Howard Lewis Ship wrote:
> > > I'm seeing some very strange effects in my code under load.  I've been
> > > reviewing Brian Goetz's concurrency book, but I have a scenario I
> > > frequently use that I have come to suspect:
> > >
> > > I often have classes with a final field of type Map.
> > >
> > > I initialize the Map, loading values inside the constructor.  I never
> > > change the contents
> > > of the Map outside of the constructor.
> > >
> > > I don't use a guard (i.e. synchronized) to access the map from other
> code.
> > >
> > > Is this thread safe, or do I need to synchronize the methods (or wrap
> > > the map in a synchronzing wrapper)?
> > >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> >
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
> --
> Robert Konigsberg
> konigsberg at gmail.com
>
> "... you know what they say: Fool me once, shame on you. Fool me twice,
> shame on The Cheat."


-- 
Howard M. Lewis Ship
TWD Consulting, Inc.
Independent J2EE / Open-Source Java Consultant
Creator and PMC Chair, Apache Tapestry
Creator, Apache HiveMind

Professional Tapestry training, mentoring, support
and project work.  http://howardlewisship.com

From brian at quiotix.com  Mon Mar  5 14:45:43 2007
From: brian at quiotix.com (Brian Goetz)
Date: Mon, 05 Mar 2007 14:45:43 -0500
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <481031b40703051126v2e8f9301o5474780089a115a5@mail.gmail.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>	
	<45EC68E6.8050602@quiotix.com>
	<481031b40703051126v2e8f9301o5474780089a115a5@mail.gmail.com>
Message-ID: <45EC7367.50202@quiotix.com>

The initialization safety guarantee offered by the new Java Memory Model 
guarantees that any value set in a constructor that is reached through a 
final field is guaranteed to be visible to any thread that loads a 
reference to the enclosing object.  Without the 'final', it is a 
garden-variety data race.

If the Foo object is properly published, you're OK with or without the 
final modifier, since m is effectively immutable.  If m is final, it is 
safe whether or not Foo is properly published.

Robert Konigsberg wrote:
> I'm not sure I follow you. How is m not effectively immutable? I presume 
> that 'no other modifications to 'm'' refers to both to reassigning the 
> reference as well as mutating the contents.
> 
> It's also my assumption that any difference in compiler optimizations 
> between your two examples are effectively irrelevant. Is it possible 
> that I'm wrong about that?
> 
> Thanks, Robert
> 
> On 3/5/07, *Brian Goetz* <brian at quiotix.com <mailto:brian at quiotix.com>> 
> wrote:
> 
>     This code is thread-safe:
> 
>     public class Foo {
>          private final Map m = new HashMap();
> 
>          public Foo() {
>              m.put("foo", "bar");
>          }
> 
>          public isKnown(String s) {
>              return m.containsKey(s);
>          }
> 
>          // no other modification to m
>     }
> 
>     and this code is not:
> 
>     public class Foo {
>          private Map m = new HashMap();
> 
>          public Foo() {
>              m.put("foo", "bar");
>          }
> 
>          public isKnown(String s) {
>              return m.containsKey(s);
>          }
> 
>          // no other modification to m
>     }
> 
>     The difference is the final keyword.  If the map is effectively
>     immutable, and the reference to it is final, and the values are set in
>     the constructor, and the 'this' reference doesn't escape construction,
>     you're OK.
> 
>     Howard Lewis Ship wrote:
>      > I'm seeing some very strange effects in my code under load.  I've
>     been
>      > reviewing Brian Goetz's concurrency book, but I have a scenario I
>      > frequently use that I have come to suspect:
>      >
>      > I often have classes with a final field of type Map.
>      >
>      > I initialize the Map, loading values inside the constructor.  I
>     never
>      > change the contents
>      > of the Map outside of the constructor.
>      >
>      > I don't use a guard (i.e. synchronized) to access the map from
>     other code.
>      >
>      > Is this thread safe, or do I need to synchronize the methods (or
>     wrap
>      > the map in a synchronzing wrapper)?
>      >
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at altair.cs.oswego.edu
>     <mailto:Concurrency-interest at altair.cs.oswego.edu>
>     http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> 
> -- 
> Robert Konigsberg
> konigsberg at gmail.com <mailto:konigsberg at gmail.com>
> 
> "... you know what they say: Fool me once, shame on you. Fool me twice, 
> shame on The Cheat."

From tackline at tackline.plus.com  Mon Mar  5 15:08:15 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Mon, 05 Mar 2007 20:08:15 +0000
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <a74683f90703050956p7532728we7005d540798710d@mail.gmail.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
	<a74683f90703050956p7532728we7005d540798710d@mail.gmail.com>
Message-ID: <45EC78AF.3070105@tackline.plus.com>

Bob Lee wrote:
> On 3/5/07, *Howard Lewis Ship* <hlship at gmail.com 
> <mailto:hlship at gmail.com>> wrote:
> 
>     I often have classes with a final field of type Map.
> 
>     I initialize the Map, loading values inside the constructor.  I never
>     change the contents
>     of the Map outside of the constructor.

> You should be fine so long as you don't let the "this" reference escape 
> from the constructor (I assume this is the case), and if you create the 
> enclosing object in one thread and access it from another, you must pass 
> the object off in a thread safe manner.

My understanding is that you do not have to publish safely, as it is a 
final field. The canonical example is the char array in String.

Also a point of note that the JLS isn't very clear on is that it's the 
constructor of the class holding the field that is important, not the 
constructor of the leaf implementation class. You should be able to 
publish this from subclass constructors.

Of course it depends upon the (probably undocumented) implementation of 
the Map. HashMap you should be fine. Anything lazy, or dynamically 
optimising, or something like WeakHashMap, and you could be in trouble.

Tom Hawtin

From brian at quiotix.com  Mon Mar  5 15:23:14 2007
From: brian at quiotix.com (Brian Goetz)
Date: Mon, 05 Mar 2007 15:23:14 -0500
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <ecd0e3310703051129i7e8a0a34r4283c008b3695bd4@mail.gmail.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>	<45EC68E6.8050602@quiotix.com>	<481031b40703051126v2e8f9301o5474780089a115a5@mail.gmail.com>
	<ecd0e3310703051129i7e8a0a34r4283c008b3695bd4@mail.gmail.com>
Message-ID: <45EC7C32.1000503@quiotix.com>

In the absence of final fields, there's nothing special about the end of 
a constructor.

In the presence of final fields, the end of a constructor is special, 
and offers something like the effects of releasing a lock, but only for 
the state reachable through that objects final fields.

Howard Lewis Ship wrote:
> I kind of interpreted this as: the JVM "flushes out" changes at the
> end of the constructor, much as it would at the end of a synchronized
> block.
> 
> On 3/5/07, Robert Konigsberg <konigsberg at gmail.com> wrote:
>> I'm not sure I follow you. How is m not effectively immutable? I presume
>> that 'no other modifications to 'm'' refers to both to reassigning the
>> reference as well as mutating the contents.
>>
>> It's also my assumption that any difference in compiler optimizations
>> between your two examples are effectively irrelevant. Is it possible that
>> I'm wrong about that?
>>
>> Thanks, Robert
>>
>> On 3/5/07, Brian Goetz <brian at quiotix.com> wrote:
>>> This code is thread-safe:
>>>
>>> public class Foo {
>>>      private final Map m = new HashMap();
>>>
>>>      public Foo() {
>>>          m.put("foo", "bar");
>>>      }
>>>
>>>      public isKnown(String s) {
>>>          return m.containsKey(s);
>>>      }
>>>
>>>      // no other modification to m
>>> }
>>>
>>> and this code is not:
>>>
>>> public class Foo {
>>>      private Map m = new HashMap();
>>>
>>>      public Foo() {
>>>          m.put("foo", "bar");
>>>      }
>>>
>>>      public isKnown(String s) {
>>>          return m.containsKey(s);
>>>      }
>>>
>>>      // no other modification to m
>>> }
>>>
>>> The difference is the final keyword.  If the map is effectively
>>> immutable, and the reference to it is final, and the values are set in
>>> the constructor, and the 'this' reference doesn't escape construction,
>>> you're OK.
>>>
>>> Howard Lewis Ship wrote:
>>>> I'm seeing some very strange effects in my code under load.  I've been
>>>> reviewing Brian Goetz's concurrency book, but I have a scenario I
>>>> frequently use that I have come to suspect:
>>>>
>>>> I often have classes with a final field of type Map.
>>>>
>>>> I initialize the Map, loading values inside the constructor.  I never
>>>> change the contents
>>>> of the Map outside of the constructor.
>>>>
>>>> I don't use a guard (i.e. synchronized) to access the map from other
>> code.
>>>> Is this thread safe, or do I need to synchronize the methods (or wrap
>>>> the map in a synchronzing wrapper)?
>>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at altair.cs.oswego.edu
>>>
>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> --
>> Robert Konigsberg
>> konigsberg at gmail.com
>>
>> "... you know what they say: Fool me once, shame on you. Fool me twice,
>> shame on The Cheat."
> 
> 

From osvaldo at visionnaire.com.br  Mon Mar  5 15:39:02 2007
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Mon, 05 Mar 2007 17:39:02 -0300
Subject: [concurrency-interest] Initializing a map inside a constructor
In-Reply-To: <45EC68E6.8050602@quiotix.com>
References: <ecd0e3310703050923j4c2df5ffq29f27e583bc88655@mail.gmail.com>
	<45EC68E6.8050602@quiotix.com>
Message-ID: <45EC7FE6.3030702@visionnaire.com.br>

One additional tip here is using an immutable map, provided by 
Collections.unmodifiableMap(). This makes your code safe even if you 
have to expose the map by a getter that returns the map, the key set, an 
iterator to the map or any other object that would normally allow 
clients to mess with the map. The unmodifiableMap() method creates one 
layer of indirection to the original map, but only clients that needs 
read-only access have to pay for that. Example:

public class Company {
     private final Map<String,Dept> depts = new HashMap<String,Dept>();
*     private final Map<String,Dept> deptsRO;
*     public Foo() {
         depts.put("Engineering", new Dept(...));
*         deptsRO = Collections.unmodifiableMap(m);
*     }
     public Set<Employee> (String ofDept) {
         return depts.get(ofDept).allEmployees();
     }
     public Set<Dept> allDepts () {
*         return deptsRO.keySet(s);
*     }
}

Notice how our Company class, internally, uses the normal depts map, 
which pays no extra indirection cost, for all tasks that don't expose 
the map's structure to clients. But in a method that must do that, like 
allDepts() (that we offer perhaps to avoid breaking the Law of Demeter 
in the clients...), we use the unmodifiable wrapper. (An unmodifiable 
map's keySet() will return a Set that's also unmodifiable, and so on.)

I have apps that cache vast amounts of metadata in memory - at init time 
I read tons of XML files and database records, put all that stuff in a 
complex graph of immutable objects and use that data from zillions of 
concurrent transactions without any synchronization. Because some of my 
data structures use collections that often have small number of 
children, empty or single-element collections are not rare, so I also 
use other utilities from collections to squeeze some additional 
performance. I created utility methods like the following to convert a 
collection into an "optimized" one if possible:

public static Map optimizedMap (final Map map) {
    switch (map.size()) {
    case 0:
        return Collections.EMPTY_MAP;
    case 1:
        final Map.Entry entry = 
(Map.Entry)map.entrySet().iterator().next();
        return Collections.singletonMap(entry.getKey(), 
entry.getValue());        
    default:
        return map;
    }
}

This version of the utility doesn't return unmodifiable maps (my data 
structures aren't exposed to untrusted code), it only substitutes the 
original map for a special zero- or single-instance map if possible, 
because the latter consume less memory and have alightly faster 
implementations of most methods (e.g., isEmpty() is a mere "return true" 
for EMPTY_MAP and "return false" for singletonMap()). But a version that 
would always return an unmodifiable map is easy, just add 
Collections.unmodifiableMap() only to the default case, since the other 
cases already return an implementation that is unmodifiable as a bonus - 
no extra indirection cost! Now, add similar utility methods 
unmodifiableSet() and unmodifiableList(), and you can build huge 
in-memory, shared, thread-safe data structures that, at least with 
respect to collection usage, will be optimally safe and efficient. And 
you don't even need j.u.c (the application I talked about is doomed by a 
certain J2EE server to use J2SE 1.4).

*Idea: the Collections.unmodifiableXxx() methods could embed the 
intelligence of my utility: if the received collection is empty or a 
singleton, unmodifiableXxx() could return an instance of the optimized 
empty/singleton class, rather than always creating an instance of the 
CollectionsUnmodifiableXxx class. This optimization only requires that 
**unmodifiableXxx() implement an additional switch structure like the 
code above. The result also avoids memory allocation for empty 
collections. As far as I can see, there is no compatibility issue... 
except for a strawman case like code that expects that for any c1 and 
c2, unmodifiableXxx(c1) != **unmodifiableXxx(c2)** even if 
c1.equals(c2), a requirement that's especially absurd for immutable 
collections.*

A+
Osvaldo

Brian Goetz escreveu:
> This code is thread-safe:
>
> public class Foo {
>      private final Map m = new HashMap();
>
>      public Foo() {
>          m.put("foo", "bar");
>      }
>
>      public isKnown(String s) {
>          return m.containsKey(s);
>      }
>
>      // no other modification to m
> }
>
> and this code is not:
>
> public class Foo {
>      private Map m = new HashMap();
>
>      public Foo() {
>          m.put("foo", "bar");
>      }
>
>      public isKnown(String s) {
>          return m.containsKey(s);
>      }
>
>      // no other modification to m
> }
>
> The difference is the final keyword.  If the map is effectively 
> immutable, and the reference to it is final, and the values are set in 
> the constructor, and the 'this' reference doesn't escape construction, 
> you're OK.
>
> Howard Lewis Ship wrote:
>   
>> I'm seeing some very strange effects in my code under load.  I've been
>> reviewing Brian Goetz's concurrency book, but I have a scenario I
>> frequently use that I have come to suspect:
>>
>> I often have classes with a final field of type Map.
>>
>> I initialize the Map, loading values inside the constructor.  I never
>> change the contents
>> of the Map outside of the constructor.
>>
>> I don't use a guard (i.e. synchronized) to access the map from other code.
>>
>> Is this thread safe, or do I need to synchronize the methods (or wrap
>> the map in a synchronzing wrapper)?
>>
>>     
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>   


-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070305/f7310e5e/attachment-0001.html 

From Martin.Buchholz at Sun.COM  Mon Mar  5 17:29:56 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Mon, 05 Mar 2007 14:29:56 -0800
Subject: [concurrency-interest]  Optimizing unmodifiableXXX
In-Reply-To: <mailman.39.1173127303.19091.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.39.1173127303.19091.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <45EC99E4.8050306@sun.com>

Osvaldo wrote:

*Idea: the Collections.unmodifiableXxx() methods could embed the
intelligence of my utility: if the received collection is empty or a
singleton, unmodifiableXxx() could return an instance of the optimized
empty/singleton class, rather than always creating an instance of the
CollectionsUnmodifiableXxx class. This optimization only requires that
**unmodifiableXxx() implement an additional switch structure like the
code above. The result also avoids memory allocation for empty
collections. As far as I can see, there is no compatibility issue...
except for a strawman case like code that expects that for any c1 and
c2, unmodifiableXxx(c1) != **unmodifiableXxx(c2)** even if
c1.equals(c2), a requirement that's especially absurd for immutable
collections.*

I think this won't work, since the underlying map may be mutable.

Unmodifiability is not immutability.

Martin

From osvaldo at visionnaire.com.br  Mon Mar  5 20:35:50 2007
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Mon, 05 Mar 2007 22:35:50 -0300
Subject: [concurrency-interest] Optimizing unmodifiableXXX
In-Reply-To: <45EC99E4.8050306@sun.com>
References: <mailman.39.1173127303.19091.concurrency-interest@altair.cs.oswego.edu>
	<45EC99E4.8050306@sun.com>
Message-ID: <45ECC576.1050803@visionnaire.com.br>

Martin Buchholz escreveu:
> Osvaldo wrote:
>
> *Idea: the Collections.unmodifiableXxx() methods could embed the
> intelligence of my utility: if the received collection is empty or a
> singleton, unmodifiableXxx() could return an instance of the optimized
> empty/singleton class, rather than always creating an instance of the
> CollectionsUnmodifiableXxx class. This optimization only requires that
> **unmodifiableXxx() implement an additional switch structure like the
> code above. The result also avoids memory allocation for empty
> collections. As far as I can see, there is no compatibility issue...
> except for a strawman case like code that expects that for any c1 and
> c2, unmodifiableXxx(c1) != **unmodifiableXxx(c2)** even if
> c1.equals(c2), a requirement that's especially absurd for immutable
> collections.*
>
> I think this won't work, since the underlying map may be mutable.
>
> Unmodifiability is not immutability.
>   
Um, only now I saw the problem - the fact that unmodifiableXxx() 
wrappers are synchronized with the underlying collections... damn. I 
knew that fact but since my personal usage pattern is always using these 
methods (as well as singletonXxx() etc) in front of immutable data, it 
seems my little green cells started to hide that unwanted feature of 
unmodifiableXxx() under the rug. Sorry. My idea would require a new API 
with the desired semantics.

A+
Osvaldo

-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223



From alarmnummer at gmail.com  Tue Mar  6 04:17:15 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 6 Mar 2007 10:17:15 +0100
Subject: [concurrency-interest] Condition.awaitNanosUninterruptibly why it
	is missing?
Message-ID: <1466c1d60703060117o70c8456bs6ef8929c77e1fb89@mail.gmail.com>

I was wondering why the Condition.awaitNanosUninterruptibly(long)
method is missing. You are able to do an uninterruptible wait on the
Condition without a timeout, but you are not able to do an
uninterruptible wait on a Condition with a timeout.

I have made the following implementation to bypass this limitation and
was wondering if it is correct.

 public static long awaitNanosUninterruptiblyAndThrow(Condition
condition, long timeoutNs) throws TimeoutException {
        if (condition == null) throw new NullPointerException();

        if(timeoutNs<=0) throw new TimeoutException();

        //This call clears the interruptstatus from the thread, because
        //the waiting we are going to do can't be interrupted.
        //But the interrupt status is restored at the
        //end of this method.
        boolean interrupt = Thread.interrupted();
        try {
            long startNs;
            while (true) {
                startNs = System.nanoTime();
                try {
                    timeoutNs = condition.awaitNanos(timeoutNs);
                    if(timeoutNs <= 0) throw new TimeoutException();
                    return timeoutNs;
                } catch (InterruptedException e) {
                    //make sure that the interrupt status is restored
when the thread
                    //leaves this method.
                    interrupt = true;
                    timeoutNs -= System.nanoTime()-startNs;
                    if(timeoutNs<=0) throw new TimeoutException();
                }
            }
        }finally {
            //If the thread has the interrupt status when it started calling
            //this method, it status should be restored. If the interrupt status
            //was set while waiting, it remains set.
            if (interrupt)
                Thread.currentThread().interrupt();
        }
    }

From peter.kovacs.1.0rc at gmail.com  Tue Mar  6 06:23:10 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 6 Mar 2007 12:23:10 +0100
Subject: [concurrency-interest] Confused about Component.getTreeLock()
Message-ID: <b6e8f2e80703060323w2753b9cdj83fa0dc1eacdd60a@mail.gmail.com>

Hi,

>From samples found on the Internet I can see that the
Component.getTreeLock() method is mainly used in custom layout
managers. Doesn't the assumption implied by the use of this lock go
against the general rule that Java graphical components should not be
manipulated from a thread other than the AWT Event Handler? In other
words: why are layout management functions likelier to be executed in
a custom thread -- a situation where locking is required at all --
than are other kinds of GUI functions?

Thanks
Peter

From dcholmes at optusnet.com.au  Tue Mar  6 06:56:09 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 6 Mar 2007 21:56:09 +1000
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <b6e8f2e80703060323w2753b9cdj83fa0dc1eacdd60a@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>

Peter,

The AWT was intended to be multi-threadsafe and does not enforce the
"everything must happen in the event thread rule". That was a mistake that
Swing rectified. So many of the AWT components use locks and the
component-tree uses the TreeLock. The problem with the tree-lock is that its
client--side synchronzation (all clients have to know when they should
acquire it) and yet there is no documentation telling clients when they need
to acquire it.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Kovacs
> Sent: Tuesday, 6 March 2007 9:23 PM
> To: concurrency-interest
> Subject: [concurrency-interest] Confused about Component.getTreeLock()
>
>
> Hi,
>
> >From samples found on the Internet I can see that the
> Component.getTreeLock() method is mainly used in custom layout
> managers. Doesn't the assumption implied by the use of this lock go
> against the general rule that Java graphical components should not be
> manipulated from a thread other than the AWT Event Handler? In other
> words: why are layout management functions likelier to be executed in
> a custom thread -- a situation where locking is required at all --
> than are other kinds of GUI functions?
>
> Thanks
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From tackline at tackline.plus.com  Tue Mar  6 07:41:04 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Tue, 06 Mar 2007 12:41:04 +0000
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <b6e8f2e80703060323w2753b9cdj83fa0dc1eacdd60a@mail.gmail.com>
References: <b6e8f2e80703060323w2753b9cdj83fa0dc1eacdd60a@mail.gmail.com>
Message-ID: <45ED6160.1030608@tackline.plus.com>

Peter Kovacs wrote:
> 
>>From samples found on the Internet I can see that the
> Component.getTreeLock() method is mainly used in custom layout
> managers. Doesn't the assumption implied by the use of this lock go
> against the general rule that Java graphical components should not be
> manipulated from a thread other than the AWT Event Handler? In other
> words: why are layout management functions likelier to be executed in
> a custom thread -- a situation where locking is required at all --
> than are other kinds of GUI functions?

Swing is single threaded, AWT is not. However, AWT has thousands 
(literally) of threading bugs, which are unlikely to be fixed. It is 
unreasonable to expect multithreaded AWT application code not to be 
completely broken.

Tom Hawtin

From peter.kovacs.1.0rc at gmail.com  Tue Mar  6 09:02:37 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 6 Mar 2007 15:02:37 +0100
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
References: <b6e8f2e80703060323w2753b9cdj83fa0dc1eacdd60a@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
Message-ID: <b6e8f2e80703060602g18516578v3dba21169b22d9fd@mail.gmail.com>

David, Tom,

I thank both of you for your quick and instructive replies. I
understand now that synchronizing on the Component tree lock can be
considered "legacy use" and made more sense in an ealier context.

Thanks
Peter


On 3/6/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> Peter,
>
> The AWT was intended to be multi-threadsafe and does not enforce the
> "everything must happen in the event thread rule". That was a mistake that
> Swing rectified. So many of the AWT components use locks and the
> component-tree uses the TreeLock. The problem with the tree-lock is that its
> client--side synchronzation (all clients have to know when they should
> acquire it) and yet there is no documentation telling clients when they need
> to acquire it.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> > Kovacs
> > Sent: Tuesday, 6 March 2007 9:23 PM
> > To: concurrency-interest
> > Subject: [concurrency-interest] Confused about Component.getTreeLock()
> >
> >
> > Hi,
> >
> > >From samples found on the Internet I can see that the
> > Component.getTreeLock() method is mainly used in custom layout
> > managers. Doesn't the assumption implied by the use of this lock go
> > against the general rule that Java graphical components should not be
> > manipulated from a thread other than the AWT Event Handler? In other
> > words: why are layout management functions likelier to be executed in
> > a custom thread -- a situation where locking is required at all --
> > than are other kinds of GUI functions?
> >
> > Thanks
> > Peter
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From gregg at cytetech.com  Tue Mar  6 10:27:02 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 06 Mar 2007 09:27:02 -0600
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
Message-ID: <45ED8846.6060801@cytetech.com>



David Holmes wrote:
> Peter,
> 
> The AWT was intended to be multi-threadsafe and does not enforce the
> "everything must happen in the event thread rule". That was a mistake that
> Swing rectified. So many of the AWT components use locks and the
> component-tree uses the TreeLock. The problem with the tree-lock is that its
> client--side synchronzation (all clients have to know when they should
> acquire it) and yet there is no documentation telling clients when they need
> to acquire it.

The standing statement from the swing development team WAS that you should never 
touch a "realized" component without using the event dispatch thread.  As of 
JDK1.5, they've ammended this statement to demand that anything which can cause 
a component to be realized must be in the event dispatch thread.  This includes 
things like Window.pack() and Window.setVisible(true).

Gregg Wonderly

From tackline at tackline.plus.com  Tue Mar  6 12:20:26 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Tue, 06 Mar 2007 17:20:26 +0000
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <45ED8846.6060801@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com>
Message-ID: <45EDA2DA.90602@tackline.plus.com>

Gregg Wonderly wrote:
> 
> The standing statement from the swing development team WAS that you should never 
> touch a "realized" component without using the event dispatch thread.  As of 
> JDK1.5, they've ammended this statement to demand that anything which can cause 
> a component to be realized must be in the event dispatch thread.  This includes 
> things like Window.pack() and Window.setVisible(true).

For Swing components. In fact other stuff, like JTextField via 
documents, can use invokeLater internally and therefore screw up. So now 
it's do everything on the EDT (with a few exceptions). It turns out that 
the explicit multithreading capabilities of the Swing text doesn't 
actually work or indeed make any sense.

I think there's probably a more general lesson in there.

Tom Hawtin

From gregg at cytetech.com  Tue Mar  6 16:02:04 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 06 Mar 2007 15:02:04 -0600
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <45EDA2DA.90602@tackline.plus.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com> <45EDA2DA.90602@tackline.plus.com>
Message-ID: <45EDD6CC.8020304@cytetech.com>



Thomas Hawtin wrote:
> Gregg Wonderly wrote:
> 
>>
>> The standing statement from the swing development team WAS that you 
>> should never touch a "realized" component without using the event 
>> dispatch thread.  As of JDK1.5, they've ammended this statement to 
>> demand that anything which can cause a component to be realized must 
>> be in the event dispatch thread.  This includes things like 
>> Window.pack() and Window.setVisible(true).
> 
> 
> For Swing components. In fact other stuff, like JTextField via 
> documents, can use invokeLater internally and therefore screw up. So now 
> it's do everything on the EDT (with a few exceptions). It turns out that 
> the explicit multithreading capabilities of the Swing text doesn't 
> actually work or indeed make any sense.

In that case, the component (the JTextField) is realized, so based on the old 
verbage, you should "know" to use the EDT.  There are a number of things that 
use InvokeLater to multitask the GUI better.  JComponent.revalidate() is one 
such thing.  If you've ever used a resizing JPanel inside of JScrollPane, you 
know that you have to be careful to use InvokeLater for anything that you do 
after a JPanel.setPreferredSize() (such as repaint or other things that use the 
new size).  If you do them in the EDT, and that EDT leg has invoked 
setPreferredSize(), then you won't see the size changes that setPreferredSize() 
effected.

At the end of the day, it's a tough balancing act.  You want to allow the 
application and the EDT to proceed independently, yet to be synchronized in how 
they interact with each other.

Gregg Wonderly

From tackline at tackline.plus.com  Tue Mar  6 16:23:40 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Tue, 06 Mar 2007 21:23:40 +0000
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <45EDD6CC.8020304@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com> <45EDA2DA.90602@tackline.plus.com>
	<45EDD6CC.8020304@cytetech.com>
Message-ID: <45EDDBDC.8010107@tackline.plus.com>

Gregg Wonderly wrote:
> 
> Thomas Hawtin wrote:
>>
>> For Swing components. In fact other stuff, like JTextField via 
>> documents, can use invokeLater internally and therefore screw up. So 
>> now it's do everything on the EDT (with a few exceptions). It turns 
>> out that the explicit multithreading capabilities of the Swing text 
>> doesn't actually work or indeed make any sense.
> 
> In that case, the component (the JTextField) is realized, so based on 

No. Even without being realised, documents can post to the EDT in 
response to be mutated from a non-EDT thread. JTextField has listeners 
on the object, so is being updated both on and off the EDT, without 
having been realised.

> the old verbage, you should "know" to use the EDT.  There are a number 
> of things that use InvokeLater to multitask the GUI better.  
> JComponent.revalidate() is one such thing.  If you've ever used a 
> resizing JPanel inside of JScrollPane, you know that you have to be 
> careful to use InvokeLater for anything that you do after a 
> JPanel.setPreferredSize() (such as repaint or other things that use the 
> new size).  If you do them in the EDT, and that EDT leg has invoked 
> setPreferredSize(), then you won't see the size changes that 
> setPreferredSize() effected.

Sometimes you need invokeLater even on the EDT. Usually this is down to 
listeners misbehaving (unfortunately they are often designed to misbehave).

> At the end of the day, it's a tough balancing act.  You want to allow 
> the application and the EDT to proceed independently, yet to be 
> synchronized in how they interact with each other.

You want to keep a very clear separation between what is EDT and what is 
not.

Tom Hawtin


From joe.bowbeer at gmail.com  Tue Mar  6 16:34:36 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 6 Mar 2007 13:34:36 -0800
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <45EDD6CC.8020304@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com> <45EDA2DA.90602@tackline.plus.com>
	<45EDD6CC.8020304@cytetech.com>
Message-ID: <31f2a7bd0703061334p47d136b5s99ac1eed3765fc6b@mail.gmail.com>

On 3/6/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
> Thomas Hawtin wrote:
> > Gregg Wonderly wrote:
> >>
> > It turns out that
> > the explicit multithreading capabilities of the Swing text doesn't
> > actually work or indeed make any sense.
>
> In that case, the component (the JTextField) is realized, so based on the old
> verbage, you should "know" to use the EDT.

There was an attempt to add support for asynchronous document updates
to Swing (though I could never figure out how it was supposed to work
reliably).  I think this is what Thomas was referring to.

From gregg at cytetech.com  Tue Mar  6 16:34:10 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 06 Mar 2007 15:34:10 -0600
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <45EDDBDC.8010107@tackline.plus.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com> <45EDA2DA.90602@tackline.plus.com>
	<45EDD6CC.8020304@cytetech.com>
	<45EDDBDC.8010107@tackline.plus.com>
Message-ID: <45EDDE52.3040207@cytetech.com>



Thomas Hawtin wrote:
> Gregg Wonderly wrote:
>> In that case, the component (the JTextField) is realized, so based on 
> 
> No. Even without being realised, documents can post to the EDT in 
> response to be mutated from a non-EDT thread. JTextField has listeners 
> on the object, so is being updated both on and off the EDT, without 
> having been realised.

Okay, I missed that you were referring to the unrealized behavior too.  Yes, a 
setText() call and many others can cause the component to assert the lock as it 
attempts to compute its new preferredSize().  That was a surprising behavior 
change as well.

> Sometimes you need invokeLater even on the EDT. Usually this is down to 
> listeners misbehaving (unfortunately they are often designed to misbehave).

I guess I was not being very clear.  If you read up on JScrollPane, and the 
suggested implementation of calling setPreferredSize() followed by revalidate(), 
it doesn't seem too complicated.  You have to realize/know though that 
revalidate() is using invokeLater() to make its changes take effect, and thus 
you MUST use invokeLater() for any activity that has to happen after the new 
component size takes effect, no matter whether you are running on the EDT at 
that point or not.  In particular, scrolling panes that contain output of some 
sort that you always want to scroll to the end of after the output is added, 
must use invokeLater() to change the scrollbar position, and, they must use 
ordering controls to make sure that another thread doesn't MESS with the state 
of the components preferredSize() while that scroll is being calculated/executed.

>> At the end of the day, it's a tough balancing act.  You want to allow 
>> the application and the EDT to proceed independently, yet to be 
>> synchronized in how they interact with each other.
>
> You want to keep a very clear separation between what is EDT and what is 
> not.

As was mentioned earlier, there is very little, if any documentation about what 
separation is actually mandated by the implementation.

Gregg Wonderly

From Martin.Buchholz at Sun.COM  Tue Mar  6 22:31:20 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Tue, 06 Mar 2007 19:31:20 -0800
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 26,
	Issue 7
In-Reply-To: <mailman.3.1173200400.9558.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.3.1173200400.9558.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <45EE3208.6060500@sun.com>

Peter Veentjer wondered,

"I was wondering why the Condition.awaitNanosUninterruptibly(long)
method is missing. You are able to do an uninterruptible wait on the
Condition without a timeout, but you are not able to do an
uninterruptible wait on a Condition with a timeout."

I've wondered the same thing myself in the past.

Should Peter's static method be added to the JDK somewhere?
Unfortunately, we cannot add new methods to existing interfaces.

Martin


From dcholmes at optusnet.com.au  Tue Mar  6 23:48:02 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 7 Mar 2007 14:48:02 +1000
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 26,
	Issue 7
In-Reply-To: <45EE3208.6060500@sun.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIELOHFAA.dcholmes@optusnet.com.au>

In early 2003 we thrashed out the details of the timed-blocking methods. At
that time we opined that anyone prepared to handle timeouts should also be
prepared to handle interrupts. We added awaitUninteruptibly as a concession
to the occasional need to have to wait for some condition regardless of
cancellation requests, and because it was a trivial implementation.
Generally the blocking methods do not have non-interruptible forms because
they are all considered cancellation points.

If we added awaitNanosUninterruptibly you could argue that all
timed-blocking methods should have an uninterruptible form. I don't think
they are needed often enough to warrant library inclusion.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
> Buchholz
> Sent: Wednesday, 7 March 2007 1:31 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
> 26,Issue 7
>
>
> Peter Veentjer wondered,
>
> "I was wondering why the Condition.awaitNanosUninterruptibly(long)
> method is missing. You are able to do an uninterruptible wait on the
> Condition without a timeout, but you are not able to do an
> uninterruptible wait on a Condition with a timeout."
>
> I've wondered the same thing myself in the past.
>
> Should Peter's static method be added to the JDK somewhere?
> Unfortunately, we cannot add new methods to existing interfaces.
>
> Martin
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From peter.kovacs.1.0rc at gmail.com  Wed Mar  7 05:49:13 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Wed, 7 Mar 2007 11:49:13 +0100
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <45EDDE52.3040207@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com> <45EDA2DA.90602@tackline.plus.com>
	<45EDD6CC.8020304@cytetech.com> <45EDDBDC.8010107@tackline.plus.com>
	<45EDDE52.3040207@cytetech.com>
Message-ID: <b6e8f2e80703070249i33724cc6y2c53724a450f7b8a@mail.gmail.com>

Gregg,

> ordering controls to make sure that another thread doesn't MESS with the state
> of the components preferredSize()

Do "ordering controls" mean "synchronization" here?

Thanks
Peter

On 3/6/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Thomas Hawtin wrote:
> > Gregg Wonderly wrote:
> >> In that case, the component (the JTextField) is realized, so based on
> >
> > No. Even without being realised, documents can post to the EDT in
> > response to be mutated from a non-EDT thread. JTextField has listeners
> > on the object, so is being updated both on and off the EDT, without
> > having been realised.
>
> Okay, I missed that you were referring to the unrealized behavior too.  Yes, a
> setText() call and many others can cause the component to assert the lock as it
> attempts to compute its new preferredSize().  That was a surprising behavior
> change as well.
>
> > Sometimes you need invokeLater even on the EDT. Usually this is down to
> > listeners misbehaving (unfortunately they are often designed to misbehave).
>
> I guess I was not being very clear.  If you read up on JScrollPane, and the
> suggested implementation of calling setPreferredSize() followed by revalidate(),
> it doesn't seem too complicated.  You have to realize/know though that
> revalidate() is using invokeLater() to make its changes take effect, and thus
> you MUST use invokeLater() for any activity that has to happen after the new
> component size takes effect, no matter whether you are running on the EDT at
> that point or not.  In particular, scrolling panes that contain output of some
> sort that you always want to scroll to the end of after the output is added,
> must use invokeLater() to change the scrollbar position, and, they must use
> ordering controls to make sure that another thread doesn't MESS with the state
> of the components preferredSize() while that scroll is being calculated/executed.
>
> >> At the end of the day, it's a tough balancing act.  You want to allow
> >> the application and the EDT to proceed independently, yet to be
> >> synchronized in how they interact with each other.
> >
> > You want to keep a very clear separation between what is EDT and what is
> > not.
>
> As was mentioned earlier, there is very little, if any documentation about what
> separation is actually mandated by the implementation.
>
> Gregg Wonderly
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From gregg at cytetech.com  Wed Mar  7 09:56:09 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 07 Mar 2007 08:56:09 -0600
Subject: [concurrency-interest] Confused about Component.getTreeLock()
In-Reply-To: <b6e8f2e80703070249i33724cc6y2c53724a450f7b8a@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCMELJHFAA.dcholmes@optusnet.com.au>
	<45ED8846.6060801@cytetech.com> <45EDA2DA.90602@tackline.plus.com>
	<45EDD6CC.8020304@cytetech.com>
	<45EDDBDC.8010107@tackline.plus.com>
	<45EDDE52.3040207@cytetech.com>
	<b6e8f2e80703070249i33724cc6y2c53724a450f7b8a@mail.gmail.com>
Message-ID: <45EED289.8040002@cytetech.com>



Peter Kovacs wrote:
>>ordering controls to make sure that another thread doesn't MESS with the state
>>of the components preferredSize()
> 
> Do "ordering controls" mean "synchronization" here?

It means inter-thread ordering that spans threads and time.  Drawing on the 
example that I was using before:

Swing's text highlighting is very slow when rendering and scrolling large 
amounts of highlighted text.

We needed a data tracing window that showed sent and received text, coloring 
each differently.  So, we implemented a faster highlighter using a JPanel inside 
of a scrollpane.  The JPanel has to be sized as new text arrives.  After the 
resize, you need to compute the location that the scrollbar should move to and 
move it.  Because of the EDT.invokeLater() calls calls involved in some of the 
logic, you have to use invoke later for everything.  Because each invokeLater() 
is a separate runnable, you have to keep order between their activities and 
subsequent arriving text which can queue new Runnables inbetween others.

private void newText( String str, boolean sent ) {
	list.add( new TextElement( str, sent ) );
	synchronized( lock ) {
		if( working )
			return;
		working = true;
	}

	// Figure out how tall we are now for scrollbar adjustments
	Dimension sz = computeSize();

	// We are usually not in the EDT
	runInSwing( new Runnable() {
		public void run() {
			// Change the panel size to fit all
			// of the text.
			panel.setPreferredSize( sz );
		}
	});

	// This causes an invokeLater() to revalidate, so now
	// everything else that depends on time ordering must run
	// via invokeLater().
	panel.revalidate();

	// Render all the text into the panel
	panel.repaint();

	// Queue the scrollbar positioning because the
	// revalidate and repaint are queued above,
	// not run in line.
	SwingUtilities.invokeLater( new Runnable() {
		public void run() {
			try {
				scrollToEnd();
			} finally {
				working = false;
			}
		}
	});
}

Now, this particular style of ordering with a shared "lock", is perilous because 
you can't use any language guarentees to make sure that working is set back to 
false, no matter what happens.

We had to defer updates that were competing for scrollbar position changes 
because if we didn't, there are troublesome interactions because diferrent 
threads are putting things into the EDT queue.

Gregg Wonderly

From alarmnummer at gmail.com  Thu Mar  8 04:02:01 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 8 Mar 2007 10:02:01 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 26,
	Issue 7
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIELOHFAA.dcholmes@optusnet.com.au>
References: <45EE3208.6060500@sun.com>
	<NFBBKALFDCPFIDBNKAPCIELOHFAA.dcholmes@optusnet.com.au>
Message-ID: <1466c1d60703080102m415637f9w35c091ebc1935a91@mail.gmail.com>

Hmmm.. I have thought about your replay David.

At the moment I'm writing some concurrency utility classes, and I most
of them contain something like this:

foo
fooUninterruptibly
tryFoo(long,timeUnit)
tryFooUninterruptibly(long,TimeUnit)

The problem is that you get a lot of methods only differ in the fact
that the call is interruptible or not. I think I have found a solution
for the case where a non interruptble version is needed, without
writing all the methods.

I have created the following classes:

public abstract class UninterruptibleCall<E> {

    public abstract E executeInterruptible() throws InterruptedException;

    public E execute() {
        boolean restoreInterrupt = Thread.interrupted();
        try {
            while (true) {
                try {
                    return executeInterruptible();
                } catch (InterruptedException ex) {
                    assert !Thread.currentThread().isInterrupted();
                    restoreInterrupt = true;
                }
            }
        } finally {
            if (restoreInterrupt)
                Thread.currentThread().interrupt();
        }
    }
}

public abstract class TimedUninterruptibleCall<E> {

    public abstract E executeInterruptible(long timeout, TimeUnit
unit)throws InterruptedException, TimeoutException;

    public E execute(long timeout, TimeUnit unit)throws TimeoutException{
        long timeoutNs = ConcurrencyUtil.toUsableNanos(timeout,unit);

        boolean restoreInterrupt = Thread.interrupted();
        try{
            while(true){
                long startNs = System.nanoTime();
                try {
                    return executeInterruptible(timeoutNs,
TimeUnit.NANOSECONDS);
                } catch (InterruptedException e) {
                    assert !Thread.currentThread().isInterrupted();
                    restoreInterrupt = true;

                    timeoutNs -= System.nanoTime()-startNs;
                    if(timeoutNs<=0)
                        throw new TimeoutException();
                }
            }
        }finally{
            if(restoreInterrupt)
                Thread.currentThread().interrupt();
        }
    }
}


usage example:

void foo(){
    CallUninterruptibly call = new CallUninterruptibly(){
          void executeInterruptibly()throws InterruptedEx{
                 blockingQueue.put("foo");
                 return null;
          }
   }

   call.execute();
}

These can be used to get a non interruptible version of an
interruptible call. It is just a proof of concept, I haven't tested
them so they could contains bugs. But I hope you get the point. If
this is usable, it means that I can remove all the non uninterruptible
methods.



On 3/7/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> In early 2003 we thrashed out the details of the timed-blocking methods. At
> that time we opined that anyone prepared to handle timeouts should also be
> prepared to handle interrupts. We added awaitUninteruptibly as a concession
> to the occasional need to have to wait for some condition regardless of
> cancellation requests, and because it was a trivial implementation.
> Generally the blocking methods do not have non-interruptible forms because
> they are all considered cancellation points.
>
> If we added awaitNanosUninterruptibly you could argue that all
> timed-blocking methods should have an uninterruptible form. I don't think
> they are needed often enough to warrant library inclusion.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
> > Buchholz
> > Sent: Wednesday, 7 March 2007 1:31 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
> > 26,Issue 7
> >
> >
> > Peter Veentjer wondered,
> >
> > "I was wondering why the Condition.awaitNanosUninterruptibly(long)
> > method is missing. You are able to do an uninterruptible wait on the
> > Condition without a timeout, but you are not able to do an
> > uninterruptible wait on a Condition with a timeout."
> >
> > I've wondered the same thing myself in the past.
> >
> > Should Peter's static method be added to the JDK somewhere?
> > Unfortunately, we cannot add new methods to existing interfaces.
> >
> > Martin
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dcholmes at optusnet.com.au  Fri Mar  9 21:03:18 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sat, 10 Mar 2007 12:03:18 +1000
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 26,
	Issue 7
In-Reply-To: <1466c1d60703080102m415637f9w35c091ebc1935a91@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEMGHFAA.dcholmes@optusnet.com.au>

Peter,

I think what you have is workable. Note that your asserts aren't valid -
they assume only single interrupts are targeted at a given thread.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Veentjer
> Sent: Thursday, 8 March 2007 7:02 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu; Martin Buchholz
> Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
> 26,Issue 7
>
>
> Hmmm.. I have thought about your replay David.
>
> At the moment I'm writing some concurrency utility classes, and I most
> of them contain something like this:
>
> foo
> fooUninterruptibly
> tryFoo(long,timeUnit)
> tryFooUninterruptibly(long,TimeUnit)
>
> The problem is that you get a lot of methods only differ in the fact
> that the call is interruptible or not. I think I have found a solution
> for the case where a non interruptble version is needed, without
> writing all the methods.
>
> I have created the following classes:
>
> public abstract class UninterruptibleCall<E> {
>
>     public abstract E executeInterruptible() throws InterruptedException;
>
>     public E execute() {
>         boolean restoreInterrupt = Thread.interrupted();
>         try {
>             while (true) {
>                 try {
>                     return executeInterruptible();
>                 } catch (InterruptedException ex) {
>                     assert !Thread.currentThread().isInterrupted();
>                     restoreInterrupt = true;
>                 }
>             }
>         } finally {
>             if (restoreInterrupt)
>                 Thread.currentThread().interrupt();
>         }
>     }
> }
>
> public abstract class TimedUninterruptibleCall<E> {
>
>     public abstract E executeInterruptible(long timeout, TimeUnit
> unit)throws InterruptedException, TimeoutException;
>
>     public E execute(long timeout, TimeUnit unit)throws TimeoutException{
>         long timeoutNs = ConcurrencyUtil.toUsableNanos(timeout,unit);
>
>         boolean restoreInterrupt = Thread.interrupted();
>         try{
>             while(true){
>                 long startNs = System.nanoTime();
>                 try {
>                     return executeInterruptible(timeoutNs,
> TimeUnit.NANOSECONDS);
>                 } catch (InterruptedException e) {
>                     assert !Thread.currentThread().isInterrupted();
>                     restoreInterrupt = true;
>
>                     timeoutNs -= System.nanoTime()-startNs;
>                     if(timeoutNs<=0)
>                         throw new TimeoutException();
>                 }
>             }
>         }finally{
>             if(restoreInterrupt)
>                 Thread.currentThread().interrupt();
>         }
>     }
> }
>
>
> usage example:
>
> void foo(){
>     CallUninterruptibly call = new CallUninterruptibly(){
>           void executeInterruptibly()throws InterruptedEx{
>                  blockingQueue.put("foo");
>                  return null;
>           }
>    }
>
>    call.execute();
> }
>
> These can be used to get a non interruptible version of an
> interruptible call. It is just a proof of concept, I haven't tested
> them so they could contains bugs. But I hope you get the point. If
> this is usable, it means that I can remove all the non uninterruptible
> methods.
>
>
>
> On 3/7/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > In early 2003 we thrashed out the details of the timed-blocking
> methods. At
> > that time we opined that anyone prepared to handle timeouts
> should also be
> > prepared to handle interrupts. We added awaitUninteruptibly as
> a concession
> > to the occasional need to have to wait for some condition regardless of
> > cancellation requests, and because it was a trivial implementation.
> > Generally the blocking methods do not have non-interruptible
> forms because
> > they are all considered cancellation points.
> >
> > If we added awaitNanosUninterruptibly you could argue that all
> > timed-blocking methods should have an uninterruptible form. I
> don't think
> > they are needed often enough to warrant library inclusion.
> >
> > Cheers,
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
> > > Buchholz
> > > Sent: Wednesday, 7 March 2007 1:31 PM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
> > > 26,Issue 7
> > >
> > >
> > > Peter Veentjer wondered,
> > >
> > > "I was wondering why the Condition.awaitNanosUninterruptibly(long)
> > > method is missing. You are able to do an uninterruptible wait on the
> > > Condition without a timeout, but you are not able to do an
> > > uninterruptible wait on a Condition with a timeout."
> > >
> > > I've wondered the same thing myself in the past.
> > >
> > > Should Peter's static method be added to the JDK somewhere?
> > > Unfortunately, we cannot add new methods to existing interfaces.
> > >
> > > Martin
> > >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From alarmnummer at gmail.com  Sat Mar 10 07:17:34 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Sat, 10 Mar 2007 13:17:34 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 26,
	Issue 7
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEMGHFAA.dcholmes@optusnet.com.au>
References: <1466c1d60703080102m415637f9w35c091ebc1935a91@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEMGHFAA.dcholmes@optusnet.com.au>
Message-ID: <1466c1d60703100417n4cebf540wc0a40f93dc52af71@mail.gmail.com>

True, a different thread could have reset the interrupt-status while
the interruptedexception is handled.


On 3/10/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> Peter,
>
> I think what you have is workable. Note that your asserts aren't valid -
> they assume only single interrupts are targeted at a given thread.
>
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> > Veentjer
> > Sent: Thursday, 8 March 2007 7:02 PM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu; Martin Buchholz
> > Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
> > 26,Issue 7
> >
> >
> > Hmmm.. I have thought about your replay David.
> >
> > At the moment I'm writing some concurrency utility classes, and I most
> > of them contain something like this:
> >
> > foo
> > fooUninterruptibly
> > tryFoo(long,timeUnit)
> > tryFooUninterruptibly(long,TimeUnit)
> >
> > The problem is that you get a lot of methods only differ in the fact
> > that the call is interruptible or not. I think I have found a solution
> > for the case where a non interruptble version is needed, without
> > writing all the methods.
> >
> > I have created the following classes:
> >
> > public abstract class UninterruptibleCall<E> {
> >
> >     public abstract E executeInterruptible() throws InterruptedException;
> >
> >     public E execute() {
> >         boolean restoreInterrupt = Thread.interrupted();
> >         try {
> >             while (true) {
> >                 try {
> >                     return executeInterruptible();
> >                 } catch (InterruptedException ex) {
> >                     assert !Thread.currentThread().isInterrupted();
> >                     restoreInterrupt = true;
> >                 }
> >             }
> >         } finally {
> >             if (restoreInterrupt)
> >                 Thread.currentThread().interrupt();
> >         }
> >     }
> > }
> >
> > public abstract class TimedUninterruptibleCall<E> {
> >
> >     public abstract E executeInterruptible(long timeout, TimeUnit
> > unit)throws InterruptedException, TimeoutException;
> >
> >     public E execute(long timeout, TimeUnit unit)throws TimeoutException{
> >         long timeoutNs = ConcurrencyUtil.toUsableNanos(timeout,unit);
> >
> >         boolean restoreInterrupt = Thread.interrupted();
> >         try{
> >             while(true){
> >                 long startNs = System.nanoTime();
> >                 try {
> >                     return executeInterruptible(timeoutNs,
> > TimeUnit.NANOSECONDS);
> >                 } catch (InterruptedException e) {
> >                     assert !Thread.currentThread().isInterrupted();
> >                     restoreInterrupt = true;
> >
> >                     timeoutNs -= System.nanoTime()-startNs;
> >                     if(timeoutNs<=0)
> >                         throw new TimeoutException();
> >                 }
> >             }
> >         }finally{
> >             if(restoreInterrupt)
> >                 Thread.currentThread().interrupt();
> >         }
> >     }
> > }
> >
> >
> > usage example:
> >
> > void foo(){
> >     CallUninterruptibly call = new CallUninterruptibly(){
> >           void executeInterruptibly()throws InterruptedEx{
> >                  blockingQueue.put("foo");
> >                  return null;
> >           }
> >    }
> >
> >    call.execute();
> > }
> >
> > These can be used to get a non interruptible version of an
> > interruptible call. It is just a proof of concept, I haven't tested
> > them so they could contains bugs. But I hope you get the point. If
> > this is usable, it means that I can remove all the non uninterruptible
> > methods.
> >
> >
> >
> > On 3/7/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > > In early 2003 we thrashed out the details of the timed-blocking
> > methods. At
> > > that time we opined that anyone prepared to handle timeouts
> > should also be
> > > prepared to handle interrupts. We added awaitUninteruptibly as
> > a concession
> > > to the occasional need to have to wait for some condition regardless of
> > > cancellation requests, and because it was a trivial implementation.
> > > Generally the blocking methods do not have non-interruptible
> > forms because
> > > they are all considered cancellation points.
> > >
> > > If we added awaitNanosUninterruptibly you could argue that all
> > > timed-blocking methods should have an uninterruptible form. I
> > don't think
> > > they are needed often enough to warrant library inclusion.
> > >
> > > Cheers,
> > > David Holmes
> > >
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
> > > > Buchholz
> > > > Sent: Wednesday, 7 March 2007 1:31 PM
> > > > To: concurrency-interest at cs.oswego.edu
> > > > Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
> > > > 26,Issue 7
> > > >
> > > >
> > > > Peter Veentjer wondered,
> > > >
> > > > "I was wondering why the Condition.awaitNanosUninterruptibly(long)
> > > > method is missing. You are able to do an uninterruptible wait on the
> > > > Condition without a timeout, but you are not able to do an
> > > > uninterruptible wait on a Condition with a timeout."
> > > >
> > > > I've wondered the same thing myself in the past.
> > > >
> > > > Should Peter's static method be added to the JDK somewhere?
> > > > Unfortunately, we cannot add new methods to existing interfaces.
> > > >
> > > > Martin
> > > >
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at altair.cs.oswego.edu
> > > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From rajesh.balamohan at gmail.com  Wed Mar 14 23:01:55 2007
From: rajesh.balamohan at gmail.com (Rajesh Balamohan)
Date: Thu, 15 Mar 2007 03:01:55 +0000
Subject: [concurrency-interest] Regarding a design suggestion..
In-Reply-To: <1da12e810703140856o2503e003r263a1967f768d026@mail.gmail.com>
References: <1da12e810703140856o2503e003r263a1967f768d026@mail.gmail.com>
Message-ID: <1da12e810703142001m33a62725h99eef7092dcd4cd2@mail.gmail.com>

Any inputs on this would be of great help Dough.


                ============                 ============
                |          |                 |          |
                |          |                 |          |
Insert Item =>  | Inbound  |                 | Outbound |   ===> out
                |  Queue   |                 |  Queue   |
                |          |                 |          |
                |          |                 |          |
                ============                 ============
                    |                            |
                    |                             |                |
                    |                            |------------- |
    1.    A seperate thread does                                  |
        queue.take() from here                  1.    A seperate thread does
    2. Creates a runnable task and                  queue.take() from
outbound queue
    enques to ThreadPoolExecutor (B)           2. Creates a runnable task
and
                                                enques to ThreadPoolExecutor
(C)




Please let me know if you need more explanation.

1. There are 2 LinkedBlockingQueue. One for inbound and another for outbound
2. There are 3 ThreadPoolExecutors available. Letz say A, B, C
3. Someone puts a task in "A", which puts an item in InboundQueue.
4. A separate thread is blocked on "take()" method of this queue. Once it
gets an item, it
creates another "TASK" and puts it in "B" threadpool.
5. This task does some work and finally enqueues to "OUTBOUND QUEUE"
6. OUTBOUND Queue has a separate thread to dequeue and do some processing in
"C" threadpool.

Problem:
========
1. Too many short lived tasks are created.
2. Too many context switching happening in system due to #1.
3. Do you suggest any better way to implement it. Basic thing is the
queueing and dequeuing has to happen asynchronously.


-- 
~Rajesh.B
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070315/b93d16d7/attachment.html 

From dcholmes at optusnet.com.au  Thu Mar 15 00:02:17 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 15 Mar 2007 14:02:17 +1000
Subject: [concurrency-interest] Regarding a design suggestion..
In-Reply-To: <1da12e810703142001m33a62725h99eef7092dcd4cd2@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIENFHFAA.dcholmes@optusnet.com.au>

Rajesh,

If the queues were directly attached to the pools you wouldn't need the
intermediate threads. You also may not need three pools. Direct insertion
into the queue has some issues when the queue is attached to a pool - it
avoids the normal thread creation logic - but you can work around that to
some extent by either pre-priming the pool, or else turning what appears to
be queue.put() into an Executor.execute.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rajesh
> Balamohan
> Sent: Thursday, 15 March 2007 1:02 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Regarding a design suggestion..
>
>
> Any inputs on this would be of great help Dough.
>
>
>                 ============                 ============
>                 |          |                 |          |
>                 |          |                 |          |
> Insert Item =>  | Inbound  |                 | Outbound |   ===> out
>                 |  Queue   |                 |  Queue   |
>                 |          |                 |          |
>                 |          |                 |          |
>                 ============                 ============
>                     |                            |
>                     |                            |                |
>                     |                            |------------- |
>     1.    A seperate thread does                                  |
>         queue.take() from here                  1.    A seperate
> thread does
>     2. Creates a runnable task and                  queue.take()
> from outbound queue
>     enques to ThreadPoolExecutor (B)           2. Creates a
> runnable task and
>                                                 enques to
> ThreadPoolExecutor (C)
>
>
>
>
> Please let me know if you need more explanation.
>
> 1. There are 2 LinkedBlockingQueue. One for inbound and another
> for outbound
> 2. There are 3 ThreadPoolExecutors available. Letz say A, B, C
> 3. Someone puts a task in "A", which puts an item in InboundQueue.
> 4. A separate thread is blocked on "take()" method of this queue.
> Once it gets an item, it
> creates another "TASK" and puts it in "B" threadpool.
> 5. This task does some work and finally enqueues to "OUTBOUND QUEUE"
> 6. OUTBOUND Queue has a separate thread to dequeue and do some
> processing in "C" threadpool.
>
> Problem:
> ========
> 1. Too many short lived tasks are created.
> 2. Too many context switching happening in system due to #1.
> 3. Do you suggest any better way to implement it. Basic thing is
> the queueing and dequeuing has to happen asynchronously.
>
>
> --
> ~Rajesh.B


From alarmnummer at gmail.com  Thu Mar 15 04:14:59 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 15 Mar 2007 09:14:59 +0100
Subject: [concurrency-interest] Regarding a design suggestion..
In-Reply-To: <1da12e810703142001m33a62725h99eef7092dcd4cd2@mail.gmail.com>
References: <1da12e810703140856o2503e003r263a1967f768d026@mail.gmail.com>
	<1da12e810703142001m33a62725h99eef7092dcd4cd2@mail.gmail.com>
Message-ID: <1466c1d60703150114w45963803p97e1630f252a3152@mail.gmail.com>

Hi Rahesh,

I think I understand your pain. You need some kind of mechanism that
isn't passively waiting for something to execute (like an executor)
but is actively  waiting for something to execute.

I have created a threading structure called the Repeater that does
this job, example:

BlockingQueue inbound = new ArrayBlockingQueue();
BlockingQueue outbound = new ArrayBlockingQueue();

class BTask implements Runnable{
	public void run(){
		Object item = blockingQueue.take();
		Object result = item.process();
		outbound.put(result);
	}
}

class CTask implements Runnable{
	public void run(){
		Object item = outbound.take();
		take.someMoreProcessing();
	}
}

Repeater brepeater = new ThreadPoolRepeater(1);
brepeater.repeat(new BTask());
Repeater crepeater = new ThreadPoolRepeater(1);
crepeater.repeat(new CTask());

I don't have enough information for the 'A' step. It could be done
with an Executor when a task is actively placed, or done with a
Repeater if no task is being placed, but you need repeated execution.
If someone could place data directly in the inbound queue, the whole A
step can be removed.

On 3/15/07, Rajesh Balamohan <rajesh.balamohan at gmail.com> wrote:
> Any inputs on this would be of great help Dough.
>
>
>                 ============                 ============
>                 |          |                 |          |
>                 |          |                 |          |
> Insert Item =>  | Inbound  |                 | Outbound |   ===> out
>                 |  Queue   |                 |  Queue   |
>                 |          |                 |          |
>                 |          |                 |          |
>                 ============                 ============
>                     |                            |
>                     |                             |                |
>                     |                            |------------- |
>     1.    A seperate thread does                                  |
>         queue.take() from here                  1.    A seperate thread does
>     2. Creates a runnable task and                  queue.take() from
> outbound queue
>     enques to ThreadPoolExecutor (B)           2. Creates a runnable task
> and
>                                                 enques to
> ThreadPoolExecutor (C)
>
>
>
>
> Please let me know if you need more explanation.
>
> 1. There are 2 LinkedBlockingQueue. One for inbound and another for outbound
> 2. There are 3 ThreadPoolExecutors available. Letz say A, B, C
> 3. Someone puts a task in "A", which puts an item in InboundQueue.
> 4. A separate thread is blocked on "take()" method of this queue. Once it
> gets an item, it
> creates another "TASK" and puts it in "B" threadpool.
> 5. This task does some work and finally enqueues to "OUTBOUND QUEUE"
> 6. OUTBOUND Queue has a separate thread to dequeue and do some processing in
> "C" threadpool.
>
> Problem:
> ========
>  1. Too many short lived tasks are created.
> 2. Too many context switching happening in system due to #1.
> 3. Do you suggest any better way to implement it. Basic thing is the
> queueing and dequeuing has to happen asynchronously.
>
>
> --
> ~Rajesh.B
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From mclain at halcyon.com  Fri Mar 16 20:42:10 2007
From: mclain at halcyon.com (Fred McLain)
Date: Fri, 16 Mar 2007 17:42:10 -0700
Subject: [concurrency-interest] Remove me from this list
Message-ID: <200703161742.10341.mclain@halcyon.com>

Sorry to have to send this request this to all of you, but my transition to 
k-mail is causing issues.  Please remove me from this list.

Thanks,

	-Fred-

From peter.kovacs.1.0rc at gmail.com  Sat Mar 17 06:15:32 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Sat, 17 Mar 2007 11:15:32 +0100
Subject: [concurrency-interest] Looking for ways to track down the source of
	a concurrency problem
Message-ID: <b6e8f2e80703170315kecefa21gd3aa684fb1688070@mail.gmail.com>

Hi,

We have a concurrency-related data integrity problem and I am not sure
how to best proceed to find the cause.

We have started introducing concurrency into a library which is
essentially designed for single threaded execution. Our strategy has
been fairly simple:
(a) find a repetitive task performed by a coarsely grained object "R"
(b) establish the degree of concurrency needed (ie. based on the
number of CPUs): "n"
(c) create "n" instances of "R"
(d) start "n" threads with one "R" instance dedicated to (contained
in) each individual thread.

We have been assuming that instances of "R" themselves made use of
objects fully contained in "R" instances (no publication at all).
Since there is no "explicit" multithreading down the containment
hierarchy, proper concurrent use of "R" has been thought to guarantee
thread-safety. Since none of the objects are supposed to publish data
outside the containment hierarchy, we assume that these contained
objects do not have to be thread safe.

Now it appears that somewhere down the containment hierarchy there is
something which is inconsistent with our assumptions. Behind the
scenes, data is somehow published/shared across multiple threads. My
question is: what usage patterns should we look for to find out the
problem?

The only possible problematic usage pattern I have been able to think
of is that some of the contained instances manipulate static fields. I
haven't found any such instances yet, but this is probably something
to start with. Still, there may be other hideous ways in which objects
share data across threads in such "containment hierarchy" situations.
Please, can you tell me any other such way?

Again: to my best knowledge, only the top level objects "R"
participate directly in multithreading. (The threads retrieve the
parameters for "R" from one single source concurrently, but this
operation seems to be pretty well protected. The same applies for the
objects consuming the results from "R" instances.)

Interestingly, a couple of months ago we've already had a very similar
problem with another top level function (for a different top level
object, let's call it "U"). At that time, the appearance of the
problem was traced back to some changes in one of the contained
objects (an object which was contained a couple levels below "U" --
let's call it "A"). The changes were reverted and the problem
disappeared. (I was not involved in solving that issue, but I suspect
that no thorough examination had been performed to find out the real
cause.)

This time round, after a due-diligence check of the code actually
multithreading "R", I have tried various versions of "A" which is also
contained in "R". It turned out that with some of the earlier versions
of "A", the problem goes away. (We haven't seen the problem with "U"
every since. But that's a separate function, a separate issue, so...)
After fleetingly checking the code of "A", I haven't found any
conspicuous "irregularities". (The closest I came to finding
suspicious code was some static initializers in classes instantiated
by "A", but static initializers themselves are, I seem to remember,
thread-safe.)

Any help appreciated,
Peter

From peter.kovacs.1.0rc at gmail.com  Sun Mar 18 07:39:21 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Sun, 18 Mar 2007 12:39:21 +0100
Subject: [concurrency-interest] Looking for ways to track down the
	source of a concurrency problem
In-Reply-To: <b6e8f2e80703170315kecefa21gd3aa684fb1688070@mail.gmail.com>
References: <b6e8f2e80703170315kecefa21gd3aa684fb1688070@mail.gmail.com>
Message-ID: <b6e8f2e80703180439v7c2622c1u7a8e1ea56f3ad42a@mail.gmail.com>

The culprit was easier found than I had feared. It was a static
"prototype" instance which was not cloned "early enough" before used.

Peter

On 3/17/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> Hi,
>
> We have a concurrency-related data integrity problem and I am not sure
> how to best proceed to find the cause.
>
> We have started introducing concurrency into a library which is
> essentially designed for single threaded execution. Our strategy has
> been fairly simple:
> (a) find a repetitive task performed by a coarsely grained object "R"
> (b) establish the degree of concurrency needed (ie. based on the
> number of CPUs): "n"
> (c) create "n" instances of "R"
> (d) start "n" threads with one "R" instance dedicated to (contained
> in) each individual thread.
>
> We have been assuming that instances of "R" themselves made use of
> objects fully contained in "R" instances (no publication at all).
> Since there is no "explicit" multithreading down the containment
> hierarchy, proper concurrent use of "R" has been thought to guarantee
> thread-safety. Since none of the objects are supposed to publish data
> outside the containment hierarchy, we assume that these contained
> objects do not have to be thread safe.
>
> Now it appears that somewhere down the containment hierarchy there is
> something which is inconsistent with our assumptions. Behind the
> scenes, data is somehow published/shared across multiple threads. My
> question is: what usage patterns should we look for to find out the
> problem?
>
> The only possible problematic usage pattern I have been able to think
> of is that some of the contained instances manipulate static fields. I
> haven't found any such instances yet, but this is probably something
> to start with. Still, there may be other hideous ways in which objects
> share data across threads in such "containment hierarchy" situations.
> Please, can you tell me any other such way?
>
> Again: to my best knowledge, only the top level objects "R"
> participate directly in multithreading. (The threads retrieve the
> parameters for "R" from one single source concurrently, but this
> operation seems to be pretty well protected. The same applies for the
> objects consuming the results from "R" instances.)
>
> Interestingly, a couple of months ago we've already had a very similar
> problem with another top level function (for a different top level
> object, let's call it "U"). At that time, the appearance of the
> problem was traced back to some changes in one of the contained
> objects (an object which was contained a couple levels below "U" --
> let's call it "A"). The changes were reverted and the problem
> disappeared. (I was not involved in solving that issue, but I suspect
> that no thorough examination had been performed to find out the real
> cause.)
>
> This time round, after a due-diligence check of the code actually
> multithreading "R", I have tried various versions of "A" which is also
> contained in "R". It turned out that with some of the earlier versions
> of "A", the problem goes away. (We haven't seen the problem with "U"
> every since. But that's a separate function, a separate issue, so...)
> After fleetingly checking the code of "A", I haven't found any
> conspicuous "irregularities". (The closest I came to finding
> suspicious code was some static initializers in classes instantiated
> by "A", but static initializers themselves are, I seem to remember,
> thread-safe.)
>
> Any help appreciated,
> Peter
>

From peter.kovacs.1.0rc at gmail.com  Mon Mar 19 18:38:51 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 19 Mar 2007 23:38:51 +0100
Subject: [concurrency-interest] Reducing contention overhead by suspending
	worker threads
Message-ID: <b6e8f2e80703191538q6f5174d6s1e5e9e94c46a7ae5@mail.gmail.com>

Hi,

I've got a bounded blocking queue "outputQueue". A number of worker
threads are feeding this queue and one single thread is consuming its
elements. I've got two implementations of this setup with slightly
different details and a performance difference of about 25-30%. The
faster implementation is pretty messy and consequently difficult to
compare with the clean(er) but slower implementation.

The worker threads get sometimes blocked because the consumer cannot
keep up with the pace of the result production and the outputQueue
gets full. The only palpable difference between the slow and the fast
implementation I can find is that at this point (outputQueue gets
full) the worker threads of the faster implementation both go into
wait, while one of the workers of the slower implementation goes into
wait while the other get blocked by an outer intrinsic lock
(protecting the input source for the workers).

Now I speculate as follows: the slower guy is slower because the
threads blocked on the intrinsic lock must be rescheduled anyway on
the OS level: the only waiting thread must first be able to put its
data on the output queue before the other can have a chance to go
ahead.

Now if I try to balance the number of worker threads so that the
bounded queue does not possibly get full, then I can significantly
reduce the reschedule overhead.

Does this all makes sense? Or am I completely naive with this idea?
May this kind of speculation hold any substance at all (reschedule
overhead causing performance loss)?

Thanks
Peter

From jseigh_cp00 at xemaps.com  Mon Mar 19 20:23:46 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Mon, 19 Mar 2007 19:23:46 -0500
Subject: [concurrency-interest] Reducing contention overhead by
 suspending worker threads
In-Reply-To: <b6e8f2e80703191538q6f5174d6s1e5e9e94c46a7ae5@mail.gmail.com>
References: <b6e8f2e80703191538q6f5174d6s1e5e9e94c46a7ae5@mail.gmail.com>
Message-ID: <45FF2992.7080104@xemaps.com>

Peter Kovacs wrote:

>Hi,
>
>I've got a bounded blocking queue "outputQueue". A number of worker
>threads are feeding this queue and one single thread is consuming its
>elements. I've got two implementations of this setup with slightly
>different details and a performance difference of about 25-30%. The
>faster implementation is pretty messy and consequently difficult to
>compare with the clean(er) but slower implementation.
>
>The worker threads get sometimes blocked because the consumer cannot
>keep up with the pace of the result production and the outputQueue
>gets full. The only palpable difference between the slow and the fast
>implementation I can find is that at this point (outputQueue gets
>full) the worker threads of the faster implementation both go into
>wait, while one of the workers of the slower implementation goes into
>wait while the other get blocked by an outer intrinsic lock
>(protecting the input source for the workers).
>
>Now I speculate as follows: the slower guy is slower because the
>threads blocked on the intrinsic lock must be rescheduled anyway on
>the OS level: the only waiting thread must first be able to put its
>data on the output queue before the other can have a chance to go
>ahead.
>
>Now if I try to balance the number of worker threads so that the
>bounded queue does not possibly get full, then I can significantly
>reduce the reschedule overhead.
>
>Does this all makes sense? Or am I completely naive with this idea?
>May this kind of speculation hold any substance at all (reschedule
>overhead causing performance loss)?
>  
>

Try a Semaphore with a ConcurrentLinkedQueue.   In a artificially high 
contention
testcase, it ran about 1.5x faster than a blocking queue with a unfair 
semaphore and
about 2x slower with a fair semaphore, so you might want to avoid the 
latter.

I have a fast pathed semaphore which with a ConcurrentLinkedQueue will 
go about
3x faster than a blocking queue for both the unfair and fair case, the 
former being slightly faster.

--
Joe Seigh



From jseigh_cp00 at xemaps.com  Mon Mar 19 20:28:10 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Mon, 19 Mar 2007 19:28:10 -0500
Subject: [concurrency-interest] Thread Pools and ThreadLocal
Message-ID: <45FF2A9A.90203@xemaps.com>

Any way to purge or reset ThreadLocal variables for threads in
a thread pool before they're reused?  The assumption is the
thread pool implementation doesn't know which ones are being
used by the executed tasks.

--
Joe Seigh

From josh at bloch.us  Mon Mar 19 20:48:34 2007
From: josh at bloch.us (Joshua Bloch)
Date: Mon, 19 Mar 2007 17:48:34 -0700
Subject: [concurrency-interest] Thread Pools and ThreadLocal
In-Reply-To: <45FF2A9A.90203@xemaps.com>
References: <45FF2A9A.90203@xemaps.com>
Message-ID: <b097ac510703191748ve8bd615w31b64b2a770d1a02@mail.gmail.com>

Nope.  This question comes up once every year, like clockwork.  If you want
a new thread,  type new Thread(); Thread pool threads are cheaper, and they
may have a few dents and dings.  You get what you pay for.

      Josh


On 3/19/07, Joseph Seigh <jseigh_cp00 at xemaps.com> wrote:
>
> Any way to purge or reset ThreadLocal variables for threads in
> a thread pool before they're reused?  The assumption is the
> thread pool implementation doesn't know which ones are being
> used by the executed tasks.
>
> --
> Joe Seigh
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070319/ed139914/attachment.html 

From rajesh.balamohan at gmail.com  Mon Mar 19 22:55:10 2007
From: rajesh.balamohan at gmail.com (Rajesh Balamohan)
Date: Tue, 20 Mar 2007 02:55:10 +0000
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
Message-ID: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>

Hi All,

We are using LinkedBlockingQueue since it blocks on take() method. We have a
requirement like the following.

1. Many tasks are submitted to a threadpool by different threads. The task
internally adds some item to a LinkedBlockingQueue. I have striped down most
of the logic below. Please ignore the contents as such.

//The following task will be submitted by a pool of threads to a
threadPoolExecutor.
 static class Request implements Runnable {

        MessageState state = new MessageState();

        public void run() {
            synchronized (state) {
                if (!state.isRequestStarted()) {
                    state.addEvent(
MessageState.EVENT.REQUEST_RECEIVE_COMPLETE);
                }
            }
            myLinkedBlockingQueue.add(state);
        }
    }

2. One reaper thread is created whose job is to keep on taking out the items
from the LinkedBlockingQueue (basically like the following)

while(true) {
  accept();
}

private void accept() {
  try {
     MyItem item = myLinkedBlockingQueue.take();
 } ...blah blah...
..........
......
do necessary processing.
}


Now, I feel that it should be ConcurrentLinkedQueue instead of
LinkedBlockingQueue. ConcurrentLinkedQueue might be able to scale well than
LinkedBlockingQueue for multiple threads.

Problem is ConcurrentLinkedQueue doesn't have a blocking take(). Are there
any plans to add it? Or you think that this problem can be solved
differently?

-- 
~Rajesh.B
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070320/b595d0d3/attachment.html 

From dcholmes at optusnet.com.au  Mon Mar 19 23:18:26 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 20 Mar 2007 13:18:26 +1000
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEOHHFAA.dcholmes@optusnet.com.au>

As Joe Seigh just posted earlier today, you can use a Semaphore with a ConcurrentLinkedQueue to get a BlockingQueue version.

I can't comment as to whether that scales better or worse than LinkedBlockingQueue.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rajesh Balamohan
  Sent: Tuesday, 20 March 2007 12:55 PM
  To: Concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??


  Hi All,

  We are using LinkedBlockingQueue since it blocks on take() method. We have a requirement like the following.

  1. Many tasks are submitted to a threadpool by different threads. The task internally adds some item to a LinkedBlockingQueue. I have striped down most of the logic below. Please ignore the contents as such. 

  //The following task will be submitted by a pool of threads to a threadPoolExecutor.
   static class Request implements Runnable {

          MessageState state = new MessageState();

          public void run() { 
              synchronized (state) {
                  if (!state.isRequestStarted()) {
                      state.addEvent(MessageState.EVENT.REQUEST_RECEIVE_COMPLETE);
                  }
              }
              myLinkedBlockingQueue.add(state);
          }
      }

  2. One reaper thread is created whose job is to keep on taking out the items from the LinkedBlockingQueue (basically like the following)

  while(true) {
    accept();
  }

  private void accept() {
    try {
       MyItem item = myLinkedBlockingQueue.take();
   } ...blah blah...
  ..........
  ......
  do necessary processing.
  }


  Now, I feel that it should be ConcurrentLinkedQueue instead of LinkedBlockingQueue. ConcurrentLinkedQueue might be able to scale well than LinkedBlockingQueue for multiple threads.

  Problem is ConcurrentLinkedQueue doesn't have a blocking take(). Are there any plans to add it? Or you think that this problem can be solved differently? 

  -- 
  ~Rajesh.B 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070320/9a7a8a9a/attachment.html 

From hanson.char at gmail.com  Mon Mar 19 23:25:31 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 19 Mar 2007 20:25:31 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
Message-ID: <ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>

Have you checked this out ?

    http://hansonchar.blogspot.com/2006/09/concurrentlinkedblockingqueue.html

Cheers,
Hanson

On 3/19/07, Rajesh Balamohan <rajesh.balamohan at gmail.com> wrote:
> Hi All,
>
> We are using LinkedBlockingQueue since it blocks on take() method. We have a
> requirement like the following.
>
> 1. Many tasks are submitted to a threadpool by different threads. The task
> internally adds some item to a LinkedBlockingQueue. I have striped down most
> of the logic below. Please ignore the contents as such.
>
> //The following task will be submitted by a pool of threads to a
> threadPoolExecutor.
>  static class Request implements Runnable {
>
>         MessageState state = new MessageState();
>
>         public void run() {
>             synchronized (state) {
>                 if (!state.isRequestStarted()) {
>
> state.addEvent(MessageState.EVENT.REQUEST_RECEIVE_COMPLETE);
>                 }
>             }
>              myLinkedBlockingQueue.add(state);
>         }
>     }
>
> 2. One reaper thread is created whose job is to keep on taking out the items
> from the LinkedBlockingQueue (basically like the following)
>
> while(true) {
>   accept();
> }
>
> private void accept() {
>   try {
>      MyItem item = myLinkedBlockingQueue.take();
>  } ...blah blah...
> ..........
> ......
> do necessary processing.
> }
>
>
>  Now, I feel that it should be ConcurrentLinkedQueue instead of
> LinkedBlockingQueue. ConcurrentLinkedQueue might be able to scale well than
> LinkedBlockingQueue for multiple threads.
>
> Problem is ConcurrentLinkedQueue doesn't have a blocking take(). Are there
> any plans to add it? Or you think that this problem can be solved
> differently?
>
> --
> ~Rajesh.B
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From rajesh.balamohan at gmail.com  Mon Mar 19 23:39:04 2007
From: rajesh.balamohan at gmail.com (Rajesh Balamohan)
Date: Tue, 20 Mar 2007 03:39:04 +0000
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
Message-ID: <1da12e810703192039n47e2ada3oa8a9bad93af54a50@mail.gmail.com>

Thankx a lot Hanson and David for the quick replies. I am trying out
ConcurrentLinkedBlockingQueue as given in Hanson's site. Will post the
results soon after doing the perf benchmark with our project.

~Rajesh.B

On 3/20/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> Have you checked this out ?
>
>
> http://hansonchar.blogspot.com/2006/09/concurrentlinkedblockingqueue.html
>
> Cheers,
> Hanson
>
> On 3/19/07, Rajesh Balamohan <rajesh.balamohan at gmail.com> wrote:
> > Hi All,
> >
> > We are using LinkedBlockingQueue since it blocks on take() method. We
> have a
> > requirement like the following.
> >
> > 1. Many tasks are submitted to a threadpool by different threads. The
> task
> > internally adds some item to a LinkedBlockingQueue. I have striped down
> most
> > of the logic below. Please ignore the contents as such.
> >
> > //The following task will be submitted by a pool of threads to a
> > threadPoolExecutor.
> >  static class Request implements Runnable {
> >
> >         MessageState state = new MessageState();
> >
> >         public void run() {
> >             synchronized (state) {
> >                 if (!state.isRequestStarted()) {
> >
> > state.addEvent(MessageState.EVENT.REQUEST_RECEIVE_COMPLETE);
> >                 }
> >             }
> >              myLinkedBlockingQueue.add(state);
> >         }
> >     }
> >
> > 2. One reaper thread is created whose job is to keep on taking out the
> items
> > from the LinkedBlockingQueue (basically like the following)
> >
> > while(true) {
> >   accept();
> > }
> >
> > private void accept() {
> >   try {
> >      MyItem item = myLinkedBlockingQueue.take();
> >  } ...blah blah...
> > ..........
> > ......
> > do necessary processing.
> > }
> >
> >
> >  Now, I feel that it should be ConcurrentLinkedQueue instead of
> > LinkedBlockingQueue. ConcurrentLinkedQueue might be able to scale well
> than
> > LinkedBlockingQueue for multiple threads.
> >
> > Problem is ConcurrentLinkedQueue doesn't have a blocking take(). Are
> there
> > any plans to add it? Or you think that this problem can be solved
> > differently?
> >
> > --
> > ~Rajesh.B
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>



-- 
~Rajesh.B
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070320/696a31bd/attachment.html 

From gregg at cytetech.com  Tue Mar 20 16:06:18 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 20 Mar 2007 15:06:18 -0500
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
Message-ID: <46003EBA.7090203@cytetech.com>



Hanson Char wrote:
> Have you checked this out ?
> 
>     http://hansonchar.blogspot.com/2006/09/concurrentlinkedblockingqueue.html

Hanson, it looks like there is a pretty good chance that a thread can be left in 
the parkq and be the incorrect target of an unpark on the next offer.

Thread 1 take:      Thread 2 offer:
Line                Line
97
98
99
100
                     65
                     66
                     67
                     68
                     69
                     70
                     71
                     72
                     73
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117

it seems that parkq is left with a marker for Thread 1, and if thread 1 doesn't 
come back, but another thread does, and then another offer is made that the 
other thread will not be unparked, and Thread 1 may be spuriously unparked from 
somewhere else.

It seems like parkq should always be emptied, or some different logic needs to 
be in place to allow Thread 1 to peek parkq, and remove itself if it is at the head?

Gregg Wonderly

From hanson.char at gmail.com  Tue Mar 20 18:11:54 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 20 Mar 2007 15:11:54 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <46003EBA.7090203@cytetech.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
Message-ID: <ca53c8f80703201511p254a7705md6668bbcd20cc74b@mail.gmail.com>

Hi Gregg,

Not sure if I 100% understand you correctly.

> it seems that parkq is left with a marker for Thread 1, and if thread 1 doesn't
> come back, but another thread does, and then another offer is made that the
> other thread will not be unparked, and Thread 1 may be spuriously unparked from
> somewhere else.

First of all, according to the javadoc, the call to LockSupport.park()
can spuriously (that is, for no reason) return, regardless.

Any thread could be spuriously unparked but that is taken care of.
When Thread 1 is unparked (for whatever reason) within the take()
method, the method would either return with an element if one could be
found from q, or Thread 1 would simply park again if there q was
empty, except that the associated ThreadMarker of Thread 1 would be
placed at the tail of parkq.  So Thread 1 could be delayed from
unparking upon subsequent offer's (if we ignore the case of spurious
returns.)

> It seems like parkq should always be emptied, or some different logic needs to
> be in place to allow Thread 1 to peek parkq, and remove itself if it is at the head?

I don't see why parkq should be emptied.   parkq won't be emptied if
there were more take's than offer's.  In such case, the threads
executing the take method would be parked at queued at parkq, awaiting
items to be offered at q.

I also don't see why Thread 1 needs to peek at parkq and remove
itself.  The invocation of the offer method would always remove the
head of parkq, if there is one, and would result in either unparking a
parked thread (which even though may end up parking again if q was
found empty), or removing all ThreadMarker's that have already been
unparked at the head of parkq.

Hanson Char

On 3/20/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Hanson Char wrote:
> > Have you checked this out ?
> >
> >     http://hansonchar.blogspot.com/2006/09/concurrentlinkedblockingqueue.html
>
> Hanson, it looks like there is a pretty good chance that a thread can be left in
> the parkq and be the incorrect target of an unpark on the next offer.
>
> Thread 1 take:      Thread 2 offer:
> Line                Line
> 97
> 98
> 99
> 100
>                      65
>                      66
>                      67
>                      68
>                      69
>                      70
>                      71
>                      72
>                      73
> 101
> 102
> 103
> 104
> 105
> 106
> 107
> 108
> 109
> 110
> 111
> 112
> 113
> 114
> 115
> 116
> 117
>
> it seems that parkq is left with a marker for Thread 1, and if thread 1 doesn't
> come back, but another thread does, and then another offer is made that the
> other thread will not be unparked, and Thread 1 may be spuriously unparked from
> somewhere else.
>
> It seems like parkq should always be emptied, or some different logic needs to
> be in place to allow Thread 1 to peek parkq, and remove itself if it is at the head?
>
> Gregg Wonderly
>

From info at sixthandredriver.com  Tue Mar 20 15:24:39 2007
From: info at sixthandredriver.com (info at sixthandredriver.com)
Date: Tue, 20 Mar 2007 15:24:39 -0400
Subject: [concurrency-interest] LockSmith: Automated Refactoring for JSR-166
Message-ID: <F4C687D7-91A6-4365-A339-DE78C82BEC54@sixthandredriver.com>


Sixth and Red River software is pleased to announce the release of  
LockSmith 1.0.  LockSmith extends IntelliJ IDEA with automated  
refactorings and code transformations for concurrent Java programs.   
Both native Java synchronization and JSR-166 locking are supported,  
as are the "Java Concurrency in Practice" concurrency annotations.

Code transformations and refactorings provided by LockSmith include

*Split Lock
*Merge Lock
*Make Class Thread-Safe
*Lock Method Call-Sites
*Split Critical Section
*Shrink Critical Section
*Merge Critical Sections
*Convert Synchronization Field To Lock
*Convert Simple Lock to Read-Write Lock
*Convert Read-Write Lock to Simple Lock
*Make Field Atomic
*Make Field ThreadLocal

Future scope for LockSmith will include support for converting  
programs from explicit Thread creation to Executor use, extracting  
computations as Callables or Futures, and code audits for JCiP  
annotations.

For more information, go to http://www.sixthandredriver.com/ 
locksmith.html


(Sorry if this is unacceptable spam, but it seemed like something  
that this mailing list should know about.  If anyone wishes to  
complain, we will apologize and promise not to do it again.)

Sixth and Red River Software
"Code with Grace and Verve

From hanson.char at gmail.com  Tue Mar 20 18:43:56 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 20 Mar 2007 15:43:56 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <46003EBA.7090203@cytetech.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
Message-ID: <ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>

Hi Gregg,

> It seems like parkq should always be emptied

I think I see what you mean.  Yes there is a chance that some unparked
items are left over in parkq, if an item is placed to q after a
ThreadMarker is placed to parkq but before the thread (of the
associated ThreadMarker) is parked.  In such case, the left-over
ThreadMarker's would have "parked" set to false.

The logic in the offer method attempts to minimize the left-over in
parkq by removing all consecutive ThreadMarker with "parked" set to
false.

Not good enough ?

Hanson


On 3/20/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Hanson Char wrote:
> > Have you checked this out ?
> >
> >     http://hansonchar.blogspot.com/2006/09/concurrentlinkedblockingqueue.html
>
> Hanson, it looks like there is a pretty good chance that a thread can be left in
> the parkq and be the incorrect target of an unpark on the next offer.
>
> Thread 1 take:      Thread 2 offer:
> Line                Line
> 97
> 98
> 99
> 100
>                      65
>                      66
>                      67
>                      68
>                      69
>                      70
>                      71
>                      72
>                      73
> 101
> 102
> 103
> 104
> 105
> 106
> 107
> 108
> 109
> 110
> 111
> 112
> 113
> 114
> 115
> 116
> 117
>
> it seems that parkq is left with a marker for Thread 1, and if thread 1 doesn't
> come back, but another thread does, and then another offer is made that the
> other thread will not be unparked, and Thread 1 may be spuriously unparked from
> somewhere else.
>
> It seems like parkq should always be emptied, or some different logic needs to
> be in place to allow Thread 1 to peek parkq, and remove itself if it is at the head?
>
> Gregg Wonderly
>

From gregg at cytetech.com  Tue Mar 20 18:52:52 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 20 Mar 2007 17:52:52 -0500
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
	<ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
Message-ID: <460065C4.50508@cytetech.com>



Hanson Char wrote:
> Hi Gregg,
> 
>> It seems like parkq should always be emptied
> 
> 
> I think I see what you mean.  Yes there is a chance that some unparked
> items are left over in parkq, if an item is placed to q after a
> ThreadMarker is placed to parkq but before the thread (of the
> associated ThreadMarker) is parked.  In such case, the left-over
> ThreadMarker's would have "parked" set to false.
> 
> The logic in the offer method attempts to minimize the left-over in
> parkq by removing all consecutive ThreadMarker with "parked" set to
> false.

duh...  I missed that looping logic associated with "parked".  I was thinking it 
returned no matter what.  It looks to me like that should take care of the left 
behind "unparked" marker entries.

Sorry for the hassle.

Gregg Wonderly

From hanson.char at gmail.com  Tue Mar 20 19:30:39 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 20 Mar 2007 16:30:39 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <460065C4.50508@cytetech.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
	<ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
	<460065C4.50508@cytetech.com>
Message-ID: <ca53c8f80703201630r10f17720lc47ce8299e52d0b@mail.gmail.com>

No hassle at all.  Thanks for the scrutiny!

Hanson Char

On 3/20/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Hanson Char wrote:
> > Hi Gregg,
> >
> >> It seems like parkq should always be emptied
> >
> >
> > I think I see what you mean.  Yes there is a chance that some unparked
> > items are left over in parkq, if an item is placed to q after a
> > ThreadMarker is placed to parkq but before the thread (of the
> > associated ThreadMarker) is parked.  In such case, the left-over
> > ThreadMarker's would have "parked" set to false.
> >
> > The logic in the offer method attempts to minimize the left-over in
> > parkq by removing all consecutive ThreadMarker with "parked" set to
> > false.
>
> duh...  I missed that looping logic associated with "parked".  I was thinking it
> returned no matter what.  It looks to me like that should take care of the left
> behind "unparked" marker entries.
>
> Sorry for the hassle.
>
> Gregg Wonderly
>

From jseigh_cp00 at xemaps.com  Sun Mar 25 18:42:30 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Sun, 25 Mar 2007 17:42:30 -0500
Subject: [concurrency-interest] Software Transactional Memory
Message-ID: <4606FAD6.6010900@xemaps.com>

I took down that STM package I had out on sourceforge.  It had a few
implementation errors which I didn't notice until I changed the testcase
implementation from a LIFO queue to a FIFO queue.  It was fun debugging
that one.

I'm not going to put an up fixed package out there because I'm not real
happy with the performance and the scheduler artifacts on a single
processor system make it impossible to demonstrate scalability for
the time being.

Question about ConcurrentLinkedQueue.  It uses AtomicReferenceFieldUpdater
rather than AtomicReference.  Why is that?  The former is a lot slower 
than the
latter according to my measurments and allocating extra objects didn't 
seem to
make that much difference so having an extra object for AtomicReference 
shouldn't
be a problem.

--
Joe Seigh

From dhanji at gmail.com  Sun Mar 25 19:36:42 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Mon, 26 Mar 2007 09:36:42 +1000
Subject: [concurrency-interest] question about java.lang.reflect
Message-ID: <aa067ea10703251636i5a31b90fh3b23eb0fa3e64a34@mail.gmail.com>

Hi

I am curious if the reflection classes do any synchronization? Particularly,
I have got multiple threads using the same Field (and Method) to mutate
thread-local objects of the same class. The Fields and Methods are
introspected only once (and cached in "final" members) before any other
threads have access to them.

But does Field or Method have a critical section that may be a chokepoint?
If so, am I better off constructing a synthetic class to mutate the objects
at runtime? I know the latter would be faster, but I am curious if it is
faster due to the fact that it's a static invocation, rather than a
synchronization chokepoint.
Thanks,

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070326/087adf8e/attachment.html 

From dcholmes at optusnet.com.au  Sun Mar 25 19:58:17 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 26 Mar 2007 09:58:17 +1000
Subject: [concurrency-interest] question about java.lang.reflect
In-Reply-To: <aa067ea10703251636i5a31b90fh3b23eb0fa3e64a34@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEPIHFAA.dcholmes@optusnet.com.au>

If the member is non-public then there are synchronized sections to check
cached security credentials. Otherwise there is no real use of
synchronization that I can see. Note that the reflection mechanism also uses
dynamically generated code to speed up invocations.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dhanji R.
Prasanna
  Sent: Monday, 26 March 2007 9:37 AM
  To: concurrency-interest
  Subject: [concurrency-interest] question about java.lang.reflect


  Hi

  I am curious if the reflection classes do any synchronization?
Particularly, I have got multiple threads using the same Field (and Method)
to mutate thread-local objects of the same class. The Fields and Methods are
introspected only once (and cached in "final" members) before any other
threads have access to them.

  But does Field or Method have a critical section that may be a chokepoint?
If so, am I better off constructing a synthetic class to mutate the objects
at runtime? I know the latter would be faster, but I am curious if it is
faster due to the fact that it's a static invocation, rather than a
synchronization chokepoint.
  Thanks,

  Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070326/ea80b640/attachment.html 

From dhanji at gmail.com  Sun Mar 25 20:13:07 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Mon, 26 Mar 2007 10:13:07 +1000
Subject: [concurrency-interest] question about java.lang.reflect
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEPIHFAA.dcholmes@optusnet.com.au>
References: <aa067ea10703251636i5a31b90fh3b23eb0fa3e64a34@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEPIHFAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10703251713r5abb7a08v16917bd3df0308be@mail.gmail.com>

On 3/26/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  If the member is non-public then there are synchronized sections to check
> cached security credentials. Otherwise there is no real use of
> synchronization that I can see. Note that the reflection mechanism also uses
> dynamically generated code to speed up invocations.
>

perfect! Thanks very much, David.

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070326/6b1fb22d/attachment.html 

From dl at cs.oswego.edu  Mon Mar 26 06:43:05 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 26 Mar 2007 06:43:05 -0400
Subject: [concurrency-interest] Software Transactional Memory
In-Reply-To: <4606FAD6.6010900@xemaps.com>
References: <4606FAD6.6010900@xemaps.com>
Message-ID: <4607A3B9.5020109@cs.oswego.edu>

Joseph Seigh wrote:
> 
> 
> Question about ConcurrentLinkedQueue.  It uses AtomicReferenceFieldUpdater
> rather than AtomicReference.  Why is that?  T

The two choices have different tradeoffs. Using fieldUpdaters does
have more per-call overhead, but in principle most of it
is optimizable away, and on some platforms and some contexts,
it often is. Using a separate AtomicReference in essence doubles
the length of a list (every second indirection is just a
pointer holding the real pointer). And for small nodes as used
here, nearly doubles the footprint -- even a one-field object
has object header etc overhead, and increases GC overhead.
All in all, using fieldUpdaters in this case is the best
choice, even though on some programs/platforms it might on average
be a  little slower (and on others faster).

-Doug



From tackline at tackline.plus.com  Mon Mar 26 08:16:14 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Mon, 26 Mar 2007 13:16:14 +0100
Subject: [concurrency-interest] Software Transactional Memory
In-Reply-To: <4607A3B9.5020109@cs.oswego.edu>
References: <4606FAD6.6010900@xemaps.com> <4607A3B9.5020109@cs.oswego.edu>
Message-ID: <4607B98E.1000302@tackline.plus.com>

Doug Lea wrote:
> Joseph Seigh wrote:
>>
>> Question about ConcurrentLinkedQueue.  It uses AtomicReferenceFieldUpdater
>> rather than AtomicReference.  Why is that?  T
> 
> The two choices have different tradeoffs. Using fieldUpdaters does
> have more per-call overhead, but in principle most of it
> is optimizable away, and on some platforms and some contexts,
> it often is.

I got a figure of around 80 cycles per getAndSet (when warmed up) in a 
microbenchmark. That's quite significant on my platform (single core AMD 
64).

>              Using a separate AtomicReference in essence doubles
> the length of a list (every second indirection is just a
> pointer holding the real pointer). And for small nodes as used
> here, nearly doubles the footprint -- even a one-field object
> has object header etc overhead, and increases GC overhead.

ConcurrentLinkedQueue.Node has two volatile fields with updaters: next 
and item. Node has Object as base class, so it might make sense to 
opportunistically extend AtomicReference for the next field. OTOH, that 
would presumably may tend to make methods like contains(Object) slightly 
slower (not tested).

ConcurrentLinkedQueue.head and tail also have updaters. Here only many 
small queues would be significantly affected by the overhead of extra 
AtomicReferences. So it's still a trade off on how often CAS is used and 
how important size is. (Similarly, frequency of CAS vs frequency of get 
led to JDK7 java.nio.channels.SelectionKey using an updater for attach.)

Tom Hawtin

From hanson.char at gmail.com  Mon Mar 26 16:32:41 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 26 Mar 2007 13:32:41 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <460065C4.50508@cytetech.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
	<ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
	<460065C4.50508@cytetech.com>
Message-ID: <ca53c8f80703261332o7f69b16k73b049afc9652f33@mail.gmail.com>

However, it does seem the algorithm can be further improved to
1) reduce the number of "unparked" called on a waiting threads;
2) ensure max of only 1 marker is created for a waiting thread; and
3) maintain the fairness at the same time.

Like so:

   public E take() throws InterruptedException
   {
       ThreadMarker m = null;

       for (;;) {
           E e = q.poll();

           if (e != null)
               return e;
           if (m == null)
           {   // thread has never been marked
               m = new ThreadMarker(Thread.currentThread());

               if (Thread.interrupted())
               {   // avoid the parkq.offer(m) if already interrupted
                   throw new InterruptedException();
               }
               parkq.offer(m);
               // check again in case there is data race
               e = q.poll();

               if (e != null)
               {   // data race indeed
                   m.parked = false;
                   return e;
               }
           }
           LockSupport.park();

           if (Thread.interrupted())
           {
               m.parked = false;
               throw new InterruptedException();
           }
       }
   }

Hanson Char

From hanson.char at gmail.com  Mon Mar 26 16:37:53 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 26 Mar 2007 13:37:53 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <ca53c8f80703261332o7f69b16k73b049afc9652f33@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
	<ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
	<460065C4.50508@cytetech.com>
	<ca53c8f80703261332o7f69b16k73b049afc9652f33@mail.gmail.com>
Message-ID: <ca53c8f80703261337k35b1d0a1x7da7a27b06e8dcdc@mail.gmail.com>

Oops, I meant:

    public E take() throws InterruptedException
    {
        ThreadMarker m = null;

        for (;;) {
            E e = q.poll();

            if (e != null)
            {
                if (m != null)
                    m.parked = false;
                return e;
            }
            if (m == null)
            {   // thread has never been marked
                m = new ThreadMarker(Thread.currentThread());

                if (Thread.interrupted())
                {   // avoid the parkq.offer(m) if already interrupted
                    throw new InterruptedException();
                }
                parkq.offer(m);
                // check again in case there is data race
                e = q.poll();

                if (e != null)
                {   // data race indeed
                    m.parked = false;
                    return e;
                }
            }
            LockSupport.park();

            if (Thread.interrupted())
            {
                m.parked = false;
                throw new InterruptedException();
            }
        }
    }

Hanson Char

On 3/26/07, Hanson Char <hanson.char at gmail.com> wrote:
> However, it does seem the algorithm can be further improved to
> 1) reduce the number of "unparked" called on a waiting threads;
> 2) ensure max of only 1 marker is created for a waiting thread; and
> 3) maintain the fairness at the same time.

From hanson.char at gmail.com  Mon Mar 26 18:07:05 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 26 Mar 2007 15:07:05 -0700
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <ca53c8f80703261454j5a1edf97v3c8eaacf3682be70@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
	<ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
	<460065C4.50508@cytetech.com>
	<ca53c8f80703261332o7f69b16k73b049afc9652f33@mail.gmail.com>
	<ca53c8f80703261337k35b1d0a1x7da7a27b06e8dcdc@mail.gmail.com>
	<ca53c8f80703261454j5a1edf97v3c8eaacf3682be70@mail.gmail.com>
Message-ID: <ca53c8f80703261507g2222e044h1466bff37950e713@mail.gmail.com>

Here you go:

http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java

Let me know if there is any reason I need to be blamed :)

Hanson Char

On 3/26/07, Hanson Char <hanson.char at gmail.com> wrote:
> Thanks, Szabolcs.
>
> I will update the code in sourceforge shortly.  Stay tuned.
>
> Hanson Char

From concurrency-interest at nitwit.de  Tue Mar 27 12:16:51 2007
From: concurrency-interest at nitwit.de (Timo Nentwig)
Date: Tue, 27 Mar 2007 18:16:51 +0200
Subject: [concurrency-interest] how to auto-terminate producer-consumer
	service
Message-ID: <200703271816.51768.concurrency-interest@nitwit.de>

This is about chapter 7.2 in jcip but I don't want to shutdown or cancel the 
service but merely there's finite amount of work to do and when it's done the 
service is supposed to shutdown itself.

So Nproducer threads and Nconsumer thread connected via a BlockingQueue. The 
problem: when the producers have done their job how do the consumer know? And 
even if they would know they would be blocked in take() anyway.

One solution is presented in 7.2.2 but I waiting until the producers are done 
and then interupting the consumers just to tell them to finished their work 
and then shutdown would be reallly weird coding.

7.2.3 suggest a poison pill. This is actually what I did but I'm not happy 
with it. If each producer puts a single poison pill into the queue it will 
only work if Nproducer>=Nconsumer. Letting each producer put Nconsumer poison 
pills in the queue will only work for Nproducer==1 otherwise all consumers 
will  be dead by the time other producers are still producing. And finally 
IMHO it's bad design that the producer are coupled to the consumer by having 
to know what many consumers are actually out there.

So came up with the idea that not the producers are putting the poison pills 
into the queue but actually the thread that started the producers and 
consumers:

			// start producers and consumers

			// wait until producers are finished
			for( final Thread t : producers )
                                t.join();

			// put Nconsumer poison pill in the queue, put() will block
                        for( int i = 0; i < consumers.length; i++ )
                                queue.put( POISON_PILL );

			// and finally wait for the consumers to swallow the poison pill
                        for( final Thread i : consumers )
                                i.join();

(I yet didn't have had a closer look at the new Executer stuff :-)

This works. But I don't like it. The consumers could peek() before take() and 
watch out for poison pills but I would have to lock the queue for this case 
and that's not worth it.

Isn't there a better solution? Some Queue with poison pilll functionality 
comes to my mind but it will be somewhat tricky how to handle multiple 
producers...

From concurrency-interest at nitwit.de  Tue Mar 27 12:16:51 2007
From: concurrency-interest at nitwit.de (Timo Nentwig)
Date: Tue, 27 Mar 2007 18:16:51 +0200
Subject: [concurrency-interest] how to auto-terminate producer-consumer
	service
Message-ID: <200703271816.51768.concurrency-interest@nitwit.de>

This is about chapter 7.2 in jcip but I don't want to shutdown or cancel the 
service but merely there's finite amount of work to do and when it's done the 
service is supposed to shutdown itself.

So Nproducer threads and Nconsumer thread connected via a BlockingQueue. The 
problem: when the producers have done their job how do the consumer know? And 
even if they would know they would be blocked in take() anyway.

One solution is presented in 7.2.2 but I waiting until the producers are done 
and then interupting the consumers just to tell them to finished their work 
and then shutdown would be reallly weird coding.

7.2.3 suggest a poison pill. This is actually what I did but I'm not happy 
with it. If each producer puts a single poison pill into the queue it will 
only work if Nproducer>=Nconsumer. Letting each producer put Nconsumer poison 
pills in the queue will only work for Nproducer==1 otherwise all consumers 
will  be dead by the time other producers are still producing. And finally 
IMHO it's bad design that the producer are coupled to the consumer by having 
to know what many consumers are actually out there.

So came up with the idea that not the producers are putting the poison pills 
into the queue but actually the thread that started the producers and 
consumers:

			// start producers and consumers

			// wait until producers are finished
			for( final Thread t : producers )
                                t.join();

			// put Nconsumer poison pill in the queue, put() will block
                        for( int i = 0; i < consumers.length; i++ )
                                queue.put( POISON_PILL );

			// and finally wait for the consumers to swallow the poison pill
                        for( final Thread i : consumers )
                                i.join();

(I yet didn't have had a closer look at the new Executer stuff :-)

This works. But I don't like it. The consumers could peek() before take() and 
watch out for poison pills but I would have to lock the queue for this case 
and that's not worth it.

Isn't there a better solution? Some Queue with poison pilll functionality 
comes to my mind but it will be somewhat tricky how to handle multiple 
producers...

From mike.quilleash at subexazure.com  Tue Mar 27 12:39:39 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Tue, 27 Mar 2007 12:39:39 -0400
Subject: [concurrency-interest] how to auto-terminate producer-consumer
 service
In-Reply-To: <200703271816.51768.concurrency-interest@nitwit.de>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E062F4381@MI8NYCMAIL15.Mi8.com>

I've solved this in the past by using ExecutorCompletionService (ECS).
Something like the following:

1) Create an ECS for the producer.
2) Create an ECS for the consumer.
3) Submit all the producers.
4) Submit all the consumers.
5) Loop over the producer ECS doing a .take() for each submitted
producer.
6) Now all the producers have completed, submit a poison pill to the
queue for each consumer.
7) Each consumer will read one poison pill and die.
8) Loop over the consumer ECS doing a .take() for each submitted
consumer.

2) and 8) are optional if you don't care about waiting for the consumers
to finish.

This leaves the producers and consumers separated each other with only
the submitting thread needing to know how many of each there was.

HTH.

Mike.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Timo
Nentwig
Sent: 27 March 2007 17:17
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] how to auto-terminate producer-consumer
service

This is about chapter 7.2 in jcip but I don't want to shutdown or cancel
the service but merely there's finite amount of work to do and when it's
done the service is supposed to shutdown itself.

So Nproducer threads and Nconsumer thread connected via a BlockingQueue.
The
problem: when the producers have done their job how do the consumer
know? And even if they would know they would be blocked in take()
anyway.

One solution is presented in 7.2.2 but I waiting until the producers are
done and then interupting the consumers just to tell them to finished
their work and then shutdown would be reallly weird coding.

7.2.3 suggest a poison pill. This is actually what I did but I'm not
happy with it. If each producer puts a single poison pill into the queue
it will only work if Nproducer>=Nconsumer. Letting each producer put
Nconsumer poison pills in the queue will only work for Nproducer==1
otherwise all consumers will  be dead by the time other producers are
still producing. And finally IMHO it's bad design that the producer are
coupled to the consumer by having to know what many consumers are
actually out there.

So came up with the idea that not the producers are putting the poison
pills into the queue but actually the thread that started the producers
and
consumers:

			// start producers and consumers

			// wait until producers are finished
			for( final Thread t : producers )
                                t.join();

			// put Nconsumer poison pill in the queue, put()
will block
                        for( int i = 0; i < consumers.length; i++ )
                                queue.put( POISON_PILL );

			// and finally wait for the consumers to swallow
the poison pill
                        for( final Thread i : consumers )
                                i.join();

(I yet didn't have had a closer look at the new Executer stuff :-)

This works. But I don't like it. The consumers could peek() before
take() and watch out for poison pills but I would have to lock the queue
for this case and that's not worth it.

Isn't there a better solution? Some Queue with poison pilll
functionality comes to my mind but it will be somewhat tricky how to
handle multiple producers...
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From szabolcs.ferenczi at gmail.com  Tue Mar 27 18:15:49 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 28 Mar 2007 00:15:49 +0200
Subject: [concurrency-interest] Is there a ConcurrentBlockingQueue ??
In-Reply-To: <ca53c8f80703261507g2222e044h1466bff37950e713@mail.gmail.com>
References: <1da12e810703191955p7568b1aai5eaa2c41c8c5b273@mail.gmail.com>
	<ca53c8f80703192025r19d2bdc3od054d0aa117e105f@mail.gmail.com>
	<46003EBA.7090203@cytetech.com>
	<ca53c8f80703201543m23002e8dn34380e590e49dd0b@mail.gmail.com>
	<460065C4.50508@cytetech.com>
	<ca53c8f80703261332o7f69b16k73b049afc9652f33@mail.gmail.com>
	<ca53c8f80703261337k35b1d0a1x7da7a27b06e8dcdc@mail.gmail.com>
	<ca53c8f80703261454j5a1edf97v3c8eaacf3682be70@mail.gmail.com>
	<ca53c8f80703261507g2222e044h1466bff37950e713@mail.gmail.com>
Message-ID: <c8955b000703271515k1492f4c9t951888085fabc8@mail.gmail.com>

Hi Hanson,

I have thought about it a bit more and I came to a very surprising
conclusion. (It is about the previous version not about the last
update.) The solution you provide is basically an optimised busy
loop. If we have a look at the very core of it, it looks like this
(when optimisation and interrupt handling is removed):

    public boolean offer(E e) {
        return q.offer(e);
    }
    public E take() throws InterruptedException
    {
	E e;
	do {
	    e = q.poll();
	} while (e == null);
	return e;
    }

The pack/unpack stuff is just some optimalisation sugar on it.

It functions exactly like your optimised one and performs the same or
slightly better for your N producer 1 consumer load test on a dual
core processor. BTW I think a better load test could be the reverse,
i.e. N consumer 1 producer, since the interesting issue is in the long
term scheduling of the consumer processes which is not exercised by
the N producer 1 consumer test.

In fact, your solution is the inverse of the conventional monitor-like
solution which would look like this:

    public synchronized boolean offer(E e) {
        boolean b = q.offer(e);
	notify();
	return b;
    }
    public synchronized E take() throws InterruptedException
    {
	while (q.isEmpty()) {
	    wait();
	}
	E e = q.poll();
	return e;
    }

I say inverse because in the monitor-like solution the effective
action follows the check. The check to true is the precondition of the
action. The check is performed in an optimised (see wait()) busy loop
too. In the monitor one needs the lock to keep the check and the
corresponding action together as an atomic action.---In your solution,
on the other hand, the lock is not necessary since the check follows
the action. At the time the check comes, the result is already private
to the thread so mutual exclusion is not needed.

Best Regards,
Szabolcs



On 27/03/07, Hanson Char <hanson.char at gmail.com> wrote:
> Here you go:
>
> http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java
>
> Let me know if there is any reason I need to be blamed :)
>
> Hanson Char
>
> On 3/26/07, Hanson Char <hanson.char at gmail.com> wrote:
> > Thanks, Szabolcs.
> >
> > I will update the code in sourceforge shortly.  Stay tuned.
> >
> > Hanson Char
>

From matthias.ernst at coremedia.com  Wed Mar 28 05:56:08 2007
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Wed, 28 Mar 2007 11:56:08 +0200
Subject: [concurrency-interest] Counters/Aggregations/ Visible Thread-Locals
Message-ID: <AE2A8E488D9B26438919DF3C9C95528D168E88@hermes.coremedia.com>


Hi,

recently[1], I've had to implement a number of data structures for mostly statistical/analytical purposes: in principle, all
they allow for is aggregation of a number of T's through these operations: zero:U, add(U,T), add(U,U):U. The important property being that "add" is commutative and associative: you can add up any subsets in any order and get the same result. Simplest example being a counter with U=long and T={1}. Others being "average", "set of all instances", "max", "min" and mappings from some key to an aggregation.

To minimize synchronization I would do all add(U,T) thread-local whenever an event happens and, more infrequently, propagate the thread-local U into the global one. This was much more efficient than going through an j.u.c.atomic structure on every event.

Questions: I cannot look into the thread-local map of other threads. I do not have the application threads under enough control to reliably garantuee that they publish their thread-local state in a timely manner. Does one of the list members have thread-local structures that are visible to other threads in use somewhere? And, do you think this style of processing is interesting enough to offer general purpose APIs for that, i.e. something along java.util.concurrent.aggregate?

Thanks
Matthias

[1] http://mernst.org/blog/rss.xml#Get-the-Jist
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070328/835969c1/attachment.html 

From jseigh_cp00 at xemaps.com  Wed Mar 28 06:00:59 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Wed, 28 Mar 2007 05:00:59 -0500
Subject: [concurrency-interest] Measuring lock contention with ThreadMXBean
Message-ID: <460A3CDB.3050302@xemaps.com>

I was using ThreadMXBean to compare the lock usage of some collections,
lock based and lock-free.  The lock-free one I wrote spends most of its
time blocked on locks according to ThreadMXBean.   So if you are *not*
using locks, how do you figure out which locks you are blocking on?

--
Joe Seigh

From gregg at cytetech.com  Wed Mar 28 10:19:30 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 28 Mar 2007 09:19:30 -0500
Subject: [concurrency-interest] ConcurrentWeakIdentityHashMap
Message-ID: <460A7972.2010305@cytetech.com>

Is there any thought about creating a new WeakIdentityHashMap which can be used 
in places where classloaders and other dynamic bindings are in use.  I've not 
looked into this at any depth yet, but there are some places where WeakHashMap 
are used in the Jini 2.1 codebase which I've been looking at to do some 
contention reduction.  The use of distributed key based locks in 
ConcurrentHashMap is nice for things related to threading, ClassLoader and 
ProtectionDomain issues where multiple unrelated users are active at one time.

Gregg Wonderly

From josh at bloch.us  Wed Mar 28 13:40:04 2007
From: josh at bloch.us (Joshua Bloch)
Date: Wed, 28 Mar 2007 13:40:04 -0400
Subject: [concurrency-interest] Counters/Aggregations/ Visible
	Thread-Locals
In-Reply-To: <AE2A8E488D9B26438919DF3C9C95528D168E88@hermes.coremedia.com>
References: <AE2A8E488D9B26438919DF3C9C95528D168E88@hermes.coremedia.com>
Message-ID: <b097ac510703281040l264d77a9m3c5c4cd3b8be0244@mail.gmail.com>

Matthias,

You can make this work by having the ThreadLocal point to a wrapped volatile
long (or whatever).  The initialValue method for the ThreadLocal can
register the wrapped long, and the "aggregator" method can iterate over all
the registered values. It would be interesting to see what gains you could
achieve from this strategy in practice.  If the gains are significant, and
there are sufficiently many applications then it could be worth putting in
j.u.c.  I don't have a strong intuition.  I'll bet Doug does:)

                   Josh

On 3/28/07, Ernst, Matthias <matthias.ernst at coremedia.com> wrote:
>
>
> Hi,
>
> recently[1], I've had to implement a number of data structures for mostly
> statistical/analytical purposes: in principle, all
> they allow for is aggregation of a number of T's through these operations:
> zero:U, add(U,T), add(U,U):U. The important property being that "add" is
> commutative and associative: you can add up any subsets in any order and get
> the same result. Simplest example being a counter with U=long and T={1}.
> Others being "average", "set of all instances", "max", "min" and mappings
> from some key to an aggregation.
>
> To minimize synchronization I would do all add(U,T) thread-local whenever
> an event happens and, more infrequently, propagate the thread-local U into
> the global one. This was much more efficient than going through an
> j.u.c.atomic structure on every event.
>
> Questions: I cannot look into the thread-local map of other threads. I do
> not have the application threads under enough control to reliably garantuee
> that they publish their thread-local state in a timely manner. Does one of
> the list members have thread-local structures that are visible to other
> threads in use somewhere? And, do you think this style of processing is
> interesting enough to offer general purpose APIs for that, i.e. something
> along java.util.concurrent.aggregate?
>
> Thanks
> Matthias
>
> [1] http://mernst.org/blog/rss.xml#Get-the-Jist
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070328/3ebd9eef/attachment.html 

From jseigh_cp00 at xemaps.com  Thu Mar 29 07:04:16 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Thu, 29 Mar 2007 06:04:16 -0500
Subject: [concurrency-interest] Measuring lock contention with
	ThreadMXBean
In-Reply-To: <460B2B4D.3090503@sun.com>
References: <460B2B4D.3090503@sun.com>
Message-ID: <460B9D30.8010805@xemaps.com>

Mandy Chung wrote:

>
> Hi Joe,
>
> Your question was forwarded to me as I'm not on concurrency-interest.
>
> Can you elaborate what you have done?  I assume that you refer "lock" 
> as one of the java.util.concurrent.locks you use.  Are you using the 
> java.util.concurrent.locks class or using your custom lock?
>
> Thanks
> Mandy
>
> Joe Seigh wrote:
>
>> I was using ThreadMXBean to compare the lock usage of some collections,
>> lock based and lock-free.  The lock-free one I wrote spends most of its
>> time blocked on locks according to ThreadMXBean.   So if you are *not*
>> using locks, how do you figure out which locks you are blocking on?
>>
>>  
>>
>
>
The locks are whatever ThreadMXBean measures.   I suspect it is the GC 
which appears to be using
conventional synchronization to park threads.   I threw in the 
ThreadMXBean stuff in the testcase
I was running.  Lock-free algorithms tend to be memory intensive and I 
one I wrote is especially
so since it's using hashmaps and copy on write.  Usually I put in a 
semaphore on writes in lock-free
situations to put a bound on memory usage.   This isn't too easy in Java 
since the GC doesn't really
have a good interface here.  You really need a listener interface, not 
ReferenceQueue which is
set up to avoid running any user code on the GC thread.  You can use a 
polling thread there
but running an extra thread in library code is awkward, otherwise GC 
would have done it
to provide a listener interface.

Testcase output below.  Timings are in milliseconds and except for elapsed
time, are cumulative thread timings.   sum is an internal sanity check.
Additional stuff for XmemQueue are just counters to see what actually
happens.  nodes is the count of  non GC'd collector nodes at the end
of threads execution and nodes2 is count of same after a call to
System.gc() to verify I don't have a memory leak.

Source code without ThreadMXBean stuff is here
SourceForge.net: Lock-free synchronization primitives 
<http://sourceforge.net/projects/atomic-ptr-plus/>

thread count = 20
loop count   = 5000

starting ConcurrentLinkedQueue ...
elapsed time   = 1211 msec
total time     = 6545
system time    = 170
user time      = 150
blocked time   = 3964
blocked count  = 31
waited time    = 0
waited count   = 0
sum           = 249950000 (expected 249950000)

starting LinkedBlockingQueue ...
elapsed time   = 1162 msec
total time     = 8703
system time    = 100
user time      = 100
blocked time   = 0
blocked count  = 0
waited time    = 8339
waited count   = 28
sum           = 249950000 (expected 249950000)

starting Synchronized LinkedList ...
elapsed time   = 2434 msec
total time     = 29010
system time    = 1482
user time      = 650
blocked time   = 26259
blocked count  = 149748
waited time    = 0
waited count   = 0
sum           = 249950000 (expected 249950000)

starting XmemQueue ...
elapsed time   = 7821 msec
total time     = 110886
system time    = 1341
user time      = 1311
blocked time   = 95421
blocked count  = 1091
waited time    = 0
waited count   = 0
sum           = 249950000 (expected 249950000)
tries    = 200229
retries  = 228
notries  = 226
noswaps  = 3
nodes    = 85032
nodes2   = 0



--
Joe Seigh


From jmanson at cs.umd.edu  Thu Mar 29 15:28:35 2007
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Thu, 29 Mar 2007 12:28:35 -0700
Subject: [concurrency-interest] Measuring lock contention
	with	ThreadMXBean
In-Reply-To: <460B9D30.8010805@xemaps.com>
References: <460B2B4D.3090503@sun.com> <460B9D30.8010805@xemaps.com>
Message-ID: <460C1363.8040501@cs.umd.edu>

Joseph Seigh wrote:

> The locks are whatever ThreadMXBean measures.   I suspect it is the GC 
> which appears to be using
> conventional synchronization to park threads.   

I was going to respond with this -- I've seen contention happen in 
ReferenceQueue.remove and enqueue regardless of what else you are doing 
in your code.  It is possible to measure this using JVMTI.

					Jeremy

From dawidk at mathcs.emory.edu  Thu Mar 29 18:09:44 2007
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu, 29 Mar 2007 18:09:44 -0400
Subject: [concurrency-interest] ConcurrentWeakIdentityHashMap
In-Reply-To: <460A7972.2010305@cytetech.com>
References: <460A7972.2010305@cytetech.com>
Message-ID: <460C3928.2060709@mathcs.emory.edu>

Gregg Wonderly wrote:
> Is there any thought about creating a new WeakIdentityHashMap which can be used 
> in places where classloaders and other dynamic bindings are in use.  I've not 
> looked into this at any depth yet, but there are some places where WeakHashMap 
> are used in the Jini 2.1 codebase which I've been looking at to do some 
> contention reduction.  The use of distributed key based locks in 
> ConcurrentHashMap is nice for things related to threading, ClassLoader and 
> ProtectionDomain issues where multiple unrelated users are active at one time.
>   

Check out http://dcl.mathcs.emory.edu/util/, in particular:

http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/trunk/util/src/edu/emory/mathcs/util/collections/WeakIdentityHashMap.java?view=log
(WeakIdentityHashMap, non-concurrent: purging piggybacks on other 
operations, as in standard WeakHashMap)

http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/trunk/util/src/edu/emory/mathcs/util/collections/WeakValueMap.java?view=markup
(WeakValueMap: a wrapper that turns a map into a map with with values 
(rather than keys) that are weakly referenced; non-concurrent: purging 
piggybacks on other operations, as in standard WeakHashMap)

http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/trunk/util/src/edu/emory/mathcs/util/collections/WeakValueHashMap.java?view=markup
(HashMap-based instance of the above)

http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/trunk/util/src/edu/emory/mathcs/util/collections/AsyncWeakValueMap.java?view=markup
(AsyncWeakValueMap: a wrapper that turns a map into a map with with 
values (rather than keys) that are weakly referenced; concurrent: 
purging is asynchronous)

http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/trunk/util/src/edu/emory/mathcs/util/collections/AsyncWeakValueHashMap.java?view=markup
(ConcurrentHashMap-based instance of the above)

There's no AsyncWeakIdentityHashMap - I didn't happen to need one -  but 
I am sure you can connect the dots and roll one out yourself :)

Regards,
Dawid



From jseigh_cp00 at xemaps.com  Thu Mar 29 22:06:44 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Thu, 29 Mar 2007 21:06:44 -0500
Subject: [concurrency-interest] Measuring lock contention
	with	ThreadMXBean
In-Reply-To: <460C1363.8040501@cs.umd.edu>
References: <460B2B4D.3090503@sun.com> <460B9D30.8010805@xemaps.com>
	<460C1363.8040501@cs.umd.edu>
Message-ID: <460C70B4.2000500@xemaps.com>

Jeremy Manson wrote:

>
> Joseph Seigh wrote:
>
>> The locks are whatever ThreadMXBean measures.   I suspect it is the 
>> GC which appears to be using
>> conventional synchronization to park threads.   
>
>
> I was going to respond with this -- I've seen contention happen in 
> ReferenceQueue.remove and enqueue regardless of what else you are 
> doing in your code.  It is possible to measure this using JVMTI.
>
>                     Jeremy
>
I'm not currently using ReferenceQueues explicitly so unless they're 
implicit with the use of some
reference types.

I added in a gc bean to the program output.  the xmem version is really 
churing through memory.

thread count = 20
loop count   = 5000

starting ConcurrentLinkedQueue ...
elapsed time   = 471 msec
total time     = 4760
system time    = 220
user time      = 190
blocked time   = 996
blocked count  = 30
waited time    = 0
waited count   = 0
gc name        = Copy
gc time        = 47
gc count       = 6
gc name        = MarkSweepCompact
gc time        = 16
gc count       = 1
sum           = 249950000 (expected 249950000)

starting LinkedBlockingQueue ...
elapsed time   = 321 msec
total time     = 1461
system time    = 100
user time      = 100
blocked time   = 0
blocked count  = 0
waited time    = 1318
waited count   = 21
gc name        = Copy
gc time        = 47
gc count       = 6
gc name        = MarkSweepCompact
gc time        = 16
gc count       = 1
sum           = 249950000 (expected 249950000)

starting Synchronized LinkedList ...
elapsed time   = 2343 msec
total time     = 42360
system time    = 2042
user time      = 861
blocked time   = 39478
blocked count  = 199553
waited time    = 0
waited count   = 0
gc name        = Copy
gc time        = 4
gc count       = 8
gc name        = MarkSweepCompact
gc time        = 16
gc count       = 1
sum           = 249950000 (expected 249950000)

starting XmemQueue ...
elapsed time   = 5959 msec
total time     = 84800
system time    = 1241
user time      = 1241
blocked time   = 70687
blocked count  = 1226
waited time    = 0
waited count   = 0
gc name        = Copy
gc time        = 4338
gc count       = 75
gc name        = MarkSweepCompact
gc time        = 35
gc count       = 1
sum           = 249950000 (expected 249950000)
tries    = 200224
retries  = 223
notries  = 220
noswaps  = 9
nodes    = 119551
nodes2   = 0



--
Joe Seigh

From jmanson at cs.umd.edu  Fri Mar 30 05:15:04 2007
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Fri, 30 Mar 2007 02:15:04 -0700
Subject: [concurrency-interest] Cliff's Lock-Free Hash Table
Message-ID: <460CD518.6000306@cs.umd.edu>

Cliff Click gave a talk about his lock-free hashtable (which came up on 
this list about a month ago) at Google this week, and they got the video 
up very promptly.  Definitely worth a peek:

http://video.google.com/videoplay?docid=2139967204534450862

					Jeremy

From gergg at cox.net  Fri Mar 30 10:51:42 2007
From: gergg at cox.net (Gregg Wonderly)
Date: Fri, 30 Mar 2007 09:51:42 -0500
Subject: [concurrency-interest] Cliff's Lock-Free Hash Table
In-Reply-To: <460CD518.6000306@cs.umd.edu>
References: <460CD518.6000306@cs.umd.edu>
Message-ID: <460D23FE.7040907@cox.net>

Jeremy Manson wrote:
> Cliff Click gave a talk about his lock-free hashtable (which came up on 
> this list about a month ago) at Google this week, and they got the video 
> up very promptly.  Definitely worth a peek:
> 
> http://video.google.com/videoplay?docid=2139967204534450862

Thanks for the pointer Jeremy.  Cliff did a great job explaining what he has 
done.  I was not so much amazed at the feat as I was at the dedication to cover 
all the bases using the no-locks mantra that got him started.  This will be a 
great thing to have in large scale systems, and it will be very valuable in Java 
Policy implemenations where there is often high contention for read access to 
ProtectionDomain related Permission sets.

Gregg Wonderly

From jason_mehrens at hotmail.com  Fri Mar 30 14:10:56 2007
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 30 Mar 2007 13:10:56 -0500
Subject: [concurrency-interest] ConcurrentWeakIdentityHashMap
Message-ID: <BAY142-F35A7A253FA5DC1CC2F89DF83630@phx.gbl>

I hope that if any new Reference Map is added to the JDK it implements 
ConcurrentMap.  The behavior of the weak/soft references exactly align with 
the behavior of the ConcurrentMap.  Allowing null to be added to a reference 
or a ConcurrentMap has ambiguous meanings.  The WeakHashMap methods read 
just like the ConcurrentMap wrt size, isEmpty, equals, hashCode.
The WeakHashMap spec even implies that another thread (g.c)  is using the 
map.

A lot of the RFEs for new reference maps predate the ConcurrentMap.  Maybe 
they will be updated to say ConcurrentMap instead of just Map someday.

my two cents,

Jason Mehrens


>From: Gregg Wonderly <gregg at cytetech.com>
>Reply-To: gregg.wonderly at pobox.com
>To: concurrency-interest at cs.oswego.edu
>Subject: [concurrency-interest] ConcurrentWeakIdentityHashMap
>Date: Wed, 28 Mar 2007 09:19:30 -0500
>
>Is there any thought about creating a new WeakIdentityHashMap which can be 
>used
>in places where classloaders and other dynamic bindings are in use.  I've 
>not
>looked into this at any depth yet, but there are some places where 
>WeakHashMap
>are used in the Jini 2.1 codebase which I've been looking at to do some
>contention reduction.  The use of distributed key based locks in
>ConcurrentHashMap is nice for things related to threading, ClassLoader and
>ProtectionDomain issues where multiple unrelated users are active at one 
>time.
>
>Gregg Wonderly
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at altair.cs.oswego.edu
>http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

_________________________________________________________________
i'm making a difference.?Make every IM count for the cause of your choice. 
Join Now. 
http://clk.atdmt.com/MSN/go/msnnkwme0080000001msn/direct/01/?href=http://im.live.com/messenger/im/home/?source=hmtagline


