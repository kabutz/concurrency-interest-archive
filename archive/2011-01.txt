From mohanr at fss.co.in  Wed Jan  5 08:52:42 2011
From: mohanr at fss.co.in (Mohan Radhakrishnan)
Date: Wed, 5 Jan 2011 19:22:42 +0530
Subject: [concurrency-interest] Data structure concurrency question
Message-ID: <E49F4E6D734B954487B074B4EFE60D010F2914@fssbemail.fss.india>

Hi,

     Ascii representation of UML multiplicity :

 

Logger Name 1---------* Logger 1----------1 Levels

 

 

I have a requirement to associate one logger name with multiple Loggers
each of which is in turn associated with a single level. What is a
concurrent data structure recommendation for this ?

 

      It is basically a map of maps. The accesses are not going to be
highly concurrent but the log messages should not be interleaved.

 

 

Thanks,

Mohan

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110105/4bad42af/attachment.html>

From mohanr at fss.co.in  Thu Jan  6 02:25:05 2011
From: mohanr at fss.co.in (Mohan Radhakrishnan)
Date: Thu, 6 Jan 2011 12:55:05 +0530
Subject: [concurrency-interest] Race condition on singleton
In-Reply-To: <AANLkTi=2xOkfsYA==VzScL6G=6vVcDwZWJfxd4BL_+JJ@mail.gmail.com>
Message-ID: <E49F4E6D734B954487B074B4EFE60D010F2C5C@fssbemail.fss.india>

Hi,
     What about this ? Is this a similar singleton ? Since the map is static we haven't anticipated any problem.

Should the method be synchronized ? There could be a problem with a partially created object ? Logically even if threads get interleaved the map will anyway have the right object.

We run this code with about 10-15 threads with no problem.


	private static Test test = null;

	private static Hashtable<String, Test> logMap = new Hashtable<String, Test >();

	public static Test getInstance( String logName ) {

		if (null == logMap.get(logName)) {

			test = new Test (logName);

			logMap.put(logName, test);


		} else {

			test = logMap.get(logName);

		}

		return test;

	 }

Thanks,
Mohan
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Marco Villalobos
Sent: Monday, December 13, 2010 10:58 AM
To: concurrency-interest
Subject: Re: [concurrency-interest] Race condition on singleton

By simply reading his code, which I assume is an abridged version of
the original, I didn't notice anything that would cause an NPE.

However, if his original code uses static variables, then order of
those declarations will matter.

For example:

public class WillNPE {

    private final static WillNPE instance = new WillNPE();
    private final static Set<Integer> set = new HashSet<Integer>();

    public static WillNPE getInstance() {
        return instance;
    }

    public WillNPE() {
        set.add(1);
    }

    public static void main(String args[]) {
        WillNPE local = WillNPE.getInstance();
    }
}


On Sun, Dec 12, 2010 at 9:10 PM, Justin T. Sampson <justin at krasama.com> wrote:
> I'm surprised with all the replies that no one commented on the lack of
> synchronization on accessing the contents of the map. That can easily cause
> NPEs from within map.put(k, v), or almost any other arbitrary behavior for
> that matter.
> Cheers,
> Justin
>
> On Thu, Dec 9, 2010 at 4:44 AM, Guy Korland <gkorland at gmail.com> wrote:
>>
>> Hi,
>> We found a very strange pattern that seems like?contradicting?the Java
>> Memory Model.
>> It seems like a class that is?maintained?as?singleton?doesn't have its
>> constructor fully?initialized!
>> See the code example bellow.
>> public class MyClass{
>> ??private static final?MyClass = new?MyClass();
>>
>> ??private final HashMap map;
>> ??private MyClass(){
>> ?? ???map = new HashMap();
>> ??}
>> ??public void put(Object k, Object v){
>> ?? ? map.put(k,v);
>> ??}
>> ??static public getMyClass(){
>> ?? ?return myClass;
>> ??}
>> }
>>
>> And when we invoke the following:
>> MyClass.getMyClass().put("a","b");
>> We get a NullPointerException on the "map.put(k,v);", meaning the
>> map==null !?!?
>> Any ideas?
>> Thanks,
>> Guy Korland
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From mthornton at optrak.co.uk  Thu Jan  6 03:26:29 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Thu, 06 Jan 2011 08:26:29 +0000
Subject: [concurrency-interest] Race condition on singleton
In-Reply-To: <E49F4E6D734B954487B074B4EFE60D010F2C5C@fssbemail.fss.india>
References: <E49F4E6D734B954487B074B4EFE60D010F2C5C@fssbemail.fss.india>
Message-ID: <4D257CB5.8010805@optrak.co.uk>

On 06/01/2011 07:25, Mohan Radhakrishnan wrote:
> Hi,
>       What about this ? Is this a similar singleton ? Since the map is static we haven't anticipated any problem.
>
> Should the method be synchronized ? There could be a problem with a partially created object ? Logically even if threads get interleaved the map will anyway have the right object.
>
> We run this code with about 10-15 threads with no problem.

You got lucky, that code is badly broken. The simplest fix would be to 
synchronize the getInstance method.

Mark Thornton

>
> 	private static Test test = null;
>
> 	private static Hashtable<String, Test>  logMap = new Hashtable<String, Test>();
>
> 	public static Test getInstance( String logName ) {
>
> 		if (null == logMap.get(logName)) {
>
> 			test = new Test (logName);
>
> 			logMap.put(logName, test);
>
>
> 		} else {
>
> 			test = logMap.get(logName);
>
> 		}
>
> 		return test;
>
> 	 }
>
> Thanks,
> Mohan
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Marco Villalobos
> Sent: Monday, December 13, 2010 10:58 AM
> To: concurrency-interest
> Subject: Re: [concurrency-interest] Race condition on singleton
>
> By simply reading his code, which I assume is an abridged version of
> the original, I didn't notice anything that would cause an NPE.
>
> However, if his original code uses static variables, then order of
> those declarations will matter.
>
> For example:
>
> public class WillNPE {
>
>      private final static WillNPE instance = new WillNPE();
>      private final static Set<Integer>  set = new HashSet<Integer>();
>
>      public static WillNPE getInstance() {
>          return instance;
>      }
>
>      public WillNPE() {
>          set.add(1);
>      }
>
>      public static void main(String args[]) {
>          WillNPE local = WillNPE.getInstance();
>      }
> }
>
>
> On Sun, Dec 12, 2010 at 9:10 PM, Justin T. Sampson<justin at krasama.com>  wrote:
>> I'm surprised with all the replies that no one commented on the lack of
>> synchronization on accessing the contents of the map. That can easily cause
>> NPEs from within map.put(k, v), or almost any other arbitrary behavior for
>> that matter.
>> Cheers,
>> Justin
>>
>> On Thu, Dec 9, 2010 at 4:44 AM, Guy Korland<gkorland at gmail.com>  wrote:
>>> Hi,
>>> We found a very strange pattern that seems like contradicting the Java
>>> Memory Model.
>>> It seems like a class that is maintained as singleton doesn't have its
>>> constructor fully initialized!
>>> See the code example bellow.
>>> public class MyClass{
>>>    private static final MyClass = new MyClass();
>>>
>>>    private final HashMap map;
>>>    private MyClass(){
>>>        map = new HashMap();
>>>    }
>>>    public void put(Object k, Object v){
>>>       map.put(k,v);
>>>    }
>>>    static public getMyClass(){
>>>      return myClass;
>>>    }
>>> }
>>>
>>> And when we invoke the following:
>>> MyClass.getMyClass().put("a","b");
>>> We get a NullPointerException on the "map.put(k,v);", meaning the
>>> map==null !?!?
>>> Any ideas?
>>> Thanks,
>>> Guy Korland
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From sebastien.bocq at gmail.com  Fri Jan  7 10:01:34 2011
From: sebastien.bocq at gmail.com (=?ISO-8859-1?Q?S=E9bastien_Bocq?=)
Date: Fri, 7 Jan 2011 16:01:34 +0100
Subject: [concurrency-interest] Concurrent sequential access to a mutable
	field without the volatile modifier
Message-ID: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>

Hello,

I made a simple test (see below) to verify my assumption that a variable
mutated sequentially by multiple threads must be marked as volatile to have
mutations visible across these threads. How comes my test succeeds even
though I omitted the volatile keyword?

Thanks,
S?bastien

import java.util.concurrent.*;

public class VolatileTest {

    static class CountTask implements Runnable {
        public int count = 0;             // volatile omitted
        public void run() { count++; }
        @Override
        public String toString() {return String.valueOf(count);}
    };

    static class SimpleExecutor implements Runnable {

       LinkedBlockingQueue<Runnable> queue = new
LinkedBlockingQueue<Runnable>();

       public void submit(Runnable runnable) { queue.offer(runnable); }

       volatile Thread thread = null;

       public void run() {

          thread = Thread.currentThread();

          while (thread != null) {

            try {
                Runnable task = queue.take();
                task.run();
            } catch (InterruptedException e) {}
          }
       }

       public void shutdown() {
         Thread t = thread;
         thread = null;
         t.interrupt();
       }

       public SimpleExecutor() {
           new Thread(this).start();
       }
    }

    static class LoopTask implements Runnable {
        CountDownLatch latch;
        int count;
        Runnable task;
        SimpleExecutor[] executors;

        /** Repeat a task sequentially using different executors
         *
         * @param executors the executors
         * @param count     the number of iterations
         * @param latch     latch decremented after the last iteration
         * @param task      the task invoked repeatedly
         */
        public LoopTask(SimpleExecutor[] executors, int count,
CountDownLatch latch, Runnable task) {
            this.executors = executors;
            this.latch = latch;
            this.count = count;
            this.task  = task;
        }

        public void run() {
            if (count == 0)
                latch.countDown();
            else {
                task.run();
                executors[count % executors.length].submit(new
LoopTask(executors, count - 1, latch, task));
            }
        }
    }

     public static void main(String[] args) throws Exception {
       int loops = 1000000;
       int nbExecs = 10;

       CountDownLatch latch = new CountDownLatch(1);
       SimpleExecutor[] executors = new SimpleExecutor[nbExecs];

       for (int i = 0; i < executors.length; i++)
         executors[i] = new SimpleExecutor();

       CountTask task = new CountTask();

       try {
           new LoopTask(executors, loops, latch, task).run();

           latch.await();

           System.out.println(task);
           assert(task.count == loops);
       } finally {
           for (int i = 0; i < executors.length; i++)
               executors[i].shutdown();
       }
     }
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/d8b58217/attachment.html>

From mthornton at optrak.co.uk  Fri Jan  7 10:17:48 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Fri, 07 Jan 2011 15:17:48 +0000
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
Message-ID: <4D272E9C.5090705@optrak.co.uk>

On 07/01/2011 15:01, S?bastien Bocq wrote:
> Hello,
>
> I made a simple test (see below) to verify my assumption that a 
> variable mutated sequentially by multiple threads must be marked as 
> volatile to have mutations visible across these threads. How comes my 
> test succeeds even though I omitted the volatile keyword?

The absence of volatile merely means the mutations may not be visible, 
it doesn't guarantee that they won't be visible. So in some 
implementations your mutations may be visible while in others they may 
not. Adding volatile gives you a guarantee of visibility.

Mark


From sebastien.bocq at gmail.com  Fri Jan  7 10:32:22 2011
From: sebastien.bocq at gmail.com (=?ISO-8859-1?Q?S=E9bastien_Bocq?=)
Date: Fri, 7 Jan 2011 16:32:22 +0100
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <4D272E9C.5090705@optrak.co.uk>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D272E9C.5090705@optrak.co.uk>
Message-ID: <AANLkTikUVBN3f4uX=nhudYuGgpTqPuT9MpOn7LSgBJ=e@mail.gmail.com>

2011/1/7 Mark Thornton <mthornton at optrak.co.uk>

> On 07/01/2011 15:01, S?bastien Bocq wrote:
>
>> Hello,
>>
>> I made a simple test (see below) to verify my assumption that a variable
>> mutated sequentially by multiple threads must be marked as volatile to have
>> mutations visible across these threads. How comes my test succeeds even
>> though I omitted the volatile keyword?
>>
>
> The absence of volatile merely means the mutations may not be visible, it
> doesn't guarantee that they won't be visible. So in some implementations
> your mutations may be visible while in others they may not. Adding volatile
> gives you a guarantee of visibility.
>
>
Ok, I needed to be sure.

Thanks for the swift answer,
S?bastien
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/2b6f357c/attachment.html>

From holger.hoffstaette at googlemail.com  Fri Jan  7 10:48:45 2011
From: holger.hoffstaette at googlemail.com (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Fri, 07 Jan 2011 16:48:45 +0100
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
Message-ID: <4D2735DD.6010308@googlemail.com>

On 07.01.2011 16:01, S?bastien Bocq wrote:
> I made a simple test (see below) to verify my assumption that a variable
> mutated sequentially by multiple threads must be marked as volatile to
> have mutations visible across these threads. How comes my test succeeds
> even though I omitted the volatile keyword?

http://en.wikipedia.org/wiki/Memory_ordering
In short: you got lucky.

Holger

From sebastien.bocq at gmail.com  Fri Jan  7 11:48:34 2011
From: sebastien.bocq at gmail.com (=?ISO-8859-1?Q?S=E9bastien_Bocq?=)
Date: Fri, 7 Jan 2011 17:48:34 +0100
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <4D2735DD.6010308@googlemail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D2735DD.6010308@googlemail.com>
Message-ID: <AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>

2011/1/7 Holger Hoffst?tte <holger.hoffstaette at googlemail.com>

> On 07.01.2011 16:01, S?bastien Bocq wrote:
> > I made a simple test (see below) to verify my assumption that a variable
> > mutated sequentially by multiple threads must be marked as volatile to
> > have mutations visible across these threads. How comes my test succeeds
> > even though I omitted the volatile keyword?
>
> http://en.wikipedia.org/wiki/Memory_ordering
> In short: you got lucky.
>

What worries me is that I get lucky each time I run the test which means I
can't rely on regression tests for catching these kinds of mistakes, at
least on my current test setup (Intel Core Duo, Windows and Oracle JDK 1.6).
I'd feel better if I could get my hands on a test platform less tolerant
towards these kinds bugs. Any advice?

Thanks,
S?bastien
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/4709806b/attachment.html>

From forax at univ-mlv.fr  Fri Jan  7 12:04:13 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Fri, 07 Jan 2011 18:04:13 +0100
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>	<4D2735DD.6010308@googlemail.com>
	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
Message-ID: <4D27478D.4090108@univ-mlv.fr>

On 01/07/2011 05:48 PM, S?bastien Bocq wrote:
> 2011/1/7 Holger Hoffst?tte <holger.hoffstaette at googlemail.com 
> <mailto:holger.hoffstaette at googlemail.com>>
>
>     On 07.01.2011 16:01, S?bastien Bocq wrote:
>     > I made a simple test (see below) to verify my assumption that a
>     variable
>     > mutated sequentially by multiple threads must be marked as
>     volatile to
>     > have mutations visible across these threads. How comes my test
>     succeeds
>     > even though I omitted the volatile keyword?
>
>     http://en.wikipedia.org/wiki/Memory_ordering
>     In short: you got lucky.
>
>
> What worries me is that I get lucky each time I run the test which 
> means I can't rely on regression tests for catching these kinds of 
> mistakes, at least on my current test setup (Intel Core Duo, Windows 
> and Oracle JDK 1.6). I'd feel better if I could get my hands on a test 
> platform less tolerant towards these kinds bugs. Any advice?

I love this test:
public class MutablePoint {
   int x;
   int y;

   public static void main(String[] args) {
     final MutablePoint point = new MutablePoint();
     for(int i=0; i<2; i++) {
       final int id = i;
       new Thread(new Runnable() {
         @Override
         public void run() {
           for(;;) {
             point.x = point.y = id;
             if (point.x != point.y) {
               System.out.println("zorg !");
             }
           }
         }
       }).start();
     }
   }
}

which prints a finite number of "zorg !",
at least if you don't use -Xint.
Also -server usually prints more "zorg !" than -client :)

>
> Thanks,
> S?bastien

R?mi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/d01e3ba4/attachment.html>

From sjlee0 at gmail.com  Fri Jan  7 12:12:35 2011
From: sjlee0 at gmail.com (Sangjin Lee)
Date: Fri, 7 Jan 2011 09:12:35 -0800
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D2735DD.6010308@googlemail.com>
	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
Message-ID: <AANLkTi=TrHrvqo+MNeQ9ZP6TnaG1cb7wHFYbJwUniCQ8@mail.gmail.com>

It's really the handoff using the blocking queue that is providing memory
barrier. And the way you wrote, you have essentially a serial execution
(using multiple threads).

If you allowed full fledged concurrent access at the counter, you'll find
that the test fails. Actually making the count volatile does not make the
program correct in this situation. Volatile will not protect you from the
data race for the ++ operation. You'll need a strong mechanism than that to
get a thread safe concurrent counter, possibly using something like an
AtomicInteger.

Sangjin

2011/1/7 S?bastien Bocq <sebastien.bocq at gmail.com>

> 2011/1/7 Holger Hoffst?tte <holger.hoffstaette at googlemail.com>
>
> On 07.01.2011 16:01, S?bastien Bocq wrote:
>> > I made a simple test (see below) to verify my assumption that a variable
>> > mutated sequentially by multiple threads must be marked as volatile to
>> > have mutations visible across these threads. How comes my test succeeds
>> > even though I omitted the volatile keyword?
>>
>> http://en.wikipedia.org/wiki/Memory_ordering
>> In short: you got lucky.
>>
>
> What worries me is that I get lucky each time I run the test which means I
> can't rely on regression tests for catching these kinds of mistakes, at
> least on my current test setup (Intel Core Duo, Windows and Oracle JDK 1.6).
> I'd feel better if I could get my hands on a test platform less tolerant
> towards these kinds bugs. Any advice?
>
> Thanks,
> S?bastien
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/f5d93c1c/attachment.html>

From mvillalobos at kineteque.com  Fri Jan  7 12:14:44 2011
From: mvillalobos at kineteque.com (Marco Villalobos)
Date: Fri, 7 Jan 2011 09:14:44 -0800
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D2735DD.6010308@googlemail.com>
	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
Message-ID: <AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>

S?bastien,

It is very difficult to prove that thread unsafe code or bad
concurrency will fail.

For example, I once deliberately wrote a thread unsafe unique word
counter.   I had it count the words in the complete bible (all of the
books with separate files) and all of the Shakespeare books.

It rarely ever failed, even though it was thread unsafe.

Threads need to be taken in and of context in middle of an operation
while another takes over to expose errors.

These types of situations occur more commonly on multi-processor
systems and/or a stressed system.

You can kind of force this situations by introducing a
Thread.currentThread().sleep() at right places in your code for
testing purposes.

-Marco


From sebastien.bocq at gmail.com  Fri Jan  7 12:40:32 2011
From: sebastien.bocq at gmail.com (=?ISO-8859-1?Q?S=E9bastien_Bocq?=)
Date: Fri, 7 Jan 2011 18:40:32 +0100
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=TrHrvqo+MNeQ9ZP6TnaG1cb7wHFYbJwUniCQ8@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D2735DD.6010308@googlemail.com>
	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
	<AANLkTi=TrHrvqo+MNeQ9ZP6TnaG1cb7wHFYbJwUniCQ8@mail.gmail.com>
Message-ID: <AANLkTikdEGrHKRyjb_b5aBDV13GYTcnNoHc+hd7KszXs@mail.gmail.com>

2011/1/7 Sangjin Lee <sjlee0 at gmail.com>

> It's really the handoff using the blocking queue that is providing memory
> barrier. And the way you wrote, you have essentially a serial execution
> (using multiple threads).


I expected something like that but as Mark pointed out, I cant' trust this
behavior because some other implementations may behave differently.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/413d199e/attachment.html>

From sebastien.bocq at gmail.com  Fri Jan  7 12:47:51 2011
From: sebastien.bocq at gmail.com (=?ISO-8859-1?Q?S=E9bastien_Bocq?=)
Date: Fri, 7 Jan 2011 18:47:51 +0100
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D2735DD.6010308@googlemail.com>
	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
	<AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>
Message-ID: <AANLkTikhVNKDHmcMvoQEkkyWrHwg9PFji2PCDJ1COWY6@mail.gmail.com>

2011/1/7 Marco Villalobos <mvillalobos at kineteque.com>

> S?bastien,
>
> It is very difficult to prove that thread unsafe code or bad
> concurrency will fail.
>
> For example, I once deliberately wrote a thread unsafe unique word
> counter.   I had it count the words in the complete bible (all of the
> books with separate files) and all of the Shakespeare books.
>
> It rarely ever failed, even though it was thread unsafe.
>
> Threads need to be taken in and of context in middle of an operation
> while another takes over to expose errors.
>
> These types of situations occur more commonly on multi-processor
> systems and/or a stressed system.
>
> You can kind of force this situations by introducing a
> Thread.currentThread().sleep() at right places in your code for
> testing purposes.
>
>
Yes, I've been there too. I had a similar project at university: everything
went fine until I gave out the code to the examiner :-)

I hope in the future we will have better means to test concurrent software.
It could be a JVM dedicated to concurrent testing with a terrible
performance but that caches everything not correctly synchronized and
inserts tiny sleep statements randomly.

S?bastien
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110107/c8ffa4b6/attachment.html>

From david.lloyd at redhat.com  Fri Jan  7 12:49:08 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Fri, 07 Jan 2011 11:49:08 -0600
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>	<4D2735DD.6010308@googlemail.com>	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
	<AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>
Message-ID: <4D275214.7050401@redhat.com>

On 01/07/2011 11:14 AM, Marco Villalobos wrote:
> S?bastien,
>
> It is very difficult to prove that thread unsafe code or bad
> concurrency will fail.

I've always wished there was a testing JVM emulator which was 
deliberately designed to exacerbate threading problems - it would, for 
example, never publish data between threads without a proper volatile or 
synch access, or do so randomly based on configuration.  Also it would 
be configurable to do stuff like deliberately starve certain threads, or 
inject context switches or allow the user to manually set up other 
different concurrency scenarios.

Such a thing would be devilishly hard to create, but it would be 
incredibly useful for testing concurrent code and algorithms.

-- 
- DML

From aph at redhat.com  Fri Jan  7 12:56:56 2011
From: aph at redhat.com (Andrew Haley)
Date: Fri, 07 Jan 2011 17:56:56 +0000
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <AANLkTikhVNKDHmcMvoQEkkyWrHwg9PFji2PCDJ1COWY6@mail.gmail.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>	<4D2735DD.6010308@googlemail.com>	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>	<AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>
	<AANLkTikhVNKDHmcMvoQEkkyWrHwg9PFji2PCDJ1COWY6@mail.gmail.com>
Message-ID: <4D2753E8.6080801@redhat.com>

On 01/07/2011 05:47 PM, S?bastien Bocq wrote:
> 2011/1/7 Marco Villalobos<mvillalobos at kineteque.com>
>
>> S?bastien,
>>
>> It is very difficult to prove that thread unsafe code or bad
>> concurrency will fail.
>>
>> For example, I once deliberately wrote a thread unsafe unique word
>> counter.   I had it count the words in the complete bible (all of the
>> books with separate files) and all of the Shakespeare books.
>>
>> It rarely ever failed, even though it was thread unsafe.
>>
>> Threads need to be taken in and of context in middle of an operation
>> while another takes over to expose errors.
>>
>> These types of situations occur more commonly on multi-processor
>> systems and/or a stressed system.
>>
>> You can kind of force this situations by introducing a
>> Thread.currentThread().sleep() at right places in your code for
>> testing purposes.
>>
>>
> Yes, I've been there too. I had a similar project at university: everything
> went fine until I gave out the code to the examiner :-)
>
> I hope in the future we will have better means to test concurrent software.
> It could be a JVM dedicated to concurrent testing with a terrible
> performance but that caches everything not correctly synchronized and
> inserts tiny sleep statements randomly.

The best thing it could do would be to save all memory stores into a
local soft cache and not write out anything until the next memory
barrier.  Then, it could write out all the stores in a random (or
reverse!) order.  :-)

I wonder just how many bugs that would reveal!

Andrew.

From davidcholmes at aapt.net.au  Fri Jan  7 17:23:40 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 8 Jan 2011 08:23:40 +1000
Subject: [concurrency-interest] Concurrent sequential access to a
	mutable field without the volatile modifier
In-Reply-To: <AANLkTikdEGrHKRyjb_b5aBDV13GYTcnNoHc+hd7KszXs@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEIIIKAA.davidcholmes@aapt.net.au>

I didn't analyse your code but it is possible that the blocking queue
(because of its specified semantics) will always provide the necessary
happens-before orderings to avoid any lack-of-visibility problems. But as
noted when test programs contain data races, as your does, and Remi's is
even worse, then "volatile" is not the issue.

You might also want to check out the "Testing" chapter in "Java Concurrency
in Practice". A static analysis tool, like FindBugs, can be a good start.
I've also heard of tools that inject bytecodes to introduce arbitrary
interleavings, but I'm not sure of their current state so you'll have to
google for them or wait to see if anyone posts any info to the list (though
for this memory model stuff you may want to post to the Java Memory Model
list instead or as well).

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of S?bastien
Bocq
  Sent: Saturday, 8 January 2011 3:41 AM
  To: Sangjin Lee
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Concurrent sequential access to a
mutable field without the volatile modifier


  2011/1/7 Sangjin Lee <sjlee0 at gmail.com>

    It's really the handoff using the blocking queue that is providing
memory barrier. And the way you wrote, you have essentially a serial
execution (using multiple threads).

  I expected something like that but as Mark pointed out, I cant' trust this
behavior because some other implementations may behave differently.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110108/71f7dda4/attachment.html>

From djg at cs.washington.edu  Fri Jan  7 22:02:22 2011
From: djg at cs.washington.edu (Dan Grossman)
Date: Fri, 7 Jan 2011 19:02:22 -0800
Subject: [concurrency-interest] Concurrent sequential access to a
 mutable field without the volatile modifier
In-Reply-To: <4D2753E8.6080801@redhat.com>
References: <AANLkTi=u9Kdc294zxKZCzXMgLm=aQtZqjh=e-b9rumoC@mail.gmail.com>
	<4D2735DD.6010308@googlemail.com>
	<AANLkTi=Q2vTiSyxGScOh558kq1KRQsSD4ccs4azEP9X=@mail.gmail.com>
	<AANLkTi=L7-u=3PLgtHzj4Hap+CqtxLxW7Kwi4wg=08zS@mail.gmail.com>
	<AANLkTikhVNKDHmcMvoQEkkyWrHwg9PFji2PCDJ1COWY6@mail.gmail.com>
	<4D2753E8.6080801@redhat.com>
Message-ID: <AANLkTim9i755FAJeR16qFnbmXGe5-2UDg29J_YLSk3aY@mail.gmail.com>

I believe the paper "Adversarial memory for detecting destructive
races" from PLDI 2010 is relevant -- it is a dynamic tool that tries
to stretch the limits of what the JMM allows in order to exhibit bugs.
http://dx.doi.org/10.1145/1809028.1806625

--Dan

On Fri, Jan 7, 2011 at 9:56 AM, Andrew Haley <aph at redhat.com> wrote:
> On 01/07/2011 05:47 PM, S?bastien Bocq wrote:
>>
>> 2011/1/7 Marco Villalobos<mvillalobos at kineteque.com>
>>
>>> S?bastien,
>>>
>>> It is very difficult to prove that thread unsafe code or bad
>>> concurrency will fail.
>>>
>>> For example, I once deliberately wrote a thread unsafe unique word
>>> counter. ? I had it count the words in the complete bible (all of the
>>> books with separate files) and all of the Shakespeare books.
>>>
>>> It rarely ever failed, even though it was thread unsafe.
>>>
>>> Threads need to be taken in and of context in middle of an operation
>>> while another takes over to expose errors.
>>>
>>> These types of situations occur more commonly on multi-processor
>>> systems and/or a stressed system.
>>>
>>> You can kind of force this situations by introducing a
>>> Thread.currentThread().sleep() at right places in your code for
>>> testing purposes.
>>>
>>>
>> Yes, I've been there too. I had a similar project at university:
>> everything
>> went fine until I gave out the code to the examiner :-)
>>
>> I hope in the future we will have better means to test concurrent
>> software.
>> It could be a JVM dedicated to concurrent testing with a terrible
>> performance but that caches everything not correctly synchronized and
>> inserts tiny sleep statements randomly.
>
> The best thing it could do would be to save all memory stores into a
> local soft cache and not write out anything until the next memory
> barrier. ?Then, it could write out all the stores in a random (or
> reverse!) order. ?:-)
>
> I wonder just how many bugs that would reveal!
>
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From navin.jha at FXALL.com  Mon Jan 10 12:32:42 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Mon, 10 Jan 2011 12:32:42 -0500
Subject: [concurrency-interest] Timer notification drifts
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABB@NYEXCH02.fxall.com>

Hi,

Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours... we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/144f7554/attachment.html>

From szegedia at gmail.com  Mon Jan 10 13:03:30 2011
From: szegedia at gmail.com (Attila Szegedi)
Date: Mon, 10 Jan 2011 10:03:30 -0800
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABB@NYEXCH02.fxall.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABB@NYEXCH02.fxall.com>
Message-ID: <2E81F463-F07B-4B6B-BF62-DD92798A864F@gmail.com>

scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

> Hi,
>  
> Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours? we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
>  
> The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.
>  
> Is there a solution/workaround for this problem?
>  
> Regards,
> Navin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/408c9660/attachment.html>

From navin.jha at FXALL.com  Mon Jan 10 13:09:39 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Mon, 10 Jan 2011 13:09:39 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <2E81F463-F07B-4B6B-BF62-DD92798A864F@gmail.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABB@NYEXCH02.fxall.com>
	<2E81F463-F07B-4B6B-BF62-DD92798A864F@gmail.com>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABE@NYEXCH02.fxall.com>

This is exactly what we use. A sample code we tried works fine of some linux machines with a constant lag value (say 15 milliseconds) but fails on other linux machines. We are trying to find if there is something about those linux machines that causes this. The machines on which this is happening ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:


Hi,

Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours... we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/2895854d/attachment.html>

From szegedia at gmail.com  Mon Jan 10 13:24:15 2011
From: szegedia at gmail.com (Attila Szegedi)
Date: Mon, 10 Jan 2011 10:24:15 -0800
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABE@NYEXCH02.fxall.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABB@NYEXCH02.fxall.com>
	<2E81F463-F07B-4B6B-BF62-DD92798A864F@gmail.com>
	<EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABE@NYEXCH02.fxall.com>
Message-ID: <DDA31149-9323-4B84-9FF6-4DC594BF8227@gmail.com>

I see - you weren't specific about which API call you use, so I wanted to root out the rookie mistake :-) Hm? a drift should definitely not occur with scheduleAtFixedRate, as far as I can tell. At this point, this indeed start to sound as a topic relevant for this group :-) Although I can't you help past this stage (not much Linux system expertise), I guess whoever wants to look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:

> This is exactly what we use. A sample code we tried works fine of some linux machines with a constant lag value (say 15 milliseconds) but fails on other linux machines. We are trying to find if there is something about those linux machines that causes this. The machines on which this is happening ironically have much better hardware (high end multi-core linux servers).
>  
> From: Attila Szegedi [mailto:szegedia at gmail.com] 
> Sent: Monday, January 10, 2011 1:03 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
>  
> scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
>  
> On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
> 
> 
> Hi,
>  
> Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours? we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
>  
> The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.
>  
> Is there a solution/workaround for this problem?
>  
> Regards,
> Navin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/f3646487/attachment-0001.html>

From navin.jha at FXALL.com  Mon Jan 10 13:29:53 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Mon, 10 Jan 2011 13:29:53 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <DDA31149-9323-4B84-9FF6-4DC594BF8227@gmail.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABB@NYEXCH02.fxall.com>
	<2E81F463-F07B-4B6B-BF62-DD92798A864F@gmail.com>
	<EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEABE@NYEXCH02.fxall.com>
	<DDA31149-9323-4B84-9FF6-4DC594BF8227@gmail.com>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAC2@NYEXCH02.fxall.com>

>From what I have learned so far is that this is a common problem but the drift is too much for us since it effects our trading date rollover :)

David Holmes has nice blog on clocks (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his blog he suggested to someone with a similar problem that he should post the problem here.

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:24 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

I see - you weren't specific about which API call you use, so I wanted to root out the rookie mistake :-) Hm... a drift should definitely not occur with scheduleAtFixedRate, as far as I can tell. At this point, this indeed start to sound as a topic relevant for this group :-) Although I can't you help past this stage (not much Linux system expertise), I guess whoever wants to look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:


This is exactly what we use. A sample code we tried works fine of some linux machines with a constant lag value (say 15 milliseconds) but fails on other linux machines. We are trying to find if there is something about those linux machines that causes this. The machines on which this is happening ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:



Hi,

Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours... we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/42c440d9/attachment.html>

From davidcholmes at aapt.net.au  Mon Jan 10 15:46:19 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 11 Jan 2011 06:46:19 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAC2@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEJBIKAA.davidcholmes@aapt.net.au>

Check what clocksource the problematic system is using. If it is TSC then
switch to HPET.

These things are difficult to diagnoze.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
  Sent: Tuesday, 11 January 2011 4:30 AM
  To: Attila Szegedi
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Timer notification drifts


  From what I have learned so far is that this is a common problem but the
drift is too much for us since it effects our trading date rollover J



  David Holmes has nice blog on clocks
(http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his
blog he suggested to someone with a similar problem that he should post the
problem here.



  From: Attila Szegedi [mailto:szegedia at gmail.com]
  Sent: Monday, January 10, 2011 1:24 PM
  To: Navin Jha
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Timer notification drifts



  I see - you weren't specific about which API call you use, so I wanted to
root out the rookie mistake :-) Hm. a drift should definitely not occur with
scheduleAtFixedRate, as far as I can tell. At this point, this indeed start
to sound as a topic relevant for this group :-) Although I can't you help
past this stage (not much Linux system expertise), I guess whoever wants to
look into this will want the JRE, Linux, and CPU versions of your system.



  On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:





  This is exactly what we use. A sample code we tried works fine of some
linux machines with a constant lag value (say 15 milliseconds) but fails on
other linux machines. We are trying to find if there is something about
those linux machines that causes this. The machines on which this is
happening ironically have much better hardware (high end multi-core linux
servers).



  From: Attila Szegedi [mailto:szegedia at gmail.com]
  Sent: Monday, January 10, 2011 1:03 PM
  To: Navin Jha
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Timer notification drifts



  scheduleAtFixedRate should help:
<http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>



  On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:






  Hi,



  Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..



  The only solutions we can think of right now is to run the timer for
smaller duration and restart it after that duration.



  Is there a solution/workaround for this problem?



  Regards,

  Navin


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110111/a1dcf2a4/attachment-0001.html>

From navin.jha at FXALL.com  Mon Jan 10 17:11:29 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Mon, 10 Jan 2011 17:11:29 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEJBIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAC2@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCIEJBIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEACF@NYEXCH02.fxall.com>

No luck :(

Does having too many cpus effect this in anyway?

The machine on which a sample test code works only has 2 cpus while the machine on which we see a huge drift has 8 cpus.

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 3:46 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Check what clocksource the problematic system is using. If it is TSC then switch to HPET.

These things are difficult to diagnoze.

David Holmes
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
Sent: Tuesday, 11 January 2011 4:30 AM
To: Attila Szegedi
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts
>From what I have learned so far is that this is a common problem but the drift is too much for us since it effects our trading date rollover :)

David Holmes has nice blog on clocks (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his blog he suggested to someone with a similar problem that he should post the problem here.

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:24 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

I see - you weren't specific about which API call you use, so I wanted to root out the rookie mistake :-) Hm... a drift should definitely not occur with scheduleAtFixedRate, as far as I can tell. At this point, this indeed start to sound as a topic relevant for this group :-) Although I can't you help past this stage (not much Linux system expertise), I guess whoever wants to look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:

This is exactly what we use. A sample code we tried works fine of some linux machines with a constant lag value (say 15 milliseconds) but fails on other linux machines. We are trying to find if there is something about those linux machines that causes this. The machines on which this is happening ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:


Hi,

Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours... we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/0326e54e/attachment.html>

From davidcholmes at aapt.net.au  Mon Jan 10 17:21:29 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 11 Jan 2011 08:21:29 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEACF@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEJCIKAA.davidcholmes@aapt.net.au>

So I take it that HPET is already being used.

The other possibility here is that it is not the timer that is drifting but
the time source that you are using to measure/track when the timer fires.
How are you tracking that?

David
  -----Original Message-----
  From: Navin Jha [mailto:navin.jha at FXALL.com]
  Sent: Tuesday, 11 January 2011 8:11 AM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Timer notification drifts


  No luck L



  Does having too many cpus effect this in anyway?



  The machine on which a sample test code works only has 2 cpus while the
machine on which we see a huge drift has 8 cpus.



  From: David Holmes [mailto:davidcholmes at aapt.net.au]
  Sent: Monday, January 10, 2011 3:46 PM
  To: Navin Jha
  Cc: concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Timer notification drifts



  Check what clocksource the problematic system is using. If it is TSC then
switch to HPET.



  These things are difficult to diagnoze.



  David Holmes

    -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
    Sent: Tuesday, 11 January 2011 4:30 AM
    To: Attila Szegedi
    Cc: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] Timer notification drifts

    From what I have learned so far is that this is a common problem but the
drift is too much for us since it effects our trading date rollover J



    David Holmes has nice blog on clocks
(http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his
blog he suggested to someone with a similar problem that he should post the
problem here.



    From: Attila Szegedi [mailto:szegedia at gmail.com]
    Sent: Monday, January 10, 2011 1:24 PM
    To: Navin Jha
    Cc: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] Timer notification drifts



    I see - you weren't specific about which API call you use, so I wanted
to root out the rookie mistake :-) Hm. a drift should definitely not occur
with scheduleAtFixedRate, as far as I can tell. At this point, this indeed
start to sound as a topic relevant for this group :-) Although I can't you
help past this stage (not much Linux system expertise), I guess whoever
wants to look into this will want the JRE, Linux, and CPU versions of your
system.



    On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:



    This is exactly what we use. A sample code we tried works fine of some
linux machines with a constant lag value (say 15 milliseconds) but fails on
other linux machines. We are trying to find if there is something about
those linux machines that causes this. The machines on which this is
happening ironically have much better hardware (high end multi-core linux
servers).



    From: Attila Szegedi [mailto:szegedia at gmail.com]
    Sent: Monday, January 10, 2011 1:03 PM
    To: Navin Jha
    Cc: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] Timer notification drifts



    scheduleAtFixedRate should help:
<http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>



    On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:





    Hi,



    Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..



    The only solutions we can think of right now is to run the timer for
smaller duration and restart it after that duration.



    Is there a solution/workaround for this problem?



    Regards,

    Navin


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110111/35a2607d/attachment-0001.html>

From navin.jha at FXALL.com  Mon Jan 10 17:33:19 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Mon, 10 Jan 2011 17:33:19 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEJCIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEACF@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCGEJCIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD1@NYEXCH02.fxall.com>

David,
TSC was used by default (according to unix support folks, since I don't have access to configs on those machine), they switched it to use HPET and I got the same result. Below is the sample code I used to test. On one machine I see a constant drift of about 15 milliseconds regardless of how of long the timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has 2 cpus. On the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.

import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Timer;
import java.util.TimerTask;

public class TimerTest {

         public static void main(String[] args) {

               try {
                  long schedule=500;
                  if (args.length > 0)
                        schedule=Long.parseLong(args[0]);
                  System.out.println( " scheduling job\n");
                  Timer eodTimer = new Timer(true);
                  SimpleDateFormat simpleDateFormat = new SimpleDateFormat("HH:mm:ss:S");
                  System.out.println(" Current time = " + simpleDateFormat.format(Calendar.getInstance().getTime()));
                  eodTimer.scheduleAtFixedRate(new TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule, schedule);
                  Thread.sleep(Long.MAX_VALUE);
            } catch (Exception e) {
              System.out.println(e);
            }

      }

         private static class TestTask extends TimerTask {

          long startTime;
          long sch;
          SimpleDateFormat simpleDateFormat;
          TestTask (long startTime,long schedule, SimpleDateFormat simpleDateFormat)
          {
            this.startTime=startTime;
            sch=schedule;
            this.simpleDateFormat = simpleDateFormat;
          }
            public void run() {
                  long now = System.currentTimeMillis();
                  System.out.println(" End time     = " + simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
                  System.out.println(" Actual diff  = "+(now-startTime)+ " milliseconds, expected diff = " + sch + " milliseconds");
                  System.exit(1);

            }
         }
}

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:21 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

So I take it that HPET is already being used.

The other possibility here is that it is not the timer that is drifting but the time source that you are using to measure/track when the timer fires. How are you tracking that?

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:11 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
No luck :(

Does having too many cpus effect this in anyway?

The machine on which a sample test code works only has 2 cpus while the machine on which we see a huge drift has 8 cpus.

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 3:46 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Check what clocksource the problematic system is using. If it is TSC then switch to HPET.

These things are difficult to diagnoze.

David Holmes
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
Sent: Tuesday, 11 January 2011 4:30 AM
To: Attila Szegedi
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts
>From what I have learned so far is that this is a common problem but the drift is too much for us since it effects our trading date rollover :)

David Holmes has nice blog on clocks (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his blog he suggested to someone with a similar problem that he should post the problem here.

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:24 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

I see - you weren't specific about which API call you use, so I wanted to root out the rookie mistake :-) Hm... a drift should definitely not occur with scheduleAtFixedRate, as far as I can tell. At this point, this indeed start to sound as a topic relevant for this group :-) Although I can't you help past this stage (not much Linux system expertise), I guess whoever wants to look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:

This is exactly what we use. A sample code we tried works fine of some linux machines with a constant lag value (say 15 milliseconds) but fails on other linux machines. We are trying to find if there is something about those linux machines that causes this. The machines on which this is happening ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

Hi,

Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours... we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/0ff5f2a9/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Jan 10 17:41:00 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 11 Jan 2011 08:41:00 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD1@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEJDIKAA.davidcholmes@aapt.net.au>

Try using System.nanoTime to track things.

BTW unless you have CPUs with reliable TSC then you should never use TSC as
the clocksource on multi-processor systems. There are some OS specific
utilities from the chip vendors to fix TSC drift but I don't know what is
available for Linux. It's been a little while since I checked on the current
state of this.

David
  -----Original Message-----
  From: Navin Jha [mailto:navin.jha at FXALL.com]
  Sent: Tuesday, 11 January 2011 8:33 AM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Timer notification drifts


  David,

  TSC was used by default (according to unix support folks, since I don't
have access to configs on those machine), they switched it to use HPET and I
got the same result. Below is the sample code I used to test. On one machine
I see a constant drift of about 15 milliseconds regardless of how of long
the timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has 2
cpus. On the machine with 8 cpus The drift was close to 11 seconds for 24
hrs.



  import java.text.SimpleDateFormat;

  import java.util.Calendar;

  import java.util.Timer;

  import java.util.TimerTask;



  public class TimerTest {



           public static void main(String[] args) {



                 try {

                    long schedule=500;

                    if (args.length > 0)

                          schedule=Long.parseLong(args[0]);

                    System.out.println( " scheduling job\n");

                    Timer eodTimer = new Timer(true);

                    SimpleDateFormat simpleDateFormat = new
SimpleDateFormat("HH:mm:ss:S");

                    System.out.println(" Current time = " +
simpleDateFormat.format(Calendar.getInstance().getTime()));

                    eodTimer.scheduleAtFixedRate(new
TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule,
schedule);

                    Thread.sleep(Long.MAX_VALUE);

              } catch (Exception e) {

                System.out.println(e);

              }



        }



           private static class TestTask extends TimerTask {



            long startTime;

            long sch;

            SimpleDateFormat simpleDateFormat;

            TestTask (long startTime,long schedule, SimpleDateFormat
simpleDateFormat)

            {

              this.startTime=startTime;

              sch=schedule;

              this.simpleDateFormat = simpleDateFormat;

            }

              public void run() {

                    long now = System.currentTimeMillis();

                    System.out.println(" End time     = " +
simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");

                    System.out.println(" Actual diff  = "+(now-startTime)+ "
milliseconds, expected diff = " + sch + " milliseconds");

                    System.exit(1);



              }

           }

  }



  From: David Holmes [mailto:davidcholmes at aapt.net.au]
  Sent: Monday, January 10, 2011 5:21 PM
  To: Navin Jha
  Cc: concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Timer notification drifts



  So I take it that HPET is already being used.



  The other possibility here is that it is not the timer that is drifting
but the time source that you are using to measure/track when the timer
fires. How are you tracking that?



  David

    -----Original Message-----
    From: Navin Jha [mailto:navin.jha at FXALL.com]
    Sent: Tuesday, 11 January 2011 8:11 AM
    To: dholmes at ieee.org
    Cc: concurrency-interest at cs.oswego.edu
    Subject: RE: [concurrency-interest] Timer notification drifts

    No luck L



    Does having too many cpus effect this in anyway?



    The machine on which a sample test code works only has 2 cpus while the
machine on which we see a huge drift has 8 cpus.



    From: David Holmes [mailto:davidcholmes at aapt.net.au]
    Sent: Monday, January 10, 2011 3:46 PM
    To: Navin Jha
    Cc: concurrency-interest at cs.oswego.edu
    Subject: RE: [concurrency-interest] Timer notification drifts



    Check what clocksource the problematic system is using. If it is TSC
then switch to HPET.



    These things are difficult to diagnoze.



    David Holmes

      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
      Sent: Tuesday, 11 January 2011 4:30 AM
      To: Attila Szegedi
      Cc: concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Timer notification drifts

      From what I have learned so far is that this is a common problem but
the drift is too much for us since it effects our trading date rollover J



      David Holmes has nice blog on clocks
(http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his
blog he suggested to someone with a similar problem that he should post the
problem here.



      From: Attila Szegedi [mailto:szegedia at gmail.com]
      Sent: Monday, January 10, 2011 1:24 PM
      To: Navin Jha
      Cc: concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Timer notification drifts



      I see - you weren't specific about which API call you use, so I wanted
to root out the rookie mistake :-) Hm. a drift should definitely not occur
with scheduleAtFixedRate, as far as I can tell. At this point, this indeed
start to sound as a topic relevant for this group :-) Although I can't you
help past this stage (not much Linux system expertise), I guess whoever
wants to look into this will want the JRE, Linux, and CPU versions of your
system.



      On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:



      This is exactly what we use. A sample code we tried works fine of some
linux machines with a constant lag value (say 15 milliseconds) but fails on
other linux machines. We are trying to find if there is something about
those linux machines that causes this. The machines on which this is
happening ironically have much better hardware (high end multi-core linux
servers).



      From: Attila Szegedi [mailto:szegedia at gmail.com]
      Sent: Monday, January 10, 2011 1:03 PM
      To: Navin Jha
      Cc: concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Timer notification drifts



      scheduleAtFixedRate should help:
<http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>



      On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:



      Hi,



      Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..



      The only solutions we can think of right now is to run the timer for
smaller duration and restart it after that duration.



      Is there a solution/workaround for this problem?



      Regards,

      Navin


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110111/f688de84/attachment-0001.html>

From navin.jha at FXALL.com  Mon Jan 10 18:04:07 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Mon, 10 Jan 2011 18:04:07 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEJDIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD1@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCEEJDIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD3@NYEXCH02.fxall.com>

David,

I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same results and they use nano time. Are you suggesting using nano time in any other way? I will try them again after the switch to HPET to see if there is any difference. I have communicated your concern  about the use of TSC on multi-processor systems to our unix support group.

One more question, how do I make sure that the clock source is set up correctly to HPET? Since it was done by the support group  I want to make sure that they did it  correctly?

-Navin

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:41 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Try using System.nanoTime to track things.

BTW unless you have CPUs with reliable TSC then you should never use TSC as the clocksource on multi-processor systems. There are some OS specific utilities from the chip vendors to fix TSC drift but I don't know what is available for Linux. It's been a little while since I checked on the current state of this.

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:33 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
David,
TSC was used by default (according to unix support folks, since I don't have access to configs on those machine), they switched it to use HPET and I got the same result. Below is the sample code I used to test. On one machine I see a constant drift of about 15 milliseconds regardless of how of long the timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has 2 cpus. On the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.

import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Timer;
import java.util.TimerTask;

public class TimerTest {

         public static void main(String[] args) {

               try {
                  long schedule=500;
                  if (args.length > 0)
                        schedule=Long.parseLong(args[0]);
                  System.out.println( " scheduling job\n");
                  Timer eodTimer = new Timer(true);
                  SimpleDateFormat simpleDateFormat = new SimpleDateFormat("HH:mm:ss:S");
                  System.out.println(" Current time = " + simpleDateFormat.format(Calendar.getInstance().getTime()));
                  eodTimer.scheduleAtFixedRate(new TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule, schedule);
                  Thread.sleep(Long.MAX_VALUE);
            } catch (Exception e) {
              System.out.println(e);
            }

      }

         private static class TestTask extends TimerTask {

          long startTime;
          long sch;
          SimpleDateFormat simpleDateFormat;
          TestTask (long startTime,long schedule, SimpleDateFormat simpleDateFormat)
          {
            this.startTime=startTime;
            sch=schedule;
            this.simpleDateFormat = simpleDateFormat;
          }
            public void run() {
                  long now = System.currentTimeMillis();
                  System.out.println(" End time     = " + simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
                  System.out.println(" Actual diff  = "+(now-startTime)+ " milliseconds, expected diff = " + sch + " milliseconds");
                  System.exit(1);

            }
         }
}

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:21 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

So I take it that HPET is already being used.

The other possibility here is that it is not the timer that is drifting but the time source that you are using to measure/track when the timer fires. How are you tracking that?

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:11 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
No luck :(

Does having too many cpus effect this in anyway?

The machine on which a sample test code works only has 2 cpus while the machine on which we see a huge drift has 8 cpus.

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 3:46 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Check what clocksource the problematic system is using. If it is TSC then switch to HPET.

These things are difficult to diagnoze.

David Holmes
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
Sent: Tuesday, 11 January 2011 4:30 AM
To: Attila Szegedi
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts
>From what I have learned so far is that this is a common problem but the drift is too much for us since it effects our trading date rollover :)

David Holmes has nice blog on clocks (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his blog he suggested to someone with a similar problem that he should post the problem here.

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:24 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

I see - you weren't specific about which API call you use, so I wanted to root out the rookie mistake :-) Hm... a drift should definitely not occur with scheduleAtFixedRate, as far as I can tell. At this point, this indeed start to sound as a topic relevant for this group :-) Although I can't you help past this stage (not much Linux system expertise), I guess whoever wants to look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:

This is exactly what we use. A sample code we tried works fine of some linux machines with a constant lag value (say 15 milliseconds) but fails on other linux machines. We are trying to find if there is something about those linux machines that causes this. The machines on which this is happening ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help: <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#scheduleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

Hi,

Not sure if this is the right place to post this problem. We use java.util.Timer class for a notification that needs to happens every 24 hours. We noticed that on some linux multi-core servers the notification occurs almost 11 seconds later. If we run for successive smaller durations say 1 hour, 2 hours, 3 hours... we notice that the lag does accumulate. So for 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110110/a8fcd728/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Jan 10 18:12:29 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 11 Jan 2011 09:12:29 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD3@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJEIKAA.davidcholmes@aapt.net.au>

I believe you need root access to check the clocksource (unless default
perms are modified):

cat /sys/devices/system/clocksource/clocksource0/available_clocksource

to see what's available, and

cat /sys/devices/system/clocksource/clocksource0/current_clocksource

to see what is in use.

I was suggesting using nanoTime to measure the elapsed time, rather than
date/currentTimeMillis, as nanoTime should not be affected by time-of-day
adjustments. Which reminds me: check if ntp is running and if so turn it
off, if not turn it on, and see if that makes a difference.

David

-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 9:04 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts


David,

I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
results and they use nano time. Are you suggesting using nano time in any
other way? I will try them again after the switch to HPET to see if there is
any difference. I have communicated your concern  about the use of TSC on
multi-processor systems to our unix support group.

One more question, how do I make sure that the clock source is set up
correctly to HPET? Since it was done by the support group  I want to make
sure that they did it  correctly?

-Navin

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:41 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Try using System.nanoTime to track things.

BTW unless you have CPUs with reliable TSC then you should never use TSC as
the clocksource on multi-processor systems. There are some OS specific
utilities from the chip vendors to fix TSC drift but I don't know what is
available for Linux. It's been a little while since I checked on the current
state of this.

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:33 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
David,
TSC was used by default (according to unix support folks, since I don't have
access to configs on those machine), they switched it to use HPET and I got
the same result. Below is the sample code I used to test. On one machine I
see a constant drift of about 15 milliseconds regardless of how of long the
timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has 2 cpus. On
the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.

import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Timer;
import java.util.TimerTask;

public class TimerTest {

         public static void main(String[] args) {

               try {
                  long schedule=500;
                  if (args.length > 0)
                        schedule=Long.parseLong(args[0]);
                  System.out.println( " scheduling job\n");
                  Timer eodTimer = new Timer(true);
                  SimpleDateFormat simpleDateFormat = new
SimpleDateFormat("HH:mm:ss:S");
                  System.out.println(" Current time = " +
simpleDateFormat.format(Calendar.getInstance().getTime()));
                  eodTimer.scheduleAtFixedRate(new
TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule,
schedule);
                  Thread.sleep(Long.MAX_VALUE);
            } catch (Exception e) {
              System.out.println(e);
            }

      }

         private static class TestTask extends TimerTask {

          long startTime;
          long sch;
          SimpleDateFormat simpleDateFormat;
          TestTask (long startTime,long schedule, SimpleDateFormat
simpleDateFormat)
          {
            this.startTime=startTime;
            sch=schedule;
            this.simpleDateFormat = simpleDateFormat;
          }
            public void run() {
                  long now = System.currentTimeMillis();
                  System.out.println(" End time     = " +
simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
                  System.out.println(" Actual diff  = "+(now-startTime)+ "
milliseconds, expected diff = " + sch + " milliseconds");
                  System.exit(1);

            }
         }
}

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:21 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

So I take it that HPET is already being used.

The other possibility here is that it is not the timer that is drifting but
the time source that you are using to measure/track when the timer fires.
How are you tracking that?

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:11 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
No luck L

Does having too many cpus effect this in anyway?

The machine on which a sample test code works only has 2 cpus while the
machine on which we see a huge drift has 8 cpus.

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 3:46 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Check what clocksource the problematic system is using. If it is TSC then
switch to HPET.

These things are difficult to diagnoze.

David Holmes
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
Sent: Tuesday, 11 January 2011 4:30 AM
To: Attila Szegedi
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts
>From what I have learned so far is that this is a common problem but the
drift is too much for us since it effects our trading date rollover J

David Holmes has nice blog on clocks
(http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his
blog he suggested to someone with a similar problem that he should post the
problem here.

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:24 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

I see - you weren't specific about which API call you use, so I wanted to
root out the rookie mistake :-) Hm. a drift should definitely not occur with
scheduleAtFixedRate, as far as I can tell. At this point, this indeed start
to sound as a topic relevant for this group :-) Although I can't you help
past this stage (not much Linux system expertise), I guess whoever wants to
look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:

This is exactly what we use. A sample code we tried works fine of some linux
machines with a constant lag value (say 15 milliseconds) but fails on other
linux machines. We are trying to find if there is something about those
linux machines that causes this. The machines on which this is happening
ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help:
<http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

Hi,

Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller
duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin



From mthornton at optrak.co.uk  Tue Jan 11 03:33:41 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Tue, 11 Jan 2011 08:33:41 +0000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJEIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEJEIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D2C15E5.3010904@optrak.co.uk>

On 10/01/2011 23:12, David Holmes wrote:
> I believe you need root access to check the clocksource (unless default
> perms are modified):
>
> cat /sys/devices/system/clocksource/clocksource0/available_clocksource
>
> to see what's available, and
>
> cat /sys/devices/system/clocksource/clocksource0/current_clocksource
>
> to see what is in use.
>
For information this is what I get on Ubuntu Server 10.04.1 (default 
configuration):

~$ cat /sys/devices/system/clocksource/clocksource0/available_clocksource
tsc hpet acpi_pm
~$ cat /sys/devices/system/clocksource/clocksource0/current_clocksource
tsc

I didn't need any special permission. The CPU is a dual core Athlon.

The results on Fedora (quad core xeon) are the same.

Mark Thornton


From davidcholmes at aapt.net.au  Tue Jan 11 03:49:38 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 11 Jan 2011 18:49:38 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <4D2C15E5.3010904@optrak.co.uk>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEJFIKAA.davidcholmes@aapt.net.au>

Thanks Mark.

I'm wondering if the boot messages (dmesg?) show a warning about the TSC
being unstable?

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Mark
> Thornton
> Sent: Tuesday, 11 January 2011 6:34 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
>
>
> On 10/01/2011 23:12, David Holmes wrote:
> > I believe you need root access to check the clocksource (unless default
> > perms are modified):
> >
> > cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> >
> > to see what's available, and
> >
> > cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> >
> > to see what is in use.
> >
> For information this is what I get on Ubuntu Server 10.04.1 (default
> configuration):
>
> ~$ cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> tsc hpet acpi_pm
> ~$ cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> tsc
>
> I didn't need any special permission. The CPU is a dual core Athlon.
>
> The results on Fedora (quad core xeon) are the same.
>
> Mark Thornton
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From mthornton at optrak.co.uk  Tue Jan 11 04:03:23 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Tue, 11 Jan 2011 09:03:23 +0000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEJFIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCOEJFIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D2C1CDB.2090403@optrak.co.uk>

On 11/01/2011 08:49, David Holmes wrote:
> Thanks Mark.
>
> I'm wondering if the boot messages (dmesg?) show a warning about the TSC
> being unstable?
>
> David
>

Not that I can see

[    0.000000] hpet clockevent registered
[    0.000000] HPET: 3 timers in total, 0 timers will be used for 
per-cpu timer
[    0.000000] Fast TSC calibration using PIT
[    0.000000] Detected 1297.845 MHz processor.
[    0.020008] Calibrating delay loop (skipped), value calculated using 
timer fr
equency.. 2595.68 BogoMIPS (lpj=12978440)
...
[    0.320086] CPU1: AMD Athlon(tm) II Neo N36L Dual-Core Processor 
stepping 03
[    0.320097] checking TSC synchronization [CPU#0 -> CPU#1]: passed.
[    0.330021] Brought up 2 CPUs
[    0.330025] Total of 2 processors activated (5191.37 BogoMIPS).


On the other machine:

hpet clockevent registered
Fast TSC calibration using PIT
Detected 2333.017 MHz processor.
Calibrating delay loop (skipped), value calculated using timer 
frequency.. 4666.
03 BogoMIPS (lpj=2333017)

CPU0: Intel(R) Xeon(R) CPU           E5345  @ 2.33GHz stepping 07

No check for synchronization reported in this case.

No mention of TSC being unstable in either case.

Mark Thornton




From ach at quartetfs.com  Tue Jan 11 05:01:03 2011
From: ach at quartetfs.com (Antoine CHAMBILLE)
Date: Tue, 11 Jan 2011 11:01:03 +0100
Subject: [concurrency-interest] Question about signalWork() implementation
	in the Fork Join Pool
Message-ID: <00dd01cbb176$771b3480$65519d80$@quartetfs.com>

We are investigating dead lock issues in an application relying on the fork
join pool. We are using the latest (December 2010) jsr166y release.

We submit main tasks to the pool that process a number of items. Every n
item the task creates a subtask in charge of those n items, register the
subtask in a phaser, and forks the sub task. When the subtask completes it
arrives and deregisters from the phaser. Once all the groups of items have
been forked, the main task awaits the phaser, does a bit of post processing
and returns.

We continuously submit main tasks to the pool during the application life
and this works well for large periods of time (several hours) but regularly
at some point the pool deadlocks. Analysing the stack trace shows us that
most worker threads are blocked awaiting the phaser, and a few worker
threads are parked by awaitEvent() (untimed park), and never wake up while
only them could allow some progress. It looks like some of the fork events
have not been accounted for.


So we have this question about the implementation of signalWork() in the
fork join pool:
Why is compare and swap failure allowed when maintaining the event count of
the pool?

/**
     * Tries to advance eventCount and releases waiters. Called only
     * from workers.
     */
    final void signalWork() {
        int c; // try to increment event count -- CAS failure OK
        UNSAFE.compareAndSwapInt(this, eventCountOffset, c = eventCount,
c+1);
        if (eventWaiters != 0L)
            releaseEventWaiters();
    }


Antoine CHAMBILLE
QuartetFS


From mthornton at optrak.co.uk  Tue Jan 11 05:41:18 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Tue, 11 Jan 2011 10:41:18 +0000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD1@NYEXCH02.fxall.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEACF@NYEXCH02.fxall.com>	<NFBBKALFDCPFIDBNKAPCGEJCIKAA.davidcholmes@aapt.net.au>
	<EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD1@NYEXCH02.fxall.com>
Message-ID: <4D2C33CE.7070101@optrak.co.uk>

On 10/01/2011 22:33, Navin Jha wrote:
>
> David,
>
> TSC was used by default (according to unix support folks, since I 
> don?t have access to configs on those machine), they switched it to 
> use HPET and I got the same result. Below is the sample code I used to 
> test. On one machine I see a constant drift of about 15 milliseconds 
> regardless of how of long the timer runs (I ran it for 1 hr, 2 hrs and 
> 24hrs). This machine has 2 cpus. On the machine with 8 cpus The drift 
> was close to 11 seconds for 24 hrs.
>
>
Are both machines 'real' (i.e. running direct on the hardware) or are 
either of them virtual machines (running within a hypervisor like Xen)?

Mark


From gdenys at yahoo.com  Tue Jan 11 06:40:24 2011
From: gdenys at yahoo.com (Geert Denys)
Date: Tue, 11 Jan 2011 03:40:24 -0800 (PST)
Subject: [concurrency-interest] Question about signalWork()
	implementation in the Fork Join Pool
In-Reply-To: <00dd01cbb176$771b3480$65519d80$@quartetfs.com>
References: <00dd01cbb176$771b3480$65519d80$@quartetfs.com>
Message-ID: <769743.12507.qm@web161204.mail.bf1.yahoo.com>

Could the Phaser be replaced by simply joining the subtask?

In that case, the main task can join the forked subtask and then do its post 
processing. Possibly, you avoid the problem with missed events.

- Geert


----- Original Message ----
From: Antoine CHAMBILLE <ach at quartetfs.com>
To: concurrency-interest at cs.oswego.edu
Sent: Tue, January 11, 2011 11:01:03 AM
Subject: [concurrency-interest] Question about signalWork() implementation in 
the Fork Join Pool

We are investigating dead lock issues in an application relying on the fork
join pool. We are using the latest (December 2010) jsr166y release.

We submit main tasks to the pool that process a number of items. Every n
item the task creates a subtask in charge of those n items, register the
subtask in a phaser, and forks the sub task. When the subtask completes it
arrives and deregisters from the phaser. Once all the groups of items have
been forked, the main task awaits the phaser, does a bit of post processing
and returns.

We continuously submit main tasks to the pool during the application life
and this works well for large periods of time (several hours) but regularly
at some point the pool deadlocks. Analysing the stack trace shows us that
most worker threads are blocked awaiting the phaser, and a few worker
threads are parked by awaitEvent() (untimed park), and never wake up while
only them could allow some progress. It looks like some of the fork events
have not been accounted for.


So we have this question about the implementation of signalWork() in the
fork join pool:
Why is compare and swap failure allowed when maintaining the event count of
the pool?

/**
     * Tries to advance eventCount and releases waiters. Called only
     * from workers.
     */
    final void signalWork() {
        int c; // try to increment event count -- CAS failure OK
        UNSAFE.compareAndSwapInt(this, eventCountOffset, c = eventCount,
c+1);
        if (eventWaiters != 0L)
            releaseEventWaiters();
    }


Antoine CHAMBILLE
QuartetFS

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      

From dl at cs.oswego.edu  Tue Jan 11 08:23:46 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 11 Jan 2011 08:23:46 -0500
Subject: [concurrency-interest] Question about signalWork()
 implementation in the Fork Join Pool
In-Reply-To: <00dd01cbb176$771b3480$65519d80$@quartetfs.com>
References: <00dd01cbb176$771b3480$65519d80$@quartetfs.com>
Message-ID: <4D2C59E2.4020701@cs.oswego.edu>

On 01/11/11 05:01, Antoine CHAMBILLE wrote:
> We are investigating dead lock issues in an application relying on the fork
> join pool. We are using the latest (December 2010) jsr166y release.

Sorry for problems. It would be very helpful if you could
send me (off-list) a stripped-down test case.

> We submit main tasks to the pool that process a number of items. Every n
> item the task creates a subtask in charge of those n items, register the
> subtask in a phaser,

Almost surely, you are encountering cases where the
total number of registered parties transiently exceeds
the pool's parallelism level (or internal target level).
Failure to accommodate this is a bug, that will be fixed:
the specs for FJ and Phaser don't say you cannot do this,
so it was wrong to assume programs would not do it.
(And we should not just add a disclaimer saying you cannot.)
Some soon-upcoming unrelated-looking improvements
that I'll post about separately address this problem.

(As Geert posted, as a temporary workaround, you can join
all subtasks rather than await the phaser, which evades
this issue.)

> So we have this question about the implementation of signalWork() in the
> fork join pool:
> Why is compare and swap failure allowed when maintaining the event count of
> the pool?

This is unrelated to your problem, but the answer is that,
under assumptions of maintaining minimal adequate parallelism,
it suffices for any signaller to wake up any worker. The "minimal
adequate parallelism" part is the issue here.

-Doug



From ach at quartetfs.com  Tue Jan 11 08:44:17 2011
From: ach at quartetfs.com (Antoine CHAMBILLE)
Date: Tue, 11 Jan 2011 14:44:17 +0100
Subject: [concurrency-interest] Question about signalWork()
	implementation in the Fork Join Pool
In-Reply-To: <4D2C59E2.4020701@cs.oswego.edu>
References: <00dd01cbb176$771b3480$65519d80$@quartetfs.com>
	<4D2C59E2.4020701@cs.oswego.edu>
Message-ID: <00f301cbb195$a6a73310$f3f59930$@quartetfs.com>

Doug, Geert, thank you very much for your attention.


Actually our previous implementation relied on joining. The main tasks where
continuously forking child tasks and joining all of them at the end. Joining
seemed the natural option, because joining is an active wait that allows
more tasks to run on the thread instead of wasting the thread.

But we did experience a similar dead-lock issue with the joining design:
after a long period of running time a dead-lock eventually occurs and the
pool state is the following: most of the worker threads are waiting in the
pool awaitJoin(), and a few worker threads (those that could allow some
progress) are parked in awaitEvent() without ever being unparked. We see the
joining workers sometimes trying to helpMaintainParallelism() but that never
results in the creation of a new worker, neither in unparking one of those
few parked workers...


That's why we tried another design involving a Phaser, a waiting mechanism
that is allowed to be used within a fork join pool. But as reported the
Phaser design also eventually dead-locks.

Are we doing something inherently wrong? Are there known bad practices that
can lead to this fork join pool dead-lock state (most workers waiting
somehow, the few remaining workers parked by awaitEvent() and never
unparked). Shouldn't the fork join pool always guarantee this state is never
reached whatever the workload?


We are already at work trying to reproduce the issue on an isolated test
case, but as often that proves quite difficult to reproduce such a rarely
occurring issue.

Thanks a lot for your help,

-Antoine




-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Doug Lea
Sent: 11 January 2011 14:24
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Question about signalWork()
implementation in the Fork Join Pool

On 01/11/11 05:01, Antoine CHAMBILLE wrote:
> We are investigating dead lock issues in an application relying on the 
> fork join pool. We are using the latest (December 2010) jsr166y release.

Sorry for problems. It would be very helpful if you could send me (off-list)
a stripped-down test case.

> We submit main tasks to the pool that process a number of items. Every 
> n item the task creates a subtask in charge of those n items, register 
> the subtask in a phaser,

Almost surely, you are encountering cases where the total number of
registered parties transiently exceeds the pool's parallelism level (or
internal target level).
Failure to accommodate this is a bug, that will be fixed:
the specs for FJ and Phaser don't say you cannot do this, so it was wrong to
assume programs would not do it.
(And we should not just add a disclaimer saying you cannot.) Some
soon-upcoming unrelated-looking improvements that I'll post about separately
address this problem.

(As Geert posted, as a temporary workaround, you can join all subtasks
rather than await the phaser, which evades this issue.)

> So we have this question about the implementation of signalWork() in 
> the fork join pool:
> Why is compare and swap failure allowed when maintaining the event 
> count of the pool?

This is unrelated to your problem, but the answer is that, under assumptions
of maintaining minimal adequate parallelism, it suffices for any signaller
to wake up any worker. The "minimal adequate parallelism" part is the issue
here.

-Doug


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From navin.jha at FXALL.com  Tue Jan 11 11:24:18 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Tue, 11 Jan 2011 11:24:18 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJEIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD3@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCAEJEIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAE4@NYEXCH02.fxall.com>

David,

We don't see these files, is there another way to check this? 

OS details are:
Linux numpintapp15 2.6.9-78.ELlargesmp #1 SMP Wed Jul 9 16:03:59 EDT 2008 x86_64 x86_64 x86_64 GNU/Linux-bash-3.00$ cat /etc/redhat-release 
Red Hat Enterprise Linux AS release 4 (Nahant Update 7)

Here is the output of the command:
[11:15:53][root:~]$ cat /sys/devices/system/clocksource/clocksource0/available_clocksource
cat: /sys/devices/system/clocksource/clocksource0/available_clocksource: No such file or directory

Also this the log that might tell you more:
[11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
Jan 10 16:51:18 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 16:51:18 numpintapp15 time.c: Using HPET/TSC based timekeeping.
Jan 10 17:00:54 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 17:00:54 numpintapp15 time.c: Using HPET/TSC based timekeeping.
Jan 10 17:18:06 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 17:18:06 numpintapp15 time.c: Using HPET/TSC based timekeeping.
Jan 10 17:35:08 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 17:35:08 numpintapp15 time.c: Using HPET/TSC based timekeeping.
Jan 10 17:38:45 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 17:38:45 numpintapp15 time.c: Using HPET/TSC based timekeeping.
Jan 10 18:07:18 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 18:07:18 numpintapp15 time.c: Using HPET/TSC based timekeeping.
Jan 10 18:12:27 numpintapp15 Bootdata ok (command line is ro root=LABEL=/ hda=ide-scsi notsc hpet=enable)
Jan 10 18:12:27 numpintapp15 Kernel command line: ro root=LABEL=/ hda=ide-scsi notsc hpet=enable console=tty0
Jan 10 18:12:27 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro root=LABEL=/ hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/ hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
Jan 10 18:44:16 numpintapp15 checking TSC synchronization across 12 CPUs: passed.
Jan 10 18:44:16 numpintapp15 time.c: Using HPET/TSC based timekeeping.

We've tried to specify the clocksource in the /boot/grub/grub.conf file.  We've been trying various clocksources. Would you let us know how to set the appropriate clocksource? Below is the grub.conf file.

[11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf 
# grub.conf generated by anaconda
#
# Note that you do not have to rerun grub after making changes to this file
# NOTICE:  You have a /boot partition.  This means that
#          all kernel and initrd paths are relative to /boot/, eg.
#          root (hd0,0)
#          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
#          initrd /initrd-version.img
#boot=/dev/cciss/c0d0
default=1
timeout=5
splashimage=(hd0,0)/grub/splash.xpm.gz
hiddenmenu
title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
        root (hd0,0)
        kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/ hda=ide-scsi clock=hpet clocksource=hpet
        initrd /initrd-2.6.9-78.0.8.EL.img
title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
        root (hd0,0)
        kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/ hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
        initrd /initrd-2.6.9-78.ELlargesmp.img
title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
        root (hd0,0)
        kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi  clock=hpet clocksource=hpet
        initrd /initrd-2.6.9-78.EL.img




-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Monday, January 10, 2011 6:12 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

I believe you need root access to check the clocksource (unless default
perms are modified):

cat /sys/devices/system/clocksource/clocksource0/available_clocksource

to see what's available, and

cat /sys/devices/system/clocksource/clocksource0/current_clocksource

to see what is in use.

I was suggesting using nanoTime to measure the elapsed time, rather than
date/currentTimeMillis, as nanoTime should not be affected by time-of-day
adjustments. Which reminds me: check if ntp is running and if so turn it
off, if not turn it on, and see if that makes a difference.

David

-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 9:04 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts


David,

I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
results and they use nano time. Are you suggesting using nano time in any
other way? I will try them again after the switch to HPET to see if there is
any difference. I have communicated your concern  about the use of TSC on
multi-processor systems to our unix support group.

One more question, how do I make sure that the clock source is set up
correctly to HPET? Since it was done by the support group  I want to make
sure that they did it  correctly?

-Navin

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:41 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Try using System.nanoTime to track things.

BTW unless you have CPUs with reliable TSC then you should never use TSC as
the clocksource on multi-processor systems. There are some OS specific
utilities from the chip vendors to fix TSC drift but I don't know what is
available for Linux. It's been a little while since I checked on the current
state of this.

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:33 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
David,
TSC was used by default (according to unix support folks, since I don't have
access to configs on those machine), they switched it to use HPET and I got
the same result. Below is the sample code I used to test. On one machine I
see a constant drift of about 15 milliseconds regardless of how of long the
timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has 2 cpus. On
the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.

import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Timer;
import java.util.TimerTask;

public class TimerTest {

         public static void main(String[] args) {

               try {
                  long schedule=500;
                  if (args.length > 0)
                        schedule=Long.parseLong(args[0]);
                  System.out.println( " scheduling job\n");
                  Timer eodTimer = new Timer(true);
                  SimpleDateFormat simpleDateFormat = new
SimpleDateFormat("HH:mm:ss:S");
                  System.out.println(" Current time = " +
simpleDateFormat.format(Calendar.getInstance().getTime()));
                  eodTimer.scheduleAtFixedRate(new
TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule,
schedule);
                  Thread.sleep(Long.MAX_VALUE);
            } catch (Exception e) {
              System.out.println(e);
            }

      }

         private static class TestTask extends TimerTask {

          long startTime;
          long sch;
          SimpleDateFormat simpleDateFormat;
          TestTask (long startTime,long schedule, SimpleDateFormat
simpleDateFormat)
          {
            this.startTime=startTime;
            sch=schedule;
            this.simpleDateFormat = simpleDateFormat;
          }
            public void run() {
                  long now = System.currentTimeMillis();
                  System.out.println(" End time     = " +
simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
                  System.out.println(" Actual diff  = "+(now-startTime)+ "
milliseconds, expected diff = " + sch + " milliseconds");
                  System.exit(1);

            }
         }
}

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 5:21 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

So I take it that HPET is already being used.

The other possibility here is that it is not the timer that is drifting but
the time source that you are using to measure/track when the timer fires.
How are you tracking that?

David
-----Original Message-----
From: Navin Jha [mailto:navin.jha at FXALL.com]
Sent: Tuesday, 11 January 2011 8:11 AM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts
No luck L

Does having too many cpus effect this in anyway?

The machine on which a sample test code works only has 2 cpus while the
machine on which we see a huge drift has 8 cpus.

From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Monday, January 10, 2011 3:46 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Check what clocksource the problematic system is using. If it is TSC then
switch to HPET.

These things are difficult to diagnoze.

David Holmes
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
Sent: Tuesday, 11 January 2011 4:30 AM
To: Attila Szegedi
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts
>From what I have learned so far is that this is a common problem but the
drift is too much for us since it effects our trading date rollover J

David Holmes has nice blog on clocks
(http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks) and in his
blog he suggested to someone with a similar problem that he should post the
problem here.

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:24 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

I see - you weren't specific about which API call you use, so I wanted to
root out the rookie mistake :-) Hm. a drift should definitely not occur with
scheduleAtFixedRate, as far as I can tell. At this point, this indeed start
to sound as a topic relevant for this group :-) Although I can't you help
past this stage (not much Linux system expertise), I guess whoever wants to
look into this will want the JRE, Linux, and CPU versions of your system.

On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:

This is exactly what we use. A sample code we tried works fine of some linux
machines with a constant lag value (say 15 milliseconds) but fails on other
linux machines. We are trying to find if there is something about those
linux machines that causes this. The machines on which this is happening
ironically have much better hardware (high end multi-core linux servers).

From: Attila Szegedi [mailto:szegedia at gmail.com]
Sent: Monday, January 10, 2011 1:03 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Timer notification drifts

scheduleAtFixedRate should help:
<http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

Hi,

Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller
duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin




From mthornton at optrak.co.uk  Tue Jan 11 11:41:54 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Tue, 11 Jan 2011 16:41:54 +0000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAE4@NYEXCH02.fxall.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAD3@NYEXCH02.fxall.com>	<NFBBKALFDCPFIDBNKAPCAEJEIKAA.davidcholmes@aapt.net.au>
	<EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAE4@NYEXCH02.fxall.com>
Message-ID: <4D2C8852.9080102@optrak.co.uk>

On 11/01/2011 16:24, Navin Jha wrote:
> David,
>
> We don't see these files, is there another way to check this?
>
> OS details are:
> Linux numpintapp15 2.6.9-78.ELlargesmp #1 SMP Wed Jul 9 16:03:59 EDT 2008 x86_64 x86_64 x86_64 GNU/Linux-bash-3.00$ cat /etc/redhat-release
> Red Hat Enterprise Linux AS release 4 (Nahant Update 7)
>
> Here is the output of the command:
> [11:15:53][root:~]$ cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> cat: /sys/devices/system/clocksource/clocksource0/available_clocksource: No such file or directory

I think 2.6.9 is too old, clocksource appears to have been added around 
2.6.18 (latest is 2.6.37).

Mark


From davidcholmes at aapt.net.au  Tue Jan 11 18:03:35 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 12 Jan 2011 09:03:35 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAE4@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>

> We don't see these files, is there another way to check this?

As Mark says your kernel may be too old to expose these.

> Also this the log that might tell you more:
> [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> 12 CPUs: passed.

I'm very skeptical that an old kernel will be able to synchronize the TSC
across 12 cores. Linux abandoned use of the TSC as the primary timesource
for MP systems.

http://lwn.net/Articles/209101/

But maybe things have progressed since then. I know Solaris went to great
lengths to do the TSC synchronization, and while it seems reasonable today
there were a few bumps along the road.

> We've tried to specify the clocksource in the
> /boot/grub/grub.conf file.  We've been trying various
> clocksources. Would you let us know how to set the appropriate
> clocksource? Below is the grub.conf file.

I'm not a linux expert but it appears that clock=hpet as the appropriate
boot option should work. These log entries indicate tsc is used:

Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro root=LABEL=/
hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0

David
------

> [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> # grub.conf generated by anaconda
> #
> # Note that you do not have to rerun grub after making changes to
> this file
> # NOTICE:  You have a /boot partition.  This means that
> #          all kernel and initrd paths are relative to /boot/, eg.
> #          root (hd0,0)
> #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> #          initrd /initrd-version.img
> #boot=/dev/cciss/c0d0
> default=1
> timeout=5
> splashimage=(hd0,0)/grub/splash.xpm.gz
> hiddenmenu
> title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
>         root (hd0,0)
>         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> hda=ide-scsi clock=hpet clocksource=hpet
>         initrd /initrd-2.6.9-78.0.8.EL.img
> title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
>         root (hd0,0)
>         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
>         initrd /initrd-2.6.9-78.ELlargesmp.img
> title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
>         root (hd0,0)
>         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> clock=hpet clocksource=hpet
>         initrd /initrd-2.6.9-78.EL.img
>
>
>
>
> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 6:12 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> I believe you need root access to check the clocksource (unless default
> perms are modified):
>
> cat /sys/devices/system/clocksource/clocksource0/available_clocksource
>
> to see what's available, and
>
> cat /sys/devices/system/clocksource/clocksource0/current_clocksource
>
> to see what is in use.
>
> I was suggesting using nanoTime to measure the elapsed time, rather than
> date/currentTimeMillis, as nanoTime should not be affected by time-of-day
> adjustments. Which reminds me: check if ntp is running and if so turn it
> off, if not turn it on, and see if that makes a difference.
>
> David
>
> -----Original Message-----
> From: Navin Jha [mailto:navin.jha at FXALL.com]
> Sent: Tuesday, 11 January 2011 9:04 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
>
> David,
>
> I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
> results and they use nano time. Are you suggesting using nano time in any
> other way? I will try them again after the switch to HPET to see
> if there is
> any difference. I have communicated your concern  about the use of TSC on
> multi-processor systems to our unix support group.
>
> One more question, how do I make sure that the clock source is set up
> correctly to HPET? Since it was done by the support group  I want to make
> sure that they did it  correctly?
>
> -Navin
>
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 5:41 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> Try using System.nanoTime to track things.
>
> BTW unless you have CPUs with reliable TSC then you should never
> use TSC as
> the clocksource on multi-processor systems. There are some OS specific
> utilities from the chip vendors to fix TSC drift but I don't know what is
> available for Linux. It's been a little while since I checked on
> the current
> state of this.
>
> David
> -----Original Message-----
> From: Navin Jha [mailto:navin.jha at FXALL.com]
> Sent: Tuesday, 11 January 2011 8:33 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
> David,
> TSC was used by default (according to unix support folks, since I
> don't have
> access to configs on those machine), they switched it to use HPET
> and I got
> the same result. Below is the sample code I used to test. On one machine I
> see a constant drift of about 15 milliseconds regardless of how
> of long the
> timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> 2 cpus. On
> the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
>
> import java.text.SimpleDateFormat;
> import java.util.Calendar;
> import java.util.Timer;
> import java.util.TimerTask;
>
> public class TimerTest {
>
>          public static void main(String[] args) {
>
>                try {
>                   long schedule=500;
>                   if (args.length > 0)
>                         schedule=Long.parseLong(args[0]);
>                   System.out.println( " scheduling job\n");
>                   Timer eodTimer = new Timer(true);
>                   SimpleDateFormat simpleDateFormat = new
> SimpleDateFormat("HH:mm:ss:S");
>                   System.out.println(" Current time = " +
> simpleDateFormat.format(Calendar.getInstance().getTime()));
>                   eodTimer.scheduleAtFixedRate(new
> TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule,
> schedule);
>                   Thread.sleep(Long.MAX_VALUE);
>             } catch (Exception e) {
>               System.out.println(e);
>             }
>
>       }
>
>          private static class TestTask extends TimerTask {
>
>           long startTime;
>           long sch;
>           SimpleDateFormat simpleDateFormat;
>           TestTask (long startTime,long schedule, SimpleDateFormat
> simpleDateFormat)
>           {
>             this.startTime=startTime;
>             sch=schedule;
>             this.simpleDateFormat = simpleDateFormat;
>           }
>             public void run() {
>                   long now = System.currentTimeMillis();
>                   System.out.println(" End time     = " +
> simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
>                   System.out.println(" Actual diff  = "+(now-startTime)+ "
> milliseconds, expected diff = " + sch + " milliseconds");
>                   System.exit(1);
>
>             }
>          }
> }
>
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 5:21 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> So I take it that HPET is already being used.
>
> The other possibility here is that it is not the timer that is
> drifting but
> the time source that you are using to measure/track when the timer fires.
> How are you tracking that?
>
> David
> -----Original Message-----
> From: Navin Jha [mailto:navin.jha at FXALL.com]
> Sent: Tuesday, 11 January 2011 8:11 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
> No luck L
>
> Does having too many cpus effect this in anyway?
>
> The machine on which a sample test code works only has 2 cpus while the
> machine on which we see a huge drift has 8 cpus.
>
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 3:46 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> Check what clocksource the problematic system is using. If it is TSC then
> switch to HPET.
>
> These things are difficult to diagnoze.
>
> David Holmes
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
> Sent: Tuesday, 11 January 2011 4:30 AM
> To: Attila Szegedi
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
> From what I have learned so far is that this is a common problem but the
> drift is too much for us since it effects our trading date rollover J
>
> David Holmes has nice blog on clocks
> (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> and in his
> blog he suggested to someone with a similar problem that he
> should post the
> problem here.
>
> From: Attila Szegedi [mailto:szegedia at gmail.com]
> Sent: Monday, January 10, 2011 1:24 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
>
> I see - you weren't specific about which API call you use, so I wanted to
> root out the rookie mistake :-) Hm. a drift should definitely not
> occur with
> scheduleAtFixedRate, as far as I can tell. At this point, this
> indeed start
> to sound as a topic relevant for this group :-) Although I can't you help
> past this stage (not much Linux system expertise), I guess
> whoever wants to
> look into this will want the JRE, Linux, and CPU versions of your system.
>
> On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
>
> This is exactly what we use. A sample code we tried works fine of
> some linux
> machines with a constant lag value (say 15 milliseconds) but
> fails on other
> linux machines. We are trying to find if there is something about those
> linux machines that causes this. The machines on which this is happening
> ironically have much better hardware (high end multi-core linux servers).
>
> From: Attila Szegedi [mailto:szegedia at gmail.com]
> Sent: Monday, January 10, 2011 1:03 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
>
> scheduleAtFixedRate should help:
> <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

Hi,

Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller
duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin




From adrian.tarau at gmail.com  Fri Jan 14 11:16:43 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Fri, 14 Jan 2011 11:16:43 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3076EB.5080709@gmail.com>

Hi,

For a long time I wanted to ask this question but now it really burns 
me. This lock happens in JGroups but I know I've seen it before in my 
own code too.

This is how it is used in JGroups:
1. Locks creation
     /** Lock protecting sent credits table and some other vars 
(creditors for example) */
     private final Lock sent_lock=new ReentrantLock();

     /** Lock protecting received credits table */
     private final Lock received_lock=new ReentrantLock();


     /** Mutex to block on down() */
     private final Condition credits_available=sent_lock.newCondition();

2. Locks usage

                             long block_time=max_block_time;
                             if(max_block_times != null) {
                                 Long tmp=end_time.get();
                                 if(tmp != null) {
                                     // Negative value means we don't 
wait at all ! If the end_time already elapsed
                                     // (because we waited for other 
threads to get processed), the message will not
                                     // block at all and get sent 
immediately
                                     block_time=tmp - start_blocking;
                                 }
                             }

                             boolean 
rc=credits_available.await(block_time, TimeUnit.MILLISECONDS); <- here 
it locks



I do not understand why it locks...Other than this particular 
usage(JGroups), I've seen it before in ThreadPoolExecutor(locked in the 
blocking  queue used by the executor). Strange enough I think it happens 
when the JVM Heap runs out of memory or it is closed to run out of 
memory and GC kicks in and runs close to 80-90% CPU usage.

What does the "parking to wait for" mean?

Thanks.


"Channel default Messaging" - Thread t at 29
    java.lang.Thread.State: TIMED_WAITING
     at sun.misc.Unsafe.park(Native Method)
     - parking to wait for <189fc4d> (a 
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
     at 
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
     at 
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2054)
     at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
     at org.jgroups.protocols.FC.down(FC.java:423)
     at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
     at 
org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
     at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
     at org.jgroups.JChannel.down(JChannel.java:1623)
     at org.jgroups.JChannel.send(JChannel.java:724)
     at 
com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.java:316)
     at 
com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java:33)
     at 
com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(ChannelImpl.java:678)

    Locked ownable synchronizers:
     - None


On 01/11/2011 06:03 PM, David Holmes wrote:
>> We don't see these files, is there another way to check this?
> As Mark says your kernel may be too old to expose these.
>
>> Also this the log that might tell you more:
>> [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
>> Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
>> 12 CPUs: passed.
> I'm very skeptical that an old kernel will be able to synchronize the TSC
> across 12 cores. Linux abandoned use of the TSC as the primary timesource
> for MP systems.
>
> http://lwn.net/Articles/209101/
>
> But maybe things have progressed since then. I know Solaris went to great
> lengths to do the TSC synchronization, and while it seems reasonable today
> there were a few bumps along the road.
>
>> We've tried to specify the clocksource in the
>> /boot/grub/grub.conf file.  We've been trying various
>> clocksources. Would you let us know how to set the appropriate
>> clocksource? Below is the grub.conf file.
> I'm not a linux expert but it appears that clock=hpet as the appropriate
> boot option should work. These log entries indicate tsc is used:
>
> Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
> Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
>
> David
> ------
>
>> [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
>> # grub.conf generated by anaconda
>> #
>> # Note that you do not have to rerun grub after making changes to
>> this file
>> # NOTICE:  You have a /boot partition.  This means that
>> #          all kernel and initrd paths are relative to /boot/, eg.
>> #          root (hd0,0)
>> #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
>> #          initrd /initrd-version.img
>> #boot=/dev/cciss/c0d0
>> default=1
>> timeout=5
>> splashimage=(hd0,0)/grub/splash.xpm.gz
>> hiddenmenu
>> title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
>>          root (hd0,0)
>>          kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
>> hda=ide-scsi clock=hpet clocksource=hpet
>>          initrd /initrd-2.6.9-78.0.8.EL.img
>> title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
>>          root (hd0,0)
>>          kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
>> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
>>          initrd /initrd-2.6.9-78.ELlargesmp.img
>> title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
>>          root (hd0,0)
>>          kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
>> clock=hpet clocksource=hpet
>>          initrd /initrd-2.6.9-78.EL.img
>>
>>
>>
>>
>> -----Original Message-----
>> From: David Holmes [mailto:davidcholmes at aapt.net.au]
>> Sent: Monday, January 10, 2011 6:12 PM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>>
>> I believe you need root access to check the clocksource (unless default
>> perms are modified):
>>
>> cat /sys/devices/system/clocksource/clocksource0/available_clocksource
>>
>> to see what's available, and
>>
>> cat /sys/devices/system/clocksource/clocksource0/current_clocksource
>>
>> to see what is in use.
>>
>> I was suggesting using nanoTime to measure the elapsed time, rather than
>> date/currentTimeMillis, as nanoTime should not be affected by time-of-day
>> adjustments. Which reminds me: check if ntp is running and if so turn it
>> off, if not turn it on, and see if that makes a difference.
>>
>> David
>>
>> -----Original Message-----
>> From: Navin Jha [mailto:navin.jha at FXALL.com]
>> Sent: Tuesday, 11 January 2011 9:04 AM
>> To: dholmes at ieee.org
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>>
>>
>> David,
>>
>> I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
>> results and they use nano time. Are you suggesting using nano time in any
>> other way? I will try them again after the switch to HPET to see
>> if there is
>> any difference. I have communicated your concern  about the use of TSC on
>> multi-processor systems to our unix support group.
>>
>> One more question, how do I make sure that the clock source is set up
>> correctly to HPET? Since it was done by the support group  I want to make
>> sure that they did it  correctly?
>>
>> -Navin
>>
>> From: David Holmes [mailto:davidcholmes at aapt.net.au]
>> Sent: Monday, January 10, 2011 5:41 PM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>>
>> Try using System.nanoTime to track things.
>>
>> BTW unless you have CPUs with reliable TSC then you should never
>> use TSC as
>> the clocksource on multi-processor systems. There are some OS specific
>> utilities from the chip vendors to fix TSC drift but I don't know what is
>> available for Linux. It's been a little while since I checked on
>> the current
>> state of this.
>>
>> David
>> -----Original Message-----
>> From: Navin Jha [mailto:navin.jha at FXALL.com]
>> Sent: Tuesday, 11 January 2011 8:33 AM
>> To: dholmes at ieee.org
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>> David,
>> TSC was used by default (according to unix support folks, since I
>> don't have
>> access to configs on those machine), they switched it to use HPET
>> and I got
>> the same result. Below is the sample code I used to test. On one machine I
>> see a constant drift of about 15 milliseconds regardless of how
>> of long the
>> timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
>> 2 cpus. On
>> the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
>>
>> import java.text.SimpleDateFormat;
>> import java.util.Calendar;
>> import java.util.Timer;
>> import java.util.TimerTask;
>>
>> public class TimerTest {
>>
>>           public static void main(String[] args) {
>>
>>                 try {
>>                    long schedule=500;
>>                    if (args.length>  0)
>>                          schedule=Long.parseLong(args[0]);
>>                    System.out.println( " scheduling job\n");
>>                    Timer eodTimer = new Timer(true);
>>                    SimpleDateFormat simpleDateFormat = new
>> SimpleDateFormat("HH:mm:ss:S");
>>                    System.out.println(" Current time = " +
>> simpleDateFormat.format(Calendar.getInstance().getTime()));
>>                    eodTimer.scheduleAtFixedRate(new
>> TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule,
>> schedule);
>>                    Thread.sleep(Long.MAX_VALUE);
>>              } catch (Exception e) {
>>                System.out.println(e);
>>              }
>>
>>        }
>>
>>           private static class TestTask extends TimerTask {
>>
>>            long startTime;
>>            long sch;
>>            SimpleDateFormat simpleDateFormat;
>>            TestTask (long startTime,long schedule, SimpleDateFormat
>> simpleDateFormat)
>>            {
>>              this.startTime=startTime;
>>              sch=schedule;
>>              this.simpleDateFormat = simpleDateFormat;
>>            }
>>              public void run() {
>>                    long now = System.currentTimeMillis();
>>                    System.out.println(" End time     = " +
>> simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
>>                    System.out.println(" Actual diff  = "+(now-startTime)+ "
>> milliseconds, expected diff = " + sch + " milliseconds");
>>                    System.exit(1);
>>
>>              }
>>           }
>> }
>>
>> From: David Holmes [mailto:davidcholmes at aapt.net.au]
>> Sent: Monday, January 10, 2011 5:21 PM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>>
>> So I take it that HPET is already being used.
>>
>> The other possibility here is that it is not the timer that is
>> drifting but
>> the time source that you are using to measure/track when the timer fires.
>> How are you tracking that?
>>
>> David
>> -----Original Message-----
>> From: Navin Jha [mailto:navin.jha at FXALL.com]
>> Sent: Tuesday, 11 January 2011 8:11 AM
>> To: dholmes at ieee.org
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>> No luck L
>>
>> Does having too many cpus effect this in anyway?
>>
>> The machine on which a sample test code works only has 2 cpus while the
>> machine on which we see a huge drift has 8 cpus.
>>
>> From: David Holmes [mailto:davidcholmes at aapt.net.au]
>> Sent: Monday, January 10, 2011 3:46 PM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] Timer notification drifts
>>
>> Check what clocksource the problematic system is using. If it is TSC then
>> switch to HPET.
>>
>> These things are difficult to diagnoze.
>>
>> David Holmes
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
>> Sent: Tuesday, 11 January 2011 4:30 AM
>> To: Attila Szegedi
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Timer notification drifts
>>  From what I have learned so far is that this is a common problem but the
>> drift is too much for us since it effects our trading date rollover J
>>
>> David Holmes has nice blog on clocks
>> (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
>> and in his
>> blog he suggested to someone with a similar problem that he
>> should post the
>> problem here.
>>
>> From: Attila Szegedi [mailto:szegedia at gmail.com]
>> Sent: Monday, January 10, 2011 1:24 PM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Timer notification drifts
>>
>> I see - you weren't specific about which API call you use, so I wanted to
>> root out the rookie mistake :-) Hm. a drift should definitely not
>> occur with
>> scheduleAtFixedRate, as far as I can tell. At this point, this
>> indeed start
>> to sound as a topic relevant for this group :-) Although I can't you help
>> past this stage (not much Linux system expertise), I guess
>> whoever wants to
>> look into this will want the JRE, Linux, and CPU versions of your system.
>>
>> On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
>>
>> This is exactly what we use. A sample code we tried works fine of
>> some linux
>> machines with a constant lag value (say 15 milliseconds) but
>> fails on other
>> linux machines. We are trying to find if there is something about those
>> linux machines that causes this. The machines on which this is happening
>> ironically have much better hardware (high end multi-core linux servers).
>>
>> From: Attila Szegedi [mailto:szegedia at gmail.com]
>> Sent: Monday, January 10, 2011 1:03 PM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Timer notification drifts
>>
>> scheduleAtFixedRate should help:
>> <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
> html#sched
> uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
>
> On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
>
> Hi,
>
> Not sure if this is the right place to post this problem. We use
> java.util.Timer class for a notification that needs to happens every 24
> hours. We noticed that on some linux multi-core servers the notification
> occurs almost 11 seconds later. If we run for successive smaller durations
> say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
> 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
>
> The only solutions we can think of right now is to run the timer for smaller
> duration and restart it after that duration.
>
> Is there a solution/workaround for this problem?
>
> Regards,
> Navin
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From navin.jha at FXALL.com  Fri Jan 14 14:41:08 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Fri, 14 Jan 2011 14:41:08 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEAE4@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBB3@NYEXCH02.fxall.com>

David,

We upgraded one of our box to 5.4 linux as you suggested and that did it!

We did't even have to change any setting.

Thank you so much!

Regards,
Navin 


-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Tuesday, January 11, 2011 6:04 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

> We don't see these files, is there another way to check this?

As Mark says your kernel may be too old to expose these.

> Also this the log that might tell you more:
> [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> 12 CPUs: passed.

I'm very skeptical that an old kernel will be able to synchronize the TSC
across 12 cores. Linux abandoned use of the TSC as the primary timesource
for MP systems.

http://lwn.net/Articles/209101/

But maybe things have progressed since then. I know Solaris went to great
lengths to do the TSC synchronization, and while it seems reasonable today
there were a few bumps along the road.

> We've tried to specify the clocksource in the
> /boot/grub/grub.conf file.  We've been trying various
> clocksources. Would you let us know how to set the appropriate
> clocksource? Below is the grub.conf file.

I'm not a linux expert but it appears that clock=hpet as the appropriate
boot option should work. These log entries indicate tsc is used:

Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro root=LABEL=/
hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0

David
------

> [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> # grub.conf generated by anaconda
> #
> # Note that you do not have to rerun grub after making changes to
> this file
> # NOTICE:  You have a /boot partition.  This means that
> #          all kernel and initrd paths are relative to /boot/, eg.
> #          root (hd0,0)
> #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> #          initrd /initrd-version.img
> #boot=/dev/cciss/c0d0
> default=1
> timeout=5
> splashimage=(hd0,0)/grub/splash.xpm.gz
> hiddenmenu
> title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
>         root (hd0,0)
>         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> hda=ide-scsi clock=hpet clocksource=hpet
>         initrd /initrd-2.6.9-78.0.8.EL.img
> title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
>         root (hd0,0)
>         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
>         initrd /initrd-2.6.9-78.ELlargesmp.img
> title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
>         root (hd0,0)
>         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> clock=hpet clocksource=hpet
>         initrd /initrd-2.6.9-78.EL.img
>
>
>
>
> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 6:12 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> I believe you need root access to check the clocksource (unless default
> perms are modified):
>
> cat /sys/devices/system/clocksource/clocksource0/available_clocksource
>
> to see what's available, and
>
> cat /sys/devices/system/clocksource/clocksource0/current_clocksource
>
> to see what is in use.
>
> I was suggesting using nanoTime to measure the elapsed time, rather than
> date/currentTimeMillis, as nanoTime should not be affected by time-of-day
> adjustments. Which reminds me: check if ntp is running and if so turn it
> off, if not turn it on, and see if that makes a difference.
>
> David
>
> -----Original Message-----
> From: Navin Jha [mailto:navin.jha at FXALL.com]
> Sent: Tuesday, 11 January 2011 9:04 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
>
> David,
>
> I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
> results and they use nano time. Are you suggesting using nano time in any
> other way? I will try them again after the switch to HPET to see
> if there is
> any difference. I have communicated your concern  about the use of TSC on
> multi-processor systems to our unix support group.
>
> One more question, how do I make sure that the clock source is set up
> correctly to HPET? Since it was done by the support group  I want to make
> sure that they did it  correctly?
>
> -Navin
>
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 5:41 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> Try using System.nanoTime to track things.
>
> BTW unless you have CPUs with reliable TSC then you should never
> use TSC as
> the clocksource on multi-processor systems. There are some OS specific
> utilities from the chip vendors to fix TSC drift but I don't know what is
> available for Linux. It's been a little while since I checked on
> the current
> state of this.
>
> David
> -----Original Message-----
> From: Navin Jha [mailto:navin.jha at FXALL.com]
> Sent: Tuesday, 11 January 2011 8:33 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
> David,
> TSC was used by default (according to unix support folks, since I
> don't have
> access to configs on those machine), they switched it to use HPET
> and I got
> the same result. Below is the sample code I used to test. On one machine I
> see a constant drift of about 15 milliseconds regardless of how
> of long the
> timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> 2 cpus. On
> the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
>
> import java.text.SimpleDateFormat;
> import java.util.Calendar;
> import java.util.Timer;
> import java.util.TimerTask;
>
> public class TimerTest {
>
>          public static void main(String[] args) {
>
>                try {
>                   long schedule=500;
>                   if (args.length > 0)
>                         schedule=Long.parseLong(args[0]);
>                   System.out.println( " scheduling job\n");
>                   Timer eodTimer = new Timer(true);
>                   SimpleDateFormat simpleDateFormat = new
> SimpleDateFormat("HH:mm:ss:S");
>                   System.out.println(" Current time = " +
> simpleDateFormat.format(Calendar.getInstance().getTime()));
>                   eodTimer.scheduleAtFixedRate(new
> TestTask(System.currentTimeMillis(),schedule, simpleDateFormat), schedule,
> schedule);
>                   Thread.sleep(Long.MAX_VALUE);
>             } catch (Exception e) {
>               System.out.println(e);
>             }
>
>       }
>
>          private static class TestTask extends TimerTask {
>
>           long startTime;
>           long sch;
>           SimpleDateFormat simpleDateFormat;
>           TestTask (long startTime,long schedule, SimpleDateFormat
> simpleDateFormat)
>           {
>             this.startTime=startTime;
>             sch=schedule;
>             this.simpleDateFormat = simpleDateFormat;
>           }
>             public void run() {
>                   long now = System.currentTimeMillis();
>                   System.out.println(" End time     = " +
> simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
>                   System.out.println(" Actual diff  = "+(now-startTime)+ "
> milliseconds, expected diff = " + sch + " milliseconds");
>                   System.exit(1);
>
>             }
>          }
> }
>
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 5:21 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> So I take it that HPET is already being used.
>
> The other possibility here is that it is not the timer that is
> drifting but
> the time source that you are using to measure/track when the timer fires.
> How are you tracking that?
>
> David
> -----Original Message-----
> From: Navin Jha [mailto:navin.jha at FXALL.com]
> Sent: Tuesday, 11 January 2011 8:11 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
> No luck L
>
> Does having too many cpus effect this in anyway?
>
> The machine on which a sample test code works only has 2 cpus while the
> machine on which we see a huge drift has 8 cpus.
>
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 10, 2011 3:46 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> Check what clocksource the problematic system is using. If it is TSC then
> switch to HPET.
>
> These things are difficult to diagnoze.
>
> David Holmes
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Navin Jha
> Sent: Tuesday, 11 January 2011 4:30 AM
> To: Attila Szegedi
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
> From what I have learned so far is that this is a common problem but the
> drift is too much for us since it effects our trading date rollover J
>
> David Holmes has nice blog on clocks
> (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> and in his
> blog he suggested to someone with a similar problem that he
> should post the
> problem here.
>
> From: Attila Szegedi [mailto:szegedia at gmail.com]
> Sent: Monday, January 10, 2011 1:24 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
>
> I see - you weren't specific about which API call you use, so I wanted to
> root out the rookie mistake :-) Hm. a drift should definitely not
> occur with
> scheduleAtFixedRate, as far as I can tell. At this point, this
> indeed start
> to sound as a topic relevant for this group :-) Although I can't you help
> past this stage (not much Linux system expertise), I guess
> whoever wants to
> look into this will want the JRE, Linux, and CPU versions of your system.
>
> On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
>
> This is exactly what we use. A sample code we tried works fine of
> some linux
> machines with a constant lag value (say 15 milliseconds) but
> fails on other
> linux machines. We are trying to find if there is something about those
> linux machines that causes this. The machines on which this is happening
> ironically have much better hardware (high end multi-core linux servers).
>
> From: Attila Szegedi [mailto:szegedia at gmail.com]
> Sent: Monday, January 10, 2011 1:03 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Timer notification drifts
>
> scheduleAtFixedRate should help:
> <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
html#sched
uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>

On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:

Hi,

Not sure if this is the right place to post this problem. We use
java.util.Timer class for a notification that needs to happens every 24
hours. We noticed that on some linux multi-core servers the notification
occurs almost 11 seconds later. If we run for successive smaller durations
say 1 hour, 2 hours, 3 hours. we notice that the lag does accumulate. So for
1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..

The only solutions we can think of right now is to run the timer for smaller
duration and restart it after that duration.

Is there a solution/workaround for this problem?

Regards,
Navin





From davidcholmes at aapt.net.au  Sat Jan 15 01:48:52 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 15 Jan 2011 16:48:52 +1000
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D3076EB.5080709@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEKKIKAA.davidcholmes@aapt.net.au>

I'm not sure what your question is, other than:

>      - parking to wait for <189fc4d> (a
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)

means you've invoked await on the condition object.

So this thread is waiting for a notification that doesn't turn up it seems,
but there's very little to go on in what you wrote.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Adrian
> Tarau
> Sent: Saturday, 15 January 2011 2:17 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] "parking to wait for" hangs forever
>
>
> Hi,
>
> For a long time I wanted to ask this question but now it really burns
> me. This lock happens in JGroups but I know I've seen it before in my
> own code too.
>
> This is how it is used in JGroups:
> 1. Locks creation
>      /** Lock protecting sent credits table and some other vars
> (creditors for example) */
>      private final Lock sent_lock=new ReentrantLock();
>
>      /** Lock protecting received credits table */
>      private final Lock received_lock=new ReentrantLock();
>
>
>      /** Mutex to block on down() */
>      private final Condition credits_available=sent_lock.newCondition();
>
> 2. Locks usage
>
>                              long block_time=max_block_time;
>                              if(max_block_times != null) {
>                                  Long tmp=end_time.get();
>                                  if(tmp != null) {
>                                      // Negative value means we don't
> wait at all ! If the end_time already elapsed
>                                      // (because we waited for other
> threads to get processed), the message will not
>                                      // block at all and get sent
> immediately
>                                      block_time=tmp - start_blocking;
>                                  }
>                              }
>
>                              boolean
> rc=credits_available.await(block_time, TimeUnit.MILLISECONDS); <- here
> it locks
>
>
>
> I do not understand why it locks...Other than this particular
> usage(JGroups), I've seen it before in ThreadPoolExecutor(locked in the
> blocking  queue used by the executor). Strange enough I think it happens
> when the JVM Heap runs out of memory or it is closed to run out of
> memory and GC kicks in and runs close to 80-90% CPU usage.
>
> What does the "parking to wait for" mean?
>
> Thanks.
>
>
> "Channel default Messaging" - Thread t at 29
>     java.lang.Thread.State: TIMED_WAITING
>      at sun.misc.Unsafe.park(Native Method)
>      - parking to wait for <189fc4d> (a
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>      at
> java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>      at
> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObj
> ect.await(AbstractQueuedSynchronizer.java:2054)
>      at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
>      at org.jgroups.protocols.FC.down(FC.java:423)
>      at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
>      at
> org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
>      at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
>      at org.jgroups.JChannel.down(JChannel.java:1623)
>      at org.jgroups.JChannel.send(JChannel.java:724)
>      at
> com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(Cha
> nnelImpl.java:316)
>      at
> com.daxtechnologies.services.cluster.ChannelImpl.access$700(Channe
> lImpl.java:33)
>      at
> com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWork
> er.run(ChannelImpl.java:678)
>
>     Locked ownable synchronizers:
>      - None


From davidcholmes at aapt.net.au  Sat Jan 15 04:49:48 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 15 Jan 2011 19:49:48 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBB3@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKLIKAA.davidcholmes@aapt.net.au>

Navin Jha writes:
> We upgraded one of our box to 5.4 linux as you suggested and that did it!
>
> We did't even have to change any setting.

Out of interest what clocksource is the updated system using?

David


> Thank you so much!
>
> Regards,
> Navin
>
>
> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Tuesday, January 11, 2011 6:04 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> > We don't see these files, is there another way to check this?
>
> As Mark says your kernel may be too old to expose these.
>
> > Also this the log that might tell you more:
> > [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> > Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> > 12 CPUs: passed.
>
> I'm very skeptical that an old kernel will be able to synchronize the TSC
> across 12 cores. Linux abandoned use of the TSC as the primary timesource
> for MP systems.
>
> http://lwn.net/Articles/209101/
>
> But maybe things have progressed since then. I know Solaris went to great
> lengths to do the TSC synchronization, and while it seems reasonable today
> there were a few bumps along the road.
>
> > We've tried to specify the clocksource in the
> > /boot/grub/grub.conf file.  We've been trying various
> > clocksources. Would you let us know how to set the appropriate
> > clocksource? Below is the grub.conf file.
>
> I'm not a linux expert but it appears that clock=hpet as the appropriate
> boot option should work. These log entries indicate tsc is used:
>
> Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
> Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
>
> David
> ------
>
> > [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> > # grub.conf generated by anaconda
> > #
> > # Note that you do not have to rerun grub after making changes to
> > this file
> > # NOTICE:  You have a /boot partition.  This means that
> > #          all kernel and initrd paths are relative to /boot/, eg.
> > #          root (hd0,0)
> > #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> > #          initrd /initrd-version.img
> > #boot=/dev/cciss/c0d0
> > default=1
> > timeout=5
> > splashimage=(hd0,0)/grub/splash.xpm.gz
> > hiddenmenu
> > title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
> >         root (hd0,0)
> >         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> > hda=ide-scsi clock=hpet clocksource=hpet
> >         initrd /initrd-2.6.9-78.0.8.EL.img
> > title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
> >         root (hd0,0)
> >         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
> >         initrd /initrd-2.6.9-78.ELlargesmp.img
> > title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
> >         root (hd0,0)
> >         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> > clock=hpet clocksource=hpet
> >         initrd /initrd-2.6.9-78.EL.img
> >
> >
> >
> >
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 6:12 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > I believe you need root access to check the clocksource (unless default
> > perms are modified):
> >
> > cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> >
> > to see what's available, and
> >
> > cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> >
> > to see what is in use.
> >
> > I was suggesting using nanoTime to measure the elapsed time, rather than
> > date/currentTimeMillis, as nanoTime should not be affected by
> time-of-day
> > adjustments. Which reminds me: check if ntp is running and if so turn it
> > off, if not turn it on, and see if that makes a difference.
> >
> > David
> >
> > -----Original Message-----
> > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > Sent: Tuesday, 11 January 2011 9:04 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> >
> > David,
> >
> > I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
> > results and they use nano time. Are you suggesting using nano
> time in any
> > other way? I will try them again after the switch to HPET to see
> > if there is
> > any difference. I have communicated your concern  about the use
> of TSC on
> > multi-processor systems to our unix support group.
> >
> > One more question, how do I make sure that the clock source is set up
> > correctly to HPET? Since it was done by the support group  I
> want to make
> > sure that they did it  correctly?
> >
> > -Navin
> >
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 5:41 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > Try using System.nanoTime to track things.
> >
> > BTW unless you have CPUs with reliable TSC then you should never
> > use TSC as
> > the clocksource on multi-processor systems. There are some OS specific
> > utilities from the chip vendors to fix TSC drift but I don't
> know what is
> > available for Linux. It's been a little while since I checked on
> > the current
> > state of this.
> >
> > David
> > -----Original Message-----
> > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > Sent: Tuesday, 11 January 2011 8:33 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> > David,
> > TSC was used by default (according to unix support folks, since I
> > don't have
> > access to configs on those machine), they switched it to use HPET
> > and I got
> > the same result. Below is the sample code I used to test. On
> one machine I
> > see a constant drift of about 15 milliseconds regardless of how
> > of long the
> > timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> > 2 cpus. On
> > the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
> >
> > import java.text.SimpleDateFormat;
> > import java.util.Calendar;
> > import java.util.Timer;
> > import java.util.TimerTask;
> >
> > public class TimerTest {
> >
> >          public static void main(String[] args) {
> >
> >                try {
> >                   long schedule=500;
> >                   if (args.length > 0)
> >                         schedule=Long.parseLong(args[0]);
> >                   System.out.println( " scheduling job\n");
> >                   Timer eodTimer = new Timer(true);
> >                   SimpleDateFormat simpleDateFormat = new
> > SimpleDateFormat("HH:mm:ss:S");
> >                   System.out.println(" Current time = " +
> > simpleDateFormat.format(Calendar.getInstance().getTime()));
> >                   eodTimer.scheduleAtFixedRate(new
> > TestTask(System.currentTimeMillis(),schedule,
> simpleDateFormat), schedule,
> > schedule);
> >                   Thread.sleep(Long.MAX_VALUE);
> >             } catch (Exception e) {
> >               System.out.println(e);
> >             }
> >
> >       }
> >
> >          private static class TestTask extends TimerTask {
> >
> >           long startTime;
> >           long sch;
> >           SimpleDateFormat simpleDateFormat;
> >           TestTask (long startTime,long schedule, SimpleDateFormat
> > simpleDateFormat)
> >           {
> >             this.startTime=startTime;
> >             sch=schedule;
> >             this.simpleDateFormat = simpleDateFormat;
> >           }
> >             public void run() {
> >                   long now = System.currentTimeMillis();
> >                   System.out.println(" End time     = " +
> > simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
> >                   System.out.println(" Actual diff  =
> "+(now-startTime)+ "
> > milliseconds, expected diff = " + sch + " milliseconds");
> >                   System.exit(1);
> >
> >             }
> >          }
> > }
> >
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 5:21 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > So I take it that HPET is already being used.
> >
> > The other possibility here is that it is not the timer that is
> > drifting but
> > the time source that you are using to measure/track when the
> timer fires.
> > How are you tracking that?
> >
> > David
> > -----Original Message-----
> > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > Sent: Tuesday, 11 January 2011 8:11 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> > No luck L
> >
> > Does having too many cpus effect this in anyway?
> >
> > The machine on which a sample test code works only has 2 cpus while the
> > machine on which we see a huge drift has 8 cpus.
> >
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 3:46 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > Check what clocksource the problematic system is using. If it
> is TSC then
> > switch to HPET.
> >
> > These things are difficult to diagnoze.
> >
> > David Holmes
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> Navin Jha
> > Sent: Tuesday, 11 January 2011 4:30 AM
> > To: Attila Szegedi
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Timer notification drifts
> > From what I have learned so far is that this is a common problem but the
> > drift is too much for us since it effects our trading date rollover J
> >
> > David Holmes has nice blog on clocks
> > (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> > and in his
> > blog he suggested to someone with a similar problem that he
> > should post the
> > problem here.
> >
> > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > Sent: Monday, January 10, 2011 1:24 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Timer notification drifts
> >
> > I see - you weren't specific about which API call you use, so I
> wanted to
> > root out the rookie mistake :-) Hm. a drift should definitely not
> > occur with
> > scheduleAtFixedRate, as far as I can tell. At this point, this
> > indeed start
> > to sound as a topic relevant for this group :-) Although I
> can't you help
> > past this stage (not much Linux system expertise), I guess
> > whoever wants to
> > look into this will want the JRE, Linux, and CPU versions of
> your system.
> >
> > On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
> >
> > This is exactly what we use. A sample code we tried works fine of
> > some linux
> > machines with a constant lag value (say 15 milliseconds) but
> > fails on other
> > linux machines. We are trying to find if there is something about those
> > linux machines that causes this. The machines on which this is happening
> > ironically have much better hardware (high end multi-core linux
> servers).
> >
> > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > Sent: Monday, January 10, 2011 1:03 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Timer notification drifts
> >
> > scheduleAtFixedRate should help:
> > <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
> html#sched
> uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
>
> On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
>
> Hi,
>
> Not sure if this is the right place to post this problem. We use
> java.util.Timer class for a notification that needs to happens every 24
> hours. We noticed that on some linux multi-core servers the notification
> occurs almost 11 seconds later. If we run for successive smaller durations
> say 1 hour, 2 hours, 3 hours. we notice that the lag does
> accumulate. So for
> 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
>
> The only solutions we can think of right now is to run the timer
> for smaller
> duration and restart it after that duration.
>
> Is there a solution/workaround for this problem?
>
> Regards,
> Navin
>
>
>
>


From adrian.tarau at gmail.com  Sat Jan 15 10:21:37 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Sat, 15 Jan 2011 10:21:37 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEKKIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIEKKIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D31BB81.90404@gmail.com>

David,

Thanks for your answer. My question, to put it shortly, is why it locks 
indefinitely when await is called with a timout. Based on the API 
documentation "Causes the current thread to wait until it is signalled 
or interrupted, or the specified waiting time elapses".

Also I think it more then a coincidence that it happened every time when 
the JVM was closed to run OOM - no OOM exception in the logs but when I 
looked at the heap was full and GC was high on CPU.

I will post this issue on the JGroups dev mailing list but I would like 
to understand why a call to await(timout) blocks indefinitely? There is 
an undocumented behaviour(like in certain situations it still waits for 
a condition to happen even if we specified a timeout?) or do I 
misunderstand how await should work?.

Thanks for your time.

On 01/15/2011 01:48 AM, David Holmes wrote:
> I'm not sure what your question is, other than:
>
>>       - parking to wait for<189fc4d>  (a
>> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
> means you've invoked await on the condition object.
>
> So this thread is waiting for a notification that doesn't turn up it seems,
> but there's very little to go on in what you wrote.
>
> David Holmes
>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Adrian
>> Tarau
>> Sent: Saturday, 15 January 2011 2:17 AM
>> To: concurrency-interest at cs.oswego.edu
>> Subject: [concurrency-interest] "parking to wait for" hangs forever
>>
>>
>> Hi,
>>
>> For a long time I wanted to ask this question but now it really burns
>> me. This lock happens in JGroups but I know I've seen it before in my
>> own code too.
>>
>> This is how it is used in JGroups:
>> 1. Locks creation
>>       /** Lock protecting sent credits table and some other vars
>> (creditors for example) */
>>       private final Lock sent_lock=new ReentrantLock();
>>
>>       /** Lock protecting received credits table */
>>       private final Lock received_lock=new ReentrantLock();
>>
>>
>>       /** Mutex to block on down() */
>>       private final Condition credits_available=sent_lock.newCondition();
>>
>> 2. Locks usage
>>
>>                               long block_time=max_block_time;
>>                               if(max_block_times != null) {
>>                                   Long tmp=end_time.get();
>>                                   if(tmp != null) {
>>                                       // Negative value means we don't
>> wait at all ! If the end_time already elapsed
>>                                       // (because we waited for other
>> threads to get processed), the message will not
>>                                       // block at all and get sent
>> immediately
>>                                       block_time=tmp - start_blocking;
>>                                   }
>>                               }
>>
>>                               boolean
>> rc=credits_available.await(block_time, TimeUnit.MILLISECONDS);<- here
>> it locks
>>
>>
>>
>> I do not understand why it locks...Other than this particular
>> usage(JGroups), I've seen it before in ThreadPoolExecutor(locked in the
>> blocking  queue used by the executor). Strange enough I think it happens
>> when the JVM Heap runs out of memory or it is closed to run out of
>> memory and GC kicks in and runs close to 80-90% CPU usage.
>>
>> What does the "parking to wait for" mean?
>>
>> Thanks.
>>
>>
>> "Channel default Messaging" - Thread t at 29
>>      java.lang.Thread.State: TIMED_WAITING
>>       at sun.misc.Unsafe.park(Native Method)
>>       - parking to wait for<189fc4d>  (a
>> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>>       at
>> java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>>       at
>> java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObj
>> ect.await(AbstractQueuedSynchronizer.java:2054)
>>       at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
>>       at org.jgroups.protocols.FC.down(FC.java:423)
>>       at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
>>       at
>> org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
>>       at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
>>       at org.jgroups.JChannel.down(JChannel.java:1623)
>>       at org.jgroups.JChannel.send(JChannel.java:724)
>>       at
>> com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(Cha
>> nnelImpl.java:316)
>>       at
>> com.daxtechnologies.services.cluster.ChannelImpl.access$700(Channe
>> lImpl.java:33)
>>       at
>> com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWork
>> er.run(ChannelImpl.java:678)
>>
>>      Locked ownable synchronizers:
>>       - None


From dl at cs.oswego.edu  Sat Jan 15 10:39:45 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 15 Jan 2011 10:39:45 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D31BB81.90404@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIEKKIKAA.davidcholmes@aapt.net.au>
	<4D31BB81.90404@gmail.com>
Message-ID: <4D31BFC1.5050808@cs.oswego.edu>

On 01/15/11 10:21, Adrian Tarau wrote:
> Also I think it more then a coincidence that it happened every time when the JVM
> was closed to run OOM - no OOM exception in the logs but when I looked at the
> heap was full and GC was high on CPU.
>
> I will post this issue on the JGroups dev mailing list but I would like to
> understand why a call to await(timout) blocks indefinitely? There is an
> undocumented behaviour(like in certain situations it still waits for a condition
> to happen even if we specified a timeout?) or do I misunderstand how await
> should work?.

No, a timed wait should not block forever.

There have been some hotspot JVM lost wake-up JVM bugs, at least
one of which was associated with GC (although possibly only
using the "G1" collector). My best guess is that these are
fixed in current (b123+) versions of openJDK7 releases
(http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
I'm not sure when various fixes have or will be applied to
JDK6 updates. (This also appears to be related to the
FJ problems reported last week.) If I get more information,
I will relay.

-Doug



From adrian.tarau at gmail.com  Sat Jan 15 16:43:41 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Sat, 15 Jan 2011 16:43:41 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D31BFC1.5050808@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCIEKKIKAA.davidcholmes@aapt.net.au>	<4D31BB81.90404@gmail.com>
	<4D31BFC1.5050808@cs.oswego.edu>
Message-ID: <4D32150D.9000005@gmail.com>

We are using Linux boxes /Linux 2.6.18-194.el5 #1 SMP Mon Mar 29 
22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux /with Java 
1.6.0_20/(Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode)/)

We have ~ 140 (+several other processes) small Java processes running 
with 64M heap on 9 servers(pre-production) and 30 Java 
processes(+several other processes) running with 32M heap :) on 5 VM 
servers(development, don't remember the virtualization platform, 
something that is freely available in the CentOS repository).

These processes are called "collectors". We use Apache Commons VFS to 
connect to remote systems and JGroups to send collector activities to 
other processes(managers). Once in a blue moon, due to some bug in 
Apache Commons VFS or in code written by us around AC VFS(memory leaks) 
the heap is consumed up to 99% and GC(default GC, not G1) kicks in using 
~ 50%-60% CPU(as VisualVM reports) but it doesn't actually throw an OOM 
- somehow it manages to clean up enough memory to avoid an OOM(jumping 
from 1-2% CPU usage to 8%-9% CPU as reported by the OS).

When it reaches this state, the process runs very slow(due to intensive 
GC activity) and after a while it remains locked in a "parking to wait 
for ..." in JGroups

I will do an update to the latest JVM(update 23) on some machines and 
see how it goes. I found a bug 
(http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems similar with 
what we are experiencing but it was fixed in 1.6.0_18. Also this bugs 
http://bugs.sun.com/view_bug.do?bug_id=6807483 
(java.util.concurrent.locks.Condition.await(timeout, units) hangs 
forever) looks exactly like our issue but its state is "11-Closed, Not 
Reproducible".

Thanks.

On 01/15/2011 10:39 AM, Doug Lea wrote:
> On 01/15/11 10:21, Adrian Tarau wrote:
>> Also I think it more then a coincidence that it happened every time 
>> when the JVM
>> was closed to run OOM - no OOM exception in the logs but when I 
>> looked at the
>> heap was full and GC was high on CPU.
>>
>> I will post this issue on the JGroups dev mailing list but I would 
>> like to
>> understand why a call to await(timout) blocks indefinitely? There is an
>> undocumented behaviour(like in certain situations it still waits for 
>> a condition
>> to happen even if we specified a timeout?) or do I misunderstand how 
>> await
>> should work?.
>
> No, a timed wait should not block forever.
>
> There have been some hotspot JVM lost wake-up JVM bugs, at least
> one of which was associated with GC (although possibly only
> using the "G1" collector). My best guess is that these are
> fixed in current (b123+) versions of openJDK7 releases
> (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
> I'm not sure when various fixes have or will be applied to
> JDK6 updates. (This also appears to be related to the
> FJ problems reported last week.) If I get more information,
> I will relay.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110115/f7ffd87c/attachment.html>

From davidcholmes at aapt.net.au  Sat Jan 15 19:27:06 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 16 Jan 2011 10:27:06 +1000
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D32150D.9000005@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEKMIKAA.davidcholmes@aapt.net.au>

Adrian,

Thanks for the additional information - very helpful.

As Doug said a timed-await should not wait forever. 6807483 was a problem
encountered by one customer that did not reproduce anywhere else and which
disappeared when the customer upgraded to Solaris 10u7.

Can you attach gdb to the process to see what it reports in its stack trace?
It may be that this is a case where GC is going into overdrive and so the
system remains almost constantly at a safepoint and prevents any other
threads from progressing. At the native level we may see that the thread has
stopped waiting but has not been able to execute the code that would update
its state to reflect that.

Also can you try using an alternative GC? I know there are some situation
where CMS continually runs, managing to free up tiny amounts of space, not
enough for the requested allocation but enough to avoid deciding to throw
OutOfMemoryError.

Thanks,
David Holmes

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Adrian Tarau
Sent: Sunday, 16 January 2011 7:44 AM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] "parking to wait for" hangs forever


  We are using Linux boxes Linux 2.6.18-194.el5 #1 SMP Mon Mar 29 22:10:29
EDT 2010 x86_64 x86_64 x86_64 GNU/Linux  with Java 1.6.0_20 (Java(TM) SE
Runtime Environment (build 1.6.0_20-b02)
  Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode))

  We have ~ 140 (+several other processes) small Java processes running with
64M heap on 9 servers(pre-production) and 30 Java processes(+several other
processes) running with 32M heap :) on 5 VM servers(development, don't
remember the virtualization platform, something that is freely available in
the CentOS repository).

  These processes are called "collectors". We use Apache Commons VFS to
connect to remote systems and JGroups to send collector activities to other
processes(managers). Once in a blue moon, due to some bug in Apache Commons
VFS or in code written by us around AC VFS(memory leaks) the heap is
consumed up to 99% and GC(default GC, not G1) kicks in using ~ 50%-60%
CPU(as VisualVM reports) but it doesn't actually throw an OOM - somehow it
manages to clean up enough memory to avoid an OOM(jumping from 1-2% CPU
usage to 8%-9% CPU as reported by the OS).

  When it reaches this state, the process runs very slow(due to intensive GC
activity) and after a while it remains locked in a "parking to wait for ..."
in JGroups

  I will do an update to the latest JVM(update 23) on some machines and see
how it goes. I found a bug (http://bugs.sun.com/view_bug.do?bug_id=6822370)
that seems similar with what we are experiencing but it was fixed in
1.6.0_18. Also this bugs http://bugs.sun.com/view_bug.do?bug_id=6807483
(java.util.concurrent.locks.Condition.await(timeout, units) hangs forever)
looks exactly like our issue but its state is "11-Closed, Not Reproducible".

  Thanks.

  On 01/15/2011 10:39 AM, Doug Lea wrote:
    On 01/15/11 10:21, Adrian Tarau wrote:

      Also I think it more then a coincidence that it happened every time
when the JVM
      was closed to run OOM - no OOM exception in the logs but when I looked
at the
      heap was full and GC was high on CPU.

      I will post this issue on the JGroups dev mailing list but I would
like to
      understand why a call to await(timout) blocks indefinitely? There is
an
      undocumented behaviour(like in certain situations it still waits for a
condition
      to happen even if we specified a timeout?) or do I misunderstand how
await
      should work?.


    No, a timed wait should not block forever.

    There have been some hotspot JVM lost wake-up JVM bugs, at least
    one of which was associated with GC (although possibly only
    using the "G1" collector). My best guess is that these are
    fixed in current (b123+) versions of openJDK7 releases
    (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
    I'm not sure when various fixes have or will be applied to
    JDK6 updates. (This also appears to be related to the
    FJ problems reported last week.) If I get more information,
    I will relay.

    -Doug


    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110116/bcca5c87/attachment.html>

From adrian.tarau at gmail.com  Sat Jan 15 20:49:17 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Sat, 15 Jan 2011 20:49:17 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEKMIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEKMIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D324E9D.2090500@gmail.com>

David,

I'll try :) I'm not very familiar with gdb, is it enough to run the "bt" 
command?

I'm not very concerned with this kind of failure under these 
circumstances, at this point we can safely consider the process "dead" 
anyway. We are implementing a watchdog type functionality in our process 
manager so we would restart processes that looks dead - we do not 
receive "successful" reports or runs with heap less than 5%.

However, over the last 6-8 months(running on JVM versions from 1.6.0_18 
to 1.6.0_20) I've seen these issues even on processes without memory 
issues(at that time production quality was not a concern :) and I really 
thought it might be an issues in our software or third-party libraries). 
I do not care (too much) if these collectors could lock, a downtime of 5 
minutes would not be that bad, just a small delay in collecting 
data(users are not impacted directly) but if this happens in the 
application server that could be a problem :)

As I said, I will upgrade JVM on some machines and keep the current 
one(1.6.0_20) on the rest and we will see how it goes. If it happens 
again I will extract the stack trace of the process with gdb. Actually 
wouldn't be better to log the system calls with strace?

Thanks.


On 01/15/2011 07:27 PM, David Holmes wrote:
> Adrian,
> Thanks for the additional information - very helpful.
> As Doug said a timed-await should not wait forever. 6807483 was a 
> problem encountered by one customer that did not reproduce anywhere 
> else and which disappeared when the customer upgraded to Solaris 10u7.
> Can you attach gdb to the process to see what it reports in its stack 
> trace? It may be that this is a case where GC is going into overdrive 
> and so the system remains almost constantly at a safepoint and 
> prevents any other threads from progressing. At the native level we 
> may see that the thread has stopped waiting but has not been able to 
> execute the code that would update its state to reflect that.
> Also can you try using an alternative GC? I know there are some 
> situation where CMS continually runs, managing to free up tiny amounts 
> of space, not enough for the requested allocation but enough to avoid 
> deciding to throw OutOfMemoryError.
> Thanks,
> David Holmes
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of 
> *Adrian Tarau
> *Sent:* Sunday, 16 January 2011 7:44 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] "parking to wait for" hangs forever
>
>     We are using Linux boxes /Linux 2.6.18-194.el5 #1 SMP Mon Mar 29
>     22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux /with Java
>     1.6.0_20/(Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
>     Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode)/)
>
>     We have ~ 140 (+several other processes) small Java processes
>     running with 64M heap on 9 servers(pre-production) and 30 Java
>     processes(+several other processes) running with 32M heap :) on 5
>     VM servers(development, don't remember the virtualization
>     platform, something that is freely available in the CentOS
>     repository).
>
>     These processes are called "collectors". We use Apache Commons VFS
>     to connect to remote systems and JGroups to send collector
>     activities to other processes(managers). Once in a blue moon, due
>     to some bug in Apache Commons VFS or in code written by us around
>     AC VFS(memory leaks) the heap is consumed up to 99% and GC(default
>     GC, not G1) kicks in using ~ 50%-60% CPU(as VisualVM reports) but
>     it doesn't actually throw an OOM - somehow it manages to clean up
>     enough memory to avoid an OOM(jumping from 1-2% CPU usage to 8%-9%
>     CPU as reported by the OS).
>
>     When it reaches this state, the process runs very slow(due to
>     intensive GC activity) and after a while it remains locked in a
>     "parking to wait for ..." in JGroups
>
>     I will do an update to the latest JVM(update 23) on some machines
>     and see how it goes. I found a bug
>     (http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems
>     similar with what we are experiencing but it was fixed in
>     1.6.0_18. Also this bugs
>     http://bugs.sun.com/view_bug.do?bug_id=6807483
>     (java.util.concurrent.locks.Condition.await(timeout, units) hangs
>     forever) looks exactly like our issue but its state is "11-Closed,
>     Not Reproducible".
>
>     Thanks.
>
>     On 01/15/2011 10:39 AM, Doug Lea wrote:
>>     On 01/15/11 10:21, Adrian Tarau wrote:
>>>     Also I think it more then a coincidence that it happened every
>>>     time when the JVM
>>>     was closed to run OOM - no OOM exception in the logs but when I
>>>     looked at the
>>>     heap was full and GC was high on CPU.
>>>
>>>     I will post this issue on the JGroups dev mailing list but I
>>>     would like to
>>>     understand why a call to await(timout) blocks indefinitely?
>>>     There is an
>>>     undocumented behaviour(like in certain situations it still waits
>>>     for a condition
>>>     to happen even if we specified a timeout?) or do I misunderstand
>>>     how await
>>>     should work?.
>>
>>     No, a timed wait should not block forever.
>>
>>     There have been some hotspot JVM lost wake-up JVM bugs, at least
>>     one of which was associated with GC (although possibly only
>>     using the "G1" collector). My best guess is that these are
>>     fixed in current (b123+) versions of openJDK7 releases
>>     (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
>>     I'm not sure when various fixes have or will be applied to
>>     JDK6 updates. (This also appears to be related to the
>>     FJ problems reported last week.) If I get more information,
>>     I will relay.
>>
>>     -Doug
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110115/c0139e79/attachment-0001.html>

From bryan at systap.com  Sun Jan 16 14:14:51 2011
From: bryan at systap.com (Bryan Thompson)
Date: Sun, 16 Jan 2011 13:14:51 -0600
Subject: [concurrency-interest] Spacing out a workload burst?
Message-ID: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>

Hello,

I was hoping that someone could point me to either some literature, s/w or patterns which we could use to space out a sudden workload burst.  This shows up in a benchmark where a number of client threads all start pounding on the service at once.  Watching the clients returning, it is pretty clear that the requests tend to take around the same amount of time and that requests complete and new requests are issued more or less in batch bursts as a result.  It seems to me that we might have better overall throughput if we could space out a burst of requests so the resource utilization has an opportunity to become more uniform.

Thanks in advance,
Bryan

From joe.bowbeer at gmail.com  Sun Jan 16 14:37:53 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 16 Jan 2011 11:37:53 -0800
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>
Message-ID: <AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>

Can I assume you've read Chapter 8, Applying Thread Pools in Java
Concurrency in Practice?

Here's an earlier take on the same material:

http://www.ibm.com/developerworks/library/j-jtp0730.html

Off hand, I'd recommend using a thread pool backed by a queue.  The queue's
job is to space-out the bursts.

If you need more throttling, you can use a bounded queue and a saturation
policy such as CallerRunsPolicy.

Joe

On Sun, Jan 16, 2011 at 11:14 AM, Bryan Thompson wrote:

> Hello,
>
> I was hoping that someone could point me to either some literature, s/w or
> patterns which we could use to space out a sudden workload burst.  This
> shows up in a benchmark where a number of client threads all start pounding
> on the service at once.  Watching the clients returning, it is pretty clear
> that the requests tend to take around the same amount of time and that
> requests complete and new requests are issued more or less in batch bursts
> as a result.  It seems to me that we might have better overall throughput if
> we could space out a burst of requests so the resource utilization has an
> opportunity to become more uniform.
>
> Thanks in advance,
> Bryan
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110116/3ff21e30/attachment.html>

From bryan at systap.com  Sun Jan 16 17:22:18 2011
From: bryan at systap.com (Bryan Thompson)
Date: Sun, 16 Jan 2011 16:22:18 -0600
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>,
	<AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
Message-ID: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>

Joe,

I am using a fixed size thread pool backed by a queue.  What I am looking to do is space out the onset of the task processing on the service in order to avoid having them all spike the resource demand at nearly the same moment.  Essentially, even though the original set of requests appears in a burst and each set of satisfied requests brings on another burst, I would like the service to stagger out the requests so they begin to appear at times predicted by a uniform distribution rather than centered around a periodic task arrival spike.

Thanks,
Bryan
________________________________________
From: concurrency-interest-bounces at cs.oswego.edu [concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joe Bowbeer [joe.bowbeer at gmail.com]
Sent: Sunday, January 16, 2011 2:37 PM
To: concurrency-interest
Subject: Re: [concurrency-interest] Spacing out a workload burst?

Can I assume you've read Chapter 8, Applying Thread Pools in Java Concurrency in Practice?

Here's an earlier take on the same material:

http://www.ibm.com/developerworks/library/j-jtp0730.html

Off hand, I'd recommend using a thread pool backed by a queue.  The queue's job is to space-out the bursts.

If you need more throttling, you can use a bounded queue and a saturation policy such as CallerRunsPolicy.

Joe

On Sun, Jan 16, 2011 at 11:14 AM, Bryan Thompson wrote:
Hello,

I was hoping that someone could point me to either some literature, s/w or patterns which we could use to space out a sudden workload burst.  This shows up in a benchmark where a number of client threads all start pounding on the service at once.  Watching the clients returning, it is pretty clear that the requests tend to take around the same amount of time and that requests complete and new requests are issued more or less in batch bursts as a result.  It seems to me that we might have better overall throughput if we could space out a burst of requests so the resource utilization has an opportunity to become more uniform.

Thanks in advance,
Bryan


From joe.bowbeer at gmail.com  Mon Jan 17 10:44:40 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 17 Jan 2011 07:44:40 -0800
Subject: [concurrency-interest] Data structure concurrency question
In-Reply-To: <E49F4E6D734B954487B074B4EFE60D010F2914@fssbemail.fss.india>
References: <Acus39LeAN41mO/5RpWAo5fvMyB6+A==>
	<E49F4E6D734B954487B074B4EFE60D010F2914@fssbemail.fss.india>
Message-ID: <AANLkTi=DLiNQTKj-69gWOhvJfYsMeLktWcBxBTH9=oF9@mail.gmail.com>

You can use a ConcurrentMap implementation (such as ConcurrentHashMap) to
map Loggers to their Name

http://download.oracle.com/javase/6/docs/api/java/util/concurrent/ConcurrentMap.html

On Wed, Jan 5, 2011 at 5:52 AM, Mohan Radhakrishnan wrote:

>  Hi,
>
>      Ascii representation of UML multiplicity :
>
>
>
> Logger Name 1---------* Logger 1----------1 Levels
>
>
>
>
>
> I have a requirement to associate one logger name with multiple Loggers
> each of which is in turn associated with a single level. What is a
> concurrent data structure recommendation for this ?
>
>
>
>       It is basically a map of maps. The accesses are not going to be
> highly concurrent but the log messages should not be interleaved.
>
>
>
>
>
> Thanks,
>
> Mohan
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110117/ab61ea5d/attachment.html>

From gregg at wonderly.org  Mon Jan 17 11:15:49 2011
From: gregg at wonderly.org (Gregg Wonderly)
Date: Mon, 17 Jan 2011 10:15:49 -0600
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D3076EB.5080709@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>
	<4D3076EB.5080709@gmail.com>
Message-ID: <4D346B35.7030809@wonderly.org>

On 1/14/2011 10:16 AM, Adrian Tarau wrote:
> boolean rc=credits_available.await(block_time, TimeUnit.MILLISECONDS); <- here
> it locks

This can almost always be traced to block_time becoming 0.  I find it always 
better to be defensive here and do something like the following.

boolean rc=credits_available.await(
	 Math.max( _MIN_WAIT_INTERVAL, block_time), TimeUnit.MILLISECONDS );

_MIN_WAIT_INTERVAL would be set to something that was the minimum about of time 
that made sense to wait.  Perhaps 1, but probably something more like 10.

Moving to MICROSECONDS might also be needed if 1ms is too long.

Gregg Wonderly

From gregg at wonderly.org  Mon Jan 17 11:15:59 2011
From: gregg at wonderly.org (Gregg Wonderly)
Date: Mon, 17 Jan 2011 10:15:59 -0600
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>,
	<AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
	<DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>
Message-ID: <4D346B3F.102@wonderly.org>

On 1/16/2011 4:22 PM, Bryan Thompson wrote:
> Joe,
>
> I am using a fixed size thread pool backed by a queue.  What I am looking
> to do is space out the onset of the task processing on the service in order
> to avoid having them all spike the resource demand at nearly the same moment.
> Essentially, even though the original set of requests appears in a burst
> and each set of satisfied requests brings on another burst, I would like
> the service to stagger out the requests so they begin to appear at times
> predicted by a uniform distribution rather than centered around a periodic
> task arrival spike.

The basic issue, is that in any system, the slowest point through the system 
will provide the highest contention and cause the most number of entities to 
gather there.  The simple math is that you can add all of the times of each 
phase of processing, and then use that as the denominator of a fraction with the 
time of each segment as the numerator.  That will tell you the fraction of the 
total that will be grouped at each phase.  You can then use this to create 
measurement values that you can use to check that the system is maintaining your 
expected latency/throughput.

You can do something with "delays" to try and space things out more, but the 
faster phases will still allow requests to come back around to the slower phases 
fast enough that you can't "change" the system behavior measurably.  You will 
just cause the appropriate number of tasks to group at the delay point.

If I have phases with execution time unit values such as the following:

2 5 2 8 20 2 5

then the total time through is 44 time units.  20/44 of the total participants 
will be at the phase that takes 20 time units on the average, in a continuous 
system.

If you have 20 tasks, and only 10 will fit through the system at any time, then 
you can use throttling such as you say you are using to control how many are 
running at any time.  But, then you've changed the picture to be

2 5 2 8 20*(n/10) 20 2 5

where n is the number of participants, because as soon as there are more than 10 
participants, then the extra tasks, will have to wait (20 * (n/10)) time units 
for someone to get through the phase that takes 20 time units, and then they 
will take another 20 time units to get through that point.

Horizontal scaling at the slowest phase is what becomes necessary, or a 
reduction of the latency through that point by algorithmic or other related changes.

Where ever you put the delay, you will paint a picture like this.  It can help 
the overall throughput to do this because of contention reduction on 
non-scalable resources.  But, you just have to figure out what the right choice 
is before you really go to horizontal scaling of the work load.

Gregg Wonderly

> Thanks,
> Bryan
> ________________________________________
> From: concurrency-interest-bounces at cs.oswego.edu [concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joe Bowbeer [joe.bowbeer at gmail.com]
> Sent: Sunday, January 16, 2011 2:37 PM
> To: concurrency-interest
> Subject: Re: [concurrency-interest] Spacing out a workload burst?
>
> Can I assume you've read Chapter 8, Applying Thread Pools in Java Concurrency in Practice?
>
> Here's an earlier take on the same material:
>
> http://www.ibm.com/developerworks/library/j-jtp0730.html
>
> Off hand, I'd recommend using a thread pool backed by a queue.  The queue's job is to space-out the bursts.
>
> If you need more throttling, you can use a bounded queue and a saturation policy such as CallerRunsPolicy.
>
> Joe
>
> On Sun, Jan 16, 2011 at 11:14 AM, Bryan Thompson wrote:
> Hello,
>
> I was hoping that someone could point me to either some literature, s/w or patterns which we could use to space out a sudden workload burst.  This shows up in a benchmark where a number of client threads all start pounding on the service at once.  Watching the clients returning, it is pretty clear that the requests tend to take around the same amount of time and that requests complete and new requests are issued more or less in batch bursts as a result.  It seems to me that we might have better overall throughput if we could space out a burst of requests so the resource utilization has an opportunity to become more uniform.
>
> Thanks in advance,
> Bryan
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From mthornton at optrak.co.uk  Mon Jan 17 11:29:23 2011
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Mon, 17 Jan 2011 16:29:23 +0000
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D346B35.7030809@wonderly.org>
References: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>	<4D3076EB.5080709@gmail.com>
	<4D346B35.7030809@wonderly.org>
Message-ID: <4D346E63.4010906@optrak.co.uk>

On 17/01/2011 16:15, Gregg Wonderly wrote:
> On 1/14/2011 10:16 AM, Adrian Tarau wrote:
>> boolean rc=credits_available.await(block_time,
>> TimeUnit.MILLISECONDS); <- here
>> it locks
>
> This can almost always be traced to block_time becoming 0.  I find it
> always better to be defensive here and do

CyclicBarrier.await(long timeout, TimeUnit unit) is documented as not 
waiting at all if timeout is <= 0.
On the other hand Future.get(long timeout, TimeUnit unit) doesn't 
document what happens if timeout is not positive. Finally Object.wait(0) 
is documented as waiting forever.

A rather unsatisfactory variety of behaviour for similar methods.

Mark Thornton


From belaban at yahoo.com  Mon Jan 17 11:38:03 2011
From: belaban at yahoo.com (Bela Ban)
Date: Mon, 17 Jan 2011 17:38:03 +0100
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D346B35.7030809@wonderly.org>
References: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>	<4D3076EB.5080709@gmail.com>
	<4D346B35.7030809@wonderly.org>
Message-ID: <4D34706B.4090003@yahoo.com>



On 1/17/11 5:15 PM, Gregg Wonderly wrote:
> On 1/14/2011 10:16 AM, Adrian Tarau wrote:
>> boolean rc=credits_available.await(block_time, TimeUnit.MILLISECONDS);
>> <- here
>> it locks
>
> This can almost always be traced to block_time becoming 0.


The block_time is static (5000) and is never changed...

I actually ran a small test:

Lock lock=new ReentrantTest();
Condition cond=lock.newCondition();
lock.lock();
boolean rc=cond.await(0, TimeUnit.MILLISECONDS);
lock.unlock();


, which does NOT block on a timeout of 0. The javadoc of 
Condition.await(long, TimeUnit) doesn't say that 0 is not permitted.

-- 
Bela Ban
Lead JGroups / Clustering Team
JBoss

From dl at cs.oswego.edu  Mon Jan 17 11:37:49 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 17 Jan 2011 11:37:49 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D346E63.4010906@optrak.co.uk>
References: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>	<4D3076EB.5080709@gmail.com>	<4D346B35.7030809@wonderly.org>
	<4D346E63.4010906@optrak.co.uk>
Message-ID: <4D34705D.9000407@cs.oswego.edu>

On 01/17/11 11:29, Mark Thornton wrote:
> On 17/01/2011 16:15, Gregg Wonderly wrote:
>> On 1/14/2011 10:16 AM, Adrian Tarau wrote:
>>> boolean rc=credits_available.await(block_time,
>>> TimeUnit.MILLISECONDS); <- here
>>> it locks
>>
>> This can almost always be traced to block_time becoming 0.

This cannot be possible for any java.util.concurrent.* method.
As documented many places (including the java.util.concurrent package
docs):
"All methods that accept timeout parameters treat values less than or equal to 
zero to mean not to wait at all."

But apparently still not enough places...

> On the other hand Future.get(long timeout, TimeUnit unit) doesn't document what
> happens if timeout is not positive.

Well, it does have the param javadoc:
   timeout - the maximum time to wait

-Doug

From adrian.tarau at gmail.com  Mon Jan 17 11:38:23 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Mon, 17 Jan 2011 11:38:23 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D346B35.7030809@wonderly.org>
References: <NFBBKALFDCPFIDBNKAPCCEJKIKAA.davidcholmes@aapt.net.au>
	<4D3076EB.5080709@gmail.com> <4D346B35.7030809@wonderly.org>
Message-ID: <4D34707F.7010009@gmail.com>

Condition.await doesn't specify but it doesn't wait if time <= 0. This 
test unit stops as soon as it started...

    @Test
     public void testLocking() throws Exception {

         /** Lock protecting sent credits table and some other vars 
(creditors for example) */
         Lock sent_lock = new ReentrantLock();

         /** Mutex to block on down() */
         Condition credits_available = sent_lock.newCondition();

         boolean rc;

         sent_lock.lock();
         try {

             //rc=credits_available.await(1000, TimeUnit.MILLISECONDS);
             rc=credits_available.await(0, TimeUnit.MILLISECONDS);

             //rc=credits_available.await(-1000, TimeUnit.MILLISECONDS);
         } finally {
             sent_lock.unlock();
         }
     }

On 01/17/2011 11:15 AM, Gregg Wonderly wrote:
> On 1/14/2011 10:16 AM, Adrian Tarau wrote:
>> boolean rc=credits_available.await(block_time, 
>> TimeUnit.MILLISECONDS); <- here
>> it locks
>
> This can almost always be traced to block_time becoming 0.  I find it 
> always better to be defensive here and do something like the following.
>
> boolean rc=credits_available.await(
>      Math.max( _MIN_WAIT_INTERVAL, block_time), TimeUnit.MILLISECONDS );
>
> _MIN_WAIT_INTERVAL would be set to something that was the minimum 
> about of time that made sense to wait.  Perhaps 1, but probably 
> something more like 10.
>
> Moving to MICROSECONDS might also be needed if 1ms is too long.
>
> Gregg Wonderly


From adrian.tarau at gmail.com  Mon Jan 17 13:55:02 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Mon, 17 Jan 2011 13:55:02 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEKMIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEKMIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D349086.1070409@gmail.com>


David,

I just have one process with 2 threads waiting in await(xxx). How do I 
actually use gdb to extract the stack trace? t at 67 I know for sure(99.9% 
sure :) ) it is locked because I cannot send any message, not sure the 
RMI thread....Successive dumps of the stack trace shows both threads in 
the same state, several times.

Thanks.

/"Channel default Messaging" - Thread t at 67
    java.lang.Thread.State: TIMED_WAITING
     at sun.misc.Unsafe.park(Native Method)
     - parking to wait for <664425> (a 
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
     at 
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
     at 
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2054)
     at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
     at org.jgroups.protocols.FC.down(FC.java:423)
     at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
     at 
org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
     at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
     at org.jgroups.JChannel.down(JChannel.java:1623)
     at org.jgroups.JChannel.send(JChannel.java:724)
     at 
com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.java:321)
     at 
com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java:33)
     at 
com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(ChannelImpl.java:683)

    Locked ownable synchronizers:
     - None

"RMI Scheduler(0)" - Thread t at 66
    java.lang.Thread.State: TIMED_WAITING
     at sun.misc.Unsafe.park(Native Method)
     - parking to wait for <40159> (a 
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
     at 
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
     at 
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
     at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
     at 
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:583)
     at 
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:576)
     at 
java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
     at 
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
     at java.lang.Thread.run(Thread.java:619)

    Locked ownable synchronizers:
     - None

On 01/15/2011 07:27 PM, David Hol/mes wrote:
> Adrian,
> Thanks for the additional information - very helpful.
> As Doug said a timed-await should not wait forever. 6807483 was a 
> problem encountered by one customer that did not reproduce anywhere 
> else and which disappeared when the customer upgraded to Solaris 10u7.
> Can you attach gdb to the process to see what it reports in its stack 
> trace? It may be that this is a case where GC is going into overdrive 
> and so the system remains almost constantly at a safepoint and 
> prevents any other threads from progressing. At the native level we 
> may see that the thread has stopped waiting but has not been able to 
> execute the code that would update its state to reflect that.
> Also can you try using an alternative GC? I know there are some 
> situation where CMS continually runs, managing to free up tiny amounts 
> of space, not enough for the requested allocation but enough to avoid 
> deciding to throw OutOfMemoryError.
> Thanks,
> David Holmes
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of 
> *Adrian Tarau
> *Sent:* Sunday, 16 January 2011 7:44 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] "parking to wait for" hangs forever
>
>     We are using Linux boxes /Linux 2.6.18-194.el5 #1 SMP Mon Mar 29
>     22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux /with Java
>     1.6.0_20/(Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
>     Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode)/)
>
>     We have ~ 140 (+several other processes) small Java processes
>     running with 64M heap on 9 servers(pre-production) and 30 Java
>     processes(+several other processes) running with 32M heap :) on 5
>     VM servers(development, don't remember the virtualization
>     platform, something that is freely available in the CentOS
>     repository).
>
>     These processes are called "collectors". We use Apache Commons VFS
>     to connect to remote systems and JGroups to send collector
>     activities to other processes(managers). Once in a blue moon, due
>     to some bug in Apache Commons VFS or in code written by us around
>     AC VFS(memory leaks) the heap is consumed up to 99% and GC(default
>     GC, not G1) kicks in using ~ 50%-60% CPU(as VisualVM reports) but
>     it doesn't actually throw an OOM - somehow it manages to clean up
>     enough memory to avoid an OOM(jumping from 1-2% CPU usage to 8%-9%
>     CPU as reported by the OS).
>
>     When it reaches this state, the process runs very slow(due to
>     intensive GC activity) and after a while it remains locked in a
>     "parking to wait for ..." in JGroups
>
>     I will do an update to the latest JVM(update 23) on some machines
>     and see how it goes. I found a bug
>     (http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems
>     similar with what we are experiencing but it was fixed in
>     1.6.0_18. Also this bugs
>     http://bugs.sun.com/view_bug.do?bug_id=6807483
>     (java.util.concurrent.locks.Condition.await(timeout, units) hangs
>     forever) looks exactly like our issue but its state is "11-Closed,
>     Not Reproducible".
>
>     Thanks.
>
>     On 01/15/2011 10:39 AM, Doug Lea wrote:
>>     On 01/15/11 10:21, Adrian Tarau wrote:
>>>     Also I think it more then a coincidence that it happened every
>>>     time when the JVM
>>>     was closed to run OOM - no OOM exception in the logs but when I
>>>     looked at the
>>>     heap was full and GC was high on CPU.
>>>
>>>     I will post this issue on the JGroups dev mailing list but I
>>>     would like to
>>>     understand why a call to await(timout) blocks indefinitely?
>>>     There is an
>>>     undocumented behaviour(like in certain situations it still waits
>>>     for a condition
>>>     to happen even if we specified a timeout?) or do I misunderstand
>>>     how await
>>>     should work?.
>>
>>     No, a timed wait should not block forever.
>>
>>     There have been some hotspot JVM lost wake-up JVM bugs, at least
>>     one of which was associated with GC (although possibly only
>>     using the "G1" collector). My best guess is that these are
>>     fixed in current (b123+) versions of openJDK7 releases
>>     (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
>>     I'm not sure when various fixes have or will be applied to
>>     JDK6 updates. (This also appears to be related to the
>>     FJ problems reported last week.) If I get more information,
>>     I will relay.
>>
>>     -Doug
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110117/85d55c5f/attachment.html>

From davidcholmes at aapt.net.au  Mon Jan 17 17:14:53 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 18 Jan 2011 08:14:53 +1000
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D349086.1070409@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMELEIKAA.davidcholmes@aapt.net.au>

Adrian,

You can attach gdb to the process:

gdb <path to java> <pid>

then use:

thread apply all bt

(bt is short for backtrace) to get all the thread stacks

See:

http://wiki.debian.org/HowToGetABacktrace
http://sourceware.org/gdb/current/onlinedocs/gdb/Backtrace.html

David
  -----Original Message-----
  From: Adrian Tarau [mailto:adrian.tarau at gmail.com]
  Sent: Tuesday, 18 January 2011 4:55 AM
  To: dholmes at ieee.org
  Cc: David Holmes; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] "parking to wait for" hangs forever



  David,

  I just have one process with 2 threads waiting in await(xxx). How do I
actually use gdb to extract the stack trace? t at 67 I know for sure(99.9% sure
:) ) it is locked because I cannot send any message, not sure the RMI
thread....Successive dumps of the stack trace shows both threads in the same
state, several times.

  Thanks.

  "Channel default Messaging" - Thread t at 67
     java.lang.Thread.State: TIMED_WAITING
      at sun.misc.Unsafe.park(Native Method)
      - parking to wait for <664425> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
      at
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
      at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(
AbstractQueuedSynchronizer.java:2054)
      at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
      at org.jgroups.protocols.FC.down(FC.java:423)
      at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
      at
org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
      at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
      at org.jgroups.JChannel.down(JChannel.java:1623)
      at org.jgroups.JChannel.send(JChannel.java:724)
      at
com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.j
ava:321)
      at
com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java
:33)
      at
com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(Cha
nnelImpl.java:683)

     Locked ownable synchronizers:
      - None

  "RMI Scheduler(0)" - Thread t at 66
     java.lang.Thread.State: TIMED_WAITING
      at sun.misc.Unsafe.park(Native Method)
      - parking to wait for <40159> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
      at
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
      at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitN
anos(AbstractQueuedSynchronizer.java:1963)
      at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
      at
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(Sched
uledThreadPoolExecutor.java:583)
      at
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(Sched
uledThreadPoolExecutor.java:576)
      at
java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
      at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:9
07)
      at java.lang.Thread.run(Thread.java:619)

     Locked ownable synchronizers:
      - None

  On 01/15/2011 07:27 PM, David Holmes wrote:
    Adrian,

    Thanks for the additional information - very helpful.

    As Doug said a timed-await should not wait forever. 6807483 was a
problem encountered by one customer that did not reproduce anywhere else and
which disappeared when the customer upgraded to Solaris 10u7.

    Can you attach gdb to the process to see what it reports in its stack
trace? It may be that this is a case where GC is going into overdrive and so
the system remains almost constantly at a safepoint and prevents any other
threads from progressing. At the native level we may see that the thread has
stopped waiting but has not been able to execute the code that would update
its state to reflect that.

    Also can you try using an alternative GC? I know there are some
situation where CMS continually runs, managing to free up tiny amounts of
space, not enough for the requested allocation but enough to avoid deciding
to throw OutOfMemoryError.

    Thanks,
    David Holmes

    -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Adrian Tarau
    Sent: Sunday, 16 January 2011 7:44 AM
    To: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] "parking to wait for" hangs forever


      We are using Linux boxes Linux 2.6.18-194.el5 #1 SMP Mon Mar 29
22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux  with Java 1.6.0_20
(Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
      Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode))

      We have ~ 140 (+several other processes) small Java processes running
with 64M heap on 9 servers(pre-production) and 30 Java processes(+several
other processes) running with 32M heap :) on 5 VM servers(development, don't
remember the virtualization platform, something that is freely available in
the CentOS repository).

      These processes are called "collectors". We use Apache Commons VFS to
connect to remote systems and JGroups to send collector activities to other
processes(managers). Once in a blue moon, due to some bug in Apache Commons
VFS or in code written by us around AC VFS(memory leaks) the heap is
consumed up to 99% and GC(default GC, not G1) kicks in using ~ 50%-60%
CPU(as VisualVM reports) but it doesn't actually throw an OOM - somehow it
manages to clean up enough memory to avoid an OOM(jumping from 1-2% CPU
usage to 8%-9% CPU as reported by the OS).

      When it reaches this state, the process runs very slow(due to
intensive GC activity) and after a while it remains locked in a "parking to
wait for ..." in JGroups

      I will do an update to the latest JVM(update 23) on some machines and
see how it goes. I found a bug
(http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems similar with
what we are experiencing but it was fixed in 1.6.0_18. Also this bugs
http://bugs.sun.com/view_bug.do?bug_id=6807483
(java.util.concurrent.locks.Condition.await(timeout, units) hangs forever)
looks exactly like our issue but its state is "11-Closed, Not Reproducible".

      Thanks.

      On 01/15/2011 10:39 AM, Doug Lea wrote:
        On 01/15/11 10:21, Adrian Tarau wrote:

          Also I think it more then a coincidence that it happened every
time when the JVM
          was closed to run OOM - no OOM exception in the logs but when I
looked at the
          heap was full and GC was high on CPU.

          I will post this issue on the JGroups dev mailing list but I would
like to
          understand why a call to await(timout) blocks indefinitely? There
is an
          undocumented behaviour(like in certain situations it still waits
for a condition
          to happen even if we specified a timeout?) or do I misunderstand
how await
          should work?.


        No, a timed wait should not block forever.

        There have been some hotspot JVM lost wake-up JVM bugs, at least
        one of which was associated with GC (although possibly only
        using the "G1" collector). My best guess is that these are
        fixed in current (b123+) versions of openJDK7 releases
        (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
        I'm not sure when various fixes have or will be applied to
        JDK6 updates. (This also appears to be related to the
        FJ problems reported last week.) If I get more information,
        I will relay.

        -Doug


        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest at cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110118/5795e334/attachment-0001.html>

From adrian.tarau at gmail.com  Mon Jan 17 17:30:45 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Mon, 17 Jan 2011 17:30:45 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMELEIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCMELEIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D34C315.4010702@gmail.com>

I just found a blog a few minutes ago and now I have a command line 
prepared :) .It dumps something like this(see bellow, this is a thread 
with a Condition.await() ). I couldn't find a document saying which Java 
thread id(as listed in thread dump) corresponds with what gdb is 
printing here but I found a match by trial & error :) nid(hexa)=LWP(decimal)

Thanks

gdb -ex "set pagination 0" -ex "thread apply all bt" --batch -p <pid> and

Thread 22 (Thread 0xb6a81b70 (LWP 28993)):
#0  0xb77bc430 in __kernel_vsyscall ()
#1  0xb7796342 in pthread_cond_timedwait@@GLIBC_2.3.2 () from 
/lib/tls/i686/cmov/libpthread.so.0
#2  0xb77968a9 in pthread_cond_timedwait at GLIBC_2.0 () from 
/lib/tls/i686/cmov/libpthread.so.0
#3  0xb7006dfa in Parker::park(bool, long long) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#4  0xb711daf0 in Unsafe_Park () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#5  0xb380a1e0 in ?? ()
#6  0xb37fe10d in ?? ()
#7  0xb37fe10d in ?? ()
#8  0xb37fe3bd in ?? ()
#9  0xb37fb34c in ?? ()
#10 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*, methodHandle*, 
JavaCallArguments*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#11 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*, 
methodHandle*, JavaCallArguments*, Thread*), JavaValue*, methodHandle*, 
JavaCallArguments*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#12 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle, 
JavaCallArguments*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#13 0xb7055bcb in Reflection::invoke(instanceKlassHandle, methodHandle, 
Handle, bool, objArrayHandle, BasicType, objArrayHandle, bool, Thread*) 
() from /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#14 0xb7058b31 in Reflection::invoke_method(oopDesc*, Handle, 
objArrayHandle, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#15 0xb6ea9b0f in JVM_InvokeMethod () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#16 0xb6a18314 in Java_sun_reflect_NativeMethodAccessorImpl_invoke0 () 
from /work/jdk/jdk1.6.0_20/jre/lib/i386/libjava.so
#17 0xb380a1e0 in ?? ()
#18 0xb37fdfa7 in ?? ()
#19 0xb37fdfa7 in ?? ()
#20 0xb37fe483 in ?? ()
#21 0xb37fdfa7 in ?? ()
#22 0xb37fdfa7 in ?? ()
#23 0xb37fdfa7 in ?? ()
#24 0xb37fdfa7 in ?? ()
#25 0xb37fe10d in ?? ()
#26 0xb37fe10d in ?? ()
#27 0xb37fe10d in ?? ()
#28 0xb37fe10d in ?? ()
#29 0xb37fe10d in ?? ()
#30 0xb37fe10d in ?? ()
#31 0xb37fe10d in ?? ()
#32 0xb37fe10d in ?? ()
#33 0xb37fe10d in ?? ()
#34 0xb37fe10d in ?? ()
#35 0xb37fe10d in ?? ()
#36 0xb37fdfa7 in ?? ()
#37 0xb37fe4c5 in ?? ()
#38 0xb37fdfe9 in ?? ()
#39 0xb37fb34c in ?? ()
#40 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*, methodHandle*, 
JavaCallArguments*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#41 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*, 
methodHandle*, JavaCallArguments*, Thread*), JavaValue*, methodHandle*, 
JavaCallArguments*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#42 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle, 
JavaCallArguments*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#43 0xb6e60163 in jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, 
JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#44 0xb6e503bc in jni_CallStaticVoidMethod () from 
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
#45 0x08049b98 in JavaMain ()
#46 0xb779196e in start_thread () from /lib/tls/i686/cmov/libpthread.so.0
#47 0xb76f1a4e in clone () from /lib/tls/i686/cmov/libc.so.6

On 01/17/2011 05:14 PM, David Holmes wrote:
> Adrian,
> You can attach gdb to the process:
> gdb <path to java> <pid>
> then use:
> thread apply all bt
> (bt is short for backtrace) to get all the thread stacks
> See:
> http://wiki.debian.org/HowToGetABacktrace
> http://sourceware.org/gdb/current/onlinedocs/gdb/Backtrace.html
> David
>
>     -----Original Message-----
>     *From:* Adrian Tarau [mailto:adrian.tarau at gmail.com]
>     *Sent:* Tuesday, 18 January 2011 4:55 AM
>     *To:* dholmes at ieee.org
>     *Cc:* David Holmes; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] "parking to wait for" hangs
>     forever
>
>
>     David,
>
>     I just have one process with 2 threads waiting in await(xxx). How
>     do I actually use gdb to extract the stack trace? t at 67 I know for
>     sure(99.9% sure :) ) it is locked because I cannot send any
>     message, not sure the RMI thread....Successive dumps of the stack
>     trace shows both threads in the same state, several times.
>
>     Thanks.
>
>     /"Channel default Messaging" - Thread t at 67
>        java.lang.Thread.State: TIMED_WAITING
>         at sun.misc.Unsafe.park(Native Method)
>         - parking to wait for <664425> (a
>     java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>         at
>     java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>         at
>     java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2054)
>         at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
>         at org.jgroups.protocols.FC.down(FC.java:423)
>         at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
>         at
>     org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
>         at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
>         at org.jgroups.JChannel.down(JChannel.java:1623)
>         at org.jgroups.JChannel.send(JChannel.java:724)
>         at
>     com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.java:321)
>         at
>     com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java:33)
>         at
>     com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(ChannelImpl.java:683)
>
>        Locked ownable synchronizers:
>         - None
>
>     "RMI Scheduler(0)" - Thread t at 66
>        java.lang.Thread.State: TIMED_WAITING
>         at sun.misc.Unsafe.park(Native Method)
>         - parking to wait for <40159> (a
>     java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>         at
>     java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>         at
>     java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
>         at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
>         at
>     java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:583)
>         at
>     java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:576)
>         at
>     java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
>         at
>     java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
>         at java.lang.Thread.run(Thread.java:619)
>
>        Locked ownable synchronizers:
>         - None
>
>     On 01/15/2011 07:27 PM, David Hol/mes wrote:
>>     Adrian,
>>     Thanks for the additional information - very helpful.
>>     As Doug said a timed-await should not wait forever. 6807483 was a
>>     problem encountered by one customer that did not reproduce
>>     anywhere else and which disappeared when the customer upgraded to
>>     Solaris 10u7.
>>     Can you attach gdb to the process to see what it reports in its
>>     stack trace? It may be that this is a case where GC is going into
>>     overdrive and so the system remains almost constantly at a
>>     safepoint and prevents any other threads from progressing. At the
>>     native level we may see that the thread has stopped waiting but
>>     has not been able to execute the code that would update its state
>>     to reflect that.
>>     Also can you try using an alternative GC? I know there are some
>>     situation where CMS continually runs, managing to free up tiny
>>     amounts of space, not enough for the requested allocation but
>>     enough to avoid deciding to throw OutOfMemoryError.
>>     Thanks,
>>     David Holmes
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>>     *Adrian Tarau
>>     *Sent:* Sunday, 16 January 2011 7:44 AM
>>     *To:* concurrency-interest at cs.oswego.edu
>>     *Subject:* Re: [concurrency-interest] "parking to wait for" hangs
>>     forever
>>
>>         We are using Linux boxes /Linux 2.6.18-194.el5 #1 SMP Mon Mar
>>         29 22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux /with
>>         Java 1.6.0_20/(Java(TM) SE Runtime Environment (build
>>         1.6.0_20-b02)
>>         Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode)/)
>>
>>         We have ~ 140 (+several other processes) small Java processes
>>         running with 64M heap on 9 servers(pre-production) and 30
>>         Java processes(+several other processes) running with 32M
>>         heap :) on 5 VM servers(development, don't remember the
>>         virtualization platform, something that is freely available
>>         in the CentOS repository).
>>
>>         These processes are called "collectors". We use Apache
>>         Commons VFS to connect to remote systems and JGroups to send
>>         collector activities to other processes(managers). Once in a
>>         blue moon, due to some bug in Apache Commons VFS or in code
>>         written by us around AC VFS(memory leaks) the heap is
>>         consumed up to 99% and GC(default GC, not G1) kicks in using
>>         ~ 50%-60% CPU(as VisualVM reports) but it doesn't actually
>>         throw an OOM - somehow it manages to clean up enough memory
>>         to avoid an OOM(jumping from 1-2% CPU usage to 8%-9% CPU as
>>         reported by the OS).
>>
>>         When it reaches this state, the process runs very slow(due to
>>         intensive GC activity) and after a while it remains locked in
>>         a "parking to wait for ..." in JGroups
>>
>>         I will do an update to the latest JVM(update 23) on some
>>         machines and see how it goes. I found a bug
>>         (http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems
>>         similar with what we are experiencing but it was fixed in
>>         1.6.0_18. Also this bugs
>>         http://bugs.sun.com/view_bug.do?bug_id=6807483
>>         (java.util.concurrent.locks.Condition.await(timeout, units)
>>         hangs forever) looks exactly like our issue but its state is
>>         "11-Closed, Not Reproducible".
>>
>>         Thanks.
>>
>>         On 01/15/2011 10:39 AM, Doug Lea wrote:
>>>         On 01/15/11 10:21, Adrian Tarau wrote:
>>>>         Also I think it more then a coincidence that it happened
>>>>         every time when the JVM
>>>>         was closed to run OOM - no OOM exception in the logs but
>>>>         when I looked at the
>>>>         heap was full and GC was high on CPU.
>>>>
>>>>         I will post this issue on the JGroups dev mailing list but
>>>>         I would like to
>>>>         understand why a call to await(timout) blocks indefinitely?
>>>>         There is an
>>>>         undocumented behaviour(like in certain situations it still
>>>>         waits for a condition
>>>>         to happen even if we specified a timeout?) or do I
>>>>         misunderstand how await
>>>>         should work?.
>>>
>>>         No, a timed wait should not block forever.
>>>
>>>         There have been some hotspot JVM lost wake-up JVM bugs, at
>>>         least
>>>         one of which was associated with GC (although possibly only
>>>         using the "G1" collector). My best guess is that these are
>>>         fixed in current (b123+) versions of openJDK7 releases
>>>         (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
>>>         I'm not sure when various fixes have or will be applied to
>>>         JDK6 updates. (This also appears to be related to the
>>>         FJ problems reported last week.) If I get more information,
>>>         I will relay.
>>>
>>>         -Doug
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110117/2c4f60ba/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Jan 17 17:39:00 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 18 Jan 2011 08:39:00 +1000
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D34C315.4010702@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIELFIKAA.davidcholmes@aapt.net.au>

So this shows the thread is still in the timed-wait. Assuming this is the
native stack for the Java stack you showed previously, does the code here:

org.jgroups.protocols.FC.handleDownMessage(FC.java:549)

and upward cause the await to be called in a loop, or will the timeout lead
to an abort of some kind?

Probably best to take this off-list

David
  -----Original Message-----
  From: Adrian Tarau [mailto:adrian.tarau at gmail.com]
  Sent: Tuesday, 18 January 2011 8:31 AM
  To: dholmes at ieee.org
  Cc: David Holmes; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] "parking to wait for" hangs forever


  I just found a blog a few minutes ago and now I have a command line
prepared :) .It dumps something like this(see bellow, this is a thread with
a Condition.await() ). I couldn't find a document saying which Java thread
id(as listed in thread dump) corresponds with what gdb is printing here but
I found a match by trial & error :) nid(hexa)=LWP(decimal)

  Thanks

  gdb -ex "set pagination 0" -ex "thread apply all bt" --batch -p <pid> and

  Thread 22 (Thread 0xb6a81b70 (LWP 28993)):
  #0  0xb77bc430 in __kernel_vsyscall ()
  #1  0xb7796342 in pthread_cond_timedwait@@GLIBC_2.3.2 () from
/lib/tls/i686/cmov/libpthread.so.0
  #2  0xb77968a9 in pthread_cond_timedwait at GLIBC_2.0 () from
/lib/tls/i686/cmov/libpthread.so.0
  #3  0xb7006dfa in Parker::park(bool, long long) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #4  0xb711daf0 in Unsafe_Park () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #5  0xb380a1e0 in ?? ()
  #6  0xb37fe10d in ?? ()
  #7  0xb37fe10d in ?? ()
  #8  0xb37fe3bd in ?? ()
  #9  0xb37fb34c in ?? ()
  #10 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #11 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*,
methodHandle*, JavaCallArguments*, Thread*), JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #12 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #13 0xb7055bcb in Reflection::invoke(instanceKlassHandle, methodHandle,
Handle, bool, objArrayHandle, BasicType, objArrayHandle, bool, Thread*) ()
from /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #14 0xb7058b31 in Reflection::invoke_method(oopDesc*, Handle,
objArrayHandle, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #15 0xb6ea9b0f in JVM_InvokeMethod () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #16 0xb6a18314 in Java_sun_reflect_NativeMethodAccessorImpl_invoke0 ()
from /work/jdk/jdk1.6.0_20/jre/lib/i386/libjava.so
  #17 0xb380a1e0 in ?? ()
  #18 0xb37fdfa7 in ?? ()
  #19 0xb37fdfa7 in ?? ()
  #20 0xb37fe483 in ?? ()
  #21 0xb37fdfa7 in ?? ()
  #22 0xb37fdfa7 in ?? ()
  #23 0xb37fdfa7 in ?? ()
  #24 0xb37fdfa7 in ?? ()
  #25 0xb37fe10d in ?? ()
  #26 0xb37fe10d in ?? ()
  #27 0xb37fe10d in ?? ()
  #28 0xb37fe10d in ?? ()
  #29 0xb37fe10d in ?? ()
  #30 0xb37fe10d in ?? ()
  #31 0xb37fe10d in ?? ()
  #32 0xb37fe10d in ?? ()
  #33 0xb37fe10d in ?? ()
  #34 0xb37fe10d in ?? ()
  #35 0xb37fe10d in ?? ()
  #36 0xb37fdfa7 in ?? ()
  #37 0xb37fe4c5 in ?? ()
  #38 0xb37fdfe9 in ?? ()
  #39 0xb37fb34c in ?? ()
  #40 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #41 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*,
methodHandle*, JavaCallArguments*, Thread*), JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #42 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #43 0xb6e60163 in jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*,
JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #44 0xb6e503bc in jni_CallStaticVoidMethod () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
  #45 0x08049b98 in JavaMain ()
  #46 0xb779196e in start_thread () from /lib/tls/i686/cmov/libpthread.so.0
  #47 0xb76f1a4e in clone () from /lib/tls/i686/cmov/libc.so.6

  On 01/17/2011 05:14 PM, David Holmes wrote:
    Adrian,

    You can attach gdb to the process:

    gdb <path to java> <pid>

    then use:

    thread apply all bt

    (bt is short for backtrace) to get all the thread stacks

    See:

    http://wiki.debian.org/HowToGetABacktrace
    http://sourceware.org/gdb/current/onlinedocs/gdb/Backtrace.html

    David
      -----Original Message-----
      From: Adrian Tarau [mailto:adrian.tarau at gmail.com]
      Sent: Tuesday, 18 January 2011 4:55 AM
      To: dholmes at ieee.org
      Cc: David Holmes; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] "parking to wait for" hangs
forever



      David,

      I just have one process with 2 threads waiting in await(xxx). How do I
actually use gdb to extract the stack trace? t at 67 I know for sure(99.9% sure
:) ) it is locked because I cannot send any message, not sure the RMI
thread....Successive dumps of the stack trace shows both threads in the same
state, several times.

      Thanks.

      "Channel default Messaging" - Thread t at 67
         java.lang.Thread.State: TIMED_WAITING
          at sun.misc.Unsafe.park(Native Method)
          - parking to wait for <664425> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
          at
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
          at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(
AbstractQueuedSynchronizer.java:2054)
          at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
          at org.jgroups.protocols.FC.down(FC.java:423)
          at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
          at
org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
          at org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
          at org.jgroups.JChannel.down(JChannel.java:1623)
          at org.jgroups.JChannel.send(JChannel.java:724)
          at
com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.j
ava:321)
          at
com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java
:33)
          at
com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(Cha
nnelImpl.java:683)

         Locked ownable synchronizers:
          - None

      "RMI Scheduler(0)" - Thread t at 66
         java.lang.Thread.State: TIMED_WAITING
          at sun.misc.Unsafe.park(Native Method)
          - parking to wait for <40159> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
          at
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
          at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitN
anos(AbstractQueuedSynchronizer.java:1963)
          at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
          at
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(Sched
uledThreadPoolExecutor.java:583)
          at
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(Sched
uledThreadPoolExecutor.java:576)
          at
java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
          at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:9
07)
          at java.lang.Thread.run(Thread.java:619)

         Locked ownable synchronizers:
          - None

      On 01/15/2011 07:27 PM, David Holmes wrote:
        Adrian,

        Thanks for the additional information - very helpful.

        As Doug said a timed-await should not wait forever. 6807483 was a
problem encountered by one customer that did not reproduce anywhere else and
which disappeared when the customer upgraded to Solaris 10u7.

        Can you attach gdb to the process to see what it reports in its
stack trace? It may be that this is a case where GC is going into overdrive
and so the system remains almost constantly at a safepoint and prevents any
other threads from progressing. At the native level we may see that the
thread has stopped waiting but has not been able to execute the code that
would update its state to reflect that.

        Also can you try using an alternative GC? I know there are some
situation where CMS continually runs, managing to free up tiny amounts of
space, not enough for the requested allocation but enough to avoid deciding
to throw OutOfMemoryError.

        Thanks,
        David Holmes

        -----Original Message-----
        From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Adrian Tarau
        Sent: Sunday, 16 January 2011 7:44 AM
        To: concurrency-interest at cs.oswego.edu
        Subject: Re: [concurrency-interest] "parking to wait for" hangs
forever


          We are using Linux boxes Linux 2.6.18-194.el5 #1 SMP Mon Mar 29
22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux  with Java 1.6.0_20
(Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
          Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode))

          We have ~ 140 (+several other processes) small Java processes
running with 64M heap on 9 servers(pre-production) and 30 Java
processes(+several other processes) running with 32M heap :) on 5 VM
servers(development, don't remember the virtualization platform, something
that is freely available in the CentOS repository).

          These processes are called "collectors". We use Apache Commons VFS
to connect to remote systems and JGroups to send collector activities to
other processes(managers). Once in a blue moon, due to some bug in Apache
Commons VFS or in code written by us around AC VFS(memory leaks) the heap is
consumed up to 99% and GC(default GC, not G1) kicks in using ~ 50%-60%
CPU(as VisualVM reports) but it doesn't actually throw an OOM - somehow it
manages to clean up enough memory to avoid an OOM(jumping from 1-2% CPU
usage to 8%-9% CPU as reported by the OS).

          When it reaches this state, the process runs very slow(due to
intensive GC activity) and after a while it remains locked in a "parking to
wait for ..." in JGroups

          I will do an update to the latest JVM(update 23) on some machines
and see how it goes. I found a bug
(http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems similar with
what we are experiencing but it was fixed in 1.6.0_18. Also this bugs
http://bugs.sun.com/view_bug.do?bug_id=6807483
(java.util.concurrent.locks.Condition.await(timeout, units) hangs forever)
looks exactly like our issue but its state is "11-Closed, Not Reproducible".

          Thanks.

          On 01/15/2011 10:39 AM, Doug Lea wrote:
            On 01/15/11 10:21, Adrian Tarau wrote:

              Also I think it more then a coincidence that it happened every
time when the JVM
              was closed to run OOM - no OOM exception in the logs but when
I looked at the
              heap was full and GC was high on CPU.

              I will post this issue on the JGroups dev mailing list but I
would like to
              understand why a call to await(timout) blocks indefinitely?
There is an
              undocumented behaviour(like in certain situations it still
waits for a condition
              to happen even if we specified a timeout?) or do I
misunderstand how await
              should work?.


            No, a timed wait should not block forever.

            There have been some hotspot JVM lost wake-up JVM bugs, at least
            one of which was associated with GC (although possibly only
            using the "G1" collector). My best guess is that these are
            fixed in current (b123+) versions of openJDK7 releases
            (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
            I'm not sure when various fixes have or will be applied to
            JDK6 updates. (This also appears to be related to the
            FJ problems reported last week.) If I get more information,
            I will relay.

            -Doug


            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest at cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110118/26d65548/attachment-0001.html>

From adrian.tarau at gmail.com  Mon Jan 17 17:59:27 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Mon, 17 Jan 2011 17:59:27 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIELFIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIELFIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D34C9CF.8080406@gmail.com>

David,

Mea culpa, I forgot so specify that this thread is just an simulated 
example, I wanted to see what it prints when it waits in 
Condition.await. Sorry about that...not a stack trace of the real issue...

It is called in a loop and it breaks the loop based on several 
conditions. I will move this discussion over the JGroups devel list, 
there is already a thread regarding this issue(it seems I'm not alone in 
this).

Thank you for your support.

                     while(length > lowest_credit && running) {
                         try {
                             long block_time=max_block_time;
                             if(max_block_times != null) {
                                 Long tmp=end_time.get();
                                 if(tmp != null) {
                                     // Negative value means we don't 
wait at all ! If the end_time already elapsed
                                     // (because we waited for other 
threads to get processed), the message will not
                                     // block at all and get sent 
immediately
                                     block_time=tmp - start_blocking;
                                 }
                             }

                             boolean 
rc=credits_available.await(block_time, TimeUnit.MILLISECONDS);
*if(rc || length <= lowest_credit || !running)
                                 break;*

                             // if we use max_block_times, then we do 
*not* send credit requests, even if we run
                             // into timeouts: in this case, it is up to 
the receivers to send new credits
*if(!rc && max_block_times != null)
                                 break;*

                             long wait_time=System.currentTimeMillis() - 
last_credit_request;
                             if(wait_time >= max_block_time) {

                                 // we have to set this var now, because 
we release the lock below (for sending a
                                 // credit request), so all blocked 
threads would send a credit request, leading to
                                 // a credit request storm
                                 
last_credit_request=System.currentTimeMillis();

                                 // we need to send the credit requests 
down *without* holding the sent_lock, otherwise we might
                                 // run into the deadlock described in 
http://jira.jboss.com/jira/browse/JGRP-292
                                 Map<Address,Long> sent_copy=new 
HashMap<Address,Long>(sent);
                                 sent_copy.keySet().retainAll(creditors);
                                 sent_lock.unlock();
                                 try {
                                     for(Map.Entry<Address,Long> entry: 
sent_copy.entrySet())
                                         
sendCreditRequest(entry.getKey(), entry.getValue());
                                 }
                                 finally {
                                     sent_lock.lock();
                                 }
                             }
                         }
                         catch(InterruptedException e) {
                             // bela June 15 2007: don't interrupt the 
thread again, as this will trigger an infinite loop !!
                             // (http://jira.jboss.com/jira/browse/JGRP-536)
                             // Thread.currentThread().interrupt();
                         }
                     }
                     long block_time=System.currentTimeMillis() - 
start_blocking;
                     if(log.isTraceEnabled())
                         log.trace("total time blocked: " + block_time + 
" ms");
                     total_time_blocking+=block_time;
                     last_blockings.add(block_time);
                 }

On 01/17/2011 05:39 PM, David Holmes wrote:
> So this shows the thread is still in the timed-wait. Assuming this is 
> the native stack for the Java stack you showed previously, does the 
> code here:
> /org.jgroups.protocols.FC.handleDownMessage(FC.java:549)/
> and upward cause the await to be called in a loop, or will the timeout 
> lead to an abort of some kind?
> Probably best to take this off-list
> David
>
>     -----Original Message-----
>     *From:* Adrian Tarau [mailto:adrian.tarau at gmail.com]
>     *Sent:* Tuesday, 18 January 2011 8:31 AM
>     *To:* dholmes at ieee.org
>     *Cc:* David Holmes; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] "parking to wait for" hangs
>     forever
>
>     I just found a blog a few minutes ago and now I have a command
>     line prepared :) .It dumps something like this(see bellow, this is
>     a thread with a Condition.await() ). I couldn't find a document
>     saying which Java thread id(as listed in thread dump) corresponds
>     with what gdb is printing here but I found a match by trial &
>     error :) nid(hexa)=LWP(decimal)
>
>     Thanks
>
>     gdb -ex "set pagination 0" -ex "thread apply all bt" --batch -p
>     <pid> and
>
>     Thread 22 (Thread 0xb6a81b70 (LWP 28993)):
>     #0  0xb77bc430 in __kernel_vsyscall ()
>     #1  0xb7796342 in pthread_cond_timedwait@@GLIBC_2.3.2 () from
>     /lib/tls/i686/cmov/libpthread.so.0
>     #2  0xb77968a9 in pthread_cond_timedwait at GLIBC_2.0 () from
>     /lib/tls/i686/cmov/libpthread.so.0
>     #3  0xb7006dfa in Parker::park(bool, long long) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #4  0xb711daf0 in Unsafe_Park () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #5  0xb380a1e0 in ?? ()
>     #6  0xb37fe10d in ?? ()
>     #7  0xb37fe10d in ?? ()
>     #8  0xb37fe3bd in ?? ()
>     #9  0xb37fb34c in ?? ()
>     #10 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*,
>     methodHandle*, JavaCallArguments*, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #11 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*,
>     methodHandle*, JavaCallArguments*, Thread*), JavaValue*,
>     methodHandle*, JavaCallArguments*, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #12 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
>     JavaCallArguments*, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #13 0xb7055bcb in Reflection::invoke(instanceKlassHandle,
>     methodHandle, Handle, bool, objArrayHandle, BasicType,
>     objArrayHandle, bool, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #14 0xb7058b31 in Reflection::invoke_method(oopDesc*, Handle,
>     objArrayHandle, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #15 0xb6ea9b0f in JVM_InvokeMethod () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #16 0xb6a18314 in
>     Java_sun_reflect_NativeMethodAccessorImpl_invoke0 () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/libjava.so
>     #17 0xb380a1e0 in ?? ()
>     #18 0xb37fdfa7 in ?? ()
>     #19 0xb37fdfa7 in ?? ()
>     #20 0xb37fe483 in ?? ()
>     #21 0xb37fdfa7 in ?? ()
>     #22 0xb37fdfa7 in ?? ()
>     #23 0xb37fdfa7 in ?? ()
>     #24 0xb37fdfa7 in ?? ()
>     #25 0xb37fe10d in ?? ()
>     #26 0xb37fe10d in ?? ()
>     #27 0xb37fe10d in ?? ()
>     #28 0xb37fe10d in ?? ()
>     #29 0xb37fe10d in ?? ()
>     #30 0xb37fe10d in ?? ()
>     #31 0xb37fe10d in ?? ()
>     #32 0xb37fe10d in ?? ()
>     #33 0xb37fe10d in ?? ()
>     #34 0xb37fe10d in ?? ()
>     #35 0xb37fe10d in ?? ()
>     #36 0xb37fdfa7 in ?? ()
>     #37 0xb37fe4c5 in ?? ()
>     #38 0xb37fdfe9 in ?? ()
>     #39 0xb37fb34c in ?? ()
>     #40 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*,
>     methodHandle*, JavaCallArguments*, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #41 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*,
>     methodHandle*, JavaCallArguments*, Thread*), JavaValue*,
>     methodHandle*, JavaCallArguments*, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #42 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
>     JavaCallArguments*, Thread*) () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #43 0xb6e60163 in jni_invoke_static(JNIEnv_*, JavaValue*,
>     _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*)
>     () from /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #44 0xb6e503bc in jni_CallStaticVoidMethod () from
>     /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>     #45 0x08049b98 in JavaMain ()
>     #46 0xb779196e in start_thread () from
>     /lib/tls/i686/cmov/libpthread.so.0
>     #47 0xb76f1a4e in clone () from /lib/tls/i686/cmov/libc.so.6
>
>     On 01/17/2011 05:14 PM, David Holmes wrote:
>>     Adrian,
>>     You can attach gdb to the process:
>>     gdb <path to java> <pid>
>>     then use:
>>     thread apply all bt
>>     (bt is short for backtrace) to get all the thread stacks
>>     See:
>>     http://wiki.debian.org/HowToGetABacktrace
>>     http://sourceware.org/gdb/current/onlinedocs/gdb/Backtrace.html
>>     David
>>
>>         -----Original Message-----
>>         *From:* Adrian Tarau [mailto:adrian.tarau at gmail.com]
>>         *Sent:* Tuesday, 18 January 2011 4:55 AM
>>         *To:* dholmes at ieee.org
>>         *Cc:* David Holmes; concurrency-interest at cs.oswego.edu
>>         *Subject:* Re: [concurrency-interest] "parking to wait for"
>>         hangs forever
>>
>>
>>         David,
>>
>>         I just have one process with 2 threads waiting in await(xxx).
>>         How do I actually use gdb to extract the stack trace? t at 67 I
>>         know for sure(99.9% sure :) ) it is locked because I cannot
>>         send any message, not sure the RMI thread....Successive dumps
>>         of the stack trace shows both threads in the same state,
>>         several times.
>>
>>         Thanks.
>>
>>         /"Channel default Messaging" - Thread t at 67
>>            java.lang.Thread.State: TIMED_WAITING
>>             at sun.misc.Unsafe.park(Native Method)
>>             - parking to wait for <664425> (a
>>         java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>>             at
>>         java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>>             at
>>         java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2054)
>>             at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
>>             at org.jgroups.protocols.FC.down(FC.java:423)
>>             at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
>>             at
>>         org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
>>             at
>>         org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
>>             at org.jgroups.JChannel.down(JChannel.java:1623)
>>             at org.jgroups.JChannel.send(JChannel.java:724)
>>             at
>>         com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.java:321)
>>             at
>>         com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java:33)
>>             at
>>         com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(ChannelImpl.java:683)
>>
>>            Locked ownable synchronizers:
>>             - None
>>
>>         "RMI Scheduler(0)" - Thread t at 66
>>            java.lang.Thread.State: TIMED_WAITING
>>             at sun.misc.Unsafe.park(Native Method)
>>             - parking to wait for <40159> (a
>>         java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>>             at
>>         java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>>             at
>>         java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
>>             at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
>>             at
>>         java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:583)
>>             at
>>         java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:576)
>>             at
>>         java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
>>             at
>>         java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
>>             at java.lang.Thread.run(Thread.java:619)
>>
>>            Locked ownable synchronizers:
>>             - None
>>
>>         On 01/15/2011 07:27 PM, David Hol/mes wrote:
>>>         Adrian,
>>>         Thanks for the additional information - very helpful.
>>>         As Doug said a timed-await should not wait forever. 6807483
>>>         was a problem encountered by one customer that did not
>>>         reproduce anywhere else and which disappeared when the
>>>         customer upgraded to Solaris 10u7.
>>>         Can you attach gdb to the process to see what it reports in
>>>         its stack trace? It may be that this is a case where GC is
>>>         going into overdrive and so the system remains almost
>>>         constantly at a safepoint and prevents any other threads
>>>         from progressing. At the native level we may see that the
>>>         thread has stopped waiting but has not been able to execute
>>>         the code that would update its state to reflect that.
>>>         Also can you try using an alternative GC? I know there are
>>>         some situation where CMS continually runs, managing to free
>>>         up tiny amounts of space, not enough for the requested
>>>         allocation but enough to avoid deciding to throw
>>>         OutOfMemoryError.
>>>         Thanks,
>>>         David Holmes
>>>         -----Original Message-----
>>>         *From:* concurrency-interest-bounces at cs.oswego.edu
>>>         [mailto:concurrency-interest-bounces at cs.oswego.edu]*On
>>>         Behalf Of *Adrian Tarau
>>>         *Sent:* Sunday, 16 January 2011 7:44 AM
>>>         *To:* concurrency-interest at cs.oswego.edu
>>>         *Subject:* Re: [concurrency-interest] "parking to wait for"
>>>         hangs forever
>>>
>>>             We are using Linux boxes /Linux 2.6.18-194.el5 #1 SMP
>>>             Mon Mar 29 22:10:29 EDT 2010 x86_64 x86_64 x86_64
>>>             GNU/Linux /with Java 1.6.0_20/(Java(TM) SE Runtime
>>>             Environment (build 1.6.0_20-b02)
>>>             Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode)/)
>>>
>>>             We have ~ 140 (+several other processes) small Java
>>>             processes running with 64M heap on 9
>>>             servers(pre-production) and 30 Java processes(+several
>>>             other processes) running with 32M heap :) on 5 VM
>>>             servers(development, don't remember the virtualization
>>>             platform, something that is freely available in the
>>>             CentOS repository).
>>>
>>>             These processes are called "collectors". We use Apache
>>>             Commons VFS to connect to remote systems and JGroups to
>>>             send collector activities to other processes(managers).
>>>             Once in a blue moon, due to some bug in Apache Commons
>>>             VFS or in code written by us around AC VFS(memory leaks)
>>>             the heap is consumed up to 99% and GC(default GC, not
>>>             G1) kicks in using ~ 50%-60% CPU(as VisualVM reports)
>>>             but it doesn't actually throw an OOM - somehow it
>>>             manages to clean up enough memory to avoid an
>>>             OOM(jumping from 1-2% CPU usage to 8%-9% CPU as reported
>>>             by the OS).
>>>
>>>             When it reaches this state, the process runs very
>>>             slow(due to intensive GC activity) and after a while it
>>>             remains locked in a "parking to wait for ..." in JGroups
>>>
>>>             I will do an update to the latest JVM(update 23) on some
>>>             machines and see how it goes. I found a bug
>>>             (http://bugs.sun.com/view_bug.do?bug_id=6822370) that
>>>             seems similar with what we are experiencing but it was
>>>             fixed in 1.6.0_18. Also this bugs
>>>             http://bugs.sun.com/view_bug.do?bug_id=6807483
>>>             (java.util.concurrent.locks.Condition.await(timeout,
>>>             units) hangs forever) looks exactly like our issue but
>>>             its state is "11-Closed, Not Reproducible".
>>>
>>>             Thanks.
>>>
>>>             On 01/15/2011 10:39 AM, Doug Lea wrote:
>>>>             On 01/15/11 10:21, Adrian Tarau wrote:
>>>>>             Also I think it more then a coincidence that it
>>>>>             happened every time when the JVM
>>>>>             was closed to run OOM - no OOM exception in the logs
>>>>>             but when I looked at the
>>>>>             heap was full and GC was high on CPU.
>>>>>
>>>>>             I will post this issue on the JGroups dev mailing list
>>>>>             but I would like to
>>>>>             understand why a call to await(timout) blocks
>>>>>             indefinitely? There is an
>>>>>             undocumented behaviour(like in certain situations it
>>>>>             still waits for a condition
>>>>>             to happen even if we specified a timeout?) or do I
>>>>>             misunderstand how await
>>>>>             should work?.
>>>>
>>>>             No, a timed wait should not block forever.
>>>>
>>>>             There have been some hotspot JVM lost wake-up JVM bugs,
>>>>             at least
>>>>             one of which was associated with GC (although possibly
>>>>             only
>>>>             using the "G1" collector). My best guess is that these are
>>>>             fixed in current (b123+) versions of openJDK7 releases
>>>>             (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
>>>>
>>>>             I'm not sure when various fixes have or will be applied to
>>>>             JDK6 updates. (This also appears to be related to the
>>>>             FJ problems reported last week.) If I get more
>>>>             information,
>>>>             I will relay.
>>>>
>>>>             -Doug
>>>>
>>>>
>>>>             _______________________________________________
>>>>             Concurrency-interest mailing list
>>>>             Concurrency-interest at cs.oswego.edu
>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110117/8fe976d7/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Jan 17 18:03:04 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 18 Jan 2011 09:03:04 +1000
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <4D34C9CF.8080406@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEELGIKAA.davidcholmes@aapt.net.au>

Ok. You might want to sanity check the actual block_time value that is
calculated and passed in.

David
  -----Original Message-----
  From: Adrian Tarau [mailto:adrian.tarau at gmail.com]
  Sent: Tuesday, 18 January 2011 8:59 AM
  To: dholmes at ieee.org
  Cc: David Holmes; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] "parking to wait for" hangs forever


  David,

  Mea culpa, I forgot so specify that this thread is just an simulated
example, I wanted to see what it prints when it waits in Condition.await.
Sorry about that...not a stack trace of the real issue...

  It is called in a loop and it breaks the loop based on several conditions.
I will move this discussion over the JGroups devel list, there is already a
thread regarding this issue(it seems I'm not alone in this).

  Thank you for your support.

                      while(length > lowest_credit && running) {
                          try {
                              long block_time=max_block_time;
                              if(max_block_times != null) {
                                  Long tmp=end_time.get();
                                  if(tmp != null) {
                                      // Negative value means we don't wait
at all ! If the end_time already elapsed
                                      // (because we waited for other
threads to get processed), the message will not
                                      // block at all and get sent
immediately
                                      block_time=tmp - start_blocking;
                                  }
                              }

                              boolean rc=credits_available.await(block_time,
TimeUnit.MILLISECONDS);
                              if(rc || length <= lowest_credit || !running)
                                  break;

                              // if we use max_block_times, then we do *not*
send credit requests, even if we run
                              // into timeouts: in this case, it is up to
the receivers to send new credits
                              if(!rc && max_block_times != null)
                                  break;

                              long wait_time=System.currentTimeMillis() -
last_credit_request;
                              if(wait_time >= max_block_time) {

                                  // we have to set this var now, because we
release the lock below (for sending a
                                  // credit request), so all blocked threads
would send a credit request, leading to
                                  // a credit request storm
                                  last_credit_request=System.currentTimeMill
is();

                                  // we need to send the credit requests
down *without* holding the sent_lock, otherwise we might
                                  // run into the deadlock described in
http://jira.jboss.com/jira/browse/JGRP-292
                                  Map<Address,Long> sent_copy=new
HashMap<Address,Long>(sent);
                                  sent_copy.keySet().retainAll(creditors);
                                  sent_lock.unlock();
                                  try {
                                      for(Map.Entry<Address,Long> entry:
sent_copy.entrySet())
                                          sendCreditRequest(entry.getKey(),
entry.getValue());
                                  }
                                  finally {
                                      sent_lock.lock();
                                  }
                              }
                          }
                          catch(InterruptedException e) {
                              // bela June 15 2007: don't interrupt the
thread again, as this will trigger an infinite loop !!
                              //
(http://jira.jboss.com/jira/browse/JGRP-536)
                              // Thread.currentThread().interrupt();
                          }
                      }
                      long block_time=System.currentTimeMillis() -
start_blocking;
                      if(log.isTraceEnabled())
                          log.trace("total time blocked: " + block_time + "
ms");
                      total_time_blocking+=block_time;
                      last_blockings.add(block_time);
                  }

  On 01/17/2011 05:39 PM, David Holmes wrote:
    So this shows the thread is still in the timed-wait. Assuming this is
the native stack for the Java stack you showed previously, does the code
here:

    org.jgroups.protocols.FC.handleDownMessage(FC.java:549)

    and upward cause the await to be called in a loop, or will the timeout
lead to an abort of some kind?

    Probably best to take this off-list

    David
      -----Original Message-----
      From: Adrian Tarau [mailto:adrian.tarau at gmail.com]
      Sent: Tuesday, 18 January 2011 8:31 AM
      To: dholmes at ieee.org
      Cc: David Holmes; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] "parking to wait for" hangs
forever


      I just found a blog a few minutes ago and now I have a command line
prepared :) .It dumps something like this(see bellow, this is a thread with
a Condition.await() ). I couldn't find a document saying which Java thread
id(as listed in thread dump) corresponds with what gdb is printing here but
I found a match by trial & error :) nid(hexa)=LWP(decimal)

      Thanks

      gdb -ex "set pagination 0" -ex "thread apply all bt" --batch -p <pid>
and

      Thread 22 (Thread 0xb6a81b70 (LWP 28993)):
      #0  0xb77bc430 in __kernel_vsyscall ()
      #1  0xb7796342 in pthread_cond_timedwait@@GLIBC_2.3.2 () from
/lib/tls/i686/cmov/libpthread.so.0
      #2  0xb77968a9 in pthread_cond_timedwait at GLIBC_2.0 () from
/lib/tls/i686/cmov/libpthread.so.0
      #3  0xb7006dfa in Parker::park(bool, long long) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #4  0xb711daf0 in Unsafe_Park () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #5  0xb380a1e0 in ?? ()
      #6  0xb37fe10d in ?? ()
      #7  0xb37fe10d in ?? ()
      #8  0xb37fe3bd in ?? ()
      #9  0xb37fb34c in ?? ()
      #10 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #11 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*,
methodHandle*, JavaCallArguments*, Thread*), JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #12 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #13 0xb7055bcb in Reflection::invoke(instanceKlassHandle,
methodHandle, Handle, bool, objArrayHandle, BasicType, objArrayHandle, bool,
Thread*) () from /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #14 0xb7058b31 in Reflection::invoke_method(oopDesc*, Handle,
objArrayHandle, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #15 0xb6ea9b0f in JVM_InvokeMethod () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #16 0xb6a18314 in Java_sun_reflect_NativeMethodAccessorImpl_invoke0 ()
from /work/jdk/jdk1.6.0_20/jre/lib/i386/libjava.so
      #17 0xb380a1e0 in ?? ()
      #18 0xb37fdfa7 in ?? ()
      #19 0xb37fdfa7 in ?? ()
      #20 0xb37fe483 in ?? ()
      #21 0xb37fdfa7 in ?? ()
      #22 0xb37fdfa7 in ?? ()
      #23 0xb37fdfa7 in ?? ()
      #24 0xb37fdfa7 in ?? ()
      #25 0xb37fe10d in ?? ()
      #26 0xb37fe10d in ?? ()
      #27 0xb37fe10d in ?? ()
      #28 0xb37fe10d in ?? ()
      #29 0xb37fe10d in ?? ()
      #30 0xb37fe10d in ?? ()
      #31 0xb37fe10d in ?? ()
      #32 0xb37fe10d in ?? ()
      #33 0xb37fe10d in ?? ()
      #34 0xb37fe10d in ?? ()
      #35 0xb37fe10d in ?? ()
      #36 0xb37fdfa7 in ?? ()
      #37 0xb37fe4c5 in ?? ()
      #38 0xb37fdfe9 in ?? ()
      #39 0xb37fb34c in ?? ()
      #40 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #41 0xb7005d58 in os::os_exception_wrapper(void (*)(JavaValue*,
methodHandle*, JavaCallArguments*, Thread*), JavaValue*, methodHandle*,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #42 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
JavaCallArguments*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #43 0xb6e60163 in jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*,
JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #44 0xb6e503bc in jni_CallStaticVoidMethod () from
/work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
      #45 0x08049b98 in JavaMain ()
      #46 0xb779196e in start_thread () from
/lib/tls/i686/cmov/libpthread.so.0
      #47 0xb76f1a4e in clone () from /lib/tls/i686/cmov/libc.so.6

      On 01/17/2011 05:14 PM, David Holmes wrote:
        Adrian,

        You can attach gdb to the process:

        gdb <path to java> <pid>

        then use:

        thread apply all bt

        (bt is short for backtrace) to get all the thread stacks

        See:

        http://wiki.debian.org/HowToGetABacktrace
        http://sourceware.org/gdb/current/onlinedocs/gdb/Backtrace.html

        David
          -----Original Message-----
          From: Adrian Tarau [mailto:adrian.tarau at gmail.com]
          Sent: Tuesday, 18 January 2011 4:55 AM
          To: dholmes at ieee.org
          Cc: David Holmes; concurrency-interest at cs.oswego.edu
          Subject: Re: [concurrency-interest] "parking to wait for" hangs
forever



          David,

          I just have one process with 2 threads waiting in await(xxx). How
do I actually use gdb to extract the stack trace? t at 67 I know for sure(99.9%
sure :) ) it is locked because I cannot send any message, not sure the RMI
thread....Successive dumps of the stack trace shows both threads in the same
state, several times.

          Thanks.

          "Channel default Messaging" - Thread t at 67
             java.lang.Thread.State: TIMED_WAITING
              at sun.misc.Unsafe.park(Native Method)
              - parking to wait for <664425> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
              at
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
              at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(
AbstractQueuedSynchronizer.java:2054)
              at org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
              at org.jgroups.protocols.FC.down(FC.java:423)
              at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
              at
org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
              at
org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
              at org.jgroups.JChannel.down(JChannel.java:1623)
              at org.jgroups.JChannel.send(JChannel.java:724)
              at
com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.j
ava:321)
              at
com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java
:33)
              at
com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(Cha
nnelImpl.java:683)

             Locked ownable synchronizers:
              - None

          "RMI Scheduler(0)" - Thread t at 66
             java.lang.Thread.State: TIMED_WAITING
              at sun.misc.Unsafe.park(Native Method)
              - parking to wait for <40159> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
              at
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
              at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitN
anos(AbstractQueuedSynchronizer.java:1963)
              at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
              at
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(Sched
uledThreadPoolExecutor.java:583)
              at
java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(Sched
uledThreadPoolExecutor.java:576)
              at
java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
              at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:9
07)
              at java.lang.Thread.run(Thread.java:619)

             Locked ownable synchronizers:
              - None

          On 01/15/2011 07:27 PM, David Holmes wrote:
            Adrian,

            Thanks for the additional information - very helpful.

            As Doug said a timed-await should not wait forever. 6807483 was
a problem encountered by one customer that did not reproduce anywhere else
and which disappeared when the customer upgraded to Solaris 10u7.

            Can you attach gdb to the process to see what it reports in its
stack trace? It may be that this is a case where GC is going into overdrive
and so the system remains almost constantly at a safepoint and prevents any
other threads from progressing. At the native level we may see that the
thread has stopped waiting but has not been able to execute the code that
would update its state to reflect that.

            Also can you try using an alternative GC? I know there are some
situation where CMS continually runs, managing to free up tiny amounts of
space, not enough for the requested allocation but enough to avoid deciding
to throw OutOfMemoryError.

            Thanks,
            David Holmes

            -----Original Message-----
            From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Adrian Tarau
            Sent: Sunday, 16 January 2011 7:44 AM
            To: concurrency-interest at cs.oswego.edu
            Subject: Re: [concurrency-interest] "parking to wait for" hangs
forever


              We are using Linux boxes Linux 2.6.18-194.el5 #1 SMP Mon Mar
29 22:10:29 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux  with Java 1.6.0_20
(Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
              Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode))

              We have ~ 140 (+several other processes) small Java processes
running with 64M heap on 9 servers(pre-production) and 30 Java
processes(+several other processes) running with 32M heap :) on 5 VM
servers(development, don't remember the virtualization platform, something
that is freely available in the CentOS repository).

              These processes are called "collectors". We use Apache Commons
VFS to connect to remote systems and JGroups to send collector activities to
other processes(managers). Once in a blue moon, due to some bug in Apache
Commons VFS or in code written by us around AC VFS(memory leaks) the heap is
consumed up to 99% and GC(default GC, not G1) kicks in using ~ 50%-60%
CPU(as VisualVM reports) but it doesn't actually throw an OOM - somehow it
manages to clean up enough memory to avoid an OOM(jumping from 1-2% CPU
usage to 8%-9% CPU as reported by the OS).

              When it reaches this state, the process runs very slow(due to
intensive GC activity) and after a while it remains locked in a "parking to
wait for ..." in JGroups

              I will do an update to the latest JVM(update 23) on some
machines and see how it goes. I found a bug
(http://bugs.sun.com/view_bug.do?bug_id=6822370) that seems similar with
what we are experiencing but it was fixed in 1.6.0_18. Also this bugs
http://bugs.sun.com/view_bug.do?bug_id=6807483
(java.util.concurrent.locks.Condition.await(timeout, units) hangs forever)
looks exactly like our issue but its state is "11-Closed, Not Reproducible".

              Thanks.

              On 01/15/2011 10:39 AM, Doug Lea wrote:
                On 01/15/11 10:21, Adrian Tarau wrote:

                  Also I think it more then a coincidence that it happened
every time when the JVM
                  was closed to run OOM - no OOM exception in the logs but
when I looked at the
                  heap was full and GC was high on CPU.

                  I will post this issue on the JGroups dev mailing list but
I would like to
                  understand why a call to await(timout) blocks
indefinitely? There is an
                  undocumented behaviour(like in certain situations it still
waits for a condition
                  to happen even if we specified a timeout?) or do I
misunderstand how await
                  should work?.


                No, a timed wait should not block forever.

                There have been some hotspot JVM lost wake-up JVM bugs, at
least
                one of which was associated with GC (although possibly only
                using the "G1" collector). My best guess is that these are
                fixed in current (b123+) versions of openJDK7 releases
                (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
                I'm not sure when various fixes have or will be applied to
                JDK6 updates. (This also appears to be related to the
                FJ problems reported last week.) If I get more information,
                I will relay.

                -Doug


                _______________________________________________
                Concurrency-interest mailing list
                Concurrency-interest at cs.oswego.edu
                http://cs.oswego.edu/mailman/listinfo/concurrency-interest








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110118/a124347d/attachment-0001.html>

From adrian.tarau at gmail.com  Mon Jan 17 18:07:08 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Mon, 17 Jan 2011 18:07:08 -0500
Subject: [concurrency-interest] "parking to wait for" hangs forever
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEELGIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEELGIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D34CB9C.2010907@gmail.com>

Thanks, I will check this with JGroups developers.

On 01/17/2011 06:03 PM, David Holmes wrote:
> Ok. You might want to sanity check the actual block_time value that is 
> calculated and passed in.
> David
>
>     -----Original Message-----
>     *From:* Adrian Tarau [mailto:adrian.tarau at gmail.com]
>     *Sent:* Tuesday, 18 January 2011 8:59 AM
>     *To:* dholmes at ieee.org
>     *Cc:* David Holmes; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] "parking to wait for" hangs
>     forever
>
>     David,
>
>     Mea culpa, I forgot so specify that this thread is just an
>     simulated example, I wanted to see what it prints when it waits in
>     Condition.await. Sorry about that...not a stack trace of the real
>     issue...
>
>     It is called in a loop and it breaks the loop based on several
>     conditions. I will move this discussion over the JGroups devel
>     list, there is already a thread regarding this issue(it seems I'm
>     not alone in this).
>
>     Thank you for your support.
>
>                         while(length > lowest_credit && running) {
>                             try {
>                                 long block_time=max_block_time;
>                                 if(max_block_times != null) {
>                                     Long tmp=end_time.get();
>                                     if(tmp != null) {
>                                         // Negative value means we
>     don't wait at all ! If the end_time already elapsed
>                                         // (because we waited for
>     other threads to get processed), the message will not
>                                         // block at all and get sent
>     immediately
>                                         block_time=tmp - start_blocking;
>                                     }
>                                 }
>
>                                 boolean
>     rc=credits_available.await(block_time, TimeUnit.MILLISECONDS);
>     *if(rc || length <= lowest_credit || !running)
>                                     break;*
>
>                                 // if we use max_block_times, then we
>     do *not* send credit requests, even if we run
>                                 // into timeouts: in this case, it is
>     up to the receivers to send new credits
>     *if(!rc && max_block_times != null)
>                                     break;*
>
>                                 long
>     wait_time=System.currentTimeMillis() - last_credit_request;
>                                 if(wait_time >= max_block_time) {
>
>                                     // we have to set this var now,
>     because we release the lock below (for sending a
>                                     // credit request), so all blocked
>     threads would send a credit request, leading to
>                                     // a credit request storm
>                                    
>     last_credit_request=System.currentTimeMillis();
>
>                                     // we need to send the credit
>     requests down *without* holding the sent_lock, otherwise we might
>                                     // run into the deadlock described
>     in http://jira.jboss.com/jira/browse/JGRP-292
>                                     Map<Address,Long> sent_copy=new
>     HashMap<Address,Long>(sent);
>                                    
>     sent_copy.keySet().retainAll(creditors);
>                                     sent_lock.unlock();
>                                     try {
>                                         for(Map.Entry<Address,Long>
>     entry: sent_copy.entrySet())
>                                            
>     sendCreditRequest(entry.getKey(), entry.getValue());
>                                     }
>                                     finally {
>                                         sent_lock.lock();
>                                     }
>                                 }
>                             }
>                             catch(InterruptedException e) {
>                                 // bela June 15 2007: don't interrupt
>     the thread again, as this will trigger an infinite loop !!
>                                 //
>     (http://jira.jboss.com/jira/browse/JGRP-536)
>                                 // Thread.currentThread().interrupt();
>                             }
>                         }
>                         long block_time=System.currentTimeMillis() -
>     start_blocking;
>                         if(log.isTraceEnabled())
>                             log.trace("total time blocked: " +
>     block_time + " ms");
>                         total_time_blocking+=block_time;
>                         last_blockings.add(block_time);
>                     }
>
>     On 01/17/2011 05:39 PM, David Holmes wrote:
>>     So this shows the thread is still in the timed-wait. Assuming
>>     this is the native stack for the Java stack you showed
>>     previously, does the code here:
>>     /org.jgroups.protocols.FC.handleDownMessage(FC.java:549)/
>>     and upward cause the await to be called in a loop, or will the
>>     timeout lead to an abort of some kind?
>>     Probably best to take this off-list
>>     David
>>
>>         -----Original Message-----
>>         *From:* Adrian Tarau [mailto:adrian.tarau at gmail.com]
>>         *Sent:* Tuesday, 18 January 2011 8:31 AM
>>         *To:* dholmes at ieee.org
>>         *Cc:* David Holmes; concurrency-interest at cs.oswego.edu
>>         *Subject:* Re: [concurrency-interest] "parking to wait for"
>>         hangs forever
>>
>>         I just found a blog a few minutes ago and now I have a
>>         command line prepared :) .It dumps something like this(see
>>         bellow, this is a thread with a Condition.await() ). I
>>         couldn't find a document saying which Java thread id(as
>>         listed in thread dump) corresponds with what gdb is printing
>>         here but I found a match by trial & error :)
>>         nid(hexa)=LWP(decimal)
>>
>>         Thanks
>>
>>         gdb -ex "set pagination 0" -ex "thread apply all bt" --batch
>>         -p <pid> and
>>
>>         Thread 22 (Thread 0xb6a81b70 (LWP 28993)):
>>         #0  0xb77bc430 in __kernel_vsyscall ()
>>         #1  0xb7796342 in pthread_cond_timedwait@@GLIBC_2.3.2 () from
>>         /lib/tls/i686/cmov/libpthread.so.0
>>         #2  0xb77968a9 in pthread_cond_timedwait at GLIBC_2.0 () from
>>         /lib/tls/i686/cmov/libpthread.so.0
>>         #3  0xb7006dfa in Parker::park(bool, long long) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #4  0xb711daf0 in Unsafe_Park () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #5  0xb380a1e0 in ?? ()
>>         #6  0xb37fe10d in ?? ()
>>         #7  0xb37fe10d in ?? ()
>>         #8  0xb37fe3bd in ?? ()
>>         #9  0xb37fb34c in ?? ()
>>         #10 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*,
>>         methodHandle*, JavaCallArguments*, Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #11 0xb7005d58 in os::os_exception_wrapper(void
>>         (*)(JavaValue*, methodHandle*, JavaCallArguments*, Thread*),
>>         JavaValue*, methodHandle*, JavaCallArguments*, Thread*) ()
>>         from /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #12 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
>>         JavaCallArguments*, Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #13 0xb7055bcb in Reflection::invoke(instanceKlassHandle,
>>         methodHandle, Handle, bool, objArrayHandle, BasicType,
>>         objArrayHandle, bool, Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #14 0xb7058b31 in Reflection::invoke_method(oopDesc*, Handle,
>>         objArrayHandle, Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #15 0xb6ea9b0f in JVM_InvokeMethod () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #16 0xb6a18314 in
>>         Java_sun_reflect_NativeMethodAccessorImpl_invoke0 () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/libjava.so
>>         #17 0xb380a1e0 in ?? ()
>>         #18 0xb37fdfa7 in ?? ()
>>         #19 0xb37fdfa7 in ?? ()
>>         #20 0xb37fe483 in ?? ()
>>         #21 0xb37fdfa7 in ?? ()
>>         #22 0xb37fdfa7 in ?? ()
>>         #23 0xb37fdfa7 in ?? ()
>>         #24 0xb37fdfa7 in ?? ()
>>         #25 0xb37fe10d in ?? ()
>>         #26 0xb37fe10d in ?? ()
>>         #27 0xb37fe10d in ?? ()
>>         #28 0xb37fe10d in ?? ()
>>         #29 0xb37fe10d in ?? ()
>>         #30 0xb37fe10d in ?? ()
>>         #31 0xb37fe10d in ?? ()
>>         #32 0xb37fe10d in ?? ()
>>         #33 0xb37fe10d in ?? ()
>>         #34 0xb37fe10d in ?? ()
>>         #35 0xb37fe10d in ?? ()
>>         #36 0xb37fdfa7 in ?? ()
>>         #37 0xb37fe4c5 in ?? ()
>>         #38 0xb37fdfe9 in ?? ()
>>         #39 0xb37fb34c in ?? ()
>>         #40 0xb6e2dd80 in JavaCalls::call_helper(JavaValue*,
>>         methodHandle*, JavaCallArguments*, Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #41 0xb7005d58 in os::os_exception_wrapper(void
>>         (*)(JavaValue*, methodHandle*, JavaCallArguments*, Thread*),
>>         JavaValue*, methodHandle*, JavaCallArguments*, Thread*) ()
>>         from /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #42 0xb6e2dbdf in JavaCalls::call(JavaValue*, methodHandle,
>>         JavaCallArguments*, Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #43 0xb6e60163 in jni_invoke_static(JNIEnv_*, JavaValue*,
>>         _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*,
>>         Thread*) () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #44 0xb6e503bc in jni_CallStaticVoidMethod () from
>>         /work/jdk/jdk1.6.0_20/jre/lib/i386/server/libjvm.so
>>         #45 0x08049b98 in JavaMain ()
>>         #46 0xb779196e in start_thread () from
>>         /lib/tls/i686/cmov/libpthread.so.0
>>         #47 0xb76f1a4e in clone () from /lib/tls/i686/cmov/libc.so.6
>>
>>         On 01/17/2011 05:14 PM, David Holmes wrote:
>>>         Adrian,
>>>         You can attach gdb to the process:
>>>         gdb <path to java> <pid>
>>>         then use:
>>>         thread apply all bt
>>>         (bt is short for backtrace) to get all the thread stacks
>>>         See:
>>>         http://wiki.debian.org/HowToGetABacktrace
>>>         http://sourceware.org/gdb/current/onlinedocs/gdb/Backtrace.html
>>>         David
>>>
>>>             -----Original Message-----
>>>             *From:* Adrian Tarau [mailto:adrian.tarau at gmail.com]
>>>             *Sent:* Tuesday, 18 January 2011 4:55 AM
>>>             *To:* dholmes at ieee.org
>>>             *Cc:* David Holmes; concurrency-interest at cs.oswego.edu
>>>             *Subject:* Re: [concurrency-interest] "parking to wait
>>>             for" hangs forever
>>>
>>>
>>>             David,
>>>
>>>             I just have one process with 2 threads waiting in
>>>             await(xxx). How do I actually use gdb to extract the
>>>             stack trace? t at 67 I know for sure(99.9% sure :) ) it is
>>>             locked because I cannot send any message, not sure the
>>>             RMI thread....Successive dumps of the stack trace shows
>>>             both threads in the same state, several times.
>>>
>>>             Thanks.
>>>
>>>             /"Channel default Messaging" - Thread t at 67
>>>                java.lang.Thread.State: TIMED_WAITING
>>>                 at sun.misc.Unsafe.park(Native Method)
>>>                 - parking to wait for <664425> (a
>>>             java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>>>                 at
>>>             java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>>>                 at
>>>             java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2054)
>>>                 at
>>>             org.jgroups.protocols.FC.handleDownMessage(FC.java:549)
>>>                 at org.jgroups.protocols.FC.down(FC.java:423)
>>>                 at org.jgroups.protocols.FRAG2.down(FRAG2.java:154)
>>>                 at
>>>             org.jgroups.protocols.pbcast.STATE_TRANSFER.down(STATE_TRANSFER.java:215)
>>>                 at
>>>             org.jgroups.stack.ProtocolStack.down(ProtocolStack.java:894)
>>>                 at org.jgroups.JChannel.down(JChannel.java:1623)
>>>                 at org.jgroups.JChannel.send(JChannel.java:724)
>>>                 at
>>>             com.daxtechnologies.services.cluster.ChannelImpl.doSendMessage(ChannelImpl.java:321)
>>>                 at
>>>             com.daxtechnologies.services.cluster.ChannelImpl.access$700(ChannelImpl.java:33)
>>>                 at
>>>             com.daxtechnologies.services.cluster.ChannelImpl$MessageSenderWorker.run(ChannelImpl.java:683)
>>>
>>>                Locked ownable synchronizers:
>>>                 - None
>>>
>>>             "RMI Scheduler(0)" - Thread t at 66
>>>                java.lang.Thread.State: TIMED_WAITING
>>>                 at sun.misc.Unsafe.park(Native Method)
>>>                 - parking to wait for <40159> (a
>>>             java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
>>>                 at
>>>             java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
>>>                 at
>>>             java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
>>>                 at
>>>             java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
>>>                 at
>>>             java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:583)
>>>                 at
>>>             java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:576)
>>>                 at
>>>             java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
>>>                 at
>>>             java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
>>>                 at java.lang.Thread.run(Thread.java:619)
>>>
>>>                Locked ownable synchronizers:
>>>                 - None
>>>
>>>             On 01/15/2011 07:27 PM, David Hol/mes wrote:
>>>>             Adrian,
>>>>             Thanks for the additional information - very helpful.
>>>>             As Doug said a timed-await should not wait forever.
>>>>             6807483 was a problem encountered by one customer that
>>>>             did not reproduce anywhere else and which disappeared
>>>>             when the customer upgraded to Solaris 10u7.
>>>>             Can you attach gdb to the process to see what it
>>>>             reports in its stack trace? It may be that this is a
>>>>             case where GC is going into overdrive and so the system
>>>>             remains almost constantly at a safepoint and prevents
>>>>             any other threads from progressing. At the native level
>>>>             we may see that the thread has stopped waiting but has
>>>>             not been able to execute the code that would update its
>>>>             state to reflect that.
>>>>             Also can you try using an alternative GC? I know there
>>>>             are some situation where CMS continually runs, managing
>>>>             to free up tiny amounts of space, not enough for the
>>>>             requested allocation but enough to avoid deciding to
>>>>             throw OutOfMemoryError.
>>>>             Thanks,
>>>>             David Holmes
>>>>             -----Original Message-----
>>>>             *From:* concurrency-interest-bounces at cs.oswego.edu
>>>>             [mailto:concurrency-interest-bounces at cs.oswego.edu]*On
>>>>             Behalf Of *Adrian Tarau
>>>>             *Sent:* Sunday, 16 January 2011 7:44 AM
>>>>             *To:* concurrency-interest at cs.oswego.edu
>>>>             *Subject:* Re: [concurrency-interest] "parking to wait
>>>>             for" hangs forever
>>>>
>>>>                 We are using Linux boxes /Linux 2.6.18-194.el5 #1
>>>>                 SMP Mon Mar 29 22:10:29 EDT 2010 x86_64 x86_64
>>>>                 x86_64 GNU/Linux /with Java 1.6.0_20/(Java(TM) SE
>>>>                 Runtime Environment (build 1.6.0_20-b02)
>>>>                 Java HotSpot(TM) Server VM (build 16.3-b01, mixed
>>>>                 mode)/)
>>>>
>>>>                 We have ~ 140 (+several other processes) small Java
>>>>                 processes running with 64M heap on 9
>>>>                 servers(pre-production) and 30 Java
>>>>                 processes(+several other processes) running with
>>>>                 32M heap :) on 5 VM servers(development, don't
>>>>                 remember the virtualization platform, something
>>>>                 that is freely available in the CentOS repository).
>>>>
>>>>                 These processes are called "collectors". We use
>>>>                 Apache Commons VFS to connect to remote systems and
>>>>                 JGroups to send collector activities to other
>>>>                 processes(managers). Once in a blue moon, due to
>>>>                 some bug in Apache Commons VFS or in code written
>>>>                 by us around AC VFS(memory leaks) the heap is
>>>>                 consumed up to 99% and GC(default GC, not G1) kicks
>>>>                 in using ~ 50%-60% CPU(as VisualVM reports) but it
>>>>                 doesn't actually throw an OOM - somehow it manages
>>>>                 to clean up enough memory to avoid an OOM(jumping
>>>>                 from 1-2% CPU usage to 8%-9% CPU as reported by the
>>>>                 OS).
>>>>
>>>>                 When it reaches this state, the process runs very
>>>>                 slow(due to intensive GC activity) and after a
>>>>                 while it remains locked in a "parking to wait for
>>>>                 ..." in JGroups
>>>>
>>>>                 I will do an update to the latest JVM(update 23) on
>>>>                 some machines and see how it goes. I found a bug
>>>>                 (http://bugs.sun.com/view_bug.do?bug_id=6822370)
>>>>                 that seems similar with what we are experiencing
>>>>                 but it was fixed in 1.6.0_18. Also this bugs
>>>>                 http://bugs.sun.com/view_bug.do?bug_id=6807483
>>>>                 (java.util.concurrent.locks.Condition.await(timeout, units)
>>>>                 hangs forever) looks exactly like our issue but its
>>>>                 state is "11-Closed, Not Reproducible".
>>>>
>>>>                 Thanks.
>>>>
>>>>                 On 01/15/2011 10:39 AM, Doug Lea wrote:
>>>>>                 On 01/15/11 10:21, Adrian Tarau wrote:
>>>>>>                 Also I think it more then a coincidence that it
>>>>>>                 happened every time when the JVM
>>>>>>                 was closed to run OOM - no OOM exception in the
>>>>>>                 logs but when I looked at the
>>>>>>                 heap was full and GC was high on CPU.
>>>>>>
>>>>>>                 I will post this issue on the JGroups dev mailing
>>>>>>                 list but I would like to
>>>>>>                 understand why a call to await(timout) blocks
>>>>>>                 indefinitely? There is an
>>>>>>                 undocumented behaviour(like in certain situations
>>>>>>                 it still waits for a condition
>>>>>>                 to happen even if we specified a timeout?) or do
>>>>>>                 I misunderstand how await
>>>>>>                 should work?.
>>>>>
>>>>>                 No, a timed wait should not block forever.
>>>>>
>>>>>                 There have been some hotspot JVM lost wake-up JVM
>>>>>                 bugs, at least
>>>>>                 one of which was associated with GC (although
>>>>>                 possibly only
>>>>>                 using the "G1" collector). My best guess is that
>>>>>                 these are
>>>>>                 fixed in current (b123+) versions of openJDK7
>>>>>                 releases
>>>>>                 (http://dlc.sun.com.edgesuite.net/jdk7/binaries/index.html).
>>>>>
>>>>>                 I'm not sure when various fixes have or will be
>>>>>                 applied to
>>>>>                 JDK6 updates. (This also appears to be related to the
>>>>>                 FJ problems reported last week.) If I get more
>>>>>                 information,
>>>>>                 I will relay.
>>>>>
>>>>>                 -Doug
>>>>>
>>>>>
>>>>>                 _______________________________________________
>>>>>                 Concurrency-interest mailing list
>>>>>                 Concurrency-interest at cs.oswego.edu
>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110117/80a8ea61/attachment-0001.html>

From ach at quartetfs.com  Tue Jan 18 03:55:45 2011
From: ach at quartetfs.com (Antoine CHAMBILLE)
Date: Tue, 18 Jan 2011 09:55:45 +0100
Subject: [concurrency-interest] preFork() protected method in ForkJoinTask
Message-ID: <010d01cbb6ed$81566ba0$840342e0$@quartetfs.com>

Could we consider adding a < preFork() > protected method to the
ForkJoinTask, that would be called by the final fork() method before pushing
the task in the queue?

 

We have at least one use case for that: when some fork join tasks call
legacy code that rely on thread local contexts it would be nice to subclass
a fork join task that reads the thread local context during preFork() and
stores it internally, and then wraps the compute() call by setting that
context on the actual execution thread. This would also allow the
application to record statistics comparing the fork time and the computation
start time for instance.

 

-Antoine

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110118/75d022bd/attachment.html>

From tim at peierls.net  Tue Jan 18 08:46:57 2011
From: tim at peierls.net (Tim Peierls)
Date: Tue, 18 Jan 2011 08:46:57 -0500
Subject: [concurrency-interest] preFork() protected method in
	ForkJoinTask
In-Reply-To: <010d01cbb6ed$81566ba0$840342e0$@quartetfs.com>
References: <010d01cbb6ed$81566ba0$840342e0$@quartetfs.com>
Message-ID: <AANLkTikxPEamPgmwGH8nHumtqYer68_cda2ipJUip=ZT@mail.gmail.com>

I must be missing something. Can't you just have all your tasks extend some
common base that provides enhanced fork and wrapped compute methods?

  public MyTaskBase extends RecursiveAction {
      public MyTaskBase enhancedFork() {
          preFork();
          fork();
          return this;
      }
      protected final void compute() {
          preCompute();
          doCompute();
      }
      protected void preFork() {}
      protected void preCompute() {}
      protected abstract void doCompute();
  }

I don't think the folks who don't want this facility would care to pay for
the extra method calls just to support those who do.

--tim


On Tue, Jan 18, 2011 at 3:55 AM, Antoine CHAMBILLE <ach at quartetfs.com>wrote:

> Could we consider adding a ? preFork() ? protected method to the
> ForkJoinTask, that would be called by the final fork() method before pushing
> the task in the queue?
>
>
>
> We have at least one use case for that: when some fork join tasks call
> legacy code that rely on thread local contexts it would be nice to subclass
> a fork join task that reads the thread local context during preFork() and
> stores it internally, and then wraps the compute() call by setting that
> context on the actual execution thread. This would also allow the
> application to record statistics comparing the fork time and the computation
> start time for instance.
>
>
>
> -Antoine
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110118/d257b639/attachment.html>

From navin.jha at FXALL.com  Tue Jan 18 10:05:17 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Tue, 18 Jan 2011 10:05:17 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEKLIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBB3@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCCEKLIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBC7@NYEXCH02.fxall.com>

David,

The machine is using jiffies.

-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Saturday, January 15, 2011 4:50 AM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

Navin Jha writes:
> We upgraded one of our box to 5.4 linux as you suggested and that did it!
>
> We did't even have to change any setting.

Out of interest what clocksource is the updated system using?

David


> Thank you so much!
>
> Regards,
> Navin
>
>
> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Tuesday, January 11, 2011 6:04 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> > We don't see these files, is there another way to check this?
>
> As Mark says your kernel may be too old to expose these.
>
> > Also this the log that might tell you more:
> > [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> > Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> > 12 CPUs: passed.
>
> I'm very skeptical that an old kernel will be able to synchronize the TSC
> across 12 cores. Linux abandoned use of the TSC as the primary timesource
> for MP systems.
>
> http://lwn.net/Articles/209101/
>
> But maybe things have progressed since then. I know Solaris went to great
> lengths to do the TSC synchronization, and while it seems reasonable today
> there were a few bumps along the road.
>
> > We've tried to specify the clocksource in the
> > /boot/grub/grub.conf file.  We've been trying various
> > clocksources. Would you let us know how to set the appropriate
> > clocksource? Below is the grub.conf file.
>
> I'm not a linux expert but it appears that clock=hpet as the appropriate
> boot option should work. These log entries indicate tsc is used:
>
> Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
> Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
> hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
>
> David
> ------
>
> > [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> > # grub.conf generated by anaconda
> > #
> > # Note that you do not have to rerun grub after making changes to
> > this file
> > # NOTICE:  You have a /boot partition.  This means that
> > #          all kernel and initrd paths are relative to /boot/, eg.
> > #          root (hd0,0)
> > #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> > #          initrd /initrd-version.img
> > #boot=/dev/cciss/c0d0
> > default=1
> > timeout=5
> > splashimage=(hd0,0)/grub/splash.xpm.gz
> > hiddenmenu
> > title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
> >         root (hd0,0)
> >         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> > hda=ide-scsi clock=hpet clocksource=hpet
> >         initrd /initrd-2.6.9-78.0.8.EL.img
> > title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
> >         root (hd0,0)
> >         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
> >         initrd /initrd-2.6.9-78.ELlargesmp.img
> > title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
> >         root (hd0,0)
> >         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> > clock=hpet clocksource=hpet
> >         initrd /initrd-2.6.9-78.EL.img
> >
> >
> >
> >
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 6:12 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > I believe you need root access to check the clocksource (unless default
> > perms are modified):
> >
> > cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> >
> > to see what's available, and
> >
> > cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> >
> > to see what is in use.
> >
> > I was suggesting using nanoTime to measure the elapsed time, rather than
> > date/currentTimeMillis, as nanoTime should not be affected by
> time-of-day
> > adjustments. Which reminds me: check if ntp is running and if so turn it
> > off, if not turn it on, and see if that makes a difference.
> >
> > David
> >
> > -----Original Message-----
> > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > Sent: Tuesday, 11 January 2011 9:04 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> >
> > David,
> >
> > I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
> > results and they use nano time. Are you suggesting using nano
> time in any
> > other way? I will try them again after the switch to HPET to see
> > if there is
> > any difference. I have communicated your concern  about the use
> of TSC on
> > multi-processor systems to our unix support group.
> >
> > One more question, how do I make sure that the clock source is set up
> > correctly to HPET? Since it was done by the support group  I
> want to make
> > sure that they did it  correctly?
> >
> > -Navin
> >
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 5:41 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > Try using System.nanoTime to track things.
> >
> > BTW unless you have CPUs with reliable TSC then you should never
> > use TSC as
> > the clocksource on multi-processor systems. There are some OS specific
> > utilities from the chip vendors to fix TSC drift but I don't
> know what is
> > available for Linux. It's been a little while since I checked on
> > the current
> > state of this.
> >
> > David
> > -----Original Message-----
> > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > Sent: Tuesday, 11 January 2011 8:33 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> > David,
> > TSC was used by default (according to unix support folks, since I
> > don't have
> > access to configs on those machine), they switched it to use HPET
> > and I got
> > the same result. Below is the sample code I used to test. On
> one machine I
> > see a constant drift of about 15 milliseconds regardless of how
> > of long the
> > timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> > 2 cpus. On
> > the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
> >
> > import java.text.SimpleDateFormat;
> > import java.util.Calendar;
> > import java.util.Timer;
> > import java.util.TimerTask;
> >
> > public class TimerTest {
> >
> >          public static void main(String[] args) {
> >
> >                try {
> >                   long schedule=500;
> >                   if (args.length > 0)
> >                         schedule=Long.parseLong(args[0]);
> >                   System.out.println( " scheduling job\n");
> >                   Timer eodTimer = new Timer(true);
> >                   SimpleDateFormat simpleDateFormat = new
> > SimpleDateFormat("HH:mm:ss:S");
> >                   System.out.println(" Current time = " +
> > simpleDateFormat.format(Calendar.getInstance().getTime()));
> >                   eodTimer.scheduleAtFixedRate(new
> > TestTask(System.currentTimeMillis(),schedule,
> simpleDateFormat), schedule,
> > schedule);
> >                   Thread.sleep(Long.MAX_VALUE);
> >             } catch (Exception e) {
> >               System.out.println(e);
> >             }
> >
> >       }
> >
> >          private static class TestTask extends TimerTask {
> >
> >           long startTime;
> >           long sch;
> >           SimpleDateFormat simpleDateFormat;
> >           TestTask (long startTime,long schedule, SimpleDateFormat
> > simpleDateFormat)
> >           {
> >             this.startTime=startTime;
> >             sch=schedule;
> >             this.simpleDateFormat = simpleDateFormat;
> >           }
> >             public void run() {
> >                   long now = System.currentTimeMillis();
> >                   System.out.println(" End time     = " +
> > simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
> >                   System.out.println(" Actual diff  =
> "+(now-startTime)+ "
> > milliseconds, expected diff = " + sch + " milliseconds");
> >                   System.exit(1);
> >
> >             }
> >          }
> > }
> >
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 5:21 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > So I take it that HPET is already being used.
> >
> > The other possibility here is that it is not the timer that is
> > drifting but
> > the time source that you are using to measure/track when the
> timer fires.
> > How are you tracking that?
> >
> > David
> > -----Original Message-----
> > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > Sent: Tuesday, 11 January 2011 8:11 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> > No luck L
> >
> > Does having too many cpus effect this in anyway?
> >
> > The machine on which a sample test code works only has 2 cpus while the
> > machine on which we see a huge drift has 8 cpus.
> >
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 10, 2011 3:46 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > Check what clocksource the problematic system is using. If it
> is TSC then
> > switch to HPET.
> >
> > These things are difficult to diagnoze.
> >
> > David Holmes
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> Navin Jha
> > Sent: Tuesday, 11 January 2011 4:30 AM
> > To: Attila Szegedi
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Timer notification drifts
> > From what I have learned so far is that this is a common problem but the
> > drift is too much for us since it effects our trading date rollover J
> >
> > David Holmes has nice blog on clocks
> > (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> > and in his
> > blog he suggested to someone with a similar problem that he
> > should post the
> > problem here.
> >
> > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > Sent: Monday, January 10, 2011 1:24 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Timer notification drifts
> >
> > I see - you weren't specific about which API call you use, so I
> wanted to
> > root out the rookie mistake :-) Hm. a drift should definitely not
> > occur with
> > scheduleAtFixedRate, as far as I can tell. At this point, this
> > indeed start
> > to sound as a topic relevant for this group :-) Although I
> can't you help
> > past this stage (not much Linux system expertise), I guess
> > whoever wants to
> > look into this will want the JRE, Linux, and CPU versions of
> your system.
> >
> > On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
> >
> > This is exactly what we use. A sample code we tried works fine of
> > some linux
> > machines with a constant lag value (say 15 milliseconds) but
> > fails on other
> > linux machines. We are trying to find if there is something about those
> > linux machines that causes this. The machines on which this is happening
> > ironically have much better hardware (high end multi-core linux
> servers).
> >
> > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > Sent: Monday, January 10, 2011 1:03 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Timer notification drifts
> >
> > scheduleAtFixedRate should help:
> > <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
> html#sched
> uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
>
> On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
>
> Hi,
>
> Not sure if this is the right place to post this problem. We use
> java.util.Timer class for a notification that needs to happens every 24
> hours. We noticed that on some linux multi-core servers the notification
> occurs almost 11 seconds later. If we run for successive smaller durations
> say 1 hour, 2 hours, 3 hours. we notice that the lag does
> accumulate. So for
> 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
>
> The only solutions we can think of right now is to run the timer
> for smaller
> duration and restart it after that duration.
>
> Is there a solution/workaround for this problem?
>
> Regards,
> Navin
>
>
>
>




From davidcholmes at aapt.net.au  Tue Jan 18 16:44:17 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 19 Jan 2011 07:44:17 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBC7@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOELJIKAA.davidcholmes@aapt.net.au>

> The machine is using jiffies.

Strewth! That's not what you want! Get it changed to hpet.

David

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Saturday, January 15, 2011 4:50 AM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> Navin Jha writes:
> > We upgraded one of our box to 5.4 linux as you suggested and
> that did it!
> >
> > We did't even have to change any setting.
>
> Out of interest what clocksource is the updated system using?
>
> David
>
>
> > Thank you so much!
> >
> > Regards,
> > Navin
> >
> >
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Tuesday, January 11, 2011 6:04 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > > We don't see these files, is there another way to check this?
> >
> > As Mark says your kernel may be too old to expose these.
> >
> > > Also this the log that might tell you more:
> > > [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> > > Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> > > 12 CPUs: passed.
> >
> > I'm very skeptical that an old kernel will be able to
> synchronize the TSC
> > across 12 cores. Linux abandoned use of the TSC as the primary
> timesource
> > for MP systems.
> >
> > http://lwn.net/Articles/209101/
> >
> > But maybe things have progressed since then. I know Solaris
> went to great
> > lengths to do the TSC synchronization, and while it seems
> reasonable today
> > there were a few bumps along the road.
> >
> > > We've tried to specify the clocksource in the
> > > /boot/grub/grub.conf file.  We've been trying various
> > > clocksources. Would you let us know how to set the appropriate
> > > clocksource? Below is the grub.conf file.
> >
> > I'm not a linux expert but it appears that clock=hpet as the appropriate
> > boot option should work. These log entries indicate tsc is used:
> >
> > Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro
> root=LABEL=/
> > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
> > Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
> > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
> >
> > David
> > ------
> >
> > > [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> > > # grub.conf generated by anaconda
> > > #
> > > # Note that you do not have to rerun grub after making changes to
> > > this file
> > > # NOTICE:  You have a /boot partition.  This means that
> > > #          all kernel and initrd paths are relative to /boot/, eg.
> > > #          root (hd0,0)
> > > #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> > > #          initrd /initrd-version.img
> > > #boot=/dev/cciss/c0d0
> > > default=1
> > > timeout=5
> > > splashimage=(hd0,0)/grub/splash.xpm.gz
> > > hiddenmenu
> > > title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
> > >         root (hd0,0)
> > >         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> > > hda=ide-scsi clock=hpet clocksource=hpet
> > >         initrd /initrd-2.6.9-78.0.8.EL.img
> > > title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
> > >         root (hd0,0)
> > >         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> > > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
> > >         initrd /initrd-2.6.9-78.ELlargesmp.img
> > > title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
> > >         root (hd0,0)
> > >         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> > > clock=hpet clocksource=hpet
> > >         initrd /initrd-2.6.9-78.EL.img
> > >
> > >
> > >
> > >
> > > -----Original Message-----
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 6:12 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > I believe you need root access to check the clocksource
> (unless default
> > > perms are modified):
> > >
> > > cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> > >
> > > to see what's available, and
> > >
> > > cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> > >
> > > to see what is in use.
> > >
> > > I was suggesting using nanoTime to measure the elapsed time,
> rather than
> > > date/currentTimeMillis, as nanoTime should not be affected by
> > time-of-day
> > > adjustments. Which reminds me: check if ntp is running and if
> so turn it
> > > off, if not turn it on, and see if that makes a difference.
> > >
> > > David
> > >
> > > -----Original Message-----
> > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > Sent: Tuesday, 11 January 2011 9:04 AM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > >
> > > David,
> > >
> > > I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
> > > results and they use nano time. Are you suggesting using nano
> > time in any
> > > other way? I will try them again after the switch to HPET to see
> > > if there is
> > > any difference. I have communicated your concern  about the use
> > of TSC on
> > > multi-processor systems to our unix support group.
> > >
> > > One more question, how do I make sure that the clock source is set up
> > > correctly to HPET? Since it was done by the support group  I
> > want to make
> > > sure that they did it  correctly?
> > >
> > > -Navin
> > >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 5:41 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > Try using System.nanoTime to track things.
> > >
> > > BTW unless you have CPUs with reliable TSC then you should never
> > > use TSC as
> > > the clocksource on multi-processor systems. There are some OS specific
> > > utilities from the chip vendors to fix TSC drift but I don't
> > know what is
> > > available for Linux. It's been a little while since I checked on
> > > the current
> > > state of this.
> > >
> > > David
> > > -----Original Message-----
> > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > Sent: Tuesday, 11 January 2011 8:33 AM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > David,
> > > TSC was used by default (according to unix support folks, since I
> > > don't have
> > > access to configs on those machine), they switched it to use HPET
> > > and I got
> > > the same result. Below is the sample code I used to test. On
> > one machine I
> > > see a constant drift of about 15 milliseconds regardless of how
> > > of long the
> > > timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> > > 2 cpus. On
> > > the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
> > >
> > > import java.text.SimpleDateFormat;
> > > import java.util.Calendar;
> > > import java.util.Timer;
> > > import java.util.TimerTask;
> > >
> > > public class TimerTest {
> > >
> > >          public static void main(String[] args) {
> > >
> > >                try {
> > >                   long schedule=500;
> > >                   if (args.length > 0)
> > >                         schedule=Long.parseLong(args[0]);
> > >                   System.out.println( " scheduling job\n");
> > >                   Timer eodTimer = new Timer(true);
> > >                   SimpleDateFormat simpleDateFormat = new
> > > SimpleDateFormat("HH:mm:ss:S");
> > >                   System.out.println(" Current time = " +
> > > simpleDateFormat.format(Calendar.getInstance().getTime()));
> > >                   eodTimer.scheduleAtFixedRate(new
> > > TestTask(System.currentTimeMillis(),schedule,
> > simpleDateFormat), schedule,
> > > schedule);
> > >                   Thread.sleep(Long.MAX_VALUE);
> > >             } catch (Exception e) {
> > >               System.out.println(e);
> > >             }
> > >
> > >       }
> > >
> > >          private static class TestTask extends TimerTask {
> > >
> > >           long startTime;
> > >           long sch;
> > >           SimpleDateFormat simpleDateFormat;
> > >           TestTask (long startTime,long schedule, SimpleDateFormat
> > > simpleDateFormat)
> > >           {
> > >             this.startTime=startTime;
> > >             sch=schedule;
> > >             this.simpleDateFormat = simpleDateFormat;
> > >           }
> > >             public void run() {
> > >                   long now = System.currentTimeMillis();
> > >                   System.out.println(" End time     = " +
> > > simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
> > >                   System.out.println(" Actual diff  =
> > "+(now-startTime)+ "
> > > milliseconds, expected diff = " + sch + " milliseconds");
> > >                   System.exit(1);
> > >
> > >             }
> > >          }
> > > }
> > >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 5:21 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > So I take it that HPET is already being used.
> > >
> > > The other possibility here is that it is not the timer that is
> > > drifting but
> > > the time source that you are using to measure/track when the
> > timer fires.
> > > How are you tracking that?
> > >
> > > David
> > > -----Original Message-----
> > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > Sent: Tuesday, 11 January 2011 8:11 AM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > No luck L
> > >
> > > Does having too many cpus effect this in anyway?
> > >
> > > The machine on which a sample test code works only has 2 cpus
> while the
> > > machine on which we see a huge drift has 8 cpus.
> > >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 3:46 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > Check what clocksource the problematic system is using. If it
> > is TSC then
> > > switch to HPET.
> > >
> > > These things are difficult to diagnoze.
> > >
> > > David Holmes
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > Navin Jha
> > > Sent: Tuesday, 11 January 2011 4:30 AM
> > > To: Attila Szegedi
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Timer notification drifts
> > > From what I have learned so far is that this is a common
> problem but the
> > > drift is too much for us since it effects our trading date rollover J
> > >
> > > David Holmes has nice blog on clocks
> > > (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> > > and in his
> > > blog he suggested to someone with a similar problem that he
> > > should post the
> > > problem here.
> > >
> > > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > > Sent: Monday, January 10, 2011 1:24 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Timer notification drifts
> > >
> > > I see - you weren't specific about which API call you use, so I
> > wanted to
> > > root out the rookie mistake :-) Hm. a drift should definitely not
> > > occur with
> > > scheduleAtFixedRate, as far as I can tell. At this point, this
> > > indeed start
> > > to sound as a topic relevant for this group :-) Although I
> > can't you help
> > > past this stage (not much Linux system expertise), I guess
> > > whoever wants to
> > > look into this will want the JRE, Linux, and CPU versions of
> > your system.
> > >
> > > On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
> > >
> > > This is exactly what we use. A sample code we tried works fine of
> > > some linux
> > > machines with a constant lag value (say 15 milliseconds) but
> > > fails on other
> > > linux machines. We are trying to find if there is something
> about those
> > > linux machines that causes this. The machines on which this
> is happening
> > > ironically have much better hardware (high end multi-core linux
> > servers).
> > >
> > > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > > Sent: Monday, January 10, 2011 1:03 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Timer notification drifts
> > >
> > > scheduleAtFixedRate should help:
> > > <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
> > html#sched
> > uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
> >
> > On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
> >
> > Hi,
> >
> > Not sure if this is the right place to post this problem. We use
> > java.util.Timer class for a notification that needs to happens every 24
> > hours. We noticed that on some linux multi-core servers the notification
> > occurs almost 11 seconds later. If we run for successive
> smaller durations
> > say 1 hour, 2 hours, 3 hours. we notice that the lag does
> > accumulate. So for
> > 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
> >
> > The only solutions we can think of right now is to run the timer
> > for smaller
> > duration and restart it after that duration.
> >
> > Is there a solution/workaround for this problem?
> >
> > Regards,
> > Navin
> >
> >
> >
> >
>
>
>


From navin.jha at FXALL.com  Tue Jan 18 16:46:10 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Tue, 18 Jan 2011 16:46:10 -0500
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOELJIKAA.davidcholmes@aapt.net.au>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBC7@NYEXCH02.fxall.com>
	<NFBBKALFDCPFIDBNKAPCOELJIKAA.davidcholmes@aapt.net.au>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBE9@NYEXCH02.fxall.com>

Why is that? It seems to work fine.

-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Tuesday, January 18, 2011 4:44 PM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Timer notification drifts

> The machine is using jiffies.

Strewth! That's not what you want! Get it changed to hpet.

David

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Saturday, January 15, 2011 4:50 AM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> Navin Jha writes:
> > We upgraded one of our box to 5.4 linux as you suggested and
> that did it!
> >
> > We did't even have to change any setting.
>
> Out of interest what clocksource is the updated system using?
>
> David
>
>
> > Thank you so much!
> >
> > Regards,
> > Navin
> >
> >
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Tuesday, January 11, 2011 6:04 PM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > > We don't see these files, is there another way to check this?
> >
> > As Mark says your kernel may be too old to expose these.
> >
> > > Also this the log that might tell you more:
> > > [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> > > Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> > > 12 CPUs: passed.
> >
> > I'm very skeptical that an old kernel will be able to
> synchronize the TSC
> > across 12 cores. Linux abandoned use of the TSC as the primary
> timesource
> > for MP systems.
> >
> > http://lwn.net/Articles/209101/
> >
> > But maybe things have progressed since then. I know Solaris
> went to great
> > lengths to do the TSC synchronization, and while it seems
> reasonable today
> > there were a few bumps along the road.
> >
> > > We've tried to specify the clocksource in the
> > > /boot/grub/grub.conf file.  We've been trying various
> > > clocksources. Would you let us know how to set the appropriate
> > > clocksource? Below is the grub.conf file.
> >
> > I'm not a linux expert but it appears that clock=hpet as the appropriate
> > boot option should work. These log entries indicate tsc is used:
> >
> > Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro
> root=LABEL=/
> > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
> > Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
> > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
> >
> > David
> > ------
> >
> > > [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> > > # grub.conf generated by anaconda
> > > #
> > > # Note that you do not have to rerun grub after making changes to
> > > this file
> > > # NOTICE:  You have a /boot partition.  This means that
> > > #          all kernel and initrd paths are relative to /boot/, eg.
> > > #          root (hd0,0)
> > > #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> > > #          initrd /initrd-version.img
> > > #boot=/dev/cciss/c0d0
> > > default=1
> > > timeout=5
> > > splashimage=(hd0,0)/grub/splash.xpm.gz
> > > hiddenmenu
> > > title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
> > >         root (hd0,0)
> > >         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> > > hda=ide-scsi clock=hpet clocksource=hpet
> > >         initrd /initrd-2.6.9-78.0.8.EL.img
> > > title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
> > >         root (hd0,0)
> > >         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> > > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
> > >         initrd /initrd-2.6.9-78.ELlargesmp.img
> > > title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
> > >         root (hd0,0)
> > >         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> > > clock=hpet clocksource=hpet
> > >         initrd /initrd-2.6.9-78.EL.img
> > >
> > >
> > >
> > >
> > > -----Original Message-----
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 6:12 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > I believe you need root access to check the clocksource
> (unless default
> > > perms are modified):
> > >
> > > cat /sys/devices/system/clocksource/clocksource0/available_clocksource
> > >
> > > to see what's available, and
> > >
> > > cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> > >
> > > to see what is in use.
> > >
> > > I was suggesting using nanoTime to measure the elapsed time,
> rather than
> > > date/currentTimeMillis, as nanoTime should not be affected by
> > time-of-day
> > > adjustments. Which reminds me: check if ntp is running and if
> so turn it
> > > off, if not turn it on, and see if that makes a difference.
> > >
> > > David
> > >
> > > -----Original Message-----
> > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > Sent: Tuesday, 11 January 2011 9:04 AM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > >
> > > David,
> > >
> > > I tried LockSupport.park(..) and ScheduledThreadPoolExecutor with same
> > > results and they use nano time. Are you suggesting using nano
> > time in any
> > > other way? I will try them again after the switch to HPET to see
> > > if there is
> > > any difference. I have communicated your concern  about the use
> > of TSC on
> > > multi-processor systems to our unix support group.
> > >
> > > One more question, how do I make sure that the clock source is set up
> > > correctly to HPET? Since it was done by the support group  I
> > want to make
> > > sure that they did it  correctly?
> > >
> > > -Navin
> > >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 5:41 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > Try using System.nanoTime to track things.
> > >
> > > BTW unless you have CPUs with reliable TSC then you should never
> > > use TSC as
> > > the clocksource on multi-processor systems. There are some OS specific
> > > utilities from the chip vendors to fix TSC drift but I don't
> > know what is
> > > available for Linux. It's been a little while since I checked on
> > > the current
> > > state of this.
> > >
> > > David
> > > -----Original Message-----
> > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > Sent: Tuesday, 11 January 2011 8:33 AM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > David,
> > > TSC was used by default (according to unix support folks, since I
> > > don't have
> > > access to configs on those machine), they switched it to use HPET
> > > and I got
> > > the same result. Below is the sample code I used to test. On
> > one machine I
> > > see a constant drift of about 15 milliseconds regardless of how
> > > of long the
> > > timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> > > 2 cpus. On
> > > the machine with 8 cpus The drift was close to 11 seconds for 24 hrs.
> > >
> > > import java.text.SimpleDateFormat;
> > > import java.util.Calendar;
> > > import java.util.Timer;
> > > import java.util.TimerTask;
> > >
> > > public class TimerTest {
> > >
> > >          public static void main(String[] args) {
> > >
> > >                try {
> > >                   long schedule=500;
> > >                   if (args.length > 0)
> > >                         schedule=Long.parseLong(args[0]);
> > >                   System.out.println( " scheduling job\n");
> > >                   Timer eodTimer = new Timer(true);
> > >                   SimpleDateFormat simpleDateFormat = new
> > > SimpleDateFormat("HH:mm:ss:S");
> > >                   System.out.println(" Current time = " +
> > > simpleDateFormat.format(Calendar.getInstance().getTime()));
> > >                   eodTimer.scheduleAtFixedRate(new
> > > TestTask(System.currentTimeMillis(),schedule,
> > simpleDateFormat), schedule,
> > > schedule);
> > >                   Thread.sleep(Long.MAX_VALUE);
> > >             } catch (Exception e) {
> > >               System.out.println(e);
> > >             }
> > >
> > >       }
> > >
> > >          private static class TestTask extends TimerTask {
> > >
> > >           long startTime;
> > >           long sch;
> > >           SimpleDateFormat simpleDateFormat;
> > >           TestTask (long startTime,long schedule, SimpleDateFormat
> > > simpleDateFormat)
> > >           {
> > >             this.startTime=startTime;
> > >             sch=schedule;
> > >             this.simpleDateFormat = simpleDateFormat;
> > >           }
> > >             public void run() {
> > >                   long now = System.currentTimeMillis();
> > >                   System.out.println(" End time     = " +
> > > simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
> > >                   System.out.println(" Actual diff  =
> > "+(now-startTime)+ "
> > > milliseconds, expected diff = " + sch + " milliseconds");
> > >                   System.exit(1);
> > >
> > >             }
> > >          }
> > > }
> > >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 5:21 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > So I take it that HPET is already being used.
> > >
> > > The other possibility here is that it is not the timer that is
> > > drifting but
> > > the time source that you are using to measure/track when the
> > timer fires.
> > > How are you tracking that?
> > >
> > > David
> > > -----Original Message-----
> > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > Sent: Tuesday, 11 January 2011 8:11 AM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > No luck L
> > >
> > > Does having too many cpus effect this in anyway?
> > >
> > > The machine on which a sample test code works only has 2 cpus
> while the
> > > machine on which we see a huge drift has 8 cpus.
> > >
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 10, 2011 3:46 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > Check what clocksource the problematic system is using. If it
> > is TSC then
> > > switch to HPET.
> > >
> > > These things are difficult to diagnoze.
> > >
> > > David Holmes
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > Navin Jha
> > > Sent: Tuesday, 11 January 2011 4:30 AM
> > > To: Attila Szegedi
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Timer notification drifts
> > > From what I have learned so far is that this is a common
> problem but the
> > > drift is too much for us since it effects our trading date rollover J
> > >
> > > David Holmes has nice blog on clocks
> > > (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> > > and in his
> > > blog he suggested to someone with a similar problem that he
> > > should post the
> > > problem here.
> > >
> > > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > > Sent: Monday, January 10, 2011 1:24 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Timer notification drifts
> > >
> > > I see - you weren't specific about which API call you use, so I
> > wanted to
> > > root out the rookie mistake :-) Hm. a drift should definitely not
> > > occur with
> > > scheduleAtFixedRate, as far as I can tell. At this point, this
> > > indeed start
> > > to sound as a topic relevant for this group :-) Although I
> > can't you help
> > > past this stage (not much Linux system expertise), I guess
> > > whoever wants to
> > > look into this will want the JRE, Linux, and CPU versions of
> > your system.
> > >
> > > On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
> > >
> > > This is exactly what we use. A sample code we tried works fine of
> > > some linux
> > > machines with a constant lag value (say 15 milliseconds) but
> > > fails on other
> > > linux machines. We are trying to find if there is something
> about those
> > > linux machines that causes this. The machines on which this
> is happening
> > > ironically have much better hardware (high end multi-core linux
> > servers).
> > >
> > > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > > Sent: Monday, January 10, 2011 1:03 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Timer notification drifts
> > >
> > > scheduleAtFixedRate should help:
> > > <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
> > html#sched
> > uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
> >
> > On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
> >
> > Hi,
> >
> > Not sure if this is the right place to post this problem. We use
> > java.util.Timer class for a notification that needs to happens every 24
> > hours. We noticed that on some linux multi-core servers the notification
> > occurs almost 11 seconds later. If we run for successive
> smaller durations
> > say 1 hour, 2 hours, 3 hours. we notice that the lag does
> > accumulate. So for
> > 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
> >
> > The only solutions we can think of right now is to run the timer
> > for smaller
> > duration and restart it after that duration.
> >
> > Is there a solution/workaround for this problem?
> >
> > Regards,
> > Navin
> >
> >
> >
> >
>
>
>




From davidcholmes at aapt.net.au  Tue Jan 18 17:02:31 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 19 Jan 2011 08:02:31 +1000
Subject: [concurrency-interest] Timer notification drifts
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEBE9@NYEXCH02.fxall.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKELKIKAA.davidcholmes@aapt.net.au>

> Why is that? It seems to work fine.

jiffies is low resolution based on the system tick. Fine for time-of-day,
but may not be suitable if you need higher resolution timing capabilities.

Also beware never to set NO_HZ at the same time (google for it :) ).

But if it works for you then ...

Cheers,
David

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Tuesday, January 18, 2011 4:44 PM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Timer notification drifts
>
> > The machine is using jiffies.
>
> Strewth! That's not what you want! Get it changed to hpet.
>
> David
>
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Saturday, January 15, 2011 4:50 AM
> > To: Navin Jha
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Timer notification drifts
> >
> > Navin Jha writes:
> > > We upgraded one of our box to 5.4 linux as you suggested and
> > that did it!
> > >
> > > We did't even have to change any setting.
> >
> > Out of interest what clocksource is the updated system using?
> >
> > David
> >
> >
> > > Thank you so much!
> > >
> > > Regards,
> > > Navin
> > >
> > >
> > > -----Original Message-----
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Tuesday, January 11, 2011 6:04 PM
> > > To: Navin Jha
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Timer notification drifts
> > >
> > > > We don't see these files, is there another way to check this?
> > >
> > > As Mark says your kernel may be too old to expose these.
> > >
> > > > Also this the log that might tell you more:
> > > > [11:16:23][root at numpintapp15:~]$ grep -i tsc /var/log/messages
> > > > Jan 10 16:51:18 numpintapp15 checking TSC synchronization across
> > > > 12 CPUs: passed.
> > >
> > > I'm very skeptical that an old kernel will be able to
> > synchronize the TSC
> > > across 12 cores. Linux abandoned use of the TSC as the primary
> > timesource
> > > for MP systems.
> > >
> > > http://lwn.net/Articles/209101/
> > >
> > > But maybe things have progressed since then. I know Solaris
> > went to great
> > > lengths to do the TSC synchronization, and while it seems
> > reasonable today
> > > there were a few bumps along the road.
> > >
> > > > We've tried to specify the clocksource in the
> > > > /boot/grub/grub.conf file.  We've been trying various
> > > > clocksources. Would you let us know how to set the appropriate
> > > > clocksource? Below is the grub.conf file.
> > >
> > > I'm not a linux expert but it appears that clock=hpet as the
> appropriate
> > > boot option should work. These log entries indicate tsc is used:
> > >
> > > Jan 10 18:44:16 numpintapp15 Bootdata ok (command line is ro
> > root=LABEL=/
> > > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc)
> > > Jan 10 18:44:16 numpintapp15 Kernel command line: ro root=LABEL=/
> > > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc console=tty0
> > >
> > > David
> > > ------
> > >
> > > > [11:17:43][root at numpintapp15:~]$ cat /boot/grub/grub.conf
> > > > # grub.conf generated by anaconda
> > > > #
> > > > # Note that you do not have to rerun grub after making changes to
> > > > this file
> > > > # NOTICE:  You have a /boot partition.  This means that
> > > > #          all kernel and initrd paths are relative to /boot/, eg.
> > > > #          root (hd0,0)
> > > > #          kernel /vmlinuz-version ro root=/dev/cciss/c0d0p6
> > > > #          initrd /initrd-version.img
> > > > #boot=/dev/cciss/c0d0
> > > > default=1
> > > > timeout=5
> > > > splashimage=(hd0,0)/grub/splash.xpm.gz
> > > > hiddenmenu
> > > > title Red Hat Enterprise Linux AS (2.6.9-78.0.8.EL)
> > > >         root (hd0,0)
> > > >         kernel /vmlinuz-2.6.9-78.0.8.EL ro root=LABEL=/
> > > > hda=ide-scsi clock=hpet clocksource=hpet
> > > >         initrd /initrd-2.6.9-78.0.8.EL.img
> > > > title Red Hat Enterprise Linux AS (2.6.9-78.ELlargesmp)
> > > >         root (hd0,0)
> > > >         kernel /vmlinuz-2.6.9-78.ELlargesmp ro root=LABEL=/
> > > > hda=ide-scsi hpet=disable pnpacpi=off clock=tsc
> > > >         initrd /initrd-2.6.9-78.ELlargesmp.img
> > > > title Red Hat Enterprise Linux AS-up (2.6.9-78.EL)
> > > >         root (hd0,0)
> > > >         kernel /vmlinuz-2.6.9-78.EL ro root=LABEL=/ hda=ide-scsi
> > > > clock=hpet clocksource=hpet
> > > >         initrd /initrd-2.6.9-78.EL.img
> > > >
> > > >
> > > >
> > > >
> > > > -----Original Message-----
> > > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > > Sent: Monday, January 10, 2011 6:12 PM
> > > > To: Navin Jha
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > >
> > > > I believe you need root access to check the clocksource
> > (unless default
> > > > perms are modified):
> > > >
> > > > cat
> /sys/devices/system/clocksource/clocksource0/available_clocksource
> > > >
> > > > to see what's available, and
> > > >
> > > > cat /sys/devices/system/clocksource/clocksource0/current_clocksource
> > > >
> > > > to see what is in use.
> > > >
> > > > I was suggesting using nanoTime to measure the elapsed time,
> > rather than
> > > > date/currentTimeMillis, as nanoTime should not be affected by
> > > time-of-day
> > > > adjustments. Which reminds me: check if ntp is running and if
> > so turn it
> > > > off, if not turn it on, and see if that makes a difference.
> > > >
> > > > David
> > > >
> > > > -----Original Message-----
> > > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > > Sent: Tuesday, 11 January 2011 9:04 AM
> > > > To: dholmes at ieee.org
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > >
> > > >
> > > > David,
> > > >
> > > > I tried LockSupport.park(..) and
> ScheduledThreadPoolExecutor with same
> > > > results and they use nano time. Are you suggesting using nano
> > > time in any
> > > > other way? I will try them again after the switch to HPET to see
> > > > if there is
> > > > any difference. I have communicated your concern  about the use
> > > of TSC on
> > > > multi-processor systems to our unix support group.
> > > >
> > > > One more question, how do I make sure that the clock source
> is set up
> > > > correctly to HPET? Since it was done by the support group  I
> > > want to make
> > > > sure that they did it  correctly?
> > > >
> > > > -Navin
> > > >
> > > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > > Sent: Monday, January 10, 2011 5:41 PM
> > > > To: Navin Jha
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > >
> > > > Try using System.nanoTime to track things.
> > > >
> > > > BTW unless you have CPUs with reliable TSC then you should never
> > > > use TSC as
> > > > the clocksource on multi-processor systems. There are some
> OS specific
> > > > utilities from the chip vendors to fix TSC drift but I don't
> > > know what is
> > > > available for Linux. It's been a little while since I checked on
> > > > the current
> > > > state of this.
> > > >
> > > > David
> > > > -----Original Message-----
> > > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > > Sent: Tuesday, 11 January 2011 8:33 AM
> > > > To: dholmes at ieee.org
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > > David,
> > > > TSC was used by default (according to unix support folks, since I
> > > > don't have
> > > > access to configs on those machine), they switched it to use HPET
> > > > and I got
> > > > the same result. Below is the sample code I used to test. On
> > > one machine I
> > > > see a constant drift of about 15 milliseconds regardless of how
> > > > of long the
> > > > timer runs (I ran it for 1 hr, 2 hrs and 24hrs). This machine has
> > > > 2 cpus. On
> > > > the machine with 8 cpus The drift was close to 11 seconds
> for 24 hrs.
> > > >
> > > > import java.text.SimpleDateFormat;
> > > > import java.util.Calendar;
> > > > import java.util.Timer;
> > > > import java.util.TimerTask;
> > > >
> > > > public class TimerTest {
> > > >
> > > >          public static void main(String[] args) {
> > > >
> > > >                try {
> > > >                   long schedule=500;
> > > >                   if (args.length > 0)
> > > >                         schedule=Long.parseLong(args[0]);
> > > >                   System.out.println( " scheduling job\n");
> > > >                   Timer eodTimer = new Timer(true);
> > > >                   SimpleDateFormat simpleDateFormat = new
> > > > SimpleDateFormat("HH:mm:ss:S");
> > > >                   System.out.println(" Current time = " +
> > > > simpleDateFormat.format(Calendar.getInstance().getTime()));
> > > >                   eodTimer.scheduleAtFixedRate(new
> > > > TestTask(System.currentTimeMillis(),schedule,
> > > simpleDateFormat), schedule,
> > > > schedule);
> > > >                   Thread.sleep(Long.MAX_VALUE);
> > > >             } catch (Exception e) {
> > > >               System.out.println(e);
> > > >             }
> > > >
> > > >       }
> > > >
> > > >          private static class TestTask extends TimerTask {
> > > >
> > > >           long startTime;
> > > >           long sch;
> > > >           SimpleDateFormat simpleDateFormat;
> > > >           TestTask (long startTime,long schedule, SimpleDateFormat
> > > > simpleDateFormat)
> > > >           {
> > > >             this.startTime=startTime;
> > > >             sch=schedule;
> > > >             this.simpleDateFormat = simpleDateFormat;
> > > >           }
> > > >             public void run() {
> > > >                   long now = System.currentTimeMillis();
> > > >                   System.out.println(" End time     = " +
> > > > simpleDateFormat.format(Calendar.getInstance().getTime()) + "\n");
> > > >                   System.out.println(" Actual diff  =
> > > "+(now-startTime)+ "
> > > > milliseconds, expected diff = " + sch + " milliseconds");
> > > >                   System.exit(1);
> > > >
> > > >             }
> > > >          }
> > > > }
> > > >
> > > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > > Sent: Monday, January 10, 2011 5:21 PM
> > > > To: Navin Jha
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > >
> > > > So I take it that HPET is already being used.
> > > >
> > > > The other possibility here is that it is not the timer that is
> > > > drifting but
> > > > the time source that you are using to measure/track when the
> > > timer fires.
> > > > How are you tracking that?
> > > >
> > > > David
> > > > -----Original Message-----
> > > > From: Navin Jha [mailto:navin.jha at FXALL.com]
> > > > Sent: Tuesday, 11 January 2011 8:11 AM
> > > > To: dholmes at ieee.org
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > > No luck L
> > > >
> > > > Does having too many cpus effect this in anyway?
> > > >
> > > > The machine on which a sample test code works only has 2 cpus
> > while the
> > > > machine on which we see a huge drift has 8 cpus.
> > > >
> > > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > > Sent: Monday, January 10, 2011 3:46 PM
> > > > To: Navin Jha
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: RE: [concurrency-interest] Timer notification drifts
> > > >
> > > > Check what clocksource the problematic system is using. If it
> > > is TSC then
> > > > switch to HPET.
> > > >
> > > > These things are difficult to diagnoze.
> > > >
> > > > David Holmes
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > > Navin Jha
> > > > Sent: Tuesday, 11 January 2011 4:30 AM
> > > > To: Attila Szegedi
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: Re: [concurrency-interest] Timer notification drifts
> > > > From what I have learned so far is that this is a common
> > problem but the
> > > > drift is too much for us since it effects our trading date
> rollover J
> > > >
> > > > David Holmes has nice blog on clocks
> > > > (http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks)
> > > > and in his
> > > > blog he suggested to someone with a similar problem that he
> > > > should post the
> > > > problem here.
> > > >
> > > > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > > > Sent: Monday, January 10, 2011 1:24 PM
> > > > To: Navin Jha
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: Re: [concurrency-interest] Timer notification drifts
> > > >
> > > > I see - you weren't specific about which API call you use, so I
> > > wanted to
> > > > root out the rookie mistake :-) Hm. a drift should definitely not
> > > > occur with
> > > > scheduleAtFixedRate, as far as I can tell. At this point, this
> > > > indeed start
> > > > to sound as a topic relevant for this group :-) Although I
> > > can't you help
> > > > past this stage (not much Linux system expertise), I guess
> > > > whoever wants to
> > > > look into this will want the JRE, Linux, and CPU versions of
> > > your system.
> > > >
> > > > On Jan 10, 2011, at 10:09 AM, Navin Jha wrote:
> > > >
> > > > This is exactly what we use. A sample code we tried works fine of
> > > > some linux
> > > > machines with a constant lag value (say 15 milliseconds) but
> > > > fails on other
> > > > linux machines. We are trying to find if there is something
> > about those
> > > > linux machines that causes this. The machines on which this
> > is happening
> > > > ironically have much better hardware (high end multi-core linux
> > > servers).
> > > >
> > > > From: Attila Szegedi [mailto:szegedia at gmail.com]
> > > > Sent: Monday, January 10, 2011 1:03 PM
> > > > To: Navin Jha
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: Re: [concurrency-interest] Timer notification drifts
> > > >
> > > > scheduleAtFixedRate should help:
> > > > <http://download.oracle.com/javase/1.4.2/docs/api/java/util/Timer.
> > > html#sched
> > > uleAtFixedRate(java.util.TimerTask,%20java.util.Date,%20long)>
> > >
> > > On Jan 10, 2011, at 9:32 AM, Navin Jha wrote:
> > >
> > > Hi,
> > >
> > > Not sure if this is the right place to post this problem. We use
> > > java.util.Timer class for a notification that needs to
> happens every 24
> > > hours. We noticed that on some linux multi-core servers the
> notification
> > > occurs almost 11 seconds later. If we run for successive
> > smaller durations
> > > say 1 hour, 2 hours, 3 hours. we notice that the lag does
> > > accumulate. So for
> > > 1 hour it is 600 milliseconds, for 2 hours it is 1.2 seconds etc..
> > >
> > > The only solutions we can think of right now is to run the timer
> > > for smaller
> > > duration and restart it after that duration.
> > >
> > > Is there a solution/workaround for this problem?
> > >
> > > Regards,
> > > Navin
> > >
> > >
> > >
> > >
> >
> >
> >
>
>
>


From ach at quartetfs.com  Wed Jan 19 03:53:49 2011
From: ach at quartetfs.com (Antoine CHAMBILLE)
Date: Wed, 19 Jan 2011 09:53:49 +0100
Subject: [concurrency-interest] preFork() protected method in
	ForkJoinTask
In-Reply-To: <AANLkTikxPEamPgmwGH8nHumtqYer68_cda2ipJUip=ZT@mail.gmail.com>
References: <010d01cbb6ed$81566ba0$840342e0$@quartetfs.com>
	<AANLkTikxPEamPgmwGH8nHumtqYer68_cda2ipJUip=ZT@mail.gmail.com>
Message-ID: <016901cbb7b6$64fc0540$2ef40fc0$@quartetfs.com>

Hi Tim,

 

Thanks for the comment, I guess you are right, that is of course how we do
it right now.

 

If was asking myself whether that was a popular use case that could deserve
base API support.

 

Let's forget about it.

 

-Antoine

 

 

From: tpeierls at gmail.com [mailto:tpeierls at gmail.com] On Behalf Of Tim
Peierls
Sent: 18 January 2011 14:47
To: Antoine CHAMBILLE
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] preFork() protected method in
ForkJoinTask

 

I must be missing something. Can't you just have all your tasks extend some
common base that provides enhanced fork and wrapped compute methods?

 

  public MyTaskBase extends RecursiveAction {

      public MyTaskBase enhancedFork() {

          preFork();

          fork();

          return this;

      }

      protected final void compute() {

          preCompute();

          doCompute();

      }

      protected void preFork() {}

      protected void preCompute() {}

      protected abstract void doCompute();

  }

I don't think the folks who don't want this facility would care to pay for
the extra method calls just to support those who do.

 

--tim

 

 

On Tue, Jan 18, 2011 at 3:55 AM, Antoine CHAMBILLE <ach at quartetfs.com>
wrote:

Could we consider adding a < preFork() > protected method to the
ForkJoinTask, that would be called by the final fork() method before pushing
the task in the queue?

 

We have at least one use case for that: when some fork join tasks call
legacy code that rely on thread local contexts it would be nice to subclass
a fork join task that reads the thread local context during preFork() and
stores it internally, and then wraps the compute() call by setting that
context on the actual execution thread. This would also allow the
application to record statistics comparing the fork time and the computation
start time for instance.

 

-Antoine


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110119/45b32663/attachment.html>

From dl at cs.oswego.edu  Wed Jan 19 06:59:06 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 19 Jan 2011 06:59:06 -0500 (EST)
Subject: [concurrency-interest] preFork() protected method in
 ForkJoinTask
In-Reply-To: <016901cbb7b6$64fc0540$2ef40fc0$@quartetfs.com>
References: <010d01cbb6ed$81566ba0$840342e0$@quartetfs.com>
	<AANLkTikxPEamPgmwGH8nHumtqYer68_cda2ipJUip=ZT@mail.gmail.com>
	<016901cbb7b6$64fc0540$2ef40fc0$@quartetfs.com>
Message-ID: <41316.174.119.17.999.17.99.1295438346.squirrel@altair.cs.oswego.edu>


> On Tue, Jan 18, 2011 at 3:55 AM, Antoine CHAMBILLE <ach at quartetfs.com>
> wrote:
>
>
> We have at least one use case for that: when some fork join tasks call
> legacy code that rely on thread local contexts it would be nice to
> subclass
> a fork join task that reads the thread local context ...

We do supply a different way to get this kind of effect, at
least sometimes: You can subclass ForkJoinWorkerThread and
supply a factory so that your threads are used in a given pool.
If these threads can be made to hold the needed, you are OK.

-Doug








From gdenys at yahoo.com  Wed Jan 19 08:45:13 2011
From: gdenys at yahoo.com (Geert Denys)
Date: Wed, 19 Jan 2011 05:45:13 -0800 (PST)
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>,
	<AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
	<DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>
Message-ID: <801632.6198.qm@web161204.mail.bf1.yahoo.com>

You may want to check out SEDA at http://www.eecs.harvard.edu/~mdw/proj/seda/.
Although the project is not active anymore, it seems relevant to the workload 
issues you're facing. One of the core concepts is to protect critical resources 
by a tunable stage (basically a threadpool), fronted by a queue. This prevents 
resources from being swamped and allows graceful handling of overload 
situations.

- Geert.


      

From Philip.Lee at smartstream-stp.com  Wed Jan 19 10:16:04 2011
From: Philip.Lee at smartstream-stp.com (Philip Lee)
Date: Wed, 19 Jan 2011 15:16:04 +0000
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <801632.6198.qm@web161204.mail.bf1.yahoo.com>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>,
	<AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
	<DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>,
	<801632.6198.qm@web161204.mail.bf1.yahoo.com>
Message-ID: <62EC155DFFC99A4EB1D3BBC6CD0A395D7240BB47@briexch0002.sst.stp>

Mulesoft have open source / commercial supported versions of Mule which is based on the SEDA work.

http://www.mulesoft.org/

- Phil.
________________________________________
From: concurrency-interest-bounces at cs.oswego.edu [concurrency-interest-bounces at cs.oswego.edu] on behalf of Geert Denys [gdenys at yahoo.com]
Sent: 19 January 2011 13:45
To: Bryan Thompson; concurrency-interest
Subject: Re: [concurrency-interest] Spacing out a workload burst?

You may want to check out SEDA at http://www.eecs.harvard.edu/~mdw/proj/seda/.
Although the project is not active anymore, it seems relevant to the workload
issues you're facing. One of the core concepts is to protect critical resources
by a tunable stage (basically a threadpool), fronted by a queue. This prevents
resources from being swamped and allows graceful handling of overload
situations.

- Geert.



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
________________________________
 The information in this email is confidential and may be legally privileged. It is intended solely for the addressee. Access to this email by anyone else is unauthorised. If you are not the intended recipient, any disclosure, copying, distribution or any action taken or omitted to be taken in reliance on it, is prohibited and may be unlawful.
SmartStream Technologies Ltd. is a company incorporated in England and Wales. Registered office: St Helen's, 1 Undershaft, London, EC3A 8EE. Registration No. 2285524


From ben_manes at yahoo.com  Wed Jan 19 19:48:43 2011
From: ben_manes at yahoo.com (Ben Manes)
Date: Wed, 19 Jan 2011 16:48:43 -0800 (PST)
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <62EC155DFFC99A4EB1D3BBC6CD0A395D7240BB47@briexch0002.sst.stp>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>,
	<AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
	<DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>,
	<801632.6198.qm@web161204.mail.bf1.yahoo.com>
	<62EC155DFFC99A4EB1D3BBC6CD0A395D7240BB47@briexch0002.sst.stp>
Message-ID: <223618.40585.qm@web38802.mail.mud.yahoo.com>

The book Release-It! does a good job covering some of these operational issues 
and general practices.




________________________________
From: Philip Lee <Philip.Lee at smartstream-stp.com>
To: concurrency-interest <concurrency-interest at cs.oswego.edu>
Sent: Wed, January 19, 2011 7:16:04 AM
Subject: Re: [concurrency-interest] Spacing out a workload burst?

Mulesoft have open source / commercial supported versions of Mule which is based 
on the SEDA work.

http://www.mulesoft.org/

- Phil.
________________________________________
From: concurrency-interest-bounces at cs.oswego.edu 
[concurrency-interest-bounces at cs.oswego.edu] on behalf of Geert Denys 
[gdenys at yahoo.com]
Sent: 19 January 2011 13:45
To: Bryan Thompson; concurrency-interest
Subject: Re: [concurrency-interest] Spacing out a workload burst?

You may want to check out SEDA at http://www.eecs.harvard.edu/~mdw/proj/seda/.
Although the project is not active anymore, it seems relevant to the workload
issues you're facing. One of the core concepts is to protect critical resources
by a tunable stage (basically a threadpool), fronted by a queue. This prevents
resources from being swamped and allows graceful handling of overload
situations.

- Geert.



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
________________________________
The information in this email is confidential and may be legally privileged. It 
is intended solely for the addressee. Access to this email by anyone else is 
unauthorised. If you are not the intended recipient, any disclosure, copying, 
distribution or any action taken or omitted to be taken in reliance on it, is 
prohibited and may be unlawful.
SmartStream Technologies Ltd. is a company incorporated in England and Wales. 
Registered office: St Helen's, 1 Undershaft, London, EC3A 8EE. Registration No. 
2285524

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110119/4666475b/attachment.html>

From gregg at cytetech.com  Wed Jan 19 22:30:11 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 19 Jan 2011 21:30:11 -0600
Subject: [concurrency-interest] Spacing out a workload burst?
In-Reply-To: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>
References: <DE10B00CCE0DC54883734F3060AC9ED4525F2FDFC8@AUSP01VMBX06.collaborationhost.net>,
	<AANLkTi=H1y3a8Zs-_--j0Hrz7VurRaZa4ztyFx3NWmF6@mail.gmail.com>
	<DE10B00CCE0DC54883734F3060AC9ED4525F2FDFCB@AUSP01VMBX06.collaborationhost.net>
Message-ID: <4D37AC43.9080601@cytetech.com>

On 1/16/2011 4:22 PM, Bryan Thompson wrote:
> Joe,
>
> I am using a fixed size thread pool backed by a queue.  What I am looking
> to do is space out the onset of the task processing on the service in order
> to avoid having them all spike the resource demand at nearly the same moment.
> Essentially, even though the original set of requests appears in a burst
> and each set of satisfied requests brings on another burst, I would like
> the service to stagger out the requests so they begin to appear at times
> predicted by a uniform distribution rather than centered around a periodic
> task arrival spike.

The basic issue, is that in any system, the slowest point through the system 
will provide the highest contention and cause the most number of entities to 
gather there.  The simple math is that you can add all of the times of each 
phase of processing, and then use that as the denominator of a fraction with the 
time of each segment as the numerator.  That will tell you the fraction of the 
total participants which will bes grouped at each phase.  You can then use this 
to create measurement values that you can use to check that the system is 
maintaining your expected latency/throughput.

You can do something with "delays" to try and space things out more, but the 
faster phases will still allow requests to come back around to the slower phases 
fast enough that you can't "change" the system behavior measurably.  You will 
just cause the appropriate number of tasks to group at the delay point.

If I have phases with execution time unit values such as the following:

2 5 2 8 20 2 5

then the total time through is 44 time units.  20/44 of the total participants 
will be at the phase that takes 20 time units on the average, in a continuous 
system.

If you have 20 tasks, and only 10 will fit through the system at any time, then 
you can use throttling such as the thread pool you say you are using to control 
how many are running at any time.  But, then you've changed the picture to be

2 5 2 8 20*(n/10) 20 2 5

where n is the number of participants, because as soon as there are more than 10 
participants, then the extra tasks, will have to wait (20 * (n/10)) time units 
for someone to get through the phase that takes 20 time units, and then they 
will take another 20 time units to get through that point.

Horizontal scaling at the slowest phase is what becomes necessary, or a 
reduction of the latency through that point by algorithmic or other related changes.

Where ever you put the delay, you will paint a picture like this.  It can help 
the overall throughput to do this because of contention reduction on 
non-scalable resources.  But, you just have to figure out what the right choice 
is before you really go to horizontal scaling of the work load.

Gregg Wonderly

> Thanks,
> Bryan
> ________________________________________
> From: concurrency-interest-bounces at cs.oswego.edu [concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joe Bowbeer [joe.bowbeer at gmail.com]
> Sent: Sunday, January 16, 2011 2:37 PM
> To: concurrency-interest
> Subject: Re: [concurrency-interest] Spacing out a workload burst?
>
> Can I assume you've read Chapter 8, Applying Thread Pools in Java Concurrency in Practice?
>
> Here's an earlier take on the same material:
>
> http://www.ibm.com/developerworks/library/j-jtp0730.html
>
> Off hand, I'd recommend using a thread pool backed by a queue.  The queue's job is to space-out the bursts.
>
> If you need more throttling, you can use a bounded queue and a saturation policy such as CallerRunsPolicy.
>
> Joe
>
> On Sun, Jan 16, 2011 at 11:14 AM, Bryan Thompson wrote:
> Hello,
>
> I was hoping that someone could point me to either some literature, s/w or patterns which we could use to space out a sudden workload burst.  This shows up in a benchmark where a number of client threads all start pounding on the service at once.  Watching the clients returning, it is pretty clear that the requests tend to take around the same amount of time and that requests complete and new requests are issued more or less in batch bursts as a result.  It seems to me that we might have better overall throughput if we could space out a burst of requests so the resource utilization has an opportunity to become more uniform.
>
> Thanks in advance,
> Bryan
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From navin.jha at FXALL.com  Fri Jan 21 11:32:37 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Fri, 21 Jan 2011 11:32:37 -0500
Subject: [concurrency-interest] Making copy of a reference to ReentrantLock
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC56@NYEXCH02.fxall.com>

I was looking at the CopyOnWriteArrayList.java source code and I see that in all the modification methods a copy of the lock is made first, something like:

public E set(int index, E element) {
                final ReentrantLock lock = this.lock;
                lock.lock();
................................... // rest of the method

I understand that making local copies of object variables would reduce contention but is that the reason for doing this in this case or something else?

Regards,
Navin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110121/174a1d45/attachment.html>

From joe.bowbeer at gmail.com  Fri Jan 21 11:53:23 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 21 Jan 2011 08:53:23 -0800
Subject: [concurrency-interest] Making copy of a reference to
	ReentrantLock
In-Reply-To: <AANLkTikVSgPMELaCdEDZkh+AqrMrcG1LxN0ELT+E52FN@mail.gmail.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC56@NYEXCH02.fxall.com>
	<AANLkTinSyVhJgK7+4N65S8z_hO2KYX5BXXeW06=SbS5t@mail.gmail.com>
	<AANLkTim9KJz7AO7VVOHhoXKQM+CqMFjLUvPrDV3PGTHG@mail.gmail.com>
	<AANLkTikVSgPMELaCdEDZkh+AqrMrcG1LxN0ELT+E52FN@mail.gmail.com>
Message-ID: <AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>

Note that this is a local reference not a local copy. Reusing a local
reference eliminates one (slower) instance variable lookup at runtime.

On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com> wrote:

 I was looking at the CopyOnWriteArrayList.java source code and I see that
in all the modification methods a copy of the lock is made first, something
like:



public E set(int index, E element) {

                final ReentrantLock lock = this.lock;

                lock.lock();

???????????.. // rest of the method



I understand that making local copies of object variables would reduce
contention but is that the reason for doing this in this case or something
else?



Regards,

Navin



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110121/b9ff0755/attachment.html>

From navin.jha at FXALL.com  Fri Jan 21 12:29:22 2011
From: navin.jha at FXALL.com (Navin Jha)
Date: Fri, 21 Jan 2011 12:29:22 -0500
Subject: [concurrency-interest] Making copy of a reference to
 ReentrantLock
In-Reply-To: <AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC56@NYEXCH02.fxall.com>
	<AANLkTinSyVhJgK7+4N65S8z_hO2KYX5BXXeW06=SbS5t@mail.gmail.com>
	<AANLkTim9KJz7AO7VVOHhoXKQM+CqMFjLUvPrDV3PGTHG@mail.gmail.com>
	<AANLkTikVSgPMELaCdEDZkh+AqrMrcG1LxN0ELT+E52FN@mail.gmail.com>
	<AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>
Message-ID: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC57@NYEXCH02.fxall.com>

Thanks. What about using final keyword inside the method for the local reference, what is the reason for that?

From: Joe Bowbeer [mailto:joe.bowbeer at gmail.com]
Sent: Friday, January 21, 2011 11:53 AM
To: Navin Jha
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Making copy of a reference to ReentrantLock


Note that this is a local reference not a local copy. Reusing a local reference eliminates one (slower) instance variable lookup at runtime.
On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com<mailto:navin.jha at fxall.com>> wrote:
I was looking at the CopyOnWriteArrayList.java source code and I see that in all the modification methods a copy of the lock is made first, something like:

public E set(int index, E element) {
                final ReentrantLock lock = this.lock;
                lock.lock();
................................... // rest of the method

I understand that making local copies of object variables would reduce contention but is that the reason for doing this in this case or something else?

Regards,
Navin


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110121/884a5664/attachment.html>

From forax at univ-mlv.fr  Fri Jan 21 13:16:00 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Fri, 21 Jan 2011 19:16:00 +0100
Subject: [concurrency-interest] Making copy of a reference to
	ReentrantLock
In-Reply-To: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC57@NYEXCH02.fxall.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC56@NYEXCH02.fxall.com>	<AANLkTinSyVhJgK7+4N65S8z_hO2KYX5BXXeW06=SbS5t@mail.gmail.com>	<AANLkTim9KJz7AO7VVOHhoXKQM+CqMFjLUvPrDV3PGTHG@mail.gmail.com>	<AANLkTikVSgPMELaCdEDZkh+AqrMrcG1LxN0ELT+E52FN@mail.gmail.com>	<AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>
	<EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC57@NYEXCH02.fxall.com>
Message-ID: <4D39CD60.6050109@univ-mlv.fr>

On 01/21/2011 06:29 PM, Navin Jha wrote:
>
> Thanks. What about using final keyword inside the method for the local 
> reference, what is the reason for that?
>

To get an error when you update the local reference instead of the 
corresponding field.
Or here because the field is also declared final (assignable once in the 
constructor).

R?mi

> *From:*Joe Bowbeer [mailto:joe.bowbeer at gmail.com]
> *Sent:* Friday, January 21, 2011 11:53 AM
> *To:* Navin Jha
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Making copy of a reference to 
> ReentrantLock
>
> Note that this is a local reference not a local copy. Reusing a local 
> reference eliminates one (slower) instance variable lookup at runtime.
>
>     On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com
>     <mailto:navin.jha at fxall.com>> wrote:
>
>     I was looking at the CopyOnWriteArrayList.java source code and I
>     see that in all the modification methods a copy of the lock is
>     made first, something like:
>
>     public E set(int index, E element) {
>
>                     final ReentrantLock lock = this.lock;
>
>                     lock.lock();
>
>     ................................... // rest of the method
>
>     I understand that making local copies of object variables would
>     reduce contention but is that the reason for doing this in this
>     case or something else?
>
>     Regards,
>
>     Navin
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110121/73cc56be/attachment.html>

From vitalyd at gmail.com  Fri Jan 21 13:56:46 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 21 Jan 2011 13:56:46 -0500
Subject: [concurrency-interest] Making copy of a reference to
	ReentrantLock
In-Reply-To: <AANLkTik5pFBkqEyuJjDSyp-CVyCN9AFbk8vzVKnRBqgk@mail.gmail.com>
References: <EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC56@NYEXCH02.fxall.com>
	<AANLkTinSyVhJgK7+4N65S8z_hO2KYX5BXXeW06=SbS5t@mail.gmail.com>
	<AANLkTim9KJz7AO7VVOHhoXKQM+CqMFjLUvPrDV3PGTHG@mail.gmail.com>
	<AANLkTikVSgPMELaCdEDZkh+AqrMrcG1LxN0ELT+E52FN@mail.gmail.com>
	<AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>
	<EA6FFD6D7496E940BA1A5A5C1CEFAF76135BBDEC57@NYEXCH02.fxall.com>
	<AANLkTik5pFBkqEyuJjDSyp-CVyCN9AFbk8vzVKnRBqgk@mail.gmail.com>
Message-ID: <AANLkTikEAF-z+oqVekhcODze6G+AsqWQcogMYFMz8u8O@mail.gmail.com>

Missed rest of the group.
On Jan 21, 2011 1:13 PM, "Vitaly Davidovich" <vitalyd at gmail.com> wrote:
> I believe this is Doug's optimization to work around hotspot not
eliminating
> repeated final instance field reads across lock() calls.
> On Jan 21, 2011 12:38 PM, "Navin Jha" <navin.jha at fxall.com> wrote:
>> Thanks. What about using final keyword inside the method for the local
> reference, what is the reason for that?
>>
>> From: Joe Bowbeer [mailto:joe.bowbeer at gmail.com]
>> Sent: Friday, January 21, 2011 11:53 AM
>> To: Navin Jha
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Making copy of a reference to
> ReentrantLock
>>
>>
>> Note that this is a local reference not a local copy. Reusing a local
> reference eliminates one (slower) instance variable lookup at runtime.
>> On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com<mailto:
> navin.jha at fxall.com>> wrote:
>> I was looking at the CopyOnWriteArrayList.java source code and I see that
> in all the modification methods a copy of the lock is made first,
something
> like:
>>
>> public E set(int index, E element) {
>> final ReentrantLock lock = this.lock;
>> lock.lock();
>> ................................... // rest of the method
>>
>> I understand that making local copies of object variables would reduce
> contention but is that the reason for doing this in this case or something
> else?
>>
>> Regards,
>> Navin
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu<mailto:
> Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110121/13ed9b6b/attachment-0001.html>

From davidcholmes at aapt.net.au  Fri Jan 21 17:36:47 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 22 Jan 2011 08:36:47 +1000
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>

This question does pop up from time to time on this list :) In theory if you
referenced the final field throughout the method the compiler would only
load it once. But when this was written the handling of final fields was
suboptimal and they would get re-loaded (perhaps still would). By loading
once into a final local variable the performance was improved. By making the
local final you potentially allow further compiler optimizations.

David Holmes

  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Joe Bowbeer
  Sent: Saturday, 22 January 2011 2:53 AM
  To: Navin Jha
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Making copy of a reference
toReentrantLock


  Note that this is a local reference not a local copy. Reusing a local
reference eliminates one (slower) instance variable lookup at runtime.


    On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com> wrote:


    I was looking at the CopyOnWriteArrayList.java source code and I see
that in all the modification methods a copy of the lock is made first,
something like:



    public E set(int index, E element) {

                    final ReentrantLock lock = this.lock;

                    lock.lock();

    ???????????.. // rest of the method



    I understand that making local copies of object variables would reduce
contention but is that the reason for doing this in this case or something
else?



    Regards,

    Navin




    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/5ebf727c/attachment.html>

From gregg at cytetech.com  Fri Jan 21 17:57:30 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Fri, 21 Jan 2011 16:57:30 -0600
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3A0F5A.9020903@cytetech.com>

I also try and do this for any class value that I reference multiple times in a 
single method to create a "singular" view of the value that I am working with. 
In many cases, I do "copy/reconstruct" on map and other data structures as a 
means of removing "mutation contention" and so by having a single reference I 
get a consistent view of the "value" throughout the entire method to eliminate 
some forms of "data race".

Gregg Wonderly

On 1/21/2011 4:36 PM, David Holmes wrote:
> This question does pop up from time to time on this list :) In theory if you
> referenced the final field throughout the method the compiler would only load it
> once. But when this was written the handling of final fields was suboptimal and
> they would get re-loaded (perhaps still would). By loading once into a final
> local variable the performance was improved. By making the local final you
> potentially allow further compiler optimizations.
> David Holmes
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Joe Bowbeer
>     *Sent:* Saturday, 22 January 2011 2:53 AM
>     *To:* Navin Jha
>     *Cc:* concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Making copy of a reference toReentrantLock
>
>     Note that this is a local reference not a local copy. Reusing a local
>     reference eliminates one (slower) instance variable lookup at runtime.
>
>>     On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com
>>     <mailto:navin.jha at fxall.com>> wrote:
>>
>>     I was looking at the CopyOnWriteArrayList.java source code and I see that
>>     in all the modification methods a copy of the lock is made first,
>>     something like:
>>
>>     public E set(int index, E element) {
>>
>>     final ReentrantLock lock = this.lock;
>>
>>     lock.lock();
>>
>>     ???????????.. // rest of the method
>>
>>     I understand that making local copies of object variables would reduce
>>     contention but is that the reason for doing this in this case or something
>>     else?
>>
>>     Regards,
>>
>>     Navin
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From vitalyd at gmail.com  Fri Jan 21 23:56:17 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 21 Jan 2011 23:56:17 -0500
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
References: <AANLkTik20mBAtMq+y3kpztRQKeWc_8u3dvtVrijXQ6d3@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTikC=vWnrLqJMLp7nOp55Gd6bPUqfeYNzAn5gZZS@mail.gmail.com>

David,

If I recall Doug's comments correctly, the load of a final field was not
optimized away only across the lock() in this case (probably generalized to
any mem barrier inducing code path).  Perhaps this is still the case, but I
would certainly hope (expect?) that it would eliminate them for normal code
paths even back then.

Would be good to have someone from the compiler team comment on current
state of affairs here.

Vitaly
On Jan 21, 2011 5:38 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:
> This question does pop up from time to time on this list :) In theory if
you
> referenced the final field throughout the method the compiler would only
> load it once. But when this was written the handling of final fields was
> suboptimal and they would get re-loaded (perhaps still would). By loading
> once into a final local variable the performance was improved. By making
the
> local final you potentially allow further compiler optimizations.
>
> David Holmes
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Joe
Bowbeer
> Sent: Saturday, 22 January 2011 2:53 AM
> To: Navin Jha
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Making copy of a reference
> toReentrantLock
>
>
> Note that this is a local reference not a local copy. Reusing a local
> reference eliminates one (slower) instance variable lookup at runtime.
>
>
> On Jan 21, 2011 8:39 AM, "Navin Jha" <navin.jha at fxall.com> wrote:
>
>
> I was looking at the CopyOnWriteArrayList.java source code and I see
> that in all the modification methods a copy of the lock is made first,
> something like:
>
>
>
> public E set(int index, E element) {
>
> final ReentrantLock lock = this.lock;
>
> lock.lock();
>
> ???????????.. // rest of the method
>
>
>
> I understand that making local copies of object variables would reduce
> contention but is that the reason for doing this in this case or something
> else?
>
>
>
> Regards,
>
> Navin
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110121/c8588835/attachment.html>

From forax at univ-mlv.fr  Sat Jan 22 07:55:45 2011
From: forax at univ-mlv.fr (=?windows-1252?Q?R=E9mi_Forax?=)
Date: Sat, 22 Jan 2011 13:55:45 +0100
Subject: [concurrency-interest] Making copy of a
	reference	toReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3AD3D1.303@univ-mlv.fr>

On 01/21/2011 11:36 PM, David Holmes wrote:
> This question does pop up from time to time on this list :) In theory 
> if you referenced the final field throughout the method the compiler 
> would only load it once. But when this was written the handling of 
> final fields was suboptimal and they would get re-loaded (perhaps 
> still would). By loading once into a final local variable the 
> performance was improved. By making the local final you potentially 
> allow further compiler optimizations.

No, making the local final doesn't trigger any optimization.
javac doesn't do any optimization and in the bytecode there is no way to 
say this local variable is final.

> David Holmes
>

R?mi

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/665fa5ca/attachment.html>

From martinrb at google.com  Sat Jan 22 15:21:44 2011
From: martinrb at google.com (Martin Buchholz)
Date: Sat, 22 Jan 2011 12:21:44 -0800
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <4D3AD3D1.303@univ-mlv.fr>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
Message-ID: <AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>

On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr> wrote:

>
> No, making the local final doesn't trigger any optimization.
> javac doesn't do any optimization and in the bytecode there is no way to
> say this local variable is final.
>

We in jsr166-land consider our software important enough to make
optimizations we don't recommend to regular java programmers.  Copying final
fields to locals generates smaller bytecode and might help the jit produce
better code (and with current hotspot, still does).

Using final on locals has no performance advantage, but it does have some
software engineering advantages.  We tend to use it for locals with the same
name as a field, e.g.

final Foo foo = this.foo;

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/c5c4e0f4/attachment.html>

From joe.bowbeer at gmail.com  Sat Jan 22 15:45:37 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 22 Jan 2011 12:45:37 -0800
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
Message-ID: <AANLkTimhcmVquZ-_M9kocEOy=JXp7Pu3k8FRei3OkmmC@mail.gmail.com>

Those in jsr166-land also choose to ignore the name shadowing warnings
typically flagged by Eclipse and other IDEs:

"Local variable declaration [lock] hides another field or variable"

On Sat, Jan 22, 2011 at 12:21 PM, Martin Buchholz wrote:

>
> On Sat, Jan 22, 2011 at 04:55, R?mi Forax wrote:
>
>>
>> No, making the local final doesn't trigger any optimization.
>> javac doesn't do any optimization and in the bytecode there is no way to
>> say this local variable is final.
>>
>
> We in jsr166-land consider our software important enough to make
> optimizations we don't recommend to regular java programmers.  Copying final
> fields to locals generates smaller bytecode and might help the jit produce
> better code (and with current hotspot, still does).
>
> Using final on locals has no performance advantage, but it does have some
> software engineering advantages.  We tend to use it for locals with the same
> name as a field, e.g.
>
> final Foo foo = this.foo;
>
> Martin
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/76e77a71/attachment.html>

From david.lloyd at redhat.com  Sat Jan 22 16:00:04 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Sat, 22 Jan 2011 15:00:04 -0600
Subject: [concurrency-interest] Making copy of a
	reference	toReentrantLock
In-Reply-To: <AANLkTimhcmVquZ-_M9kocEOy=JXp7Pu3k8FRei3OkmmC@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>	<4D3AD3D1.303@univ-mlv.fr>	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
	<AANLkTimhcmVquZ-_M9kocEOy=JXp7Pu3k8FRei3OkmmC@mail.gmail.com>
Message-ID: <4D3B4554.1000506@redhat.com>

That's a bit weak, as any good IDE lets the user decide what style 
points are "good" and what style points are "bad".  I for one think 
there's nothing wrong with hiding variables with other variables, 
stylistically, so I will not allow my IDE to warn on that.

There are many other such warnings that can be configured in IDEs, some 
of which are contradictory, so saying that such a warning exists is 
justification for not doing something basically doesn't hold up.  For 
example, IDEA can be configured to warn if local variables are declared 
final; it can also be configured to warn if local variables are *not* 
declared final.  So should I stop using local variables altogether?

On 01/22/2011 02:45 PM, Joe Bowbeer wrote:
> Those in jsr166-land also choose to ignore the name shadowing warnings
> typically flagged by Eclipse and other IDEs:
>
> "Local variable declaration [lock] hides another field or variable"
>
> On Sat, Jan 22, 2011 at 12:21 PM, Martin Buchholz wrote:
>
>
>     On Sat, Jan 22, 2011 at 04:55, R?mi Forax wrote:
>
>
>         No, making the local final doesn't trigger any optimization.
>         javac doesn't do any optimization and in the bytecode there is
>         no way to say this local variable is final.
>
>
>     We in jsr166-land consider our software important enough to make
>     optimizations we don't recommend to regular java programmers.
>     Copying final fields to locals generates smaller bytecode and might
>     help the jit produce better code (and with current hotspot, still does).
>
>     Using final on locals has no performance advantage, but it does have
>     some software engineering advantages.  We tend to use it for locals
>     with the same name as a field, e.g.
>
>     final Foo foo = this.foo;
>
>     Martin
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
- DML

From dmdabbs at gmail.com  Sat Jan 22 16:21:12 2011
From: dmdabbs at gmail.com (David Dabbs)
Date: Sat, 22 Jan 2011 15:21:12 -0600
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
Message-ID: <00e601cbba7a$4c72a7b0$e557f710$@com>



From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin
Buchholz
Sent: Saturday, January 22, 2011 2:22 PM
To: R?mi Forax
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Making copy of a reference
toReentrantLock


On Sat, Jan 22, 2011 at 04:55, R?mi Forax wrote:

No, making the local final doesn't trigger any optimization.
javac doesn't do any optimization and in the bytecode there is no way to say
this local variable is final.
?
On Sat, Jan 22, 2011 at 04:55, Martin Buchholz wrote:
We in jsr166-land consider our software important enough to make
optimizations we don't recommend to regular java programmers.? 
Copying final fields to locals generates smaller bytecode and might help the
jit produce better code (and with current hotspot, still does).

Using final on locals has no performance advantage, but it does have some
software engineering advantages.? We tend to use it for locals with the same
name as a field, e.g.

final Foo foo = this.foo;


I think I understand the bytecode size benefit - smaller means method is
more likely to be under Hotspot method-size compilation/inlining limit(s),
yes?
Or something else?

Would you mind elaborating on "(and with current hotspot, still does)"? For
instance, HS20 or 19? What benefits and how measured?


Many thanks from a cargo culter of this pattern.


David





From vitalyd at gmail.com  Sat Jan 22 16:24:19 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sat, 22 Jan 2011 16:24:19 -0500
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
Message-ID: <AANLkTikP-eZ_RzudWvnnJM6uNF1Gae0K1j-DbCScW8Je@mail.gmail.com>

Martin,

Are you saying that the current (e.g. jdk 6u23) C2 compiler (let's focus on
this one) does not eliminate repeated loads of final fields even in trivial
methods (i.e. no mem fences)? I'd imagine that's a failure in the compiler
if that's true.  Style/engineering practices aside, developers should not
have to resort to manually optimizing a final read by using a local.  I'm
still curious to hear from someone on the compiler team on this subject.

Vitaly
On Jan 22, 2011 3:35 PM, "Martin Buchholz" <martinrb at google.com> wrote:
> On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr> wrote:
>
>>
>> No, making the local final doesn't trigger any optimization.
>> javac doesn't do any optimization and in the bytecode there is no way to
>> say this local variable is final.
>>
>
> We in jsr166-land consider our software important enough to make
> optimizations we don't recommend to regular java programmers. Copying
final
> fields to locals generates smaller bytecode and might help the jit produce
> better code (and with current hotspot, still does).
>
> Using final on locals has no performance advantage, but it does have some
> software engineering advantages. We tend to use it for locals with the
same
> name as a field, e.g.
>
> final Foo foo = this.foo;
>
> Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/dab26ca0/attachment.html>

From vitalyd at gmail.com  Sat Jan 22 16:31:12 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sat, 22 Jan 2011 16:31:12 -0500
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <00e601cbba7a$4c72a7b0$e557f710$@com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
	<00e601cbba7a$4c72a7b0$e557f710$@com>
Message-ID: <AANLkTinJDuw4qYamTMw9ZmPX7wfWxuRHtH3j=-7RxWby@mail.gmail.com>

My assumption would be that the compiler would first build a graph for the
method, performing whatever static and dynamic (i.e based on interpreter
stats) optimizations, before deciding whether the method is a good inline
candidate.  I hope that's true and it doesn't blindly look at the
unoptimized bytecode size to make the determination.
On Jan 22, 2011 4:22 PM, "David Dabbs" <dmdabbs at gmail.com> wrote:
>
>
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin
> Buchholz
> Sent: Saturday, January 22, 2011 2:22 PM
> To: R?mi Forax
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Making copy of a reference
> toReentrantLock
>
>
> On Sat, Jan 22, 2011 at 04:55, R?mi Forax wrote:
>
> No, making the local final doesn't trigger any optimization.
> javac doesn't do any optimization and in the bytecode there is no way to
say
> this local variable is final.
>
> On Sat, Jan 22, 2011 at 04:55, Martin Buchholz wrote:
> We in jsr166-land consider our software important enough to make
> optimizations we don't recommend to regular java programmers.
> Copying final fields to locals generates smaller bytecode and might help
the
> jit produce better code (and with current hotspot, still does).
>
> Using final on locals has no performance advantage, but it does have some
> software engineering advantages.  We tend to use it for locals with the
same
> name as a field, e.g.
>
> final Foo foo = this.foo;
>
>
> I think I understand the bytecode size benefit - smaller means method is
> more likely to be under Hotspot method-size compilation/inlining limit(s),
> yes?
> Or something else?
>
> Would you mind elaborating on "(and with current hotspot, still does)"?
For
> instance, HS20 or 19? What benefits and how measured?
>
>
> Many thanks from a cargo culter of this pattern.
>
>
> David
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/541f53e3/attachment-0001.html>

From joe.bowbeer at gmail.com  Sat Jan 22 16:54:29 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 22 Jan 2011 13:54:29 -0800
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <4D3B4554.1000506@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
	<AANLkTimhcmVquZ-_M9kocEOy=JXp7Pu3k8FRei3OkmmC@mail.gmail.com>
	<4D3B4554.1000506@redhat.com>
Message-ID: <AANLkTi=8Kjc2R_FXULyEGHrmx_42wFnL7eihjvbKjVii@mail.gmail.com>

Correction: The shadowing warning that is enabled by default in NetBeans
(see below) is ignored by those of us in jsr166-land.  (This warning is also
available in Eclipse but is not enabled by default.)

When I'm not in jsr166-land, I try to heed these warnings because I'd rather
work within the popular defaults than impose my own preferences on everyone
else.

(*) http://wiki.netbeans.org/Java_Hints

  "Local variable hides a field"

On Sat, Jan 22, 2011 at 1:00 PM, David M. Lloyd wrote:

> That's a bit weak, as any good IDE lets the user decide what style points
> are "good" and what style points are "bad".  I for one think there's nothing
> wrong with hiding variables with other variables, stylistically, so I will
> not allow my IDE to warn on that.
>
> There are many other such warnings that can be configured in IDEs, some of
> which are contradictory, so saying that such a warning exists is
> justification for not doing something basically doesn't hold up.  For
> example, IDEA can be configured to warn if local variables are declared
> final; it can also be configured to warn if local variables are *not*
> declared final.  So should I stop using local variables altogether?
>
>
> On 01/22/2011 02:45 PM, Joe Bowbeer wrote:
>
>> Those in jsr166-land also choose to ignore the name shadowing warnings
>> typically flagged by Eclipse and other IDEs:
>>
>> "Local variable declaration [lock] hides another field or variable"
>>
>> On Sat, Jan 22, 2011 at 12:21 PM, Martin Buchholz wrote:
>>
>>
>>    On Sat, Jan 22, 2011 at 04:55, R?mi Forax wrote:
>>
>>
>>        No, making the local final doesn't trigger any optimization.
>>        javac doesn't do any optimization and in the bytecode there is
>>        no way to say this local variable is final.
>>
>>
>>    We in jsr166-land consider our software important enough to make
>>    optimizations we don't recommend to regular java programmers.
>>    Copying final fields to locals generates smaller bytecode and might
>>    help the jit produce better code (and with current hotspot, still
>> does).
>>
>>    Using final on locals has no performance advantage, but it does have
>>    some software engineering advantages.  We tend to use it for locals
>>    with the same name as a field, e.g.
>>
>>    final Foo foo = this.foo;
>>
>>    Martin
>>
>> --
> - DML
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/d19a6822/attachment.html>

From forax at univ-mlv.fr  Sat Jan 22 18:00:04 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sun, 23 Jan 2011 00:00:04 +0100
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <AANLkTikP-eZ_RzudWvnnJM6uNF1Gae0K1j-DbCScW8Je@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>	<4D3AD3D1.303@univ-mlv.fr>	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
	<AANLkTikP-eZ_RzudWvnnJM6uNF1Gae0K1j-DbCScW8Je@mail.gmail.com>
Message-ID: <4D3B6174.3020203@univ-mlv.fr>

On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
>
> Martin,
>
> Are you saying that the current (e.g. jdk 6u23) C2 compiler (let's 
> focus on this one) does not eliminate repeated loads of final fields 
> even in trivial methods (i.e. no mem fences)? I'd imagine that's a 
> failure in the compiler if that's true.  Style/engineering practices 
> aside, developers should not have to resort to manually optimizing a 
> final read by using a local.  I'm still curious to hear from someone 
> on the compiler team on this subject.
>
> Vitaly
>

c1 and c2 eliminate redundant loads (as far as I can see by playing with 
hsdis),
but for that all the bytecodes between the two loads must be inlined.
It's often the case with c2, c1 is less aggressive.

R?mi

> On Jan 22, 2011 3:35 PM, "Martin Buchholz" <martinrb at google.com 
> <mailto:martinrb at google.com>> wrote:
> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr 
> <mailto:forax at univ-mlv.fr>> wrote:
> >
> >>
> >> No, making the local final doesn't trigger any optimization.
> >> javac doesn't do any optimization and in the bytecode there is no 
> way to
> >> say this local variable is final.
> >>
> >
> > We in jsr166-land consider our software important enough to make
> > optimizations we don't recommend to regular java programmers. 
> Copying final
> > fields to locals generates smaller bytecode and might help the jit 
> produce
> > better code (and with current hotspot, still does).
> >
> > Using final on locals has no performance advantage, but it does have 
> some
> > software engineering advantages. We tend to use it for locals with 
> the same
> > name as a field, e.g.
> >
> > final Foo foo = this.foo;
> >
> > Martin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110123/674cc742/attachment.html>

From vitalyd at gmail.com  Sat Jan 22 18:20:45 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sat, 22 Jan 2011 18:20:45 -0500
Subject: [concurrency-interest] Making copy of a reference
	toReentrantLock
In-Reply-To: <4D3B6174.3020203@univ-mlv.fr>
References: <NFBBKALFDCPFIDBNKAPCKEMIIKAA.davidcholmes@aapt.net.au>
	<4D3AD3D1.303@univ-mlv.fr>
	<AANLkTi=BDX9koEF2h9fUhZM0PwVNZuTUxZvTQ=JuQ2+x@mail.gmail.com>
	<AANLkTikP-eZ_RzudWvnnJM6uNF1Gae0K1j-DbCScW8Je@mail.gmail.com>
	<4D3B6174.3020203@univ-mlv.fr>
Message-ID: <AANLkTimWiOE00S4Yh3zQqu5uN=ofKnzYmiUddK8ZVPMk@mail.gmail.com>

I guess you're talking about final field loads across method calls by
mentioning inlining; if so, clearly inlining exposes opportunities for
optos, but I'm personally curious whether all loads are eliminated within
one method - seems you're saying that's the case (I should take a look at
the disassembly myself and not be lazy :)).  Furthermore,  with respect to
the original question, interesting to know whether lock() and the like
prevent this opto in the latest product hotspot.
On Jan 22, 2011 6:03 PM, "R?mi Forax" <forax at univ-mlv.fr> wrote:
> On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
>>
>> Martin,
>>
>> Are you saying that the current (e.g. jdk 6u23) C2 compiler (let's
>> focus on this one) does not eliminate repeated loads of final fields
>> even in trivial methods (i.e. no mem fences)? I'd imagine that's a
>> failure in the compiler if that's true. Style/engineering practices
>> aside, developers should not have to resort to manually optimizing a
>> final read by using a local. I'm still curious to hear from someone
>> on the compiler team on this subject.
>>
>> Vitaly
>>
>
> c1 and c2 eliminate redundant loads (as far as I can see by playing with
> hsdis),
> but for that all the bytecodes between the two loads must be inlined.
> It's often the case with c2, c1 is less aggressive.
>
> R?mi
>
>> On Jan 22, 2011 3:35 PM, "Martin Buchholz" <martinrb at google.com
>> <mailto:martinrb at google.com>> wrote:
>> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr
>> <mailto:forax at univ-mlv.fr>> wrote:
>> >
>> >>
>> >> No, making the local final doesn't trigger any optimization.
>> >> javac doesn't do any optimization and in the bytecode there is no
>> way to
>> >> say this local variable is final.
>> >>
>> >
>> > We in jsr166-land consider our software important enough to make
>> > optimizations we don't recommend to regular java programmers.
>> Copying final
>> > fields to locals generates smaller bytecode and might help the jit
>> produce
>> > better code (and with current hotspot, still does).
>> >
>> > Using final on locals has no performance advantage, but it does have
>> some
>> > software engineering advantages. We tend to use it for locals with
>> the same
>> > name as a field, e.g.
>> >
>> > final Foo foo = this.foo;
>> >
>> > Martin
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110122/1f19a1da/attachment.html>

From davidcholmes at aapt.net.au  Sat Jan 22 19:37:16 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 23 Jan 2011 10:37:16 +1000
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <AANLkTimWiOE00S4Yh3zQqu5uN=ofKnzYmiUddK8ZVPMk@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEMLIKAA.davidcholmes@aapt.net.au>

Re-loading a final field is always redundant, the question is whether the
compiler recognizes that regardless of method calls or inlining. It didn't
in the past. I dont know what it does now.

Remi:thanks for correcting my comment on final locals.

Cheers,
David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Vitaly
Davidovich
  Sent: Sunday, 23 January 2011 9:21 AM
  To: R?mi Forax
  Cc: Martin Buchholz; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Making copy of a
referencetoReentrantLock


  I guess you're talking about final field loads across method calls by
mentioning inlining; if so, clearly inlining exposes opportunities for
optos, but I'm personally curious whether all loads are eliminated within
one method - seems you're saying that's the case (I should take a look at
the disassembly myself and not be lazy :)).  Furthermore,  with respect to
the original question, interesting to know whether lock() and the like
prevent this opto in the latest product hotspot.

  On Jan 22, 2011 6:03 PM, "R?mi Forax" <forax at univ-mlv.fr> wrote:
  > On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
  >>
  >> Martin,
  >>
  >> Are you saying that the current (e.g. jdk 6u23) C2 compiler (let's
  >> focus on this one) does not eliminate repeated loads of final fields
  >> even in trivial methods (i.e. no mem fences)? I'd imagine that's a
  >> failure in the compiler if that's true. Style/engineering practices
  >> aside, developers should not have to resort to manually optimizing a
  >> final read by using a local. I'm still curious to hear from someone
  >> on the compiler team on this subject.
  >>
  >> Vitaly
  >>
  >
  > c1 and c2 eliminate redundant loads (as far as I can see by playing with
  > hsdis),
  > but for that all the bytecodes between the two loads must be inlined.
  > It's often the case with c2, c1 is less aggressive.
  >
  > R?mi
  >
  >> On Jan 22, 2011 3:35 PM, "Martin Buchholz" <martinrb at google.com
  >> <mailto:martinrb at google.com>> wrote:
  >> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr
  >> <mailto:forax at univ-mlv.fr>> wrote:
  >> >
  >> >>
  >> >> No, making the local final doesn't trigger any optimization.
  >> >> javac doesn't do any optimization and in the bytecode there is no
  >> way to
  >> >> say this local variable is final.
  >> >>
  >> >
  >> > We in jsr166-land consider our software important enough to make
  >> > optimizations we don't recommend to regular java programmers.
  >> Copying final
  >> > fields to locals generates smaller bytecode and might help the jit
  >> produce
  >> > better code (and with current hotspot, still does).
  >> >
  >> > Using final on locals has no performance advantage, but it does have
  >> some
  >> > software engineering advantages. We tend to use it for locals with
  >> the same
  >> > name as a field, e.g.
  >> >
  >> > final Foo foo = this.foo;
  >> >
  >> > Martin
  >
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110123/2303b7e0/attachment-0001.html>

From forax at univ-mlv.fr  Sat Jan 22 19:48:48 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sun, 23 Jan 2011 01:48:48 +0100
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEMLIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEMLIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3B7AF0.5010601@univ-mlv.fr>

On 01/23/2011 01:37 AM, David Holmes wrote:
> Re-loading a final field is always redundant, the question is 
> whether the compiler recognizes that regardless of method calls or 
> inlining. It didn't in the past. I dont know what it does now.

You can't optimize re-loading of final field if the field is changed (by 
reflection or using unsafe) in the middle.
That why it depends on method calls/inlining.

The other solution is optimize optimistically and deopt if someone 
changes the field.
Hotspot don't do that.

> Remi:thanks for correcting my comment on final locals.
> Cheers,
> David

regards,
R?mi

>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Vitaly Davidovich
>     *Sent:* Sunday, 23 January 2011 9:21 AM
>     *To:* R?mi Forax
>     *Cc:* Martin Buchholz; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Making copy of a
>     referencetoReentrantLock
>
>     I guess you're talking about final field loads across method calls
>     by mentioning inlining; if so, clearly inlining exposes
>     opportunities for optos, but I'm personally curious whether all
>     loads are eliminated within one method - seems you're saying
>     that's the case (I should take a look at the disassembly myself
>     and not be lazy :)).  Furthermore,  with respect to the original
>     question, interesting to know whether lock() and the like prevent
>     this opto in the latest product hotspot.
>
>     On Jan 22, 2011 6:03 PM, "R?mi Forax" <forax at univ-mlv.fr
>     <mailto:forax at univ-mlv.fr>> wrote:
>     > On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
>     >>
>     >> Martin,
>     >>
>     >> Are you saying that the current (e.g. jdk 6u23) C2 compiler (let's
>     >> focus on this one) does not eliminate repeated loads of final
>     fields
>     >> even in trivial methods (i.e. no mem fences)? I'd imagine that's a
>     >> failure in the compiler if that's true. Style/engineering
>     practices
>     >> aside, developers should not have to resort to manually
>     optimizing a
>     >> final read by using a local. I'm still curious to hear from
>     someone
>     >> on the compiler team on this subject.
>     >>
>     >> Vitaly
>     >>
>     >
>     > c1 and c2 eliminate redundant loads (as far as I can see by
>     playing with
>     > hsdis),
>     > but for that all the bytecodes between the two loads must be
>     inlined.
>     > It's often the case with c2, c1 is less aggressive.
>     >
>     > R?mi
>     >
>     >> On Jan 22, 2011 3:35 PM, "Martin Buchholz" <martinrb at google.com
>     <mailto:martinrb at google.com>
>     >> <mailto:martinrb at google.com <mailto:martinrb at google.com>>> wrote:
>     >> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr
>     <mailto:forax at univ-mlv.fr>
>     >> <mailto:forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>>> wrote:
>     >> >
>     >> >>
>     >> >> No, making the local final doesn't trigger any optimization.
>     >> >> javac doesn't do any optimization and in the bytecode there
>     is no
>     >> way to
>     >> >> say this local variable is final.
>     >> >>
>     >> >
>     >> > We in jsr166-land consider our software important enough to make
>     >> > optimizations we don't recommend to regular java programmers.
>     >> Copying final
>     >> > fields to locals generates smaller bytecode and might help
>     the jit
>     >> produce
>     >> > better code (and with current hotspot, still does).
>     >> >
>     >> > Using final on locals has no performance advantage, but it
>     does have
>     >> some
>     >> > software engineering advantages. We tend to use it for locals
>     with
>     >> the same
>     >> > name as a field, e.g.
>     >> >
>     >> > final Foo foo = this.foo;
>     >> >
>     >> > Martin
>     >
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110123/03c3426f/attachment.html>

From davidcholmes at aapt.net.au  Sat Jan 22 22:20:14 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 23 Jan 2011 13:20:14 +1000
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <4D3B7AF0.5010601@univ-mlv.fr>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEMMIKAA.davidcholmes@aapt.net.au>

Remi,

The specification makes it clear that setting of a final field via
reflection is only valid in certain contexts:

"Setting a final field in this way is meaningful only during deserialization
or reconstruction of instances of classes with blank final fields, before
they are made available for access by other parts of a program. Use in any
other context may have unpredictable effects, including cases in which other
parts of a program continue to use the original value of this field. "

So the compiler can optimize away re-loading of final fields, even if
reflection (or Unsafe) is mis-used. (Though compilation of deserialization
code would have to be handled specially.)

David
  -----Original Message-----
  From: R?mi Forax [mailto:forax at univ-mlv.fr]
  Sent: Sunday, 23 January 2011 10:49 AM
  To: dholmes at ieee.org
  Cc: David Holmes; Vitaly Davidovich; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Making copy of a
referencetoReentrantLock


  On 01/23/2011 01:37 AM, David Holmes wrote:
    Re-loading a final field is always redundant, the question is whether
the compiler recognizes that regardless of method calls or inlining. It
didn't in the past. I dont know what it does now.

  You can't optimize re-loading of final field if the field is changed (by
reflection or using unsafe) in the middle.
  That why it depends on method calls/inlining.

  The other solution is optimize optimistically and deopt if someone changes
the field.
  Hotspot don't do that.



    Remi:thanks for correcting my comment on final locals.

    Cheers,
    David

  regards,
  R?mi


      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Vitaly
Davidovich
      Sent: Sunday, 23 January 2011 9:21 AM
      To: R?mi Forax
      Cc: Martin Buchholz; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Making copy of a
referencetoReentrantLock


      I guess you're talking about final field loads across method calls by
mentioning inlining; if so, clearly inlining exposes opportunities for
optos, but I'm personally curious whether all loads are eliminated within
one method - seems you're saying that's the case (I should take a look at
the disassembly myself and not be lazy :)).  Furthermore,  with respect to
the original question, interesting to know whether lock() and the like
prevent this opto in the latest product hotspot.

      On Jan 22, 2011 6:03 PM, "R?mi Forax" <forax at univ-mlv.fr> wrote:
      > On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
      >>
      >> Martin,
      >>
      >> Are you saying that the current (e.g. jdk 6u23) C2 compiler (let's
      >> focus on this one) does not eliminate repeated loads of final
fields
      >> even in trivial methods (i.e. no mem fences)? I'd imagine that's a
      >> failure in the compiler if that's true. Style/engineering practices
      >> aside, developers should not have to resort to manually optimizing
a
      >> final read by using a local. I'm still curious to hear from someone
      >> on the compiler team on this subject.
      >>
      >> Vitaly
      >>
      >
      > c1 and c2 eliminate redundant loads (as far as I can see by playing
with
      > hsdis),
      > but for that all the bytecodes between the two loads must be
inlined.
      > It's often the case with c2, c1 is less aggressive.
      >
      > R?mi
      >
      >> On Jan 22, 2011 3:35 PM, "Martin Buchholz" <martinrb at google.com
      >> <mailto:martinrb at google.com>> wrote:
      >> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax <forax at univ-mlv.fr
      >> <mailto:forax at univ-mlv.fr>> wrote:
      >> >
      >> >>
      >> >> No, making the local final doesn't trigger any optimization.
      >> >> javac doesn't do any optimization and in the bytecode there is
no
      >> way to
      >> >> say this local variable is final.
      >> >>
      >> >
      >> > We in jsr166-land consider our software important enough to make
      >> > optimizations we don't recommend to regular java programmers.
      >> Copying final
      >> > fields to locals generates smaller bytecode and might help the
jit
      >> produce
      >> > better code (and with current hotspot, still does).
      >> >
      >> > Using final on locals has no performance advantage, but it does
have
      >> some
      >> > software engineering advantages. We tend to use it for locals
with
      >> the same
      >> > name as a field, e.g.
      >> >
      >> > final Foo foo = this.foo;
      >> >
      >> > Martin
      >


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110123/7737ffb4/attachment.html>

From forax at univ-mlv.fr  Sun Jan 23 08:04:36 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sun, 23 Jan 2011 14:04:36 +0100
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEMMIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEMMIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3C2764.2000002@univ-mlv.fr>

On 01/23/2011 04:20 AM, David Holmes wrote:
> Remi,
> The specification makes it clear that setting of a final field via 
> reflection is only valid in certain contexts:
> "Setting a final field in this way is meaningful only during 
> deserialization or reconstruction of instances of classes with blank 
> final fields, before they are made available for access by other parts 
> of a program. Use in any other context may have unpredictable effects, 
> including cases in which other parts of a program continue to use the 
> original value of this field. "

Interesting !, I was not knowing that restriction.

> So the compiler can optimize away re-loading of final fields, even if 
> reflection (or Unsafe) is mis-used. (Though compilation of 
> deserialization code would have to be handled specially.)

So the JIT has to prove that the method that it tries to compile is not 
accessible from
any deserialization code. A simple way is to optimize field re-loading 
in method of the class
that has no readResolve(), etc.

Digging in hotspot source, I have found something,
there is a flag TrustFinalNonStaticFields that request final field 
optimization.
(see ciField.cpp near line 180).

> David

R?mi

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110123/73d612cb/attachment-0001.html>

From david.lloyd at redhat.com  Sun Jan 23 10:45:49 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Sun, 23 Jan 2011 09:45:49 -0600
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEMMIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEMMIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3C4D2D.2080006@redhat.com>

There's a bit more to it than that.  System.in/out/err are "special" in 
that they are final but can be reloaded in the normal course of program 
execution.

On 01/22/2011 09:20 PM, David Holmes wrote:
> Remi,
> The specification makes it clear that setting of a final field via
> reflection is only valid in certain contexts:
> "Setting a final field in this way is meaningful only during
> deserialization or reconstruction of instances of classes with blank
> final fields, before they are made available for access by other parts
> of a program. Use in any other context may have unpredictable effects,
> including cases in which other parts of a program continue to use the
> original value of this field. "
> So the compiler can optimize away re-loading of final fields, even if
> reflection (or Unsafe) is mis-used. (Though compilation of
> deserialization code would have to be handled specially.)
> David
>
>     -----Original Message-----
>     *From:* R?mi Forax [mailto:forax at univ-mlv.fr]
>     *Sent:* Sunday, 23 January 2011 10:49 AM
>     *To:* dholmes at ieee.org
>     *Cc:* David Holmes; Vitaly Davidovich;
>     concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Making copy of a
>     referencetoReentrantLock
>
>     On 01/23/2011 01:37 AM, David Holmes wrote:
>>     Re-loading a final field is always redundant, the question is
>>     whether the compiler recognizes that regardless of method calls or
>>     inlining. It didn't in the past. I dont know what it does now.
>
>     You can't optimize re-loading of final field if the field is changed
>     (by reflection or using unsafe) in the middle.
>     That why it depends on method calls/inlining.
>
>     The other solution is optimize optimistically and deopt if someone
>     changes the field.
>     Hotspot don't do that.
>
>>     Remi:thanks for correcting my comment on final locals.
>>     Cheers,
>>     David
>
>     regards,
>     R?mi
>
>>         -----Original Message-----
>>         *From:* concurrency-interest-bounces at cs.oswego.edu
>>         [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf
>>         Of *Vitaly Davidovich
>>         *Sent:* Sunday, 23 January 2011 9:21 AM
>>         *To:* R?mi Forax
>>         *Cc:* Martin Buchholz; concurrency-interest at cs.oswego.edu
>>         *Subject:* Re: [concurrency-interest] Making copy of a
>>         referencetoReentrantLock
>>
>>         I guess you're talking about final field loads across method
>>         calls by mentioning inlining; if so, clearly inlining exposes
>>         opportunities for optos, but I'm personally curious whether
>>         all loads are eliminated within one method - seems you're
>>         saying that's the case (I should take a look at the
>>         disassembly myself and not be lazy :)). Furthermore, with
>>         respect to the original question, interesting to know whether
>>         lock() and the like prevent this opto in the latest product
>>         hotspot.
>>
>>         On Jan 22, 2011 6:03 PM, "R?mi Forax" <forax at univ-mlv.fr
>>         <mailto:forax at univ-mlv.fr>> wrote:
>>         > On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
>>         >>
>>         >> Martin,
>>         >>
>>         >> Are you saying that the current (e.g. jdk 6u23) C2 compiler
>>         (let's
>>         >> focus on this one) does not eliminate repeated loads of
>>         final fields
>>         >> even in trivial methods (i.e. no mem fences)? I'd imagine
>>         that's a
>>         >> failure in the compiler if that's true. Style/engineering
>>         practices
>>         >> aside, developers should not have to resort to manually
>>         optimizing a
>>         >> final read by using a local. I'm still curious to hear from
>>         someone
>>         >> on the compiler team on this subject.
>>         >>
>>         >> Vitaly
>>         >>
>>         >
>>         > c1 and c2 eliminate redundant loads (as far as I can see by
>>         playing with
>>         > hsdis),
>>         > but for that all the bytecodes between the two loads must be
>>         inlined.
>>         > It's often the case with c2, c1 is less aggressive.
>>         >
>>         > R?mi
>>         >
>>         >> On Jan 22, 2011 3:35 PM, "Martin Buchholz"
>>         <martinrb at google.com <mailto:martinrb at google.com>
>>         >> <mailto:martinrb at google.com <mailto:martinrb at google.com>>>
>>         wrote:
>>         >> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax
>>         <forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>
>>         >> <mailto:forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>>> wrote:
>>         >> >
>>         >> >>
>>         >> >> No, making the local final doesn't trigger any optimization.
>>         >> >> javac doesn't do any optimization and in the bytecode
>>         there is no
>>         >> way to
>>         >> >> say this local variable is final.
>>         >> >>
>>         >> >
>>         >> > We in jsr166-land consider our software important enough
>>         to make
>>         >> > optimizations we don't recommend to regular java
>>         programmers.
>>         >> Copying final
>>         >> > fields to locals generates smaller bytecode and might
>>         help the jit
>>         >> produce
>>         >> > better code (and with current hotspot, still does).
>>         >> >
>>         >> > Using final on locals has no performance advantage, but
>>         it does have
>>         >> some
>>         >> > software engineering advantages. We tend to use it for
>>         locals with
>>         >> the same
>>         >> > name as a field, e.g.
>>         >> >
>>         >> > final Foo foo = this.foo;
>>         >> >
>>         >> > Martin
>>         >
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
- DML

From davidcholmes at aapt.net.au  Sun Jan 23 17:30:03 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 24 Jan 2011 08:30:03 +1000
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <4D3C4D2D.2080006@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEMOIKAA.davidcholmes@aapt.net.au>

David,

> There's a bit more to it than that.  System.in/out/err are "special" in
> that they are final but can be reloaded in the normal course of program
> execution.

But that happens during VM initialization and is covered by "before they are
made available for access by other parts of a program" clause.

I guess all this just reinforces why finals are tricky to handle and hence
why the j.u.c code loads finals into locals.

David Holmes

> On 01/22/2011 09:20 PM, David Holmes wrote:
> > Remi,
> > The specification makes it clear that setting of a final field via
> > reflection is only valid in certain contexts:
> > "Setting a final field in this way is meaningful only during
> > deserialization or reconstruction of instances of classes with blank
> > final fields, before they are made available for access by other parts
> > of a program. Use in any other context may have unpredictable effects,
> > including cases in which other parts of a program continue to use the
> > original value of this field. "
> > So the compiler can optimize away re-loading of final fields, even if
> > reflection (or Unsafe) is mis-used. (Though compilation of
> > deserialization code would have to be handled specially.)
> > David
> >
> >     -----Original Message-----
> >     *From:* R?mi Forax [mailto:forax at univ-mlv.fr]
> >     *Sent:* Sunday, 23 January 2011 10:49 AM
> >     *To:* dholmes at ieee.org
> >     *Cc:* David Holmes; Vitaly Davidovich;
> >     concurrency-interest at cs.oswego.edu
> >     *Subject:* Re: [concurrency-interest] Making copy of a
> >     referencetoReentrantLock
> >
> >     On 01/23/2011 01:37 AM, David Holmes wrote:
> >>     Re-loading a final field is always redundant, the question is
> >>     whether the compiler recognizes that regardless of method calls or
> >>     inlining. It didn't in the past. I dont know what it does now.
> >
> >     You can't optimize re-loading of final field if the field is changed
> >     (by reflection or using unsafe) in the middle.
> >     That why it depends on method calls/inlining.
> >
> >     The other solution is optimize optimistically and deopt if someone
> >     changes the field.
> >     Hotspot don't do that.
> >
> >>     Remi:thanks for correcting my comment on final locals.
> >>     Cheers,
> >>     David
> >
> >     regards,
> >     R?mi
> >
> >>         -----Original Message-----
> >>         *From:* concurrency-interest-bounces at cs.oswego.edu
> >>         [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf
> >>         Of *Vitaly Davidovich
> >>         *Sent:* Sunday, 23 January 2011 9:21 AM
> >>         *To:* R?mi Forax
> >>         *Cc:* Martin Buchholz; concurrency-interest at cs.oswego.edu
> >>         *Subject:* Re: [concurrency-interest] Making copy of a
> >>         referencetoReentrantLock
> >>
> >>         I guess you're talking about final field loads across method
> >>         calls by mentioning inlining; if so, clearly inlining exposes
> >>         opportunities for optos, but I'm personally curious whether
> >>         all loads are eliminated within one method - seems you're
> >>         saying that's the case (I should take a look at the
> >>         disassembly myself and not be lazy :)). Furthermore, with
> >>         respect to the original question, interesting to know whether
> >>         lock() and the like prevent this opto in the latest product
> >>         hotspot.
> >>
> >>         On Jan 22, 2011 6:03 PM, "R?mi Forax" <forax at univ-mlv.fr
> >>         <mailto:forax at univ-mlv.fr>> wrote:
> >>         > On 01/22/2011 10:24 PM, Vitaly Davidovich wrote:
> >>         >>
> >>         >> Martin,
> >>         >>
> >>         >> Are you saying that the current (e.g. jdk 6u23) C2 compiler
> >>         (let's
> >>         >> focus on this one) does not eliminate repeated loads of
> >>         final fields
> >>         >> even in trivial methods (i.e. no mem fences)? I'd imagine
> >>         that's a
> >>         >> failure in the compiler if that's true. Style/engineering
> >>         practices
> >>         >> aside, developers should not have to resort to manually
> >>         optimizing a
> >>         >> final read by using a local. I'm still curious to hear from
> >>         someone
> >>         >> on the compiler team on this subject.
> >>         >>
> >>         >> Vitaly
> >>         >>
> >>         >
> >>         > c1 and c2 eliminate redundant loads (as far as I can see by
> >>         playing with
> >>         > hsdis),
> >>         > but for that all the bytecodes between the two loads must be
> >>         inlined.
> >>         > It's often the case with c2, c1 is less aggressive.
> >>         >
> >>         > R?mi
> >>         >
> >>         >> On Jan 22, 2011 3:35 PM, "Martin Buchholz"
> >>         <martinrb at google.com <mailto:martinrb at google.com>
> >>         >> <mailto:martinrb at google.com <mailto:martinrb at google.com>>>
> >>         wrote:
> >>         >> > On Sat, Jan 22, 2011 at 04:55, R?mi Forax
> >>         <forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>
> >>         >> <mailto:forax at univ-mlv.fr
> <mailto:forax at univ-mlv.fr>>> wrote:
> >>         >> >
> >>         >> >>
> >>         >> >> No, making the local final doesn't trigger any
> optimization.
> >>         >> >> javac doesn't do any optimization and in the bytecode
> >>         there is no
> >>         >> way to
> >>         >> >> say this local variable is final.
> >>         >> >>
> >>         >> >
> >>         >> > We in jsr166-land consider our software important enough
> >>         to make
> >>         >> > optimizations we don't recommend to regular java
> >>         programmers.
> >>         >> Copying final
> >>         >> > fields to locals generates smaller bytecode and might
> >>         help the jit
> >>         >> produce
> >>         >> > better code (and with current hotspot, still does).
> >>         >> >
> >>         >> > Using final on locals has no performance advantage, but
> >>         it does have
> >>         >> some
> >>         >> > software engineering advantages. We tend to use it for
> >>         locals with
> >>         >> the same
> >>         >> > name as a field, e.g.
> >>         >> >
> >>         >> > final Foo foo = this.foo;
> >>         >> >
> >>         >> > Martin
> >>         >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> --
> - DML
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From david.lloyd at redhat.com  Sun Jan 23 18:03:04 2011
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Sun, 23 Jan 2011 17:03:04 -0600
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEMOIKAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEMOIKAA.davidcholmes@aapt.net.au>
Message-ID: <4D3CB3A8.2060103@redhat.com>

On 01/23/2011 04:30 PM, David Holmes wrote:
> David,
>
>> There's a bit more to it than that.  System.in/out/err are "special" in
>> that they are final but can be reloaded in the normal course of program
>> execution.
>
> But that happens during VM initialization and is covered by "before they are
> made available for access by other parts of a program" clause.

However, you can call System.setIn/Out/Err() at any time, thus it's not 
exclusively relegated to VM init.

-- 
- DML

From davidcholmes at aapt.net.au  Sun Jan 23 18:41:57 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 24 Jan 2011 09:41:57 +1000
Subject: [concurrency-interest] Making copy of a referencetoReentrantLock
In-Reply-To: <4D3CB3A8.2060103@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEMPIKAA.davidcholmes@aapt.net.au>

David Lloyd writes:
> >> There's a bit more to it than that.  System.in/out/err are "special" in
> >> that they are final but can be reloaded in the normal course of program
> >> execution.
> >
> > But that happens during VM initialization and is covered by
> "before they are
> > made available for access by other parts of a program" clause.
>
> However, you can call System.setIn/Out/Err() at any time, thus it's not
> exclusively relegated to VM init.

Ouch! So you can. Those static fields are treated specially by the compiler
as explicitly not being considered constants.

David


From rmcilroy at microsoft.com  Fri Jan 28 18:13:06 2011
From: rmcilroy at microsoft.com (Ross McIlroy)
Date: Fri, 28 Jan 2011 23:13:06 +0000
Subject: [concurrency-interest] [CfP]: Workshop on Systems for Future
 Multi-Core Architectures at EuroSys 2011
In-Reply-To: <5109AB538DE99B41A5C31A5882E1EE9628213A17@TK5EX14MBXC113.redmond.corp.microsoft.com>
References: <5109AB538DE99B41A5C31A5882E1EE9628213A17@TK5EX14MBXC113.redmond.corp.microsoft.com>
Message-ID: <5109AB538DE99B41A5C31A5882E1EE962826B874@TK5EX14MBXC115.redmond.corp.microsoft.com>

[Apologies if you receive multiple copies of this CfP]

New deadline: ** 8th February **


=================================================================
                        Call for Papers

Workshop on Systems for Future Multi-Core Architectures (SFMA'11)

               April 10th 2011,  Salzburg, Austria
                   Co-located with EuroSys 2011<http://eurosys2011.cs.uni-salzburg.at/welcome.php>

          http://research.microsoft.com/~rmcilroy/SFMA/index.htm
=================================================================

The current trend towards multi-core computing is of significant
importance to practitioners of systems-level software, such as
operating systems, language runtimes and virtual machines. As the
layer between application software and the underlying hardware,
systems-level software must directly tackle the challenges of
multi-core hardware (e.g., scalability, concurrency control and
data-sharing costs), while providing appropriate abstractions to
higher-level software. Future hardware is likely to increase the
challenges encountered by systems software due to increasing
system diversity, core heterogeneity, complex memory hierarchies,
dynamic core failure, and non-cache coherent shared memory.
However, the abundance of parallelism and potential for core
specialization and inter-core message passing hardware also
provide a number of new opportunities for system software. The
current shift in hardware design provides an exciting opportunity
to radically rethink the design and implementation of systems-
level software.

The workshop on Systems for Future Multi-Core Architectures
(SFMA'11) brings together researchers in the operating systems,
language runtime and virtual machine communities to exchange
ideas and experiences on the challenges and opportunities
presented by future multi-core hardware.

The workshop program will include presentations of peer-reviewed
papers as well as a panel with participants from research /
academia and industry. SFMA topics of interest include, but are
not limited to:


?         novel multi-core operating system designs,

?         runtime systems and programming environments for future

hardware, operating system or runtime support for

heterogeneous processing cores, scheduling on many-core

architectures,

?         energy efficiency, fault tolerance and resource management on

future multi-core architectures,

?         performance evaluation of potential future hardware,

?         architectural support for systems-level software,

?         case studies of system-level software design for current or

future multi-core hardware.

Paper Submission:
-----------------

Authors are invited to submit original and unpublished work that
exposes a new problem, advocates a specific solution, or reports
on actual experience. Papers should be submitted using the
standard double column ACM SIG proceedings format, to
https://eurosys2011.ertos.nicta.com.au/workshops/sfma/hotcrp/.
Papers are limited to 6 pages, including figures and tables.

Final papers will be available to participants electronically at
the meeting, but to facilitate resubmission to more formal venues,
no archival proceedings will be published, and papers will not be
sent to the ACM Digital Library. Authors will have the option of
having their final paper accessible from the workshop website.

Important dates:
----------------
Submissions due: 8th February 2011 (11:59pm PST)
Notification: 1st March 2011
Workshop: 10th April 2011

Program committee:
------------------
Ali-Reza Adl-Tabatabai (Intel)
Mats Brorsson (KTH Royal Institute of Technology, Sweden)
Juan Colmenares (University of California, Berkeley)
Stephan Diestelhorst (AMD)
Tim Harris (Microsoft Research Cambridge)
Hermann H?rtig (TU Dresden)
Ross McIlroy (Microsoft Research Cambridge)
Derek Murray (University of Cambridge)
Timothy Roscoe (ETH Z?rich)
Michael Scott (University of Rochester)
Jeremy Singer (University of Glasgow)
Joe Sventek (University of Glasgow)
Michael Swift (University of Wisconsin)
Ian Watson (University of Manchester)
Nickolai Zeldovich (MIT)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110128/c8b4cd01/attachment.html>

From mohanr at fss.co.in  Sat Jan 29 09:17:16 2011
From: mohanr at fss.co.in (Mohan Radhakrishnan)
Date: Sat, 29 Jan 2011 19:47:16 +0530
Subject: [concurrency-interest] Possibly Offtopic - Java
	Concurrency/Parallelism adoption by Clojure
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEMPIKAA.davidcholmes@aapt.net.au>
Message-ID: <E49F4E6D734B954487B074B4EFE60D0123FA19@fssbemail.fss.india>

Hi,
       I am a beginner and I have come across news that Fork/Join is
reused by Clojure to support parallelism.

I would like to know if the existing concurrency support ( Futures ? )
are also reused. I am posting this here first because the JSR 166
contributors might have been consulted by the Clojure developers.


Thanks,
Mohan


From joe.bowbeer at gmail.com  Sat Jan 29 16:01:16 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 29 Jan 2011 13:01:16 -0800
Subject: [concurrency-interest] Possibly Offtopic - Java
 Concurrency/Parallelism adoption by Clojure
In-Reply-To: <E49F4E6D734B954487B074B4EFE60D0123FA19@fssbemail.fss.india>
References: <NFBBKALFDCPFIDBNKAPCAEMPIKAA.davidcholmes@aapt.net.au>
	<E49F4E6D734B954487B074B4EFE60D0123FA19@fssbemail.fss.india>
Message-ID: <AANLkTikaECNb7m+LEpyiRGEaysyCfK1r2LtKU6fX2_rr@mail.gmail.com>

Clojure embraces Future and Callable.  A "future-call" in Closure returns a
java.util.concurrent Future.  Follow the source link in the doc below to see
its implementation.

http://richhickey.github.com/clojure/clojure.core-api.html#clojure.core/future-call

More on Clojure concurrency at the link below.

http://clojure.org/concurrent_programming

This talk by Clojure's creator Rich Hickey is excellent -- particularly at
24:20 :-)

http://blip.tv/file/812787

On Sat, Jan 29, 2011 at 6:17 AM, Mohan Radhakrishnan wrote:

> Hi,
>       I am a beginner and I have come across news that Fork/Join is
> reused by Clojure to support parallelism.
>
> I would like to know if the existing concurrency support ( Futures ? )
> are also reused. I am posting this here first because the JSR 166
> contributors might have been consulted by the Clojure developers.
>
>
> Thanks,
> Mohan
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110129/0cc79e6d/attachment.html>

From alex at puredanger.com  Sat Jan 29 16:55:06 2011
From: alex at puredanger.com (Alex Miller)
Date: Sat, 29 Jan 2011 15:55:06 -0600
Subject: [concurrency-interest] Possibly Offtopic - Java
	Concurrency/Parallelism adoption by Clojure
Message-ID: <AANLkTikoMBuHv4mZuOO0cW=rs9U81CFSw-BKgS2ZLbf5@mail.gmail.com>

Fork/join is not currently used in Clojure core.  There is an
experimental version that provides support for parallel sequence
operations (filter, map, reduce, etc) over a fork-join pool (discussed
in David Liebke's talk at the Clojure Conj conference last year:
http://incanter.org/downloads/fjclj.pdf ) but it will evolve and
probably not be included in Clojure core for some time to come.

The concurrency model in Clojure is based primarily on immutable
(persistent) functional data structures.  Immutability means all core
Clojure data structures to be thread-safe.  Mutable state is supported
by the ref construct which provides identity and a reference to the
current version of an immutable data structure.  Changes to refs are
protected by a software transactional memory system.  To change one
(or more) refs you must create a transaction that is applied by the
STM and may retry.  See http://clojure.org/refs for much more info.
There are also atoms (for uncoordinated synchronous state) and agents
(asynchronous uncoordinated state).  Change requests are sent to
agents with either send (for CPU tasks) or send-off (for possible I/O
blocking tasks).  Agent send is backed by
Executors.newFixedThreadPool() of size 2 + # processors.  Agent
send-off is backed by an unbounded Executors.newCachedThreadPool().
Clojure also supports a "future" that will execute an arbitrary
function body (all Clojure functions implement Runnable and Callable)
in a separate thread and return an instance of Future.  Clojure
provides a set of helper functions that expose all of the Future
methods (except timed get).

As far as I know, Scala uses fork/join underneath the Scala actor
pool.  Also Fortress uses fork/join as the basis of its
threading/concurrency model.

Hope that helps...


Mohan Radhakrishnan wrote:

> ? ? ? I am a beginner and I have come across news that Fork/Join is
> reused by Clojure to support parallelism.
>
> I would like to know if the existing concurrency support ( Futures ? )
> are also reused. I am posting this here first because the JSR 166
> contributors might have been consulted by the Clojure developers.


From markus.jevring at petercam.be  Mon Jan 31 04:50:48 2011
From: markus.jevring at petercam.be (Markus Jevring)
Date: Mon, 31 Jan 2011 10:50:48 +0100
Subject: [concurrency-interest] Concurrent writes to an array with safe
	handover
In-Reply-To: <AANLkTikoMBuHv4mZuOO0cW=rs9U81CFSw-BKgS2ZLbf5@mail.gmail.com>
References: <AANLkTikoMBuHv4mZuOO0cW=rs9U81CFSw-BKgS2ZLbf5@mail.gmail.com>
Message-ID: <FC96218C31BC8442949628C0A26159979685EF8C38@emaildata.petercam.corp>

Hey folks, 

I have a question about concurrent array access that you might be able to help me with.
Say I have a two-dimensional array (imagine a screen buffer), that I have many threads writing to. There is never any write target overlap. E.g., one thread per row. What would I have to do to safely hand over this array (with all the writes happening-before the hand-over) to another thread (for rendering)? Do I have to force a volatile write (reassignment?) of the array, or is waiting on some synchronization primitive (for instance a CountDownLatch) sufficient to ensure that the receiving thread sees all the writes made to the array, or do I have to do something else? The array is created anew before each cycle, so there would never be any updates, just the handover.

Markus

From davidcholmes at aapt.net.au  Mon Jan 31 05:25:06 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 31 Jan 2011 20:25:06 +1000
Subject: [concurrency-interest] Concurrent writes to an array with
	safehandover
In-Reply-To: <FC96218C31BC8442949628C0A26159979685EF8C38@emaildata.petercam.corp>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEAAILAA.davidcholmes@aapt.net.au>

Hi Markus,

You just have to insert a happens-before edge as part of the handover. This
could be done by handing-over via a volatile field, or handing-over via a
synchronized data structure (blocking queue, or perhaps an Exchanger) or by
explicitly synchronizing the two threads involved via a synchronizer
(semaphore/latch/barrier etc)

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Markus
> Jevring
> Sent: Monday, 31 January 2011 7:51 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Concurrent writes to an array with
> safehandover
>
>
> Hey folks,
>
> I have a question about concurrent array access that you might be
> able to help me with.
> Say I have a two-dimensional array (imagine a screen buffer),
> that I have many threads writing to. There is never any write
> target overlap. E.g., one thread per row. What would I have to do
> to safely hand over this array (with all the writes
> happening-before the hand-over) to another thread (for
> rendering)? Do I have to force a volatile write (reassignment?)
> of the array, or is waiting on some synchronization primitive
> (for instance a CountDownLatch) sufficient to ensure that the
> receiving thread sees all the writes made to the array, or do I
> have to do something else? The array is created anew before each
> cycle, so there would never be any updates, just the handover.
>
> Markus
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From markus.jevring at petercam.be  Mon Jan 31 05:33:07 2011
From: markus.jevring at petercam.be (Markus Jevring)
Date: Mon, 31 Jan 2011 11:33:07 +0100
Subject: [concurrency-interest] Concurrent writes to an array with
 safehandover
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEAAILAA.davidcholmes@aapt.net.au>
References: <FC96218C31BC8442949628C0A26159979685EF8C38@emaildata.petercam.corp>
	<NFBBKALFDCPFIDBNKAPCAEAAILAA.davidcholmes@aapt.net.au>
Message-ID: <FC96218C31BC8442949628C0A26159979685EF8C44@emaildata.petercam.corp>

Excellent, thanks! 

-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Monday, January 31, 2011 11:25 AM
To: Markus Jevring; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Concurrent writes to an array with safehandover

Hi Markus,

You just have to insert a happens-before edge as part of the handover. This
could be done by handing-over via a volatile field, or handing-over via a
synchronized data structure (blocking queue, or perhaps an Exchanger) or by
explicitly synchronizing the two threads involved via a synchronizer
(semaphore/latch/barrier etc)

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Markus
> Jevring
> Sent: Monday, 31 January 2011 7:51 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Concurrent writes to an array with
> safehandover
>
>
> Hey folks,
>
> I have a question about concurrent array access that you might be
> able to help me with.
> Say I have a two-dimensional array (imagine a screen buffer),
> that I have many threads writing to. There is never any write
> target overlap. E.g., one thread per row. What would I have to do
> to safely hand over this array (with all the writes
> happening-before the hand-over) to another thread (for
> rendering)? Do I have to force a volatile write (reassignment?)
> of the array, or is waiting on some synchronization primitive
> (for instance a CountDownLatch) sufficient to ensure that the
> receiving thread sees all the writes made to the array, or do I
> have to do something else? The array is created anew before each
> cycle, so there would never be any updates, just the handover.
>
> Markus
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From davidcholmes at aapt.net.au  Mon Jan 31 06:36:12 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 31 Jan 2011 21:36:12 +1000
Subject: [concurrency-interest] Concurrent writes to an array with
	safehandover
In-Reply-To: <FC96218C31BC8442949628C0A26159979685EF8C44@emaildata.petercam.corp>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEAAILAA.davidcholmes@aapt.net.au>

Sorry I have to retract that. What I said assumed that all the writes into
the array happen-before the handover. But with different threads doing the
writes you would have to synchronize with every thread to ensure all the
writes happen-before the handover.

David

> -----Original Message-----
> From: Markus Jevring [mailto:markus.jevring at petercam.be]
> Sent: Monday, 31 January 2011 8:33 PM
> To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Concurrent writes to an array with
> safehandover
>
>
> Excellent, thanks!
>
> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 31, 2011 11:25 AM
> To: Markus Jevring; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Concurrent writes to an array
> with safehandover
>
> Hi Markus,
>
> You just have to insert a happens-before edge as part of the
> handover. This
> could be done by handing-over via a volatile field, or handing-over via a
> synchronized data structure (blocking queue, or perhaps an
> Exchanger) or by
> explicitly synchronizing the two threads involved via a synchronizer
> (semaphore/latch/barrier etc)
>
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Markus
> > Jevring
> > Sent: Monday, 31 January 2011 7:51 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Concurrent writes to an array with
> > safehandover
> >
> >
> > Hey folks,
> >
> > I have a question about concurrent array access that you might be
> > able to help me with.
> > Say I have a two-dimensional array (imagine a screen buffer),
> > that I have many threads writing to. There is never any write
> > target overlap. E.g., one thread per row. What would I have to do
> > to safely hand over this array (with all the writes
> > happening-before the hand-over) to another thread (for
> > rendering)? Do I have to force a volatile write (reassignment?)
> > of the array, or is waiting on some synchronization primitive
> > (for instance a CountDownLatch) sufficient to ensure that the
> > receiving thread sees all the writes made to the array, or do I
> > have to do something else? The array is created anew before each
> > cycle, so there would never be any updates, just the handover.
> >
> > Markus
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>


From markus.jevring at petercam.be  Mon Jan 31 06:44:47 2011
From: markus.jevring at petercam.be (Markus Jevring)
Date: Mon, 31 Jan 2011 12:44:47 +0100
Subject: [concurrency-interest] Concurrent writes to an array with
 safehandover
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEAAILAA.davidcholmes@aapt.net.au>
References: <FC96218C31BC8442949628C0A26159979685EF8C44@emaildata.petercam.corp>
	<NFBBKALFDCPFIDBNKAPCOEAAILAA.davidcholmes@aapt.net.au>
Message-ID: <FC96218C31BC8442949628C0A26159979685EF8C58@emaildata.petercam.corp>

Could I do that with a CountDownLatch? That would certainly ensure that the handover didn't happen until all the writing threads were completed. After that, using a SynchronousQueue or something to do the handover should work, right? 

-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Monday, January 31, 2011 12:36 PM
To: Markus Jevring; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Concurrent writes to an array with safehandover

Sorry I have to retract that. What I said assumed that all the writes into
the array happen-before the handover. But with different threads doing the
writes you would have to synchronize with every thread to ensure all the
writes happen-before the handover.

David

> -----Original Message-----
> From: Markus Jevring [mailto:markus.jevring at petercam.be]
> Sent: Monday, 31 January 2011 8:33 PM
> To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Concurrent writes to an array with
> safehandover
>
>
> Excellent, thanks!
>
> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 31, 2011 11:25 AM
> To: Markus Jevring; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Concurrent writes to an array
> with safehandover
>
> Hi Markus,
>
> You just have to insert a happens-before edge as part of the
> handover. This
> could be done by handing-over via a volatile field, or handing-over via a
> synchronized data structure (blocking queue, or perhaps an
> Exchanger) or by
> explicitly synchronizing the two threads involved via a synchronizer
> (semaphore/latch/barrier etc)
>
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Markus
> > Jevring
> > Sent: Monday, 31 January 2011 7:51 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Concurrent writes to an array with
> > safehandover
> >
> >
> > Hey folks,
> >
> > I have a question about concurrent array access that you might be
> > able to help me with.
> > Say I have a two-dimensional array (imagine a screen buffer),
> > that I have many threads writing to. There is never any write
> > target overlap. E.g., one thread per row. What would I have to do
> > to safely hand over this array (with all the writes
> > happening-before the hand-over) to another thread (for
> > rendering)? Do I have to force a volatile write (reassignment?)
> > of the array, or is waiting on some synchronization primitive
> > (for instance a CountDownLatch) sufficient to ensure that the
> > receiving thread sees all the writes made to the array, or do I
> > have to do something else? The array is created anew before each
> > cycle, so there would never be any updates, just the handover.
> >
> > Markus
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>



From davidcholmes at aapt.net.au  Mon Jan 31 06:49:28 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 31 Jan 2011 21:49:28 +1000
Subject: [concurrency-interest] Concurrent writes to an array with
	safehandover
In-Reply-To: <FC96218C31BC8442949628C0A26159979685EF8C58@emaildata.petercam.corp>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEABILAA.davidcholmes@aapt.net.au>


Markus Jevring writes:
>
> Could I do that with a CountDownLatch? That would certainly
> ensure that the handover didn't happen until all the writing
> threads were completed. After that, using a SynchronousQueue or
> something to do the handover should work, right?

Yes, if all the writers do a countDown() on the latch you could simply have
the thread "receiving" the array do the await() on the latch. That in itself
would make the handover safe.

David

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 31, 2011 12:36 PM
> To: Markus Jevring; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Concurrent writes to an array
> with safehandover
>
> Sorry I have to retract that. What I said assumed that all the writes into
> the array happen-before the handover. But with different threads doing the
> writes you would have to synchronize with every thread to ensure all the
> writes happen-before the handover.
>
> David
>
> > -----Original Message-----
> > From: Markus Jevring [mailto:markus.jevring at petercam.be]
> > Sent: Monday, 31 January 2011 8:33 PM
> > To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Concurrent writes to an array with
> > safehandover
> >
> >
> > Excellent, thanks!
> >
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 31, 2011 11:25 AM
> > To: Markus Jevring; concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Concurrent writes to an array
> > with safehandover
> >
> > Hi Markus,
> >
> > You just have to insert a happens-before edge as part of the
> > handover. This
> > could be done by handing-over via a volatile field, or
> handing-over via a
> > synchronized data structure (blocking queue, or perhaps an
> > Exchanger) or by
> > explicitly synchronizing the two threads involved via a synchronizer
> > (semaphore/latch/barrier etc)
> >
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Markus
> > > Jevring
> > > Sent: Monday, 31 January 2011 7:51 PM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: [concurrency-interest] Concurrent writes to an array with
> > > safehandover
> > >
> > >
> > > Hey folks,
> > >
> > > I have a question about concurrent array access that you might be
> > > able to help me with.
> > > Say I have a two-dimensional array (imagine a screen buffer),
> > > that I have many threads writing to. There is never any write
> > > target overlap. E.g., one thread per row. What would I have to do
> > > to safely hand over this array (with all the writes
> > > happening-before the hand-over) to another thread (for
> > > rendering)? Do I have to force a volatile write (reassignment?)
> > > of the array, or is waiting on some synchronization primitive
> > > (for instance a CountDownLatch) sufficient to ensure that the
> > > receiving thread sees all the writes made to the array, or do I
> > > have to do something else? The array is created anew before each
> > > cycle, so there would never be any updates, just the handover.
> > >
> > > Markus
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
>
>


From markus.jevring at petercam.be  Mon Jan 31 06:52:19 2011
From: markus.jevring at petercam.be (Markus Jevring)
Date: Mon, 31 Jan 2011 12:52:19 +0100
Subject: [concurrency-interest] Concurrent writes to an array with
 safehandover
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEABILAA.davidcholmes@aapt.net.au>
References: <FC96218C31BC8442949628C0A26159979685EF8C58@emaildata.petercam.corp>
	<NFBBKALFDCPFIDBNKAPCOEABILAA.davidcholmes@aapt.net.au>
Message-ID: <FC96218C31BC8442949628C0A26159979685EF8C5A@emaildata.petercam.corp>

I envision something like submit():ing a Callable to some Executor, and then doing Future.get() on the result. The callable spawns the writers and does await() on the latch (and the writers do countDown() when done). When await() returns, the callable returns, providing the coutside caller with the array. Should work, right? 

-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Monday, January 31, 2011 12:49 PM
To: Markus Jevring; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Concurrent writes to an array with safehandover


Markus Jevring writes:
>
> Could I do that with a CountDownLatch? That would certainly
> ensure that the handover didn't happen until all the writing
> threads were completed. After that, using a SynchronousQueue or
> something to do the handover should work, right?

Yes, if all the writers do a countDown() on the latch you could simply have
the thread "receiving" the array do the await() on the latch. That in itself
would make the handover safe.

David

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Monday, January 31, 2011 12:36 PM
> To: Markus Jevring; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Concurrent writes to an array
> with safehandover
>
> Sorry I have to retract that. What I said assumed that all the writes into
> the array happen-before the handover. But with different threads doing the
> writes you would have to synchronize with every thread to ensure all the
> writes happen-before the handover.
>
> David
>
> > -----Original Message-----
> > From: Markus Jevring [mailto:markus.jevring at petercam.be]
> > Sent: Monday, 31 January 2011 8:33 PM
> > To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Concurrent writes to an array with
> > safehandover
> >
> >
> > Excellent, thanks!
> >
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 31, 2011 11:25 AM
> > To: Markus Jevring; concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Concurrent writes to an array
> > with safehandover
> >
> > Hi Markus,
> >
> > You just have to insert a happens-before edge as part of the
> > handover. This
> > could be done by handing-over via a volatile field, or
> handing-over via a
> > synchronized data structure (blocking queue, or perhaps an
> > Exchanger) or by
> > explicitly synchronizing the two threads involved via a synchronizer
> > (semaphore/latch/barrier etc)
> >
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Markus
> > > Jevring
> > > Sent: Monday, 31 January 2011 7:51 PM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: [concurrency-interest] Concurrent writes to an array with
> > > safehandover
> > >
> > >
> > > Hey folks,
> > >
> > > I have a question about concurrent array access that you might be
> > > able to help me with.
> > > Say I have a two-dimensional array (imagine a screen buffer),
> > > that I have many threads writing to. There is never any write
> > > target overlap. E.g., one thread per row. What would I have to do
> > > to safely hand over this array (with all the writes
> > > happening-before the hand-over) to another thread (for
> > > rendering)? Do I have to force a volatile write (reassignment?)
> > > of the array, or is waiting on some synchronization primitive
> > > (for instance a CountDownLatch) sufficient to ensure that the
> > > receiving thread sees all the writes made to the array, or do I
> > > have to do something else? The array is created anew before each
> > > cycle, so there would never be any updates, just the handover.
> > >
> > > Markus
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
>
>



From davidcholmes at aapt.net.au  Mon Jan 31 06:56:49 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 31 Jan 2011 21:56:49 +1000
Subject: [concurrency-interest] Concurrent writes to an array with
	safehandover
In-Reply-To: <FC96218C31BC8442949628C0A26159979685EF8C5A@emaildata.petercam.corp>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEACILAA.davidcholmes@aapt.net.au>

> Markus Jevring writes:>
> I envision something like submit():ing a Callable to some
> Executor, and then doing Future.get() on the result. The callable
> spawns the writers and does await() on the latch (and the writers
> do countDown() when done). When await() returns, the callable
> returns, providing the coutside caller with the array. Should
> work, right?

Yes.

David Holmes

>
>
> Markus Jevring writes:
> >
> > Could I do that with a CountDownLatch? That would certainly
> > ensure that the handover didn't happen until all the writing
> > threads were completed. After that, using a SynchronousQueue or
> > something to do the handover should work, right?
>
> Yes, if all the writers do a countDown() on the latch you could
> simply have
> the thread "receiving" the array do the await() on the latch.
> That in itself
> would make the handover safe.
>
> David
>
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 31, 2011 12:36 PM
> > To: Markus Jevring; concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Concurrent writes to an array
> > with safehandover
> >
> > Sorry I have to retract that. What I said assumed that all the
> writes into
> > the array happen-before the handover. But with different
> threads doing the
> > writes you would have to synchronize with every thread to ensure all the
> > writes happen-before the handover.
> >
> > David
> >
> > > -----Original Message-----
> > > From: Markus Jevring [mailto:markus.jevring at petercam.be]
> > > Sent: Monday, 31 January 2011 8:33 PM
> > > To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Concurrent writes to an array with
> > > safehandover
> > >
> > >
> > > Excellent, thanks!
> > >
> > > -----Original Message-----
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 31, 2011 11:25 AM
> > > To: Markus Jevring; concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Concurrent writes to an array
> > > with safehandover
> > >
> > > Hi Markus,
> > >
> > > You just have to insert a happens-before edge as part of the
> > > handover. This
> > > could be done by handing-over via a volatile field, or
> > handing-over via a
> > > synchronized data structure (blocking queue, or perhaps an
> > > Exchanger) or by
> > > explicitly synchronizing the two threads involved via a synchronizer
> > > (semaphore/latch/barrier etc)
> > >
> > > David Holmes
> > >
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On
> Behalf Of Markus
> > > > Jevring
> > > > Sent: Monday, 31 January 2011 7:51 PM
> > > > To: concurrency-interest at cs.oswego.edu
> > > > Subject: [concurrency-interest] Concurrent writes to an array with
> > > > safehandover
> > > >
> > > >
> > > > Hey folks,
> > > >
> > > > I have a question about concurrent array access that you might be
> > > > able to help me with.
> > > > Say I have a two-dimensional array (imagine a screen buffer),
> > > > that I have many threads writing to. There is never any write
> > > > target overlap. E.g., one thread per row. What would I have to do
> > > > to safely hand over this array (with all the writes
> > > > happening-before the hand-over) to another thread (for
> > > > rendering)? Do I have to force a volatile write (reassignment?)
> > > > of the array, or is waiting on some synchronization primitive
> > > > (for instance a CountDownLatch) sufficient to ensure that the
> > > > receiving thread sees all the writes made to the array, or do I
> > > > have to do something else? The array is created anew before each
> > > > cycle, so there would never be any updates, just the handover.
> > > >
> > > > Markus
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at cs.oswego.edu
> > > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >
> > >
> > >
> >
> >
>
>


From markus.jevring at petercam.be  Mon Jan 31 06:58:18 2011
From: markus.jevring at petercam.be (Markus Jevring)
Date: Mon, 31 Jan 2011 12:58:18 +0100
Subject: [concurrency-interest] Concurrent writes to an array with
 safehandover
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEACILAA.davidcholmes@aapt.net.au>
References: <FC96218C31BC8442949628C0A26159979685EF8C5A@emaildata.petercam.corp>
	<NFBBKALFDCPFIDBNKAPCKEACILAA.davidcholmes@aapt.net.au>
Message-ID: <FC96218C31BC8442949628C0A26159979685EF8C5D@emaildata.petercam.corp>

Once again then, Excellent, thanks! =)

Markus 

-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au] 
Sent: Monday, January 31, 2011 12:57 PM
To: Markus Jevring; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Concurrent writes to an array with safehandover

> Markus Jevring writes:>
> I envision something like submit():ing a Callable to some
> Executor, and then doing Future.get() on the result. The callable
> spawns the writers and does await() on the latch (and the writers
> do countDown() when done). When await() returns, the callable
> returns, providing the coutside caller with the array. Should
> work, right?

Yes.

David Holmes

>
>
> Markus Jevring writes:
> >
> > Could I do that with a CountDownLatch? That would certainly
> > ensure that the handover didn't happen until all the writing
> > threads were completed. After that, using a SynchronousQueue or
> > something to do the handover should work, right?
>
> Yes, if all the writers do a countDown() on the latch you could
> simply have
> the thread "receiving" the array do the await() on the latch.
> That in itself
> would make the handover safe.
>
> David
>
> > -----Original Message-----
> > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > Sent: Monday, January 31, 2011 12:36 PM
> > To: Markus Jevring; concurrency-interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] Concurrent writes to an array
> > with safehandover
> >
> > Sorry I have to retract that. What I said assumed that all the
> writes into
> > the array happen-before the handover. But with different
> threads doing the
> > writes you would have to synchronize with every thread to ensure all the
> > writes happen-before the handover.
> >
> > David
> >
> > > -----Original Message-----
> > > From: Markus Jevring [mailto:markus.jevring at petercam.be]
> > > Sent: Monday, 31 January 2011 8:33 PM
> > > To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Concurrent writes to an array with
> > > safehandover
> > >
> > >
> > > Excellent, thanks!
> > >
> > > -----Original Message-----
> > > From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > Sent: Monday, January 31, 2011 11:25 AM
> > > To: Markus Jevring; concurrency-interest at cs.oswego.edu
> > > Subject: RE: [concurrency-interest] Concurrent writes to an array
> > > with safehandover
> > >
> > > Hi Markus,
> > >
> > > You just have to insert a happens-before edge as part of the
> > > handover. This
> > > could be done by handing-over via a volatile field, or
> > handing-over via a
> > > synchronized data structure (blocking queue, or perhaps an
> > > Exchanger) or by
> > > explicitly synchronizing the two threads involved via a synchronizer
> > > (semaphore/latch/barrier etc)
> > >
> > > David Holmes
> > >
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On
> Behalf Of Markus
> > > > Jevring
> > > > Sent: Monday, 31 January 2011 7:51 PM
> > > > To: concurrency-interest at cs.oswego.edu
> > > > Subject: [concurrency-interest] Concurrent writes to an array with
> > > > safehandover
> > > >
> > > >
> > > > Hey folks,
> > > >
> > > > I have a question about concurrent array access that you might be
> > > > able to help me with.
> > > > Say I have a two-dimensional array (imagine a screen buffer),
> > > > that I have many threads writing to. There is never any write
> > > > target overlap. E.g., one thread per row. What would I have to do
> > > > to safely hand over this array (with all the writes
> > > > happening-before the hand-over) to another thread (for
> > > > rendering)? Do I have to force a volatile write (reassignment?)
> > > > of the array, or is waiting on some synchronization primitive
> > > > (for instance a CountDownLatch) sufficient to ensure that the
> > > > receiving thread sees all the writes made to the array, or do I
> > > > have to do something else? The array is created anew before each
> > > > cycle, so there would never be any updates, just the handover.
> > > >
> > > > Markus
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at cs.oswego.edu
> > > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >
> > >
> > >
> >
> >
>
>



From asst2003 at sina.com  Mon Jan 31 08:27:42 2011
From: asst2003 at sina.com (asst2003 at sina.com)
Date: Mon, 31 Jan 2011 21:27:42 +0800 
Subject: [concurrency-interest] ABA Problem with ConcurrentLinkedQueue
Message-ID: <20110131132742.977AA50BA2@mail2-211.sinamail.sina.com.cn>

&nbsp;in ConcurrentLinkedQueue note :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;Note that like most non-blocking algorithms in this package,
&nbsp;&nbsp;&nbsp;&nbsp; * this implementation relies on the fact that in garbage 
&nbsp;&nbsp;&nbsp;&nbsp; * collected systems, there is no possibility of ABA problems due
&nbsp;&nbsp;&nbsp;&nbsp; * to recycled nodes, so there is no need to use "counted
&nbsp;&nbsp;&nbsp;&nbsp; * pointers" or related techniques seen in versions used in
&nbsp;&nbsp;&nbsp;&nbsp; * non-GC'ed settings.

because of java GC ?so&nbsp;no possibility of ABA problems?
if in GC environment&nbsp;?can&nbsp;avoid the ABA problem by letting the garbage collector manage link nodes?
&nbsp;
&nbsp;
in jdk7 ?how many concurrent Collection&nbsp;for Nonblocking Algorithms&nbsp; implement ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20110131/cae4fbd7/attachment.html>

