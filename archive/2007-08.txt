From Ben.Rowlands at morganstanley.com  Mon Aug 13 13:08:11 2007
From: Ben.Rowlands at morganstanley.com (Rowlands, Ben (IT))
Date: Mon, 13 Aug 2007 18:08:11 +0100
Subject: [concurrency-interest] Adding a createIfAbsent() API?
Message-ID: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>

I often find a need for an API like:

  public V createIfAbsent( K key, Callable<V> creator ) throws
ExcecutionException

Similar in operation to putIfAbsent() but taking a callback that is used
to resolve the value if one isn't found at at the key. 

A very common use-case of this is when we are using the Map to cache
values (for example, from a database query). We only want to execute the
database query if the value isn't already in the map so we can't use
putIfAbsent() directly and we end up wrapping the Map using a
lock-per-key or some other technique.

I know this kind of behaviour can be achieved using a
FutureTask/Executor etc (as described in "Concurrency in Practice")
however it seems such a useful primitive that I think it would be useful
to add to the ConcurrentMap API (or a new API in JUC) and would avoid
the copy/paste or need to roll your own implementation each time (add
will be even more succinct with closure support :). A slight difference
in the behaviour of this API is that if the creator fails with an
exception subsequent threads can have a go at creating the value rather
than forcing them to fail with the original exception.

The simple implementation below demonstrates this API using a
lock-per-key (note, createIfAbsent() -> getOrCreate()). 

Are there any plans for this sort of API in JUC? (or is there a 1-2 line
equivalent that I've overlooked and could be used instead?)

Thanks,

Ben Rowlands

----

public interface ConcurrentCreator<K, V>
{
  /**
   * Gets the value mapped to the key invoking the creator if no value
is set.
   * 
   * @param key
   * @param creator produces a value for the given key, will only be
called if there is no value
   *          currently mapped to the key.
   * @return the value mapped to the key, creating it if necessary.
   * @throws ExecutionException if any exceptions are thrown creating
the value.
   */
  public V getOrCreate( K key, Callable<V> creator ) throws
ExecutionException;

  public V get( K key );

  public V put( K key, V value );
}

----

// uses a lock-per-key to queue conflicting creators
public class SimpleConcurrentCreator<K, V> implements
ConcurrentCreator<K, V>
{
  private final ConcurrentMap<K, Lock<V>> map = new ConcurrentHashMap<K,
Lock<V>>();

  public V put( K key, V value )
  {
    Lock<V> newLock = new Lock<V>();
    Lock<V> fromMap = map.putIfAbsent( key, newLock );
    Lock<V> lock = fromMap == null ? newLock : fromMap;

    V oldValue = null;

    synchronized( lock )
    {
      if( lock.hasValue() )
      {
        oldValue = lock.getValue();
      }

      lock.setObject( value );
    }

    return oldValue;
  }

  public V get( K key )
  {
    Lock<V> lock = map.get( key );

    if( lock == null )
    {
      return null;
    }

    synchronized( lock )
    {
      return lock.getValue();
    }
  }

  public V getOrCreate( K key, Callable<V> creator ) throws
ExecutionException
  {
    Lock<V> newLock = new Lock<V>();
    Lock<V> fromMap = map.putIfAbsent( key, newLock );
    Lock<V> lock = fromMap == null ? newLock : fromMap;

    synchronized( lock )
    {
      if( lock.hasValue() )
      {
        return lock.getValue();
      }

      try
      {
        V result = creator.call();
        lock.setObject( result );
        return result;
      }
      catch( Exception e )
      {
        throw new ExecutionException( "Failed to generate value for key:
" + key, e );
      }
    }
  }

  private static final class Lock<V>
  {
    private V _object;

    private boolean _isSet; // allows for null value

    public V getValue()
    {
      return _object;
    }

    public boolean hasValue()
    {
      return _isSet;
    }

    public void setObject( V object_ )
    {
      _isSet = true;
      _object = object_;
    }
  }
}

----
--------------------------------------------------------

NOTICE: If received in error, please destroy and notify sender. Sender does not intend to waive confidentiality or privilege. Use of this email is prohibited when received in error.


From dl at cs.oswego.edu  Mon Aug 13 13:16:03 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 13 Aug 2007 13:16:03 -0400
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
Message-ID: <46C091D3.1020105@cs.oswego.edu>

It's about time to recycle this (that I first posted May 15, 2006):

> Lazy initialization of map values in ConcurrentMaps is starting to be
> a FAQ. It is a variant of the famous double-checked lazy
> initialization problem. In both cases, there are no universal answers, but
> some common approaches.  Here's a start, including some variants that
> Joe has posted in reply to similar questions.  Feel free to add
> others.
> 
> Problem:
>   You have a ConcurrentMap map, where each key maps to a value that
>   should be constructed and put into the map only if the key is not
>   already mapped.
> 
> Solutions
> 
> 1. Just use map.putIfAbsent(key, new Value(...)).
> 
> This applies when constructing the Value doesn't have any irreversible
> side effects, so it doesn't hurt to throw it away if already entered
> into the map. When contention is expected to be rare, it is even OK if
> constructing a new Value is expensive, since it will rarely happen.
> (In general, don't be too afraid of occasionally wasting effort
> especially on multiprocessors. It is usually cheaper than
> blocking. But always verify whether this holds in your application.)
> 
> (Aside. The Java Concurrency in Practice book has some examples of
> such usages.)
> 
> 1a. You can further minimize wasted effort by using:
>     if (!map.contains(key))
>       map.putIfAbsent(key, new Value(...));
> 
> This narrows the window in which you might create multiple Values,
> but adds overhead for each put.
> 
> 1b. If applicable, you can also invoke a rollback action if you
> lose race to insert, as in:
>     if (!map.contains(key))
>       if (map.putIfAbsent(key, new Value(...) != null))
>          undoEffectsOfCallingNewValue(...);
> 
> This might apply if you need to close a connection or somesuch.
> 
> 
> 2. Use a wrapper around Value classes that perform lazy initialization
> on first access. One way to do this is to declare the map as Map<Key,
> Future<Value>>, and define a simple custom Future<Value> such as:
> 
>   class FutureValue implements Future<Value> {
>      private volatile Value value;
>      public Value get() {
>         Value v = value;
>         if (v == null)
>            value = v = // initialize, probably under some lock
>         return v;
>      }
>      public boolean isDone() { return value != null; }
>      public Value get(long timeout, TimeUnit unit) { return get(); }
>      // Don't need cancellation support:
>      public boolean isCancelled() { return false; }
>      public boolean cancel(boolean interrupt) { return false; }
>   }
> 
> Or use a FutureTask, especially if you'd like this run in a different
> thread. (Java Concurrency in Practice also has some examples of this.)
> 
> The main disadvantage is that it imposes an extra level of
> indirection, which is usually not a performance concern but may be a
> usage concern.  All users of the map must be prepared for map.get(key)
> to return a Future, which if non-null, must be dereferenced via
> future.get() in order to use.
> 
> 
> 3. Define the Value class to itself perform lazy initialization on
> first use. As in:
> 
>   class Value {
>      private volatile boolean initialized;
>      // lots more fields ...
>      public void someMethod() {
>         if (!initialized) initialize(); // probably under some lock
>         // ... perform method action
>      }
>   }
> 
> This has the disadvantage of requiring initialization checks
> on each method call.
> 
> 
> 4. Define a special RESERVED sentinel Value, and use it as a
> reservation, in code looking something like (there are many variants):
> 
>    Value v = map.get(key);
>    if (v == null && (v = map.putIfAbsent(key, RESERVED)) == null)
>       v = RESERVED;
>    if (v == RESERVED) {
>       v = // initialize, probably under some lock
>       if (!map.replace(key, RESERVED, v))
>           v = map.get(key);
>    }
> 
> This has the disadvantage that all users will need to deal with
> RESERVED as a value for get, put, etc. You can/should avoid this by
> declaring a special purpose Map class that delegates get, put etc to a
> ConcurrentMap, and performs these actions inside get, put, etc.  Also,
> it only applies when you can come up with a reasonable RESERVED
> value. Without generics, you can use
>   static final RESERVED = new Object();
> With generics, you'd need to either find a way for RESERVED to be an
> actual instance of Value class, or internally use a raw Object type,
> and use casts within each method.
> 
> 
> 5. Instead of calling new Value(...) call a factory method that
> returns an existing instance if available, as in
>   map.putIfAbsent(key, Value.create(...));
> This just defers the issue one level deeper, but might apply if for
> example Value is a singleton object, in which case you can use either
> double-check (with a volatile reference!) or static holders.
> 
> 
> 6. Give up on ConcurrentMaps, and use custom synchronization wrappers
> on unsynchronized maps (HashMap, TreeMap). You can then define
>   synchronized void createIfAbsent(K key) {
>     if (!map.contains(key))
>         map.put(key, new Value())
>    }
> 
> The disadvantage is much poorer throughput for concurrent operations. 





From Ben.Rowlands at morganstanley.com  Mon Aug 13 13:21:20 2007
From: Ben.Rowlands at morganstanley.com (Rowlands, Ben (IT))
Date: Mon, 13 Aug 2007 18:21:20 +0100
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <46C091D3.1020105@cs.oswego.edu>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
	<46C091D3.1020105@cs.oswego.edu>
Message-ID: <6E88AC4207ED7245BA40032D5772AB640937837E@LNWEXMB25.msad.ms.com>

Appologies! I did google didn't come up with anything.

Thanks,

Ben Rowlands

> -----Original Message-----
> From: Doug Lea [mailto:dl at cs.oswego.edu] 
> Sent: 13 August 2007 18:16
> To: Rowlands, Ben (IT)
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Adding a createIfAbsent() API?
> 
> It's about time to recycle this (that I first posted May 15, 2006):
> 
> > Lazy initialization of map values in ConcurrentMaps is 
> starting to be
> > a FAQ. It is a variant of the famous double-checked lazy
> > initialization problem. In both cases, there are no 
> universal answers, but
> > some common approaches.  Here's a start, including some 
> variants that
> > Joe has posted in reply to similar questions.  Feel free to add
> > others.
> > 
> > Problem:
> >   You have a ConcurrentMap map, where each key maps to a value that
> >   should be constructed and put into the map only if the key is not
> >   already mapped.
> > 
> > Solutions
> > 
> > 1. Just use map.putIfAbsent(key, new Value(...)).
> > 
> > This applies when constructing the Value doesn't have any 
> irreversible
> > side effects, so it doesn't hurt to throw it away if already entered
> > into the map. When contention is expected to be rare, it is 
> even OK if
> > constructing a new Value is expensive, since it will rarely happen.
> > (In general, don't be too afraid of occasionally wasting effort
> > especially on multiprocessors. It is usually cheaper than
> > blocking. But always verify whether this holds in your application.)
> > 
> > (Aside. The Java Concurrency in Practice book has some examples of
> > such usages.)
> > 
> > 1a. You can further minimize wasted effort by using:
> >     if (!map.contains(key))
> >       map.putIfAbsent(key, new Value(...));
> > 
> > This narrows the window in which you might create multiple Values,
> > but adds overhead for each put.
> > 
> > 1b. If applicable, you can also invoke a rollback action if you
> > lose race to insert, as in:
> >     if (!map.contains(key))
> >       if (map.putIfAbsent(key, new Value(...) != null))
> >          undoEffectsOfCallingNewValue(...);
> > 
> > This might apply if you need to close a connection or somesuch.
> > 
> > 
> > 2. Use a wrapper around Value classes that perform lazy 
> initialization
> > on first access. One way to do this is to declare the map 
> as Map<Key,
> > Future<Value>>, and define a simple custom Future<Value> such as:
> > 
> >   class FutureValue implements Future<Value> {
> >      private volatile Value value;
> >      public Value get() {
> >         Value v = value;
> >         if (v == null)
> >            value = v = // initialize, probably under some lock
> >         return v;
> >      }
> >      public boolean isDone() { return value != null; }
> >      public Value get(long timeout, TimeUnit unit) { return get(); }
> >      // Don't need cancellation support:
> >      public boolean isCancelled() { return false; }
> >      public boolean cancel(boolean interrupt) { return false; }
> >   }
> > 
> > Or use a FutureTask, especially if you'd like this run in a 
> different
> > thread. (Java Concurrency in Practice also has some 
> examples of this.)
> > 
> > The main disadvantage is that it imposes an extra level of
> > indirection, which is usually not a performance concern but may be a
> > usage concern.  All users of the map must be prepared for 
> map.get(key)
> > to return a Future, which if non-null, must be dereferenced via
> > future.get() in order to use.
> > 
> > 
> > 3. Define the Value class to itself perform lazy initialization on
> > first use. As in:
> > 
> >   class Value {
> >      private volatile boolean initialized;
> >      // lots more fields ...
> >      public void someMethod() {
> >         if (!initialized) initialize(); // probably under some lock
> >         // ... perform method action
> >      }
> >   }
> > 
> > This has the disadvantage of requiring initialization checks
> > on each method call.
> > 
> > 
> > 4. Define a special RESERVED sentinel Value, and use it as a
> > reservation, in code looking something like (there are many 
> variants):
> > 
> >    Value v = map.get(key);
> >    if (v == null && (v = map.putIfAbsent(key, RESERVED)) == null)
> >       v = RESERVED;
> >    if (v == RESERVED) {
> >       v = // initialize, probably under some lock
> >       if (!map.replace(key, RESERVED, v))
> >           v = map.get(key);
> >    }
> > 
> > This has the disadvantage that all users will need to deal with
> > RESERVED as a value for get, put, etc. You can/should avoid this by
> > declaring a special purpose Map class that delegates get, 
> put etc to a
> > ConcurrentMap, and performs these actions inside get, put, 
> etc.  Also,
> > it only applies when you can come up with a reasonable RESERVED
> > value. Without generics, you can use
> >   static final RESERVED = new Object();
> > With generics, you'd need to either find a way for RESERVED to be an
> > actual instance of Value class, or internally use a raw Object type,
> > and use casts within each method.
> > 
> > 
> > 5. Instead of calling new Value(...) call a factory method that
> > returns an existing instance if available, as in
> >   map.putIfAbsent(key, Value.create(...));
> > This just defers the issue one level deeper, but might apply if for
> > example Value is a singleton object, in which case you can 
> use either
> > double-check (with a volatile reference!) or static holders.
> > 
> > 
> > 6. Give up on ConcurrentMaps, and use custom 
> synchronization wrappers
> > on unsynchronized maps (HashMap, TreeMap). You can then define
> >   synchronized void createIfAbsent(K key) {
> >     if (!map.contains(key))
> >         map.put(key, new Value())
> >    }
> > 
> > The disadvantage is much poorer throughput for concurrent 
> operations. 
> 
> 
> 
> 
>
--------------------------------------------------------

NOTICE: If received in error, please destroy and notify sender. Sender does not intend to waive confidentiality or privilege. Use of this email is prohibited when received in error.


From jed at atlassian.com  Mon Aug 13 20:29:29 2007
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Tue, 14 Aug 2007 10:29:29 +1000
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
Message-ID: <46C0F769.1070606@atlassian.com>

Basically you are describing the memoizer pattern in JCIP 5.6. There is 
an implementation in there that works pretty well. We did a similar 
implementation for JIRA that is described here: 
http://blogs.atlassian.com/developer/2007/02/preventing_concurrent_operatio.html 
although this one is specifically for preventing concurrent database 
inserts of the same value and does not cache them further.

Bob Lee's Guice framework has a memoized cache implementation that is 
rather nice as well, with just an abstract create method you implement 
to resolve the value. It has the benefit of being able to specify 
Strong/Soft/Weak keys and values (although he has moved the 
implementation to an internal package since Guice was first released). 
You can find that here: 
http://google-guice.googlecode.com/svn/trunk/src/com/google/inject/internal/ReferenceCache.java

I don't know if a juc library class makes complete sense as there are a 
few interesting and subtle edge-cases you want to handle yourself - as 
well as a few sharp edges - as the differences in the above 
implementations show.

Rowlands, Ben (IT) wrote:
> I often find a need for an API like:
>
>   public V createIfAbsent( K key, Callable<V> creator ) throws
> ExcecutionException
>
> Similar in operation to putIfAbsent() but taking a callback that is used
> to resolve the value if one isn't found at at the key. 
>
> A very common use-case of this is when we are using the Map to cache
> values (for example, from a database query). We only want to execute the
> database query if the value isn't already in the map so we can't use
> putIfAbsent() directly and we end up wrapping the Map using a
> lock-per-key or some other technique.
>
> I know this kind of behaviour can be achieved using a
> FutureTask/Executor etc (as described in "Concurrency in Practice")
> however it seems such a useful primitive that I think it would be useful
> to add to the ConcurrentMap API (or a new API in JUC) and would avoid
> the copy/paste or need to roll your own implementation each time (add
> will be even more succinct with closure support :). A slight difference
> in the behaviour of this API is that if the creator fails with an
> exception subsequent threads can have a go at creating the value rather
> than forcing them to fail with the original exception.
>
> The simple implementation below demonstrates this API using a
> lock-per-key (note, createIfAbsent() -> getOrCreate()). 
>
> Are there any plans for this sort of API in JUC? (or is there a 1-2 line
> equivalent that I've overlooked and could be used instead?)
>   
-- 
cheers,
- jed.


From rob.griffin at quest.com  Mon Aug 13 22:35:32 2007
From: rob.griffin at quest.com (Rob Griffin)
Date: Tue, 14 Aug 2007 12:35:32 +1000
Subject: [concurrency-interest] Illegal IllegalMonitorStateException
In-Reply-To: <0BAEFFA7AFADFD4497F50DD093687E07043D9F52@melmbxw01.prod.quest.corp>
References: <0BAEFFA7AFADFD4497F50DD093687E07043D9D49@melmbxw01.prod.quest.corp><A2167F6D-0919-460A-8DB2-C6667DB9C693@bellsouth.net>
	<0BAEFFA7AFADFD4497F50DD093687E07043D9F52@melmbxw01.prod.quest.corp>
Message-ID: <0BAEFFA7AFADFD4497F50DD093687E0705ACAB1E@melmbxw01.prod.quest.corp>

Just in case anyone else has this strange behaviour we believe that it
was caused by native code calling back into the JVM from unregistered
native threads. 

Rob Griffin.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Rob
Griffin
Sent: Tuesday, 10 July 2007 4:06 PM
To: Dave Griffith
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Illegal IllegalMonitorStateException

Dave,

I've made them final now but a search through the code shows no
assignments to these variables other than the initial ones. They are not
being altered. 

As for you other observation; yes we realize this but the code is quite
old. We are intending to go to Java 6 for the next release and rewrite a
fair proportion of this stuff to use the concurrent packages. We have a
few reinvented wheels in this application that we would like to replace
with nice shiny new round ones.

Rob Griffin.    

-----Original Message-----
From: Dave Griffith [mailto:dgriffith at bellsouth.net] 
Sent: Tuesday, 10 July 2007 2:10 PM
To: Rob Griffin
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Illegal IllegalMonitorStateException

If the "namedQueues" and "transactions" variables aren't final, they  
should be.  If they can't be final, it most likely means they are  
being altered, and there's your problem.  Once you do that, I'm  
pretty sure your problem will go away (unless there's a VM bug I'm  
unaware of, which is certainly possible).  Note that it's not enough  
to say "the variable is never modified".  Marking fields final has  
very specific Java memory model implications, beyond the naive  
semantics.

Beyond that, it looks like you've got a pattern that could be better  
solved by using an Executor class, rather than creating your own  
QueueManager.  No need to reinvent the wheel, especially if you  
aren't sure you can make it round.

--Dave Griffith



On Jul 9, 2007, at 9:13 PM, Rob Griffin wrote:

> Hello,
>
> We are getting this intermittent exception in our application
>
> java.lang.IllegalMonitorStateException: current thread not owner
>
>       at java.lang.Object.notify(Native Method)
>       at
> com.quest.adk.threads.queues.QueueManager.removeFromQueue 
> (QueueManager.j
> ava:257)
>
> 	......
>
>
> This seems reasonable until we look at the code that throws the
> exception:
>
>     synchronized (namedQueues) {
>        namedQueues.notify();  // <---- thrown here
>     }
>
> And we also get it in another place as well:
>
>      synchronized(transactions) {
>          transactions.notifyAll();  // <-- and here!
>      }
>
> In both cases the variables are never changed by the code once they  
> are
> initialized, so it is not possible for then to reference different
> objects between one statement and the next.
>
> We are using 1.5 on Windows.
>
> java version "1.5.0_10"
> Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_10-b03)
> Java HotSpot(TM) Server VM (build 1.5.0_10-b03, mixed mode)
>
> Anyone seen anything like this? This has just started happening in a
> mature application and we have been using this version of Java for  
> many
> months. We do have some native code called via JNI but if it was  
> running
> amok I would have expected random errors. I have checked the release
> notes for 1.5.0._12 and there is no mention of
> IllegalMonitorStateException. As well we are approaching a release for
> our product and feel uneasy about changing JVM versions at this late
> stage.
>
>
> Regards,
>
> Rob Griffin
> Quest Software
> www.quest.com
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest





From gluck at gregluck.com  Mon Aug 13 23:09:19 2007
From: gluck at gregluck.com (Greg Luck)
Date: Tue, 14 Aug 2007 13:09:19 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
Message-ID: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>

Guys

I have an issue reported where someone is trying to use ehcache with  
Java 6 and backport-concurrent is throwing a VerifyError.

I checked the doco and there is no mention of Java 6 support. Is it  
coming?

This is the result of using a clustered config, Java 6 and backport for
Java 5:

Caused by: java.lang.VerifyError: class
edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
overrides final method lazySet.(I)V
at java.lang.ClassLoader.defineClass1(Native Method)
at java.lang.ClassLoader.defineClass(ClassLoader.java:620)
at
java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:260)
at java.net.URLClassLoader.access$000(URLClassLoader.java:56)
at java.net.URLClassLoader$1.run(URLClassLoader.java:195)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
at java.lang.ClassLoader.loadClass(ClassLoader.java:251)
at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319)
at
edu.emory.mathcs.backport.java.util.concurrent.Executors 
$DefaultThreadFacto
ry.<clinit>(Executors.java:528)
at
edu.emory.mathcs.backport.java.util.concurrent.Executors.defaultThreadFa 
cto
ry(Executors.java:288)
at
edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.<init> 
(Th
readPoolExecutor.java:1042)
at
edu.emory.mathcs.backport.java.util.concurrent.Executors.newCachedThread 
Poo
l(Executors.java:150)
at
net.sf.ehcache.distribution.MulticastKeepaliveHeartbeatReceiver.init 
(Multic
astKeepaliveHeartbeatReceiver.java:81)
at
net.sf.ehcache.distribution.MulticastRMICacheManagerPeerProvider.init 
(Multi
castRMICacheManagerPeerProvider.java:89)
at net.sf.ehcache.CacheManager.init(CacheManager.java:221)
at net.sf.ehcache.CacheManager.<init>(CacheManager.java:179)

Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622




From neal at gafter.com  Mon Aug 13 23:57:41 2007
From: neal at gafter.com (Neal Gafter)
Date: Mon, 13 Aug 2007 20:57:41 -0700
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <46C091D3.1020105@cs.oswego.edu>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
	<46C091D3.1020105@cs.oswego.edu>
Message-ID: <15e8b9d20708132057k61b58c97m63c8edd76df38f3f@mail.gmail.com>

On 8/13/07, Doug Lea <dl at cs.oswego.edu> wrote:
>
> It's about time to recycle this (that I first posted May 15, 2006):


>From an API point of view (i.e. the user of the API), the callback approach
is, in my opinion, a much neater solution to the problem. A few details make
it unappealing - for example the ExecutionException instead of Java's
ordinary exception checking (whatever the passed code can actually throw
should be known by the compiler to be thrown by the invocation of
createIfAbsent). My hope is that closures would make this approach more
appealing. However, this kind of API may be inappropriate for a concurrent
map unless the implementation is sometimes allowed to invoke the callable
and then discard the value (Doug's solution 1a). If the map is implemented
using locking, the lock must be held for an arbitrarily long time while the
callable is invoked. It may be very difficult to implement in a wait-free
map.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070813/6c7791c6/attachment.html 

From dhanji at gmail.com  Tue Aug 14 00:26:28 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 14 Aug 2007 14:26:28 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
References: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
Message-ID: <aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>

It's obviously not a version mismatch bug (6 can play 5 bins), but still a
bytecode verification error (some kind of corruption...).
Is there a reason this person can't use the j.u.c packages within the core
SDK (i.e. shipped with java 6)?

Just curious--sorry if it's not a real soln =)

Dhanji.

On 8/14/07, Greg Luck <gluck at gregluck.com> wrote:
>
> Guys
>
> I have an issue reported where someone is trying to use ehcache with
> Java 6 and backport-concurrent is throwing a VerifyError.
>
> I checked the doco and there is no mention of Java 6 support. Is it
> coming?
>
> This is the result of using a clustered config, Java 6 and backport for
> Java 5:
>
> Caused by: java.lang.VerifyError: class
> edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
> overrides final method lazySet.(I)V
> at java.lang.ClassLoader.defineClass1(Native Method)
> at java.lang.ClassLoader.defineClass(ClassLoader.java:620)
> at
> java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124)
> at java.net.URLClassLoader.defineClass(URLClassLoader.java:260)
> at java.net.URLClassLoader.access$000(URLClassLoader.java:56)
> at java.net.URLClassLoader$1.run(URLClassLoader.java:195)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:251)
> at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors
> $DefaultThreadFacto
> ry.<clinit>(Executors.java:528)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors.defaultThreadFa
> cto
> ry(Executors.java:288)
> at
> edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.<init>
> (Th
> readPoolExecutor.java:1042)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors.newCachedThread
> Poo
> l(Executors.java:150)
> at
> net.sf.ehcache.distribution.MulticastKeepaliveHeartbeatReceiver.init
> (Multic
> astKeepaliveHeartbeatReceiver.java:81)
> at
> net.sf.ehcache.distribution.MulticastRMICacheManagerPeerProvider.init
> (Multi
> castRMICacheManagerPeerProvider.java:89)
> at net.sf.ehcache.CacheManager.init(CacheManager.java:221)
> at net.sf.ehcache.CacheManager.<init>(CacheManager.java:179)
>
> Regards
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluck
> yahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/aace50b5/attachment.html 

From gluck at gregluck.com  Tue Aug 14 00:29:00 2007
From: gluck at gregluck.com (Greg Luck)
Date: Tue, 14 Aug 2007 14:29:00 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>
References: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
	<aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>
Message-ID: <D8799B58-2033-48F5-B936-E2095F5EA208@gregluck.com>

Dhanji

Ehcache uses backport-concurrent. The package names are backport  
concurrent. I could change to JDK 1.5 j.u.c  by not using backport- 
concurrent but then lose JDK1.4 support.


On 14/08/2007, at 2:26 PM, Dhanji R. Prasanna wrote:

> It's obviously not a version mismatch bug (6 can play 5 bins), but  
> still a bytecode verification error (some kind of corruption...).
> Is there a reason this person can't use the j.u.c packages within  
> the core SDK ( i.e. shipped with java 6)?
>
> Just curious--sorry if it's not a real soln =)
>
> Dhanji.
>
> On 8/14/07, Greg Luck < gluck at gregluck.com> wrote:
> Guys
>
> I have an issue reported where someone is trying to use ehcache with
> Java 6 and backport-concurrent is throwing a VerifyError.
>
> I checked the doco and there is no mention of Java 6 support. Is it
> coming?
>
> This is the result of using a clustered config, Java 6 and backport  
> for
> Java 5:
>
> Caused by: java.lang.VerifyError: class
> edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
> overrides final method lazySet.(I)V
> at java.lang.ClassLoader.defineClass1(Native Method)
> at java.lang.ClassLoader.defineClass(ClassLoader.java:620)
> at
> java.security.SecureClassLoader.defineClass(SecureClassLoader.java: 
> 124)
> at java.net.URLClassLoader.defineClass(URLClassLoader.java:260)
> at java.net.URLClassLoader.access$000 (URLClassLoader.java:56)
> at java.net.URLClassLoader$1.run(URLClassLoader.java:195)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:251)
> at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors
> $DefaultThreadFacto
> ry.<clinit>(Executors.java:528)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors.defaultThread 
> Fa
> cto
> ry(Executors.java:288)
> at
> edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor .<in 
> it>
> (Th
> readPoolExecutor.java:1042)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors.newCachedThre 
> ad
> Poo
> l(Executors.java:150)
> at
> net.sf.ehcache.distribution.MulticastKeepaliveHeartbeatReceiver.init
> (Multic
> astKeepaliveHeartbeatReceiver.java:81)
> at
> net.sf.ehcache.distribution.MulticastRMICacheManagerPeerProvider.init
> (Multi
> castRMICacheManagerPeerProvider.java:89)
> at net.sf.ehcache.CacheManager.init (CacheManager.java:221)
> at net.sf.ehcache.CacheManager.<init>(CacheManager.java:179)
>
> Regards
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluck
> yahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/567b8f04/attachment.html 

From dcholmes at optusnet.com.au  Tue Aug 14 00:52:08 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 14 Aug 2007 14:52:08 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
Message-ID: <ABEHILABNFKEAJNKLENCKECHCFAA.dcholmes@optusnet.com.au>

Greg,

This error doesn't make sense.

Caused by: java.lang.VerifyError: class
 edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
 overrides final method lazySet.(I)V

The backport AtomicInteger class doesn't override lazySet, it defines it. It
also has no superclass other than Object to be verified against.

It's almost as if the verifier thinks the backport version of AtomicInteger
extends the j.u.c version.

???

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Greg
> Luck
> Sent: Tuesday, 14 August 2007 1:09 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Java 6 support in backport-concurrent
>
>
> Guys
>
> I have an issue reported where someone is trying to use ehcache with
> Java 6 and backport-concurrent is throwing a VerifyError.
>
> I checked the doco and there is no mention of Java 6 support. Is it
> coming?
>
> This is the result of using a clustered config, Java 6 and backport for
> Java 5:
>
> Caused by: java.lang.VerifyError: class
> edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
> overrides final method lazySet.(I)V
> at java.lang.ClassLoader.defineClass1(Native Method)
> at java.lang.ClassLoader.defineClass(ClassLoader.java:620)
> at
> java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124)
> at java.net.URLClassLoader.defineClass(URLClassLoader.java:260)
> at java.net.URLClassLoader.access$000(URLClassLoader.java:56)
> at java.net.URLClassLoader$1.run(URLClassLoader.java:195)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:251)
> at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors
> $DefaultThreadFacto
> ry.<clinit>(Executors.java:528)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors.defaultThreadFa
> cto
> ry(Executors.java:288)
> at
> edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.<init>
> (Th
> readPoolExecutor.java:1042)
> at
> edu.emory.mathcs.backport.java.util.concurrent.Executors.newCachedThread
> Poo
> l(Executors.java:150)
> at
> net.sf.ehcache.distribution.MulticastKeepaliveHeartbeatReceiver.init
> (Multic
> astKeepaliveHeartbeatReceiver.java:81)
> at
> net.sf.ehcache.distribution.MulticastRMICacheManagerPeerProvider.init
> (Multi
> castRMICacheManagerPeerProvider.java:89)
> at net.sf.ehcache.CacheManager.init(CacheManager.java:221)
> at net.sf.ehcache.CacheManager.<init>(CacheManager.java:179)
>
> Regards
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluck
> yahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From holger at wizards.de  Tue Aug 14 02:52:05 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Tue, 14 Aug 2007 08:52:05 +0200
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <ABEHILABNFKEAJNKLENCKECHCFAA.dcholmes@optusnet.com.au>
References: <ABEHILABNFKEAJNKLENCKECHCFAA.dcholmes@optusnet.com.au>
Message-ID: <46C15115.5040506@wizards.de>

David Holmes wrote:
> Greg,
> 
> This error doesn't make sense.

It sure does!

> Caused by: java.lang.VerifyError: class
>  edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
>  overrides final method lazySet.(I)V
> 
> The backport AtomicInteger class doesn't override lazySet, it defines it. It
> also has no superclass other than Object to be verified against.
> 
> It's almost as if the verifier thinks the backport version of AtomicInteger
> extends the j.u.c version.

There are several backport "flavors" and in the JDK5 version the backport
classes indeed extend some native classes. In JDK6 some methods in
AbstractOwnableQueuedSynchronizer were made final (among them lazySet()),
so the "half-native" JDK5 backport does not load anymore on JDK6.

I sent the attached patch to Dawid in March and he wanted to incorporate
it to make a JDK6 flavored backport, but so far it seems that has not
happened (/nudge). Would be really nice to have, I just started to use
EHCache as well..

Anybody who needs a Java6 backport lib can just apply the patch to the
backport 3.0 source or get a prebuilt bundle here:
http://hoho.dyndns.org/~holger/dist/backport-util-concurrent-3.0-jdk6.zip

Holger
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: buc-jdk6.patch
Url: /pipermail/attachments/20070814/b79ddaf0/attachment.ksh 

From joe.bowbeer at gmail.com  Tue Aug 14 03:02:22 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 14 Aug 2007 00:02:22 -0700
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <15e8b9d20708132057k61b58c97m63c8edd76df38f3f@mail.gmail.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
	<46C091D3.1020105@cs.oswego.edu>
	<15e8b9d20708132057k61b58c97m63c8edd76df38f3f@mail.gmail.com>
Message-ID: <31f2a7bd0708140002p11f5693dvf578b11615177b11@mail.gmail.com>

On 8/13/07, Neal Gafter wrote:
> On 8/13/07, Doug Lea wrote:
> > It's about time to recycle this (that I first posted May 15, 2006):
>
> From an API point of view (i.e. the user of the API), the callback approach
> is, in my opinion, a much neater solution to the problem. A few details make
> it unappealing - for example the ExecutionException instead of Java's
> ordinary exception checking (whatever the passed code can actually throw
> should be known by the compiler to be thrown by the invocation of
> createIfAbsent). My hope is that closures would make this approach more
> appealing. However, this kind of API may be inappropriate for a concurrent
> map unless the implementation is sometimes allowed to invoke the callable
> and then discard the value (Doug's solution 1a). If the map is implemented
> using locking, the lock must be held for an arbitrarily long time while the
> callable is invoked. It may be very difficult to implement in a wait-free
> map.
>

It just occurred to me that createIfAbsent, if it were to exist,
should probably return the current mapping rather than the previous
one.  That way it will return the newly constructed value when it is
used.  This is the opposite of putIfAbsent.

1a. If the createIfAbsent implementation doesn't use locking, I assume
it must be allowed to throw away the constructed value:

  if (!containsKey(key))
    putIfAbsent(key, callable.call());
  return get(key);

1b. However, if the value is expensive to create, then some kind of
cleanup is more likely to be needed when it is discarded:

  V val = get(key);
  if (val == null) {
    V next = callable.call();
    val = putIfAbsent(key, next);
    if (val == null)
      val = next;
    else
      next.dispose();
  }
  return val;

--Joe

From gluck at gregluck.com  Tue Aug 14 04:52:29 2007
From: gluck at gregluck.com (Greg Luck)
Date: Tue, 14 Aug 2007 18:52:29 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <46C15115.5040506@wizards.de>
References: <ABEHILABNFKEAJNKLENCKECHCFAA.dcholmes@optusnet.com.au>
	<46C15115.5040506@wizards.de>
Message-ID: <2C2DD0E3-6F2E-4D30-A521-456A8DA5DADD@gregluck.com>

Holger

Thanks for clarifying that.

  My user base is centered around Java 1.5 and slowly
moving to Java 6. Java 3 usage is very low with still a significant  
number on 1.4.

The best answer for me is for backport-concurrent to support Java 6.

If I cannot get assurances that your patch will be applied and  
released in next little while, then the
next best answer is to drop backport-concurrent in the next version  
of ehcache. 1.4 users can continue
to use the backport-concurrent version until they upgrade to Java 5.

I would be great if we can get a position on whether Java 6 will be  
supported.


On 14/08/2007, at 4:52 PM, Holger Hoffst?tte wrote:

> David Holmes wrote:
>> Greg,
>>
>> This error doesn't make sense.
>
> It sure does!
>
>> Caused by: java.lang.VerifyError: class
>>  edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
>>  overrides final method lazySet.(I)V
>>
>> The backport AtomicInteger class doesn't override lazySet, it  
>> defines it. It
>> also has no superclass other than Object to be verified against.
>>
>> It's almost as if the verifier thinks the backport version of  
>> AtomicInteger
>> extends the j.u.c version.
>
> There are several backport "flavors" and in the JDK5 version the  
> backport
> classes indeed extend some native classes. In JDK6 some methods in
> AbstractOwnableQueuedSynchronizer were made final (among them  
> lazySet()),
> so the "half-native" JDK5 backport does not load anymore on JDK6.
>
> I sent the attached patch to Dawid in March and he wanted to  
> incorporate
> it to make a JDK6 flavored backport, but so far it seems that has not
> happened (/nudge). Would be really nice to have, I just started to use
> EHCache as well..
>
> Anybody who needs a Java6 backport lib can just apply the patch to the
> backport 3.0 source or get a prebuilt bundle here:
> http://hoho.dyndns.org/~holger/dist/backport-util-concurrent-3.0- 
> jdk6.zip
>
> Holger
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> helpers/AbstractOwnableQueuedSynchronizer.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/helpers/ 
> AbstractOwnableQueuedSynchronizer.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/helpers/ 
> AbstractOwnableQueuedSynchronizer.java	(working copy)
> @@ -31,29 +31,4 @@
>       */
>      protected AbstractOwnableQueuedSynchronizer() { }
>
> -    /**
> -     * The current owner of exclusive mode synchronization.
> -     */
> -    private transient Thread exclusiveOwnerThread;
> -
> -    /**
> -     * Sets the thread that currently owns exclusive access. A
> -     * <tt>null</tt> argument indicates that no thread owns access.
> -     * This method does not otherwise impose any synchronization or
> -     * <tt>volatile</tt> field accesses.
> -     */
> -    protected final void setExclusiveOwnerThread(Thread t) {
> -        exclusiveOwnerThread = t;
> -    }
> -
> -    /**
> -     * Returns the thread last set by
> -     * <tt>setExclusiveOwnerThread</tt>, or <tt>null</tt> if never
> -     * set.  This method does not otherwise impose any  
> synchronization
> -     * or <tt>volatile</tt> field accesses.
> -     * @return the owner thread
> -     */
> -    protected final Thread getExclusiveOwnerThread() {
> -        return exclusiveOwnerThread;
> -    }
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicIntegerArray.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicIntegerArray.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicIntegerArray.java	(working copy)
> @@ -39,14 +39,4 @@
>          super(array);
>      }
>
> -    /**
> -     * Eventually sets the element at position {@code i} to the  
> given value.
> -     *
> -     * @param i the index
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(int i, int newValue) {
> -        super.set(i, newValue);
> -    }
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicInteger.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicInteger.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicInteger.java	(working copy)
> @@ -40,13 +40,4 @@
>          super();
>      }
>
> -    /**
> -     * Eventually sets to the given value.
> -     *
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(int newValue) {
> -        super.set(newValue);
> -    }
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicReferenceArray.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicReferenceArray.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicReferenceArray.java	(working copy)
> @@ -38,14 +38,4 @@
>          super(array);
>      }
>
> -    /**
> -     * Eventually sets the element at position {@code i} to the  
> given value.
> -     *
> -     * @param i the index
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(int i, Object newValue) {
> -        super.set(i, newValue);
> -    }
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicLongArray.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicLongArray.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicLongArray.java	(working copy)
> @@ -38,14 +38,4 @@
>          super(array);
>      }
>
> -    /**
> -     * Eventually sets the element at position {@code i} to the  
> given value.
> -     *
> -     * @param i the index
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(int i, long newValue) {
> -        super.set(i, newValue);
> -    }
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicReference.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicReference.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicReference.java	(working copy)
> @@ -34,13 +34,4 @@
>          super();
>      }
>
> -    /**
> -     * Eventually sets to the given value.
> -     *
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(Object newValue) {
> -        super.set(newValue);
> -    }
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicBoolean.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicBoolean.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicBoolean.java	(working copy)
> @@ -37,13 +37,5 @@
>      public AtomicBoolean() {
>          super();
>      }
> -    /**
> -     * Eventually sets to the given value.
> -     *
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(boolean newValue) {
> -        super.set(newValue);
> -    }
> +
>  }
> Index: C:/home/holger/Projects/h2oWorkspace/backport-util- 
> concurrent-jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/ 
> atomic/AtomicLong.java
> ===================================================================
> --- C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicLong.java	(revision 3596)
> +++ C:/home/holger/Projects/h2oWorkspace/backport-util-concurrent- 
> jdk6/src/edu/emory/mathcs/backport/java/util/concurrent/atomic/ 
> AtomicLong.java	(working copy)
> @@ -40,13 +40,4 @@
>          super();
>      }
>
> -    /**
> -     * Eventually sets to the given value.
> -     *
> -     * @param newValue the new value
> -     * @since 1.6
> -     */
> -    public final void lazySet(long newValue) {
> -        super.set(newValue);
> -    }
>  }

Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/c248bc1d/attachment-0001.html 

From holger at wizards.de  Tue Aug 14 05:25:08 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Tue, 14 Aug 2007 11:25:08 +0200
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <2C2DD0E3-6F2E-4D30-A521-456A8DA5DADD@gregluck.com>
References: <ABEHILABNFKEAJNKLENCKECHCFAA.dcholmes@optusnet.com.au>
	<46C15115.5040506@wizards.de>
	<2C2DD0E3-6F2E-4D30-A521-456A8DA5DADD@gregluck.com>
Message-ID: <46C174F4.1090203@wizards.de>

Greg Luck wrote:
> The best answer for me is for backport-concurrent to support Java 6.  

I guess Dawid just didn't find the time to do it yet. He's on this list
and will hopefully chime in.

> If I cannot get assurances that your patch will be applied and released
> in next little while, then the next best answer is to drop
> backport-concurrent in the next version of ehcache. 1.4 users can
> continue to use the backport-concurrent version until they upgrade to
> Java 5.

There's no reason to ditch the backport - Java6 users can just use the
1.4-flavored backport version! It's what I've been using and it works fine
on all JDKs. The performance impact is a lot less than expected; overall
performance improvements in the Java6 VM outweigh the concurrency bits by
a large factor. Add any kind of I/O to the mix and it becomes even less of
a problem.
If you want to move ehcache to Java5 in order to take advantage of
generics and new methods, you can continue to support JDK 1.4 deployment
by using retrotranslator (on SourceForge).

regards
Holger

PS: ehcache is really neat and easy to use, I like it a lot :)

From crazybob at crazybob.org  Tue Aug 14 10:02:41 2007
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 14 Aug 2007 07:02:41 -0700
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <31f2a7bd0708140002p11f5693dvf578b11615177b11@mail.gmail.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
	<46C091D3.1020105@cs.oswego.edu>
	<15e8b9d20708132057k61b58c97m63c8edd76df38f3f@mail.gmail.com>
	<31f2a7bd0708140002p11f5693dvf578b11615177b11@mail.gmail.com>
Message-ID: <a74683f90708140702x5f8ad89dw4d029d2a6282d6d8@mail.gmail.com>

A general purpose createIfAbsent() should ensure only one value gets
created. As Jed pointed out, ReferenceCache strikes a pretty good balance:
http://google-guice.googlecode.com/svn/trunk/src/com/google/inject/internal/AbstractReferenceCache.java

You could implement this as a set of simple function classes (classes with
one method each) which delegate to a ConcurrentMap.

You probably want one where you can pass in the callback every time, and
another where you can pass in the callback once at construction time. Heck,
you might as well have one where you can pass in a new value every time.

You might also want versions which can get() interruptibly (i.e. it throws
InterruptedException).

If you delegate to any old ConcurrentMap, you'd probably have to tell the
function about your comparison strategy: equals or identity.

Exception transparency (passing exceptions from the callback through without
wrapping them) makes client code considerably simpler. As Neal pointed out,
this API could benefit in multiple ways from closures.

I thought the JCache JSR might be the place to design this API, and I'm in
the process of joining it for that very purpose, but I have no idea what
they've been working on and whether it's actually a good fit.

In any case, I really want to get something like this into the JDK also.

Bob

On 8/14/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
>
> It just occurred to me that createIfAbsent, if it were to exist,
> should probably return the current mapping rather than the previous
> one.  That way it will return the newly constructed value when it is
> used.  This is the opposite of putIfAbsent.
>
> 1a. If the createIfAbsent implementation doesn't use locking, I assume
> it must be allowed to throw away the constructed value:
>
>   if (!containsKey(key))
>     putIfAbsent(key, callable.call());
>   return get(key);
>
> 1b. However, if the value is expensive to create, then some kind of
> cleanup is more likely to be needed when it is discarded:
>
>   V val = get(key);
>   if (val == null) {
>     V next = callable.call();
>     val = putIfAbsent(key, next);
>     if (val == null)
>       val = next;
>     else
>       next.dispose();
>   }
>   return val;
>
> --Joe
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/c9c315b6/attachment.html 

From neal at gafter.com  Tue Aug 14 12:32:26 2007
From: neal at gafter.com (Neal Gafter)
Date: Tue, 14 Aug 2007 09:32:26 -0700
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <a74683f90708140702x5f8ad89dw4d029d2a6282d6d8@mail.gmail.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
	<46C091D3.1020105@cs.oswego.edu>
	<15e8b9d20708132057k61b58c97m63c8edd76df38f3f@mail.gmail.com>
	<31f2a7bd0708140002p11f5693dvf578b11615177b11@mail.gmail.com>
	<a74683f90708140702x5f8ad89dw4d029d2a6282d6d8@mail.gmail.com>
Message-ID: <15e8b9d20708140932of6928f2m17478803d6bf5dc0@mail.gmail.com>

On 8/14/07, Bob Lee <crazybob at crazybob.org> wrote:
>
> I thought the JCache JSR might be the place to design this API, and I'm in
> the process of joining it for that very purpose, but I have no idea what
> they've been working on and whether it's actually a good fit.


jsr107 started six years ago and expected to complete their work within a
matter of weeks. Perhaps they've stalled.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/93bccc14/attachment.html 

From crazybob at crazybob.org  Tue Aug 14 13:01:26 2007
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 14 Aug 2007 10:01:26 -0700
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <15e8b9d20708140932of6928f2m17478803d6bf5dc0@mail.gmail.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
	<46C091D3.1020105@cs.oswego.edu>
	<15e8b9d20708132057k61b58c97m63c8edd76df38f3f@mail.gmail.com>
	<31f2a7bd0708140002p11f5693dvf578b11615177b11@mail.gmail.com>
	<a74683f90708140702x5f8ad89dw4d029d2a6282d6d8@mail.gmail.com>
	<15e8b9d20708140932of6928f2m17478803d6bf5dc0@mail.gmail.com>
Message-ID: <a74683f90708141001w6e08166ape253305c3874b637@mail.gmail.com>

On 8/14/07, Neal Gafter <neal at gafter.com> wrote:
>
> jsr107 started six years ago and expected to complete their work within a
> matter of weeks. Perhaps they've stalled.


It was definitely dead for awhile, but Cameron Purdy and now Greg Luck
recently took it over and have been actively working on it.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/b570c83f/attachment.html 

From gluck at gregluck.com  Tue Aug 14 20:09:13 2007
From: gluck at gregluck.com (Greg Luck)
Date: Wed, 15 Aug 2007 10:09:13 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <46C174F4.1090203@wizards.de>
References: <ABEHILABNFKEAJNKLENCKECHCFAA.dcholmes@optusnet.com.au>
	<46C15115.5040506@wizards.de>
	<2C2DD0E3-6F2E-4D30-A521-456A8DA5DADD@gregluck.com>
	<46C174F4.1090203@wizards.de>
Message-ID: <0EDC32B5-33A1-43D0-A03A-1B6DA14A0E0B@gregluck.com>

Holger

That is good news.

I checked the maven repository. The jar manifest says it was built  
with 1.4.2. It is that version
which maven users are getting, so no problem there.

I am going to bundle the 1.4.2 version in my next release, and add  
some documentation to dependencies and FAQ to explain
the workaround for Java 6.

On 14/08/2007, at 7:25 PM, Holger Hoffst?tte wrote:

> There's no reason to ditch the backport - Java6 users can just use the
> 1.4-flavored backport version! It's what I've been using and it  
> works fine
> on all JDKs. The performance impact is a lot less than expected;  
> overall
> performance improvements in the Java6 VM outweigh the concurrency  
> bits by
> a large factor. Add any kind of I/O to the mix and it becomes even  
> less of
> a problem.
> If you want to move ehcache to Java5 in order to take advantage of
> generics and new methods, you can continue to support JDK 1.4  
> deployment
> by using retrotranslator (on SourceForge).

Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070815/363cc0fb/attachment.html 

From geoffrey.wiseman at gmail.com  Tue Aug 14 20:43:42 2007
From: geoffrey.wiseman at gmail.com (Geoffrey Wiseman)
Date: Tue, 14 Aug 2007 20:43:42 -0400
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <D8799B58-2033-48F5-B936-E2095F5EA208@gregluck.com>
References: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
	<aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>
	<D8799B58-2033-48F5-B936-E2095F5EA208@gregluck.com>
Message-ID: <835d522e0708141743p46071a7ib7ace2eff42a1bfd@mail.gmail.com>

On 8/14/07, Greg Luck <gluck at gregluck.com> wrote:
>
> Ehcache uses backport-concurrent. The package names are backport
> concurrent. I could change to JDK 1.5 j.u.c  by not using
> backport-concurrent but then lose JDK1.4 support.
>

If only there were a commons-concurrency, or a scf4j.  ;)

That's unfortunate; if the number of classes that touch j.u.c is small, you
could isolate them to a thin layer and swap implementations, but ... sounds
like there's a deeper problem, based on the other messages in this thread.

  - Geoffrey
-- 
Geoffrey Wiseman
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070814/db7c6e30/attachment.html 

From dhanji at gmail.com  Tue Aug 14 21:53:01 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 15 Aug 2007 11:53:01 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <835d522e0708141743p46071a7ib7ace2eff42a1bfd@mail.gmail.com>
References: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
	<aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>
	<D8799B58-2033-48F5-B936-E2095F5EA208@gregluck.com>
	<835d522e0708141743p46071a7ib7ace2eff42a1bfd@mail.gmail.com>
Message-ID: <aa067ea10708141853r5744ee11o45dda9e182eb775@mail.gmail.com>

On 8/15/07, Geoffrey Wiseman <geoffrey.wiseman at gmail.com> wrote:
>
> On 8/14/07, Greg Luck <gluck at gregluck.com> wrote:
> >
> > Ehcache uses backport-concurrent. The package names are backport
> > concurrent. I could change to JDK 1.5 j.u.c  by not using
> > backport-concurrent but then lose JDK1.4 support.
> >
>
> If only there were a commons-concurrency, or a scf4j.  ;)
>

=)

I believe there is a springframework abstraction for Executors pluggable
with quartz for <5.0 jres... not sure if this helps with Greg's problem
though??

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070815/89f637c3/attachment.html 

From dhanji at gmail.com  Tue Aug 14 21:57:24 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 15 Aug 2007 11:57:24 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <aa067ea10708141853r5744ee11o45dda9e182eb775@mail.gmail.com>
References: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
	<aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>
	<D8799B58-2033-48F5-B936-E2095F5EA208@gregluck.com>
	<835d522e0708141743p46071a7ib7ace2eff42a1bfd@mail.gmail.com>
	<aa067ea10708141853r5744ee11o45dda9e182eb775@mail.gmail.com>
Message-ID: <aa067ea10708141857y2a479a01r10043f04ab8cf713@mail.gmail.com>

http://www.springframework.org/docs/reference/scheduling.html

see the "TaskExecutor" abstraction, it is analogous to j.u.c.Executor and
plugs j.u.c.* vs Quartz in non jdk5 environments.

Dhanji

On 8/15/07, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
>
>
>
> On 8/15/07, Geoffrey Wiseman <geoffrey.wiseman at gmail.com> wrote:
> >
> > On 8/14/07, Greg Luck <gluck at gregluck.com> wrote:
> > >
> > > Ehcache uses backport-concurrent. The package names are backport
> > > concurrent. I could change to JDK 1.5 j.u.c  by not using
> > > backport-concurrent but then lose JDK1.4 support.
> > >
> >
> > If only there were a commons-concurrency, or a scf4j.  ;)
> >
>
> =)
>
> I believe there is a springframework abstraction for Executors pluggable
> with quartz for <5.0 jres... not sure if this helps with Greg's problem
> though??
>
> Dhanji.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070815/da828052/attachment.html 

From gluck at gregluck.com  Wed Aug 15 02:54:57 2007
From: gluck at gregluck.com (Greg Luck)
Date: Wed, 15 Aug 2007 16:54:57 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <835d522e0708141743p46071a7ib7ace2eff42a1bfd@mail.gmail.com>
References: <5E8D66A4-448C-4D28-852E-B79FDC60FF0B@gregluck.com>
	<aa067ea10708132126h52fb606bofa514733b6069c14@mail.gmail.com>
	<D8799B58-2033-48F5-B936-E2095F5EA208@gregluck.com>
	<835d522e0708141743p46071a7ib7ace2eff42a1bfd@mail.gmail.com>
Message-ID: <135C2EEC-21DD-4568-B5F4-61FC312E5CF0@gregluck.com>

Hi

There are lots of work arounds with varying degrees of ugliness. I  
think the best answer is for Dawid to just go ahead and release a  
Java 6 version of backport-concurrent.

On 15/08/2007, at 10:43 AM, Geoffrey Wiseman wrote:

> On 8/14/07, Greg Luck <gluck at gregluck.com> wrote:
> Ehcache uses backport-concurrent. The package names are backport  
> concurrent. I could change to JDK 1.5 j.u.c  by not using backport- 
> concurrent but then lose JDK1.4 support.
>
> If only there were a commons-concurrency, or a scf4j.  ;)
>
> That's unfortunate; if the number of classes that touch j.u.c is  
> small, you could isolate them to a thin layer and swap  
> implementations, but ... sounds like there's a deeper problem,  
> based on the other messages in this thread.
>
>   - Geoffrey
> -- 
> Geoffrey Wiseman

Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070815/498ab1e9/attachment-0001.html 

From oliver at zeigermann.de  Wed Aug 15 16:20:22 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Wed, 15 Aug 2007 22:20:22 +0200
Subject: [concurrency-interest] Need a special lock implementation
Message-ID: <9da4f4520708151320v321172a9k6633604bdf96dd0a@mail.gmail.com>

Hi folks!

I need a lock implementation having the following features:

(1) read/write lock
(2) ownership must be transferable from one thread to another
(3) upgrade from read-lock to write-lock must be supported (I know
this is deadlock prone)
(4) one must be able to find out which thread holds which locks

The lock is intended to protect resources that exist in large numer.

Does anyone know of an implementation that has those features or at
least something I could use as a starting point? Should I use AQS and
start from scratch?

Thanks in advance and cheers

Oliver

From dcholmes at optusnet.com.au  Wed Aug 15 19:40:17 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 16 Aug 2007 09:40:17 +1000
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <46C15115.5040506@wizards.de>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEDFHIAA.dcholmes@optusnet.com.au>

Holger,

Thanks for pointing out the different backport flavors.

Holger Hoffst?tte writes:
> David Holmes wrote:
> > This error doesn't make sense.
>
> It sure does!
>
> > Caused by: java.lang.VerifyError: class
> >  edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicInteger
> >  overrides final method lazySet.(I)V
> >
> > The backport AtomicInteger class doesn't override lazySet, it
> > defines it. It
> > also has no superclass other than Object to be verified against.
> >
>
> There are several backport "flavors" and in the JDK5 version the backport
> classes indeed extend some native classes. In JDK6 some methods in
> AbstractOwnableQueuedSynchronizer were made final (among them lazySet()),
> so the "half-native" JDK5 backport does not load anymore on JDK6.

AbstractOwnableSynchronizer  does not have a lazySet method, lazySet is a
new method for the Atomic* classes in JDK 6.  I presume what you meant is
that the JDK 5 version of the backport has its AtomicInteger extend
j.u.c.a.AtomicInteger and adds the jsr166x methods, which would explain the
problem when used in JDK 6.

Cheers,
David Holmes


From oliver at zeigermann.de  Thu Aug 16 19:25:35 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 17 Aug 2007 01:25:35 +0200
Subject: [concurrency-interest] AQS Question (WAS: Need a special lock
	implementation)
Message-ID: <9da4f4520708161625l7d196e84wc71f9b5eb8ee499@mail.gmail.com>

I have finally come up with a solution based on AQS:

However, I had more state than would fit into an integer, so I
introduced more state (in form of a Set of reader threads).

Now my question: What is the right way to handle this mixed state? I
tried to code, NO_LOCK, A_SINGLE_READ_LOCK, MORE_READ_LOCKS and
WRITE_LOCK into the state and added more details in form of the set of
reader threads for states A_SINGLE_READ_LOCK and MORE_READ_LOCKS. Does
that make sense? It looks really strange.

In case anyone minds, here is the code. Look for the inner class "Sync".

http://svn.apache.org/viewvc/commons/proper/transaction/branches/TRANSACTION_2/src/java/org/apache/commons/transaction/locking/locks/ResourceRWLock.java?view=markup

Thanks for any hints in advance and cheers

Oliver

2007/8/15, Oliver Zeigermann <oliver at zeigermann.de>:
> Hi folks!
>
> I need a lock implementation having the following features:
>
> (1) read/write lock
> (2) ownership must be transferable from one thread to another
> (3) upgrade from read-lock to write-lock must be supported (I know
> this is deadlock prone)
> (4) one must be able to find out which thread holds which locks
>
> The lock is intended to protect resources that exist in large numer.
>
> Does anyone know of an implementation that has those features or at
> least something I could use as a starting point? Should I use AQS and
> start from scratch?
>
> Thanks in advance and cheers
>
> Oliver
>

From dcholmes at optusnet.com.au  Thu Aug 16 19:57:19 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 17 Aug 2007 09:57:19 +1000
Subject: [concurrency-interest] AQS Question (WAS: Need a special
	lockimplementation)
In-Reply-To: <9da4f4520708161625l7d196e84wc71f9b5eb8ee499@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEDKHIAA.dcholmes@optusnet.com.au>

Oliver,

I don't see any issue with encoding auxiliary state this way.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Oliver
> Zeigermann
> Sent: Friday, 17 August 2007 9:26 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] AQS Question (WAS: Need a special
> lockimplementation)
> 
> 
> I have finally come up with a solution based on AQS:
> 
> However, I had more state than would fit into an integer, so I
> introduced more state (in form of a Set of reader threads).
> 
> Now my question: What is the right way to handle this mixed state? I
> tried to code, NO_LOCK, A_SINGLE_READ_LOCK, MORE_READ_LOCKS and
> WRITE_LOCK into the state and added more details in form of the set of
> reader threads for states A_SINGLE_READ_LOCK and MORE_READ_LOCKS. Does
> that make sense? It looks really strange.
> 
> In case anyone minds, here is the code. Look for the inner class "Sync".
> 
> http://svn.apache.org/viewvc/commons/proper/transaction/branches/T
> RANSACTION_2/src/java/org/apache/commons/transaction/locking/locks
/ResourceRWLock.java?view=markup
> 
> Thanks for any hints in advance and cheers
> 
> Oliver
> 
> 2007/8/15, Oliver Zeigermann <oliver at zeigermann.de>:
> > Hi folks!
> >
> > I need a lock implementation having the following features:
> >
> > (1) read/write lock
> > (2) ownership must be transferable from one thread to another
> > (3) upgrade from read-lock to write-lock must be supported (I know
> > this is deadlock prone)
> > (4) one must be able to find out which thread holds which locks
> >
> > The lock is intended to protect resources that exist in large numer.
> >
> > Does anyone know of an implementation that has those features or at
> > least something I could use as a starting point? Should I use AQS and
> > start from scratch?
> >
> > Thanks in advance and cheers
> >
> > Oliver
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From dawid.kurzyniec at gmail.com  Thu Aug 16 20:05:28 2007
From: dawid.kurzyniec at gmail.com (Dawid Kurzyniec)
Date: Fri, 17 Aug 2007 02:05:28 +0200
Subject: [concurrency-interest] Java 6 support in backport-concurrent
In-Reply-To: <FEEA76A6-F38F-4902-9543-4518B13CEEF0@gregluck.com>
References: <46C174F4.1090203@wizards.de>
	<FEEA76A6-F38F-4902-9543-4518B13CEEF0@gregluck.com>
Message-ID: <3cbaca580708161705n495ba440j6099b6d505b25590@mail.gmail.com>

I apologize everyone for being slow on handling this so far. Now, seeing the
demand being that high (which is great!), I pledge to improve.

Anyway, the 6.0 version has actually been ready for quite a while now, it is
just that I've never found enough time to properly publish it. So, before it
appears on the Web page, you can download the sources directly from the
frozen branch in SVN at:

http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/tags/backport-util-concurrent/3.1/util/backport-util-concurrent-Java60/

Select 'download tarball', then run ant, and you've got yourself a
6.0-compliant backport ready, and with a few minor fixes as well since the
previous version (see the changelog at
http://dcl.mathcs.emory.edu/cgi-bin/viewvc.cgi/software/harness2/tags/backport-util-concurrent/3.1/util/backport-util-concurrent-Java60/README.html
).

I have run stress tests on it, but as usual, run them on your target
machines as well to verify that there are no surprises.

And yes, the reason why the 5.0 version does not work on 6.0 is that atomics
in 5.0 backport inherit from j.u.c., and add lazySet methods, introduced as
final in 6.0. This is one of these rare corner cases when a new Java release
breaks backward binary compatibility. I had to add lazySets so that 1.4 and
5.0 backports remained fully compatible from the client code perspective. I
actually knew that the 6.0 incompatibility is going to happen, but the
alternative would be to use delegation instead of inheritance in atomics,
which would double the object count, impacting performance. I came to the
conclusion that if compatibility and convenience of using a single JAR
everywhere is more important to somebody than performance, they can just use
the 1.4 backport version on all Java platform versions.

The good news is that the backport transition from 6.0 to 7.0 is likely to
go without hoops like that - it should 'just work'.


So, to summarize:

The 1.4 version can be used on 1.4, 5.0, 6.0, and future versions. Unless
the concurrency code is a performance bottleneck, it may be best to just
stick to this version to avoid deployment issues.
The 5.0 version can be used on 5.0 only; it enjoys full performance of j.u.c
.
The 6.0 version can be used on 6.0 and hopefully future versions; it enjoys
full performance of j.u.c.
The 1.3 version can be used on 1.2, 1.3, 1.4, 5.0, 6.0, and future versions,
but I would recommend against using it unless you need to, because I won't
be supporting it much longer.

Regards,
Dawid


On 8/16/07, Greg Luck <gluck at gregluck.com> wrote:
>
> Dawid
> You probably saw the thread on the backport-concurrent list.
>
> It seems that the 1.4 version of backport-concurrent is needed for use
> with 1.6.
>
> It would be a lot better for me people like me using your library in their
> projects if the end users could have a less confusing
> installation. I am getting bugs logged against ehcache.
>
>
>
> Begin forwarded message:
>
> There's no reason to ditch the backport - Java6 users can just use the
>
> 1.4-flavored backport version! It's what I've been using and it works fine
>
> on all JDKs. The performance impact is a lot less than expected; overall
>
> performance improvements in the Java6 VM outweigh the concurrency bits by
>
> a large factor. Add any kind of I/O to the mix and it becomes even less of
>
> a problem.
>
> If you want to move ehcache to Java5 in order to take advantage of
>
> generics and new methods, you can continue to support JDK 1.4 deployment
>
> by using retrotranslator (on SourceForge).
>
>
> Regards
>
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluckyahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070817/5e7c571d/attachment.html 

From complystill at gmail.com  Tue Aug 21 07:27:21 2007
From: complystill at gmail.com (Compl Yue Still)
Date: Tue, 21 Aug 2007 19:27:21 +0800
Subject: [concurrency-interest] Curious: How Java Memory Model is satisfied
	in JSR166 locks?
Message-ID: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>

Hi list,

I'm just curious that how lock implementations of JSR166 correctly
satisfied the following requirement in the lock specification:

"Memory Synchronization

All Lock implementations must enforce the same memory synchronization
semantics as provided by the built-in monitor lock, as described in
The Java Language Specification, Third Edition (17.4 Memory Model):
A successful lock operation has the same memory synchronization
effects as a successful Lock action.
A successful unlock operation has the same memory synchronization
effects as a successful Unlock action."

I saw dl.util.concurrent code leverages synchronized(){} blocks to
assure similar effects, but I found no equivalent code in jdk source,
it's such a myth to me.

Is any black magic there?

BTW, I'm currently figuring a methcanism that can assign locks to
normal objects (transaction objects specifically, and
detached/attached to worker threads over time) other than threads. I
only have a rough understanding of AQS this far, and feels like it's
adequate but not happily sure yet... Any suggestions?

Best regards,
Compl

From matthias at mernst.org  Tue Aug 21 08:46:43 2007
From: matthias at mernst.org (Matthias Ernst)
Date: Tue, 21 Aug 2007 14:46:43 +0200
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
Message-ID: <22ec15240708210546l74e3291fm81a850291debb146@mail.gmail.com>

> I'm just curious that how lock implementations of JSR166 correctly
> satisfied the following requirement in the lock specification:

One word: volatile.

From osvaldo at visionnaire.com.br  Tue Aug 21 08:46:35 2007
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Tue, 21 Aug 2007 09:46:35 -0300
Subject: [concurrency-interest] Curious: How Java Memory Model is
 satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
Message-ID: <46CADEAB.8010903@visionnaire.com.br>

Hi,

Yes there is black magic - it's in class sun.misc.Unsafe, in methods 
like park(), compareAndSwapXxx() and others that are used by the 
implementations of j.u.c classes. These methods of the Unsafe class (as 
I understand it) are declared as common native methods, without any 
synchronization that you can notice, but they are really implemented as 
HotSpot intrinsics, i.e. the JVM will usually replace invocations to 
those methods for inline code that both avoids JNI overhead, and 
includes the necessary instructions for JMM satisfaction. Notice that 
you cannot invoke Unsafe's methods from your own code, access to that 
class is restricted to core classes. So you must channel your needs 
though public APIs like j.u.c locks, atomic objects and base classes 
like AQS.

A+
Osvaldo

Compl Yue Still escreveu:
> Hi list,
>
> I'm just curious that how lock implementations of JSR166 correctly
> satisfied the following requirement in the lock specification:
>
> "Memory Synchronization
>
> All Lock implementations must enforce the same memory synchronization
> semantics as provided by the built-in monitor lock, as described in
> The Java Language Specification, Third Edition (17.4 Memory Model):
> A successful lock operation has the same memory synchronization
> effects as a successful Lock action.
> A successful unlock operation has the same memory synchronization
> effects as a successful Unlock action."
>
> I saw dl.util.concurrent code leverages synchronized(){} blocks to
> assure similar effects, but I found no equivalent code in jdk source,
> it's such a myth to me.
>
> Is any black magic there?
>
> BTW, I'm currently figuring a methcanism that can assign locks to
> normal objects (transaction objects specifically, and
> detached/attached to worker threads over time) other than threads. I
> only have a rough understanding of AQS this far, and feels like it's
> adequate but not happily sure yet... Any suggestions?
>
> Best regards,
> Compl
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>   


-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223


From forax at univ-mlv.fr  Tue Aug 21 09:23:51 2007
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Tue, 21 Aug 2007 15:23:51 +0200
Subject: [concurrency-interest] Curious: How Java Memory Model is
 satisfied in JSR166 locks?
In-Reply-To: <46CADEAB.8010903@visionnaire.com.br>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CADEAB.8010903@visionnaire.com.br>
Message-ID: <46CAE767.3040005@univ-mlv.fr>

Osvaldo Pinali Doederlein a ?crit :
> Hi,
>
> Yes there is black magic - it's in class sun.misc.Unsafe, in methods 
> like park(), compareAndSwapXxx() and others that are used by the 
> implementations of j.u.c classes. These methods of the Unsafe class (as 
> I understand it) are declared as common native methods, without any 
> synchronization that you can notice, but they are really implemented as 
> HotSpot intrinsics, i.e. the JVM will usually replace invocations to 
> those methods for inline code that both avoids JNI overhead, and 
> includes the necessary instructions for JMM satisfaction. Notice that 
> you cannot invoke Unsafe's methods from your own code,
technically you can (with some reflection black magic) but you should not :)
>  access to that 
> class is restricted to core classes. So you must channel your needs 
> though public APIs like j.u.c locks, atomic objects and base classes 
> like AQS.
>
> A+
> Osvaldo
R?mi

From gregg at cytetech.com  Tue Aug 21 09:24:06 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 21 Aug 2007 08:24:06 -0500
Subject: [concurrency-interest] Curious: How Java Memory Model is
 satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
Message-ID: <46CAE776.5070005@cytetech.com>

Compl Yue Still wrote:
> I saw dl.util.concurrent code leverages synchronized(){} blocks to
> assure similar effects, but I found no equivalent code in jdk source,
> it's such a myth to me.
> 
> Is any black magic there?

The underlying JVM facilities for monitor-entry and monitor-exit are used by 
lock and unlock.  In a simple sense, synchronized is equivalent to:

lock.lock();
try {

	...

} finally {
	lock.unlock();
}

If you're familar with the JNI environment, you know that there is a monitor 
entry and monitor exit function available.  These are at the core of what 
synchronized() is.  In Sun's JVM, these functions are now made available to 
application code through their visibility in the Unsafe class.  If you look at 
the JDK1.6 source code on Java.net, you can find the Unsafe class and unsafe.cpp 
to see all of the things in the internals which are available in Sun's 
implementation.

Gregg Wonderly

From complystill at gmail.com  Tue Aug 21 09:25:11 2007
From: complystill at gmail.com (Compl Yue Still)
Date: Tue, 21 Aug 2007 21:25:11 +0800
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
Message-ID: <d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>

But to my understanding of the requirements of the Memory Model, upon
a lock action all variable values must be flushed out of the thread's
working memory, especially other variables not marked as volatile but
ever read by current thread; and upon unlock, all assigned variables
even not marked as volatile in the thread's working memory must be
synchronized to the main memory. So if my understanding is correct so
far, do you imply that accessing a volatile variable causes Hotspot to
synchronize the thread's working memory with main memory? I'm doubting
coz I havn't noticed this requirement in JLS.. Or this is specific to
Hotspot VM?

Thanks for the reply, but I'm still unclear about it.

Regards,
Compl

On 8/21/07, Matthias Ernst <ernst.matthias at gmail.com> wrote:
> > I'm just curious that how lock implementations of JSR166 correctly
> > satisfied the following requirement in the lock specification:
>
> One word: volatile.
>

From matthias at mernst.org  Tue Aug 21 09:36:38 2007
From: matthias at mernst.org (Matthias Ernst)
Date: Tue, 21 Aug 2007 15:36:38 +0200
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
	<d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>
Message-ID: <22ec15240708210636m1a9839afu7055120c7f487525@mail.gmail.com>

On 8/21/07, Compl Yue Still <complystill at gmail.com> wrote:
> do you imply that accessing a volatile variable causes Hotspot to
> synchronize the thread's working memory with main memory? I'm doubting
> coz I havn't noticed this requirement in JLS..

Sorry for the short reply, esp. since I missed mentioning the magic
entailed in the Unsafe class as explained by Osvaldo.

To answer your question: this is new since the JSR133 revision of the
memory model (JLS v3;
http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.4.5).
In layman's terms, yes, access to volatile fields also affects the
visibility of values read from/written to ordinary fields after/before
that. It follows from "program order" in combination with "A write to
a volatile field (?8.3.1.4) happens-before every subsequent read of
that field.".

Before v3, this was not the case and it is one of the, if not the
major achievement of 133.

Matthias


From complystill at gmail.com  Tue Aug 21 09:44:30 2007
From: complystill at gmail.com (Compl Yue Still)
Date: Tue, 21 Aug 2007 21:44:30 +0800
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <46CAE776.5070005@cytetech.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CAE776.5070005@cytetech.com>
Message-ID: <d7be953d0708210644h37e73894x6ea7da0053678362@mail.gmail.com>

Thanks Osvaldo & Gregg,

I know Unsafe is there, but when I read the
java.util.concurrent.locks.ReentrantLock source code from JDK6, the
only connection from a successful lock acquisition to Unsafe is the
state manipulation method defined at AQS, and these methods just "has
memory semantics of a volatile write", how is this enough adequate to
make compatible with the default synchronization lock mechanisms?

Thanks & expecting more ideas.

Regards,
Compl

On 8/21/07, Gregg Wonderly <gregg at cytetech.com> wrote:
> Compl Yue Still wrote:
> > I saw dl.util.concurrent code leverages synchronized(){} blocks to
> > assure similar effects, but I found no equivalent code in jdk source,
> > it's such a myth to me.
> >
> > Is any black magic there?
>
> The underlying JVM facilities for monitor-entry and monitor-exit are used by
> lock and unlock.  In a simple sense, synchronized is equivalent to:
>
> lock.lock();
> try {
>
>        ...
>
> } finally {
>        lock.unlock();
> }
>
> If you're familar with the JNI environment, you know that there is a monitor
> entry and monitor exit function available.  These are at the core of what
> synchronized() is.  In Sun's JVM, these functions are now made available to
> application code through their visibility in the Unsafe class.  If you look at
> the JDK1.6 source code on Java.net, you can find the Unsafe class and unsafe.cpp
> to see all of the things in the internals which are available in Sun's
> implementation.
>
> Gregg Wonderly
>

From jason.greene at redhat.com  Tue Aug 21 09:56:54 2007
From: jason.greene at redhat.com (Jason T. Greene)
Date: Tue, 21 Aug 2007 08:56:54 -0500
Subject: [concurrency-interest] Curious: How Java Memory Model is
 satisfied in JSR166 locks?
In-Reply-To: <46CADEAB.8010903@visionnaire.com.br>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CADEAB.8010903@visionnaire.com.br>
Message-ID: <46CAEF26.5000301@redhat.com>

Osvaldo Pinali Doederlein wrote:

-snip-

> Notice that 
> you cannot invoke Unsafe's methods from your own code, access to that 
> class is restricted to core classes. So you must channel your needs 
> though public APIs like j.u.c locks, atomic objects and base classes 
> like AQS.
> 

Technically there are two ways to get at Unsafe:
1) Put the class that accesses it on the bootclasspath
2) Use reflection to gain access to the Unsafe private static field 
instance (requires a privilege if there is a security manager).

-- 
Jason T. Greene
Lead, POJO Cache
JBoss, a division of Red Hat

From jason.greene at redhat.com  Tue Aug 21 10:04:11 2007
From: jason.greene at redhat.com (Jason T. Greene)
Date: Tue, 21 Aug 2007 09:04:11 -0500
Subject: [concurrency-interest] Curious: How Java Memory Model
 is	satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
	<d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>
Message-ID: <46CAF0DB.1040803@redhat.com>

Compl Yue Still wrote:
> But to my understanding of the requirements of the Memory Model, upon
> a lock action all variable values must be flushed out of the thread's
> working memory, especially other variables not marked as volatile but
> ever read by current thread; and upon unlock, all assigned variables
> even not marked as volatile in the thread's working memory must be
> synchronized to the main memory. So if my understanding is correct so
> far, do you imply that accessing a volatile variable causes Hotspot to
> synchronize the thread's working memory with main memory? I'm doubting
> coz I havn't noticed this requirement in JLS.. Or this is specific to
> Hotspot VM?
> 

Yes volatile in JDK 5+ triggers a memory barrier.

-- 
Jason T. Greene
Lead, POJO Cache
JBoss, a division of Red Hat

From dawid.kurzyniec at gmail.com  Tue Aug 21 10:04:44 2007
From: dawid.kurzyniec at gmail.com (Dawid Kurzyniec)
Date: Tue, 21 Aug 2007 16:04:44 +0200
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210644h37e73894x6ea7da0053678362@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CAE776.5070005@cytetech.com>
	<d7be953d0708210644h37e73894x6ea7da0053678362@mail.gmail.com>
Message-ID: <3cbaca580708210704k2d8eda43w720775e8bdb6c352@mail.gmail.com>

On 8/21/07, Compl Yue Still <complystill at gmail.com> wrote:
> Thanks Osvaldo & Gregg,
>
> I know Unsafe is there, but when I read the
> java.util.concurrent.locks.ReentrantLock source code from JDK6, the
> only connection from a successful lock acquisition to Unsafe is the
> state manipulation method defined at AQS, and these methods just "has
> memory semantics of a volatile write", how is this enough adequate to
> make compatible with the default synchronization lock mechanisms?

To extend upon Matthias' answer: Since Java 5.0, volatile has quite
strong semantics, which is sufficient to implement memory
synchronization as required by the spec you quote. Volatile write in
thread A followed by a volatile read of the same variable in thread B
is a memory synchronization point: _all_ changes made by A are visible
to B. (That is all memory, not just that one variable). It is exactly
the same memory behavior as Lock followed by Unlock. (Compare the
first two bullets in
http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.4.4).

Note that the above answers only the _memory_ synchronization
question. If you wanted to implement your own full-blown exclusion
locks without using synchronized keyword, AQS, or Unsafe, you would
also need atomics (for resolving races) and LockSupport (for
blocking).

I think the Unsafe is a red-herring in the context of your question.

--
Regards,
Dawid

From matthias at mernst.org  Tue Aug 21 10:29:26 2007
From: matthias at mernst.org (Matthias Ernst)
Date: Tue, 21 Aug 2007 16:29:26 +0200
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <46CADEAB.8010903@visionnaire.com.br>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CADEAB.8010903@visionnaire.com.br>
Message-ID: <22ec15240708210729l36851692g3bd808ee51acac84@mail.gmail.com>

On 8/21/07, Osvaldo Pinali Doederlein <osvaldo at visionnaire.com.br> wrote:
> Yes there is black magic - it's in class sun.misc.Unsafe

I find this an interesting point BTW - this is where the distinction
between VM and language spec falls apart. Library methods with an
impact on language semantics should actually be part of the VM
specification; look how #finalize() made it into the JVMS and
java.util.ref hasn't.

Matthias

From complystill at gmail.com  Tue Aug 21 11:18:23 2007
From: complystill at gmail.com (Compl Yue Still)
Date: Tue, 21 Aug 2007 23:18:23 +0800
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <3cbaca580708210704k2d8eda43w720775e8bdb6c352@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CAE776.5070005@cytetech.com>
	<d7be953d0708210644h37e73894x6ea7da0053678362@mail.gmail.com>
	<3cbaca580708210704k2d8eda43w720775e8bdb6c352@mail.gmail.com>
Message-ID: <d7be953d0708210818w13704273vefd83eb61c8c0bab@mail.gmail.com>

Thanks much Dawid, this is the best answer I'd expected to hear!

However I'm still a little away from this happy conclusion, given your
suggested bullets from
http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.4.4

* An unlock action on monitor m synchronizes-with all subsequent lock
actions on m (where subsequent is defined according to the
synchronization order).
* A write to a volatile variable (?8.3.1.4) v synchronizes-with all
subsequent reads of v by any thread (where subsequent is defined
according to the synchronization order).

Where I understand that the order between actions is specific to a
monitor (of an object) or a volatile variable. But from JVM Spec 8.6 (
http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#22253
)

8.6 Rules About the Interaction of Locks and Variables
  Let T be any thread, let V be any variable, and let L be any lock.
There are certain constraints on the operations performed by T with
respect to V and L:

* Between an assign operation by T on V and a subsequent unlock
operation by T on L, a store operation by T on V must intervene;
moreover, the write operation corresponding to that store must precede
the unlock operation, as seen by main memory. (Less formally: if a
thread is to perform an unlock operation on any lock, it must first
copy all assigned values in its working memory back out to main
memory.)
* Between a lock operation by T on L and a subsequent use or store
operation by T on a variable V, an assign or load operation on V must
intervene; moreover, if it is a load operation, then the read
operation corresponding to that load must follow the lock operation,
as seen by main memory. (Less formally: a lock operation behaves as if
it flushes all variables from the thread's working memory, after which
the thread must either assign them itself or load copies anew from
main memory.)

Where I understand applies to all variables regardless their
associations with a lock.

So I still can't fully affirm that "_all_ changes made by A are visible
to B. (That is all memory, not just that one variable)."  in case by
accessing a volatile variable. Am I wrongly interpreting those 2
bullets in JLS, or where is the problem in my understanding?

Oh, maybe fully memory synchronization upon volatile access is just a
guaranteed side-effect by Hostspot, so java.util.concurrent source are
not portable to other JVM implementations?


Thanks to Jason's reply, could you confirm whether the "memory
barrier" is specific to Hotspot or guaranteed for any JVM
implementation?


Please inspire me :)

Best regards,
Compl


On 8/21/07, Dawid Kurzyniec <dawid.kurzyniec at gmail.com> wrote:
> On 8/21/07, Compl Yue Still <complystill at gmail.com> wrote:
> > Thanks Osvaldo & Gregg,
> >
> > I know Unsafe is there, but when I read the
> > java.util.concurrent.locks.ReentrantLock source code from JDK6, the
> > only connection from a successful lock acquisition to Unsafe is the
> > state manipulation method defined at AQS, and these methods just "has
> > memory semantics of a volatile write", how is this enough adequate to
> > make compatible with the default synchronization lock mechanisms?
>
> To extend upon Matthias' answer: Since Java 5.0, volatile has quite
> strong semantics, which is sufficient to implement memory
> synchronization as required by the spec you quote. Volatile write in
> thread A followed by a volatile read of the same variable in thread B
> is a memory synchronization point: _all_ changes made by A are visible
> to B. (That is all memory, not just that one variable). It is exactly
> the same memory behavior as Lock followed by Unlock. (Compare the
> first two bullets in
> http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.4.4).
>
> Note that the above answers only the _memory_ synchronization
> question. If you wanted to implement your own full-blown exclusion
> locks without using synchronized keyword, AQS, or Unsafe, you would
> also need atomics (for resolving races) and LockSupport (for
> blocking).
>
> I think the Unsafe is a red-herring in the context of your question.
>
> --
> Regards,
> Dawid
>


From dawid.kurzyniec at gmail.com  Tue Aug 21 11:50:13 2007
From: dawid.kurzyniec at gmail.com (Dawid Kurzyniec)
Date: Tue, 21 Aug 2007 17:50:13 +0200
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210818w13704273vefd83eb61c8c0bab@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CAE776.5070005@cytetech.com>
	<d7be953d0708210644h37e73894x6ea7da0053678362@mail.gmail.com>
	<3cbaca580708210704k2d8eda43w720775e8bdb6c352@mail.gmail.com>
	<d7be953d0708210818w13704273vefd83eb61c8c0bab@mail.gmail.com>
Message-ID: <3cbaca580708210850y1e7b02adl3f44bfa5e00d5ce9@mail.gmail.com>

On 8/21/07, Compl Yue Still <complystill at gmail.com> wrote:
> Thanks much Dawid, this is the best answer I'd expected to hear!
>
> However I'm still a little away from this happy conclusion, given your
> suggested bullets from
> http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.4.4
>
> * An unlock action on monitor m synchronizes-with all subsequent lock
> actions on m (where subsequent is defined according to the
> synchronization order).
> * A write to a volatile variable (?8.3.1.4) v synchronizes-with all
> subsequent reads of v by any thread (where subsequent is defined
> according to the synchronization order).
>
> Where I understand that the order between actions is specific to a
> monitor (of an object) or a volatile variable. But from JVM Spec 8.6 (
> http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#22253
> )
>
> 8.6 Rules About the Interaction of Locks and Variables
>   Let T be any thread, let V be any variable, and let L be any lock.
> There are certain constraints on the operations performed by T with
> respect to V and L:
> (...)

You're quoting the JVM spec _second_ edition. Throw it out the window,
or better yet, burn it, so that no one can find it and get confused by
it ;)

All that stuff has been obsoleted by JSR 133.

--
Regards,
Dawid


From osvaldo at visionnaire.com.br  Tue Aug 21 12:27:52 2007
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Tue, 21 Aug 2007 13:27:52 -0300
Subject: [concurrency-interest] Curious: How Java Memory Model is
 satisfied in JSR166 locks?
In-Reply-To: <22ec15240708210728q30b377d5qbdcdd09907cdc42e@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>	
	<46CADEAB.8010903@visionnaire.com.br>
	<22ec15240708210728q30b377d5qbdcdd09907cdc42e@mail.gmail.com>
Message-ID: <46CB1288.2040406@visionnaire.com.br>

Matthias Ernst escreveu:
> On 8/21/07, Osvaldo Pinali Doederlein <osvaldo at visionnaire.com.br> wrote:
>   
>> Yes there is black magic - it's in class sun.misc.Unsafe
>>     
> I find this an interesting point BTW - this is where the distinction
> between VM and language spec falls apart. Library methods with an
> impact on language semantics should actually be part of the VM
> specification; look how #finalize() made it into the JVMS and
> java.util.ref hasn't.
>   
Well, sun.misc.Unsafe is an implementation detail of Sun's JVM. The same 
can be said of all code inside critical methods of j.u.c classes. As far 
as spec compliance goes, the entire j.u.c could be implemented on top of 
standard Java monitors + volatiles (esp. with the new JMM). Such 
implementation wouldn't be particularly fast, but it would be compliant 
(it's how the backport library targets Java1.4, AFAIK). Or perhaps, 
Unsafe's methods (or their equivalents) could be real JNI calls into 
native code that contains special instructions like CAS. Once again 
performance would suffer (JNI) but you don't need special JVM support 
(intrinsification) to obtain compliance. Specifications (at least 
Java's) don't need to go down to performance requirements. (The closer 
Java specs goes is some O(N) specs, e.g. in collections.) In summary, 
just because there is a public API, like lock(), that requires a 
specific JMM semantics, this doesn't mean that the specification should 
mention how to implement this semantics. Even the language doesn't need 
to provide any standard mechanism to make it possible. Because Java is a 
managed language, there are several APIs that cannot be implemented in 
pure Java per definition.

Other JVMs that are based on Sun code, like the IBM JDK, have the same 
sun.misc.Unsafe class, but they could implement j.u.c and other special 
libraries (e.g. serialization and reflection) with completely different 
code if they wanted to. But I was curious enough to check the latest GNU 
Classpath, and... they have a sun.misc.Unsafe class! But it's a 
clean-room implementation, the methods are different. Only the essential 
stuff is there (park/unpark, CAS, and support for direct access to 
object fields with specific memory semantics). But they probably did 
that just because they can (and do) use all JSR166 sources, which are in 
public domain.

A+
Osvaldo

-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070821/656027d5/attachment.html 

From joe.bowbeer at gmail.com  Tue Aug 21 12:36:28 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 21 Aug 2007 09:36:28 -0700
Subject: [concurrency-interest] Curious: How Java Memory Model is
	satisfied in JSR166 locks?
In-Reply-To: <d7be953d0708210818w13704273vefd83eb61c8c0bab@mail.gmail.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<46CAE776.5070005@cytetech.com>
	<d7be953d0708210644h37e73894x6ea7da0053678362@mail.gmail.com>
	<3cbaca580708210704k2d8eda43w720775e8bdb6c352@mail.gmail.com>
	<d7be953d0708210818w13704273vefd83eb61c8c0bab@mail.gmail.com>
Message-ID: <31f2a7bd0708210936m3dc9dbcbvd2f98b8f6c4a65c7@mail.gmail.com>

On 8/21/07, Compl Yue Still <complystill at gmail.com> wrote:
> Thanks much Dawid, this is the best answer I'd expected to hear!
>
> However I'm still a little away from this happy conclusion, given your
> suggested bullets from
> http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.4.4
>

Check in here:

http://www.cs.umd.edu/~pugh/java/memoryModel/

Spec:

http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf

From pugh at cs.umd.edu  Tue Aug 21 18:49:48 2007
From: pugh at cs.umd.edu (Bill Pugh)
Date: Tue, 21 Aug 2007 18:49:48 -0400
Subject: [concurrency-interest] Curious: How Java Memory Model
	is	satisfied in JSR166 locks?
In-Reply-To: <46CAF0DB.1040803@redhat.com>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
	<d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>
	<46CAF0DB.1040803@redhat.com>
Message-ID: <068215B3-B1F1-41A3-8D77-13D1FE874956@cs.umd.edu>

Don't use the term "memory barrier" in the Java context.

Nothing in Java establishing a memory barrier. Thinking of memory  
barriers in Java can lead you down a bad path.

Various operations establish a happens-before ordering:
  * from an unlock on a monitor to a later lock of the same monitor
  * from a volatile write to a later volatile read of the same field
  * from an update to a later read of an atomic field (e.g., compare  
and swap)

There is nothing that make it impossible/difficult/wrong for special  
methods, defined by the JVM, to establish happens-before orderings.

 From the viewpoint of the user of a library, you don't care whether  
a happens-before ordering is established, just that it is. Having  
consistent documentation of which pairs of operations establish  
happens-before orderings would be a good thing, and an attempt to  
provide that documentation has been made for java.util.concurrent*

Bill



From jason.greene at redhat.com  Tue Aug 21 19:38:00 2007
From: jason.greene at redhat.com (Jason T. Greene)
Date: Tue, 21 Aug 2007 18:38:00 -0500
Subject: [concurrency-interest] Curious: How Java Memory Model
 is	satisfied in JSR166 locks?
In-Reply-To: <068215B3-B1F1-41A3-8D77-13D1FE874956@cs.umd.edu>
References: <d7be953d0708210427qe9d6a0dleb0275f4d54034be@mail.gmail.com>
	<22ec15240708210545o6cb92554i4ed5469acd996eca@mail.gmail.com>
	<d7be953d0708210625w448e746fk8d5dd644f50eda9b@mail.gmail.com>
	<46CAF0DB.1040803@redhat.com>
	<068215B3-B1F1-41A3-8D77-13D1FE874956@cs.umd.edu>
Message-ID: <46CB7758.2090504@redhat.com>

Bill Pugh wrote:
> Don't use the term "memory barrier" in the Java context.
 >
> Nothing in Java establishing a memory barrier. Thinking of memory 
> barriers in Java can lead you down a bad path.

I was answering from a hardware context (mainly because hotspot was 
mentioned), of how its possible that volatile access could/would affect 
the visibility of other values in memory. Although I agree I should have 
given more information and a proper link to the JMM.

> Various operations establish a happens-before ordering:
>  * from an unlock on a monitor to a later lock of the same monitor
>  * from a volatile write to a later volatile read of the same field
>  * from an update to a later read of an atomic field (e.g., compare and 
> swap)
> 
> There is nothing that make it impossible/difficult/wrong for special 
> methods, defined by the JVM, to establish happens-before orderings.

Yes not wrong, just slow ;)

>  From the viewpoint of the user of a library, you don't care whether a 
> happens-before ordering is established, just that it is. Having 
> consistent documentation of which pairs of operations establish 
> happens-before orderings would be a good thing, and an attempt to 
> provide that documentation has been made for java.util.concurrent*

Agreed, although I find that many people are interested in some of the 
details, especially when they are thinking about performance. As far as 
documentation goes, I think concurrent has done an exceptional job.

-- 
Jason T. Greene
Lead, POJO Cache
JBoss, a division of Red Hat

From moran at gigaspaces.com  Sun Aug 26 05:26:59 2007
From: moran at gigaspaces.com (Moran Avigdor)
Date: Sun, 26 Aug 2007 12:26:59 +0300
Subject: [concurrency-interest] ThreadPoolExecutor's allowCoreThreadTimeOut
Message-ID: <3623E06481E65B45866CB3AF32C4FA8755087E@hercules.gspaces.com>

I have noticed some strange behavior using the ThreadPoolExecutor when
moving to java 1.6 (1.6.0_02-b06 on windows xp)

Core pool threads were being terminated although I was explicitly
setting the core pool size:

 

ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long
keepAliveTime,  TimeUnit unit,

                              BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory) 

 

I noticed it when JConsole was up and monitoring the thread consumption.
After my 1 min timeout, all threads were terminated.

 

In 1.6, the new allowCoreThreadTimeOut(boolean value) will in fact
explain this behavior if value is set to true - But I am not explicitly
calling it, but instead using the constructor above.




I should not that on a linux running 1.6.0-rc-b104 it seemed to have
behaved as expected.
Is anyone aware of such a fix or a known issue? 
 
Thanks in advance.

 

---

Moran

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070826/7be99675/attachment.html 

From dcholmes at optusnet.com.au  Sun Aug 26 17:50:24 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 27 Aug 2007 07:50:24 +1000
Subject: [concurrency-interest] ThreadPoolExecutor's
	allowCoreThreadTimeOut
In-Reply-To: <3623E06481E65B45866CB3AF32C4FA8755087E@hercules.gspaces.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEFGHIAA.dcholmes@optusnet.com.au>

Moran,

How you were actually constructing the ThreadPoolExecutor?

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Moran
Avigdor
  Sent: Sunday, 26 August 2007 7:27 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut


  I have noticed some strange behavior using the ThreadPoolExecutor when
moving to java 1.6 (1.6.0_02-b06 on windows xp)

  Core pool threads were being terminated although I was explicitly setting
the core pool size:



  ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long
keepAliveTime,  TimeUnit unit,

                                BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory)



  I noticed it when JConsole was up and monitoring the thread consumption.
After my 1 min timeout, all threads were terminated.



In 1.6, the new allowCoreThreadTimeOut(boolean value) will in fact explain
this behavior if value is set to true - But I am not explicitly calling it,
but instead using the constructor above.

I should not that on a linux running 1.6.0-rc-b104 it seemed to have behaved
as expected.Is anyone aware of such a fix or a known issue?  Thanks in
advance.

  ---

  Moran


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/1bf5ea7a/attachment.html 

From dhanji at gmail.com  Sun Aug 26 23:13:56 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Mon, 27 Aug 2007 13:13:56 +1000
Subject: [concurrency-interest] synchronized maps
Message-ID: <aa067ea10708262013s589a4391q669dd3c53e3b7eaf@mail.gmail.com>

Hi,

I have a JIT-style cache implemented as a HashMap. When client code requests
a key, it looks for an entry and if there is nothing, "compiles" and stashes
a value for that key. Currently, I am using a Collections.synchronizedMap()
wrapper over a j.u.HM. Since I am assured that the value for a key ("natural
value") is always the same, I don't really care if multiple threads compile
and overwrite the same key concurrently.

Am I correct in assuming that using a ConcurrentMap.putIfAbsent() will be
faster in my case (so I can discard concurrently compiled values that are
"later" than the first-put) than a straightforward synchronized overwrite
(multiple puts)?

Assuming of course, that the cost of creating the value is negligible
compared to the cost of locking the entire cache-get method as number of
threads increase... the cache-get method exposed to client code right now is
(deliberately) unsynchronized.


I have another minor question regarding j.u.HM. I publish an unmodifiable
(pre-constructed) HM instance to a final member of an object, is it safe to
assume that leaving the map unsynchronized for multiple threads invoking
get() is ok (i.e. is there any kind of internal optimization after the
last-put)?

Thanks in advance,

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/7a65dc14/attachment.html 

From dcholmes at optusnet.com.au  Mon Aug 27 00:25:33 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 27 Aug 2007 14:25:33 +1000
Subject: [concurrency-interest] synchronized maps
In-Reply-To: <aa067ea10708262013s589a4391q669dd3c53e3b7eaf@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEFIHIAA.dcholmes@optusnet.com.au>

Dhanji,

Once an entry (K, V1) is in the map (CHM) then the difference between put(K,
V2) and putIfAbsent(K, V2) is negligible - a single extra putField in the
put() case. In CHM the two methods share the exact same code - with a flag
controlling whether or not a replacing store takes place.

The get() method for CHM does not use locking except in a very rare
(theoretical but not observed in practice) case.

java.util.HashMap is safe for concurrent reads as long as no structural
modifications occur concurrently. If you publish via a final field of
another object, then as long as you didn't publish that object during
construction, the assignment to the final field must happen-before any
susequent read of the final field. Hence any modifications to the map must
happen-before any subsequents reads of the map.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dhanji R.
Prasanna
  Sent: Monday, 27 August 2007 1:14 PM
  To: concurrency-interest
  Subject: [concurrency-interest] synchronized maps


  Hi,

  I have a JIT-style cache implemented as a HashMap. When client code
requests a key, it looks for an entry and if there is nothing, "compiles"
and stashes a value for that key. Currently, I am using a
Collections.synchronizedMap () wrapper over a j.u.HM. Since I am assured
that the value for a key ("natural value") is always the same, I don't
really care if multiple threads compile and overwrite the same key
concurrently.

  Am I correct in assuming that using a ConcurrentMap.putIfAbsent() will be
faster in my case (so I can discard concurrently compiled values that are
"later" than the first-put) than a straightforward synchronized overwrite
(multiple puts)?

  Assuming of course, that the cost of creating the value is negligible
compared to the cost of locking the entire cache-get method as number of
threads increase... the cache-get method exposed to client code right now is
(deliberately) unsynchronized.


  I have another minor question regarding j.u.HM. I publish an unmodifiable
(pre-constructed) HM instance to a final member of an object, is it safe to
assume that leaving the map unsynchronized for multiple threads invoking
get() is ok ( i.e. is there any kind of internal optimization after the
last-put)?

  Thanks in advance,

  Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/d87ce768/attachment.html 

From dhanji at gmail.com  Mon Aug 27 02:54:30 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Mon, 27 Aug 2007 16:54:30 +1000
Subject: [concurrency-interest] synchronized maps
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEFIHIAA.dcholmes@optusnet.com.au>
References: <aa067ea10708262013s589a4391q669dd3c53e3b7eaf@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEFIHIAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10708262354m6d54f8eag423ef1c7a70988e4@mail.gmail.com>

Ok that's pretty much what I figured. Thanks very much David,

Dhanji.

PS: nice sunny day today for a change =)

On 8/27/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  Dhanji,
>
> Once an entry (K, V1) is in the map (CHM) then the difference between
> put(K, V2) and putIfAbsent(K, V2) is negligible - a single extra putField in
> the put() case. In CHM the two methods share the exact same code - with a
> flag controlling whether or not a replacing store takes place.
>
> The get() method for CHM does not use locking except in a very rare
> (theoretical but not observed in practice) case.
>
> java.util.HashMap is safe for concurrent reads as long as no structural
> modifications occur concurrently. If you publish via a final field of
> another object, then as long as you didn't publish that object during
> construction, the assignment to the final field must happen-before any
> susequent read of the final field. Hence any modifications to the map must
> happen-before any subsequents reads of the map.
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Dhanji R.
> Prasanna
> *Sent:* Monday, 27 August 2007 1:14 PM
> *To:* concurrency-interest
> *Subject:* [concurrency-interest] synchronized maps
>
> Hi,
>
> I have a JIT-style cache implemented as a HashMap. When client code
> requests a key, it looks for an entry and if there is nothing, "compiles"
> and stashes a value for that key. Currently, I am using a
> Collections.synchronizedMap () wrapper over a j.u.HM. Since I am assured
> that the value for a key ("natural value") is always the same, I don't
> really care if multiple threads compile and overwrite the same key
> concurrently.
>
> Am I correct in assuming that using a ConcurrentMap.putIfAbsent() will be
> faster in my case (so I can discard concurrently compiled values that are
> "later" than the first-put) than a straightforward synchronized overwrite
> (multiple puts)?
>
> Assuming of course, that the cost of creating the value is negligible
> compared to the cost of locking the entire cache-get method as number of
> threads increase... the cache-get method exposed to client code right now is
> (deliberately) unsynchronized.
>
>
> I have another minor question regarding j.u.HM. I publish an unmodifiable
> (pre-constructed) HM instance to a final member of an object, is it safe to
> assume that leaving the map unsynchronized for multiple threads invoking
> get() is ok ( i.e. is there any kind of internal optimization after the
> last-put)?
>
> Thanks in advance,
>
> Dhanji.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/d987acad/attachment-0001.html 

From moran at gigaspaces.com  Mon Aug 27 08:22:36 2007
From: moran at gigaspaces.com (Moran Avigdor)
Date: Mon, 27 Aug 2007 15:22:36 +0300
Subject: [concurrency-interest] ThreadPoolExecutor's
	allowCoreThreadTimeOut
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEFGHIAA.dcholmes@optusnet.com.au>
Message-ID: <3623E06481E65B45866CB3AF32C4FA87550AD5@hercules.gspaces.com>

David,

 

Thank you for looking into this. I have written a recreation code to
ease our discussion.

We are using the latest 1.6.0_02-b06 on a windows machine.

 

The code opens a ThreadPoolExecutor with a capacity limited
LinkedBlockingQueue in order

to trigger pool sizing. The code checks that the number of pool threads
does not go below the

Core pool size.

 

The following is the output when it fails.

 

ThreadPoolExecutor with:

 CORE_POOL_SIZE = 4

 MAX_POOL_SIZE = 16

 KEEP_ALIVE_TIMEOUT = 10

 QUEUE_SIZE = 2

 

 java -verions: 1.6.0_02

------------------------------------------------------

...

 

Pool Threads: 7

java.lang.ThreadGroup[name=main,maxpri=10]

    Thread[main,5,main]

    Thread[pool-1-thread-1,5,main]

    Thread[pool-1-thread-2,5,main]

    Thread[pool-1-thread-3,5,main]

    Thread[pool-1-thread-4,5,main]

    Thread[pool-1-thread-5,5,main]

    Thread[pool-1-thread-6,5,main]

    Thread[pool-1-thread-7,5,main]

 

 

Pool Threads: 0

java.lang.ThreadGroup[name=main,maxpri=10]

    Thread[main,5,main]

 

 

Exception in thread "main" java.lang.IllegalStateException: core pool
size is below minimum, expected: 4 actual: 0

      at test.TestTPE.monitorPoolThreads(TestTPE.java:117)

      at test.TestTPE.main(TestTPE.java:17)

 

Just a final note - if you run this exact test with java 1.5 (e.g.
1.5.0_12) this does not happen.

 

Thank you for your time.

Moran Avigdor

 

 

________________________________

From: David Holmes [mailto:dcholmes at optusnet.com.au] 
Sent: Monday, August 27, 2007 12:50 AM
To: Moran Avigdor; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut

 

Moran,

 

How you were actually constructing the ThreadPoolExecutor?

 

David Holmes

	-----Original Message-----
	From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Moran
Avigdor
	Sent: Sunday, 26 August 2007 7:27 PM
	To: concurrency-interest at cs.oswego.edu
	Subject: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut

	I have noticed some strange behavior using the
ThreadPoolExecutor when moving to java 1.6 (1.6.0_02-b06 on windows xp)

	Core pool threads were being terminated although I was
explicitly setting the core pool size:

	 

	ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long
keepAliveTime,  TimeUnit unit,

	                              BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory) 

	 

	I noticed it when JConsole was up and monitoring the thread
consumption. After my 1 min timeout, all threads were terminated.

	 

	In 1.6, the new allowCoreThreadTimeOut(boolean value) will in
fact explain this behavior if value is set to true - But I am not
explicitly calling it, but instead using the constructor above.
	
	
	
	
	
	
	
	
	
	 
	I should not that on a linux running 1.6.0-rc-b104 it seemed to
have behaved as expected.
	Is anyone aware of such a fix or a known issue? 
	 
	Thanks in advance.

	 

	---

	Moran

	 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/6af1e245/attachment-0001.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: TestTPE.java
Type: application/octet-stream
Size: 4532 bytes
Desc: TestTPE.java
Url : /pipermail/attachments/20070827/6af1e245/attachment-0001.obj 

From yechielf at gigaspaces.com  Mon Aug 27 10:52:38 2007
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Mon, 27 Aug 2007 17:52:38 +0300
Subject: [concurrency-interest] a question regarding non-volatile long
Message-ID: <3623E06481E65B45866CB3AF32C4FA87550B83@hercules.gspaces.com>

If, in multi-core 32 bits system, 2 threads are assigning values to a
long variable concurrently (non volatile long)- is it possible that the
final result will contain an inconsistent result- i.e. the first 32 bits
part of the long variable will contain half of the long assigned by
thread 1 while the second half will contain assignment from thread #2 ? 

 

Thanks,

Yechiel  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/ab27fd39/attachment.html 

From trilokgk at gmail.com  Mon Aug 27 11:54:37 2007
From: trilokgk at gmail.com (Trilok Khairnar)
Date: Mon, 27 Aug 2007 21:24:37 +0530
Subject: [concurrency-interest] a question regarding non-volatile long
In-Reply-To: <3623E06481E65B45866CB3AF32C4FA87550B83@hercules.gspaces.com>
References: <3623E06481E65B45866CB3AF32C4FA87550B83@hercules.gspaces.com>
Message-ID: <002301c7e8c2$96d724d0$f92d580a@persistent.co.in>

Possible (multi core or not) since the JVM does not treat assignment two a
64 bit number as one single operation, but two. Apparently because 64 bit
architectures were not widely prevalent when the JVM specification was
written. (This is correct if I was not too low on caffeine while reading the
excellent 'Java Concurrency on Practice' Brian Goetz et. al. the other day)
Is this behaviour going to change though, and does it still hold true on the
latest modern JVM?
 
Regards,
Trilok.

 
  _____  

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Yechiel
Feffer
Sent: Monday, August 27, 2007 8:23 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] a question regarding non-volatile long



If, in multi-core 32 bits system, 2 threads are assigning values to a long
variable concurrently (non volatile long)- is it possible that the final
result will contain an inconsistent result- i.e. the first 32 bits part of
the long variable will contain half of the long assigned by thread 1 while
the second half will contain assignment from thread #2 ? 

 

Thanks,

Yechiel  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/326b61ab/attachment.html 

From holger at wizards.de  Mon Aug 27 12:12:01 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Mon, 27 Aug 2007 18:12:01 +0200
Subject: [concurrency-interest] a question regarding non-volatile long
In-Reply-To: <3623E06481E65B45866CB3AF32C4FA87550B83@hercules.gspaces.com>
References: <3623E06481E65B45866CB3AF32C4FA87550B83@hercules.gspaces.com>
Message-ID: <46D2F7D1.2000904@wizards.de>

Yechiel Feffer wrote:
> If, in multi-core 32 bits system, 2 threads are assigning values to a
> long variable concurrently (non volatile long)- is it possible that the
> final result will contain an inconsistent result- i.e. the first 32 bits
> part of the long variable will contain half of the long assigned by
> thread 1 while the second half will contain assignment from thread #2 ?

Strictly speaking the answer to your question is "yes". Volatile extends
the atomicity of reading/writing scalar values to longs and doubles. This
does not help with interleaved operations by multiple threads
(read-modify-write, aka long++), which still need to be synchronized properly.

Holger


From dl at cs.oswego.edu  Mon Aug 27 16:14:48 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 27 Aug 2007 16:14:48 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
Message-ID: <46D330B8.3020907@cs.oswego.edu>

As people who have been keeping track of the new fine-grained parallelism
framework might have noticed, we are firming up the aggregate operations
APIs. The main APIs surround class ParallelArray, which provides
apply, map, reduce, select, transform etc operations. For javadocs, see:
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/forkjoin/ParallelArray.html

(And for jars, sources etc, see the usual places linked at
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)

While I expect a few minor changes will occur, unlike some previous
forms, these classes no longer say that they are standins for
functionality that will be developed. We think the APIs and
code are just about ready for routine (non-production) use,
and so invite you to uses them and report back any comments
and suggestions. (Now is your big chance before things become
too entrenched to change.)

Here's something pasted from javadocs that gives a feeling
for how you use ParallelArrays:

   import static Ops.*;
   class StudentStatistics {
     ParallelArray<Student> students = ...
     // ...
     public double getMaxSeniorGpa() {
       return students.withFilter(isSenior).withMapping(gpaField).max();
     }

     // helpers:
     static final class IsSenior implements Predicate<Student> {
       public boolean evaluate(Student s) { return s.credits > 90; }
     }
     static final IsSenior isSenior = new IsSenior();
     static final class GpaField implements MappertoDouble<Student> {
       public double map(Student s) { return s.gpa; }
     }
     static final GpaField gpaField = new GpaField();
   }



-Doug

From neal at gafter.com  Mon Aug 27 18:00:25 2007
From: neal at gafter.com (Neal Gafter)
Date: Mon, 27 Aug 2007 15:00:25 -0700
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D330B8.3020907@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>
Message-ID: <15e8b9d20708271500u582cd0c1s25a2cadb719acfc5@mail.gmail.com>

Doug-

The class hierarchy appears to be carefully designed to support specific use
cases. But once you step outside them things don't fare so well. I think
this was intentional to force users into the patterns of code that are most
efficiently handled in the current implementation. But perhaps there is
something about the way the API is supposed to fit together that I just
don't understand.

For example, if I have a parallel array a, I can perform a.withMapping(...)
to map it onto another sequence-like thing. But the resulting thing doesn't
have a withMapping operation, so it isn't possible to apply a mapping (or a
filter) after a mapping; you can't a.withMapping(...).withMapping(...).  A
ParallelArray.WithMapping appears to implement the mapping lazily (on an
as-needed basis). That's a good thing, for a number of reasons. Once you've
mapped, though, the result can only be used to reduce. If you want to map
again, you have to materialize the whole thing using newArray(). That
materializes all the values by applying the mapping (eagerly). That seems an
arbitrary point to force the client to go from lazy to eager evaluation of
the elements. It isn't clear it will result in effective concurrency for
clients that are forced down this route.  I was thinking maybe I could get
the same results (at the cost of reorganizing the client code) by applying a
"composition" operation to two Mappers, but I didn't find a composition
operation in the framework.

I think the whole API should be interface-based.  For example, I think the
results of a.withMapping() should be the ParallelArray interface or some
subtype.  Implement efficiently what you can today.  If the implementation
is interface-based, you can expand the set of use cases that are
efficiently-implemented in the future without changing the API.

Regards,
Neal

On 8/27/07, Doug Lea <dl at cs.oswego.edu> wrote:
>
> As people who have been keeping track of the new fine-grained parallelism
> framework might have noticed, we are firming up the aggregate operations
> APIs. The main APIs surround class ParallelArray, which provides
> apply, map, reduce, select, transform etc operations. For javadocs, see:
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/forkjoin/ParallelArray.html
>
> (And for jars, sources etc, see the usual places linked at
> http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)
>
> While I expect a few minor changes will occur, unlike some previous
> forms, these classes no longer say that they are standins for
> functionality that will be developed. We think the APIs and
> code are just about ready for routine (non-production) use,
> and so invite you to uses them and report back any comments
> and suggestions. (Now is your big chance before things become
> too entrenched to change.)
>
> Here's something pasted from javadocs that gives a feeling
> for how you use ParallelArrays:
>
>    import static Ops.*;
>    class StudentStatistics {
>      ParallelArray<Student> students = ...
>      // ...
>      public double getMaxSeniorGpa() {
>        return students.withFilter(isSenior).withMapping(gpaField).max();
>      }
>
>      // helpers:
>      static final class IsSenior implements Predicate<Student> {
>        public boolean evaluate(Student s) { return s.credits > 90; }
>      }
>      static final IsSenior isSenior = new IsSenior();
>      static final class GpaField implements MappertoDouble<Student> {
>        public double map(Student s) { return s.gpa; }
>      }
>      static final GpaField gpaField = new GpaField();
>    }
>
>
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/6bfa57f0/attachment.html 

From dl at cs.oswego.edu  Mon Aug 27 19:14:29 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 27 Aug 2007 19:14:29 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <15e8b9d20708271500u582cd0c1s25a2cadb719acfc5@mail.gmail.com>
References: <46D330B8.3020907@cs.oswego.edu>
	<15e8b9d20708271500u582cd0c1s25a2cadb719acfc5@mail.gmail.com>
Message-ID: <46D35AD5.10606@cs.oswego.edu>

Neal Gafter wrote:
> 
> 
> For example, if I have a parallel array a, I can perform 
> a.withMapping(...) to map it onto another sequence-like thing. But the 
> resulting thing doesn't have a withMapping operation, so it isn't 
> possible to apply a mapping (or a filter) after a mapping; you can't 
> a.withMapping(...).withMapping(...).  

Right. If you want to apply functions F and G, then you
must define a function/object GofF that combines them itself
to hand to withMapping.

We supply only something that knows how to do
select then map then {apply, reduce, etc} in one efficient
parallel pass, not an arbitrary function composition
library. (Someone else might want to take this on.)

Note: select-then-map-then-operate is a fairly well-entrenched
parallel idiom. We're trying to expose it in a way that is
both useful and efficient.

> 
> I think the whole API should be interface-based.  For example, I think 
> the results of a.withMapping() should be the ParallelArray interface or 
> some subtype. 

We debated this. I think the current form is an OK compromise
between too little and too much abstraction. For example, to
properly generalize ParallelArray as an interface, you'd also need to
somehow generalize ForkJoinExecutor into something that would allow
say alternate ParallelArray implementations via say GPU parallelism.
Which then gets you into lots of bulky layers of interfaces and
factories before you can get anything done. Maybe someday we will
need such a thing, but if so, it can be retrospectively abstracted.

-Doug

From larryr at saturn.sdsu.edu  Mon Aug 27 20:25:14 2007
From: larryr at saturn.sdsu.edu (Larry Riedel)
Date: Mon, 27 Aug 2007 17:25:14 -0700
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D35AD5.10606@cs.oswego.edu>
Message-ID: <1188260714.098524.19409.nullmailer@riedel.org>


> > I think the whole API should be interface-based. [...]
> 
> We debated this. I think the current form is an OK compromise
> between too little and too much abstraction. For example, to
> properly generalize ParallelArray as an interface, you'd also
> need to somehow generalize ForkJoinExecutor into something that
> would allow say alternate ParallelArray implementations via say
> GPU parallelism.  Which then gets you into lots of bulky layers
> of interfaces and factories before you can get anything done.

To me the latter approach below is negligibly more burdensome
for the provider of the default implementation, negligibly
more burdensome for the consumer, and negligibly increases
the complexity of the API.  I think there are benefits to
providing an API as interfaces rather than classes which are
orthogonal to whether the API has been "properly generalized".
I, as a default provider, would like to invite people to find
alternative ways to implement the API without lots of bulky
layers of interfaces and factories... or with them if it makes
their overall system implementation simpler.  But I do not mean
to suggest /every/ API should be all interfaces; I do think
maybe a good default choice for a relatively complex general
purpose API is to be interfaces.


provider:
    package abc.def;
    public class Ghi { ... }
    public class Jkl { ... }
consumer:
    import abc.def.Ghi;
    import abc.def.Jkl;
    ...
    someGhi = new Ghi();
    someJkl = new Jkl();

vs

provider:
    package abc.def;
    public interface Ghi { ... }
    public interface Jkl { ... }
    public static class Def {
        public static Ghi newGhi() { return new DefaultGhi... }
        public static Jkl newJkl() { return new DefaultJkl... }
    }
consumer:
    import abc.def.Def;
    import abc.def.Ghi;
    import abc.def.Jkl;
    ...
    someGhi = Def.newGhi();
    someJkl = Def.newJkl();


Larry


From tim at peierls.net  Mon Aug 27 20:41:15 2007
From: tim at peierls.net (Tim Peierls)
Date: Mon, 27 Aug 2007 20:41:15 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D35AD5.10606@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>
	<15e8b9d20708271500u582cd0c1s25a2cadb719acfc5@mail.gmail.com>
	<46D35AD5.10606@cs.oswego.edu>
Message-ID: <63b4e4050708271741y6eb5a693xf5fdf5562b0d6b1@mail.gmail.com>

On 8/27/07, Doug Lea <dl at cs.oswego.edu> wrote:
>
> Neal Gafter wrote:
> > I think the whole API should be interface-based.  For example, I think
> > the results of a.withMapping() should be the ParallelArray interface or
> > some subtype.
>
> We debated this. I think the current form is an OK compromise
> between too little and too much abstraction. For example, to
> properly generalize ParallelArray as an interface, you'd also need to
> somehow generalize ForkJoinExecutor into something that would allow
> say alternate ParallelArray implementations via say GPU parallelism.
> Which then gets you into lots of bulky layers of interfaces and
> factories before you can get anything done. Maybe someday we will
> need such a thing, but if so, it can be retrospectively abstracted.


I argued strongly for an interface-based API, but I've come to accept Doug's
<strikethru>dictum</strikethru>reasoning. :-)

Seriously, after playing with the current API for a bit, it seems to me that
we need a lot more experience using these FJ creatures before trying to
device interface-based APIs that are implemented in terms of them. Classes
come and go; interfaces are forever.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/9a48daa6/attachment.html 

From dcholmes at optusnet.com.au  Mon Aug 27 22:13:50 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 28 Aug 2007 12:13:50 +1000
Subject: [concurrency-interest]
	ThreadPoolExecutor'sallowCoreThreadTimeOut
In-Reply-To: <3623E06481E65B45866CB3AF32C4FA87550AD5@hercules.gspaces.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEFOHIAA.dcholmes@optusnet.com.au>

Moran,

It is a known bug: 6458662

It is fixed in Java 7 but not Java 6.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Moran
Avigdor
  Sent: Monday, 27 August 2007 10:23 PM
  To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest]
ThreadPoolExecutor'sallowCoreThreadTimeOut


  David,



  Thank you for looking into this. I have written a recreation code to ease
our discussion.

  We are using the latest 1.6.0_02-b06 on a windows machine.



  The code opens a ThreadPoolExecutor with a capacity limited
LinkedBlockingQueue in order

  to trigger pool sizing. The code checks that the number of pool threads
does not go below the

  Core pool size.



  The following is the output when it fails.



  ThreadPoolExecutor with:

   CORE_POOL_SIZE = 4

   MAX_POOL_SIZE = 16

   KEEP_ALIVE_TIMEOUT = 10

   QUEUE_SIZE = 2



   java -verions: 1.6.0_02

  ------------------------------------------------------

  ...



  Pool Threads: 7

  java.lang.ThreadGroup[name=main,maxpri=10]

      Thread[main,5,main]

      Thread[pool-1-thread-1,5,main]

      Thread[pool-1-thread-2,5,main]

      Thread[pool-1-thread-3,5,main]

      Thread[pool-1-thread-4,5,main]

      Thread[pool-1-thread-5,5,main]

      Thread[pool-1-thread-6,5,main]

      Thread[pool-1-thread-7,5,main]





  Pool Threads: 0

  java.lang.ThreadGroup[name=main,maxpri=10]

      Thread[main,5,main]





  Exception in thread "main" java.lang.IllegalStateException: core pool size
is below minimum, expected: 4 actual: 0

        at test.TestTPE.monitorPoolThreads(TestTPE.java:117)

        at test.TestTPE.main(TestTPE.java:17)



  Just a final note - if you run this exact test with java 1.5 (e.g.
1.5.0_12) this does not happen.



  Thank you for your time.

  Moran Avigdor






----------------------------------------------------------------------------
--

  From: David Holmes [mailto:dcholmes at optusnet.com.au]
  Sent: Monday, August 27, 2007 12:50 AM
  To: Moran Avigdor; concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut



  Moran,



  How you were actually constructing the ThreadPoolExecutor?



  David Holmes

    -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Moran
Avigdor
    Sent: Sunday, 26 August 2007 7:27 PM
    To: concurrency-interest at cs.oswego.edu
    Subject: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut

    I have noticed some strange behavior using the ThreadPoolExecutor when
moving to java 1.6 (1.6.0_02-b06 on windows xp)

    Core pool threads were being terminated although I was explicitly
setting the core pool size:



    ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long
keepAliveTime,  TimeUnit unit,

                                  BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory)



    I noticed it when JConsole was up and monitoring the thread consumption.
After my 1 min timeout, all threads were terminated.



In 1.6, the new allowCoreThreadTimeOut(boolean value) will in fact explain
this behavior if value is set to true - But I am not explicitly calling it,
but instead using the constructor above.



 I should not that on a linux running 1.6.0-rc-b104 it seemed to have
behaved as expected.Is anyone aware of such a fix or a known issue?  Thanks
in advance.

    ---

    Moran


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070828/f5fcebb2/attachment-0001.html 

From tim at peierls.net  Mon Aug 27 22:55:00 2007
From: tim at peierls.net (Tim Peierls)
Date: Mon, 27 Aug 2007 22:55:00 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D330B8.3020907@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>
Message-ID: <63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>

Doug warned us not to expect too much from ForkJoin-based programs running
on only one or two processors, so when I tried a comparison of ParallelArray
vs. a hand-coded loop on a single hyper-threaded processor laptop, I was
just hoping the fork-join overhead wouldn't be too egregious. Instead, to my
surprise, the ParallelArray version consistently outperformed the loop
version by 10-20%!

http://dev.priorartisans.com/tim/jsr166y/src/main/java/net/jcip/jsr166y/ParallelArrayVsHandCodedLoop.java

My test program is pretty crude, though. It uses the same tired max senior
GPA example as in the ParallelArray javadoc, and it just alternates between
the two approaches under test, ignoring some warmup runs.

--tim

On 8/27/07, Doug Lea <dl at cs.oswego.edu> wrote:
>
> As people who have been keeping track of the new fine-grained parallelism
> framework might have noticed, we are firming up the aggregate operations
> APIs. The main APIs surround class ParallelArray, which provides
> apply, map, reduce, select, transform etc operations. For javadocs, see:
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/forkjoin/ParallelArray.html
>
> (And for jars, sources etc, see the usual places linked at
> http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070827/50e4807f/attachment.html 

From moran at gigaspaces.com  Tue Aug 28 05:24:53 2007
From: moran at gigaspaces.com (Moran Avigdor)
Date: Tue, 28 Aug 2007 12:24:53 +0300
Subject: [concurrency-interest]
	ThreadPoolExecutor'sallowCoreThreadTimeOut
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEFOHIAA.dcholmes@optusnet.com.au>
Message-ID: <3623E06481E65B45866CB3AF32C4FA87550CB7@hercules.gspaces.com>

David,

Thank you for your help.

 

Moran

 

 

________________________________

From: David Holmes [mailto:dcholmes at optusnet.com.au] 
Sent: Tuesday, August 28, 2007 5:14 AM
To: Moran Avigdor; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest]
ThreadPoolExecutor'sallowCoreThreadTimeOut

 

Moran,

 

It is a known bug: 6458662

 

It is fixed in Java 7 but not Java 6.

 

David

	-----Original Message-----
	From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Moran
Avigdor
	Sent: Monday, 27 August 2007 10:23 PM
	To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
	Subject: Re: [concurrency-interest]
ThreadPoolExecutor'sallowCoreThreadTimeOut

	David,

	 

	Thank you for looking into this. I have written a recreation
code to ease our discussion.

	We are using the latest 1.6.0_02-b06 on a windows machine.

	 

	The code opens a ThreadPoolExecutor with a capacity limited
LinkedBlockingQueue in order

	to trigger pool sizing. The code checks that the number of pool
threads does not go below the

	Core pool size.

	 

	The following is the output when it fails.

	 

	ThreadPoolExecutor with:

	 CORE_POOL_SIZE = 4

	 MAX_POOL_SIZE = 16

	 KEEP_ALIVE_TIMEOUT = 10

	 QUEUE_SIZE = 2

	 

	 java -verions: 1.6.0_02

	------------------------------------------------------

	...

	 

	Pool Threads: 7

	java.lang.ThreadGroup[name=main,maxpri=10]

	    Thread[main,5,main]

	    Thread[pool-1-thread-1,5,main]

	    Thread[pool-1-thread-2,5,main]

	    Thread[pool-1-thread-3,5,main]

	    Thread[pool-1-thread-4,5,main]

	    Thread[pool-1-thread-5,5,main]

	    Thread[pool-1-thread-6,5,main]

	    Thread[pool-1-thread-7,5,main]

	 

	 

	Pool Threads: 0

	java.lang.ThreadGroup[name=main,maxpri=10]

	    Thread[main,5,main]

	 

	 

	Exception in thread "main" java.lang.IllegalStateException: core
pool size is below minimum, expected: 4 actual: 0

	      at test.TestTPE.monitorPoolThreads(TestTPE.java:117)

	      at test.TestTPE.main(TestTPE.java:17)

	 

	Just a final note - if you run this exact test with java 1.5
(e.g. 1.5.0_12) this does not happen.

	 

	Thank you for your time.

	Moran Avigdor

	 

	 

	
________________________________


	From: David Holmes [mailto:dcholmes at optusnet.com.au] 
	Sent: Monday, August 27, 2007 12:50 AM
	To: Moran Avigdor; concurrency-interest at cs.oswego.edu
	Subject: RE: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut

	 

	Moran,

	 

	How you were actually constructing the ThreadPoolExecutor?

	 

	David Holmes

		-----Original Message-----
		From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Moran
Avigdor
		Sent: Sunday, 26 August 2007 7:27 PM
		To: concurrency-interest at cs.oswego.edu
		Subject: [concurrency-interest] ThreadPoolExecutor's
allowCoreThreadTimeOut

		I have noticed some strange behavior using the
ThreadPoolExecutor when moving to java 1.6 (1.6.0_02-b06 on windows xp)

		Core pool threads were being terminated although I was
explicitly setting the core pool size:

		 

		ThreadPoolExecutor(int corePoolSize, int
maximumPoolSize, long keepAliveTime,  TimeUnit unit,

		                              BlockingQueue<Runnable>
workQueue, ThreadFactory threadFactory) 

		 

		I noticed it when JConsole was up and monitoring the
thread consumption. After my 1 min timeout, all threads were terminated.

		 

		In 1.6, the new allowCoreThreadTimeOut(boolean value)
will in fact explain this behavior if value is set to true - But I am
not explicitly calling it, but instead using the constructor above.
		
		
		
		
		
		
		
		
		
		 
		
		
		
		
		
		
		
		
		
		
		 
		 
		I should not that on a linux running 1.6.0-rc-b104 it
seemed to have behaved as expected.
		Is anyone aware of such a fix or a known issue? 
		 
		Thanks in advance.

		 

		---

		Moran

		 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070828/9b46fc54/attachment-0001.html 

From dl at cs.oswego.edu  Tue Aug 28 06:22:18 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 28 Aug 2007 06:22:18 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <63b4e4050708271741y6eb5a693xf5fdf5562b0d6b1@mail.gmail.com>
References: <46D330B8.3020907@cs.oswego.edu>	
	<15e8b9d20708271500u582cd0c1s25a2cadb719acfc5@mail.gmail.com>	
	<46D35AD5.10606@cs.oswego.edu>
	<63b4e4050708271741y6eb5a693xf5fdf5562b0d6b1@mail.gmail.com>
Message-ID: <46D3F75A.1020101@cs.oswego.edu>

Tim Peierls wrote:

> Seriously, after playing with the current API for a bit, it seems to me 
> that we need a lot more experience using these FJ creatures before 
> trying to device interface-based APIs that are implemented in terms of 
> them. Classes come and go; interfaces are forever.
> 

My take is that premature abstraction into interfaces in libraries
is the worse evil here. Perhaps a good rule of thumb is to postpone
such things for a full release. There are too many examples where
we have had to either throw away good suggestions (createIfAbsent)
or undertake painful retrofitting (NavigableMap) to be very tempted
to relive these sorts of experiences. Especially since the
essential core functionality of ParallelArray is still a bit
tenuous. Random example: Method precumulate is very nichy,
but when you need it, it is very difficult to do yourself
efficiently outside of this class. (For some applications of
precumulate, see  Blelloch's "Prefix Sums and Their Applications"
http://www.cs.cmu.edu/~scandal/alg/scan.html) There may be
others along these lines that we discover as people start
using it. If we had to incrementally add new subinterfaces
here (ParallelArrayWithPrecumulate,
ParallelArrayWithPrecumulateWithFusedMultiplyAdd, etc),
we would soon hit the point of unusability.

-Doug


From dl at cs.oswego.edu  Tue Aug 28 06:45:53 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 28 Aug 2007 06:45:53 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D35AD5.10606@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>	<15e8b9d20708271500u582cd0c1s25a2cadb719acfc5@mail.gmail.com>
	<46D35AD5.10606@cs.oswego.edu>
Message-ID: <46D3FCE1.70702@cs.oswego.edu>

I wrote:
> 
> 
> Right. If you want to apply functions F and G, then you
> must define a function/object GofF that combines them itself
> to hand to withMapping.
> 

Actually, we might as well be nice to users and
automate this. We can not only supply in class Ops
classes like...
   class CompositeMapper<T,U,V> implements Mapper<T,V> {
     public CompositeMapper(Mapper<? super T, ? extends U> m1,
                            Mapper<? super U, ? extends V> m2) ...
     public V map(T t) { return m2(m1(t)); }
   }

...but also allow nested withMapping's to construct them,
relieving people of one bit of the unpleasantness of manually
arranging this.
Especially since the WithMapping style eliminates a potential
source of error, of forgetting whether a CompositeMapper<T,T,T>
applies m1 first or m2 first.

Similarly with Predicates and a few others.

Neal: Thanks for the suggestion :-)

-Doug


From dl at cs.oswego.edu  Tue Aug 28 07:34:28 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 28 Aug 2007 07:34:28 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
References: <46D330B8.3020907@cs.oswego.edu>
	<63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
Message-ID: <46D40844.8060906@cs.oswego.edu>

Here's a question about another intentional lack of complete
generality we'd like some feedback on:

Background: We supply special scalar-based ParallelDoubleArray,
ParallelLongArray, and ParallelIntArray. Operations
on a ParallelIntArray are in general noticeably faster than
a ParallelArray<Integer> (and similarly for the others).
In fact, the differences between boxed and unboxed array
operations on scalars are usually more extreme for parallel
vs sequential use because of locality issues -- the elements of a
ParallelIntArray are always nearby each other in memory,
but the Integers of a ParallelArray<Integer> may become
scattered across memory, depending on GC/mutation patterns.
GC runtime mechanics usually also cause array element updates
(as in a[i] = x) of references to contend with each other
more than do scalar writes, which can limit scalability.
I suspect that as time goes by, the gap between boxed and
unboxed versions may shrink. But it will still surely be wider
for parallel than sequential processing for the medium-term future.

On the other hand, supporting special scalar forms in
an almost-uniform (*) way requires APIs/code that grow
with the square of the number of forms. So we don't want
to add thousands of lines of special-case code (and provide
lots more WithMapping etc classes to cross-map) to
handle cases that practically never arise.

So the question is: Do you have or know of parallelizable
usages that require support for byte, short, char, float
or boolean arrays? If there's a strong case to be made for
any of them, we should at least consider supporting.

There are a lot of common usages for ints, longs, and doubles,
but I just don't know of any compelling ones for the
others. Even for floats -- in most usages, people would
rather use twice the space, for doubles, to preserve
better accuracy. In fact, even int (vs long) is slightly
questionable for such reasons but still common enough to support.

(*) "almost-uniform" because a few differences between
scalars and objects show up in APIs. For example max()
for objects returns null for empty arrays
(or empty selections) for objects, but Double.MIN_VALUE
for doubles. (It would be possible to throw an exception
instead in both cases to make them uniform, but this
would not interact well with the base-case processing
conventions people normally use.)

-Doug


From dl at cs.oswego.edu  Tue Aug 28 08:06:01 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 28 Aug 2007 08:06:01 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D40844.8060906@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>	<63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu>
Message-ID: <46D40FA9.70505@cs.oswego.edu>

And one more:

ParallelArray tries to be as agnostic as possible about whether
Java will ever provide some form of syntactic closure support.

Without closures, users will need to create lots of little
classes and instances like the illustrated
     static final class IsSenior implements Predicate<Student> {
         public boolean evaluate(Student s) { return s.credits > 90; }
     }
     static final IsSenior isSenior = new IsSenior();

It would be great if IDEs helped automate this.
Maybe some of you would like to help develop such plugins
or lobby for them. It's not very different than IDE support
for little action classes and objects used in GUIs.

Even with this though, it's a bit weird to have all of
the interfaces and adaptors in Ops sitting in what
will probably eventually be java.util.concurrent.forkjoin.
They have little to do with fork/join parallelism per se.
But trying to place them elsewhere would be an uphill battle.
Where should they go? Should they all be nested in one
static-importable class, or each lifted into its own
class/interface? If lifted, do the names conflict with others
in any commonly used package out there? And so on.
Given all this, the simple expedient of keeping them as
they are seems like the surest path to making these usable.

On the other hand, if Java does end up providing closures,
then we or someone will eventually
be faced with a big retrofitting problem. If the
types are nameless types (e.g., "int(int)" rather than
"MapperFromIntToInt") then there might even be a need for
special tools to massage existing usages into the right
form.

Any advice about these issues would be welcome.

-Doug



From mwh at cs.umd.edu  Tue Aug 28 08:13:54 2007
From: mwh at cs.umd.edu (Michael Hicks)
Date: Tue, 28 Aug 2007 08:13:54 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D40844.8060906@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>
	<63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu>
Message-ID: <D65D9E03-2507-4CDB-847D-715224B46F27@cs.umd.edu>

> In fact, the differences between boxed and unboxed array
> operations on scalars are usually more extreme for parallel
> vs sequential use because of locality issues

Functional programming languages that use polymorphism have performed  
unboxing optimizations to good effect for quite a while now (e.g.,  
the simplest approach is to do a kind of in-lining or  
"monomorphization" of polymorphically-instantiated classes, which is,  
I believe, performed in the .NET runtime).  Assuming FJ becomes part  
of the assumed standard, should we not expect the VM to perform these  
optimizations for Java as well?  I know this doesn't answer your  
short-term need to provide classes that people can use now, but  
perhaps this addresses the longer-term API issue?

-Mike


From dl at cs.oswego.edu  Tue Aug 28 08:28:34 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 28 Aug 2007 08:28:34 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <D65D9E03-2507-4CDB-847D-715224B46F27@cs.umd.edu>
References: <46D330B8.3020907@cs.oswego.edu>
	<63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu>
	<D65D9E03-2507-4CDB-847D-715224B46F27@cs.umd.edu>
Message-ID: <46D414F2.40603@cs.oswego.edu>

Michael Hicks wrote:

> Functional programming languages that use polymorphism have performed 
> unboxing optimizations to good effect for quite a while now 

In defense of JVM implementors, it's a lot more challenging
to do this in OO languages with mutation than in functional
languages. (Digressing: because of mutation, it is usually
easier for OO programmers to get more
predictable performance by manually special-casing.
And I think that predictability of performance ranks
pretty high in goals for a parallel processing library.)

But everyone should feel free to volunteer within some open
source JVM project and implement this for us :-) When you are
done, we can deprecate the special scalar classes.

-Doug


From gregg at cytetech.com  Tue Aug 28 10:04:02 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 28 Aug 2007 09:04:02 -0500
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D40844.8060906@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>
	<63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu>
Message-ID: <46D42B52.7040908@cytetech.com>

Doug Lea wrote:
> (*) "almost-uniform" because a few differences between
> scalars and objects show up in APIs. For example max()
> for objects returns null for empty arrays
> (or empty selections) for objects, but Double.MIN_VALUE
> for doubles. (It would be possible to throw an exception
> instead in both cases to make them uniform, but this
> would not interact well with the base-case processing
> conventions people normally use.)

So a casual suggestion of the top of my head would be to provide an
isEmpty() method, a setEmptyReturnValue() method, and make the max method throw 
a EmptyArrayException if setEmptyReturnValue() has not been called.

Gregg Wonderly

From gregg at cytetech.com  Tue Aug 28 10:10:34 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 28 Aug 2007 09:10:34 -0500
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D40FA9.70505@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu>
	<63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu> <46D40FA9.70505@cs.oswego.edu>
Message-ID: <46D42CDA.2050104@cytetech.com>

Doug Lea wrote:
> And one more:
> 
> ParallelArray tries to be as agnostic as possible about whether
> Java will ever provide some form of syntactic closure support.
> 
> Without closures, users will need to create lots of little
> classes and instances like the illustrated
>      static final class IsSenior implements Predicate<Student> {
>          public boolean evaluate(Student s) { return s.credits > 90; }
>      }
>      static final IsSenior isSenior = new IsSenior();

Using this pattern, it would be pretty easy to create a templating mechanism in 
Netbeans 6.0 which could find all existing Predicates in a class, show them to 
you, allow you to create new ones, and then insert a reference to one in your 
source code.

If no one else does this, I'm willing to do something to make this available 
late this year, as NB6.0 ends development.

Gregg Wonderly

From larryr at saturn.sdsu.edu  Tue Aug 28 12:29:28 2007
From: larryr at saturn.sdsu.edu (Larry Riedel)
Date: Tue, 28 Aug 2007 09:29:28 -0700
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D40844.8060906@cs.oswego.edu>
Message-ID: <1188318568.484662.10839.nullmailer@home35>


> Do you have or know of parallelizable usages that require
> support for byte, short, char, float or boolean arrays?

If I could map a byte array directly onto a file a regular
unix C program has mapped using mmap(...MAP_SHARED...), I
think that would be really neat.  I have no idea if that
is feasible; the idea would be to have a low overhead
common denominator for high bandwidth low latency IPC.
If it is not feasible, please ignore this message. (-:


Larry


From rob.griffin at quest.com  Tue Aug 28 20:19:47 2007
From: rob.griffin at quest.com (Rob Griffin)
Date: Wed, 29 Aug 2007 10:19:47 +1000
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <46D40844.8060906@cs.oswego.edu>
References: <46D330B8.3020907@cs.oswego.edu><63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu>
Message-ID: <0BAEFFA7AFADFD4497F50DD093687E07062D97E7@melmbxw01.prod.quest.corp>

Doug,

Are you aware that unlike the Integer and Long MIN_VALUE constants
Double.MIN_VALUE is a positive number?

I think that -Double.MAX_VALUE is the value that should be used.

Regards,

Rob Griffin. 

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Doug
Lea
Sent: Tuesday, 28 August 2007 9:34 PM
To: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] forkjoin.ParallelArray and friends

Here's a question about another intentional lack of complete
generality we'd like some feedback on:

Background: We supply special scalar-based ParallelDoubleArray,
ParallelLongArray, and ParallelIntArray. Operations
on a ParallelIntArray are in general noticeably faster than
a ParallelArray<Integer> (and similarly for the others).
In fact, the differences between boxed and unboxed array
operations on scalars are usually more extreme for parallel
vs sequential use because of locality issues -- the elements of a
ParallelIntArray are always nearby each other in memory,
but the Integers of a ParallelArray<Integer> may become
scattered across memory, depending on GC/mutation patterns.
GC runtime mechanics usually also cause array element updates
(as in a[i] = x) of references to contend with each other
more than do scalar writes, which can limit scalability.
I suspect that as time goes by, the gap between boxed and
unboxed versions may shrink. But it will still surely be wider
for parallel than sequential processing for the medium-term future.

On the other hand, supporting special scalar forms in
an almost-uniform (*) way requires APIs/code that grow
with the square of the number of forms. So we don't want
to add thousands of lines of special-case code (and provide
lots more WithMapping etc classes to cross-map) to
handle cases that practically never arise.

So the question is: Do you have or know of parallelizable
usages that require support for byte, short, char, float
or boolean arrays? If there's a strong case to be made for
any of them, we should at least consider supporting.

There are a lot of common usages for ints, longs, and doubles,
but I just don't know of any compelling ones for the
others. Even for floats -- in most usages, people would
rather use twice the space, for doubles, to preserve
better accuracy. In fact, even int (vs long) is slightly
questionable for such reasons but still common enough to support.

(*) "almost-uniform" because a few differences between
scalars and objects show up in APIs. For example max()
for objects returns null for empty arrays
(or empty selections) for objects, but Double.MIN_VALUE
for doubles. (It would be possible to throw an exception
instead in both cases to make them uniform, but this
would not interact well with the base-case processing
conventions people normally use.)

-Doug

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest



From dl at cs.oswego.edu  Wed Aug 29 07:53:03 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 29 Aug 2007 07:53:03 -0400
Subject: [concurrency-interest] forkjoin.ParallelArray and friends
In-Reply-To: <0BAEFFA7AFADFD4497F50DD093687E07062D97E7@melmbxw01.prod.quest.corp>
References: <46D330B8.3020907@cs.oswego.edu><63b4e4050708271955p47a28860scbd5dfbd83ac560@mail.gmail.com>
	<46D40844.8060906@cs.oswego.edu>
	<0BAEFFA7AFADFD4497F50DD093687E07062D97E7@melmbxw01.prod.quest.corp>
Message-ID: <46D55E1F.4060605@cs.oswego.edu>

Rob Griffin wrote:
> Doug,
> 
> Are you aware that unlike the Integer and Long MIN_VALUE constants
> Double.MIN_VALUE is a positive number?
> 
> I think that -Double.MAX_VALUE is the value that should be used.
> 

Thanks!! I confess to once knowing this but forgetting it.
Will fix. Along these lines,  Ops.NaturalDoubleComparator
does reflect a related oddity by using Double.compare
http://java.sun.com/javase/6/docs/api/java/lang/Double.html#compare(double,%20double)

-Doug


From hanson.char at gmail.com  Thu Aug 30 18:57:14 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 30 Aug 2007 15:57:14 -0700
Subject: [concurrency-interest] Parametric Initialization On Demand Holder
	Idiom ?
Message-ID: <ca53c8f80708301557q364c48fchbb5b5c5d73d9aceb@mail.gmail.com>

Similar to the Initialization On Demand Holder Idiom (IODHI), it
occurs to me that sometimes not only is there a need to access a
singleton instance, which is lazily initialized if constructed for the
first time, but also to initialize with parameters, which are ignored
if the singleton instance has already been constructed.  Also, if
there is concurrent access to the singleton instance for the very
first time, it doesn't matter from which thread the parameters are
passed, as long as the parameters are specified by one of these
threads (ie the parameters don't come from "out-of-thin-air".)

The API would be something like:

    SomethingMore singleton = SomethingMore.getInstance(params);

Now this begs the question: similar to the original IODHI, can the
implementation of such "Parametric IODHI" be thread-safe without
explicit synchronization ?

See below for one proposed yet potentially controversial
implementation.  (I know I could have used ThreadLocal to eliminate
the controversy, but then it seems unnecessary and relatively
expensive.)

Any comment on it's thread-safeness and/or correctness ?  Better ideas
?  Or maybe this is completely mis-guided ?

Hanson Char

/**
 * Parametric Initialization On Demand Holder Idiom,
  * which is thread-safe yet incorrectly synchronized.
 */
public class SomethingMore
{
    /** A thread-safe value, such as a {@link String} instance. */
    private final Object value;
    private SomethingMore(Object value) { this.value = value; }
    public Object getValue() { return value; }

    /**
     * A temporary buffer to hold the thread-safe value used to initialize
     * the singleton instance of SomethingMore.
     *
     * Technically data race can occur among the multiple writes to and the
     * single read from this field, and therefore it is considered
     * "incorrectly synchronized" according to the JMM.
     * Yet it doesn't matter in this case.  Or does it ?
     */
    private static Object valueHolder;
    private static class LazySomethingMoreHolder {
        public static SomethingMore something = new SomethingMore(valueHolder);
    }
    /**
     * Returns the singleton instance of {@link SomethingMore}.
     *
     * @param value a thread-safe value used to initialize the
     * singleton instance of SomethingMore, if the instance is
     * constructed for the first time;
     * ignored otherwise.
     * Caller of this method is responsible for passing in a
     * value which is thread-safe per se,
     * such as a {@link String} instance.
     */
    public static SomethingMore getInstance(Object value) {
        SomethingMore.valueHolder = value;
        return LazySomethingMoreHolder.something;
    }
}

From joe.bowbeer at gmail.com  Thu Aug 30 19:45:46 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 30 Aug 2007 16:45:46 -0700
Subject: [concurrency-interest] Parametric Initialization On Demand
	Holder Idiom ?
In-Reply-To: <ca53c8f80708301557q364c48fchbb5b5c5d73d9aceb@mail.gmail.com>
References: <ca53c8f80708301557q364c48fchbb5b5c5d73d9aceb@mail.gmail.com>
Message-ID: <31f2a7bd0708301645i7fc04997t76ec865cab0976aa@mail.gmail.com>

The value is not safely published here:

SomethingMore.valueHolder = value;

That creates a window where another thread could overwrite valueHolder
before the current thread initializes the singleton.

This is OK for super-safe values like String.  Immutable objects with
all fields final do not require safe publication.  In general,
thread-safe values do require safe publication.

--Joe

On 8/30/07, Hanson Char <hanson.char at gmail.com> wrote:
> Similar to the Initialization On Demand Holder Idiom (IODHI), it
> occurs to me that sometimes not only is there a need to access a
> singleton instance, which is lazily initialized if constructed for the
> first time, but also to initialize with parameters, which are ignored
> if the singleton instance has already been constructed.  Also, if
> there is concurrent access to the singleton instance for the very
> first time, it doesn't matter from which thread the parameters are
> passed, as long as the parameters are specified by one of these
> threads (ie the parameters don't come from "out-of-thin-air".)
>
> The API would be something like:
>
>     SomethingMore singleton = SomethingMore.getInstance(params);
>
> Now this begs the question: similar to the original IODHI, can the
> implementation of such "Parametric IODHI" be thread-safe without
> explicit synchronization ?
>
> See below for one proposed yet potentially controversial
> implementation.  (I know I could have used ThreadLocal to eliminate
> the controversy, but then it seems unnecessary and relatively
> expensive.)
>
> Any comment on it's thread-safeness and/or correctness ?  Better ideas
> ?  Or maybe this is completely mis-guided ?
>
> Hanson Char
>
> /**
>  * Parametric Initialization On Demand Holder Idiom,
>   * which is thread-safe yet incorrectly synchronized.
>  */
> public class SomethingMore
> {
>     /** A thread-safe value, such as a {@link String} instance. */
>     private final Object value;
>     private SomethingMore(Object value) { this.value = value; }
>     public Object getValue() { return value; }
>
>     /**
>      * A temporary buffer to hold the thread-safe value used to initialize
>      * the singleton instance of SomethingMore.
>      *
>      * Technically data race can occur among the multiple writes to and the
>      * single read from this field, and therefore it is considered
>      * "incorrectly synchronized" according to the JMM.
>      * Yet it doesn't matter in this case.  Or does it ?
>      */
>     private static Object valueHolder;
>     private static class LazySomethingMoreHolder {
>         public static SomethingMore something = new SomethingMore(valueHolder);
>     }
>     /**
>      * Returns the singleton instance of {@link SomethingMore}.
>      *
>      * @param value a thread-safe value used to initialize the
>      * singleton instance of SomethingMore, if the instance is
>      * constructed for the first time;
>      * ignored otherwise.
>      * Caller of this method is responsible for passing in a
>      * value which is thread-safe per se,
>      * such as a {@link String} instance.
>      */
>     public static SomethingMore getInstance(Object value) {
>         SomethingMore.valueHolder = value;
>         return LazySomethingMoreHolder.something;
>     }
> }
>

From hanson.char at gmail.com  Fri Aug 31 00:41:02 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 30 Aug 2007 21:41:02 -0700
Subject: [concurrency-interest] Parametric Initialization On Demand
	Holder Idiom ?
In-Reply-To: <31f2a7bd0708301645i7fc04997t76ec865cab0976aa@mail.gmail.com>
References: <ca53c8f80708301557q364c48fchbb5b5c5d73d9aceb@mail.gmail.com>
	<31f2a7bd0708301645i7fc04997t76ec865cab0976aa@mail.gmail.com>
Message-ID: <ca53c8f80708302141s76040adbh2523f771fd29bda3@mail.gmail.com>

On 8/30/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> The value is not safely published here:
>
> SomethingMore.valueHolder = value;
>
> That creates a window where another thread could overwrite valueHolder
> before the current thread initializes the singleton.

True.  As explained in the outset, this is considered acceptable as
long as the overwriting value comes from one of the contending threads
rather than "out-of-thin-air".

> This is OK for super-safe values like String.  Immutable objects with
> all fields final do not require safe publication.  In general,
> thread-safe values do require safe publication.

Agree.  However, is it possible to contrive an example where a
thread-safe (but not super-safe like  immutable) value passed to the
SomethingMore.getInstance(params) would cause a
surprising/unexpected/corrupted/partially-initialized result ?

Hanson Char

From joe.bowbeer at gmail.com  Fri Aug 31 02:18:07 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 30 Aug 2007 23:18:07 -0700
Subject: [concurrency-interest] Parametric Initialization On Demand
	Holder Idiom ?
In-Reply-To: <ca53c8f80708302141s76040adbh2523f771fd29bda3@mail.gmail.com>
References: <ca53c8f80708301557q364c48fchbb5b5c5d73d9aceb@mail.gmail.com>
	<31f2a7bd0708301645i7fc04997t76ec865cab0976aa@mail.gmail.com>
	<ca53c8f80708302141s76040adbh2523f771fd29bda3@mail.gmail.com>
Message-ID: <31f2a7bd0708302318i51a6b167h5ccc2729eac3800c@mail.gmail.com>

On 8/30/07, Hanson Char <hanson.char at gmail.com> wrote:
> On 8/30/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
>
> > This is OK for super-safe values like String.  Immutable objects with
> > all fields final do not require safe publication.  In general,
> > thread-safe values do require safe publication.
>
> Agree.  However, is it possible to contrive an example where a
> thread-safe (but not super-safe like  immutable) value passed to the
> SomethingMore.getInstance(params) would cause a
> surprising/unexpected/corrupted/partially-initialized result ?
>

Now I think this is a safe construction.  The key is that
SomethingMore.value is final.

private final Object value;

http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#finalRight

--Joe

From dcholmes at optusnet.com.au  Fri Aug 31 03:11:44 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 31 Aug 2007 17:11:44 +1000
Subject: [concurrency-interest] Parametric Initialization On
	Demand	Holder Idiom ?
In-Reply-To: <ca53c8f80708302141s76040adbh2523f771fd29bda3@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEHAHIAA.dcholmes@optusnet.com.au>

Hanson, Joe,

> Agree.  However, is it possible to contrive an example where a
> thread-safe (but not super-safe like  immutable) value passed to the
> SomethingMore.getInstance(params) would cause a
> surprising/unexpected/corrupted/partially-initialized result ?

I think the general answer is yes. If thread-1 sets valueHolder and thread-2
does LazySomethingMoreHolder.something (because concurrent calls to
getInstance are interleaved) and then thread-2 uses the object created by
thread-1, then it is using an unsafely published object. There is no
happens-before relationship between the construction of the object by
thread-1 and its use in thread-2.

Now Joe has pointed out the rule for final fields, but I don't think that
quite applies to this situation - or if it does then there is a problem for
VM implementors.

The final-field rule allows you to unsafely publish an object but have final
fields of that object safely visible and "the objects to which they refer".
But I believe the intent there was to cover the case where the thread
setting the final field *also* constructed the object. That is not the case
here.

Suppose the final-field rule does apply, then when thread-1 does:

 Foo f = new Foo();
 SomethingMore.valueHolder = f;

the VM has to know that valueHolder will soon be assigned to a final field
in another thread, and force a happens-before ordering between the two
actions. But the VM can't know that will happen so it won't do anything to
enforce happens before.

Of course, depending on the nature of the object itself it might be harmless
to unsafely publish it.

That's my take anyway  - perhaps we need to discuss this on the JMM mailing
list :)

Cheers,
David Holmes


From dhanji at gmail.com  Fri Aug 31 05:00:52 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Fri, 31 Aug 2007 19:00:52 +1000
Subject: [concurrency-interest] synchronized maps
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEFIHIAA.dcholmes@optusnet.com.au>
References: <aa067ea10708262013s589a4391q669dd3c53e3b7eaf@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEFIHIAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10708310200j35089e37ka96383440e83db27@mail.gmail.com>

Is there an implementation of ConcurrentMap that has WeakHashMap semantics?
Or am I doomed to using synchronizedMap() over j.u.WHM?
Thanks,

Dhanji.

On 8/27/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  Dhanji,
>
> Once an entry (K, V1) is in the map (CHM) then the difference between
> put(K, V2) and putIfAbsent(K, V2) is negligible - a single extra putField in
> the put() case. In CHM the two methods share the exact same code - with a
> flag controlling whether or not a replacing store takes place.
>
> The get() method for CHM does not use locking except in a very rare
> (theoretical but not observed in practice) case.
>
> java.util.HashMap is safe for concurrent reads as long as no structural
> modifications occur concurrently. If you publish via a final field of
> another object, then as long as you didn't publish that object during
> construction, the assignment to the final field must happen-before any
> susequent read of the final field. Hence any modifications to the map must
> happen-before any subsequents reads of the map.
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Dhanji R.
> Prasanna
> *Sent:* Monday, 27 August 2007 1:14 PM
> *To:* concurrency-interest
> *Subject:* [concurrency-interest] synchronized maps
>
> Hi,
>
> I have a JIT-style cache implemented as a HashMap. When client code
> requests a key, it looks for an entry and if there is nothing, "compiles"
> and stashes a value for that key. Currently, I am using a
> Collections.synchronizedMap () wrapper over a j.u.HM. Since I am assured
> that the value for a key ("natural value") is always the same, I don't
> really care if multiple threads compile and overwrite the same key
> concurrently.
>
> Am I correct in assuming that using a ConcurrentMap.putIfAbsent() will be
> faster in my case (so I can discard concurrently compiled values that are
> "later" than the first-put) than a straightforward synchronized overwrite
> (multiple puts)?
>
> Assuming of course, that the cost of creating the value is negligible
> compared to the cost of locking the entire cache-get method as number of
> threads increase... the cache-get method exposed to client code right now is
> (deliberately) unsynchronized.
>
>
> I have another minor question regarding j.u.HM. I publish an unmodifiable
> (pre-constructed) HM instance to a final member of an object, is it safe to
> assume that leaving the map unsynchronized for multiple threads invoking
> get() is ok ( i.e. is there any kind of internal optimization after the
> last-put)?
>
> Thanks in advance,
>
> Dhanji.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070831/aa0a1d13/attachment.html 

From glyn.normington at gmail.com  Fri Aug 31 12:10:41 2007
From: glyn.normington at gmail.com (Glyn Normington)
Date: Fri, 31 Aug 2007 17:10:41 +0100
Subject: [concurrency-interest] Fixed thread pool problem?
Message-ID: <5668a1520708310910n4d896c64u19a9dd55a0e10827@mail.gmail.com>

I wrote the attached testcase to try out the concurrency utilities on a dual
processor system and found that the fixed thread pool sometimes schedules
threads serially. I've reproduced this behaviour on a 4-way system and on
Java 5 and Java 6 with a couple of different JVMs. I've also spent a fair
amount of time analysing thread dumps to try to understand the behaviour.
Unfortunately, my current employer doesn't like me reading GPL code (but
let's not get into that here!), so the only source code I've found for the
concurrency utilities is some early "public domain" code, so I haven't been
able to get much further in analysis.

To reproduce the behaviour, execute:

java -jar life.jar

and watch the CPU utilisation using a system monitor. On a dual or quad CPU
system, this stays at around one processor's worth.

The source code is included in the jar, but snippets of the crucial class
follow at the end of this post. To highlight the undesirable behaviour,
uncomment the line marked [A] and you'll find that all CPUs run at 100%. But
if you comment out [A] again and uncomment the line marked [B], then only
one processor is driven to 100% on average. I say on average because, on the
systems I've tried, the hot thread seems to move between CPUs from time to
time. It's a mystery to me why moving the infinite loop after the statement:

for (Generation p : list) {

should make any difference. My guess is that this simply affects the timing.
(Yes, I did try writing out the for loop in the older syntax in case there
was some surprise synchronization and the behaviour was unchanged.)

Thoughts? Simple coding slip??

Glyn

...
public class ConcurrentGenerator implements Generator {

    private static final int PROCS = Runtime.getRuntime
().availableProcessors();

    @GuardedBy("this")
    private Generation current;

    @GuardedBy("this")
    private int prevIndex = 0;

    @GuardedBy("previous[i]")
    private List<?> previous[] = new ArrayList<?>[PROCS];

    private final int dim;
    private final Rule rule;

    private volatile boolean repeated = false;

    private static final ExecutorService exec = Executors.newFixedThreadPool
(PROCS);

    ...

    private class Scanner implements Callable<Boolean> {
        private Generation curGen;
        private final ArrayList<Generation> list;
        @SuppressWarnings("unchecked")
        public Scanner(int i, Generation cur) {
            list = (ArrayList<Generation>) previous[i];
            try {
                curGen = (Generation)cur.clone();
            } catch (CloneNotSupportedException e) {
                e.printStackTrace();
            }
        }
        public Boolean call() throws Exception {
            boolean rep = false;
            synchronized (list) {
                // while (list != null) {} // produces 2x100% CPU on a dual
processor system [A]
                for (Generation p : list) {
                    // while (list != null) {} // only produces 100% CPU on
a dual processor system [B]
                    if (curGen.equals(p)) {
                        rep = true;
                    }
                }
            }
            return rep;
        }
    }

    @SuppressWarnings("unchecked")
    private void scheduleRepeatCheck() {
        Future<?> futures[] = new Future<?>[PROCS];
        for (int i = 0; i < PROCS; i++) {
            futures[i] = exec.submit(new Scanner(i, current));
        }
        for (int i = 0; i < PROCS; i++) {
            try {
                repeated = repeated || ((Future<Boolean>)futures[i]).get();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (ExecutionException e) {
                e.printStackTrace();
            }
        }
    }

  ...
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070831/8ad91233/attachment-0001.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: life.jar
Type: application/x-java-archive
Size: 14168 bytes
Desc: not available
Url : /pipermail/attachments/20070831/8ad91233/attachment-0001.bin 

From joe.bowbeer at gmail.com  Fri Aug 31 14:58:36 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 31 Aug 2007 11:58:36 -0700
Subject: [concurrency-interest] Fixed thread pool problem?
In-Reply-To: <5668a1520708310910n4d896c64u19a9dd55a0e10827@mail.gmail.com>
References: <5668a1520708310910n4d896c64u19a9dd55a0e10827@mail.gmail.com>
Message-ID: <31f2a7bd0708311158h2557d8e4p9467e95ee57f9ed7@mail.gmail.com>

On 8/31/07, Glyn Normington <glyn.normington at gmail.com> wrote:
>
> [...] To highlight the undesirable behaviour,
> uncomment the line marked [A] and you'll find that all CPUs run at 100%. But
> if you comment out [A] again and uncomment the line marked [B], then only
> one processor is driven to 100% on average. I say on average because, on the
> systems I've tried, the hot thread seems to move between CPUs from time to
> time. It's a mystery to me why moving the infinite loop after the statement:
>

It's clear that uncommenting A causes all processors to run an infinite loop.

It's harder to explain why uncommenting B instead causes only one
processor to infinite loop.

Observe that uncommenting B will infinite loop whenever previous[i] is
not empty.  But note that the first step() invocation only adds a
generation to previous[1].  So only scanner #1 will infinite loop.

public void step() {
  Generation cur;
  int i;
  synchronized (this) {
    cur = current;
    prevIndex = ++prevIndex % PROCS;
    i = prevIndex;
  }
  synchronized (previous[i]) {
    ((ArrayList<Generation>) previous[i]).add(cur);
  }
  scheduleRepeatCheck();
}

--Joe

From kielstra at ca.ibm.com  Fri Aug 31 17:46:52 2007
From: kielstra at ca.ibm.com (Allan Kielstra)
Date: Fri, 31 Aug 2007 17:46:52 -0400
Subject: [concurrency-interest] Fixed thread pool problem?
Message-ID: <OF2F95106F.E9F47531-ON85257348.0075CB6F-85257348.0077A53C@ca.ibm.com>

Here's what happens on my 8-way Power5 running AIX when I use the second 
infinite loop (the one marked  // while (list != null) {} // only produces 
100% CPU on a dual processor system [B])

list.size() is 0 for all Scanners except Scanner 1.  Therefore, all 
Scanners except Scanner 1 return some value pretty quickly.  Scanner 1 
waits forever.  scheduleRepeatChecks retrieves a result for Scanner 0 and 
then freezes waiting for Scanner 1.  Since scheduelRepeatChecks never 
returns, the step method never returns either.  So the whole system is 
waiting for Scanner 1 to finish and no new work is being generated. 
(Because Scanner 1 is the only thing executing a busy wait;  everything 
else is suspended waiting for something to do.)

Here's what happens when I use the first infinite loop (the one marked // 
while (list != null) {} // produces 2x100% CPU on a dual processor system 
[A] )

All Scanners go into an infinite loop.  Pretty soon the system divides the 
busy work among all the processors as follows:
cpu 2 is creating/submitting Futures
cpu 2 is checking Future 0
scanner 0initially running on cpu4
scanner 4initially running on cpu1
scanner 1initially running on cpu0
scanner 6initially running on cpu1
scanner 7initially running on cpu0
scanner 2initially running on cpu1
scanner 3initially running on cpu0
scanner 5initially running on cpu3
scanner 1migrated from 0 to 2
scanner 7migrated from 0 to 6
scanner 2migrated from 1 to 5
scanner 4migrated from 1 to 7
scanner 2migrated from 5 to 0
scanner 0migrated from 4 to 5
scanner 0migrated from 5 to 4
scanner 3migrated from 0 to 5
Now all CPUs are running a busy loop instead of code that is waiting in a 
suspended state.  Hence all CPUs appear to be busy.

Going back to the first case, AIX does gamely try:
scanner 1initially running on cpu1
scanner 1migrated from 1 to 2

but to no avail.  Only 1 CPU appears to be really busy.

Allan Kielstra
IBM Canada Lab
Phone: +1 (905) 413-3558 T/L 969-3558
kielstra at ca.ibm.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070831/bec60bde/attachment.html 

From dl at cs.oswego.edu  Fri Aug 31 19:15:30 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 31 Aug 2007 19:15:30 -0400
Subject: [concurrency-interest] Fixed thread pool problem?
In-Reply-To: <5668a1520708310910n4d896c64u19a9dd55a0e10827@mail.gmail.com>
References: <5668a1520708310910n4d896c64u19a9dd55a0e10827@mail.gmail.com>
Message-ID: <46D8A112.20705@cs.oswego.edu>

Glyn Normington wrote:
> so the 
> only source code I've found for the concurrency utilities is some early 
> "public domain" code, so I haven't been able to get much further in 
> analysis.
> 

(Not that you needed see them to answer this,
but the definitive public domain sources
for j.u.c. are always in our CVS -- see the usual links at
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html --
although we don't always know exactly which CVS revisions
any particular version of any JVM is based on.)

> and watch the CPU utilisation using a system monitor. On a dual or quad 
> CPU system, this stays at around one processor's worth.
> 

I think the lack of speedup is mostly due to synchronization
in Generation.equals? It seems that there's a lot of
lock contention there. (This is in addition to the explanation
of the infinite loop anomalies by Joe.)

(BTW, For fun, someone might want to try a ParallelArray version
of this code?)

-Doug

