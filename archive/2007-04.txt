From peter.kovacs.1.0rc at gmail.com  Sun Apr  1 09:16:23 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Sun, 1 Apr 2007 15:16:23 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
Message-ID: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>

Hi,

Does anyone have experience with java.util.concurrent or with the
backport on Windows?

I am testing the Java 5-optimized version of backport  for a specific
application. I already reported on March 20 that I observed
significant performance degradation compared to an old implementation
which makes use exclusively of "primitive" Java language concurrency
constructs (http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-March/003784.html).
In the said mail, I hinted at some possible changes in the
backport-based implementation which I thought might reduce the
performance difference. Implementing these changes I achieved a
comparable performance with the backport as with the older "primitive"
implementation.  This was on linux. (I also remember having observed
fairly good results on HP-UX, though I haven't tested that
extensively.)

Now I started testing on windows (on the same hardware) and the
performance degradation is very disappointing. I tried several
variations of my new backport-based implementation and I invariably
get an almost serial execution! (What makes this situation very
difficult to handle is that I could explain a serial behaviour [with a
slow single consumer], if I didn't have more or less acceptable
results on other platforms or with the old "primitive"
implementation.)

I am pretty much out of my wits...

Can anyone comment, please?

Thanks
Peter

From szabolcs.ferenczi at gmail.com  Sun Apr  1 11:12:12 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 1 Apr 2007 17:12:12 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
Message-ID: <c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>

On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
...
> application. I already reported on March 20 that I observed
> significant performance degradation compared to an old implementation
> which makes use exclusively of "primitive" Java language concurrency
> constructs (http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-March/003784.html).

I am curious whether you have checked the proposal that you have
received for that mail. (Using the combination of semaphores and
ConcurrentLinkedQueue.)

Anyway, some more details would be very interesting in order to say
anything about your problem. Can you give some hints about the applied
synchronization constructions in your program?

Best Regards,
Szabolcs

From peter.kovacs.1.0rc at gmail.com  Sun Apr  1 17:00:31 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Sun, 1 Apr 2007 23:00:31 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
Message-ID: <b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>

I haven't tried it, because I got worried about Doug Lea's comment
that it may be less scalable that LinkedBlockingQueue. I will probably
try it anyway.

In more concrete terms: you can find the problematic backport-based
implementation here:
http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
. "outputQueue" is the variable where I am using LinkedBlockingQueue.
And yes, my case falls into the multiple-producer-one-consumer
category.

I am still interested to know (in more general terms): to what extent
can I abstract away from the OS/hardware platform which my solution is
running on?

Which one do I have to be more worried about: differences in the
application logic (e.g. single-consumer vs. multiple consumer) or
differences in the hardware/OS platform?

In fact, this question is more general than j.u.c/backport. My old
database import implementation already takes 50% more time to execute
on Linux than on Windows on the same hardware. (See PS.) Or is it that
the implementation is not "smart enough" to perform equally well on
any platform?

I've seen in jcpip the results of several performance tests run in
Sun's lab. Has anyone done any tests to compare performance on
different platforms? Java is much about platform independence after
all.

Any comment appreciated.

Peter

PS:
I am having a hard time explaining a significant performance
difference observed between runs of the same Java application on Linux
and on Windows. The application consists of two components: a
concurrent Java producer and a database consumer. The database itself
is about 10% percent slower on Linux than Windows (if the Java
producer is running on another machine). The Java producer routines
perform the same on Windows and on Linux (if the database runs on
another machine). There is a difference of about 40% I cannot explain
when both application components run on the same Linux or Windows
system. My primary suspect currently is the Linux scheduler which
excessively prefers I/O-bound tasks over CPU-bound tasks on serveral
counts: it gives I/O-bound tasks higher dynamic priority and gives
them longer time-slice as well. (The ideology behind this is that
interactive tasks have to be more responsive than non-interactive (ie.
background) tasks. The scheduler considers a process "interactive", if
it is waiting long enough on I/O. There is also some sense of
fairness/compensation behind this policy.) Thus the I/O bound database
process may still be waiting on I/O, while the Java producer has
already consumed its time-slice and is waiting idly in the expired
priority array of the run queue. The upshot being the CPU sitting idly
while there is work to be done. (Conversely, the Windows scheduler
might be smart enough to know that disk I/O is not a sign of
interactivity.) This hypothesis seems to be supported by the fact that
CPU utilization is much lower on Linux than on Windows, but running
the database on a different machine significantly increases CPU
utilization (obviously by the Java producer) on Linux and performance
becomes about the same as on Windows.

A not performance-related observation but belongs here: after
seemingly clean tests on dual processor Intel platforms with Windows,
Linux and HP-UX, I regularly discover new concurrency-related bugs in
my implementation on a single core Opteron with Solaris. And this
reinforces my experience so far: the hardware/OS platform counts a
lot.


On 4/1/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> ...
> > application. I already reported on March 20 that I observed
> > significant performance degradation compared to an old implementation
> > which makes use exclusively of "primitive" Java language concurrency
> > constructs (http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-March/003784.html).
>
> I am curious whether you have checked the proposal that you have
> received for that mail. (Using the combination of semaphores and
> ConcurrentLinkedQueue.)
>
> Anyway, some more details would be very interesting in order to say
> anything about your problem. Can you give some hints about the applied
> synchronization constructions in your program?
>
> Best Regards,
> Szabolcs
>

From hanson.char at gmail.com  Sun Apr  1 17:31:31 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Sun, 1 Apr 2007 14:31:31 -0700
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
Message-ID: <ca53c8f80704011431g58c562e2sb01a3a5f6cbccaf8@mail.gmail.com>

Hi Peter,

> I haven't tried it, because I got worried about Doug Lea's comment
> that it may be less scalable that LinkedBlockingQueue. I will probably
> try it anyway.

I don't think Doug ever commented that the proposed
ConcurrentLinkedBlockingQueue is any less scalable than the existing
LinkedBlockingQueue.  I would think the opposite is true.

Or did I miss out his comment ?

Hanson Char

On 4/1/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> I haven't tried it, because I got worried about Doug Lea's comment
> that it may be less scalable that LinkedBlockingQueue. I will probably
> try it anyway.
>
> In more concrete terms: you can find the problematic backport-based
> implementation here:
> http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
> . "outputQueue" is the variable where I am using LinkedBlockingQueue.
> And yes, my case falls into the multiple-producer-one-consumer
> category.
>
> I am still interested to know (in more general terms): to what extent
> can I abstract away from the OS/hardware platform which my solution is
> running on?
>
> Which one do I have to be more worried about: differences in the
> application logic (e.g. single-consumer vs. multiple consumer) or
> differences in the hardware/OS platform?
>
> In fact, this question is more general than j.u.c/backport. My old
> database import implementation already takes 50% more time to execute
> on Linux than on Windows on the same hardware. (See PS.) Or is it that
> the implementation is not "smart enough" to perform equally well on
> any platform?
>
> I've seen in jcpip the results of several performance tests run in
> Sun's lab. Has anyone done any tests to compare performance on
> different platforms? Java is much about platform independence after
> all.
>
> Any comment appreciated.
>
> Peter
>
> PS:
> I am having a hard time explaining a significant performance
> difference observed between runs of the same Java application on Linux
> and on Windows. The application consists of two components: a
> concurrent Java producer and a database consumer. The database itself
> is about 10% percent slower on Linux than Windows (if the Java
> producer is running on another machine). The Java producer routines
> perform the same on Windows and on Linux (if the database runs on
> another machine). There is a difference of about 40% I cannot explain
> when both application components run on the same Linux or Windows
> system. My primary suspect currently is the Linux scheduler which
> excessively prefers I/O-bound tasks over CPU-bound tasks on serveral
> counts: it gives I/O-bound tasks higher dynamic priority and gives
> them longer time-slice as well. (The ideology behind this is that
> interactive tasks have to be more responsive than non-interactive (ie.
> background) tasks. The scheduler considers a process "interactive", if
> it is waiting long enough on I/O. There is also some sense of
> fairness/compensation behind this policy.) Thus the I/O bound database
> process may still be waiting on I/O, while the Java producer has
> already consumed its time-slice and is waiting idly in the expired
> priority array of the run queue. The upshot being the CPU sitting idly
> while there is work to be done. (Conversely, the Windows scheduler
> might be smart enough to know that disk I/O is not a sign of
> interactivity.) This hypothesis seems to be supported by the fact that
> CPU utilization is much lower on Linux than on Windows, but running
> the database on a different machine significantly increases CPU
> utilization (obviously by the Java producer) on Linux and performance
> becomes about the same as on Windows.
>
> A not performance-related observation but belongs here: after
> seemingly clean tests on dual processor Intel platforms with Windows,
> Linux and HP-UX, I regularly discover new concurrency-related bugs in
> my implementation on a single core Opteron with Solaris. And this
> reinforces my experience so far: the hardware/OS platform counts a
> lot.
>
>
> On 4/1/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> > On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> > ...
> > > application. I already reported on March 20 that I observed
> > > significant performance degradation compared to an old implementation
> > > which makes use exclusively of "primitive" Java language concurrency
> > > constructs (http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-March/003784.html).
> >
> > I am curious whether you have checked the proposal that you have
> > received for that mail. (Using the combination of semaphores and
> > ConcurrentLinkedQueue.)
> >
> > Anyway, some more details would be very interesting in order to say
> > anything about your problem. Can you give some hints about the applied
> > synchronization constructions in your program?
> >
> > Best Regards,
> > Szabolcs
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From hanson.char at gmail.com  Sun Apr  1 17:44:38 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Sun, 1 Apr 2007 14:44:38 -0700
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <ca53c8f80704011431g58c562e2sb01a3a5f6cbccaf8@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<ca53c8f80704011431g58c562e2sb01a3a5f6cbccaf8@mail.gmail.com>
Message-ID: <ca53c8f80704011444s251ae256q22b3d8d2e2c61b17@mail.gmail.com>

I think Doug's comment's on reduced scalability is when I first
proposed the use of a semaphore+LinkedBlockingQueue many months ago.

The current version of ConcurrentLinkedBlockingQueue, however, is NOT
using any semaphore and is in fact totally lock-free.

Cheers,
Hanson Char

On 4/1/07, Hanson Char <hanson.char at gmail.com> wrote:
> Hi Peter,
>
> > I haven't tried it, because I got worried about Doug Lea's comment
> > that it may be less scalable that LinkedBlockingQueue. I will probably
> > try it anyway.
>
> I don't think Doug ever commented that the proposed
> ConcurrentLinkedBlockingQueue is any less scalable than the existing
> LinkedBlockingQueue.  I would think the opposite is true.
>
> Or did I miss out his comment ?
>
> Hanson Char
>
> On 4/1/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> > I haven't tried it, because I got worried about Doug Lea's comment
> > that it may be less scalable that LinkedBlockingQueue. I will probably
> > try it anyway.
> >
> > In more concrete terms: you can find the problematic backport-based
> > implementation here:
> > http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
> > . "outputQueue" is the variable where I am using LinkedBlockingQueue.
> > And yes, my case falls into the multiple-producer-one-consumer
> > category.
> >
> > I am still interested to know (in more general terms): to what extent
> > can I abstract away from the OS/hardware platform which my solution is
> > running on?
> >
> > Which one do I have to be more worried about: differences in the
> > application logic (e.g. single-consumer vs. multiple consumer) or
> > differences in the hardware/OS platform?
> >
> > In fact, this question is more general than j.u.c/backport. My old
> > database import implementation already takes 50% more time to execute
> > on Linux than on Windows on the same hardware. (See PS.) Or is it that
> > the implementation is not "smart enough" to perform equally well on
> > any platform?
> >
> > I've seen in jcpip the results of several performance tests run in
> > Sun's lab. Has anyone done any tests to compare performance on
> > different platforms? Java is much about platform independence after
> > all.
> >
> > Any comment appreciated.
> >
> > Peter
> >
> > PS:
> > I am having a hard time explaining a significant performance
> > difference observed between runs of the same Java application on Linux
> > and on Windows. The application consists of two components: a
> > concurrent Java producer and a database consumer. The database itself
> > is about 10% percent slower on Linux than Windows (if the Java
> > producer is running on another machine). The Java producer routines
> > perform the same on Windows and on Linux (if the database runs on
> > another machine). There is a difference of about 40% I cannot explain
> > when both application components run on the same Linux or Windows
> > system. My primary suspect currently is the Linux scheduler which
> > excessively prefers I/O-bound tasks over CPU-bound tasks on serveral
> > counts: it gives I/O-bound tasks higher dynamic priority and gives
> > them longer time-slice as well. (The ideology behind this is that
> > interactive tasks have to be more responsive than non-interactive (ie.
> > background) tasks. The scheduler considers a process "interactive", if
> > it is waiting long enough on I/O. There is also some sense of
> > fairness/compensation behind this policy.) Thus the I/O bound database
> > process may still be waiting on I/O, while the Java producer has
> > already consumed its time-slice and is waiting idly in the expired
> > priority array of the run queue. The upshot being the CPU sitting idly
> > while there is work to be done. (Conversely, the Windows scheduler
> > might be smart enough to know that disk I/O is not a sign of
> > interactivity.) This hypothesis seems to be supported by the fact that
> > CPU utilization is much lower on Linux than on Windows, but running
> > the database on a different machine significantly increases CPU
> > utilization (obviously by the Java producer) on Linux and performance
> > becomes about the same as on Windows.
> >
> > A not performance-related observation but belongs here: after
> > seemingly clean tests on dual processor Intel platforms with Windows,
> > Linux and HP-UX, I regularly discover new concurrency-related bugs in
> > my implementation on a single core Opteron with Solaris. And this
> > reinforces my experience so far: the hardware/OS platform counts a
> > lot.
> >
> >
> > On 4/1/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> > > On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> > > ...
> > > > application. I already reported on March 20 that I observed
> > > > significant performance degradation compared to an old implementation
> > > > which makes use exclusively of "primitive" Java language concurrency
> > > > constructs (http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-March/003784.html).
> > >
> > > I am curious whether you have checked the proposal that you have
> > > received for that mail. (Using the combination of semaphores and
> > > ConcurrentLinkedQueue.)
> > >
> > > Anyway, some more details would be very interesting in order to say
> > > anything about your problem. Can you give some hints about the applied
> > > synchronization constructions in your program?
> > >
> > > Best Regards,
> > > Szabolcs
> > >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>

From szabolcs.ferenczi at gmail.com  Sun Apr  1 18:51:47 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 2 Apr 2007 00:51:47 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
Message-ID: <c8955b000704011551i1b1e16f4g7877f41cccdf4ba5@mail.gmail.com>

On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> I haven't tried it, because I got worried about Doug Lea's comment
> that it may be less scalable that LinkedBlockingQueue. I will probably
> try it anyway.

I do not know what he means exactly but the thing is that the
LinkedBlockingQueue is carefully designed and behaves well against
large number of concurrent users. You can implement the same
functionality based on the combination of e.g. ConcurrentLinkedQueue
and semaphores or condition variables. But most probably that will not
be as efficient as the LinkedBlockingQueue. Note that Hanson's
ConcurrentLinkedBlockingQueue performs good as well, in fact, I think,
it performs slightly better than the LinkedBlockingQueue.

> In more concrete terms: you can find the problematic backport-based
> implementation here:
> http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
> . "outputQueue" is the variable where I am using LinkedBlockingQueue.
> And yes, my case falls into the multiple-producer-one-consumer
> category.

Now I can see you are using LinkedBlockingQueue. That is good enough.
The strange thing I can see there in the code is the extra lock
inputProducerLock. Can you explain the role of that lock? It might
serialize producers more than necessary. It is a guess only, and if
you try to explain the role of it, it can turn out whether it is a
good guess or not.

The other strange thing I can see there is that the producer waits
when the queue is full and starts producing the next item only after
the queue has a place. I think the producers could normally create an
item and then try to insert it into the queue.

These are the two issues I can see right now. I hope it helps. I am
not sure these issues can explain the performance differences on the
different platforms, though.

Best Regards,
Szabolcs

From dhanji at gmail.com  Sun Apr  1 19:36:39 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Mon, 2 Apr 2007 09:36:39 +1000
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <c8955b000704011551i1b1e16f4g7877f41cccdf4ba5@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011551i1b1e16f4g7877f41cccdf4ba5@mail.gmail.com>
Message-ID: <aa067ea10704011636r5b11fba5te2556b5a217fa644@mail.gmail.com>

I am curious--what version of windows is the poor performance on? Is the
hardware comparable (SMP, cores, etc., the same as your initial testbed)?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070402/49fba8be/attachment.html 

From szabolcs.ferenczi at gmail.com  Sun Apr  1 20:25:36 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 2 Apr 2007 02:25:36 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
Message-ID: <c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>

On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> In more concrete terms: you can find the problematic backport-based
> implementation here:
> http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
> . "outputQueue" is the variable where I am using LinkedBlockingQueue.
> And yes, my case falls into the multiple-producer-one-consumer
> category.

Now I think I can see your problem. You are using a proper bounded
buffer implementation (LinkedBlockingQueue) but you short-cut or
re-implement the synchronization of it. Try to refactor your program
so that:

- use the synchronized put method of the LinkedBlockingQueue instead of
  the polling offer method

- drop the extra handshake via the lock inputProducerLock

- make the producer create an item first and then call the put method with
  the prepared item

I believe this helps with the performance difference as well.

Best Regards,
Szabolcs

From hanson.char at gmail.com  Mon Apr  2 01:09:54 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Sun, 1 Apr 2007 22:09:54 -0700
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue vs
	LinkedBlockingQueue
Message-ID: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>

> Note that Hanson's
> ConcurrentLinkedBlockingQueue performs good as well, in fact, I think,
> it performs slightly better than the LinkedBlockingQueue.

Based on a recent test on Windows XP Professional with 1 CPU,
ConcurrentLinkedBlockingQueue performs 83% faster than
LinkedBlockingQueue.  Unfortunately I don't have access to a more
powerful box (with multi-processors) to do more testings.

If anyone does and is interested in the comparison, please download
the jar from:

    http://beanlib.sourceforge.net/clbq/070401/q-test.jar

and run (using jdk6 or jdk5):

java -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
-XX:+DisableExplicitGC -jar q-test.jar

Thanks in advance!

(Only if I could gain access to a powerful box with jdk6 installed for
5 minutes!)

Hanson Char

PS:

1) The source jar of the test harness can be downloaded from
http://beanlib.sourceforge.net/clbq/070401/q-test-sources.jar
2) Note the test is based on the SVN revision 168 of
ConcurrentLinkedBlockingQueue.java at
http://svn.sourceforge.net/viewvc/*checkout*/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?revision=168
3) I inadvertently introduced a serious flaw in revision 166.  My apology.

From peter.kovacs.1.0rc at gmail.com  Mon Apr  2 06:32:18 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 2 Apr 2007 12:32:18 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <ca53c8f80704011444s251ae256q22b3d8d2e2c61b17@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<ca53c8f80704011431g58c562e2sb01a3a5f6cbccaf8@mail.gmail.com>
	<ca53c8f80704011444s251ae256q22b3d8d2e2c61b17@mail.gmail.com>
Message-ID: <b6e8f2e80704020332o202b94betf71b73f6d0de1aa6@mail.gmail.com>

Thank you, Hanson, for the clarification! That really makes a
difference. (I didn't realize this part of Doug's comment was based on
a detail [of substance] which has been changed in the mean time.)

I am going to try using ConcurrentLinkedBlockingQueue for sure.

Thanks
Peter

On 4/1/07, Hanson Char <hanson.char at gmail.com> wrote:
> I think Doug's comment's on reduced scalability is when I first
> proposed the use of a semaphore+LinkedBlockingQueue many months ago.
>
> The current version of ConcurrentLinkedBlockingQueue, however, is NOT
> using any semaphore and is in fact totally lock-free.
>
> Cheers,
> Hanson Char
>
> On 4/1/07, Hanson Char <hanson.char at gmail.com> wrote:
> > Hi Peter,
> >
> > > I haven't tried it, because I got worried about Doug Lea's comment
> > > that it may be less scalable that LinkedBlockingQueue. I will probably
> > > try it anyway.
> >
> > I don't think Doug ever commented that the proposed
> > ConcurrentLinkedBlockingQueue is any less scalable than the existing
> > LinkedBlockingQueue.  I would think the opposite is true.
> >
> > Or did I miss out his comment ?
> >
> > Hanson Char
> >
> > On 4/1/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> > > I haven't tried it, because I got worried about Doug Lea's comment
> > > that it may be less scalable that LinkedBlockingQueue. I will probably
> > > try it anyway.
> > >
> > > In more concrete terms: you can find the problematic backport-based
> > > implementation here:
> > > http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
> > > . "outputQueue" is the variable where I am using LinkedBlockingQueue.
> > > And yes, my case falls into the multiple-producer-one-consumer
> > > category.
> > >
> > > I am still interested to know (in more general terms): to what extent
> > > can I abstract away from the OS/hardware platform which my solution is
> > > running on?
> > >
> > > Which one do I have to be more worried about: differences in the
> > > application logic (e.g. single-consumer vs. multiple consumer) or
> > > differences in the hardware/OS platform?
> > >
> > > In fact, this question is more general than j.u.c/backport. My old
> > > database import implementation already takes 50% more time to execute
> > > on Linux than on Windows on the same hardware. (See PS.) Or is it that
> > > the implementation is not "smart enough" to perform equally well on
> > > any platform?
> > >
> > > I've seen in jcpip the results of several performance tests run in
> > > Sun's lab. Has anyone done any tests to compare performance on
> > > different platforms? Java is much about platform independence after
> > > all.
> > >
> > > Any comment appreciated.
> > >
> > > Peter
> > >
> > > PS:
> > > I am having a hard time explaining a significant performance
> > > difference observed between runs of the same Java application on Linux
> > > and on Windows. The application consists of two components: a
> > > concurrent Java producer and a database consumer. The database itself
> > > is about 10% percent slower on Linux than Windows (if the Java
> > > producer is running on another machine). The Java producer routines
> > > perform the same on Windows and on Linux (if the database runs on
> > > another machine). There is a difference of about 40% I cannot explain
> > > when both application components run on the same Linux or Windows
> > > system. My primary suspect currently is the Linux scheduler which
> > > excessively prefers I/O-bound tasks over CPU-bound tasks on serveral
> > > counts: it gives I/O-bound tasks higher dynamic priority and gives
> > > them longer time-slice as well. (The ideology behind this is that
> > > interactive tasks have to be more responsive than non-interactive (ie.
> > > background) tasks. The scheduler considers a process "interactive", if
> > > it is waiting long enough on I/O. There is also some sense of
> > > fairness/compensation behind this policy.) Thus the I/O bound database
> > > process may still be waiting on I/O, while the Java producer has
> > > already consumed its time-slice and is waiting idly in the expired
> > > priority array of the run queue. The upshot being the CPU sitting idly
> > > while there is work to be done. (Conversely, the Windows scheduler
> > > might be smart enough to know that disk I/O is not a sign of
> > > interactivity.) This hypothesis seems to be supported by the fact that
> > > CPU utilization is much lower on Linux than on Windows, but running
> > > the database on a different machine significantly increases CPU
> > > utilization (obviously by the Java producer) on Linux and performance
> > > becomes about the same as on Windows.
> > >
> > > A not performance-related observation but belongs here: after
> > > seemingly clean tests on dual processor Intel platforms with Windows,
> > > Linux and HP-UX, I regularly discover new concurrency-related bugs in
> > > my implementation on a single core Opteron with Solaris. And this
> > > reinforces my experience so far: the hardware/OS platform counts a
> > > lot.
> > >
> > >
> > > On 4/1/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> > > > On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> > > > ...
> > > > > application. I already reported on March 20 that I observed
> > > > > significant performance degradation compared to an old implementation
> > > > > which makes use exclusively of "primitive" Java language concurrency
> > > > > constructs (http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-March/003784.html).
> > > >
> > > > I am curious whether you have checked the proposal that you have
> > > > received for that mail. (Using the combination of semaphores and
> > > > ConcurrentLinkedQueue.)
> > > >
> > > > Anyway, some more details would be very interesting in order to say
> > > > anything about your problem. Can you give some hints about the applied
> > > > synchronization constructions in your program?
> > > >
> > > > Best Regards,
> > > > Szabolcs
> > > >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
>

From peter.kovacs.1.0rc at gmail.com  Mon Apr  2 06:37:23 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 2 Apr 2007 12:37:23 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <aa067ea10704011636r5b11fba5te2556b5a217fa644@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011551i1b1e16f4g7877f41cccdf4ba5@mail.gmail.com>
	<aa067ea10704011636r5b11fba5te2556b5a217fa644@mail.gmail.com>
Message-ID: <b6e8f2e80704020337v5002464y50bc329a96a9ea18@mail.gmail.com>

It's the same physical hardware unit with dual boot. One difference:
Windows is on an ATA hard-drive while Linux is on a SATA disk (both
connected to same integrated controller on the motherboard with two
Xeon (Netburst) 3GHz processors).

Thanks
Peter

On 4/2/07, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
> I am curious--what version of windows is the poor performance on? Is the
> hardware comparable (SMP, cores, etc., the same as your initial testbed)?
>
>

From peter.kovacs.1.0rc at gmail.com  Mon Apr  2 07:57:48 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 2 Apr 2007 13:57:48 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
Message-ID: <b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>

Hi Szabolcs,

I am grateful for your time spent reviewing my code.

The code in InputOrderedWorkUnitProcessor comes with two variants of
putting the WorkUnitData on the outputQueue *for testing purposes*
(they do the same thing in a slightly different way):
getNextInputImmediate uses LinkedBlockingQueue.put while
getNextInputWaitForOuputQueue use LinkedBlockingQueue.offer. (I
"manually" change the "workerWaitsForRoomInOutputQueue" variable and
recompile depending on which variant I am going to test with.)

My original backport-based implementation used the "put" method, but I
observed a performance improvement of about 25% with the "offer"
method on Linux. (I am trying to emulate with the "offer" method the
behaviour of an "old" implementation which uses exlusively primitive
language constructs and which "waits" when the output queue is full
[the outputQueue in that old implementation is our own
implementation]. This "old" implementation performs significantly
better on Linux and much better on Windows.) (I think I also tried the
version with the "put" method yesterday and had the same disappointing
result on Windows.)

The purpose of the InputOrderedWorkUnitProcessor class is to produce
results in the order the corresponding input items (one input item per
result) are found in the input source ("inputProducer"). The intended
purpose of the inputProducerLock is to make sure that retrieval of the
next input item (from "inputProducer" by worker threads) and putting
the corresponding ScheduledWorkDataUnit instance on the "outputQueue"
be atomic. Otherwise the result order maybe different from that of the
input order, like in the following scenario:
(1) Worker "A" takes an input item for result "Y";
(2) worker "B" takes an input item for result "Z";
(3) worker "B" puts the ScheduledWorkDataUnit instance for result "Z"
in the outputQueue;
(4) worker "A" puts the ScheduledWorkDataUnit instance for result "Y"
in the outputQueue.
Result "Z" would then be processed by the consumer before "Y", and the
order of the two results would be swapped.

Do I miss here an alternative mechanism for making sure that order is
kept in the output? (I might try devising some kind of timestamp- or
index-based mechanism, whereby the timestamp/index would be evaluated
by the consumer for keeping the right processing order, but my gut
feeling is that moving the burden of order-keeping from the producer
to the consumer would cause more problems than it would solve. Or
maybe some kind of priority queueing?, if there are any.)

>From this perspective, I am not sure how I could maintain the required
semantics whithout the the equivalent of an inputProducerLock. Please,
let me know, what you think.

Thanks a lot
Peter

On 4/2/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 01/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
>
> > In more concrete terms: you can find the problematic backport-based
> > implementation here:
> > http://www.chemaxon.com/shared/pkovacs/concurrent/processors/InputOrderedWorkUnitProcessor.java
> > . "outputQueue" is the variable where I am using LinkedBlockingQueue.
> > And yes, my case falls into the multiple-producer-one-consumer
> > category.
>
> Now I think I can see your problem. You are using a proper bounded
> buffer implementation (LinkedBlockingQueue) but you short-cut or
> re-implement the synchronization of it. Try to refactor your program
> so that:
>
> - use the synchronized put method of the LinkedBlockingQueue instead of
>   the polling offer method
>
> - drop the extra handshake via the lock inputProducerLock
>
> - make the producer create an item first and then call the put method with
>   the prepared item
>
> I believe this helps with the performance difference as well.
>
> Best Regards,
> Szabolcs
>

From szabolcs.ferenczi at gmail.com  Mon Apr  2 08:11:08 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 2 Apr 2007 14:11:08 +0200
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue vs
	LinkedBlockingQueue
In-Reply-To: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
References: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
Message-ID: <c8955b000704020511q4565f3dak33165e7fbfcd2f8c@mail.gmail.com>

On 02/04/07, Hanson Char <hanson.char at gmail.com> wrote:

> Based on a recent test on Windows XP Professional with 1 CPU,
> ConcurrentLinkedBlockingQueue performs 83% faster than
> LinkedBlockingQueue.  Unfortunately I don't have access to a more
> powerful box (with multi-processors) to do more testings.

Hi Hanson,

I have run your performance test on a dual core XP version. Here is
the summary of the averages:

CLBQ  748+791+752+743+743+730+732+752+737+705=7433
LBQ   1271+1230+1258+1258+1221+1201+1194+1178+1206+1206=12223
LBQ/CLBQ = 0.61

However, as I have indicated earlier, your CLBQ offer/take combination
implements a busy waiting loop with some optimalization. With a simple
busy waiting loop the figures are like this:

CLBQ  776+688+739+688+702+684+675+715+708+715=7090
LBQ   1243+1243+1197+1207+1265+1265+1259+1256+1253+1261=12449
LBQ/CLBQ = 0.57

    public boolean offer(E e) {
        return q.offer(e);
    }
    public E take() throws InterruptedException
    {
        for (;;) {
            E e = q.poll();

            if (e != null)
                return e;
            if (Thread.interrupted())
            {
                throw new InterruptedException();
            }
        }
    }

I have also checked a variant with the standard conditional variable:

CLBQ  3072+2437+1967+1918+2828+1925+1930+1904+1882+1933=21796
LBQ   1261+1298+1196+1215+1212+1182+1185+1210+1198+1197=12154
LBQ/CLBQ = 1.79

    public boolean offer(E e) {
	boolean b;
	synchronized(takeLock) {
	    b = q.offer(e);
	    takeLock.notify();
	}
	return b;
    }
    public E take() throws InterruptedException
    {
	E e;
	synchronized(takeLock) {
	    while (q.isEmpty()) {
		takeLock.wait();
	    }
	    e = q.poll();
	}
	return e;
    }

Finally, I have checked the same performance test with semaphore
scheduling:

With fair semaphore:
CLBQ  3248+2637+2676+2690+2024+2197+2181+2134+2142+2139=24068
LBQ   1185+1256+1169+1201+1210+1159+1151+1162+1170+1172=11835
LBQ/CLBQ = 2.03

With unfair semaphore:
CLBQ  2473+2133+2249+2267+2226+2277+2155+2244+2284+2269=22577
LBQ   1238+1222+1200+1176+1183+1183+1293+1207+1201+1186=12089
LBQ/CLBQ = 1.87

    private final Semaphore availableItems = new Semaphore(0, true);
    public synchronized boolean offer(E e) {
        boolean b = q.offer(e);
	availableItems.release();
	return b;
    }
    public E take() throws InterruptedException
    {
	availableItems.acquire();
	synchronized(this) {
	    E e = q.poll();
	    return e;
	}
    }

My final note is that the N producer 1 consumer performance test is
not a good choice in this case. The reason is that you have added
some synchronization (lock free one) to schedule the consumers. On the
other hand the performance test omits consumer scheduling since the
N consumers make sure that the consumer should not be scheduled at the take
method since there will always be some items in the queue for the consumer.

Best Regards,
Szabolcs

From peter.kovacs.1.0rc at gmail.com  Mon Apr  2 09:02:21 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 2 Apr 2007 15:02:21 +0200
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue vs
	LinkedBlockingQueue
In-Reply-To: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
References: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
Message-ID: <b6e8f2e80704020602v592794cbp128e1fc98614ede4@mail.gmail.com>

Hi,

Dual Xeon, Windows Server 2003:

java version "1.5.0_06"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_06-b05)
Java HotSpot(TM) Client VM (build 1.5.0_06-b05, mixed mode)
-------------------------------
LBQ/CLBQ: 0.798385
-------------------------------

java version "1.6.0_01"
Java(TM) SE Runtime Environment (build 1.6.0_01-b06)
Java HotSpot(TM) Client VM (build 1.6.0_01-b06, mixed mode, sharing)
-------------------------------
LBQ/CLBQ: 1.68951
-------------------------------

Full log files attached.

Should the "-server" switch not have been specified?

Thanks
Peter


On 4/2/07, Hanson Char <hanson.char at gmail.com> wrote:
> > Note that Hanson's
> > ConcurrentLinkedBlockingQueue performs good as well, in fact, I think,
> > it performs slightly better than the LinkedBlockingQueue.
>
> Based on a recent test on Windows XP Professional with 1 CPU,
> ConcurrentLinkedBlockingQueue performs 83% faster than
> LinkedBlockingQueue.  Unfortunately I don't have access to a more
> powerful box (with multi-processors) to do more testings.
>
> If anyone does and is interested in the comparison, please download
> the jar from:
>
>     http://beanlib.sourceforge.net/clbq/070401/q-test.jar
>
> and run (using jdk6 or jdk5):
>
> java -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
> -XX:+DisableExplicitGC -jar q-test.jar
>
> Thanks in advance!
>
> (Only if I could gain access to a powerful box with jdk6 installed for
> 5 minutes!)
>
> Hanson Char
>
> PS:
>
> 1) The source jar of the test harness can be downloaded from
> http://beanlib.sourceforge.net/clbq/070401/q-test-sources.jar
> 2) Note the test is based on the SVN revision 168 of
> ConcurrentLinkedBlockingQueue.java at
> http://svn.sourceforge.net/viewvc/*checkout*/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?revision=168
> 3) I inadvertently introduced a serious flaw in revision 166.  My apology.
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: q-clbq-xeon-java5.log
Type: application/octet-stream
Size: 8999 bytes
Desc: not available
Url : /pipermail/attachments/20070402/104111ab/attachment-0002.obj 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: q-clbq-xeon-java6.log
Type: application/octet-stream
Size: 8955 bytes
Desc: not available
Url : /pipermail/attachments/20070402/104111ab/attachment-0003.obj 

From gregg at cytetech.com  Mon Apr  2 11:14:39 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 02 Apr 2007 10:14:39 -0500
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue vs
	LinkedBlockingQueue
In-Reply-To: <b6e8f2e80704020602v592794cbp128e1fc98614ede4@mail.gmail.com>
References: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
	<b6e8f2e80704020602v592794cbp128e1fc98614ede4@mail.gmail.com>
Message-ID: <46111DDF.1010006@cytetech.com>

One of the key issues with -server vs -client is that the number of method 
entries needed before the JIT will compile code.  -client is 1500 while -server 
is usually like 30000.  You can, of course specify -XX:CompileThreshold=100 or 
some such smaller value to get things compiled faster.  That may, or may not 
actually help show you the performance possibilities depending on the JITs analysis.

Gregg Wonderly

Peter Kovacs wrote:
> Hi,
> 
> Dual Xeon, Windows Server 2003:
> 
> java version "1.5.0_06"
> Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_06-b05)
> Java HotSpot(TM) Client VM (build 1.5.0_06-b05, mixed mode)
> -------------------------------
> LBQ/CLBQ: 0.798385
> -------------------------------
> 
> java version "1.6.0_01"
> Java(TM) SE Runtime Environment (build 1.6.0_01-b06)
> Java HotSpot(TM) Client VM (build 1.6.0_01-b06, mixed mode, sharing)
> -------------------------------
> LBQ/CLBQ: 1.68951
> -------------------------------
> 
> Full log files attached.
> 
> Should the "-server" switch not have been specified?
> 
> Thanks
> Peter
> 
> 
> On 4/2/07, Hanson Char <hanson.char at gmail.com> wrote:
> 
>> > Note that Hanson's
>> > ConcurrentLinkedBlockingQueue performs good as well, in fact, I think,
>> > it performs slightly better than the LinkedBlockingQueue.
>>
>> Based on a recent test on Windows XP Professional with 1 CPU,
>> ConcurrentLinkedBlockingQueue performs 83% faster than
>> LinkedBlockingQueue.  Unfortunately I don't have access to a more
>> powerful box (with multi-processors) to do more testings.
>>
>> If anyone does and is interested in the comparison, please download
>> the jar from:
>>
>>     http://beanlib.sourceforge.net/clbq/070401/q-test.jar
>>
>> and run (using jdk6 or jdk5):
>>
>> java -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
>> -XX:+DisableExplicitGC -jar q-test.jar
>>
>> Thanks in advance!
>>
>> (Only if I could gain access to a powerful box with jdk6 installed for
>> 5 minutes!)
>>
>> Hanson Char
>>
>> PS:
>>
>> 1) The source jar of the test harness can be downloaded from
>> http://beanlib.sourceforge.net/clbq/070401/q-test-sources.jar
>> 2) Note the test is based on the SVN revision 168 of
>> ConcurrentLinkedBlockingQueue.java at
>> http://svn.sourceforge.net/viewvc/*checkout*/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?revision=168 
>>
>> 3) I inadvertently introduced a serious flaw in revision 166.  My 
>> apology.
>>
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From szabolcs.ferenczi at gmail.com  Mon Apr  2 16:49:09 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 2 Apr 2007 22:49:09 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
Message-ID: <c8955b000704021349l7b96c140g5027d3ee747f5c21@mail.gmail.com>

On 02/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> getNextInputImmediate uses LinkedBlockingQueue.put while

We are talking about this fragment:

        synchronized (inputProducerLock) {
            if (inputProducer.hasNext()) {
                input = inputProducer.getNext();
            }
            scheduledWorkUnitData = new ScheduledWorkUnitData(input);
            outputQueue.put(scheduledWorkUnitData);
        }

Basically it is ok that you use the put method on the LBQ which
provides you with the long term scheduling of the threads. However,
you wrap it into a higher level critical section using the extra lock
inputProducerLock. Due to the inner put method, a worker thread might
stay for indefinitely long time in the inner critical section. Consequently,
the other threads might be hanged on the lock inputProducerLock
waiting for entrance into the upper critical region. Critical sections
are intended for short term scheduling and in this case threads are
waiting for entrance for a long time. (You mention this situation in
your 19 March message.)

Threads waiting to enter the critical section for a long time might
unnecessarily consume processing power depending how the waiting is
implemented. Usually it is implemented by some spin lock. That means
threads are scheduled with the assumption that they will gain access
to the resource shortly. Waiting to enter into a critical section for
a long time might be the cause for the performance loss. There might
be significant differences between the different platforms.

On top of all that, you mention (in your 19 March message) that the
consumer cannot keep up with the producers. That means that as soon as
the buffer gets full, the work is necessarily serialized and the
consumer determines the speed of the processing. The producer-consumer
pattern is a solution for the case when the speed of producing the
pieces of data and the speed of processing them are varying.

Best Regards,
Szabolcs

From hanson.char at gmail.com  Mon Apr  2 22:13:55 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 2 Apr 2007 19:13:55 -0700
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue vs
	LinkedBlockingQueue
In-Reply-To: <b6e8f2e80704020602v592794cbp128e1fc98614ede4@mail.gmail.com>
References: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
	<b6e8f2e80704020602v592794cbp128e1fc98614ede4@mail.gmail.com>
Message-ID: <ca53c8f80704021913l4363a88oa79296ce829ef9d9@mail.gmail.com>

Hi Peter,

> Should the "-server" switch not have been specified?

You are right.  The "-server" switch should be specified.  Or at least
that's what I originally intended.  Good catch.

Hanson


On 4/2/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> Hi,
>
> Dual Xeon, Windows Server 2003:
>
> java version "1.5.0_06"
> Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_06-b05)
> Java HotSpot(TM) Client VM (build 1.5.0_06-b05, mixed mode)
> -------------------------------
> LBQ/CLBQ: 0.798385
> -------------------------------
>
> java version "1.6.0_01"
> Java(TM) SE Runtime Environment (build 1.6.0_01-b06)
> Java HotSpot(TM) Client VM (build 1.6.0_01-b06, mixed mode, sharing)
> -------------------------------
> LBQ/CLBQ: 1.68951
> -------------------------------
>
> Full log files attached.
>
> Should the "-server" switch not have been specified?
>
> Thanks
> Peter
>
>
> On 4/2/07, Hanson Char <hanson.char at gmail.com> wrote:
> > > Note that Hanson's
> > > ConcurrentLinkedBlockingQueue performs good as well, in fact, I think,
> > > it performs slightly better than the LinkedBlockingQueue.
> >
> > Based on a recent test on Windows XP Professional with 1 CPU,
> > ConcurrentLinkedBlockingQueue performs 83% faster than
> > LinkedBlockingQueue.  Unfortunately I don't have access to a more
> > powerful box (with multi-processors) to do more testings.
> >
> > If anyone does and is interested in the comparison, please download
> > the jar from:
> >
> >     http://beanlib.sourceforge.net/clbq/070401/q-test.jar
> >
> > and run (using jdk6 or jdk5):
> >
> > java -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
> > -XX:+DisableExplicitGC -jar q-test.jar
> >
> > Thanks in advance!
> >
> > (Only if I could gain access to a powerful box with jdk6 installed for
> > 5 minutes!)
> >
> > Hanson Char
> >
> > PS:
> >
> > 1) The source jar of the test harness can be downloaded from
> > http://beanlib.sourceforge.net/clbq/070401/q-test-sources.jar
> > 2) Note the test is based on the SVN revision 168 of
> > ConcurrentLinkedBlockingQueue.java at
> > http://svn.sourceforge.net/viewvc/*checkout*/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?revision=168
> > 3) I inadvertently introduced a serious flaw in revision 166.  My apology.
> >
>
>

From peter.kovacs.1.0rc at gmail.com  Tue Apr  3 02:44:46 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 3 Apr 2007 08:44:46 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <c8955b000704021349l7b96c140g5027d3ee747f5c21@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704021349l7b96c140g5027d3ee747f5c21@mail.gmail.com>
Message-ID: <b6e8f2e80704022344k1a5f5d41g9bdeb3b4f4fa8c46@mail.gmail.com>

Thank you, Szabolcs, for your comments!

I basically agree with your observations -- except, perhaps, for the
last paragraph. The fact that multiple (two) producers cannot keep up
with a single producer doesn't mean that there is no room for
concurrent processing. Creating the result takes at least 30% more
time than consuming it, so there is room for concurrency not only
between the consumer and the producer, but also between consumers.

I think you made a good point by observing that high CPU utilization
may stem from threads spin-locking on busy resources. But the fact is
that I observe a very low CPU utilization (50-55% on a two-way Windows
system) and that is what prompts me to talk about "serial execution"
(apart from the comparatively very long execution time). Note that I
observe the same problem on Windows (with Java 5) in the other branch,
where "offer" is used on LBQ and the workers failing the "offer" go
into wait. Whereas an implementation using similar logic, but using
directly synchronization primitives and wait/notify-s, completes twice
as fast. That is where my question comes from about j.u.c/backport
performance on Windows.

Looking at the test results in another thread on this list with CLBQ,
I start to suspect that my application may produce significantly
different performance with Java 6 than with Java 5.

Thanks
Peter

On 4/2/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 02/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
>
> > getNextInputImmediate uses LinkedBlockingQueue.put while
>
> We are talking about this fragment:
>
>         synchronized (inputProducerLock) {
>             if (inputProducer.hasNext()) {
>                 input = inputProducer.getNext();
>             }
>             scheduledWorkUnitData = new ScheduledWorkUnitData(input);
>             outputQueue.put(scheduledWorkUnitData);
>         }
>
> Basically it is ok that you use the put method on the LBQ which
> provides you with the long term scheduling of the threads. However,
> you wrap it into a higher level critical section using the extra lock
> inputProducerLock. Due to the inner put method, a worker thread might
> stay for indefinitely long time in the inner critical section. Consequently,
> the other threads might be hanged on the lock inputProducerLock
> waiting for entrance into the upper critical region. Critical sections
> are intended for short term scheduling and in this case threads are
> waiting for entrance for a long time. (You mention this situation in
> your 19 March message.)
>
> Threads waiting to enter the critical section for a long time might
> unnecessarily consume processing power depending how the waiting is
> implemented. Usually it is implemented by some spin lock. That means
> threads are scheduled with the assumption that they will gain access
> to the resource shortly. Waiting to enter into a critical section for
> a long time might be the cause for the performance loss. There might
> be significant differences between the different platforms.
>
> On top of all that, you mention (in your 19 March message) that the
> consumer cannot keep up with the producers. That means that as soon as
> the buffer gets full, the work is necessarily serialized and the
> consumer determines the speed of the processing. The producer-consumer
> pattern is a solution for the case when the speed of producing the
> pieces of data and the speed of processing them are varying.
>
> Best Regards,
> Szabolcs
>

From szabolcs.ferenczi at gmail.com  Tue Apr  3 03:01:14 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 3 Apr 2007 09:01:14 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
Message-ID: <c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>

On 02/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> From this perspective, I am not sure how I could maintain the required
> semantics whithout the the equivalent of an inputProducerLock. Please,
> let me know, what you think.

What is the semantics you refer to?

This is how it looks like to me until now. In this arrangement you
define one consumer that is consuming from a single FIFO
"outputQueue". The FIFO is filled by N producers called
workers. Workers fetch items from a collection with help of a shared
iterator "inputProducer". Workers do nothing else but wrap the fetched
items into work units and push them into the FIFO queue.

The semantics you are trying to maintain is that the order of items
referred to by the iterator "inputProducer" must be the same as the
order of the corresponding work units in the FIFO "outputQueue". You
can easily maintain it by applying one single worker that takes items
with help of the iterator "inputProducer", wraps them into work units,
and pushes them into the FIFO "outputQueue". It looks like there is no
need for many workers of this kind. Hence, the semantics is maintained.

I might miss something from the story. How are the items in the
collection created? I mean the collection which is traversed by the
workers with help of the shared iterator. I guess that is the real
producer action and not what the workers do. Am I right in that? If
yes, the real producers should put their results into the FIFO right
away and the "semantics problem" is gone. Does this help?

Best Regards,
Szabolcs

From peter.kovacs.1.0rc at gmail.com  Tue Apr  3 03:19:02 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 3 Apr 2007 09:19:02 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
Message-ID: <b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>

The producers take their input from a file. They do a significant
amount of processing (build a model of a chemical compound from a
string representation into a Java objects, process the Java objects
and calculate a number of chemical properties of the molecule).
Producing the input for the consumer typically takes at least 30-35%
longer (but often much longer) than the consumer takes processing it.

Admittedly, the room for concurrency is not huge, but is still
significant in two-way systems.

Thanks
Peter

On 4/3/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 02/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
>
> > From this perspective, I am not sure how I could maintain the required
> > semantics whithout the the equivalent of an inputProducerLock. Please,
> > let me know, what you think.
>
> What is the semantics you refer to?
>
> This is how it looks like to me until now. In this arrangement you
> define one consumer that is consuming from a single FIFO
> "outputQueue". The FIFO is filled by N producers called
> workers. Workers fetch items from a collection with help of a shared
> iterator "inputProducer". Workers do nothing else but wrap the fetched
> items into work units and push them into the FIFO queue.
>
> The semantics you are trying to maintain is that the order of items
> referred to by the iterator "inputProducer" must be the same as the
> order of the corresponding work units in the FIFO "outputQueue". You
> can easily maintain it by applying one single worker that takes items
> with help of the iterator "inputProducer", wraps them into work units,
> and pushes them into the FIFO "outputQueue". It looks like there is no
> need for many workers of this kind. Hence, the semantics is maintained.
>
> I might miss something from the story. How are the items in the
> collection created? I mean the collection which is traversed by the
> workers with help of the shared iterator. I guess that is the real
> producer action and not what the workers do. Am I right in that? If
> yes, the real producers should put their results into the FIFO right
> away and the "semantics problem" is gone. Does this help?
>
> Best Regards,
> Szabolcs
>

From gregg at cytetech.com  Wed Apr  4 10:16:04 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 04 Apr 2007 09:16:04 -0500
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
	<b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
Message-ID: <4613B324.10605@cytetech.com>



Peter Kovacs wrote:
> The producers take their input from a file. They do a significant
> amount of processing (build a model of a chemical compound from a
> string representation into a Java objects, process the Java objects
> and calculate a number of chemical properties of the molecule).
> Producing the input for the consumer typically takes at least 30-35%
> longer (but often much longer) than the consumer takes processing it.
> 
> Admittedly, the room for concurrency is not huge, but is still
> significant in two-way systems.

Should you enqueue a Future for the object into the queue, and then let the 
consumer 'get' the value from there so that it is waiting for exactly the next 
value only?

Gregg Wonderly

From peter.kovacs.1.0rc at gmail.com  Tue Apr  3 09:41:35 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 3 Apr 2007 15:41:35 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <4613B324.10605@cytetech.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
	<b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
	<4613B324.10605@cytetech.com>
Message-ID: <b6e8f2e80704030641y104fe0f6gf7257c900b4dfab1@mail.gmail.com>

Yes, this is basically what I am doing. Only I use a "custom" class
for holding the result
(http://www.chemaxon.com/shared/pkovacs/concurrent/processors/ScheduledWorkUnitData.java)
instead of implementing the stock Future interface.

Thanks
Peter

On 4/4/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Peter Kovacs wrote:
> > The producers take their input from a file. They do a significant
> > amount of processing (build a model of a chemical compound from a
> > string representation into a Java objects, process the Java objects
> > and calculate a number of chemical properties of the molecule).
> > Producing the input for the consumer typically takes at least 30-35%
> > longer (but often much longer) than the consumer takes processing it.
> >
> > Admittedly, the room for concurrency is not huge, but is still
> > significant in two-way systems.
>
> Should you enqueue a Future for the object into the queue, and then let the
> consumer 'get' the value from there so that it is waiting for exactly the next
> value only?
>
> Gregg Wonderly
>

From gregg at cytetech.com  Wed Apr  4 11:34:07 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 04 Apr 2007 10:34:07 -0500
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704030641y104fe0f6gf7257c900b4dfab1@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
	<b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
	<4613B324.10605@cytetech.com>
	<b6e8f2e80704030641y104fe0f6gf7257c900b4dfab1@mail.gmail.com>
Message-ID: <4613C56F.6040704@cytetech.com>



Peter Kovacs wrote:
> Yes, this is basically what I am doing. Only I use a "custom" class
> for holding the result
> (http://www.chemaxon.com/shared/pkovacs/concurrent/processors/ScheduledWorkUnitData.java)
> instead of implementing the stock Future interface.

So it would seem that there probably are some OS related 'priority' and 
'scheduling' thing that might be changing the perceived performance.  Do you 
have a profiler to run the application with?  This might tell you a lot more 
about where the 'latency' is at.

Gregg Wonderly

From peter.kovacs.1.0rc at gmail.com  Tue Apr  3 11:17:15 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 3 Apr 2007 17:17:15 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <4613C56F.6040704@cytetech.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
	<b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
	<4613B324.10605@cytetech.com>
	<b6e8f2e80704030641y104fe0f6gf7257c900b4dfab1@mail.gmail.com>
	<4613C56F.6040704@cytetech.com>
Message-ID: <b6e8f2e80704030817u484b25edj17405c2d47991fb5@mail.gmail.com>

On 4/4/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Peter Kovacs wrote:
> > Yes, this is basically what I am doing. Only I use a "custom" class
> > for holding the result
> > (http://www.chemaxon.com/shared/pkovacs/concurrent/processors/ScheduledWorkUnitData.java)
> > instead of implementing the stock Future interface.
>
> So it would seem that there probably are some OS related 'priority' and
> 'scheduling' thing that might be changing the perceived performance.  Do you
> have a profiler to run the application with?  This might tell you a lot more
> about where the 'latency' is at.

Yes, I think the hour is slowly aproaching where I cannot get around
using a profiler. My company has a JProfiler license. Do you think it
will do the job? Do you know a better one? (I've been thinking about
looking at the NetBeans profiler [I do not know how it is called],
because it is free...)

Thanks
Peter

>
> Gregg Wonderly
>

From gregg at cytetech.com  Tue Apr  3 12:41:10 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 03 Apr 2007 11:41:10 -0500
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704030817u484b25edj17405c2d47991fb5@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
	<b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
	<4613B324.10605@cytetech.com>
	<b6e8f2e80704030641y104fe0f6gf7257c900b4dfab1@mail.gmail.com>
	<4613C56F.6040704@cytetech.com>
	<b6e8f2e80704030817u484b25edj17405c2d47991fb5@mail.gmail.com>
Message-ID: <461283A6.4040105@cytetech.com>



Peter Kovacs wrote:
> On 4/4/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>> Peter Kovacs wrote:
>> > Yes, this is basically what I am doing. Only I use a "custom" class
>> > for holding the result
>> > 
>> (http://www.chemaxon.com/shared/pkovacs/concurrent/processors/ScheduledWorkUnitData.java) 
>>
>> > instead of implementing the stock Future interface.
>>
>> So it would seem that there probably are some OS related 'priority' and
>> 'scheduling' thing that might be changing the perceived performance.  
>> Do you
>> have a profiler to run the application with?  This might tell you a 
>> lot more
>> about where the 'latency' is at.
> 
> 
> Yes, I think the hour is slowly aproaching where I cannot get around
> using a profiler. My company has a JProfiler license. Do you think it
> will do the job? Do you know a better one? (I've been thinking about
> looking at the NetBeans profiler [I do not know how it is called],
> because it is free...)

Well, I've become fond of the YourKit Java profiler because it can be started in 
the JVM, and turned on remotely for casual observation from time to time.  When 
you take a snapshot, it is transfered over the network to your computer, but 
also stored on the remote machine for later access.  So, if you request the 
snapshot and the transfer fails, you can go to that machine and FTP the snapshot 
off, for example.

It really has a number of nice features related to remote, periodic performance 
monitoring.

Gregg Wonderly

From joe.bowbeer at gmail.com  Tue Apr  3 13:34:28 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 3 Apr 2007 10:34:28 -0700
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704030817u484b25edj17405c2d47991fb5@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704030001y1f7cfdaep8e8b38fb93501989@mail.gmail.com>
	<b6e8f2e80704030019v6b950595nbfcb33b94027d2f7@mail.gmail.com>
	<4613B324.10605@cytetech.com>
	<b6e8f2e80704030641y104fe0f6gf7257c900b4dfab1@mail.gmail.com>
	<4613C56F.6040704@cytetech.com>
	<b6e8f2e80704030817u484b25edj17405c2d47991fb5@mail.gmail.com>
Message-ID: <31f2a7bd0704031034o7453f004n1fe942828a7b8116@mail.gmail.com>

The NetBeans Profiler, as it is called, is worth checking out.

On 4/3/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
>
>
> (I've been thinking about looking at the NetBeans profiler because it is
> free...)
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070403/05e3be7c/attachment.html 

From szabolcs.ferenczi at gmail.com  Tue Apr  3 15:33:17 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 3 Apr 2007 21:33:17 +0200
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue vs
	LinkedBlockingQueue
In-Reply-To: <ca53c8f80704021928s176280efv89e1429f3f6d197a@mail.gmail.com>
References: <ca53c8f80704012209g29b82ce1gc829c3d09bfbbf84@mail.gmail.com>
	<c8955b000704020511q4565f3dak33165e7fbfcd2f8c@mail.gmail.com>
	<ca53c8f80704021928s176280efv89e1429f3f6d197a@mail.gmail.com>
Message-ID: <c8955b000704031233j6ff2f2d7sfd21d0833040b495@mail.gmail.com>

Hi Hanson,

Here are the results on my dual core XP Home when the -server switch
is specified:

CLBQ  669+666+673+301+300+299+309+309+584+575=4685
LBQ   790+784+630+564+583+551+550+848+691+806=6797
0.69

WITH BUSY LOOP
CLBQ  657+666+677+632+651+649+649+654+662+647=6544
LBQ   942+846+842+810+825+948+943+949+942+981=9028
0.72

WITH SEMAPHORE UNFAIR
CLBQ  1184+1225+1188+1199+1197+1205+1210+1207+1188+1186=11989
LBQ   813+820+896+929+932+943+922+967+909+902=9033
1.33

WITH SEMAPHORE FAIR
CLBQ  1034+1051+1031+1107+1105+1110+946+1044+1086+1058=10572
LBQ   847+988+1039+933+1017+580+842+860+790+818=8714
1.21

WITH CONDITIONAL VARIABLE
CLBQ  1053+1006+1064+1023+1002+1041+1012+1030+1013+1023=10267
LBQ   880+932+1061+1044+1049+1066+1107+1052+1054+1056=10301
0.996

I hope this helps.

Best Regards,
Szabolcs

On 03/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> Thanks Szablocs.  Would you mind running it once more with the
> "-server" switch on ?
>
> java -server -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
> -XX:+DisableExplicitGC -jar q-test.jar
>
> Hanson
>
> On 4/2/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> > On 02/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> >
> > > Based on a recent test on Windows XP Professional with 1 CPU,
> > > ConcurrentLinkedBlockingQueue performs 83% faster than
> > > LinkedBlockingQueue.  Unfortunately I don't have access to a more
> > > powerful box (with multi-processors) to do more testings.
> >
> > Hi Hanson,
> >
> > I have run your performance test on a dual core XP version. Here is
> > the summary of the averages:
> >
> > CLBQ  748+791+752+743+743+730+732+752+737+705=7433
> > LBQ   1271+1230+1258+1258+1221+1201+1194+1178+1206+1206=12223
> > LBQ/CLBQ = 0.61
> >
> > However, as I have indicated earlier, your CLBQ offer/take combination
> > implements a busy waiting loop with some optimalization. With a simple
> > busy waiting loop the figures are like this:
> >
> > CLBQ  776+688+739+688+702+684+675+715+708+715=7090
> > LBQ   1243+1243+1197+1207+1265+1265+1259+1256+1253+1261=12449
> > LBQ/CLBQ = 0.57
> >
> >     public boolean offer(E e) {
> >         return q.offer(e);
> >     }
> >     public E take() throws InterruptedException
> >     {
> >         for (;;) {
> >             E e = q.poll();
> >
> >             if (e != null)
> >                 return e;
> >             if (Thread.interrupted())
> >             {
> >                 throw new InterruptedException();
> >             }
> >         }
> >     }
> >
> > I have also checked a variant with the standard conditional variable:
> >
> > CLBQ  3072+2437+1967+1918+2828+1925+1930+1904+1882+1933=21796
> > LBQ   1261+1298+1196+1215+1212+1182+1185+1210+1198+1197=12154
> > LBQ/CLBQ = 1.79
> >
> >     public boolean offer(E e) {
> >         boolean b;
> >         synchronized(takeLock) {
> >             b = q.offer(e);
> >             takeLock.notify();
> >         }
> >         return b;
> >     }
> >     public E take() throws InterruptedException
> >     {
> >         E e;
> >         synchronized(takeLock) {
> >             while (q.isEmpty()) {
> >                 takeLock.wait();
> >             }
> >             e = q.poll();
> >         }
> >         return e;
> >     }
> >
> > Finally, I have checked the same performance test with semaphore
> > scheduling:
> >
> > With fair semaphore:
> > CLBQ  3248+2637+2676+2690+2024+2197+2181+2134+2142+2139=24068
> > LBQ   1185+1256+1169+1201+1210+1159+1151+1162+1170+1172=11835
> > LBQ/CLBQ = 2.03
> >
> > With unfair semaphore:
> > CLBQ  2473+2133+2249+2267+2226+2277+2155+2244+2284+2269=22577
> > LBQ   1238+1222+1200+1176+1183+1183+1293+1207+1201+1186=12089
> > LBQ/CLBQ = 1.87
> >
> >     private final Semaphore availableItems = new Semaphore(0, true);
> >     public synchronized boolean offer(E e) {
> >         boolean b = q.offer(e);
> >         availableItems.release();
> >         return b;
> >     }
> >     public E take() throws InterruptedException
> >     {
> >         availableItems.acquire();
> >         synchronized(this) {
> >             E e = q.poll();
> >             return e;
> >         }
> >     }
> >
> > My final note is that the N producer 1 consumer performance test is
> > not a good choice in this case. The reason is that you have added
> > some synchronization (lock free one) to schedule the consumers. On the
> > other hand the performance test omits consumer scheduling since the
> > N consumers make sure that the consumer should not be scheduled at the take
> > method since there will always be some items in the queue for the consumer.
> >
> > Best Regards,
> > Szabolcs
> >
>

From llluomo at gmail.com  Tue Apr  3 18:07:14 2007
From: llluomo at gmail.com (=?ISO-8859-1?Q?Jo=E3o_Rui_Cunha?=)
Date: Tue, 3 Apr 2007 23:07:14 +0100
Subject: [concurrency-interest] (no subject)
Message-ID: <2F2E9BBC-65F0-42F6-8321-66B6FC28B6B2@gmail.com>

I?m a university student that is trying to implement a barrier using  
annotations and AspectJ.
The goal is to, given a threadGroup name in an annotation and the  
number of threads to wait,  use a cyclic barrier or latch to   
synchronize them. Is that possible? I mean forcing a cyclic barrier  
to only synchronize threads that belongs to a particular thread group  
and not stopping others?

Thanks in advanced



From llluomo at gmail.com  Tue Apr  3 18:09:27 2007
From: llluomo at gmail.com (=?ISO-8859-1?Q?Jo=E3o_Rui_Cunha?=)
Date: Tue, 3 Apr 2007 23:09:27 +0100
Subject: [concurrency-interest] How to implement CyclicBarriers that wait by
	Groups of threads
Message-ID: <081201CA-D369-4BEB-B067-3BEF7E9FEFD9@gmail.com>

I?m a university student that is trying to implement a barrier using  
annotations and AspectJ.
The goal is to, given a threadGroup name in an annotation and the  
number of threads to wait,  use a cyclic barrier or latch to   
synchronize them. Is that possible? I mean forcing a cyclic barrier  
to only synchronize threads that belongs to a particular thread group  
and not stopping others?

Thanks in advanced

From dcholmes at optusnet.com.au  Tue Apr  3 18:29:26 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 4 Apr 2007 08:29:26 +1000
Subject: [concurrency-interest] (no subject)
In-Reply-To: <2F2E9BBC-65F0-42F6-8321-66B6FC28B6B2@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEBFHGAA.dcholmes@optusnet.com.au>

Just make the call to the barrier/latch conditional on the ThreadGroup of
the current thread.

And please give emails a subject!

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jo?o Rui
> Cunha
> Sent: Wednesday, 4 April 2007 8:07 AM
> To: concurrency-interest
> Subject: [concurrency-interest] (no subject)
>
>
> I?m a university student that is trying to implement a barrier using
> annotations and AspectJ.
> The goal is to, given a threadGroup name in an annotation and the
> number of threads to wait,  use a cyclic barrier or latch to
> synchronize them. Is that possible? I mean forcing a cyclic barrier
> to only synchronize threads that belongs to a particular thread group
> and not stopping others?
>
> Thanks in advanced
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From hanson.char at gmail.com  Tue Apr  3 21:30:50 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 3 Apr 2007 18:30:50 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704030941x4a24c3b6k57376d634c5c227e@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
Message-ID: <ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>

Hi Trustin,

Actually I think you are right.  According to Jcip, the optimal thread
pool size should be

    NumberOfCpu * TargetCpuUtilization * (1 + W/C)

where W/C is the ratio of wait time to compute time.  Currently W/C is
set to zero and TargetCpuUtilization is set to 1 in the q-test.jar.
However, since the compute time is near zero, the number of threads
for the optimal pool size should be much larger.

I'll add a configurable system property such that the W/C can be
specified for running the test, and see how it goes.

Thanks for pointing this out.

Hanson Char

ps: Hope you don't mind I cc this to the concurrency forum.

On 4/3/07, Hanson Char <hanson.char at gmail.com> wrote:
> Hi Trustin,
>
> The tests suite checks the number of processors available and add 1 to
> it for the number of threads for the producers.  This is the
> recommended approach in Jcip which I just follow.
>
> The test result I've collected so far vary widely depending on whether
> there are real processors vs hyper-threading, and Windows vs Linux,
> and jdk5 vs jdk6.
>
> Hanson
>
> On 4/3/07, Trustin Lee <trustin at gmail.com> wrote:
> > Hi,
> >
> > On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
> > > Thanks, Trustin.  In this result, LBQ is 5% faster than CLBQ.
> > >
> > > Is it running jdk1.6.0 ?  Is the "-server" switch on ?  Is it a linux os ?
> >
> > I used JDK 1.6.0 with the switches you suggested.  I guess 5 threads
> > are not enough to get advantage of CLBQ.
> >
> > Trustin
> > --
> > what we call human nature is actually human habit
> > --
> > http://gleamynode.net/
> > --
> > PGP Key ID: 0x0255ECA6
> >
>

From hanson.char at gmail.com  Wed Apr  4 03:10:50 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 00:10:50 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704030941x4a24c3b6k57376d634c5c227e@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
Message-ID: <ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>

Hi,

I've enhanced the test suite such that:

   - the number of concurrent producers can be specified via the system
   property "numProducer", which defaults to 10
   - multiple concurrent consumers is now supported via the system
   property "numConsumer", which defaults to 1
   - the W/C ratio (ie wait-time to compute-time) can be specified via
   the system property "wcRatio", which defaults to 0

For example, to run the test with 10 producers, 3 consumers, and a W/C ratio
of 5:

java -DnumConsumer=3 -DnumProducer=10 -DwcRatio=5 -server
-XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode -XX:+DisableExplicitGC -jar
q-test.jar

Note an interesting observation is that Windows XP Professional is really
slow on LBQ even when there is only 1 producer and 1 consumer.

Downloads:

    http://beanlib.sourceforge.net/clbq/070403/q-test.jar
    http://beanlib.sourceforge.net/clbq/070403/q-test-sources.jar

Hanson Char

On 4/3/07, Trustin Lee <trustin at gmail.com> wrote:
> On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
> > Hi Trustin,
> >
> > Actually I think you are right.  According to Jcip, the optimal thread
> > pool size should be
> >
> >     NumberOfCpu * TargetCpuUtilization * (1 + W/C)
> >
> > where W/C is the ratio of wait time to compute time.  Currently W/C is
> > set to zero and TargetCpuUtilization is set to 1 in the q-test.jar.
> > However, since the compute time is near zero, the number of threads
> > for the optimal pool size should be much larger.
> >
> > I'll add a configurable system property such that the W/C can be
> > specified for running the test, and see how it goes.
> >
> > Thanks for pointing this out.
> >
> > Hanson Char
> >
> > ps: Hope you don't mind I cc this to the concurrency forum.
>
> Of course not.  Please cc me.
>
> Trustin
> --
> what we call human nature is actually human habit
> --
> http://gleamynode.net/
> --
> PGP Key ID: 0x0255ECA6
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/196b4120/attachment-0001.html 

From szabolcs.ferenczi at gmail.com  Wed Apr  4 06:22:54 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 4 Apr 2007 12:22:54 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
Message-ID: <c8955b000704040322j3754d6f6pb480373f2a5a2fa@mail.gmail.com>

On 02/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> From this perspective, I am not sure how I could maintain the required
> semantics whithout the the equivalent of an inputProducerLock. Please,
> let me know, what you think.

I think there are other means as well to establish the semantics you
want. Just for curiosity, I am going to show some other solutions, not
by Java language means, however, but rather by concurrency patterns.

So, your constraint is that the order of items in the beginning should
be the same as the order of the corresponding work packages at the
end.

Now, as far as the processes are concerned, you have N producers
(workers) and one single consumer. Additionally, you have a container
for the items (`I'), and an intermediate queue (`Q'). I would
visualize it like this (please set non-proportional characters to view
it properly):

                      |<---/W1/--->|
|WP|<---/C/--->|Q|<---|<---/W2/--->|--->|I|
                      |<---/W3/--->|

Some hint for the notation: `/P/' denotes a process, `|D|' denotes a
data structure, and `--->' denotes access. Here your problem is that
you have to use a critical region in the workers to ensure the same
order in the data structures `I' and `Q'. The critical region is also
needed for accessing the shared data structure `I' by the concurrent
workers `Wn' via an iterator.

One possible other solution is if you change the arrangement so that
the workers form a pipeline themselves like this:

|WP|<---/C/--->|Q|<---/W3/<--->/W2/<--->/W1/--->|I|

Here, the activity of the workers can be described as follows: Each
worker obtains an element from the right hand side. Workers must know
their position in the pipeline. Each worker forwards as many elements
without processing as many workers are sitting behind it in the
pipeline, and then it processes the next unprocessed element and
forwards it to the left. If the element from the right hand side is
processed already, it simply forwards it to the left. I hope this
works and maintains your constraint.

Another way the same ordering can be maintained between the input and
the output containers is where the worker pool is mediated by a master
process. The master is the one that takes elements from the right
(`I'), assigns a work package to one of the idle workers and forwards
the processed packages to the queue (`Q') in the same order. Workers
can be arranged by the Chain of Responsibility pattern.

|WP|<---/C/--->|Q|<---/M/--->|I|
                       |
                 --------------
                 /W1/ /W2/ /W3/

These solutions I could come up with. What do you think about them?
Perhaps changing the pattern is not an option to you, I just made this
comment to show that some concurrency problems can be avoided by
selecting the appropriate pattern for a given constraint.

Best Regards,
Szabolcs

From peter.kovacs.1.0rc at gmail.com  Wed Apr  4 07:20:51 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Wed, 4 Apr 2007 13:20:51 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704022344k1a5f5d41g9bdeb3b4f4fa8c46@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704021349l7b96c140g5027d3ee747f5c21@mail.gmail.com>
	<b6e8f2e80704022344k1a5f5d41g9bdeb3b4f4fa8c46@mail.gmail.com>
Message-ID: <b6e8f2e80704040420q3cafc8d3jec34a47f2db82203@mail.gmail.com>

It've noticed that in my starter script I forgot to specify the
-server switch. With -server, everything looks much more in line with
my expectations.

(I am not sure if it was a good decision to make -client the default.
This is the hundredth time that I ran into this kind of trouble.)

Thanks
Peter

On 4/3/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> Thank you, Szabolcs, for your comments!
>
> I basically agree with your observations -- except, perhaps, for the
> last paragraph. The fact that multiple (two) producers cannot keep up
> with a single producer doesn't mean that there is no room for
> concurrent processing. Creating the result takes at least 30% more
> time than consuming it, so there is room for concurrency not only
> between the consumer and the producer, but also between consumers.
>
> I think you made a good point by observing that high CPU utilization
> may stem from threads spin-locking on busy resources. But the fact is
> that I observe a very low CPU utilization (50-55% on a two-way Windows
> system) and that is what prompts me to talk about "serial execution"
> (apart from the comparatively very long execution time). Note that I
> observe the same problem on Windows (with Java 5) in the other branch,
> where "offer" is used on LBQ and the workers failing the "offer" go
> into wait. Whereas an implementation using similar logic, but using
> directly synchronization primitives and wait/notify-s, completes twice
> as fast. That is where my question comes from about j.u.c/backport
> performance on Windows.
>
> Looking at the test results in another thread on this list with CLBQ,
> I start to suspect that my application may produce significantly
> different performance with Java 6 than with Java 5.
>
> Thanks
> Peter
>
> On 4/2/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> > On 02/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> >
> > > getNextInputImmediate uses LinkedBlockingQueue.put while
> >
> > We are talking about this fragment:
> >
> >         synchronized (inputProducerLock) {
> >             if (inputProducer.hasNext()) {
> >                 input = inputProducer.getNext();
> >             }
> >             scheduledWorkUnitData = new ScheduledWorkUnitData(input);
> >             outputQueue.put(scheduledWorkUnitData);
> >         }
> >
> > Basically it is ok that you use the put method on the LBQ which
> > provides you with the long term scheduling of the threads. However,
> > you wrap it into a higher level critical section using the extra lock
> > inputProducerLock. Due to the inner put method, a worker thread might
> > stay for indefinitely long time in the inner critical section. Consequently,
> > the other threads might be hanged on the lock inputProducerLock
> > waiting for entrance into the upper critical region. Critical sections
> > are intended for short term scheduling and in this case threads are
> > waiting for entrance for a long time. (You mention this situation in
> > your 19 March message.)
> >
> > Threads waiting to enter the critical section for a long time might
> > unnecessarily consume processing power depending how the waiting is
> > implemented. Usually it is implemented by some spin lock. That means
> > threads are scheduled with the assumption that they will gain access
> > to the resource shortly. Waiting to enter into a critical section for
> > a long time might be the cause for the performance loss. There might
> > be significant differences between the different platforms.
> >
> > On top of all that, you mention (in your 19 March message) that the
> > consumer cannot keep up with the producers. That means that as soon as
> > the buffer gets full, the work is necessarily serialized and the
> > consumer determines the speed of the processing. The producer-consumer
> > pattern is a solution for the case when the speed of producing the
> > pieces of data and the speed of processing them are varying.
> >
> > Best Regards,
> > Szabolcs
> >
>

From szabolcs.ferenczi at gmail.com  Wed Apr  4 12:03:02 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 4 Apr 2007 18:03:02 +0200
Subject: [concurrency-interest] j.u.c/backport performance on Windows
In-Reply-To: <b6e8f2e80704040420q3cafc8d3jec34a47f2db82203@mail.gmail.com>
References: <b6e8f2e80704010616o4490ed17iaef6b9e1fe1801d3@mail.gmail.com>
	<c8955b000704010812l7f477550v9f0a227750365cd2@mail.gmail.com>
	<b6e8f2e80704011400u5b17b2fbgff39b20d7dada6ce@mail.gmail.com>
	<c8955b000704011725s6819a272ya5eb73dd41444b36@mail.gmail.com>
	<b6e8f2e80704020457w2d968517g67a1a28f24b93842@mail.gmail.com>
	<c8955b000704021349l7b96c140g5027d3ee747f5c21@mail.gmail.com>
	<b6e8f2e80704022344k1a5f5d41g9bdeb3b4f4fa8c46@mail.gmail.com>
	<b6e8f2e80704040420q3cafc8d3jec34a47f2db82203@mail.gmail.com>
Message-ID: <c8955b000704040903l7ca78b74u73686bccb27eed86@mail.gmail.com>

On 04/04/07, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> It've noticed that in my starter script I forgot to specify the
> -server switch. With -server, everything looks much more in line with
> my expectations.

It is a pity. I would have had some more ideas.
Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr  4 14:25:17 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 11:25:17 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704030941x4a24c3b6k57376d634c5c227e@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
Message-ID: <ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>

Hi,

I've further enhanced ConcurrentLinkedBlokcingQueue such that it implements
the BlockingQueue interface.  In other words, CLBQ can now be used as a
drop-in replacement for LBQ.  See:


http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

Other interesting things:

1) I realised the jdk implementation of

    ExecutorService newFixedThreadPool(int nThreads);

internally uses a LBQ for the thread pool.

To be fair (or pure?), I've updated the test suite such that the thread pool
for testing CLBQ is also a CLBQ, whereas the thread pool for testing LBQ is
a LBQ.

2) From http://dior.ics.muni.cz/~makub//java/speed.html, it seems the
-XXCompileThreshold should be set to 1500 for optimal server performance.
Like so:

    java -DnumConsumer=3 -DnumProducer=10 -DwcRatio=5 -server
-XX:CompileThreshold=1500 -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
-XX:+DisableExplicitGC -jar q-test.jar

Downloads:

    http://beanlib.sourceforge.net/clbq/070404/q-test.jar
    http://beanlib.sourceforge.net/clbq/070404/q-test-sources.jar

Cheers,
Hanson Char

On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> Hi,
>
> I've enhanced the test suite such that:
>
>    - the number of concurrent producers can be specified via the system
>    property "numProducer", which defaults to 10
>    - multiple concurrent consumers is now supported via the system
>    property "numConsumer", which defaults to 1
>    - the W/C ratio (ie wait-time to compute-time) can be specified via
>    the system property "wcRatio", which defaults to 0
>
> For example, to run the test with 10 producers, 3 consumers, and a W/C
> ratio of 5:
>
> java -DnumConsumer=3 -DnumProducer=10 -DwcRatio=5 -server
> -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode -XX:+DisableExplicitGC -jar
> q-test.jar
>
> Note an interesting observation is that Windows XP Professional is really
> slow on LBQ even when there is only 1 producer and 1 consumer.
>
> Downloads:
>
>     http://beanlib.sourceforge.net/clbq/070403/q-test.jar
>      http://beanlib.sourceforge.net/clbq/070403/q-test-sources.jar
>
> Hanson Char
>
> On 4/3/07, Trustin Lee <trustin at gmail.com> wrote:
> > On 4/4/07, Hanson Char < hanson.char at gmail.com> wrote:
> > > Hi Trustin,
> > >
> > > Actually I think you are right.  According to Jcip, the optimal thread
> > > pool size should be
> > >
> > >     NumberOfCpu * TargetCpuUtilization * (1 + W/C)
> > >
> > > where W/C is the ratio of wait time to compute time.  Currently W/C is
> > > set to zero and TargetCpuUtilization is set to 1 in the q-test.jar.
> > > However, since the compute time is near zero, the number of threads
> > > for the optimal pool size should be much larger.
> > >
> > > I'll add a configurable system property such that the W/C can be
> > > specified for running the test, and see how it goes.
> > >
> > > Thanks for pointing this out.
> > >
> > > Hanson Char
> > >
> > > ps: Hope you don't mind I cc this to the concurrency forum.
> >
> > Of course not.  Please cc me.
> >
> > Trustin
> > --
> > what we call human nature is actually human habit
> > --
> > http://gleamynode.net/
> > --
> > PGP Key ID: 0x0255ECA6
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/82e510b5/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Apr  4 15:14:58 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 4 Apr 2007 21:14:58 +0200
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704030941x4a24c3b6k57376d634c5c227e@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
Message-ID: <c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>

On 04/04/07, Hanson Char <hanson.char at gmail.com> wrote:

> I've further enhanced ConcurrentLinkedBlokcingQueue such that it implements
> the BlockingQueue interface.  In other words, CLBQ can now be used as a
> drop-in replacement for LBQ.  See:
>
>
> http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

Hi Hanson,

You claim that CLBQ implements the BlockingQueue interface. But the
put method is not implemented with the semantics as defined in the
BlockingQueue interface. Thus, CLBQ cannot be the drop-in replacement
for LBQ. Do I miss something?

I am really curious how you can implement the blocking put method
along the same principles you used for the offer method.

Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr  4 16:15:12 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 13:15:12 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704030941x4a24c3b6k57376d634c5c227e@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
Message-ID: <ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>

Hi Szablocs,

the put method is not implemented with the semantics as defined in the
> BlockingQueue interface.


Why not ?  Can you please elaborate ?

Hanson Char
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/a585844c/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Apr  4 17:23:23 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 4 Apr 2007 23:23:23 +0200
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704030941x4a24c3b6k57376d634c5c227e@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
	<ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
Message-ID: <c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>

On 04/04/07, Hanson Char <hanson.char at gmail.com> wrote:

> > the put method is not implemented with the semantics as defined in the
> > BlockingQueue interface.
>
> Why not ?  Can you please elaborate ?

The description of the put for the BlockingQueue interface says:
"Inserts the specified element into this queue, waiting if necessary
for space to become available." In the CLBQ implementation, however,
the put is implemented by a forwarded call to the add method of the
ConcurrentLinkedQueue member. The add is a non-blocking method, it
"Inserts the specified element at the tail of this queue." and returns
a boolean. Thus, no waiting is there behind the add method which is
required for the put method whenever the queue is at the limit of its
capacity. Does this help?

Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr  4 17:44:45 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 14:44:45 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<768dcb2e0704031618p33385e19h95ed32962cfbf6de@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
	<ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
	<c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>
Message-ID: <ca53c8f80704041444m7ecd4775wbd579aa821ebbd4c@mail.gmail.com>

Hi Szabolcs,

The put method in CLBQ, being unbounded, will always succeed "immediately"
without waiting.  But waiting with zero time doesn't mean it does not
satisfy the contract of the BlockingQueue put method, as the happen-before
relationship is still satisfied by the current implementation.

Or am I missing something here ?

Hanson Char

On 4/4/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> On 04/04/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> > > the put method is not implemented with the semantics as defined in the
> > > BlockingQueue interface.
> >
> > Why not ?  Can you please elaborate ?
>
> The description of the put for the BlockingQueue interface says:
> "Inserts the specified element into this queue, waiting if necessary
> for space to become available." In the CLBQ implementation, however,
> the put is implemented by a forwarded call to the add method of the
> ConcurrentLinkedQueue member. The add is a non-blocking method, it
> "Inserts the specified element at the tail of this queue." and returns
> a boolean. Thus, no waiting is there behind the add method which is
> required for the put method whenever the queue is at the limit of its
> capacity. Does this help?
>
> Best Regards,
> Szabolcs
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/e77770b8/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Apr  4 18:11:10 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Thu, 5 Apr 2007 00:11:10 +0200
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704041444m7ecd4775wbd579aa821ebbd4c@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704031733o2eea7574gc1190321821eba23@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
	<ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
	<c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>
	<ca53c8f80704041444m7ecd4775wbd579aa821ebbd4c@mail.gmail.com>
Message-ID: <c8955b000704041511m603f0a84y7a41d0a3b92808aa@mail.gmail.com>

On 04/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> The put method in CLBQ, being unbounded, will always succeed "immediately"
> without waiting.  But waiting with zero time doesn't mean it does not
> satisfy the contract of the BlockingQueue put method, as the happen-before
> relationship is still satisfied by the current implementation.
>
> Or am I missing something here ?

Hi Hanson,

I think you miss that the semantics of put in the interface
BlockingQueue says that it waits if necessary for space to become
available. It is not the same as method add which does not wait but
returns a boolean.

On the other hand, you claim that your CLBQ can replace LBQ. Now LBQ
is bounded. By default, the capacity is Integer.MAX_VALUE. This means
that on an LBQ the put waits when the queue has already
Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
if you forward the put to an instance of a ConcurrentLinkedQueue as an
add call. Do you agree?

Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr  4 18:25:50 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 15:25:50 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <c8955b000704041511m603f0a84y7a41d0a3b92808aa@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704031830o32242a5bn62157c66339dd42e@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
	<ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
	<c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>
	<ca53c8f80704041444m7ecd4775wbd579aa821ebbd4c@mail.gmail.com>
	<c8955b000704041511m603f0a84y7a41d0a3b92808aa@mail.gmail.com>
Message-ID: <ca53c8f80704041525kc88d75ai2354d2cae13389ee@mail.gmail.com>

Hi Szabolcs,

>it waits if necessary for space to become available.

In this case it's not necessary and therefore there is no need to wait.  The
condition is still satisfied, isn't it ?  (The statement "if A then B" is
always trivially true if the condition A is false.)

>This means that on an LBQ the put waits when the queue has already
>Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
>if you forward the put to an instance of a ConcurrentLinkedQueue as an
>add call.

True, they are not the same in the sense that when the number of elements in
the queue reached Integer.MAX_VALUE.

So I guess technically CLBQ is not a drop-in replacement for LBQ, since CLBQ
would allow one to continue inserting to the queue and there is always no
need to wait, whereas LBQ would block if the the number of queue items
reached Integer.MAX_VALUE.

In practice, however, I doubt if there is any application that would rely on
this peculiar behavior of LBQ to remain correct.

So CLBQ is not but can be used as a replacement for LBQ in most cases,
unless your application correctness relies on the queue to block upon the
number of elements reaching Integer.MAX_VALUE.

Hanson Char

On 4/4/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> On 04/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> > The put method in CLBQ, being unbounded, will always succeed
> "immediately"
> > without waiting.  But waiting with zero time doesn't mean it does not
> > satisfy the contract of the BlockingQueue put method, as the
> happen-before
> > relationship is still satisfied by the current implementation.
> >
> > Or am I missing something here ?
>
> Hi Hanson,
>
> I think you miss that the semantics of put in the interface
> BlockingQueue says that it waits if necessary for space to become
> available. It is not the same as method add which does not wait but
> returns a boolean.
>
> On the other hand, you claim that your CLBQ can replace LBQ. Now LBQ
> is bounded. By default, the capacity is Integer.MAX_VALUE. This means
> that on an LBQ the put waits when the queue has already
> Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
> if you forward the put to an instance of a ConcurrentLinkedQueue as an
> add call. Do you agree?
>
> Best Regards,
> Szabolcs
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/e373442b/attachment.html 

From hanson.char at gmail.com  Wed Apr  4 18:33:02 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 15:33:02 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704041525kc88d75ai2354d2cae13389ee@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<768dcb2e0704031838x786a5bbfk646ad57319cdadf3@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
	<ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
	<c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>
	<ca53c8f80704041444m7ecd4775wbd579aa821ebbd4c@mail.gmail.com>
	<c8955b000704041511m603f0a84y7a41d0a3b92808aa@mail.gmail.com>
	<ca53c8f80704041525kc88d75ai2354d2cae13389ee@mail.gmail.com>
Message-ID: <ca53c8f80704041533o5f2f066bhef7ac7062f9a8e5d@mail.gmail.com>

And of course CLBQ cannot be a drop-in replacement for LBQ in the case when
a fixed "capacity" is specified.

Alright, so they are just different implementation of BlockingQueue.

Hanson Char

On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> Hi Szabolcs,
>
> >it waits if necessary for space to become available.
>
> In this case it's not necessary and therefore there is no need to wait.
> The condition is still satisfied, isn't it ?  (The statement "if A then B"
> is always trivially true if the condition A is false.)
>
> >This means that on an LBQ the put waits when the queue has already
> >Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
> >if you forward the put to an instance of a ConcurrentLinkedQueue as an
> >add call.
>
> True, they are not the same in the sense that when the number of elements
> in the queue reached Integer.MAX_VALUE.
>
> So I guess technically CLBQ is not a drop-in replacement for LBQ, since
> CLBQ would allow one to continue inserting to the queue and there is always
> no need to wait, whereas LBQ would block if the the number of queue items
> reached Integer.MAX_VALUE.
>
> In practice, however, I doubt if there is any application that would rely
> on this peculiar behavior of LBQ to remain correct.
>
> So CLBQ is not but can be used as a replacement for LBQ in most cases,
> unless your application correctness relies on the queue to block upon the
> number of elements reaching Integer.MAX_VALUE.
>
> Hanson Char
>
> On 4/4/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> >
> > On 04/04/07, Hanson Char <hanson.char at gmail.com > wrote:
> > > The put method in CLBQ, being unbounded, will always succeed
> > "immediately"
> > > without waiting.  But waiting with zero time doesn't mean it does not
> > > satisfy the contract of the BlockingQueue put method, as the
> > happen-before
> > > relationship is still satisfied by the current implementation.
> > >
> > > Or am I missing something here ?
> >
> > Hi Hanson,
> >
> > I think you miss that the semantics of put in the interface
> > BlockingQueue says that it waits if necessary for space to become
> > available. It is not the same as method add which does not wait but
> > returns a boolean.
> >
> > On the other hand, you claim that your CLBQ can replace LBQ. Now LBQ
> > is bounded. By default, the capacity is Integer.MAX_VALUE . This means
> > that on an LBQ the put waits when the queue has already
> > Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
> > if you forward the put to an instance of a ConcurrentLinkedQueue as an
> > add call. Do you agree?
> >
> > Best Regards,
> > Szabolcs
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/68f1347a/attachment.html 

From hanson.char at gmail.com  Wed Apr  4 23:55:28 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 4 Apr 2007 20:55:28 -0700
Subject: [concurrency-interest] LBQ vs CLBQ
In-Reply-To: <ca53c8f80704041533o5f2f066bhef7ac7062f9a8e5d@mail.gmail.com>
References: <768dcb2e0704030040g324fc459s8bf5a617b259edd@mail.gmail.com>
	<ca53c8f80704040010u27ba9518xafcb0c8e469270c@mail.gmail.com>
	<ca53c8f80704041125m2637a0abo8730b8e30dd8dfa3@mail.gmail.com>
	<c8955b000704041214l4db84178ya088304b7f9120a3@mail.gmail.com>
	<ca53c8f80704041315j577bae8bmf596256f57929713@mail.gmail.com>
	<c8955b000704041423g6f102504m90bc354faab13d20@mail.gmail.com>
	<ca53c8f80704041444m7ecd4775wbd579aa821ebbd4c@mail.gmail.com>
	<c8955b000704041511m603f0a84y7a41d0a3b92808aa@mail.gmail.com>
	<ca53c8f80704041525kc88d75ai2354d2cae13389ee@mail.gmail.com>
	<ca53c8f80704041533o5f2f066bhef7ac7062f9a8e5d@mail.gmail.com>
Message-ID: <ca53c8f80704042055t262008c5i1abcca96c81924f4@mail.gmail.com>

Hmm...on 2nd thought, it wouldn't be too hard to support a capacity based
concurrent (ie lock free) blocking queue.  Let me think a bit more.

Stay tuned :)

Hanson Char

On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> And of course CLBQ cannot be a drop-in replacement for LBQ in the case
> when a fixed "capacity" is specified.
>
> Alright, so they are just different implementation of BlockingQueue.
>
> Hanson Char
>
> On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
> >
> > Hi Szabolcs,
> >
> > >it waits if necessary for space to become available.
> >
> > In this case it's not necessary and therefore there is no need to wait.
> > The condition is still satisfied, isn't it ?  (The statement "if A then B"
> > is always trivially true if the condition A is false.)
> >
> > >This means that on an LBQ the put waits when the queue has already
> > >Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
> > >if you forward the put to an instance of a ConcurrentLinkedQueue as an
> > >add call.
> >
> > True, they are not the same in the sense that when the number of
> > elements in the queue reached Integer.MAX_VALUE.
> >
> > So I guess technically CLBQ is not a drop-in replacement for LBQ, since
> > CLBQ would allow one to continue inserting to the queue and there is always
> > no need to wait, whereas LBQ would block if the the number of queue items
> > reached Integer.MAX_VALUE.
> >
> > In practice, however, I doubt if there is any application that would
> > rely on this peculiar behavior of LBQ to remain correct.
> >
> > So CLBQ is not but can be used as a replacement for LBQ in most cases,
> > unless your application correctness relies on the queue to block upon the
> > number of elements reaching Integer.MAX_VALUE.
> >
> > Hanson Char
> >
> > On 4/4/07, Szabolcs Ferenczi < szabolcs.ferenczi at gmail.com> wrote:
> > >
> > > On 04/04/07, Hanson Char < hanson.char at gmail.com > wrote:
> > > > The put method in CLBQ, being unbounded, will always succeed
> > > "immediately"
> > > > without waiting.  But waiting with zero time doesn't mean it does
> > > not
> > > > satisfy the contract of the BlockingQueue put method, as the
> > > happen-before
> > > > relationship is still satisfied by the current implementation.
> > > >
> > > > Or am I missing something here ?
> > >
> > > Hi Hanson,
> > >
> > > I think you miss that the semantics of put in the interface
> > > BlockingQueue says that it waits if necessary for space to become
> > > available. It is not the same as method add which does not wait but
> > > returns a boolean.
> > >
> > > On the other hand, you claim that your CLBQ can replace LBQ. Now LBQ
> > > is bounded. By default, the capacity is Integer.MAX_VALUE . This means
> > > that on an LBQ the put waits when the queue has already
> > > Integer.MAX_VALUE number of elements. It is not the same for your CLBQ
> > > if you forward the put to an instance of a ConcurrentLinkedQueue as an
> > > add call. Do you agree?
> > >
> > > Best Regards,
> > > Szabolcs
> > >
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070404/2c8062ac/attachment.html 

From jseigh_cp00 at xemaps.com  Thu Apr  5 06:40:33 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Thu, 05 Apr 2007 06:40:33 -0400
Subject: [concurrency-interest] fast semaphore
Message-ID: <4614D221.9070307@xemaps.com>

Here's the fast pathed semaphore I used with ConcurrentLinkedQueue.
It only does acquires and releases of single permits though it would be
easy to make it release multiple permits.  Acquiring multiple permits would
be a little tricky based on the current Semaphore semantics (atomic acquire
of all requested permits).

It's a port from a C win32/posix version that's been around for a while.

-
Joe Seigh
-


import java.util.concurrent.*;
import java.util.concurrent.atomic.*;

public class FastSemaphore {
   
    AtomicInteger     count;        // semaphore count
    AtomicInteger    cancel;        // deferred cancelation count
    Semaphore        sem;        // slow semaphore

    public FastSemaphore(int z, boolean fair) {
        count = new AtomicInteger(z);
        cancel = new AtomicInteger(0);
        sem = new Semaphore(0, fair);
    }
   
    /*
     * processCancels - add cancelCount to current count
     *
     *   increment count by min(cancelCount, -(count)) iff count < 0
     */
    void processCancels(int cancelCount) {
        int    oldCount;
        int newCount;
       
        if (cancelCount > 0) {
            while ((oldCount = count.get()) < 0) {
                if ((newCount = oldCount + cancelCount) > 0)
                    newCount = 0;
               
                if (count.compareAndSet(oldCount, newCount)) {
                    cancelCount -= (newCount - oldCount);        // 
update cancelCount           
                    break;
                }               
            }
        }
       
        // add any untransferred cancelCount back into cancel
        if (cancelCount > 0) {
            cancel.addAndGet(cancelCount);
        }       
    }
   
    public void acquire()
    throws InterruptedException
    {
        if (count.addAndGet(-1) < 0) {
            try {
                sem.acquire();
            }
           
            catch (InterruptedException e) {
                // uncomment one and only one of the following 2 statements
                cancel.incrementAndGet();
                // processCancels(1);
                throw e;
            }
        }
    }
   
    public boolean tryAcquire(long timeout, TimeUnit unit)
    throws InterruptedException
    {
        boolean rc;
        if (count.addAndGet(-1) < 0) {
            try {
                rc = sem.tryAcquire(timeout, unit);               
            }
           
            catch (InterruptedException e) {
                // uncomment one and only one of the following 2 statements
                cancel.incrementAndGet();
                // processCancels(1);
                throw e;
            }
           
            if (rc == false) {
                cancel.incrementAndGet();               
                // processCancels(1);
            }
            return rc;
        }
       
        else
            return true;
    }
   
    public boolean tryAcquire() {
        int    oldCount;
       
        do {
            oldCount = count.get();
        }
        while (oldCount > 0 && !count.compareAndSet(oldCount, (oldCount 
- 1)));
       
        return (oldCount > 0);
       
    }
   
    public void release() {
        if (cancel.get() > 0 && count.get() < 0) {
            processCancels(cancel.getAndSet(0));
        }
       
        if (count.addAndGet(1) <= 0) {
            sem.release();
        }
    }
   
}

/*-*/



From gregg at cytetech.com  Thu Apr  5 10:47:32 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 05 Apr 2007 09:47:32 -0500
Subject: [concurrency-interest] fast semaphore
In-Reply-To: <4614D221.9070307@xemaps.com>
References: <4614D221.9070307@xemaps.com>
Message-ID: <46150C04.5050304@cytetech.com>



Joseph Seigh wrote:

>     public boolean tryAcquire() {
>         int    oldCount;
>        
>         do {
>             oldCount = count.get();
>         }
>         while (oldCount > 0 && !count.compareAndSet(oldCount, (oldCount - 1)));
>    
>         return (oldCount > 0);

Shouldn't this be oldCount >= 0 so that the aquire when oldCount == 1 works?

>     }

Gregg Wonderly


From hanson.char at gmail.com  Thu Apr  5 13:25:07 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 5 Apr 2007 10:25:07 -0700
Subject: [concurrency-interest] ConcurrentLinkedBoundedBlockingQueue
Message-ID: <ca53c8f80704051025w6ebcf021xd750754c3ea5ec53@mail.gmail.com>

This is the first draft of a bounded concurrent blocking queue:


http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBoundedBlockingQueue.java?view=markup

which is extended from CLBQ:


http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

Similar to LinkedBlockingQueue, one can specify a capacity.   Unlike LBQ,
CLBBQ is entirely locked free.

Note this is only the 1st draft, but it basically illustrates how the same
technique of CLBQ can be used, almost mechanically :)

Cheers,
Hanson Char

On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> Hmm...on 2nd thought, it wouldn't be too hard to support a capacity based
> concurrent (ie lock free) blocking queue.  Let me think a bit more.
>
> Stay tuned :)
>
> Hanson Char
>
> On 4/4/07, Hanson Char <hanson.char at gmail.com> wrote:
> >
> > And of course CLBQ cannot be a drop-in replacement for LBQ in the case
> > when a fixed "capacity" is specified.
> >
> > Alright, so they are just different implementation of BlockingQueue.
> >
> > Hanson Char
> >
> > On 4/4/07, Hanson Char <hanson.char at gmail.com > wrote:
> > >
> > > Hi Szabolcs,
> > >
> > > >it waits if necessary for space to become available.
> > >
> > > In this case it's not necessary and therefore there is no need to
> > > wait.  The condition is still satisfied, isn't it ?  (The statement "if A
> > > then B" is always trivially true if the condition A is false.)
> > >
> > > >This means that on an LBQ the put waits when the queue has already
> > > >Integer.MAX_VALUE number of elements. It is not the same for your
> > > CLBQ
> > > >if you forward the put to an instance of a ConcurrentLinkedQueue as
> > > an
> > > >add call.
> > >
> > > True, they are not the same in the sense that when the number of
> > > elements in the queue reached Integer.MAX_VALUE.
> > >
> > > So I guess technically CLBQ is not a drop-in replacement for LBQ,
> > > since CLBQ would allow one to continue inserting to the queue and there is
> > > always no need to wait, whereas LBQ would block if the the number of queue
> > > items reached Integer.MAX_VALUE.
> > >
> > > In practice, however, I doubt if there is any application that would
> > > rely on this peculiar behavior of LBQ to remain correct.
> > >
> > > So CLBQ is not but can be used as a replacement for LBQ in most cases,
> > > unless your application correctness relies on the queue to block upon the
> > > number of elements reaching Integer.MAX_VALUE.
> > >
> > > Hanson Char
> > >
> > > On 4/4/07, Szabolcs Ferenczi < szabolcs.ferenczi at gmail.com> wrote:
> > > >
> > > > On 04/04/07, Hanson Char < hanson.char at gmail.com > wrote:
> > > > > The put method in CLBQ, being unbounded, will always succeed
> > > > "immediately"
> > > > > without waiting.  But waiting with zero time doesn't mean it does
> > > > not
> > > > > satisfy the contract of the BlockingQueue put method, as the
> > > > happen-before
> > > > > relationship is still satisfied by the current implementation.
> > > > >
> > > > > Or am I missing something here ?
> > > >
> > > > Hi Hanson,
> > > >
> > > > I think you miss that the semantics of put in the interface
> > > > BlockingQueue says that it waits if necessary for space to become
> > > > available. It is not the same as method add which does not wait but
> > > > returns a boolean.
> > > >
> > > > On the other hand, you claim that your CLBQ can replace LBQ. Now LBQ
> > > > is bounded. By default, the capacity is Integer.MAX_VALUE . This
> > > > means
> > > > that on an LBQ the put waits when the queue has already
> > > > Integer.MAX_VALUE number of elements. It is not the same for your
> > > > CLBQ
> > > > if you forward the put to an instance of a ConcurrentLinkedQueue as
> > > > an
> > > > add call. Do you agree?
> > > >
> > > > Best Regards,
> > > > Szabolcs
> > > >
> > >
> > >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070405/9ead057c/attachment.html 

From egordienko at yahoo.com  Thu Apr  5 16:57:16 2007
From: egordienko at yahoo.com (Eugene Gordienko)
Date: Thu, 5 Apr 2007 13:57:16 -0700 (PDT)
Subject: [concurrency-interest] Test suite to compare Sun vs IBM jre for
	multithreaded applications.
Message-ID: <326462.83202.qm@web33411.mail.mud.yahoo.com>

Hi All,
 
We are porting embedded multithreaded java (developed in 1.4 SE and 5 SE environments) applications Linux x86 to Linux PowerPC.
 
Looks like IBM's jvm is slower.
 
Any recommendations for standard jvm tests?
 
Especially we are interested in tests of I/O performance.
 
Many thanks,
Eugene


 
____________________________________________________________________________________
Food fight? Enjoy some healthy debate 
in the Yahoo! Answers Food & Drink Q&A.
http://answers.yahoo.com/dir/?link=list&sid=396545367

From kielstra at ca.ibm.com  Thu Apr  5 18:41:20 2007
From: kielstra at ca.ibm.com (Allan Kielstra)
Date: Thu, 5 Apr 2007 18:41:20 -0400
Subject: [concurrency-interest] Test suite to compare Sun vs IBM jre
	for	multithreaded applications.
In-Reply-To: <326462.83202.qm@web33411.mail.mud.yahoo.com>
Message-ID: <OF480FFFF8.EE8014F0-ON852572B4.007C5A3B-852572B4.007CA132@ca.ibm.com>

Would you be willing to share some version of any part of your code?

I'm guessing you didn't compare the two VMs on Linux/PPC?  Where and how 
did you do the comparison test?

Allan Kielstra
IBM Canada Lab
Phone: +1 (905) 413-3558 T/L 969-3558
kielstra at ca.ibm.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070405/acdaa376/attachment.html 

From brian at quiotix.com  Fri Apr  6 00:02:35 2007
From: brian at quiotix.com (Brian Goetz)
Date: Fri, 06 Apr 2007 00:02:35 -0400
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
Message-ID: <4615C65B.2000608@quiotix.com>

Bill Pugh, Cliff Click, and myself are doing a talk at JavaOne on 
Testing Concurrent Code.

I've attached a (commentable) PDF of the slides.  We'd love it if anyone 
had feedback, which you can send in text, or use Acrobat Reader to apply 
comments directly to the PDF.  (I think you can even save a .fdf file 
from Reader, which just saves the comments and which we can merge back 
into the PDF.)

If you're going to comment, please do so by Monday -- as we're already 
weeks late getting our slides in!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: TestingConcurrentCode_JavaOne2007.pdf
Type: application/pdf
Size: 610100 bytes
Desc: not available
Url : /pipermail/attachments/20070406/eed9c4d6/attachment-0001.pdf 

From David.Biesack at sas.com  Fri Apr  6 08:15:54 2007
From: David.Biesack at sas.com (David J. Biesack)
Date: Fri, 6 Apr 2007 08:15:54 -0400 (EDT)
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
Message-ID: <200704061215.l36CFs9s001725@cs.oswego.edu>


Brian;

Somewhere along the line the attachment was removed:

> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: TestingConcurrentCode_JavaOne2007.pdf
> Type: application/pdf
> Size: 610100 bytes
> Desc: not available
> Url : /pipermail/attachments/20070406/eed9c4d6/attachment.pdf 
> 
> ------------------------------

(see also http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2007-April/003871.html)

Can you post it somewhere for download?

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From elihusmails at gmail.com  Fri Apr  6 10:18:43 2007
From: elihusmails at gmail.com (Mark Webb)
Date: Fri, 6 Apr 2007 10:18:43 -0400
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <4615C65B.2000608@quiotix.com>
References: <4615C65B.2000608@quiotix.com>
Message-ID: <9f066ee90704060718h21d7cdfev6ab3ad2c180341b9@mail.gmail.com>

On slide 34, what is the JVM switch that you are talking about?

In general, I really like the presentation.  My only suggestion would be to
provide some more information for people maybe not as familiar with
concurrency issues.  Such as the JVM switch I mention on page 34, and maybe
some URL for tools like FindBugs and TestNG.  Simple google searches will
give you this information, but placing that information on the slides, to
me, seems appropriate.

Thank you.


On 4/6/07, Brian Goetz <brian at quiotix.com> wrote:
>
> Bill Pugh, Cliff Click, and myself are doing a talk at JavaOne on
> Testing Concurrent Code.
>
> I've attached a (commentable) PDF of the slides.  We'd love it if anyone
> had feedback, which you can send in text, or use Acrobat Reader to apply
> comments directly to the PDF.  (I think you can even save a .fdf file
> from Reader, which just saves the comments and which we can merge back
> into the PDF.)
>
> If you're going to comment, please do so by Monday -- as we're already
> weeks late getting our slides in!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>


-- 
..Cheers
Mark
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070406/defe63df/attachment.html 

From szabolcs.ferenczi at gmail.com  Fri Apr  6 10:27:56 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 6 Apr 2007 16:27:56 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <4615C65B.2000608@quiotix.com>
References: <4615C65B.2000608@quiotix.com>
Message-ID: <c8955b000704060727u488ec7ecndfeb66d1ad2d7b79@mail.gmail.com>

On 06/04/07, Brian Goetz <brian at quiotix.com> wrote:
> I've attached a (commentable) PDF of the slides.  We'd love it if anyone
> had feedback,

Hi Brian,

I am interested in TDD for multi-threaded designs. I am just trying to
come up with something similar to the MTC you use in the slides.
Unfortunately I did not know about MTC so far. I would like to check
whether it provides the functionality I am planning for TDD-ing
multi-threaded software. Is it public domain add on for JUnit? How can
I obtain it?

Best Regards,
Szabolcs

From brian at quiotix.com  Fri Apr  6 11:48:43 2007
From: brian at quiotix.com (Brian Goetz)
Date: Fri, 06 Apr 2007 11:48:43 -0400
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
 JavaOne talk
In-Reply-To: <9f066ee90704060718h21d7cdfev6ab3ad2c180341b9@mail.gmail.com>
References: <4615C65B.2000608@quiotix.com>
	<9f066ee90704060718h21d7cdfev6ab3ad2c180341b9@mail.gmail.com>
Message-ID: <46166BDB.5030703@quiotix.com>

That's a switch that is specific to the Azul VM -- not part of other 
VMs, sorry!

Mark Webb wrote:
> On slide 34, what is the JVM switch that you are talking about?
> 
> In general, I really like the presentation.  My only suggestion would be 
> to provide some more information for people maybe not as familiar with 
> concurrency issues.  Such as the JVM switch I mention on page 34, and 
> maybe some URL for tools like FindBugs and TestNG.  Simple google 
> searches will give you this information, but placing that information on 
> the slides, to me, seems appropriate.
> 
> Thank you.
> 
> 
> On 4/6/07, *Brian Goetz* <brian at quiotix.com <mailto:brian at quiotix.com>> 
> wrote:
> 
>     Bill Pugh, Cliff Click, and myself are doing a talk at JavaOne on
>     Testing Concurrent Code.
> 
>     I've attached a (commentable) PDF of the slides.  We'd love it if anyone
>     had feedback, which you can send in text, or use Acrobat Reader to
>     apply
>     comments directly to the PDF.  (I think you can even save a .fdf file
>     from Reader, which just saves the comments and which we can merge back
>     into the PDF.)
> 
>     If you're going to comment, please do so by Monday -- as we're already
>     weeks late getting our slides in!
> 
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at altair.cs.oswego.edu
>     <mailto:Concurrency-interest at altair.cs.oswego.edu>
>     http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> 
> 
> -- 
> ..Cheers
> Mark
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From oliver at zeigermann.de  Fri Apr  6 12:35:14 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 6 Apr 2007 18:35:14 +0200
Subject: [concurrency-interest] Deadlock detection
Message-ID: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>

Folks!

I plan to write some code for deadlock detection for Java programming
using the concurrent package introduced in Java 1.5.

The code is intended for a new version of

http://jakarta.apache.org/commons/transaction/

and there to replace the old code which is described in

http://jakarta.apache.org/commons/transaction/locks/deadlock.html

I doubt that the idea and code described there are especially good and
would be pleased if anyone could point me to a better direction.

I was especially concerned about
 *  whether a check for a deadlock with potentially every locking
request really is a good idea or if it is smarter to let an additional
thread check for deadlocks from time to time, and
 * if there is any algorithm that does not have to check the whole
dependency graph for cycles, and
 * a more elegant version of the existing code could be written that
does not have the drawback of potentially rolling back both threads
that are part of a deadlock (one should be enough)

That code has been written by me, so if you want to comment, please do
not be polite ;)

Thanks for any hints in advance and cheers

Oliver

From oliver at zeigermann.de  Fri Apr  6 12:54:45 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 6 Apr 2007 18:54:45 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <4615C65B.2000608@quiotix.com>
References: <4615C65B.2000608@quiotix.com>
Message-ID: <9da4f4520704060954w19bdd6a1jc98e642172203c7b@mail.gmail.com>

Hey, that is really cool!

I was concerned about testing concurrent code myself some time ago.
That led to some helper classes which do something similar to MTC (at
least if my understanding of MTC is correct):

http://jakarta.apache.org/commons/transaction/apidocs/org/apache/commons/transaction/util/TurnBarrier.html
http://jakarta.apache.org/commons/transaction/apidocs/org/apache/commons/transaction/util/RendezvousBarrier.html

I have never been quite sure if they actually make sense and could be useful.

What do you think?

Cheers

Oliver

2007/4/6, Brian Goetz <brian at quiotix.com>:
> Bill Pugh, Cliff Click, and myself are doing a talk at JavaOne on
> Testing Concurrent Code.
>
> I've attached a (commentable) PDF of the slides.  We'd love it if anyone
> had feedback, which you can send in text, or use Acrobat Reader to apply
> comments directly to the PDF.  (I think you can even save a .fdf file
> from Reader, which just saves the comments and which we can merge back
> into the PDF.)
>
> If you're going to comment, please do so by Monday -- as we're already
> weeks late getting our slides in!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>

From sberlin at gmail.com  Fri Apr  6 14:18:27 2007
From: sberlin at gmail.com (Sam Berlin)
Date: Fri, 6 Apr 2007 14:18:27 -0400
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
Message-ID: <19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>

Hi Oliver,

JMX features provide the ability to scan through all locks for
deadlocked code.  I can't quite tell by reading the link you provided
if this is what you're looking for.  It doesn't provide the ability to
know ahead of time if acquiring a given lock would produce a deadlock
(that would be a neat JVM switch -- I wonder how slow it would make
things), but it will tell you afterwards if you've encountered a
deadlock.  (It will even correctly report a trio of threads, where the
third is waiting on something the first two have deadlocked in.)
There's no ability to rollback any deadlocks, but that is always
fraught with peril anyway.  For an example of using the JMX features,
see the following deadlock detection class:
<https://www.limewire.org/fisheye/browse/limecvs/gui/com/limegroup/gnutella/gui/DeadlockSupport.java?r=1.3>
.  That class is written to work best on Java 1.6, but also work
well-enough on Java 1.5.

Sam

On 4/6/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
> Folks!
>
> I plan to write some code for deadlock detection for Java programming
> using the concurrent package introduced in Java 1.5.
>
> The code is intended for a new version of
>
> http://jakarta.apache.org/commons/transaction/
>
> and there to replace the old code which is described in
>
> http://jakarta.apache.org/commons/transaction/locks/deadlock.html
>
> I doubt that the idea and code described there are especially good and
> would be pleased if anyone could point me to a better direction.
>
> I was especially concerned about
>  *  whether a check for a deadlock with potentially every locking
> request really is a good idea or if it is smarter to let an additional
> thread check for deadlocks from time to time, and
>  * if there is any algorithm that does not have to check the whole
> dependency graph for cycles, and
>  * a more elegant version of the existing code could be written that
> does not have the drawback of potentially rolling back both threads
> that are part of a deadlock (one should be enough)
>
> That code has been written by me, so if you want to comment, please do
> not be polite ;)
>
> Thanks for any hints in advance and cheers
>
> Oliver
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From szabolcs.ferenczi at gmail.com  Fri Apr  6 14:19:06 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 6 Apr 2007 20:19:06 +0200
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
Message-ID: <c8955b000704061119j93aafe5j21f187271890f352@mail.gmail.com>

On 06/04/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:

> I doubt that the idea and code described there are especially good and
> would be pleased if anyone could point me to a better direction.

I have read about some deadlock detection support by ConTest:

Multithreaded unit testing with ConTest
http://www-128.ibm.com/developerworks/java/library/j-contest.html

I hope this helps.

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Fri Apr  6 15:31:05 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 6 Apr 2007 21:31:05 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <4615C65B.2000608@quiotix.com>
References: <4615C65B.2000608@quiotix.com>
Message-ID: <c8955b000704061231j20971af2n670763a7af62f42c@mail.gmail.com>

On 06/04/07, Brian Goetz <brian at quiotix.com> wrote:

> I've attached a (commentable) PDF of the slides.  We'd love it if anyone
> had feedback, which you can send in text,

Slide 17:

Since it is a presentation, perhaps a question to the audience would
be more appropriate in the cloud, something like: "Does this work?"

Slide 18:

I think that fragment at least tests that the bounded buffer is a
FIFO. So, instead, the cloud could ask something like: "What does it
test and what does it not test?"

Best Regards,
Szabolcs

From oliver at zeigermann.de  Fri Apr  6 15:36:34 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 6 Apr 2007 21:36:34 +0200
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
	<19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
Message-ID: <9da4f4520704061236x9148fadu201281fe811bbc86@mail.gmail.com>

Hi Sam!

Thanks a lot for that pointer. I had no idea anything like that
existed in JDK 1.6. Cool feature. Your code is instructive as well :)

And yes, my aim is to tell the programmer: "No, I will not give you
this lock, as this would lead to a deadlock!" before acutally
acquiring that lock. And of course, this will only work in a managed
scenario where there is some sort of manager that keeps track of all
locks of a thread. Together with some form of contract the thread and
the manager have.

The manager would signal a deadlock to the thread using an exception.
The thread then is resonsible for undoing a set of actions and
releasing all its locks in order to resolve the deadlock. Both
releasing the locks and undoing all actions can be supported by the
manager. Undoing all actions of a thread is the equivalent to rolling
back a transaction in a DB system. This scenario only makes sense when
the actions done by the thread are restricted to those undoable by the
manager.

Oliver

2007/4/6, Sam Berlin <sberlin at gmail.com>:
> Hi Oliver,
>
> JMX features provide the ability to scan through all locks for
> deadlocked code.  I can't quite tell by reading the link you provided
> if this is what you're looking for.  It doesn't provide the ability to
> know ahead of time if acquiring a given lock would produce a deadlock
> (that would be a neat JVM switch -- I wonder how slow it would make
> things), but it will tell you afterwards if you've encountered a
> deadlock.  (It will even correctly report a trio of threads, where the
> third is waiting on something the first two have deadlocked in.)
> There's no ability to rollback any deadlocks, but that is always
> fraught with peril anyway.  For an example of using the JMX features,
> see the following deadlock detection class:
> <https://www.limewire.org/fisheye/browse/limecvs/gui/com/limegroup/gnutella/gui/DeadlockSupport.java?r=1.3>
> .  That class is written to work best on Java 1.6, but also work
> well-enough on Java 1.5.
>
> Sam
>
> On 4/6/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
> > Folks!
> >
> > I plan to write some code for deadlock detection for Java programming
> > using the concurrent package introduced in Java 1.5.
> >
> > The code is intended for a new version of
> >
> > http://jakarta.apache.org/commons/transaction/
> >
> > and there to replace the old code which is described in
> >
> > http://jakarta.apache.org/commons/transaction/locks/deadlock.html
> >
> > I doubt that the idea and code described there are especially good and
> > would be pleased if anyone could point me to a better direction.
> >
> > I was especially concerned about
> >  *  whether a check for a deadlock with potentially every locking
> > request really is a good idea or if it is smarter to let an additional
> > thread check for deadlocks from time to time, and
> >  * if there is any algorithm that does not have to check the whole
> > dependency graph for cycles, and
> >  * a more elegant version of the existing code could be written that
> > does not have the drawback of potentially rolling back both threads
> > that are part of a deadlock (one should be enough)
> >
> > That code has been written by me, so if you want to comment, please do
> > not be polite ;)
> >
> > Thanks for any hints in advance and cheers
> >
> > Oliver
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>

From oliver at zeigermann.de  Fri Apr  6 15:46:57 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 6 Apr 2007 21:46:57 +0200
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <c8955b000704061119j93aafe5j21f187271890f352@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
	<c8955b000704061119j93aafe5j21f187271890f352@mail.gmail.com>
Message-ID: <9da4f4520704061246l4e848ffas816a343937ecd0b5@mail.gmail.com>

Hi Szabolcs!

Thanks for the pointer!

If I got it right, ConTest tries to bring out all deadlocks by forcing
unlikely context switches. It does so using byte code injection.

That is an interesting approach I have not thought about, yet.
However, what I was after originally was something that prevents
deadlocks all together. Either by reporting a possible deadlock
scenario or by preventing them through management.

Oliver

2007/4/6, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com>:
> On 06/04/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
>
> > I doubt that the idea and code described there are especially good and
> > would be pleased if anyone could point me to a better direction.
>
> I have read about some deadlock detection support by ConTest:
>
> Multithreaded unit testing with ConTest
> http://www-128.ibm.com/developerworks/java/library/j-contest.html
>
> I hope this helps.
>
> Best Regards,
> Szabolcs
>

From hanson.char at gmail.com  Fri Apr  6 16:26:31 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 6 Apr 2007 13:26:31 -0700
Subject: [concurrency-interest] HalfSync
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKENFGOAA.dcholmes@optusnet.com.au>
References: <4474CCFE.6020105@cs.purdue.edu>
	<NFBBKALFDCPFIDBNKAPCKENFGOAA.dcholmes@optusnet.com.au>
Message-ID: <ca53c8f80704061326r3c5dfechb448513379c9519f@mail.gmail.com>

If it is a "close call" when contended and HalfSync wins when it is
uncontended, then shouldn't we replace the implementation of AtomicInteger
with that of HalfSync in the JDK ?

That would provide us with an absolute advantage/improvement, wouldn't it ?

Hanson Char

On 5/24/06, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> Jeremy writes:
> > This isn't as thread safe as it would be if both were synchronized.
> ...
> > Even if Thread 2 terminates, Thread 1 might not, because there is no
> > happens-before edge from Thread 2's increment to Thread 1.  If getCount
> > were synchronized, then Thread 1 would terminate if Thread 2 did.
>
> Huh? count is volatile.
>
> > The class would probably be a faster read than AtomicInteger, but a
> > slower write (getting a lock is slower than performing a single atomic
> > increment).
>
> My 2c:
> - reads: same
>      both do a LD with whatever memory barrier is needed on the
>      platform (which is probably none)
> - writes:
>     - uncontended: close call
>         AtomicInteger.get has a method call with LD and CAS plus MEMBAR
>         Half-sync: CAS for synchronized, LD, ST plus MEMBAR (depends if
>                    the runtime elides the redundant MEMBARS for
> sync+volatile
>
>    - contended:  Half-sync wins by avoiding ctx switches
>
> Cheers,
> David Holmes
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070406/3cc33d79/attachment.html 

From hanson.char at gmail.com  Fri Apr  6 16:30:50 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 6 Apr 2007 13:30:50 -0700
Subject: [concurrency-interest] HalfSync
In-Reply-To: <ca53c8f80704061326r3c5dfechb448513379c9519f@mail.gmail.com>
References: <4474CCFE.6020105@cs.purdue.edu>
	<NFBBKALFDCPFIDBNKAPCKENFGOAA.dcholmes@optusnet.com.au>
	<ca53c8f80704061326r3c5dfechb448513379c9519f@mail.gmail.com>
Message-ID: <ca53c8f80704061330k51d992cfv10b09201b91ea7ae@mail.gmail.com>

Oops, never mind.  AtomicInteger provides a much richer set of
functionalities.

Hanson

On 4/6/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> If it is a "close call" when contended and HalfSync wins when it is
> uncontended, then shouldn't we replace the implementation of AtomicInteger
> with that of HalfSync in the JDK ?
>
> That would provide us with an absolute advantage/improvement, wouldn't it
> ?
>
> Hanson Char
>
> On 5/24/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> >
> > Jeremy writes:
> > > This isn't as thread safe as it would be if both were synchronized.
> > ...
> > > Even if Thread 2 terminates, Thread 1 might not, because there is no
> > > happens-before edge from Thread 2's increment to Thread 1.  If
> > getCount
> > > were synchronized, then Thread 1 would terminate if Thread 2 did.
> >
> > Huh? count is volatile.
> >
> > > The class would probably be a faster read than AtomicInteger, but a
> > > slower write (getting a lock is slower than performing a single atomic
> >
> > > increment).
> >
> > My 2c:
> > - reads: same
> >      both do a LD with whatever memory barrier is needed on the
> >      platform (which is probably none)
> > - writes:
> >     - uncontended: close call
> >         AtomicInteger.get has a method call with LD and CAS plus MEMBAR
> >         Half-sync: CAS for synchronized, LD, ST plus MEMBAR (depends if
> >                    the runtime elides the redundant MEMBARS for
> > sync+volatile
> >
> >    - contended:  Half-sync wins by avoiding ctx switches
> >
> > Cheers,
> > David Holmes
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070406/7a3917c6/attachment-0001.html 

From brian at quiotix.com  Fri Apr  6 16:47:53 2007
From: brian at quiotix.com (Brian Goetz)
Date: Fri, 06 Apr 2007 16:47:53 -0400
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
	<19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
Message-ID: <4616B1F9.10908@quiotix.com>

Scanning for deadlocks with JMX is reactive; what you want is to 
identify the causes of deadlock, which is inconsistent lock ordering. 
One approach, which requires run-time weaving with aspects, is here:

http://www-128.ibm.com/developerworks/java/library/j-jtp08226.html

Sam Berlin wrote:
> Hi Oliver,
> 
> JMX features provide the ability to scan through all locks for
> deadlocked code.  I can't quite tell by reading the link you provided
> if this is what you're looking for.  It doesn't provide the ability to
> know ahead of time if acquiring a given lock would produce a deadlock
> (that would be a neat JVM switch -- I wonder how slow it would make
> things), but it will tell you afterwards if you've encountered a
> deadlock.  (It will even correctly report a trio of threads, where the
> third is waiting on something the first two have deadlocked in.)
> There's no ability to rollback any deadlocks, but that is always
> fraught with peril anyway.  For an example of using the JMX features,
> see the following deadlock detection class:
> <https://www.limewire.org/fisheye/browse/limecvs/gui/com/limegroup/gnutella/gui/DeadlockSupport.java?r=1.3>
> .  That class is written to work best on Java 1.6, but also work
> well-enough on Java 1.5.
> 
> Sam
> 
> On 4/6/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
>> Folks!
>>
>> I plan to write some code for deadlock detection for Java programming
>> using the concurrent package introduced in Java 1.5.
>>
>> The code is intended for a new version of
>>
>> http://jakarta.apache.org/commons/transaction/
>>
>> and there to replace the old code which is described in
>>
>> http://jakarta.apache.org/commons/transaction/locks/deadlock.html
>>
>> I doubt that the idea and code described there are especially good and
>> would be pleased if anyone could point me to a better direction.
>>
>> I was especially concerned about
>>  *  whether a check for a deadlock with potentially every locking
>> request really is a good idea or if it is smarter to let an additional
>> thread check for deadlocks from time to time, and
>>  * if there is any algorithm that does not have to check the whole
>> dependency graph for cycles, and
>>  * a more elegant version of the existing code could be written that
>> does not have the drawback of potentially rolling back both threads
>> that are part of a deadlock (one should be enough)
>>
>> That code has been written by me, so if you want to comment, please do
>> not be polite ;)
>>
>> Thanks for any hints in advance and cheers
>>
>> Oliver
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at altair.cs.oswego.edu
>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From szabolcs.ferenczi at gmail.com  Fri Apr  6 17:16:25 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 6 Apr 2007 23:16:25 +0200
Subject: [concurrency-interest] fast semaphore
In-Reply-To: <4614D221.9070307@xemaps.com>
References: <4614D221.9070307@xemaps.com>
Message-ID: <c8955b000704061416y37589c21h29897e0f4abdccfd@mail.gmail.com>

On 05/04/07, Joseph Seigh <jseigh_cp00 at xemaps.com> wrote:
> Here's the fast pathed semaphore I used with ConcurrentLinkedQueue.

I have some comments about it.

If this semaphore is faster, I think, it is faster for a
release-acquire sequence. And it is faster because the check-and-swap
(CAS) operation on an atomic variable is faster than a corresponding
semaphore operation. This also means that in these cases the semaphore
operations are shortcutted or blocked by the CAS operations on an
atomic variable.

On the other hand, the `faster' semaphore is slower for the
acquire-release sequence because of the overhead of the shortcutting
wrapper code. However, in this case the delay is neglectable, since
the thread is suspended anyway.

So, it means that coding the blocking version of the
ConcurrentLinkedQueue with help of this variant of the semaphore has
some advantage only in the case when the consumer is not blocked.

Do you agree with my comments?

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Fri Apr  6 17:18:35 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 6 Apr 2007 23:18:35 +0200
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <9da4f4520704061236x9148fadu201281fe811bbc86@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
	<19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
	<9da4f4520704061236x9148fadu201281fe811bbc86@mail.gmail.com>
Message-ID: <c8955b000704061418y47ef7f59ya73eca5795e7ce6c@mail.gmail.com>

On 06/04/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:

> The manager would signal a deadlock to the thread using an exception.
> The thread then is resonsible for undoing a set of actions and
> releasing all its locks in order to resolve the deadlock. Both
> releasing the locks and undoing all actions can be supported by the
> manager. Undoing all actions of a thread is the equivalent to rolling
> back a transaction in a DB system. This scenario only makes sense when
> the actions done by the thread are restricted to those undoable by the
> manager.

To me it looks like you are transforming a possible deadlock into a
possible livelock. How do you think this algorithm would respond to
the dining philosophers scenario?

Best Regards,
Szabolcs

From oliver at zeigermann.de  Fri Apr  6 17:32:32 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 6 Apr 2007 23:32:32 +0200
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <c8955b000704061418y47ef7f59ya73eca5795e7ce6c@mail.gmail.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
	<19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
	<9da4f4520704061236x9148fadu201281fe811bbc86@mail.gmail.com>
	<c8955b000704061418y47ef7f59ya73eca5795e7ce6c@mail.gmail.com>
Message-ID: <9da4f4520704061432y314b8178ie89b9e24d8475cbe@mail.gmail.com>

2007/4/6, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com>:
> On 06/04/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
>
> > The manager would signal a deadlock to the thread using an exception.
> > The thread then is resonsible for undoing a set of actions and
> > releasing all its locks in order to resolve the deadlock. Both
> > releasing the locks and undoing all actions can be supported by the
> > manager. Undoing all actions of a thread is the equivalent to rolling
> > back a transaction in a DB system. This scenario only makes sense when
> > the actions done by the thread are restricted to those undoable by the
> > manager.
>
> To me it looks like you are transforming a possible deadlock into a
> possible livelock. How do you think this algorithm would respond to
> the dining philosophers scenario?

Each philospher would be represented as one thread. When a
philosopher's action would cause a deadlock, the manager could tell it
so using an exception. The philosopher should react accordingly and
tell the manager to return all locks. Now another philosopher that
originally waited for the first one can finish its work. So, there is
no live lock either. Another approach would be that the manager does
all the rolling back and the thread only gets notified about that.

Oliver

From oliver at zeigermann.de  Fri Apr  6 17:40:44 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Fri, 6 Apr 2007 23:40:44 +0200
Subject: [concurrency-interest] Deadlock detection
In-Reply-To: <4616B1F9.10908@quiotix.com>
References: <9da4f4520704060935p1c48b935yada0695944105c4b@mail.gmail.com>
	<19196d860704061118l5da0f4ceuf93cc706755004bd@mail.gmail.com>
	<4616B1F9.10908@quiotix.com>
Message-ID: <9da4f4520704061440y65c8b97eibd4121ca61029b6d@mail.gmail.com>

Right. Wouldn't it be a good idea to have some sort of manager that
sees after consistent lock ordering and actually guarantees it?

Oliver

2007/4/6, Brian Goetz <brian at quiotix.com>:
> Scanning for deadlocks with JMX is reactive; what you want is to
> identify the causes of deadlock, which is inconsistent lock ordering.
> One approach, which requires run-time weaving with aspects, is here:
>
> http://www-128.ibm.com/developerworks/java/library/j-jtp08226.html
>
> Sam Berlin wrote:
> > Hi Oliver,
> >
> > JMX features provide the ability to scan through all locks for
> > deadlocked code.  I can't quite tell by reading the link you provided
> > if this is what you're looking for.  It doesn't provide the ability to
> > know ahead of time if acquiring a given lock would produce a deadlock
> > (that would be a neat JVM switch -- I wonder how slow it would make
> > things), but it will tell you afterwards if you've encountered a
> > deadlock.  (It will even correctly report a trio of threads, where the
> > third is waiting on something the first two have deadlocked in.)
> > There's no ability to rollback any deadlocks, but that is always
> > fraught with peril anyway.  For an example of using the JMX features,
> > see the following deadlock detection class:
> > <https://www.limewire.org/fisheye/browse/limecvs/gui/com/limegroup/gnutella/gui/DeadlockSupport.java?r=1.3>
> > .  That class is written to work best on Java 1.6, but also work
> > well-enough on Java 1.5.
> >
> > Sam
> >
> > On 4/6/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
> >> Folks!
> >>
> >> I plan to write some code for deadlock detection for Java programming
> >> using the concurrent package introduced in Java 1.5.
> >>
> >> The code is intended for a new version of
> >>
> >> http://jakarta.apache.org/commons/transaction/
> >>
> >> and there to replace the old code which is described in
> >>
> >> http://jakarta.apache.org/commons/transaction/locks/deadlock.html
> >>
> >> I doubt that the idea and code described there are especially good and
> >> would be pleased if anyone could point me to a better direction.
> >>
> >> I was especially concerned about
> >>  *  whether a check for a deadlock with potentially every locking
> >> request really is a good idea or if it is smarter to let an additional
> >> thread check for deadlocks from time to time, and
> >>  * if there is any algorithm that does not have to check the whole
> >> dependency graph for cycles, and
> >>  * a more elegant version of the existing code could be written that
> >> does not have the drawback of potentially rolling back both threads
> >> that are part of a deadlock (one should be enough)
> >>
> >> That code has been written by me, so if you want to comment, please do
> >> not be polite ;)
> >>
> >> Thanks for any hints in advance and cheers
> >>
> >> Oliver
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at altair.cs.oswego.edu
> >> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From hanson.char at gmail.com  Fri Apr  6 18:00:22 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 6 Apr 2007 15:00:22 -0700
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <4615C65B.2000608@quiotix.com>
References: <4615C65B.2000608@quiotix.com>
Message-ID: <ca53c8f80704061500t27e4770bn1771259dbf9533ea@mail.gmail.com>

On MTC, it mentions it uses the same ideas as JUnit to run initialize() if
it exists, run threadXxxx() methods concurrently, etc.

Well that's true for JUnit 3 but since JUnit 4 they've moved on to an
annotation driven approach.  So instead of relying on method naming
convention, they use annotation such as @Test, @BeforeCass, etc.

Ideally MTS could use the similar approach.  So there will be method
annotations like

@BeforeClass or @Before // (same as JUnit 4)
@Concurrent // to run methods concurrently
@Concurrent(threadPoolSize=3)  // to run methods concurrently with the
specified thread pool size
@After // to check result after the test (same as JUnit 4)

My 2 cents.

Hanson Char

On 4/5/07, Brian Goetz <brian at quiotix.com> wrote:
>
> Bill Pugh, Cliff Click, and myself are doing a talk at JavaOne on
> Testing Concurrent Code.
>
> I've attached a (commentable) PDF of the slides.  We'd love it if anyone
> had feedback, which you can send in text, or use Acrobat Reader to apply
> comments directly to the PDF.  (I think you can even save a .fdf file
> from Reader, which just saves the comments and which we can merge back
> into the PDF.)
>
> If you're going to comment, please do so by Monday -- as we're already
> weeks late getting our slides in!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070406/61b5be8a/attachment.html 

From hanson.char at gmail.com  Fri Apr  6 19:02:47 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 6 Apr 2007 16:02:47 -0700
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <ca53c8f80704061500t27e4770bn1771259dbf9533ea@mail.gmail.com>
References: <4615C65B.2000608@quiotix.com>
	<ca53c8f80704061500t27e4770bn1771259dbf9533ea@mail.gmail.com>
Message-ID: <ca53c8f80704061602r69e994d3k314b1b5e41a0b8e7@mail.gmail.com>

The slides mentions the MTC implementation is available from
http://findbugs.cs.umd.edu.  I went there but it's unclear to me where the
MTC implementation is.  Is it part of the findbugs download bundle ?  Which
version ?  1.2.0-rc4 ?  Where in the jar is the implementation located ?
How can I make use of it ?

Hanson Char

On 4/6/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> On MTC, it mentions it uses the same ideas as JUnit to run initialize() if
> it exists, run threadXxxx() methods concurrently, etc.
>
> Well that's true for JUnit 3 but since JUnit 4 they've moved on to an
> annotation driven approach.  So instead of relying on method naming
> convention, they use annotation such as @Test, @BeforeCass, etc.
>
> Ideally MTS could use the similar approach.  So there will be method
> annotations like
>
> @BeforeClass or @Before // (same as JUnit 4)
> @Concurrent // to run methods concurrently
> @Concurrent(threadPoolSize=3)  // to run methods concurrently with the
> specified thread pool size
> @After // to check result after the test (same as JUnit 4)
>
> My 2 cents.
>
> Hanson Char
>
> On 4/5/07, Brian Goetz < brian at quiotix.com> wrote:
>
> > Bill Pugh, Cliff Click, and myself are doing a talk at JavaOne on
> > Testing Concurrent Code.
> >
> > I've attached a (commentable) PDF of the slides.  We'd love it if anyone
> > had feedback, which you can send in text, or use Acrobat Reader to apply
> > comments directly to the PDF.  (I think you can even save a .fdf file
> > from Reader, which just saves the comments and which we can merge back
> > into the PDF.)
> >
> > If you're going to comment, please do so by Monday -- as we're already
> > weeks late getting our slides in!
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070406/a8194005/attachment-0001.html 

From jseigh_cp00 at xemaps.com  Fri Apr  6 20:22:37 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Fri, 06 Apr 2007 20:22:37 -0400
Subject: [concurrency-interest] fast semaphore
In-Reply-To: <c8955b000704061416y37589c21h29897e0f4abdccfd@mail.gmail.com>
References: <4614D221.9070307@xemaps.com>
	<c8955b000704061416y37589c21h29897e0f4abdccfd@mail.gmail.com>
Message-ID: <4616E44D.4080000@xemaps.com>

Szabolcs Ferenczi wrote:

>
> On 05/04/07, Joseph Seigh <jseigh_cp00 at xemaps.com> wrote:
>
>> Here's the fast pathed semaphore I used with ConcurrentLinkedQueue.
>
>
> I have some comments about it.
>
> If this semaphore is faster, I think, it is faster for a
> release-acquire sequence. And it is faster because the check-and-swap
> (CAS) operation on an atomic variable is faster than a corresponding
> semaphore operation. This also means that in these cases the semaphore
> operations are shortcutted or blocked by the CAS operations on an
> atomic variable.
>
> On the other hand, the `faster' semaphore is slower for the
> acquire-release sequence because of the overhead of the shortcutting
> wrapper code. However, in this case the delay is neglectable, since
> the thread is suspended anyway.
>
> So, it means that coding the blocking version of the
> ConcurrentLinkedQueue with help of this variant of the semaphore has
> some advantage only in the case when the consumer is not blocked.
>
> Do you agree with my comments?


Basically yes.  Fast pathed refers to the non-blocking case.  A thread 
blocked on
a fast pathed semaphore is just as fast as a thread blocked on a regular 
semaphore.
Although some of the benefit is from a possibly shorter code path, the 
main benefit
is from being lock-free on the fast path.  No thread will block and be 
suspended
waiting for another thread holding a lock.  Adding thread suspend/resume 
overhead
for locking can add considerable delay.

--
Joe Seigh

From oliver at zeigermann.de  Sat Apr  7 03:43:39 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Sat, 7 Apr 2007 09:43:39 +0200
Subject: [concurrency-interest] Concurrent features new in JDK 1.6
Message-ID: <9da4f4520704070043h42171b57kc913b848eacd83a5@mail.gmail.com>

Folks!

Can anyone point me to a resource that summarizes all concurrent
features new in JDK 1.6.

Thanks in advance

Oliver

From dcholmes at optusnet.com.au  Sat Apr  7 04:27:17 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sat, 7 Apr 2007 18:27:17 +1000
Subject: [concurrency-interest] Concurrent features new in JDK 1.6
In-Reply-To: <9da4f4520704070043h42171b57kc913b848eacd83a5@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOECBHGAA.dcholmes@optusnet.com.au>

Oliver,

I don't think there is a single document for that - I certainly couldn't
find it.

The closest thing I could find is the list of RFE's fixed in JDK 6, that can
be found here:

http://gee.cs.oswego.edu/dl/concurrency-interest/jsr166/bugs.html

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Oliver
> Zeigermann
> Sent: Saturday, 7 April 2007 5:44 PM
> To: concurrency-interest
> Subject: [concurrency-interest] Concurrent features new in JDK 1.6
>
>
> Folks!
>
> Can anyone point me to a resource that summarizes all concurrent
> features new in JDK 1.6.
>
> Thanks in advance
>
> Oliver
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From oliver at zeigermann.de  Sat Apr  7 06:05:10 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Sat, 7 Apr 2007 12:05:10 +0200
Subject: [concurrency-interest] Concurrent features new in JDK 1.6
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOECBHGAA.dcholmes@optusnet.com.au>
References: <9da4f4520704070043h42171b57kc913b848eacd83a5@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOECBHGAA.dcholmes@optusnet.com.au>
Message-ID: <9da4f4520704070305h2566f675r60e9f0d7d4afd2b8@mail.gmail.com>

Hi David,

thanks a lot. Even though the list make me sweat a bit ;)

This

http://java.sun.com/javase/6/webnotes/features.html

(plus related pages) and that

http://www.javaperformancetuning.com/news/newtips074.shtml

contain all the info, but it is a bit hard to get an overview. In case
I can isolate a list of new features I will post them here.

Cheers

Oliver

2007/4/7, David Holmes <dcholmes at optusnet.com.au>:
> Oliver,
>
> I don't think there is a single document for that - I certainly couldn't
> find it.
>
> The closest thing I could find is the list of RFE's fixed in JDK 6, that can
> be found here:
>
> http://gee.cs.oswego.edu/dl/concurrency-interest/jsr166/bugs.html
>
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Oliver
> > Zeigermann
> > Sent: Saturday, 7 April 2007 5:44 PM
> > To: concurrency-interest
> > Subject: [concurrency-interest] Concurrent features new in JDK 1.6
> >
> >
> > Folks!
> >
> > Can anyone point me to a resource that summarizes all concurrent
> > features new in JDK 1.6.
> >
> > Thanks in advance
> >
> > Oliver
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From jmanson at cs.umd.edu  Sat Apr  7 11:49:00 2007
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Sat, 07 Apr 2007 08:49:00 -0700
Subject: [concurrency-interest] Concurrent features new in JDK 1.6
In-Reply-To: <9da4f4520704070043h42171b57kc913b848eacd83a5@mail.gmail.com>
References: <9da4f4520704070043h42171b57kc913b848eacd83a5@mail.gmail.com>
Message-ID: <4617BD6C.40306@cs.umd.edu>

The j.u.c stuff is mostly on the collections update page:

http://java.sun.com/javase/6/docs/technotes/guides/collections/changes6.html

There's nothing on that page that people who hang around on this list 
don't know already, though.

Tenuously connected to concurrency, I've seen some improvement using the 
parallel garbage collector over JDK5:

http://java.sun.com/javase/6/docs/technotes/guides/vm/index.html#features

AFAICT, the JDK6 improvements are mostly in the realm of speed.  I've 
seen some nice performance boosts from switching.

					Jeremy


Oliver Zeigermann wrote:
> Folks!
> 
> Can anyone point me to a resource that summarizes all concurrent
> features new in JDK 1.6.
> 
> Thanks in advance
> 
> Oliver
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From hanson.char at gmail.com  Sat Apr  7 19:17:25 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Sat, 7 Apr 2007 16:17:25 -0700
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue ?
In-Reply-To: <4500017E.4040202@cs.oswego.edu>
References: <ca53c8f80609062313h502eb3f9n9217820f4d8b46a0@mail.gmail.com>
	<4500017E.4040202@cs.oswego.edu>
Message-ID: <ca53c8f80704071617q79e44a11r86becb26943ecc8e@mail.gmail.com>

Hi Doug,

>So it is more likely that we'll
>put out a separate ConcurrentLinkedBlockingQueue that will be
>preferable to LinkedBlockingQueue unless you need capacity constraints.

I've been asked recently (again) if the proposed CLBQ in it's current form
is ready to be included into Java 7.

http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

What do you think ?

Regards,
Hanson Char

PS: Test harness comparing CLBQ and LBQ:


http://hansonchar.blogspot.com/2006/09/concurrentlinkedblockingqueue.html#070404

On 9/7/06, Doug Lea <dl at cs.oswego.edu> wrote:
>
> Hanson Char wrote:
> > Hi,
> >
> > I've been wondering why there is ConcurrentLinkedQueue in Java 5+, but
> > not something like a ConcurrentLinkedBlockingQueue, which would allow
> > the client to block on an empty queue via a "take" method, or block on
> > an empty for a limited time via a "poll" method.
>
> This IS a good thought.
>
> >
> > Please find below an attempt to build such queue on other existing
> > structures.
> >
> > Any concurrency problem with these classes ?  Is there a better way ?
> >
>
> This way works, but reduces concurrency by using a single semaphore,
> so is a bit less scalable than current LinkedBlockingQueue. However,
> there is a path to much better scalability by using the "dual-queue"
> approach similar to what we did for Java 6 SynchronousQueue.
> My initial intent was to find a way to internally use such
> techniques to replace the unbounded case of LinkedBlockingQueue.
> But this turns out not to work out too well because of all the
> little compatibility problems encountered -- for example, maintaining
> the same Serialization form. So it is more likely that we'll
> put out a separate ConcurrentLinkedBlockingQueue that will be
> preferable to LinkedBlockingQueue unless you need capacity constraints.
> Stay tuned for it...
>
> -Doug
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070407/00680edd/attachment.html 

From dl at cs.oswego.edu  Sun Apr  8 06:49:01 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 08 Apr 2007 06:49:01 -0400
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue ?
In-Reply-To: <ca53c8f80704071617q79e44a11r86becb26943ecc8e@mail.gmail.com>
References: <ca53c8f80609062313h502eb3f9n9217820f4d8b46a0@mail.gmail.com>	
	<4500017E.4040202@cs.oswego.edu>
	<ca53c8f80704071617q79e44a11r86becb26943ecc8e@mail.gmail.com>
Message-ID: <4618C89D.1050701@cs.oswego.edu>

Hanson Char wrote:
> Hi Doug,
> 
> 
> I've been asked recently (again) if the proposed CLBQ in it's current 
> form is ready to be included into Java 7.
>     

(Sorry for the delays on this!)

I plugged this into some of our test programs, and noticed that you
have a liveness failure (i.e., freeze) surrounding park/unpark
logic. You can find the performance-oriented  tests in
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
Try the ones that embed or are scripted to run with LinkedBlockingQueue:
(ProducerConsumerLoops,  SingleProducerMultipleConsumerLoops,
MultipleProducersSingleConsumerLoops, ConcurrentQueueLoops,
CancelledProducerConsumerLoops, and so on. There are also
further tests you can adapt from tests/tck and tests/jtreg.
As indicated by Brian et al's JavaOne slides, you can never
have too many tests for these kinds of classes ...

I haven't tried to fully diagnose cause, but I think it might be due
to failing to clean out parkq node if recheck succeeds.

Even with a workaround for this, this version of CLBQ hits the
same limitation as some others I've explored: On machines
with more than a few CPUs, CAS contention/failures start dominating
performance, especially when run with more threads that CPUs
(in which case CAS failures tend to propagate).
So, under some test loads that are not uncommon for blocking queues,
it becomes increasingly much slower than LBQ. There are good ways
out of this. Investigating them (in my usual way of letting the
problem sit in background mode for a few months :-) has led
preliminary release to be delayed.

Also, when contemplating releasing yet another queue implementation,
it occurred to us that it would be worthwhile to also add support
for some functionality that people have said they needed but could
not get with LBQ. So the upcoming LinkedTransferQueue implements
the following interface that also provides a synchronous-style mode.
Comments and suggestions on this would be welcome!


/*
  * Written by Doug Lea with assistance from members of JCP JSR-166
  * Expert Group and released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain
  */

//package jsr166y;
import java.util.concurrent.*;

/**
  * A {@link BlockingQueue} in which producers may wait for consumers
  * to receive elements.  A <tt>TransferQueue</tt> may be useful for
  * example in message passing applications in which producers
  * sometimes (using method <tt>transfer</tt>) await receipt of
  * elements by consumers invoking <tt>take</tt> or <tt>poll<tt>, while
  * at other times enqueue elements (via method <tt>put</tt>) without
  * waiting for receipt . Non-blocking and time-out versions of
  * <tt>tryTransfer</tt> are also available.
  *
  * <p>Like any <tt>BlockingQueue</tt>, a <tt>TransferQueue</tt> may be
  * capacity bounded. If so, an attempted <tt>transfer</tt> operation
  * may initially block waiting for available space, and/or
  * subsequently block waiting for reception by a consumer.  Note that
  * in a queue with zero capacity, such as {@link SynchronousQueue},
  * <tt>put</tt> and <tt>transfer</tt> are effectively synonymous.
  *
  * <p>This interface is a member of the
  * <a href="{@docRoot}/../technotes/guides/collections/index.html">
  * Java Collections Framework</a>.
  *
  * @since 1.7
  * @author Doug Lea
  * @param <E> the type of elements held in this collection
  */
interface TransferQueue<E> extends BlockingQueue<E> {
     /**
      * Transfers the specified element if there exists a consumer
      * already waiting to receive it, otherwise returning <tt>false</tt>
      * without enqueuing the element.
      *
      * @param e the element to transfer
      * @return <tt>true</tt> if the element was transferred, else
      *         <tt>false</tt>
      * @throws ClassCastException if the class of the specified element
      *         prevents it from being added to this queue
      * @throws NullPointerException if the specified element is null
      * @throws IllegalArgumentException if some property of the specified
      *         element prevents it from being added to this queue
      */
     boolean tryTransfer(E e);

     /**
      * Inserts the specified element into this queue, waiting if necessary
      * for space to become available, and subsequently waiting until
      * the element is dequeued by a consumer invoking <tt>take</tt> or
      * <tt>poll</tt>.
      *
      * @param e the element to transfer
      * @throws InterruptedException if interrupted while waiting
      * @throws ClassCastException if the class of the specified element
      *         prevents it from being added to this queue
      * @throws NullPointerException if the specified element is null
      * @throws IllegalArgumentException if some property of the specified
      *         element prevents it from being added to this queue
      */
     void transfer(E e) throws InterruptedException;

     /**
      * Inserts the specified element into this queue, waiting up to the
      * specified wait time if necessary for space to become available
      * and/or for the element to be dequeued.
      *
      * @param e the element to transfer
      * @param timeout how long to wait before giving up, in units of
      *        <tt>unit</tt>
      * @param unit a <tt>TimeUnit</tt> determining how to interpret the
      *        <tt>timeout</tt> parameter
      * @return <tt>true</tt> if successful, or <tt>false</tt> if
      *         the specified waiting time elapses before completion
      * @throws InterruptedException if interrupted while waiting
      * @throws ClassCastException if the class of the specified element
      *         prevents it from being added to this queue
      * @throws NullPointerException if the specified element is null
      * @throws IllegalArgumentException if some property of the specified
      *         element prevents it from being added to this queue
      */
     boolean tryTransfer(E e, long timeout, TimeUnit unit)
         throws InterruptedException;

     /**
      * Returns true if there is at least one consumer waiting to
      * dequeue an element via <tt>take</tt> or <tt>poll</tt>. The
      * return value represents a momentary state of affairs, that
      * may be useful for monitoring and heuristics, but not
      * for synchronization control.
      * @return true if there is at least one waiting consumer.
      */
     boolean hasWaitingConsumer();


     /**
      * Returns the number of consumers waiting to dequeue elements
      * via <tt>take</tt> or <tt>poll</tt>. The return value represents
      * a momentary state of affairs, that may be useful for monitoring
      * and heuristics, but not for synchronization control. Implementations
      * of this method are likely to be noticeably slower than
      * those for <tt>hasWaitingConsumer</tt>.
      * @return the number of consumers waiting to dequeue elements
      */
     int getWaitingConsumerCount();
}







From pugh at cs.umd.edu  Sun Apr  8 22:38:05 2007
From: pugh at cs.umd.edu (Bill Pugh)
Date: Sun, 8 Apr 2007 22:38:05 -0400
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <c8955b000704060727u488ec7ecndfeb66d1ad2d7b79@mail.gmail.com>
References: <4615C65B.2000608@quiotix.com>
	<c8955b000704060727u488ec7ecndfeb66d1ad2d7b79@mail.gmail.com>
Message-ID: <8210A81A-ADEC-44F5-9FC1-FCA42A686CA7@cs.umd.edu>

We are working to get the MultithreadedTestCase implementation
ready for JavaOne. If anyone wants to play with an unsupported version
and give us feedback on it, please contact Nathaniel Ayewah  
(ayewah at cs.umd.edu).
But we make may incompatible changes up until the public unveiling at
JavaOne.

	Bill


On Apr 6, 2007, at 10:27 AM, Szabolcs Ferenczi wrote:

> On 06/04/07, Brian Goetz <brian at quiotix.com> wrote:
>> I've attached a (commentable) PDF of the slides.  We'd love it if  
>> anyone
>> had feedback,
>
> Hi Brian,
>
> I am interested in TDD for multi-threaded designs. I am just trying to
> come up with something similar to the MTC you use in the slides.
> Unfortunately I did not know about MTC so far. I would like to check
> whether it provides the functionality I am planning for TDD-ing
> multi-threaded software. Is it public domain add on for JUnit? How can
> I obtain it?
>
> Best Regards,
> Szabolcs
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From pugh at cs.umd.edu  Sun Apr  8 22:51:40 2007
From: pugh at cs.umd.edu (Bill Pugh)
Date: Sun, 8 Apr 2007 22:51:40 -0400
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <9da4f4520704060954w19bdd6a1jc98e642172203c7b@mail.gmail.com>
References: <4615C65B.2000608@quiotix.com>
	<9da4f4520704060954w19bdd6a1jc98e642172203c7b@mail.gmail.com>
Message-ID: <0B540B1D-A783-4AEA-B39C-C7C447C15166@cs.umd.edu>


On Apr 6, 2007, at 12:54 PM, Oliver Zeigermann wrote:

> Hey, that is really cool!
>
> I was concerned about testing concurrent code myself some time ago.
> That led to some helper classes which do something similar to MTC (at
> least if my understanding of MTC is correct):
>
> http://jakarta.apache.org/commons/transaction/apidocs/org/apache/ 
> commons/transaction/util/TurnBarrier.html
> http://jakarta.apache.org/commons/transaction/apidocs/org/apache/ 
> commons/transaction/util/RendezvousBarrier.html
>
> I have never been quite sure if they actually make sense and could  
> be useful.
>
> What do you think?


I can understand them, and see where they might be useful for  
somethings. The nice thing about the tick counter
in MultithreadedTestCase is that it works very well for the case  
where you expect a thread to block and you want
to verify that it does block.

However, MultithreadedTestCase requires some deeper magic: a  
monitoring thread calling getState on all of the
test threads. Figuring out which threads should be monitored and such  
is a little tricky, and thus I'm not sure
how general purpose it is. We haven't really tried using it in a case  
where you have executors and/or dynamically
spawned threads.

	Bill

From hanson.char at gmail.com  Mon Apr  9 01:19:41 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Sun, 8 Apr 2007 22:19:41 -0700
Subject: [concurrency-interest] Quick question on ConcurrentLinkedQueue
Message-ID: <ca53c8f80704082219yef1ed9ma47b8927c2da7dba@mail.gmail.com>

Say we have two initially empty j.u.c.ConcurrentLinkedQueue, clq1 and
clq2.  If two threads offered to each queue individually at the same
time, followed by polling the other queue, is it possible for both
threads to observer the other queue as being empty ?

In other words:

Time   Thread1      Thread2
0         clq1.offer     clq2.offer
1         x=clq2.poll   y=clq1.poll

Can both x and y be null ?

Thanks,
Hanson Char

From szabolcs.ferenczi at gmail.com  Mon Apr  9 04:33:39 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 9 Apr 2007 10:33:39 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <8210A81A-ADEC-44F5-9FC1-FCA42A686CA7@cs.umd.edu>
References: <4615C65B.2000608@quiotix.com>
	<c8955b000704060727u488ec7ecndfeb66d1ad2d7b79@mail.gmail.com>
	<8210A81A-ADEC-44F5-9FC1-FCA42A686CA7@cs.umd.edu>
Message-ID: <c8955b000704090133m2f45d6bcxf8ab17b6d5bb2556@mail.gmail.com>

I would definitely like to play with it and I can give you feedback on
it as well. Please send me a version.
Best Regards,
Szabolcs

On 09/04/07, Bill Pugh <pugh at cs.umd.edu> wrote:
> We are working to get the MultithreadedTestCase implementation
> ready for JavaOne. If anyone wants to play with an unsupported version
> and give us feedback on it, please contact Nathaniel Ayewah
> (ayewah at cs.umd.edu).
> But we make may incompatible changes up until the public unveiling at
> JavaOne.
>
>         Bill
>
>
> On Apr 6, 2007, at 10:27 AM, Szabolcs Ferenczi wrote:
>
> > On 06/04/07, Brian Goetz <brian at quiotix.com> wrote:
> >> I've attached a (commentable) PDF of the slides.  We'd love it if
> >> anyone
> >> had feedback,
> >
> > Hi Brian,
> >
> > I am interested in TDD for multi-threaded designs. I am just trying to
> > come up with something similar to the MTC you use in the slides.
> > Unfortunately I did not know about MTC so far. I would like to check
> > whether it provides the functionality I am planning for TDD-ing
> > multi-threaded software. Is it public domain add on for JUnit? How can
> > I obtain it?
> >
> > Best Regards,
> > Szabolcs
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From jseigh_cp00 at xemaps.com  Mon Apr  9 06:31:24 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Mon, 09 Apr 2007 06:31:24 -0400
Subject: [concurrency-interest] Quick question on ConcurrentLinkedQueue
In-Reply-To: <ca53c8f80704082219yef1ed9ma47b8927c2da7dba@mail.gmail.com>
References: <ca53c8f80704082219yef1ed9ma47b8927c2da7dba@mail.gmail.com>
Message-ID: <461A15FC.2090502@xemaps.com>

Hanson Char wrote:

>
>Say we have two initially empty j.u.c.ConcurrentLinkedQueue, clq1 and
>clq2.  If two threads offered to each queue individually at the same
>time, followed by polling the other queue, is it possible for both
>threads to observer the other queue as being empty ?
>
>In other words:
>
>Time   Thread1      Thread2
>0         clq1.offer     clq2.offer
>1         x=clq2.poll   y=clq1.poll
>
>Can both x and y be null ?
>  
>

No.  ConcurrentLinkedQueue contains volatile fields which give it 
acquire and release semantics.

--
Joe Seigh

From dl at cs.oswego.edu  Mon Apr  9 08:04:04 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 09 Apr 2007 08:04:04 -0400
Subject: [concurrency-interest] Quick question on ConcurrentLinkedQueue
In-Reply-To: <461A15FC.2090502@xemaps.com>
References: <ca53c8f80704082219yef1ed9ma47b8927c2da7dba@mail.gmail.com>
	<461A15FC.2090502@xemaps.com>
Message-ID: <461A2BB4.7000302@cs.oswego.edu>

Joseph Seigh wrote:
> Hanson Char wrote:
> 
>> Say we have two initially empty j.u.c.ConcurrentLinkedQueue, clq1 and
>> clq2.  If two threads offered to each queue individually at the same
>> time, followed by polling the other queue, is it possible for both
>> threads to observer the other queue as being empty ?
>>
>> In other words:
>>
>> Time   Thread1      Thread2
>> 0         clq1.offer     clq2.offer
>> 1         x=clq2.poll   y=clq1.poll
>>
>> Can both x and y be null ?
>>  
>>
> 
> No.  ConcurrentLinkedQueue contains volatile fields which give it 
> acquire and release semantics.
> 

That's true for the implementation. But the spec doesn't
say anything about consistency properties spanning multiple
queues. We've discussed whether we should add some. Doing
so hits several gray areas though, that we'd have to resolve
first.

-Doug

From hanson.char at gmail.com  Mon Apr  9 13:02:39 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 9 Apr 2007 10:02:39 -0700
Subject: [concurrency-interest] Quick question on ConcurrentLinkedQueue
In-Reply-To: <461A2BB4.7000302@cs.oswego.edu>
References: <ca53c8f80704082219yef1ed9ma47b8927c2da7dba@mail.gmail.com>
	<461A15FC.2090502@xemaps.com> <461A2BB4.7000302@cs.oswego.edu>
Message-ID: <ca53c8f80704091002v3c15eb26l18b0dee049abc98c@mail.gmail.com>

Doug,

> That's true for the implementation.

If I could empirically prove that the current implementation of
ConcurrentLinkedQueue can result in both x and y being null, does it
mean the implementation is broken ?

Hanson Char

On 4/9/07, Doug Lea <dl at cs.oswego.edu> wrote:
> Joseph Seigh wrote:
> > Hanson Char wrote:
> >
> >> Say we have two initially empty j.u.c.ConcurrentLinkedQueue, clq1 and
> >> clq2.  If two threads offered to each queue individually at the same
> >> time, followed by polling the other queue, is it possible for both
> >> threads to observer the other queue as being empty ?
> >>
> >> In other words:
> >>
> >> Time   Thread1      Thread2
> >> 0         clq1.offer     clq2.offer
> >> 1         x=clq2.poll   y=clq1.poll
> >>
> >> Can both x and y be null ?
> >>
> >>
> >
> > No.  ConcurrentLinkedQueue contains volatile fields which give it
> > acquire and release semantics.
> >
>
> That's true for the implementation. But the spec doesn't
> say anything about consistency properties spanning multiple
> queues. We've discussed whether we should add some. Doing
> so hits several gray areas though, that we'd have to resolve
> first.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From hanson.char at gmail.com  Mon Apr  9 16:54:17 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 9 Apr 2007 13:54:17 -0700
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected behavior ?
Message-ID: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>

Here is the proof:

Running the following test, occasionally I got both x and y as null:
    http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib-test/dl/TwoConcurrentLinkedQueueLoops.java?view=markup

(In the test, x is referred to as result.r1, and y as result.r2)

This "impossible" case can happen both on Windows and Linux.  Not
always.  So you may need to run the test several times before hitting
it.

So is ConcurrentLinkedQueue broken ?  Or at least it doesn't seem to
behavior the way it should.  Or am I missing/overlooking something ?

Hanson Char

PS:

To reproduce the problem, add TwoConcurrentLinkedQueueLoops.java to
the jsr166/src/test/loops directory:

    http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/

Compile and run it.

On 4/9/07, Hanson Char <hanson.char at gmail.com> wrote:
> Doug,
>
> > That's true for the implementation.
>
> If I could empirically prove that the current implementation of
> ConcurrentLinkedQueue can result in both x and y being null, does it
> mean the implementation is broken ?
>
> Hanson Char
>
> On 4/9/07, Doug Lea <dl at cs.oswego.edu> wrote:
> > Joseph Seigh wrote:
> > > Hanson Char wrote:
> > >
> > >> Say we have two initially empty j.u.c.ConcurrentLinkedQueue, clq1 and
> > >> clq2.  If two threads offered to each queue individually at the same
> > >> time, followed by polling the other queue, is it possible for both
> > >> threads to observer the other queue as being empty ?
> > >>
> > >> In other words:
> > >>
> > >> Time   Thread1      Thread2
> > >> 0         clq1.offer     clq2.offer
> > >> 1         x=clq2.poll   y=clq1.poll
> > >>
> > >> Can both x and y be null ?
> > >>
> > >>
> > >
> > > No.  ConcurrentLinkedQueue contains volatile fields which give it
> > > acquire and release semantics.
> > >
> >
> > That's true for the implementation. But the spec doesn't
> > say anything about consistency properties spanning multiple
> > queues. We've discussed whether we should add some. Doing
> > so hits several gray areas though, that we'd have to resolve
> > first.
> >
> > -Doug
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>

From dl at cs.oswego.edu  Tue Apr 10 06:09:52 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 10 Apr 2007 06:09:52 -0400
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected
 behavior ?
In-Reply-To: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
References: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
Message-ID: <461B6270.70008@cs.oswego.edu>

Hanson Char wrote:
> Here is the proof:
> 
> Running the following test, occasionally I got both x and y as null:
>     http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib-test/dl/TwoConcurrentLinkedQueueLoops.java?view=markup
> 
> (In the test, x is referred to as result.r1, and y as result.r2)
> 

This doesn't seem to be testing the property that you stated,
that is:

T1           T2
q1.offer     q2.offer
x=q2.poll    y=q1.poll

Your test starts up a large number of pairs, each using the same
queues. This allows, for example, the sequence involving
added thread T3, that is conceptually a member of
a different pair:

T2: q2.offer
T2: y=q1.poll => null
T3: q1.offer
T3: q2.poll => nonnull
T1: q1.offer
T1: x=q2.poll => null

So, both x and y can be null.

-Doug

From alarmnummer at gmail.com  Tue Apr 10 08:12:06 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 10 Apr 2007 14:12:06 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <0B540B1D-A783-4AEA-B39C-C7C447C15166@cs.umd.edu>
References: <4615C65B.2000608@quiotix.com>
	<9da4f4520704060954w19bdd6a1jc98e642172203c7b@mail.gmail.com>
	<0B540B1D-A783-4AEA-B39C-C7C447C15166@cs.umd.edu>
Message-ID: <1466c1d60704100512v20247c2ei1727c6c70d535e65@mail.gmail.com>

> I can understand them, and see where they might be useful for
> somethings. The nice thing about the tick counter
> in MultithreadedTestCase is that it works very well for the case
> where you expect a thread to block and you want
> to verify that it does block.

I have created threads and runnable's that can be asked for the state
they are in, and how they have exited:

example usage:

BlockingThread waitThread = scheduleWait(somelock,somecondition);
sleepMs(SMALL_DELAY);
waitThread.assertIsWaiting();

Thread signalThread = scheduleNotify(somelock,somecondition);
joinAll(signalThread,waitThread);
waitThread.assertIsFinished();

And the joinAll method joins on thread with a timeout, so a unittest
won't stall indefinitely.

From oliver at zeigermann.de  Tue Apr 10 08:21:38 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Tue, 10 Apr 2007 14:21:38 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <1466c1d60704100512v20247c2ei1727c6c70d535e65@mail.gmail.com>
References: <4615C65B.2000608@quiotix.com>
	<9da4f4520704060954w19bdd6a1jc98e642172203c7b@mail.gmail.com>
	<0B540B1D-A783-4AEA-B39C-C7C447C15166@cs.umd.edu>
	<1466c1d60704100512v20247c2ei1727c6c70d535e65@mail.gmail.com>
Message-ID: <9da4f4520704100521k1f23f350x673f53bff4bdbf66@mail.gmail.com>

That's pretty cool. Any place where I can get the source?

Cheers

Oliver

2007/4/10, Peter Veentjer <alarmnummer at gmail.com>:
> > I can understand them, and see where they might be useful for
> > somethings. The nice thing about the tick counter
> > in MultithreadedTestCase is that it works very well for the case
> > where you expect a thread to block and you want
> > to verify that it does block.
>
> I have created threads and runnable's that can be asked for the state
> they are in, and how they have exited:
>
> example usage:
>
> BlockingThread waitThread = scheduleWait(somelock,somecondition);
> sleepMs(SMALL_DELAY);
> waitThread.assertIsWaiting();
>
> Thread signalThread = scheduleNotify(somelock,somecondition);
> joinAll(signalThread,waitThread);
> waitThread.assertIsFinished();
>
> And the joinAll method joins on thread with a timeout, so a unittest
> won't stall indefinitely.
>

From alarmnummer at gmail.com  Tue Apr 10 08:28:38 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 10 Apr 2007 14:28:38 +0200
Subject: [concurrency-interest] Request for feedback -- Bill/Brian/Cliff
	JavaOne talk
In-Reply-To: <9da4f4520704100521k1f23f350x673f53bff4bdbf66@mail.gmail.com>
References: <4615C65B.2000608@quiotix.com>
	<9da4f4520704060954w19bdd6a1jc98e642172203c7b@mail.gmail.com>
	<0B540B1D-A783-4AEA-B39C-C7C447C15166@cs.umd.edu>
	<1466c1d60704100512v20247c2ei1727c6c70d535e65@mail.gmail.com>
	<9da4f4520704100521k1f23f350x673f53bff4bdbf66@mail.gmail.com>
Message-ID: <1466c1d60704100528y52023854i627e2b616015820d@mail.gmail.com>

It is part of a concurrency library I'm working on and planning to
release (the first version still needs a lot of work).

http://prometheus.codehaus.org

but I haven't released anything. If you want I can send the current
version to you.

On 4/10/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
> That's pretty cool. Any place where I can get the source?
>
> Cheers
>
> Oliver
>
> 2007/4/10, Peter Veentjer <alarmnummer at gmail.com>:
> > > I can understand them, and see where they might be useful for
> > > somethings. The nice thing about the tick counter
> > > in MultithreadedTestCase is that it works very well for the case
> > > where you expect a thread to block and you want
> > > to verify that it does block.
> >
> > I have created threads and runnable's that can be asked for the state
> > they are in, and how they have exited:
> >
> > example usage:
> >
> > BlockingThread waitThread = scheduleWait(somelock,somecondition);
> > sleepMs(SMALL_DELAY);
> > waitThread.assertIsWaiting();
> >
> > Thread signalThread = scheduleNotify(somelock,somecondition);
> > joinAll(signalThread,waitThread);
> > waitThread.assertIsFinished();
> >
> > And the joinAll method joins on thread with a timeout, so a unittest
> > won't stall indefinitely.
> >
>

From mike.quilleash at subexazure.com  Tue Apr 10 09:07:57 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Tue, 10 Apr 2007 09:07:57 -0400
Subject: [concurrency-interest] Static initializer
Message-ID: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>

Hi all,
 
Just a quick question about static initializers.  I've read JCiP
(excellent book BTW) and wondered if the following is threadsafe.  The
examples in the book didn't quite cover this case (code/method calls in
the constructor).
 
 
public class MyClass
{
   private static MyClass instance = new MyClass();
 
   private final Map map;
 
   private MyClass()
   {
      // do some init work
 
      map = Collections.unmodifiableMap( ... );
   }
 
   public static MyClass getInstance()
   {
       return instance;
   }
 
   // other accessor method(s) to access info in the map
}
 
 
Is any thread that calls getInstance() guaranteed to see a fully
initialized MyClass instance?  If so, is this because of the static
initialization, or the "final" someObject, or both?  I'd like to know
before I go and use this pattern everywhere in my code!
 
Thanks.
 
Mike.
 

 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070410/bfa84cab/attachment.html 

From dhanji at gmail.com  Tue Apr 10 09:40:50 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 10 Apr 2007 23:40:50 +1000
Subject: [concurrency-interest] Static initializer
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
Message-ID: <aa067ea10704100640g5cf73005y5d8a838d3fa4313d@mail.gmail.com>

Im by no means a concurrency expert, but here's how I read it:

The static method cannot be invoked prior to the static initializer being
called (the static initializer is called as part of the classloading). The
final keyword ensures safe publication of the map to the instance. So
getInstance() is guaranteed to return fully initialized instances.

Classes load in a CL in a synchronized fashion so there is no danger of two
threads hitting the static initializer.

On 4/10/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
>
>  Hi all,
>
> Just a quick question about static initializers.  I've read JCiP
> (excellent book BTW) and wondered if the following is threadsafe.  The
> examples in the book didn't quite cover this case (code/method calls in the
> constructor).
>
>
> public class MyClass
> {
>    private static MyClass instance = new MyClass();
>
>    private final Map map;
>
>    private MyClass()
>    {
>        // do some init work
>
>       map = Collections.unmodifiableMap( ... );
>    }
>
>    public static MyClass getInstance()
>    {
>        return instance;
>    }
>
>    // other accessor method(s) to access info in the map
> }
>
>
> Is any thread that calls getInstance() guaranteed to see a fully
> initialized MyClass instance?  If so, is this because of the static
> initialization, or the "final" someObject, or both?  I'd like to know before
> I go and use this pattern everywhere in my code!
>
> Thanks.
>
> Mike.
>
>
>  This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070410/67555411/attachment-0001.html 

From hanson.char at gmail.com  Tue Apr 10 14:23:28 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 10 Apr 2007 11:23:28 -0700
Subject: [concurrency-interest] Static initializer
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
Message-ID: <ca53c8f80704101123v401fbc40o5657008210aac4b9@mail.gmail.com>

I would make the static "instance" field final as well in this case.

My 2 cents.

Hanson Char

On 4/10/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
>
>
> Hi all,
>
> Just a quick question about static initializers.  I've read JCiP (excellent
> book BTW) and wondered if the following is threadsafe.  The examples in the
> book didn't quite cover this case (code/method calls in the constructor).
>
>
> public class MyClass
> {
>    private static MyClass instance = new MyClass();
>
>    private final Map map;
>
>    private MyClass()
>    {
>
>       // do some init work
>
>       map = Collections.unmodifiableMap( ... );   }
>
>    public static MyClass getInstance()
>    {
>        return instance;
>    }
>
>    // other accessor method(s) to access info in the map
> }
>
>
> Is any thread that calls getInstance() guaranteed to see a fully initialized
> MyClass instance?  If so, is this because of the static initialization, or
> the "final" someObject, or both?  I'd like to know before I go and use this
> pattern everywhere in my code!
>
> Thanks.
>
> Mike.
>   This e-mail is bound by the terms and conditions described at
> http://www.subexazure.com/mail-disclaimer.html
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From szabolcs.ferenczi at gmail.com  Tue Apr 10 14:59:54 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 10 Apr 2007 20:59:54 +0200
Subject: [concurrency-interest] fast semaphore
In-Reply-To: <4616E44D.4080000@xemaps.com>
References: <4614D221.9070307@xemaps.com>
	<c8955b000704061416y37589c21h29897e0f4abdccfd@mail.gmail.com>
	<4616E44D.4080000@xemaps.com>
Message-ID: <c8955b000704101159x4a2f0dacyb2fd322159fbe338@mail.gmail.com>

On 07/04/07, Joseph Seigh <jseigh_cp00 at xemaps.com> wrote:

> main benefit
> is from being lock-free on the fast path.  No thread will block and be
> suspended
> waiting for another thread holding a lock.  Adding thread suspend/resume
> overhead
> for locking can add considerable delay.

I am afraid there is a misbelief about this in this lock-free fever.

There are two kinds of scheduling: short term and long term ones. Now,
suspend/resume is more appropriate for the latter and there is no
locking there. In case of a traditional critical section we can speak
of short term scheduling because the section is used by the threads
for a short time interval. Consequently, threads do not have to wait
for it indefinitely long. It depends on the JVM how it schedules for
the short term. On a single processor, it might mean that the
pre-emption is prevented inside the critical section. On a
multi-processor system, on the other hand, critical section can be
guarded by a spin lock or an adaptive version of the spin lock.

The lock-free version has some advantage in the case when there is no
simultaneous attempt of the threads to work on the "critical section."
In this case there is no overhead in the lock-free version whereas the
traditional synchronized version checks the lock anyway and that is an
overhead.

On the other hand, the lock-free version has major disadvantage when
the critical section is heavily visited simultaneously. In this case
the lock-free version can turn into a busy waiting loop and considerably
loads the system degrading the overall performance.

So, it looks like the lock-free solution is a hand optimisation for
the case of not heavily interacting threads.

Best Regards,
Szabolcs

From brian at quiotix.com  Tue Apr 10 15:05:59 2007
From: brian at quiotix.com (Brian Goetz)
Date: Tue, 10 Apr 2007 15:05:59 -0400
Subject: [concurrency-interest] Static initializer
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
Message-ID: <461BE017.2010104@quiotix.com>

Short answer: yes, this code is safe.

In this particular case, the work is done by the final field semantics 
and the effective immutability of the MyClass.  All the initialization 
is done in the ctor, all the state is reachable through the final field 
'map', and no modifications to the state are ever made subsequently. 
Initialization safety guarantees that any thread obtaining a reference 
to a MyClass sees the correct state.

The static initialization is a sensible way to publish this, regardless 
of thread-safety.  But if there was any state not reachable through 
final fields, you would need the static initializer (or some other safe 
publication mechanism) to ensure visibility.

Mike Quilleash wrote:
> Hi all,
>  
> Just a quick question about static initializers.  I've read JCiP 
> (excellent book BTW) and wondered if the following is threadsafe.  The 
> examples in the book didn't quite cover this case (code/method calls in 
> the constructor).
>  
>  
> public class MyClass
> {
>    private static MyClass instance = new MyClass();
>  
>    private final Map map;
>  
>    private MyClass()
>    {
>       // do some init work
>  
>       map = Collections.unmodifiableMap( ... );
>    }
>  
>    public static MyClass getInstance()
>    {
>        return instance;
>    }
>  
>    // other accessor method(s) to access info in the map
> }
>  
>  
> Is any thread that calls getInstance() guaranteed to see a fully 
> initialized MyClass instance?  If so, is this because of the static 
> initialization, or the "final" someObject, or both?  I'd like to know 
> before I go and use this pattern everywhere in my code!
>  
> Thanks.
>  
> Mike.
>  
> 
>  This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From mike.quilleash at subexazure.com  Tue Apr 10 15:29:36 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Tue, 10 Apr 2007 15:29:36 -0400
Subject: [concurrency-interest] Static initializer
In-Reply-To: <461BE017.2010104@quiotix.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E06660323@MI8NYCMAIL15.Mi8.com>

Thanks for the replies guys.  Think I've got it straight in my head now.

Cheers.

Mike. 

-----Original Message-----
From: Brian Goetz [mailto:brian at quiotix.com] 
Sent: 10 April 2007 20:06
To: Mike Quilleash 
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Static initializer

Short answer: yes, this code is safe.

In this particular case, the work is done by the final field semantics
and the effective immutability of the MyClass.  All the initialization
is done in the ctor, all the state is reachable through the final field
'map', and no modifications to the state are ever made subsequently. 
Initialization safety guarantees that any thread obtaining a reference
to a MyClass sees the correct state.

The static initialization is a sensible way to publish this, regardless
of thread-safety.  But if there was any state not reachable through
final fields, you would need the static initializer (or some other safe
publication mechanism) to ensure visibility.

Mike Quilleash wrote:
> Hi all,
>  
> Just a quick question about static initializers.  I've read JCiP 
> (excellent book BTW) and wondered if the following is threadsafe.  The

> examples in the book didn't quite cover this case (code/method calls 
> in the constructor).
>  
>  
> public class MyClass
> {
>    private static MyClass instance = new MyClass();
>  
>    private final Map map;
>  
>    private MyClass()
>    {
>       // do some init work
>  
>       map = Collections.unmodifiableMap( ... );
>    }
>  
>    public static MyClass getInstance()
>    {
>        return instance;
>    }
>  
>    // other accessor method(s) to access info in the map }
>  
>  
> Is any thread that calls getInstance() guaranteed to see a fully 
> initialized MyClass instance?  If so, is this because of the static 
> initialization, or the "final" someObject, or both?  I'd like to know 
> before I go and use this pattern everywhere in my code!
>  
> Thanks.
>  
> Mike.
>  
> 
>  This e-mail is bound by the terms and conditions described at 
> http://www.subexazure.com/mail-disclaimer.html
> 
> 
> 
> 
> ----------------------------------------------------------------------
> --
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From pugh at cs.umd.edu  Tue Apr 10 16:02:23 2007
From: pugh at cs.umd.edu (Bill Pugh)
Date: Tue, 10 Apr 2007 16:02:23 -0400
Subject: [concurrency-interest] Static initializer
In-Reply-To: <461BE017.2010104@quiotix.com>
References: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
	<461BE017.2010104@quiotix.com>
Message-ID: <D7C56485-8CDC-498C-80B5-90E09B949FEB@cs.umd.edu>

Actually, I don't think you need the final field semantics
to get thread safety in this case.

All threads that invoke MyClass.getInstance() are guaranteed
to be correctly ordered with respect to the initialization of
MyClass. Thus, they are ordered with respect to both the writing
of the static "instance" field and the instance field "map".

Making the fields is a good idea, but not required to get thread
safety (assuming you don't introduce data races anywhere else).

Bill


From jseigh_cp00 at xemaps.com  Tue Apr 10 22:39:03 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Tue, 10 Apr 2007 22:39:03 -0400
Subject: [concurrency-interest] fast semaphore
In-Reply-To: <c8955b000704101159x4a2f0dacyb2fd322159fbe338@mail.gmail.com>
References: <4614D221.9070307@xemaps.com>	
	<c8955b000704061416y37589c21h29897e0f4abdccfd@mail.gmail.com>	
	<4616E44D.4080000@xemaps.com>
	<c8955b000704101159x4a2f0dacyb2fd322159fbe338@mail.gmail.com>
Message-ID: <461C4A47.90309@xemaps.com>

Szabolcs Ferenczi wrote:

>
>
> On 07/04/07, Joseph Seigh <jseigh_cp00 at xemaps.com> wrote:
>
>> main benefit
>> is from being lock-free on the fast path.  No thread will block and be
>> suspended
>> waiting for another thread holding a lock.  Adding thread suspend/resume
>> overhead
>> for locking can add considerable delay.
>
>
> I am afraid there is a misbelief about this in this lock-free fever.

loop count     =  20000
queue size     =    200
producer count =     20
consumer count =     20

LinkedBlockingQueue:
runtime        =  3.792727288 secs

ConcurrentLinkedQueue w/ unfair semaphore:
runtime        =  2.481310054 secs

ConcurrentLinkedQueue w/ fair semaphore:
runtime        = 12.406078426 secs

ConcurrentLinkedQueue w/ unfair fast semaphore:
runtime        =  1.433149464 secs

ConcurrentLinkedQueue w/ fair fast semaphore:
runtime        =  1.490469041 secs

--
Joe Seigh

From dhanji at gmail.com  Tue Apr 10 22:46:05 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 11 Apr 2007 12:46:05 +1000
Subject: [concurrency-interest] Static initializer
In-Reply-To: <ca53c8f80704101123v401fbc40o5657008210aac4b9@mail.gmail.com>
References: <DAE04D9F6FD21448A220918A522FB60E0665FDBE@MI8NYCMAIL15.Mi8.com>
	<ca53c8f80704101123v401fbc40o5657008210aac4b9@mail.gmail.com>
Message-ID: <aa067ea10704101946h14edaf3bw75790899cdae98f5@mail.gmail.com>

On 4/11/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> I would make the static "instance" field final as well in this case.


How would this help the thread safety? It also alters the semantics of the
instance (say you wanted to replace it later on) does it not?
The static initializer is sufficiently safe in this case for races to
getInstance() -- correct me if Im wrong?

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070411/637c5462/attachment.html 

From dcholmes at optusnet.com.au  Tue Apr 10 23:10:46 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 11 Apr 2007 13:10:46 +1000
Subject: [concurrency-interest] Static initializer
In-Reply-To: <aa067ea10704101946h14edaf3bw75790899cdae98f5@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEDCHGAA.dcholmes@optusnet.com.au>

There is no need to make the static instance field final for
visibility/safety reasons, but if its really immutable then make it final.
If you intended instance to be mutable then you'd have a different problem
to solve.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dhanji R.
Prasanna
  Sent: Wednesday, 11 April 2007 12:46 PM
  To: Hanson Char
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Static initializer





  On 4/11/07, Hanson Char <hanson.char at gmail.com> wrote:
    I would make the static "instance" field final as well in this case.

  How would this help the thread safety? It also alters the semantics of the
instance (say you wanted to replace it later on) does it not?
  The static initializer is sufficiently safe in this case for races to
getInstance() -- correct me if Im wrong?


  Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070411/4d086eec/attachment.html 

From mike.quilleash at subexazure.com  Wed Apr 11 04:53:48 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 11 Apr 2007 04:53:48 -0400
Subject: [concurrency-interest] Lock free caches
Message-ID: <DAE04D9F6FD21448A220918A522FB60E06660807@MI8NYCMAIL15.Mi8.com>

Hi all,
 
I have a performance bottleneck in my code involving
java.util.regex.Pattern.  Doing Pattern.compile() is slow and I would
like to cache these across the application (as the pool of used patterns
is quite small but used regularly), but I want to keep any
synchronization to a minimum.
 
I thought about the following which just does a simple check if present
and build and insert if not.
 
 
public class RegexPatternCache
{
    private static ConcurrentMap< String, Pattern > patternCache = new
ConcurrentHashMap< String, Pattern >();
 
    public static Pattern getRegexPattern( String patternString )
    {
        if ( patternCache.containsKey( patternString ) )
            return patternCache.get( patternString );
 
        Pattern pattern = Pattern.compile( patternString );
 
        patternCache.putIfAbsent( patternString, pattern );
 
        return pattern;
    }
}

I believe the above is threadsafe (please correct me if not!), worst
case being two threads may call getRegexPattern at the same time with
the same patternString and both compile the pattern.  As this is a
deterministic operation I don't see any problem with this.  Is this the
best way of implementing this sort of mini-cache?  Is there an
established best-practice/pattern for this sort of thing?
 
Cheers.
 
Mike.
 

 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070411/5e48d44f/attachment-0001.html 

From joe.bowbeer at gmail.com  Wed Apr 11 05:34:59 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 11 Apr 2007 02:34:59 -0700
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E06660807@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E06660807@MI8NYCMAIL15.Mi8.com>
Message-ID: <31f2a7bd0704110234p290ecec9g9ef3f0b3af3b098b@mail.gmail.com>

On 4/11/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
>
> I have a performance bottleneck in my code involving
> java.util.regex.Pattern.  Doing Pattern.compile() is slow and I would like
> to cache these across the application (as the pool of used patterns is quite
> small but used regularly), but I want to keep any synchronization to a
> minimum.
>
> I thought about the following which just does a simple check if present and
> build and insert if not.
>
> public class RegexPatternCache
> {
>     private static ConcurrentMap< String, Pattern > patternCache = new
> ConcurrentHashMap< String, Pattern >();
>
>     public static Pattern getRegexPattern( String patternString )
>     {
>         if ( patternCache.containsKey( patternString ) )
>             return patternCache.get( patternString );
>
>         Pattern pattern = Pattern.compile( patternString );
>
>         patternCache.putIfAbsent( patternString, pattern );
>
>         return pattern;
>     }
> }
>
> I believe the above is threadsafe (please correct me if not!), worst case
> being two threads may call getRegexPattern at the same time with the same
> patternString and both compile the pattern.  As this is a deterministic
> operation I don't see any problem with this.  Is this the best way of
> implementing this sort of mini-cache?  Is there an established
> best-practice/pattern for this sort of thing?
>

Your solution is a 'memoization' of getRegexPattern.  There's an
example of this in 'Java Concurrency in Practice' book.  An example
has also been presented at JavaOne.  You should be able to find it in
the 2005 slides.  Maybe 2006.  Look for 'Memoize'.

In your code, the map should be declared final (for completeness).

The fully-articulated example in the slides and book stores a Future
in the map.  This is more efficient in the event that two or more
threads are simultaneously seeking the same new pattern.  It also
leverages putIfAbsent.  (putIfAbsent is not really accomplishing
anything in your code.)

--Joe

From matthias.ernst at coremedia.com  Wed Apr 11 09:04:19 2007
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Wed, 11 Apr 2007 15:04:19 +0200
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E06660807@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E06660807@MI8NYCMAIL15.Mi8.com>
Message-ID: <AE2A8E488D9B26438919DF3C9C95528D8543D7@hermes.coremedia.com>

Mike,

a technique for memoizing small amounts with a minimum of synchronization
I'm sometimes using is copy-on-write on a plain hashmap:

public class RegexPatternCache
{
  private static volatile HashMap< String, Pattern > patternCache = new HashMap< String, Pattern >();
  
     public static Pattern getRegexPattern( String patternString )
     {
         HashMap< String, Pattern > current = patternCache;

         Pattern pattern = current.get(patternString);
         if(pattern == null) {
           Pattern pattern = Pattern.compile( patternString );

           current = new HashMap(patternCache);
           current.put(patternString, pattern);
           patternCache = current;
         }

         return pattern;
     }
 }

A thread that fails to find a pattern compiles it, puts it into a copy of the cache and
writes the cache back. It might override other threads' additions but I assume this
quickly converges.

Synchronization cost: one volatile read and I guess the code path is a little shorter than with a CHM.

Matthias

-- 
matthias.ernst at coremedia.com
software architect
+49.40.32 55 87.503

CoreMedia AG
Executive Board: S?ren Stamer (CEO), Dr. Klemens Kleiminger (CFO)
Supervisory Board: Prof. Dr. Joachim Schmidt (Chairman)
Trade Register: Amtsgericht Hamburg, HR B 76277


From tim at peierls.net  Wed Apr 11 10:45:53 2007
From: tim at peierls.net (Tim Peierls)
Date: Wed, 11 Apr 2007 10:45:53 -0400
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <AE2A8E488D9B26438919DF3C9C95528D8543D7@hermes.coremedia.com>
References: <DAE04D9F6FD21448A220918A522FB60E06660807@MI8NYCMAIL15.Mi8.com>
	<AE2A8E488D9B26438919DF3C9C95528D8543D7@hermes.coremedia.com>
Message-ID: <63b4e4050704110745k29baa79bmcb9a35d528cb6f60@mail.gmail.com>

On 4/11/07, Ernst, Matthias <matthias.ernst at coremedia.com> wrote:
>
> a technique for memoizing small amounts with a minimum of synchronization
> I'm sometimes using is copy-on-write on a plain hashmap: [...]
> Synchronization cost: one volatile read and I guess the code path is a
> little shorter than with a CHM.


The synch cost of MemoizedFunction.apply(arg) for a previously cached value
of arg is a CHM.get() plus a FutureTask.get() on a completed task -- usually
a small number of volatile reads, I believe.

It's worth getting memoization right once, and encapsulating it. Once you
have it, all you need to do is something like this:

    private static final Function<String, Pattern> PATTERN_COMPILE =
        new MemoizedFunction<String, Pattern>(new Function<String,
Pattern>() {
            public Pattern apply(String s) { return Pattern.compile(s); }
        });

Then you can safely write:

    Pattern pat = PATTERN_COMPILE.apply("truth(?:iness)?");

This really ought to be standardized, or at least made available via some
quasi-standard resource. I had hoped that http://jcip.net would become such
a resource, but alas, everyone seems to be too busy to manage this.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070411/d1c4ce9e/attachment.html 

From mike.quilleash at subexazure.com  Wed Apr 11 12:18:38 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 11 Apr 2007 12:18:38 -0400
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <63b4e4050704110745k29baa79bmcb9a35d528cb6f60@mail.gmail.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E066B435D@MI8NYCMAIL15.Mi8.com>

I've merged the examples/ideas that I've seen here and in the JavaOne
slides and put all the implementations together in one place.  Please
check/comment if you have time!
 
Cheers.
 
Mike.
 
 
 
public interface Computable< K, V >
{
    public V compute( K input );
}

 
// base class for Memoizers - simply holds the computation
public abstract class Memoizer< K, V > implements Computable< K, V >
{
    private final Computable< K, V > computation;
 
    public Memoizer( Computable<K, V> computation )
    {
        this.computation = computation;
    }
 
    protected V doCompute( K input )
    {
        return computation.compute( input );
    }
}

 
// implementation that copies the internal map on every cache miss
// minimal synchronization overhead (one volatile read) once the cache
// has settled down
public class CopyOnWriteMemoizer< K, V > extends Memoizer< K, V >
{
    // technically an unmodifiable map once it is assigned
    private volatile Map< K, V > map = new HashMap< K, V >();
 
    public CopyOnWriteMemoizer( Computable<K, V> computation )
    {
        super( computation );
    }
 
    public V compute( K input )
    {
        Map< K, V > localMap = map;
 
        if ( localMap.containsKey( input ) )
            return localMap.get( input );
 
        // doCompute the missing value
        V value = doCompute( input );
 
        // copy the map and add the new value
        Map< K, V > newMap = new HashMap< K, V >( localMap );
        newMap.put( input, value );
 
        map = newMap;
 
        return value;
    }
}

 
// single ConcurrentMap implementation of memoizer.  multiple threads
may create the
// same entry and overwrite another threads result but this is a benign
race condition
public class ConcurrentMapMemoizer< K, V > extends Memoizer< K, V >
{
    private final ConcurrentMap< K, V > map = new ConcurrentHashMap< K,
V >();
 
    public ConcurrentMapMemoizer( Computable<K, V> computation )
    {
        super( computation );
    }
 
    public V compute( K input )
    {
        if ( input == null )
            throw new NullPointerException( "Input is null" );
 
        V value = map.get( input );
 
        if ( value != null )
            return value;
 
        value = doCompute( input );
        map.put( input, value );
 
        return value;
    }
}

 
// more complex Memoizer that is guaranteed to doCompute each input at
most once
// if two threads request a missing value at the same time one thread
will do the doCompute
// while the other waits for the result
// based on the JavaOne slides here:
http://developers.sun.com/learning/javaoneonline/2005/coreplatform/TS-34
23.pdf
public class ConcurrentComputeOnceMemoizer< K, V > extends Memoizer< K,
V >
{
    private final ConcurrentMap< K, Future< V > > map = new
ConcurrentHashMap< K, Future< V > >();
 
    public ConcurrentComputeOnceMemoizer( Computable<K, V> computation )
    {
        super( computation );
    }
 
    public V compute( final K input )
    {
        Future< V > future = map.get( input );
 
        // not in the map yet
        if ( future == null )
        {
            // create a task wrapping up the computation
            Callable< V > callable = new Callable< V >()
            {
                public V call() throws Exception
                {
                    return doCompute( input );
                }
            };
 
            FutureTask< V > newFuture = new FutureTask< V >( callable );
 
            // add the future to the map
            future = map.putIfAbsent( input, newFuture );
 
            // if the put into the map did NOT succeed then another
thread beat us inserting
            // into the map so just go and wait for the future result to
become available
 
            // if the put into the map succeeded then execute the newly
created future
            // in this thread
            if ( future == null )
            {
                future = newFuture;
                newFuture.run();
            }
        }
 
        // get the future result
        // if two threads enter around the same time one will "win" and
run the future
        // the other will wait here for the future result to become
available
        try
        {
            return future.get();
        }
        catch ( InterruptedException e )
        {
            // re-interrupt
            Thread.currentThread().interrupt();
 
            throw new RuntimeException( e );
        }
        catch ( ExecutionException e )
        {
            throw new RuntimeException( e );
        }
    }
}

 

________________________________

From: tpeierls at gmail.com [mailto:tpeierls at gmail.com] On Behalf Of Tim
Peierls
Sent: 11 April 2007 15:46
To: Mike Quilleash 
Cc: Ernst, Matthias; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Lock free caches


On 4/11/07, Ernst, Matthias <matthias.ernst at coremedia.com> wrote: 

	a technique for memoizing small amounts with a minimum of
synchronization
	I'm sometimes using is copy-on-write on a plain hashmap: [...]
	Synchronization cost: one volatile read and I guess the code
path is a little shorter than with a CHM. 


The synch cost of MemoizedFunction.apply(arg) for a previously cached
value of arg is a CHM.get() plus a FutureTask.get() on a completed task
-- usually a small number of volatile reads, I believe.

It's worth getting memoization right once, and encapsulating it. Once
you have it, all you need to do is something like this:

    private static final Function<String, Pattern> PATTERN_COMPILE =
        new MemoizedFunction<String, Pattern>(new Function<String,
Pattern>() { 
            public Pattern apply(String s) { return Pattern.compile(s);
}
        });

Then you can safely write:

    Pattern pat = PATTERN_COMPILE.apply("truth(?:iness)?");

This really ought to be standardized, or at least made available via
some quasi-standard resource. I had hoped that http://jcip.net would
become such a resource, but alas, everyone seems to be too busy to
manage this.

--tim




 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070411/9283b6e0/attachment.html 

From hanson.char at gmail.com  Wed Apr 11 12:24:07 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 11 Apr 2007 09:24:07 -0700
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected
	behavior ?
In-Reply-To: <461B6270.70008@cs.oswego.edu>
References: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
	<461B6270.70008@cs.oswego.edu>
Message-ID: <ca53c8f80704110924rc3e0ff0r11ac1e61795bddb@mail.gmail.com>

Nice catch.  Thanks, Doug.

I am still intrigued by CLQ and the liveness problem in CLBQ.  Will
dig further into it.

Hanson Char

On 4/10/07, Doug Lea <dl at cs.oswego.edu> wrote:
> Hanson Char wrote:
> > Here is the proof:
> >
> > Running the following test, occasionally I got both x and y as null:
> >     http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib-test/dl/TwoConcurrentLinkedQueueLoops.java?view=markup
> >
> > (In the test, x is referred to as result.r1, and y as result.r2)
> >
>
> This doesn't seem to be testing the property that you stated,
> that is:
>
> T1           T2
> q1.offer     q2.offer
> x=q2.poll    y=q1.poll
>
> Your test starts up a large number of pairs, each using the same
> queues. This allows, for example, the sequence involving
> added thread T3, that is conceptually a member of
> a different pair:
>
> T2: q2.offer
> T2: y=q1.poll => null
> T3: q1.offer
> T3: q2.poll => nonnull
> T1: q1.offer
> T1: x=q2.poll => null
>
> So, both x and y can be null.
>
> -Doug
>

From holger at wizards.de  Wed Apr 11 13:21:16 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Wed, 11 Apr 2007 19:21:16 +0200
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E066B435D@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E066B435D@MI8NYCMAIL15.Mi8.com>
Message-ID: <461D190C.2000400@wizards.de>

Mike Quilleash wrote:
>         Map< K, V > localMap = map;
>  
>         if ( localMap.containsKey( input ) )
>             return localMap.get( input );

You could still shave off the redundant lookup here, no?

In ConcurrentMemoizer:
>         value = doCompute( input );
>         map.put( input, value );
>  
>         return value;

  value = doCompute(input);
  concurrentValue = map.putIfAbsent(input, value);

  // flip refs on conflict
  if (concurrentValue != null)
  {
      value = concurrentValue;
  }

  return value;

So you'd actually use the ConcurrentMap interface.

-h

From szabolcs.ferenczi at gmail.com  Wed Apr 11 14:18:03 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 11 Apr 2007 20:18:03 +0200
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected
	behavior ?
In-Reply-To: <ca53c8f80704110924rc3e0ff0r11ac1e61795bddb@mail.gmail.com>
References: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
	<461B6270.70008@cs.oswego.edu>
	<ca53c8f80704110924rc3e0ff0r11ac1e61795bddb@mail.gmail.com>
Message-ID: <c8955b000704111118n609a61a6p5d665e8cc8c77d35@mail.gmail.com>

On 11/04/07, Hanson Char <hanson.char at gmail.com> wrote:

> I am still intrigued by CLQ and the liveness problem in CLBQ.  Will
> dig further into it.

Hi Hanson,

      I thought you have found the root of the liveness problem of
your CLBQ already. It is about the implementation of the put method we
talked about. The tests of Doug applies put/take pairs and not
offer/take pairs. Your put method is implemented on the add method of
the member ConcurrentLinkedQueue instance and omits handling of the
parked threads entirely. That is why it freezes. You might try to test
it.

Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr 11 15:49:00 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 11 Apr 2007 12:49:00 -0700
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected
	behavior ?
In-Reply-To: <c8955b000704111118n609a61a6p5d665e8cc8c77d35@mail.gmail.com>
References: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
	<461B6270.70008@cs.oswego.edu>
	<ca53c8f80704110924rc3e0ff0r11ac1e61795bddb@mail.gmail.com>
	<c8955b000704111118n609a61a6p5d665e8cc8c77d35@mail.gmail.com>
Message-ID: <ca53c8f80704111249o5be769a8w733c631683906d15@mail.gmail.com>

Ha, must be April fool's day.  Thanks, Szabolcs.

Fixed version:

http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

Hanson Char

On 4/11/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 11/04/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> > I am still intrigued by CLQ and the liveness problem in CLBQ.  Will
> > dig further into it.
>
> Hi Hanson,
>
>       I thought you have found the root of the liveness problem of
> your CLBQ already. It is about the implementation of the put method we
> talked about. The tests of Doug applies put/take pairs and not
> offer/take pairs. Your put method is implemented on the add method of
> the member ConcurrentLinkedQueue instance and omits handling of the
> parked threads entirely. That is why it freezes. You might try to test
> it.
>
> Best Regards,
> Szabolcs
>

From szabolcs.ferenczi at gmail.com  Wed Apr 11 16:10:32 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 11 Apr 2007 22:10:32 +0200
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected
	behavior ?
In-Reply-To: <ca53c8f80704111249o5be769a8w733c631683906d15@mail.gmail.com>
References: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
	<461B6270.70008@cs.oswego.edu>
	<ca53c8f80704110924rc3e0ff0r11ac1e61795bddb@mail.gmail.com>
	<c8955b000704111118n609a61a6p5d665e8cc8c77d35@mail.gmail.com>
	<ca53c8f80704111249o5be769a8w733c631683906d15@mail.gmail.com>
Message-ID: <c8955b000704111310o1f26a860w8296729ecc3ffe72@mail.gmail.com>

On 11/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> Ha, must be April fool's day.  Thanks, Szabolcs.
>
> Fixed version:
>
> http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

You are welcome but I am afraid that is not so simple. Just test it.
Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr 11 16:26:42 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 11 Apr 2007 13:26:42 -0700
Subject: [concurrency-interest] ConcurrentLinkedQueue unexpected
	behavior ?
In-Reply-To: <c8955b000704111310o1f26a860w8296729ecc3ffe72@mail.gmail.com>
References: <ca53c8f80704091354m235d89d2m4235925829962edc@mail.gmail.com>
	<461B6270.70008@cs.oswego.edu>
	<ca53c8f80704110924rc3e0ff0r11ac1e61795bddb@mail.gmail.com>
	<c8955b000704111118n609a61a6p5d665e8cc8c77d35@mail.gmail.com>
	<ca53c8f80704111249o5be769a8w733c631683906d15@mail.gmail.com>
	<c8955b000704111310o1f26a860w8296729ecc3ffe72@mail.gmail.com>
Message-ID: <ca53c8f80704111326s5bea760dl774bdb814baeed2@mail.gmail.com>

I did, and it's looking good.  I am preparing a comprehensive test
suite based on Doug's jsr166 loop test.

Stay tuned.

Hanson Char

On 4/11/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 11/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> > Ha, must be April fool's day.  Thanks, Szabolcs.
> >
> > Fixed version:
> >
> > http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup
>
> You are welcome but I am afraid that is not so simple. Just test it.
> Best Regards,
> Szabolcs
>

From mike.quilleash at subexazure.com  Wed Apr 11 18:43:09 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 11 Apr 2007 18:43:09 -0400
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <461D190C.2000400@wizards.de>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E066B46FC@MI8NYCMAIL15.Mi8.com>

Thanks for your comments.

As Joe pointed out in my original RegEx "memoizer" the putIfAbsent doesn't really accomplish anything over a normal put as you will always be replacing the same computed value in the map.

Regarding the first the convention in the examples I've seen seems to be to use containsKey + get or
!containsKey + put so I've followed that where possible.  The exception being the implementations using ConcurrentHashMap that doesn't support null keys or values.  The implementations could be extended to use a Null object placeholder to allow this I guess.  Would be sensible as someone could swap out implementations and get NPEs.  Or just change the Memoizer contract to disallow null inputs and null computed values in which case you, as you say, just use get() and skip the containsKey check.

For completeness and uselessness at the same time here's another implementation! ;)

// dumb non-implementation of a memoizer
public class NonMemoizer< K, V > extends Memoizer< K, V >
{
    public NonMemoizer( Computable<K, V> computation )
    {
        super( computation );
    }

    public V compute( K input )
    {
        return doCompute( input );
    }
}


Cheers.

Mike.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Holger Hoffst?tte
Sent: 11 April 2007 18:21
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Lock free caches

Mike Quilleash wrote:
>         Map< K, V > localMap = map;
>  
>         if ( localMap.containsKey( input ) )
>             return localMap.get( input );

You could still shave off the redundant lookup here, no?

In ConcurrentMemoizer:
>         value = doCompute( input );
>         map.put( input, value );
>  
>         return value;

  value = doCompute(input);
  concurrentValue = map.putIfAbsent(input, value);

  // flip refs on conflict
  if (concurrentValue != null)
  {
      value = concurrentValue;
  }

  return value;

So you'd actually use the ConcurrentMap interface.

-h
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From hanson.char at gmail.com  Thu Apr 12 04:53:10 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 12 Apr 2007 01:53:10 -0700
Subject: [concurrency-interest] ConcurrentLinkedBlockingQueue ?
In-Reply-To: <4618C89D.1050701@cs.oswego.edu>
References: <ca53c8f80609062313h502eb3f9n9217820f4d8b46a0@mail.gmail.com>
	<4500017E.4040202@cs.oswego.edu>
	<ca53c8f80704071617q79e44a11r86becb26943ecc8e@mail.gmail.com>
	<4618C89D.1050701@cs.oswego.edu>
Message-ID: <ca53c8f80704120153q3e862253u33a026642f3a9ca6@mail.gmail.com>

> I plugged this into some of our test programs, and noticed that you
> have a liveness failure (i.e., freeze) surrounding park/unpark
> logic.

Thanks for pointing this out.  The liveness failure is now fixed:

http://svn.sourceforge.net/viewvc/beanlib/trunk/beanlib/src/net/sf/beanlib/util/concurrent/ConcurrentLinkedBlockingQueue.java?view=markup

I plugged CLBQ to every test programs (that contains LBQ) I can find
in http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
and they all run successfully.

Hanson Char

On 4/8/07, Doug Lea <dl at cs.oswego.edu> wrote:
> Hanson Char wrote:
> > Hi Doug,
> >
> >
> > I've been asked recently (again) if the proposed CLBQ in it's current
> > form is ready to be included into Java 7.
> >
>
> (Sorry for the delays on this!)
>
> I plugged this into some of our test programs, and noticed that you
> have a liveness failure (i.e., freeze) surrounding park/unpark
> logic. You can find the performance-oriented  tests in
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
> Try the ones that embed or are scripted to run with LinkedBlockingQueue:
> (ProducerConsumerLoops,  SingleProducerMultipleConsumerLoops,
> MultipleProducersSingleConsumerLoops, ConcurrentQueueLoops,
> CancelledProducerConsumerLoops, and so on. There are also
> further tests you can adapt from tests/tck and tests/jtreg.
> As indicated by Brian et al's JavaOne slides, you can never
> have too many tests for these kinds of classes ...
>
> I haven't tried to fully diagnose cause, but I think it might be due
> to failing to clean out parkq node if recheck succeeds.
>
> Even with a workaround for this, this version of CLBQ hits the
> same limitation as some others I've explored: On machines
> with more than a few CPUs, CAS contention/failures start dominating
> performance, especially when run with more threads that CPUs
> (in which case CAS failures tend to propagate).
> So, under some test loads that are not uncommon for blocking queues,
> it becomes increasingly much slower than LBQ. There are good ways
> out of this. Investigating them (in my usual way of letting the
> problem sit in background mode for a few months :-) has led
> preliminary release to be delayed.
>
> Also, when contemplating releasing yet another queue implementation,
> it occurred to us that it would be worthwhile to also add support
> for some functionality that people have said they needed but could
> not get with LBQ. So the upcoming LinkedTransferQueue implements
> the following interface that also provides a synchronous-style mode.
> Comments and suggestions on this would be welcome!
>
>
> /*
>   * Written by Doug Lea with assistance from members of JCP JSR-166
>   * Expert Group and released to the public domain, as explained at
>   * http://creativecommons.org/licenses/publicdomain
>   */
>
> //package jsr166y;
> import java.util.concurrent.*;
>
> /**
>   * A {@link BlockingQueue} in which producers may wait for consumers
>   * to receive elements.  A <tt>TransferQueue</tt> may be useful for
>   * example in message passing applications in which producers
>   * sometimes (using method <tt>transfer</tt>) await receipt of
>   * elements by consumers invoking <tt>take</tt> or <tt>poll<tt>, while
>   * at other times enqueue elements (via method <tt>put</tt>) without
>   * waiting for receipt . Non-blocking and time-out versions of
>   * <tt>tryTransfer</tt> are also available.
>   *
>   * <p>Like any <tt>BlockingQueue</tt>, a <tt>TransferQueue</tt> may be
>   * capacity bounded. If so, an attempted <tt>transfer</tt> operation
>   * may initially block waiting for available space, and/or
>   * subsequently block waiting for reception by a consumer.  Note that
>   * in a queue with zero capacity, such as {@link SynchronousQueue},
>   * <tt>put</tt> and <tt>transfer</tt> are effectively synonymous.
>   *
>   * <p>This interface is a member of the
>   * <a href="{@docRoot}/../technotes/guides/collections/index.html">
>   * Java Collections Framework</a>.
>   *
>   * @since 1.7
>   * @author Doug Lea
>   * @param <E> the type of elements held in this collection
>   */
> interface TransferQueue<E> extends BlockingQueue<E> {
>      /**
>       * Transfers the specified element if there exists a consumer
>       * already waiting to receive it, otherwise returning <tt>false</tt>
>       * without enqueuing the element.
>       *
>       * @param e the element to transfer
>       * @return <tt>true</tt> if the element was transferred, else
>       *         <tt>false</tt>
>       * @throws ClassCastException if the class of the specified element
>       *         prevents it from being added to this queue
>       * @throws NullPointerException if the specified element is null
>       * @throws IllegalArgumentException if some property of the specified
>       *         element prevents it from being added to this queue
>       */
>      boolean tryTransfer(E e);
>
>      /**
>       * Inserts the specified element into this queue, waiting if necessary
>       * for space to become available, and subsequently waiting until
>       * the element is dequeued by a consumer invoking <tt>take</tt> or
>       * <tt>poll</tt>.
>       *
>       * @param e the element to transfer
>       * @throws InterruptedException if interrupted while waiting
>       * @throws ClassCastException if the class of the specified element
>       *         prevents it from being added to this queue
>       * @throws NullPointerException if the specified element is null
>       * @throws IllegalArgumentException if some property of the specified
>       *         element prevents it from being added to this queue
>       */
>      void transfer(E e) throws InterruptedException;
>
>      /**
>       * Inserts the specified element into this queue, waiting up to the
>       * specified wait time if necessary for space to become available
>       * and/or for the element to be dequeued.
>       *
>       * @param e the element to transfer
>       * @param timeout how long to wait before giving up, in units of
>       *        <tt>unit</tt>
>       * @param unit a <tt>TimeUnit</tt> determining how to interpret the
>       *        <tt>timeout</tt> parameter
>       * @return <tt>true</tt> if successful, or <tt>false</tt> if
>       *         the specified waiting time elapses before completion
>       * @throws InterruptedException if interrupted while waiting
>       * @throws ClassCastException if the class of the specified element
>       *         prevents it from being added to this queue
>       * @throws NullPointerException if the specified element is null
>       * @throws IllegalArgumentException if some property of the specified
>       *         element prevents it from being added to this queue
>       */
>      boolean tryTransfer(E e, long timeout, TimeUnit unit)
>          throws InterruptedException;
>
>      /**
>       * Returns true if there is at least one consumer waiting to
>       * dequeue an element via <tt>take</tt> or <tt>poll</tt>. The
>       * return value represents a momentary state of affairs, that
>       * may be useful for monitoring and heuristics, but not
>       * for synchronization control.
>       * @return true if there is at least one waiting consumer.
>       */
>      boolean hasWaitingConsumer();
>
>
>      /**
>       * Returns the number of consumers waiting to dequeue elements
>       * via <tt>take</tt> or <tt>poll</tt>. The return value represents
>       * a momentary state of affairs, that may be useful for monitoring
>       * and heuristics, but not for synchronization control. Implementations
>       * of this method are likely to be noticeably slower than
>       * those for <tt>hasWaitingConsumer</tt>.
>       * @return the number of consumers waiting to dequeue elements
>       */
>      int getWaitingConsumerCount();
> }
>
>
>
>
>
>
>

From mike.quilleash at subexazure.com  Thu Apr 12 07:58:12 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Thu, 12 Apr 2007 07:58:12 -0400
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E066B46FC@MI8NYCMAIL15.Mi8.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E066B4B83@MI8NYCMAIL15.Mi8.com>

As an enhancment to the implementation using FutureTask I think you can make it a bit more fail-safe by removing an entry from the map if the computation throws an exception.

        try
        {
            return future.get();
        }
        catch ( InterruptedException e )
        {
            // re-interrupt
            Thread.currentThread().interrupt();

            throw new RuntimeException( e );
        }
        catch ( ExecutionException e )
        {
            // remove the future from the map as it is now broken - next thread to request
            // this input will attempt to recompute the value
            if ( retryFailedCompute )
                map.remove( input );

            throw new RuntimeException( e.getCause() );
        }

So on an ExecutionException, originally thrown from doCompute(), the "dead" future will be removed from the map so the next request will cause a retry (depending on the retryFailedCompute flag).  This might be useful for operations that can-but-usually-don't fail.  Threads already passed the initial map.get() will still throw the exception but subsequent ones stand a chance of succeeding.  When the computation should never fail and is broken if it does fail then setting the retryFailedCompute to false will cause the same exception to be thrown for every thread requesting the value.

Further enhancements could involve some sort of retry policy to handle failure and decide on retrying vs exception and anything else like wait time between retries etc.

Cheers.

Mike.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Mike Quilleash 
Sent: 11 April 2007 23:43
To: Holger Hoffst?tte; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Lock free caches

Thanks for your comments.

As Joe pointed out in my original RegEx "memoizer" the putIfAbsent doesn't really accomplish anything over a normal put as you will always be replacing the same computed value in the map.

Regarding the first the convention in the examples I've seen seems to be to use containsKey + get or !containsKey + put so I've followed that where possible.  The exception being the implementations using ConcurrentHashMap that doesn't support null keys or values.  The implementations could be extended to use a Null object placeholder to allow this I guess.  Would be sensible as someone could swap out implementations and get NPEs.  Or just change the Memoizer contract to disallow null inputs and null computed values in which case you, as you say, just use get() and skip the containsKey check.

For completeness and uselessness at the same time here's another implementation! ;)

// dumb non-implementation of a memoizer public class NonMemoizer< K, V > extends Memoizer< K, V > {
    public NonMemoizer( Computable<K, V> computation )
    {
        super( computation );
    }

    public V compute( K input )
    {
        return doCompute( input );
    }
}


Cheers.

Mike.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Holger Hoffst?tte
Sent: 11 April 2007 18:21
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Lock free caches

Mike Quilleash wrote:
>         Map< K, V > localMap = map;
>  
>         if ( localMap.containsKey( input ) )
>             return localMap.get( input );

You could still shave off the redundant lookup here, no?

In ConcurrentMemoizer:
>         value = doCompute( input );
>         map.put( input, value );
>  
>         return value;

  value = doCompute(input);
  concurrentValue = map.putIfAbsent(input, value);

  // flip refs on conflict
  if (concurrentValue != null)
  {
      value = concurrentValue;
  }

  return value;

So you'd actually use the ConcurrentMap interface.

-h
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From joe.bowbeer at gmail.com  Thu Apr 12 11:48:35 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 12 Apr 2007 08:48:35 -0700
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E066B4B83@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E066B46FC@MI8NYCMAIL15.Mi8.com>
	<DAE04D9F6FD21448A220918A522FB60E066B4B83@MI8NYCMAIL15.Mi8.com>
Message-ID: <31f2a7bd0704120848n6694e6a8ye207fac1ff68c2e3@mail.gmail.com>

Note that several callers may return the previously reported error
before one of the threads removes the failed Future from the map.

Btw, the list archives contain a long discussion about error handling
that's worth checking, too.

On 4/12/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> As an enhancment to the implementation using FutureTask I think you can make it a bit more fail-safe by removing an entry from the map if the computation throws an exception.
>
>         try
>         {
>             return future.get();
>         }
>         catch ( InterruptedException e )
>         {
>             // re-interrupt
>             Thread.currentThread().interrupt();
>
>             throw new RuntimeException( e );
>         }
>         catch ( ExecutionException e )
>         {
>             // remove the future from the map as it is now broken - next thread to request
>             // this input will attempt to recompute the value
>             if ( retryFailedCompute )
>                 map.remove( input );
>
>             throw new RuntimeException( e.getCause() );
>         }
>
> So on an ExecutionException, originally thrown from doCompute(), the "dead" future will be removed from the map so the next request will cause a retry (depending on the retryFailedCompute flag).  This might be useful for operations that can-but-usually-don't fail.  Threads already passed the initial map.get() will still throw the exception but subsequent ones stand a chance of succeeding.  When the computation should never fail and is broken if it does fail then setting the retryFailedCompute to false will cause the same exception to be thrown for every thread requesting the value.
>
> Further enhancements could involve some sort of retry policy to handle failure and decide on retrying vs exception and anything else like wait time between retries etc.
>

From joe.bowbeer at gmail.com  Thu Apr 12 15:05:25 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 12 Apr 2007 12:05:25 -0700
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <31f2a7bd0704120848n6694e6a8ye207fac1ff68c2e3@mail.gmail.com>
References: <DAE04D9F6FD21448A220918A522FB60E066B46FC@MI8NYCMAIL15.Mi8.com>
	<DAE04D9F6FD21448A220918A522FB60E066B4B83@MI8NYCMAIL15.Mi8.com>
	<31f2a7bd0704120848n6694e6a8ye207fac1ff68c2e3@mail.gmail.com>
Message-ID: <31f2a7bd0704121205j30736c4ao582feb6dbce0ed9b@mail.gmail.com>

worse yet, a thread can remove a successfully retried computation.
removeIfPresent can help there though.

On 4/12/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Note that several callers may return the previously reported error
> before one of the threads removes the failed Future from the map.
>
> Btw, the list archives contain a long discussion about error handling
> that's worth checking, too.
>
> On 4/12/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> > As an enhancment to the implementation using FutureTask I think you can
> make it a bit more fail-safe by removing an entry from the map if the
> computation throws an exception.
> >
> >         try
> >         {
> >             return future.get();
> >         }
> >         catch ( InterruptedException e )
> >         {
> >             // re-interrupt
> >             Thread.currentThread().interrupt();
> >
> >             throw new RuntimeException( e );
> >         }
> >         catch ( ExecutionException e )
> >         {
> >             // remove the future from the map as it is now broken - next
> thread to request
> >             // this input will attempt to recompute the value
> >             if ( retryFailedCompute )
> >                 map.remove( input );
> >
> >             throw new RuntimeException( e.getCause() );
> >         }
> >
> > So on an ExecutionException, originally thrown from doCompute(), the
> "dead" future will be removed from the map so the next request will cause a
> retry (depending on the retryFailedCompute flag).  This might be useful for
> operations that can-but-usually-don't fail.  Threads already passed the
> initial map.get() will still throw the exception but subsequent ones stand a
> chance of succeeding.  When the computation should never fail and is broken
> if it does fail then setting the retryFailedCompute to false will cause the
> same exception to be thrown for every thread requesting the value.
> >
> > Further enhancements could involve some sort of retry policy to handle
> failure and decide on retrying vs exception and anything else like wait time
> between retries etc.
> >
>

From mike.quilleash at subexazure.com  Thu Apr 12 15:38:47 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Thu, 12 Apr 2007 15:38:47 -0400
Subject: [concurrency-interest] Lock free caches
In-Reply-To: <31f2a7bd0704121205j30736c4ao582feb6dbce0ed9b@mail.gmail.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E06703121@MI8NYCMAIL15.Mi8.com>

Good point.  Revised below.


        // get the future result
        // if two threads enter around the same time one will "win" and
run the future
        // the other will wait here for the future result to become
available
        try
        {
            return future.get();
        }
        catch ( InterruptedException e )
        {
            // re-interrupt
            Thread.currentThread().interrupt();

            throw new RuntimeException( e );
        }
        catch ( ExecutionException e )
        {
            // remove the future from the map as it is now broken - next
thread to request
            // this input will attempt to recompute the value

            // make sure to only remove if the input key is still
referencing the same future
            // there is an edge case where if more than one thread calls
future.get() and catches
            // this exception the first will remove the entry from the
map which will allow other
            // threads to recompute and add an entry to the map.  the
second failed thread may then
            // come here and remove the entry from the map again even
though the future is "stale"
            if ( retryFailedCompute )
                map.remove( input, future );

            throw new RuntimeException( e.getCause() );
        }
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joe
Bowbeer
Sent: 12 April 2007 20:05
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Lock free caches

worse yet, a thread can remove a successfully retried computation.
removeIfPresent can help there though.

On 4/12/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Note that several callers may return the previously reported error 
> before one of the threads removes the failed Future from the map.
>
> Btw, the list archives contain a long discussion about error handling 
> that's worth checking, too.
>
> On 4/12/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> > As an enhancment to the implementation using FutureTask I think you 
> > can
> make it a bit more fail-safe by removing an entry from the map if the 
> computation throws an exception.
> >
> >         try
> >         {
> >             return future.get();
> >         }
> >         catch ( InterruptedException e )
> >         {
> >             // re-interrupt
> >             Thread.currentThread().interrupt();
> >
> >             throw new RuntimeException( e );
> >         }
> >         catch ( ExecutionException e )
> >         {
> >             // remove the future from the map as it is now broken - 
> > next
> thread to request
> >             // this input will attempt to recompute the value
> >             if ( retryFailedCompute )
> >                 map.remove( input );
> >
> >             throw new RuntimeException( e.getCause() );
> >         }
> >
> > So on an ExecutionException, originally thrown from doCompute(), the
> "dead" future will be removed from the map so the next request will 
> cause a retry (depending on the retryFailedCompute flag).  This might 
> be useful for operations that can-but-usually-don't fail.  Threads 
> already passed the initial map.get() will still throw the exception 
> but subsequent ones stand a chance of succeeding.  When the 
> computation should never fail and is broken if it does fail then 
> setting the retryFailedCompute to false will cause the same exception
to be thrown for every thread requesting the value.
> >
> > Further enhancements could involve some sort of retry policy to 
> > handle
> failure and decide on retrying vs exception and anything else like 
> wait time between retries etc.
> >
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From hanson.char at gmail.com  Fri Apr 13 14:02:23 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 13 Apr 2007 11:02:23 -0700
Subject: [concurrency-interest] Bug in ThreadLocal ?
Message-ID: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>

Hi,

According to the javadoc of ThreadLocal#remove (in jdk1.6),

    "If this thread-local variable is subsequently read by the current
thread, its value will be reinitialized by invoking its initialValue method"

So I would expect, within the same thread, a ThreadLocal#get followed
by ThreadLocal#remove
followed by ThreadLocal#get would result in ThreadLocal#initialValue being
invoked twice.

But this is not the case.  The last "get" did not cause the "initValue" to
be invoked.  When I looked at the code of the "remove" and "get" method
implementation, it seems there is a bug in that the internal "t.threadLocals"
should be set to null when the remove method is invoked, but is not
currently the case.

Am I mistaken or is this a bug ?  Comment ?

Thanks,
Hanson Char
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070413/d1b9ed03/attachment.html 

From josh at bloch.us  Fri Apr 13 15:02:41 2007
From: josh at bloch.us (Joshua Bloch)
Date: Fri, 13 Apr 2007 12:02:41 -0700
Subject: [concurrency-interest] Bug in ThreadLocal ?
In-Reply-To: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>
References: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>
Message-ID: <b097ac510704131202n2d93f89bidf1cf011bd380f5b@mail.gmail.com>

Hanson,

This would be a bug, but I can't reproduce it.  When I run this program:

public class TlTest {
    private static ThreadLocal<Void> tl = new ThreadLocal<Void>() {
        @Override protected Void initialValue() {
            System.out.println("Hi mom");
            return null;
        }
    };
    public static void main(String[] args) {
        tl.get();
        tl.remove();
        tl.get();
    }
}

It prints "Hi Mom" twice.  Can you give me a small reproducible test case?

            Josh


On 4/13/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> Hi,
>
> According to the javadoc of ThreadLocal#remove (in jdk1.6),
>
>     "If this thread-local variable is subsequently read by the current
> thread, its value will be reinitialized by invoking its initialValue method"
>
> So I would expect, within the same thread, a ThreadLocal#get followed by ThreadLocal#remove
> followed by ThreadLocal#get would result in ThreadLocal#initialValue being
> invoked twice.
>
> But this is not the case.  The last "get" did not cause the "initValue" to
> be invoked.  When I looked at the code of the "remove" and "get" method
> implementation, it seems there is a bug in that the internal "
> t.threadLocals" should be set to null when the remove method is invoked,
> but is not currently the case.
>
> Am I mistaken or is this a bug ?  Comment ?
>
> Thanks,
> Hanson Char
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070413/827bb14c/attachment.html 

From jason_mehrens at hotmail.com  Fri Apr 13 15:29:45 2007
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 13 Apr 2007 14:29:45 -0500
Subject: [concurrency-interest] Bug in ThreadLocal ?
In-Reply-To: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>
Message-ID: <BAY142-F2086FD81B3850BA04E4378835D0@phx.gbl>

ThreadLocal invokes "initialValue" not "initValue".  Are you using 
"@Override"?

Jason Mehrens

public static void main(String[] args) {
    ThreadLocal<Boolean> t = new ThreadLocal<Boolean>() {
      @Override protected Boolean initialValue() {
        System.out.println("initialValue");
        return new Boolean(true);
      }
    };

    Boolean first = t.get();
    t.remove();
    Boolean second = t.get();
    System.out.println("Same object? "+ (first == second));
  }

==========================================
initialValue
initialValue
Same object? false




>followed by ThreadLocal#get would result in ThreadLocal#initialValue being 
>invoked twice.
>But this is not the case.  The last "get" did not cause the "initValue" to

_________________________________________________________________
MSN is giving away a trip to Vegas to see Elton John.? Enter to win today. 
http://msnconcertcontest.com?icid-nceltontagline


From tackline at tackline.plus.com  Fri Apr 13 15:48:50 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Fri, 13 Apr 2007 20:48:50 +0100
Subject: [concurrency-interest] Bug in ThreadLocal ?
In-Reply-To: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>
References: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>
Message-ID: <461FDEA2.6070308@tackline.plus.com>

Hanson Char wrote:
> 
> So I would expect, within the same thread, a ThreadLocal#get followed by 
> ThreadLocal#remove followed by ThreadLocal#get would result in 
> ThreadLocal#initialValue being invoked twice.
> 
> But this is not the case.  The last "get" did not cause the "initValue" 
> to be invoked.  When I looked at the code of the "remove" and "get" 
> method implementation, it seems there is a bug in that the internal " 
> t.threadLocals" should be set to null when the remove method is invoked, 
> but is not currently the case.

Works for me...

class RemoveTest {
     public static void main(String[] args) {
         ThreadLocal<Void> local = new ThreadLocal<Void>() {
             @Override
             protected Void initialValue() {
                 System.err.println("initialValue");
                 return null;
             }
         };
         local.get();
         local.remove();
         local.get();
     }
}

Have you got some code to demonstrate the problem?

Tom Hawtin

From hanson.char at gmail.com  Fri Apr 13 17:06:31 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 13 Apr 2007 14:06:31 -0700
Subject: [concurrency-interest] Bug in ThreadLocal ?
In-Reply-To: <b097ac510704131202n2d93f89bidf1cf011bd380f5b@mail.gmail.com>
References: <ca53c8f80704131102p7adaf59cgd06299e93a138f43@mail.gmail.com>
	<b097ac510704131202n2d93f89bidf1cf011bd380f5b@mail.gmail.com>
Message-ID: <ca53c8f80704131406o2db376b6oc120adfa90b6d093@mail.gmail.com>

Sorry, it's my bad.  ThreadLocal is working fine.  April is not yet over :)

Hanson Char

On 4/13/07, Joshua Bloch <josh at bloch.us> wrote:
>
> Hanson,
>
> This would be a bug, but I can't reproduce it.  When I run this program:
>
> public class TlTest {
>     private static ThreadLocal<Void> tl = new ThreadLocal<Void>() {
>         @Override protected Void initialValue() {
>             System.out.println("Hi mom");
>             return null;
>         }
>     };
>     public static void main(String[] args) {
>         tl.get();
>         tl.remove();
>         tl.get();
>     }
> }
>
> It prints "Hi Mom" twice.  Can you give me a small reproducible test case?
>
>             Josh
>
>
> On 4/13/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> > Hi,
> >
> > According to the javadoc of ThreadLocal#remove (in jdk1.6),
> >
> >     "If this thread-local variable is subsequently read by the current
> > thread, its value will be reinitialized by invoking its initialValue method"
> >
> >
> > So I would expect, within the same thread, a ThreadLocal#get followed by
> > ThreadLocal#remove followed by ThreadLocal#get would result in
> > ThreadLocal#initialValue being invoked twice.
> >
> > But this is not the case.  The last "get" did not cause the "initValue"
> > to be invoked.  When I looked at the code of the "remove" and "get" method
> > implementation, it seems there is a bug in that the internal "
> > t.threadLocals" should be set to null when the remove method is invoked,
> > but is not currently the case.
> >
> > Am I mistaken or is this a bug ?  Comment ?
> >
> > Thanks,
> > Hanson Char
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070413/594a3012/attachment.html 

From szabolcs.ferenczi at gmail.com  Sun Apr 15 15:38:22 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 15 Apr 2007 21:38:22 +0200
Subject: [concurrency-interest] Lock-free mania
Message-ID: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>

It seems that there is some kind of a lock-free mania going
around. People desire to create so-called lock-free algorithms for the
short term interaction between threads where traditionally mutual
exclusion is applicable. The idea might come from a generalization of the
check-and-swap operation that is supported by nowadays processors
instead of the traditional test-and-set operation.

What is the advantage of the lock-free algorithm? Pros:

1: If there is no conflict in the actual interaction among threads,
  the overhead is less than by a conventional mutual exclusion
  algorithm.

What are the drawbacks of the lock-free algorithm? Cons:

1: It is more complicated, more difficult to prove its correctness or
  to test it. It is a major drawback.

2: When there are frequent conflicts between threads, i.e. under heavy
  load conditions, it becomes a busy waiting loop and, consequently,
  it becomes very inefficient just at the critical moment.

3: It cannot always be applied but only in special cases.

Why are people keen to invent so-called lock-free algorithms if they
cannot prove the correctness nor can they test them? I think there are
more cons than pros for the lock-free algorithms. What do you think?

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Sun Apr 15 15:59:07 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 15 Apr 2007 21:59:07 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
Message-ID: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>

I am trying to test LinkedBlockingQueue and I cannot get the null
pointer test for the method contains through:

public class lbqTest {

    LinkedBlockingQueue q;

    @Before
    public void setUp() {
        q = new LinkedBlockingQueue(3);
    }

    @Test (expected=NullPointerException.class)
    public void seqContainsNull() {
        q.contains(null);
    }
...
}

What I receive is this:

There was 1 failure:
1) seqContainsNull(lbqTest.lbqTest)
java.lang.AssertionError: Expected exception: java.lang.NullPointerException

I would expect a successful test according to the documentation of the
method.

What is wrong?

Best Regards,
Szabolcs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070415/fb67afe4/attachment.html 

From oliver at zeigermann.de  Sun Apr 15 16:14:02 2007
From: oliver at zeigermann.de (Oliver Zeigermann)
Date: Sun, 15 Apr 2007 22:14:02 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
Message-ID: <9da4f4520704151314t373e4f4ch1fb6117b4a83702e@mail.gmail.com>

2007/4/15, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com>:
> Why are people keen to invent so-called lock-free algorithms if they
> cannot prove the correctness nor can they test them? I think there are
> more cons than pros for the lock-free algorithms. What do you think?

No locks - no deadlocks :)

Oliver

From szabolcs.ferenczi at gmail.com  Sun Apr 15 16:18:47 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 15 Apr 2007 22:18:47 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <9da4f4520704151314t373e4f4ch1fb6117b4a83702e@mail.gmail.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
	<9da4f4520704151314t373e4f4ch1fb6117b4a83702e@mail.gmail.com>
Message-ID: <c8955b000704151318u1bddaa63l1ba1193112c3fbd6@mail.gmail.com>

On 15/04/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
>
>
> No locks - no deadlocks :)



What about livelocks?

Best Regards,
Szabolcs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070415/b9245d04/attachment.html 

From szabolcs.ferenczi at gmail.com  Sun Apr 15 16:23:29 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 15 Apr 2007 22:23:29 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704151318u1bddaa63l1ba1193112c3fbd6@mail.gmail.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
	<9da4f4520704151314t373e4f4ch1fb6117b4a83702e@mail.gmail.com>
	<c8955b000704151318u1bddaa63l1ba1193112c3fbd6@mail.gmail.com>
Message-ID: <c8955b000704151323v1cec4bf4s9e350f0ae805e89e@mail.gmail.com>

On 15/04/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
>
>
> On 15/04/07, Oliver Zeigermann <oliver at zeigermann.de> wrote:
> >
> >
> > No locks - no deadlocks :)
>
>
>
> What about livelocks?
>
>
You can at least detect a deadlock situation.
Can you detect livelock?

Best Regards,
Szabolcs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070415/1da0a97e/attachment.html 

From joe.bowbeer at gmail.com  Sun Apr 15 16:37:54 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 15 Apr 2007 13:37:54 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
Message-ID: <31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>

Where is the null inserted in your test?

LinkedBlockingQueue(3) contains 0 elements...

On 4/15/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> I am trying to test LinkedBlockingQueue and I cannot get the null
> pointer test for the method contains through:
>
> public class lbqTest {
>
>     LinkedBlockingQueue q;
>
>     @Before
>     public void setUp() {
>          q = new LinkedBlockingQueue(3);
>     }
>
>     @Test (expected=NullPointerException.class)
>     public void seqContainsNull() {
>          q.contains(null);
>     }
> ...
> }
>
> What I receive is this:
>
> There was 1 failure:
> 1) seqContainsNull(lbqTest.lbqTest)
> java.lang.AssertionError: Expected exception: java.lang.NullPointerException
>
> I would expect a successful test according to the documentation of the
> method.
>
> What is wrong?
>
> Best Regards,
> Szabolcs
>

From szabolcs.ferenczi at gmail.com  Sun Apr 15 17:06:54 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 15 Apr 2007 23:06:54 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
Message-ID: <c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>

On 15/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Where is the null inserted in your test?

It is not inserted but queried, see "q.contains(null)"

The documentation for method "public boolean contains(Object o)" says:

"Throws:
...
NullPointerException - if the specified element is null and this
collection does not permit null elements (optional)"

It seems LinkedBlockingQueue does not permit null elements, does it?

Best Regards,
Szabolcs

From dl at cs.oswego.edu  Sun Apr 15 17:15:44 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 15 Apr 2007 17:15:44 -0400
Subject: [concurrency-interest] LinkedBlockingQueue does not
 throw	NullPointerException for the method call contains
In-Reply-To: <c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
Message-ID: <46229600.6090805@cs.oswego.edu>

Szabolcs Ferenczi wrote:
> 
> It is not inserted but queried, see "q.contains(null)"
> 
> The documentation for method "public boolean contains(Object o)" says:
> 
> "Throws:
> ...
> NullPointerException - if the specified element is null and this
> collection does not permit null elements (optional)"
> 

I believe the optionality refers to throwing the exception. In collections
(like Hashtable etc) where nulls cannot be handled at all (you cannot
get the hashCode of null), methods contains, remove, and so on
throw exceptions for null arguments. In others, they simply return
failure indications.

I suppose this could be made more consistent than it is, but
given the preference some people have to allow nulls as elements
in some kinds of collections, but to have others where they cannot
possibly be present, you cannot make it entirely consistent.

-Doug

From kasper at kav.dk  Sun Apr 15 17:21:49 2007
From: kasper at kav.dk (Kasper Nielsen)
Date: Sun, 15 Apr 2007 23:21:49 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not
 throw	NullPointerException for the method call contains
In-Reply-To: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
Message-ID: <4622976D.5060008@kav.dk>

|Hi,

Throwing a NullPointerException from Collection.contains() when 
specifying null ||is optional||.
And LinkedBlockingQueue extends AbstractCollection which allows you to 
specify null as a parameter to contains.

Personally, I would prefer that the collection classes with did not 
allow inserting of null elements would throw NullPointerException for 
all methods even if it is only optionally.

- Kasper

|Szabolcs Ferenczi wrote:
> I am trying to test LinkedBlockingQueue and I cannot get the null
> pointer test for the method contains through:
>
> public class lbqTest {
>
>     LinkedBlockingQueue q;
>
>     @Before
>     public void setUp() {
>         q = new LinkedBlockingQueue(3);
>     }
>
>     @Test (expected=NullPointerException.class)
>     public void seqContainsNull() {
>         q.contains(null);
>     }
> ...
> }
>
> What I receive is this:
>
> There was 1 failure:
> 1) seqContainsNull(lbqTest.lbqTest)
> java.lang.AssertionError: Expected exception: 
> java.lang.NullPointerException
>
> I would expect a successful test according to the documentation of the 
> method.
>
> What is wrong?
>
> Best Regards,
> Szabolcs
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>   


From szabolcs.ferenczi at gmail.com  Sun Apr 15 17:29:01 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 15 Apr 2007 23:29:01 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <46229600.6090805@cs.oswego.edu>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<46229600.6090805@cs.oswego.edu>
Message-ID: <c8955b000704151429pfb3d081j59ddf1767050100a@mail.gmail.com>

On 15/04/07, Doug Lea <dl at cs.oswego.edu> wrote:
> Szabolcs Ferenczi wrote:
> >
> > It is not inserted but queried, see "q.contains(null)"
> >
> > The documentation for method "public boolean contains(Object o)" says:
> >
> > "Throws:
> > ...
> > NullPointerException - if the specified element is null and this
> > collection does not permit null elements (optional)"
> >
>
> I believe the optionality refers to throwing the exception. ...

I do not think so because the doc also explains that null can be
queried by method contains if the collection may contain nulls. On the
other hand, LinkedBlockingQueue does not permit null elements. So,
optional might refer to this situation, i.e. that the method should
throw an exception for null argument just like methods offer and put
does.

Szabolcs

From joe.bowbeer at gmail.com  Sun Apr 15 17:29:59 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 15 Apr 2007 14:29:59 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
Message-ID: <31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>

Good point.  Looks like a bug to me.  Will you report it?

I expect this applies to all subclasses of AbstractQueue.


On 4/15/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 15/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > Where is the null inserted in your test?
>
> It is not inserted but queried, see "q.contains(null)"
>
> The documentation for method "public boolean contains(Object o)" says:
>
> "Throws:
> ...
> NullPointerException - if the specified element is null and this
> collection does not permit null elements (optional)"
>
> It seems LinkedBlockingQueue does not permit null elements, does it?
>
> Best Regards,
> Szabolcs
>

From joe.bowbeer at gmail.com  Sun Apr 15 17:38:44 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 15 Apr 2007 14:38:44 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
Message-ID: <31f2a7bd0704151438j5970dafbu21cdcc7dcb2676cb@mail.gmail.com>

On 4/15/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Good point.  Looks like a bug to me.  Will you report it?
>
> I expect this applies to all subclasses of AbstractQueue.
>

That is, the ones that don't themselves override contains.

In particular, DelayQueue in addition to LinkedBlockingQueue.

PriorityQueue overrides contains in 1.6 but not 1.5.

--Joe

From joe.bowbeer at gmail.com  Sun Apr 15 17:45:35 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 15 Apr 2007 14:45:35 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <46229600.6090805@cs.oswego.edu>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<46229600.6090805@cs.oswego.edu>
Message-ID: <31f2a7bd0704151445n5ce86f16ob7c91a4976ca3843@mail.gmail.com>

On 4/15/07, Doug Lea <dl at cs.oswego.edu> wrote:
>
> I believe the optionality refers to throwing the exception. In collections
> (like Hashtable etc) where nulls cannot be handled at all (you cannot
> get the hashCode of null), methods contains, remove, and so on
> throw exceptions for null arguments. In others, they simply return
> failure indications.
>
> I suppose this could be made more consistent than it is, but
> given the preference some people have to allow nulls as elements
> in some kinds of collections, but to have others where they cannot
> possibly be present, you cannot make it entirely consistent.
>

OK - I can see this spelled out in the Collection spec:

"Attempting to query the presence of an ineligible element may throw
an exception, or it may simply return false; some implementations will
exhibit the former behavior and some will exhibit the latter. More
generally, attempting an operation on an ineligible element whose
completion would not result in the insertion of an ineligible element
into the collection may throw an exception or it may succeed, at the
option of the implementation. Such exceptions are marked as "optional"
in the specification for this interface."

From kasper at kav.dk  Sun Apr 15 18:14:03 2007
From: kasper at kav.dk (Kasper Nielsen)
Date: Mon, 16 Apr 2007 00:14:03 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not
 throw	NullPointerException for the method call contains
In-Reply-To: <31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
Message-ID: <4622A3AB.9030804@kav.dk>

Joe Bowbeer wrote:
> Good point.  Looks like a bug to me.  Will you report it?
>
> I expect this applies to all subclasses of AbstractQueue.
>
>   
If this is a bug, remove/removeAll and retainAll should also be fixed
as well as the collection views returned by ConcurrentHashMap and 
ConcurrentSkipListMap.

- Kasper
> On 4/15/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>   
>> On 15/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
>>     
>>> Where is the null inserted in your test?
>>>       
>> It is not inserted but queried, see "q.contains(null)"
>>
>> The documentation for method "public boolean contains(Object o)" says:
>>
>> "Throws:
>> ...
>> NullPointerException - if the specified element is null and this
>> collection does not permit null elements (optional)"
>>
>> It seems LinkedBlockingQueue does not permit null elements, does it?
>>
>> Best Regards,
>> Szabolcs
>>
>>     
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>   


From joe.bowbeer at gmail.com  Sun Apr 15 18:20:28 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 15 Apr 2007 15:20:28 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <4622A3AB.9030804@kav.dk>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
	<4622A3AB.9030804@kav.dk>
Message-ID: <31f2a7bd0704151520i7854d7d0j276e40fd980aa6c@mail.gmail.com>

On 4/15/07, Kasper Nielsen <kasper at kav.dk> wrote:
>
> If this is a bug, remove/removeAll and retainAll should also be fixed
> as well as the collection views returned by ConcurrentHashMap and
> ConcurrentSkipListMap.
>

I was misled by the 'contains' method documentation in the same way
Szabolcs was, but I now see that the meaning of 'optional' is spelled
out in the Collection javadoc.

I think it would be nice if all AbstractQueue implementations
implemented this optional exception in the same way, and maybe they do.

In any event, it could do more harm than good to change it now, I realize.

So, never mind ...

From holger at wizards.de  Sun Apr 15 18:48:29 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Mon, 16 Apr 2007 00:48:29 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not
 throw	NullPointerException for the method call contains
In-Reply-To: <4622976D.5060008@kav.dk>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<4622976D.5060008@kav.dk>
Message-ID: <4622ABBD.8020809@wizards.de>

Kasper Nielsen wrote:
> Personally, I would prefer that the collection classes with did not 
> allow inserting of null elements would throw NullPointerException for 
> all methods even if it is only optionally.

Well..personally, I wish everyone would just stop throwing NPEs *at all*
and use IllegalArgumentException _which was made for exactly that
purpose_. NPE shouldn't even *exist*, let alone be thrown manually. Who
came up with that foolish idea anyways? :-(

-h


From dcholmes at optusnet.com.au  Sun Apr 15 19:18:43 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 16 Apr 2007 09:18:43 +1000
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>

Szabolcs Ferenczi wrote:
> What is the advantage of the lock-free algorithm? Pros:
>
> 1: If there is no conflict in the actual interaction among threads,
>   the overhead is less than by a conventional mutual exclusion
>   algorithm.

Lock-free algorithms address the situation where there *is*
conflict/contention, and where lock-based techniques would require threads
to be blocked. Taking threads off processors and placing them back later
incurs a lot of overheads, cools caches etc and can greatly lower
concurrency. Lock-free algorithms address contention by retrying operations
rather than blocking the thread (though the algorithm may degrade to
blocking depending on what its being used for). It is far more
efficient/effective to repeat a sequence of instructions than to block the
thread.

Livelock is addressed via wait-free / obstruction-free techniques where some
thread is guaranteed to make progress. If a CAS-loop fails for one thread
that means it succeeded for another one.

The implementation of locks will often use "lock-free" techniques internally
to make them more efficient on multi-processor systems.

In the uncontended case, the path through a lock-free algorithm may be
longer than a lock-using algorithm.

> 1: It is more complicated, more difficult to prove its correctness or
>   to test it. It is a major drawback.

Yes which is why we leave it to the experts to define these things and then
use them.

> 2: When there are frequent conflicts between threads, i.e. under heavy
>   load conditions, it becomes a busy waiting loop and, consequently,
>   it becomes very inefficient just at the critical moment.

In the worst-case pathology some threads might continually retry, but that
means other threads made progress. If a CAS loop fails in one thread it is
because it succeeded in another.

> Why are people keen to invent so-called lock-free algorithms if they
> cannot prove the correctness nor can they test them?

I think there are more people keen to use them rather than invent them. And
yes inventing them is fraught with peril and is best left to the experts.

Like any performance tool you need to evaluate it in context. Any mechanism
has a "sweet spot" where it performs best for the given application and
load; and they all degrade under various conditions.

Use the best tool available for a given job.

Note there are also "local" versus "global" performance issues here. If your
server application is the only thing running and tries to utilize all CPU's
all the time, the wait-free/lock-free techniques can be a boon. However, if
there are half a dozen applications running on the system, all competing for
CPU resources, then the use of lock-free might improve the throughput of an
individual application, but at the expense of the other applications. In a
sense lock-free makes an application "greedy" for CPU and in a group
environment it may be better to have less-greedy applications.

Ultimately the best solution is to always remove contention - if you can do
it.

Cheers,
David Holmes


From szabolcs.ferenczi at gmail.com  Sun Apr 15 19:34:03 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 16 Apr 2007 01:34:03 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <31f2a7bd0704151520i7854d7d0j276e40fd980aa6c@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
	<4622A3AB.9030804@kav.dk>
	<31f2a7bd0704151520i7854d7d0j276e40fd980aa6c@mail.gmail.com>
Message-ID: <c8955b000704151634o2ca60e1i1eaef51737a95d27@mail.gmail.com>

On 16/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> I was misled by the 'contains' method documentation in the same way
> Szabolcs was, but I now see that the meaning of 'optional' is spelled
> out in the Collection javadoc.
>
> I think it would be nice if all AbstractQueue implementations
> implemented this optional exception in the same way, and maybe they do.
>
> In any event, it could do more harm than good to change it now, I realize.

I am afraid there is a major difference between a Collection which is
designed for use in a single threaded environment and a
(Linked)BlockingQueue which is a shared data structure intended to be
used by multiple threads. While throwing an exception can be justified
in a single threaded environment, it is not justified in case of
multiple threads using the shared data structure. In the latter case
it is not an exception when a queried piece of data is not present at
the time of query. Although, any query like this does not make too
much sense either, the documentation should be exact, however.

Besides, I see major problems with this method in case of a shared
data structure as well as with other methods that shared classes
inherit from sequential classes.

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Sun Apr 15 20:00:40 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 16 Apr 2007 10:00:40 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not
	throwNullPointerException for the method call contains
In-Reply-To: <c8955b000704151634o2ca60e1i1eaef51737a95d27@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEEDHGAA.dcholmes@optusnet.com.au>

Szabolcs Ferenczi wrote:
> I am afraid there is a major difference between a Collection which is
> designed for use in a single threaded environment and a
> (Linked)BlockingQueue which is a shared data structure intended to be
> used by multiple threads. While throwing an exception can be justified
> in a single threaded environment, it is not justified in case of
> multiple threads using the shared data structure.

I can't see what threading has to do with whether a method throws an
exception or not.

In the case of contains(null) it really boils down to whether asking for
something that can't possibly be there is a "silly question" that should
just be ignored (ie return false), or whether it indicates a serious flaw in
the caller because the caller should never have presented a null in the
first place - and so throw an Exception.

> Besides, I see major problems with this method in case of a shared
> data structure as well as with other methods that shared classes
> inherit from sequential classes.

Any query method has limits in a concurrent context. That doesn't mean they
aren't useful, it just means the limits have to be understood. Ultimately it
how an application uses the data structure that determines what makes sense
and what does not. The data structure provides an API that is as general as
possible to account for as many use-cases as is reasonable.

Cheers,
David Holmes


From szabolcs.ferenczi at gmail.com  Sun Apr 15 20:02:41 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 16 Apr 2007 02:02:41 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704151702u28dbcd16gc94921e423eed659@mail.gmail.com>

On 16/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> Szabolcs Ferenczi wrote:
> > What is the advantage of the lock-free algorithm? Pros:
> >
> > 1: If there is no conflict in the actual interaction among threads,
> >   the overhead is less than by a conventional mutual exclusion
> >   algorithm.
>
> Lock-free algorithms address the situation where there *is*
> conflict/contention, and where lock-based techniques would require threads
> to be blocked.

I am afraid both flavour addresses the situation when there is
conflict/contention. The main difference is in the abstraction level.

The "lock-based" solution stays at a high abstraction level and does
not specify how to solve the locking. It only defines that
conflict/contention must be avoided. Locking can be implemented by
descheduling threads but it can be implemented by spin locking as
well. It depends on the implementation.

On the other hand, the "lock-free" solution defines how to schedule
the threads (manually). And it is both complicated and difficult to
prove or test.

Do not forget that we are speaking of short term scheduling. Note that
for long term scheduling "lock-free" versions are inefficient.

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Sun Apr 15 20:09:38 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 16 Apr 2007 10:09:38 +1000
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704151702u28dbcd16gc94921e423eed659@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEEDHGAA.dcholmes@optusnet.com.au>

> > Lock-free algorithms address the situation where there *is*
> > conflict/contention, and where lock-based techniques would
> > require threads to be blocked.
>
> I am afraid both flavour addresses the situation when there is
> conflict/contention. The main difference is in the abstraction level.

Of course they both address contention. My point was in response to your
statement that lock-free was about the "no conflict" case and that is not
true. Uncontended lock-free can perform worse than uncontended lock-based.
Lock-free addresses contention in a more efficient way that lock-based,
under certain conditions.

David


From szabolcs.ferenczi at gmail.com  Sun Apr 15 20:21:33 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 16 Apr 2007 02:21:33 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not
	throwNullPointerException for the method call contains
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEEDHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704151634o2ca60e1i1eaef51737a95d27@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEDHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704151721v653750a9wbe98e65f87a4ba9b@mail.gmail.com>

On 16/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> I can't see what threading has to do with whether a method throws an
> exception or not.
>
> In the case of contains(null) it really boils down to whether asking for
> something that can't possibly be there is a "silly question" that should
> just be ignored (ie return false), or whether it indicates a serious flaw in
> the caller because the caller should never have presented a null in the
> first place - and so throw an Exception.

Well, in this case threading does not really plays role. In this case
the data structure does not allow for null and if query is about a
null item, it should result in the same behavior as when the null item
is attempted to be inserted --- exception.

I really made this remark for the case if an exception is thrown when
a query is unsuccessful for the moment. But it is not the case with
"contains(null)"

> > Besides, I see major problems with this method in case of a shared
> > data structure as well as with other methods that shared classes
> > inherit from sequential classes.
>
> Any query method has limits in a concurrent context. That doesn't mean they
> aren't useful, it just means the limits have to be understood. Ultimately it
> how an application uses the data structure that determines what makes sense
> and what does not. The data structure provides an API that is as general as
> possible to account for as many use-cases as is reasonable.

I am curious when a query such as "contains(youCanHaveThisItem)" is
useful in a concurrent context. Remember---in a concurrent context. It
may be useful in a single threaded environment where it is guarantied
that the subsequent get will find it there but you can do nothing with
this query in a multi-threaded case, do you?

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Sun Apr 15 20:33:01 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 16 Apr 2007 10:33:01 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not
	throwNullPointerException for the method call contains
In-Reply-To: <c8955b000704151721v653750a9wbe98e65f87a4ba9b@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEEEHGAA.dcholmes@optusnet.com.au>

> I am curious when a query such as "contains(youCanHaveThisItem)" is
> useful in a concurrent context. Remember---in a concurrent context. It
> may be useful in a single threaded environment where it is guarantied
> that the subsequent get will find it there but you can do nothing with
> this query in a multi-threaded case, do you?

If your requirement is "contains(X) implies get(X) will succeed" - then no
you can't in general do that. But queries aren't always used that way - it
may be a "hint" to decide whether to add something or not; it may be a
simple "sample" to see how often, in general, a type of item exists in the
structure. Also just because a data structure is used concurrently it
doesn't mean that all operations are applied concurrently at all times - it
depends on how the data structure is used. For example, multiple producer
with single-consumer - the consumer can use contains(x) and know get(x) will
succeed. Or, after being concurrently populated the data structure may be
handed over to a single thread that performs some initial pre-processing,
perhaps removing certain items or doing an extra processing step for those
items, before handing of to more general "consumption" using multiple
consumers.

I don't presume to know all the ways in which people use their data
structures.

Cheers,
David Holmes


From holger at wizards.de  Sun Apr 15 21:11:39 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Mon, 16 Apr 2007 03:11:39 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does
 not	throwNullPointerException for the method call contains
In-Reply-To: <c8955b000704151721v653750a9wbe98e65f87a4ba9b@mail.gmail.com>
References: <c8955b000704151634o2ca60e1i1eaef51737a95d27@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDHGAA.dcholmes@optusnet.com.au>
	<c8955b000704151721v653750a9wbe98e65f87a4ba9b@mail.gmail.com>
Message-ID: <4622CD4B.5000100@wizards.de>

Szabolcs Ferenczi wrote:
> Well, in this case threading does not really plays role. In this case
> the data structure does not allow for null and if query is about a
> null item, it should result in the same behavior as when the null item
> is attempted to be inserted --- exception.

Taking into consideration the general robustness principle "be
conservative in what you do, be liberal in what you accept from others",
coupled with the "principle of least surprise", one could argue just as
well for returning false from contains(null).

-h

From tackline at tackline.plus.com  Sun Apr 15 22:28:07 2007
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Mon, 16 Apr 2007 03:28:07 +0100
Subject: [concurrency-interest] LinkedBlockingQueue does
 not	throwNullPointerException for the method call contains
In-Reply-To: <4622CD4B.5000100@wizards.de>
References: <c8955b000704151634o2ca60e1i1eaef51737a95d27@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEDHGAA.dcholmes@optusnet.com.au>	<c8955b000704151721v653750a9wbe98e65f87a4ba9b@mail.gmail.com>
	<4622CD4B.5000100@wizards.de>
Message-ID: <4622DF37.1080306@tackline.plus.com>

Holger Hoffst?tte wrote:
> 
> Taking into consideration the general robustness principle "be
> conservative in what you do, be liberal in what you accept from others",

That's a very dubious principle. It's the sort of thinking which has 
left us with the current state of HTML, for instance. How nasty is that? 
Better to catch bugs as soon as possible, even if it causes a little 
inconvenience to some adversaries.

> coupled with the "principle of least surprise", one could argue just as
> well for returning false from contains(null).

Least surprise would be making nulls work consistently, rather than 
depending upon who wrote the class.

Tom Hawtin

From joe.bowbeer at gmail.com  Sun Apr 15 22:28:16 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 15 Apr 2007 19:28:16 -0700
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
Message-ID: <31f2a7bd0704151928i6339b2e6r96d1380442ad0a1@mail.gmail.com>

On 4/15/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> 2: When there are frequent conflicts between threads, i.e. under heavy
>   load conditions, it becomes a busy waiting loop and, consequently,
>   it becomes very inefficient just at the critical moment.
>

I'd like to see examples of badly behaved lock-free implementations.

I've been surprised before at how frequently some combinations of
processes fall into undesirable resonances.  These are especially
apparent in graphics applications, where the resonances result in
visual patterns.  A graphics process that progresses too infrequently
appears "jerky" or even invisible.

When responsiveness or smoothness is as important as performance,
wait-free or fair guarantees are important.

--Joe

From jseigh_cp00 at xemaps.com  Mon Apr 16 06:47:56 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Mon, 16 Apr 2007 06:47:56 -0400
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704151702u28dbcd16gc94921e423eed659@mail.gmail.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
	<c8955b000704151702u28dbcd16gc94921e423eed659@mail.gmail.com>
Message-ID: <4623545C.9020001@xemaps.com>

Szabolcs Ferenczi wrote:

>On 16/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>  
>
>>Szabolcs Ferenczi wrote:
>>    
>>
>>>What is the advantage of the lock-free algorithm? Pros:
>>>
>>>1: If there is no conflict in the actual interaction among threads,
>>>  the overhead is less than by a conventional mutual exclusion
>>>  algorithm.
>>>      
>>>
>>Lock-free algorithms address the situation where there *is*
>>conflict/contention, and where lock-based techniques would require threads
>>to be blocked.
>>    
>>
>
>I am afraid both flavour addresses the situation when there is
>conflict/contention. The main difference is in the abstraction level.
>
>The "lock-based" solution stays at a high abstraction level and does
>not specify how to solve the locking. It only defines that
>conflict/contention must be avoided. Locking can be implemented by
>descheduling threads but it can be implemented by spin locking as
>well. It depends on the implementation.
>
>On the other hand, the "lock-free" solution defines how to schedule
>the threads (manually). And it is both complicated and difficult to
>prove or test.
>
>Do not forget that we are speaking of short term scheduling. Note that
>for long term scheduling "lock-free" versions are inefficient.
>
>  
>


You're making a lot of unsupported suppositions here.  One of the issues 
is  forward progress.
Lock-free (by definition) guarantees at least one thread makes forward 
progress.  Wait-free
guarantees the current thread will make forward progress.   Conventional 
synchronization
(mutexes and condvars) don't make any guarantees about forward progress, 
they only
make guarantees about when forward progress will not be made, i.e. 
negative guarantees.
The early Java docs used to make statements about only using cooperative 
threads in part
because of this.  You could only guarantee forward progress in a thread 
if in the case
where it didn't make forward progress, eventually enough other threads 
would block and
allow the former to make forward progress.  Competive threading patterns 
don't guarantee
forward progress for all threads.  Some threads may be allowed to starve.

As far as proving correctness, lock-free implementations aren't any more 
difficult to prove than
lock implementations in my experience.  Proving anything in general is 
fairly diffcult, though.
Mostly it's figuring out which assertions to prove.

Testing isn't necessarily all that difficult either.  Some lock-free 
algorithms allow you to make
observations that aren't available to lock based algorithms.  You can 
use this to verify that
your code works under some boundary conditions, e.g. that you've avoided 
certain race
conditions.

--
Joe Seigh

From szabolcs.ferenczi at gmail.com  Mon Apr 16 15:00:09 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 16 Apr 2007 21:00:09 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
Message-ID: <c8955b000704161200o3447461dq97c83cbcbc01e0c5@mail.gmail.com>

I am trying to test LinkedBlockingQueue and I cannot get the class
cast test for method add through:

public class lbqTest {

    LinkedBlockingQueue q;

    @Before
    public void setUp() {
	q = new LinkedBlockingQueue<Integer>(3);
    }

    @Test (expected=ClassCastException.class)
    public void seqAddNonmatchingArg() {
	q.add(new String("x"));
    }
...
}

What I receive is this:

There was 1 failure:
1) seqAddNonmatchingArg(lbqTest.lbqTest)
java.lang.AssertionError: Expected exception: java.lang.ClassCastException

I would expect a successful test according to the documentation of the
method.

What is wrong? How can I get the test pass?

Best Regards,
Szabolcs

From mike.quilleash at subexazure.com  Mon Apr 16 15:31:00 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Mon, 16 Apr 2007 15:31:00 -0400
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
 ClassCastException
In-Reply-To: <c8955b000704161200o3447461dq97c83cbcbc01e0c5@mail.gmail.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E0674A7A1@MI8NYCMAIL15.Mi8.com>

Generics only offer compile-time checking.  During compilation the
<Integer> of the LBQ is "erased" from the class definition so the
internal implementation has no knowledge of what type the LBQ was
declared as.  Just pretend at runtime all generic method
parameters/returns and fields become Object.  The only way to achieve
what you are asking would be to explicitly pass in Integer.class to the
LBQ during constructor and have it do a clazz.isInstance() check for
each add.

I imagine the setUp() line is throwing a compile warning about
unsafe/unchecked assignment indicating you have lost the compile-time
type-safety of the <Integer>.

HTH.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of
Szabolcs Ferenczi
Sent: 16 April 2007 20:00
To: Concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
ClassCastException

I am trying to test LinkedBlockingQueue and I cannot get the class cast
test for method add through:

public class lbqTest {

    LinkedBlockingQueue q;

    @Before
    public void setUp() {
	q = new LinkedBlockingQueue<Integer>(3);
    }

    @Test (expected=ClassCastException.class)
    public void seqAddNonmatchingArg() {
	q.add(new String("x"));
    }
...
}

What I receive is this:

There was 1 failure:
1) seqAddNonmatchingArg(lbqTest.lbqTest)
java.lang.AssertionError: Expected exception:
java.lang.ClassCastException

I would expect a successful test according to the documentation of the
method.

What is wrong? How can I get the test pass?

Best Regards,
Szabolcs
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From szabolcs.ferenczi at gmail.com  Mon Apr 16 16:27:26 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 16 Apr 2007 22:27:26 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704161327r1b4e4349y9cc8bb5b1750a192@mail.gmail.com>

On 16/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:

> .... Taking threads off processors and placing them back later
> incurs a lot of overheads, cools caches etc and can greatly lower
> concurrency.

It depends on the hardware. For instance, if a processor is especially
designed for multi-tasking, context switch can be very inexpensive. An
example was the Transputer where a context switch is comparable to any
other instruction time. Well, it was not  a business success story but
it indicates that if hardware designers want, they can make the
context switch very inexpensive. And soon they will want it.

Surprisingly, however, hardware technology develops faster than
software technology. If you hard wire your algorithms for today's
hardware technology, and you do it with the so-called lock-free
algorithm, soon you get into trouble. The thought to be efficient
algorithm becomes very inefficient.

In fact, you are already in trouble because a lock-free algorithm is
more complicated and less testable than a comparable algorithm that
uses abstractions like critical section. And you gain practically
nothing. You only have the illusion that you have control over
something.

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Mon Apr 16 18:18:37 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 08:18:37 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E0674A7A1@MI8NYCMAIL15.Mi8.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEEKHGAA.dcholmes@optusnet.com.au>

And you'll get the ClassCastException when you attempt to extract the String
as an Integer.

The line in Collection.add that says "... others will impose restrictions on
the type of elements that may be added." is not referring to Generics, but
specific concrete implementations that might impose their own direct
instanceof checks  eg pre-generic ListInteger, SetString etc.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Mike
> Quilleash
> Sent: Tuesday, 17 April 2007 5:31 AM
> To: Szabolcs Ferenczi; Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not throw
> ClassCastException
>
>
> Generics only offer compile-time checking.  During compilation the
> <Integer> of the LBQ is "erased" from the class definition so the
> internal implementation has no knowledge of what type the LBQ was
> declared as.  Just pretend at runtime all generic method
> parameters/returns and fields become Object.  The only way to achieve
> what you are asking would be to explicitly pass in Integer.class to the
> LBQ during constructor and have it do a clazz.isInstance() check for
> each add.
>
> I imagine the setUp() line is throwing a compile warning about
> unsafe/unchecked assignment indicating you have lost the compile-time
> type-safety of the <Integer>.
>
> HTH.
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of
> Szabolcs Ferenczi
> Sent: 16 April 2007 20:00
> To: Concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] LinkedBlockingQueue does not throw
> ClassCastException
>
> I am trying to test LinkedBlockingQueue and I cannot get the class cast
> test for method add through:
>
> public class lbqTest {
>
>     LinkedBlockingQueue q;
>
>     @Before
>     public void setUp() {
> 	q = new LinkedBlockingQueue<Integer>(3);
>     }
>
>     @Test (expected=ClassCastException.class)
>     public void seqAddNonmatchingArg() {
> 	q.add(new String("x"));
>     }
> ...
> }
>
> What I receive is this:
>
> There was 1 failure:
> 1) seqAddNonmatchingArg(lbqTest.lbqTest)
> java.lang.AssertionError: Expected exception:
> java.lang.ClassCastException
>
> I would expect a successful test according to the documentation of the
> method.
>
> What is wrong? How can I get the test pass?
>
> Best Regards,
> Szabolcs
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>  This e-mail is bound by the terms and conditions described at
http://www.subexazure.com/mail-disclaimer.html


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dcholmes at optusnet.com.au  Mon Apr 16 18:30:43 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 08:30:43 +1000
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704161327r1b4e4349y9cc8bb5b1750a192@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEELHGAA.dcholmes@optusnet.com.au>

Szabolcs Ferenczi wrote:
> On 16/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> > .... Taking threads off processors and placing them back later
> > incurs a lot of overheads, cools caches etc and can greatly lower
> > concurrency.
>
> It depends on the hardware. For instance, if a processor is especially
> designed for multi-tasking, context switch can be very inexpensive. An
> example was the Transputer

You asked why people use lock-free algorithms and I explained it to you.
Nobody on this list in running Java on a transputer, so its irrelevant. When
I discuss Java SE and the JDK I'm assuming we're considering the platforms
where Java SE runs. I'm not trying to make comments that cover every
conceivable piece of computing hardware. I suggest you go and read a lot of
literature on the subject to understand where the motivation comes from.


Many forms of optimization induces some coupling with the hardware - but
these are not things that change overnight. If it turns out that lock-free
doesn't work as well on future architectures then we'll replace it with
something else as needs be. That's how the real world works: there's a need,
then a solution, and if the need changes or the solution stops working, we
adapt and come up with a new solution. It's called "engineering".

Cheers,
David Holmes


From szabolcs.ferenczi at gmail.com  Mon Apr 16 18:35:07 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 00:35:07 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEEKHGAA.dcholmes@optusnet.com.au>
References: <DAE04D9F6FD21448A220918A522FB60E0674A7A1@MI8NYCMAIL15.Mi8.com>
	<NFBBKALFDCPFIDBNKAPCKEEKHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704161535i4f76aec8v478599edbdf3ba09@mail.gmail.com>

On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> And you'll get the ClassCastException when you attempt to extract the String
> as an Integer.
>
> The line in Collection.add that says "... others will impose restrictions on
> the type of elements that may be added." is not referring to Generics, but
> specific concrete implementations that might impose their own direct
> instanceof checks  eg pre-generic ListInteger, SetString etc.

Thanks a lot. So what is your suggestion for the test exactly?

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Mon Apr 16 18:39:57 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 08:39:57 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <c8955b000704161535i4f76aec8v478599edbdf3ba09@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEEMHGAA.dcholmes@optusnet.com.au>

You can't write a test for "optional" behaviour without some way of knowing
whether the implementation you are testing is trying to support that
optional behaviour.

My only suggestion is skip the test because it isn't testable without
external knowledge of the concrete collection type.

David Holmes

> -----Original Message-----
> From: Szabolcs Ferenczi [mailto:szabolcs.ferenczi at gmail.com]
> Sent: Tuesday, 17 April 2007 8:35 AM
> To: dholmes at ieee.org
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not throw
> ClassCastException
>
>
> On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > And you'll get the ClassCastException when you attempt to
> extract the String
> > as an Integer.
> >
> > The line in Collection.add that says "... others will impose
> restrictions on
> > the type of elements that may be added." is not referring to
> Generics, but
> > specific concrete implementations that might impose their own direct
> > instanceof checks  eg pre-generic ListInteger, SetString etc.
>
> Thanks a lot. So what is your suggestion for the test exactly?
>
> Best Regards,
> Szabolcs


From szabolcs.ferenczi at gmail.com  Mon Apr 16 18:57:52 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 00:57:52 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEEMHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704161535i4f76aec8v478599edbdf3ba09@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEEMHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704161557l37bd88ndf03aa3d986197d4@mail.gmail.com>

On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> You can't write a test for "optional" behaviour without some way of knowing
> whether the implementation you are testing is trying to support that
> optional behaviour.

Strange. If you cannot test it, how can you use it? If it is so
optional that it can behave any way it likes, what can you use it for?

I was trying to test it according the documentation.
"ClassCastException - if the class of the specified element prevents
it from being added to this queue" I thought, if it is documented, it
could be tested as well. Sorry.

Szabolcs

From dcholmes at optusnet.com.au  Mon Apr 16 19:04:34 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 09:04:34 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <c8955b000704161557l37bd88ndf03aa3d986197d4@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEENHGAA.dcholmes@optusnet.com.au>

You cannot test an unknown concrete implementation against optional parts of
the specification.

For non-optional functionality you can write a generic test to test any
implementation.

But for optional behaviour you must write the tests against a specific known
concrete implementation. ie if I write a class ListInteger that implements
Collection and only accepts Integer objects, then I can write the tests that
verify that, based on the specification. Now even this can be generalized in
that you can write a test for a type-constrained collection given the
expected type it is constrained to. But the knowledge that you actually have
a type-constrained collections is not evident in the program itself (it
isn't part of the type system, there is no method to query the collection
etc).

David



> -----Original Message-----
> From: Szabolcs Ferenczi [mailto:szabolcs.ferenczi at gmail.com]
> Sent: Tuesday, 17 April 2007 8:58 AM
> To: dholmes at ieee.org
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not throw
> ClassCastException
>
>
> On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > You can't write a test for "optional" behaviour without some
> way of knowing
> > whether the implementation you are testing is trying to support that
> > optional behaviour.
>
> Strange. If you cannot test it, how can you use it? If it is so
> optional that it can behave any way it likes, what can you use it for?
>
> I was trying to test it according the documentation.
> "ClassCastException - if the class of the specified element prevents
> it from being added to this queue" I thought, if it is documented, it
> could be tested as well. Sorry.
>
> Szabolcs


From szabolcs.ferenczi at gmail.com  Mon Apr 16 19:17:20 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 01:17:20 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEENHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704161557l37bd88ndf03aa3d986197d4@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEENHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704161617s76e8e510xd005d0ff32f3256b@mail.gmail.com>

On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> You cannot test an unknown concrete implementation against optional parts of
> the specification.

Well, I can test it, if it is specified, i.e. if it is intended to be
used. On the other hand, if the specification says that it behaves so
if you like so but it behaves otherwise, if you like it otherwise,
then, of course, I cannot test it. You are right there. Sorry that I
was trying to take it seriously.

Best Regards,
Szabolcs

From joe.bowbeer at gmail.com  Mon Apr 16 19:19:13 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 16 Apr 2007 16:19:13 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	NullPointerException for the method call contains
In-Reply-To: <31f2a7bd0704151520i7854d7d0j276e40fd980aa6c@mail.gmail.com>
References: <c8955b000704151259q3384fef7t313885ba3852df51@mail.gmail.com>
	<31f2a7bd0704151337w573727b9p29f952e52e63b0dd@mail.gmail.com>
	<c8955b000704151406ida3ee0fnfe724bb9b83a824f@mail.gmail.com>
	<31f2a7bd0704151429t2c77e176o57b9bf2cbad6ebf7@mail.gmail.com>
	<4622A3AB.9030804@kav.dk>
	<31f2a7bd0704151520i7854d7d0j276e40fd980aa6c@mail.gmail.com>
Message-ID: <31f2a7bd0704161619w9f1c656j7bbf844b5bc54b52@mail.gmail.com>

Martin Buchholz mentioned off-list that we could link the instances of
"(optional)" in the Collection method descriptions to the paragraph in
the Collection class description that covers optional restrictions.

Is this worthwhile?

Here's what the fix would look like:

Collection.java

1. Add "optional-restrictions" anchor.

 * <p><a name="optional-restrictions"/>
 * Some collection implementations have restrictions on the elements that they
 * may contain.  For example, some implementations prohibit null elements,

2. Add links to the optional restrictions paragraph.

There are ten instances of "(optional)" -- resulting from five sets of
ClassCastException and NullPointerException.  In each instance,
"(optional)" would be replaced by:

 (<a href="#optional-restrictions">optional</a>)

--Joe

From szabolcs.ferenczi at gmail.com  Mon Apr 16 19:21:50 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 01:21:50 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <4623545C.9020001@xemaps.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
	<c8955b000704151702u28dbcd16gc94921e423eed659@mail.gmail.com>
	<4623545C.9020001@xemaps.com>
Message-ID: <c8955b000704161621i5de2f191x2660010f93d83ad0@mail.gmail.com>

On 16/04/07, Joseph Seigh <jseigh_cp00 at xemaps.com> wrote:

> You're making a lot of unsupported suppositions here.

Very well. Then, I give some support for my statements in the form of
some working test in the TMC framework:

    private class NonblockingCounter {  // class under test
	private AtomicInteger value = new AtomicInteger(0);
	public int getValue() {return value.get();}
	public int increment() {
	    int v;
	    do {
		v = value.get();
		for (int i = 0; i<10000; ++i) i = i+2-2; // delay for the test
	    } while (!value.compareAndSet(v, v + 1));
	    return v + 1;
	}
    }
    private class TUnitTestLockFree extends MultithreadedTestCase {
	NonblockingCounter cnt;
	@Override public void initialize() {
	    cnt = new NonblockingCounter();
    	}
    	public void thread1() {
	    for (int i = 0; i<1000; ++i) cnt.increment();
    	}
    	public void thread2() {
	    for (int i = 0; i<1000; ++i) cnt.increment();
    	}
    	public void thread3() {
	    for (int i = 0; i<1000; ++i) cnt.increment();
    	}
	@Override public void finish() {
            assertEquals(3000, cnt.getValue());
	}
    }
    @Test
    public void testLockFree_tunit() throws Throwable {
	final long t0 = System.nanoTime();
    	TestFramework.runOnce( new TUnitTestLockFree() );
	long duration = (System.nanoTime() - t0)/1000000;
	assertEquals(120, duration, 40);
    }

    private class BlockingCounter {  // class under test
	private Integer value = new Integer(0);
	public synchronized int getValue() {return value;}
	public synchronized int increment() {
	    for (int i = 0; i<10000; ++i) i = i+2-2; // delay for the test
	    return ++value;
	}
    }
    private class TUnitTestLockBased extends MultithreadedTestCase {
	BlockingCounter cnt;
	@Override public void initialize() {
	    cnt = new BlockingCounter();
    	}
    	public void thread1() {
	    for (int i = 0; i<1000; ++i) cnt.increment();
    	}
    	public void thread2() {
	    for (int i = 0; i<1000; ++i) cnt.increment();
    	}
    	public void thread3() {
	    for (int i = 0; i<1000; ++i) cnt.increment();
    	}
	@Override public void finish() {
            assertEquals(3000, cnt.getValue());
	}
    }
    @Test
    public void testLockBased_tunit() throws Throwable {
	final long t0 = System.nanoTime();
    	TestFramework.runOnce( new TUnitTestLockBased() );
	long duration = (System.nanoTime() - t0)/1000000;
	assertEquals(90, duration, 15);
    }

As you can see, the difference between the lock-free and the
lock-based algorithm is ca. 4/3 in performance in favor of the
lock-based one. Besides, the lock-based version is much more simple.
You can reconstruct the test if you like. I have checked it on a dual
core Windows XP, java 1.6

I have taken the lock-free counter fragment from a publication:

Java theory and practice: Introduction to nonblocking algorithms
Brian Goetz (brian at quiotix.com), Principal Consultant, Quiotix
18 Apr 2006
http://www-128.ibm.com/developerworks/java/library/j-jtp04186/index.html

I have inserted some delay into both of the algorithms. If the delay
is not inserted, there is a slight advantage for the lock-free
algorithm. That slight advantage would not compensate for the
disadvantage in complexity, however.

Is that some support for the suppositions?

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Mon Apr 16 19:24:48 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 09:24:48 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <c8955b000704161617s76e8e510xd005d0ff32f3256b@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEEPHGAA.dcholmes@optusnet.com.au>

I don't think you get it.

You can test for optional behaviour but you need to know by some mechanism
which option the implementation has chosen. Of course you can expand your
test to allow any of the optional behaviours as meaning the test passed.

If a collection implementation can choose to throw ClassCastException if an
element of the wrong type is inserted, then you need to know:
a) that the collection you were given made that choice; and
b) what types it disallows

Then you can test that it does what it was specified to do.

I don't think there is anything else I can say.

David

> -----Original Message-----
> From: Szabolcs Ferenczi [mailto:szabolcs.ferenczi at gmail.com]
> Sent: Tuesday, 17 April 2007 9:17 AM
> To: dholmes at ieee.org
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not throw
> ClassCastException
>
>
> On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > You cannot test an unknown concrete implementation against
> optional parts of
> > the specification.
>
> Well, I can test it, if it is specified, i.e. if it is intended to be
> used. On the other hand, if the specification says that it behaves so
> if you like so but it behaves otherwise, if you like it otherwise,
> then, of course, I cannot test it. You are right there. Sorry that I
> was trying to take it seriously.
>
> Best Regards,
> Szabolcs


From szabolcs.ferenczi at gmail.com  Mon Apr 16 19:29:15 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 01:29:15 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEEPHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704161617s76e8e510xd005d0ff32f3256b@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEEPHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704161629s5eecea3ld96a109e1efe9dcf@mail.gmail.com>

On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:

> I don't think there is anything else I can say.

Well, you could answer my original question: How could this test be
changed so that it would pass. That is all.

Thanks for your efforts,

Best Regards,
Szabolcs

From hanson.char at gmail.com  Mon Apr 16 19:42:03 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 16 Apr 2007 16:42:03 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <c8955b000704161200o3447461dq97c83cbcbc01e0c5@mail.gmail.com>
References: <c8955b000704161200o3447461dq97c83cbcbc01e0c5@mail.gmail.com>
Message-ID: <ca53c8f80704161642n4bed1e87w4fb92256ac9d2793@mail.gmail.com>

Ever considered the use of Collections.checkedCollection(Collection<E>,
Class<E>) ?  That will provide you with runtime type checking.

Hanson Char

On 4/16/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> I am trying to test LinkedBlockingQueue and I cannot get the class
> cast test for method add through:
>
> public class lbqTest {
>
>     LinkedBlockingQueue q;
>
>     @Before
>     public void setUp() {
>         q = new LinkedBlockingQueue<Integer>(3);
>     }
>
>     @Test (expected=ClassCastException.class)
>     public void seqAddNonmatchingArg() {
>         q.add(new String("x"));
>     }
> ...
> }
>
> What I receive is this:
>
> There was 1 failure:
> 1) seqAddNonmatchingArg(lbqTest.lbqTest)
> java.lang.AssertionError: Expected exception: java.lang.ClassCastException
>
> I would expect a successful test according to the documentation of the
> method.
>
> What is wrong? How can I get the test pass?
>
> Best Regards,
> Szabolcs
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070416/5f2eff3c/attachment.html 

From hanson.char at gmail.com  Mon Apr 16 19:47:16 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 16 Apr 2007 16:47:16 -0700
Subject: [concurrency-interest] Source repository of test/loops
Message-ID: <ca53c8f80704161647v339e24f4r78fef028bd81f965@mail.gmail.com>

>http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/

Any chance there is an anonymous CVS or SVN access to this source
repository ?  That would be really nice.

Thanks,
Hanson Char

From szabolcs.ferenczi at gmail.com  Mon Apr 16 19:47:34 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 01:47:34 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not throw
	ClassCastException
In-Reply-To: <ca53c8f80704161642n4bed1e87w4fb92256ac9d2793@mail.gmail.com>
References: <c8955b000704161200o3447461dq97c83cbcbc01e0c5@mail.gmail.com>
	<ca53c8f80704161642n4bed1e87w4fb92256ac9d2793@mail.gmail.com>
Message-ID: <c8955b000704161647v2a6f6281kac1c6e92e9c16f9c@mail.gmail.com>

On 17/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> Ever considered the use of Collections.checkedCollection(Collection<E>,
> Class<E>) ?  That will provide you with runtime type checking.

No. My concern was to test class LinkedBlockingQueue against its documentation.

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Mon Apr 16 20:49:12 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 10:49:12 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not
	throwClassCastException
In-Reply-To: <c8955b000704161647v2a6f6281kac1c6e92e9c16f9c@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEFBHGAA.dcholmes@optusnet.com.au>

If you check the documentation you will see that LinkedBlockingQueue.add is
inherited from AbstractQueue.add, and the latter does *not* throw
ClassCastException.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Szabolcs
> Ferenczi
> Sent: Tuesday, 17 April 2007 9:48 AM
> To: Hanson Char
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not
> throwClassCastException
>
>
> On 17/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> > Ever considered the use of Collections.checkedCollection(Collection<E>,
> > Class<E>) ?  That will provide you with runtime type checking.
>
> No. My concern was to test class LinkedBlockingQueue against its
> documentation.
>
> Best Regards,
> Szabolcs
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From jseigh_cp00 at xemaps.com  Mon Apr 16 22:02:45 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Mon, 16 Apr 2007 22:02:45 -0400
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <246086.36242.qm@web62513.mail.re1.yahoo.com>
References: <246086.36242.qm@web62513.mail.re1.yahoo.com>
Message-ID: <46242AC5.9000308@xemaps.com>

Eric Crahen wrote:

> */Joseph Seigh <jseigh_cp00 at xemaps.com>/* wrote:
>
>     Testing isn't necessarily all that difficult either. Some lock-free
>     algorithms allow you to make
>     observations that aren't available to lock based algorithms. You can
>     use this to verify that
>     your code works under some boundary conditions, e.g. that you've
>     avoided
>     certain race
>     conditions.
>
> That's very interesting. Do you have any examples of using this to 
> your advantage in testing a lock-less data structure?


In testing PDR (PCOW Deferred Reclamation) algorithms, I usually  add a 
state to memory objects (
current, stale (pending reclamation), and deallocated, and make a count 
of the observed stated.  If
you see a high enough stale count without seeing any deallocated objects 
(which you shouldn't see from
an application program), you know you are getting preempted threads 
holding references to objects
pending reclamation and the memory reclamation is working by not 
deallocating the objects too soon.
I believe Paul McKenney uses the same technque to stress test RCU in the 
Linux kernel.

In lock-free, usually your boundary conditions have race conditions (the 
race condition being on the
safe side).  If you can detect executions in the race condition 
interval, you know you're executing
near the boundary but staying on the safe side.

--
Joe Seigh

From larryr at saturn.sdsu.edu  Mon Apr 16 23:57:37 2007
From: larryr at saturn.sdsu.edu (Larry Riedel)
Date: Mon, 16 Apr 2007 20:57:37 -0700
Subject: [concurrency-interest] Lock-free mania
Message-ID: <1176782257.643149.28308.nullmailer@riedel.org>


I think if there was a question of will the increasing availability and
trendiness of lock-free, wait-free, obstruction-free, blahblahblah-free
tools lead to hordes of "architects" and "principal engineers" choosing
those tools for no technically justifiable reason to create inferior and
broken solutions to nonexistent problems, I think it would be safe to
agree the answer is yes.  But I think the overall net impact of the
availability and trendiness of those tools is still going to be positive.


Larry


From dhanji at gmail.com  Tue Apr 17 00:50:27 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 17 Apr 2007 14:50:27 +1000
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <1176782257.643149.28308.nullmailer@riedel.org>
References: <1176782257.643149.28308.nullmailer@riedel.org>
Message-ID: <aa067ea10704162150x2771401bn78f93ca12b9c0788@mail.gmail.com>

On 4/17/07, Larry Riedel <larryr at saturn.sdsu.edu> wrote:
>
>
> I think if there was a question of will the increasing availability and
> trendiness of lock-free, wait-free, obstruction-free, blahblahblah-free
> tools lead to hordes of "architects" and "principal engineers" choosing
> those tools for no technically justifiable reason to create inferior and
> broken solutions to nonexistent problems, I think it would be safe to
> agree the answer is yes.
>

The same can be said of lockful or other concurrency tools. This doesnt
speak to the general effectiveness of lock-free algorithms (or lockful ones
for that matter). Just like the REST vs. SOA debate.

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070417/0049cab7/attachment.html 

From Martin.Buchholz at Sun.COM  Tue Apr 17 01:19:08 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Mon, 16 Apr 2007 22:19:08 -0700
Subject: [concurrency-interest] 6546713: coll) Clarify meaning of
	"(optional)" in collections docs
Message-ID: <462458CC.80207@sun.com>

Based on recent confusion re: "(optional)" I filed Sun bug:

6546713: coll) Clarify meaning of "(optional)" in collections docs

The implementation is unlikely to change, but at least we can
make the specification a little clearer.

To be very pedantic, changing the spec of a concrete class
to specifiy whether or not the exception is, indeed, optional,
would be an incompatible change, since a subclass of that
concrete class may have chosen differently, and tightening the spec
of the superclass would make the subclass no longer
Liskov-spec-substitutable.

Martin

From Martin.Buchholz at Sun.COM  Tue Apr 17 01:26:29 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Mon, 16 Apr 2007 22:26:29 -0700
Subject: [concurrency-interest] Collection.contains(E)
Message-ID: <46245A85.4000608@sun.com>

Here is an argument for why you might want query operations
like contains(E) to *not* throw when the query object would
not be permitted as an element:

contains(E) is used to build higher-level operations like
removeAll and retainAll.

if s is a set of students at a university, and
if p is a set of professors at a university,
then these sets need not be disjoint, and so
s.removeAll(p)
is an operation that makes sense, and should not be
prohibited, even when *inserting* an element of the
wrong type should be.

So contains(E) should generally never throw exceptions
based on the unsuitability of its argument.

Martin

From dcholmes at optusnet.com.au  Tue Apr 17 02:00:51 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 16:00:51 +1000
Subject: [concurrency-interest] Collection.contains(E)
In-Reply-To: <46245A85.4000608@sun.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEFEHGAA.dcholmes@optusnet.com.au>

The inference from which is that it was a mistake for NullPointerException
and ClassCastException to be optionally allowed on such query methods.

Water under the bridge now of course ...

Cheers,
David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Martin
> Buchholz
> Sent: Tuesday, 17 April 2007 3:26 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Collection.contains(E)
>
>
> Here is an argument for why you might want query operations
> like contains(E) to *not* throw when the query object would
> not be permitted as an element:
>
> contains(E) is used to build higher-level operations like
> removeAll and retainAll.
>
> if s is a set of students at a university, and
> if p is a set of professors at a university,
> then these sets need not be disjoint, and so
> s.removeAll(p)
> is an operation that makes sense, and should not be
> prohibited, even when *inserting* an element of the
> wrong type should be.
>
> So contains(E) should generally never throw exceptions
> based on the unsuitability of its argument.
>
> Martin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dhanji at gmail.com  Tue Apr 17 02:42:05 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 17 Apr 2007 16:42:05 +1000
Subject: [concurrency-interest] Collection.contains(E)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEFEHGAA.dcholmes@optusnet.com.au>
References: <46245A85.4000608@sun.com>
	<NFBBKALFDCPFIDBNKAPCEEFEHGAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10704162342g303ff05cxace029c3320ff362@mail.gmail.com>

On 4/17/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> The inference from which is that it was a mistake for NullPointerException
> and ClassCastException to be optionally allowed on such query methods.


Yea, and if it didnt support the optional method at all--it should be
throwing UnsupportedOperationException. Particularly in the case of
Collections implementations.

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070417/06c8c30f/attachment.html 

From szabolcs.ferenczi at gmail.com  Tue Apr 17 02:43:34 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 08:43:34 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEELHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704161327r1b4e4349y9cc8bb5b1750a192@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEELHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704162343n3e6a09a7r8c58e02ba01007ed@mail.gmail.com>

On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:

> Nobody on this list in running Java on a transputer, so its irrelevant.

Neither do I. However, I would not say that it is irrelevant, since
what I said was that context switch is not necessarily an expensive
operation. I provided you an example for this. Why would it be
irrelevant?

> .... I suggest you go and read a lot of
> literature on the subject to understand where the motivation comes from.

Thank you very much. You have been most helpful indeed.

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Tue Apr 17 02:46:11 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 16:46:11 +1000
Subject: [concurrency-interest] Collection.contains(E)
In-Reply-To: <aa067ea10704162342g303ff05cxace029c3320ff362@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEFFHGAA.dcholmes@optusnet.com.au>

Dhanji,

Unimplemented optional methods do throw UnsupportedOperationException.

We're discussing optional exceptions on methods (where the method itself may
or may not be optional).

Cheers,
David

 -----Original Message-----
From: Dhanji R. Prasanna [mailto:dhanji at gmail.com]
Sent: Tuesday, 17 April 2007 4:42 PM
To: dholmes at ieee.org
Cc: Martin Buchholz; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Collection.contains(E)





  On 4/17/07, David Holmes <dcholmes at optusnet.com.au> wrote:
    The inference from which is that it was a mistake for
NullPointerException
    and ClassCastException to be optionally allowed on such query methods.

  Yea, and if it didnt support the optional method at all--it should be
throwing UnsupportedOperationException. Particularly in the case of
Collections implementations.

  Dhanji.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070417/a7a60193/attachment.html 

From dhanji at gmail.com  Tue Apr 17 02:53:06 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 17 Apr 2007 16:53:06 +1000
Subject: [concurrency-interest] Collection.contains(E)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEFFHGAA.dcholmes@optusnet.com.au>
References: <aa067ea10704162342g303ff05cxace029c3320ff362@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEFFHGAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10704162353s689c405fn734aadebafb8236e@mail.gmail.com>

On 4/17/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  Dhanji,
>
> Unimplemented optional methods do throw UnsupportedOperationException.
>
> We're discussing optional exceptions on methods (where the method itself
> may or may not be optional).
>

My apologies, I missed the subtlety there.

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070417/9f6e8101/attachment.html 

From Eamonn.McManus at Sun.COM  Tue Apr 17 04:09:54 2007
From: Eamonn.McManus at Sun.COM (Eamonn McManus)
Date: Tue, 17 Apr 2007 10:09:54 +0200
Subject: [concurrency-interest] Collection.contains(E)
In-Reply-To: <46245A85.4000608@sun.com>
References: <46245A85.4000608@sun.com>
Message-ID: <462480D2.5040403@sun.com>

Martin Buchholz wrote:
> Here is an argument for why you might want query operations
> like contains(E) to *not* throw when the query object would
> not be permitted as an element:
>   

This is basically the same argument as for why these methods in 
Collection<E> take a parameter of type Object or Collection<?> rather 
than E or Collection<? extends E>. It's a good argument, though its 
extension to null elements is perhaps less convincing.

?amonn McManus   JMX Spec Lead   http://weblogs.java.net/blog/emcmanus/



Martin Buchholz wrote:
> Here is an argument for why you might want query operations
> like contains(E) to *not* throw when the query object would
> not be permitted as an element:
>
> contains(E) is used to build higher-level operations like
> removeAll and retainAll.
>
> if s is a set of students at a university, and
> if p is a set of professors at a university,
> then these sets need not be disjoint, and so
> s.removeAll(p)
> is an operation that makes sense, and should not be
> prohibited, even when *inserting* an element of the
> wrong type should be.
>
> So contains(E) should generally never throw exceptions
> based on the unsuitability of its argument.
>
> Martin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>   


From szabolcs.ferenczi at gmail.com  Tue Apr 17 04:23:20 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 10:23:20 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does not
	throwClassCastException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEFBHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704161647v2a6f6281kac1c6e92e9c16f9c@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEFBHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704170123t44b17aa0r51f0841790f53835@mail.gmail.com>

On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> If you check the documentation ...

That is what I did.

> ... you will see that LinkedBlockingQueue.add is
> inherited from AbstractQueue.add, and the latter does *not* throw
> ClassCastException.

On the contrary to what you claim, this is what I found:

http://java.sun.com/javase/6/docs/api/java/util/AbstractQueue.html#add(E)

add

public boolean add(E e)

    Inserts the specified element into this queue if it is possible to
do so immediately without violating capacity restrictions, returning
true upon success and throwing an IllegalStateException if no space is
currently available.

    This implementation returns true if offer succeeds, else throws an
IllegalStateException.

    Specified by:
        add in interface Collection<E>
    Specified by:
        add in interface Queue<E>
    Overrides:
        add in class AbstractCollection<E>

    Parameters:
        e - the element to add
    Returns:
        true (as specified by Collection.add(E))
    Throws:
        IllegalStateException - if the element cannot be added at this
time due to capacity restrictions
        ClassCastException - if the class of the specified element
prevents it from being added to this queue
        NullPointerException - if the specified element is null and
this queue does not permit null elements
        IllegalArgumentException - if some property of this element
prevents it from being added to this queue

End of doc

Now, what I can see from the above document is that the inherited
method can throw four types of exceptions and among them is the
ClassCastException. Why do you claim that `AbstractQueue.add, and the
latter does *not* throw
ClassCastException'? Is is not the right documentation? If this is the
correct documentation, how can one reproduce a ClassCastException?
That was all I wanted to know all along.

Besides, I would be interested in creating an IllegalArgumentException as well.

Best Regards,
Szabolcs

From peter.kovacs.1.0rc at gmail.com  Tue Apr 17 04:49:26 2007
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 17 Apr 2007 10:49:26 +0200
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEELHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704161327r1b4e4349y9cc8bb5b1750a192@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEELHGAA.dcholmes@optusnet.com.au>
Message-ID: <b6e8f2e80704170149h7b664a6el6f2b0519391b2bf3@mail.gmail.com>

On 4/17/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>
> Many forms of optimization induces some coupling with the hardware - but
> these are not things that change overnight. If it turns out that lock-free
> doesn't work as well on future architectures then we'll replace it with
> something else as needs be. That's how the real world works: there's a need,
> then a solution, and if the need changes or the solution stops working, we
> adapt and come up with a new solution. It's called "engineering".

Gee!!! In the real world, marketing departments, political parties,
viruses, etc. do this kind of adaptation all the time -- all of them
are then doing "engineering".

"These forty years now, I've been speaking in prose without knowing it!"

Thanks
Peter

>
> Cheers,
> David Holmes
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From jws at cs.mu.OZ.AU  Tue Apr 17 05:09:48 2007
From: jws at cs.mu.OZ.AU (Jeff Schultz)
Date: Tue, 17 Apr 2007 19:09:48 +1000
Subject: [concurrency-interest] Lock-free mania
Message-ID: <10442.1176800988@blunt.localdomain>

> > Nobody on this list in running Java on a transputer, so its irrelevant.

> Neither do I. However, I would not say that it is irrelevant, since
> what I said was that context switch is not necessarily an expensive
> operation. I provided you an example for this. Why would it be
> irrelevant?

I don't want to start a flamewar, but from one point of view at least,
the Transputer made context switching relatively fast in large part by
making all other operations relatively slow.  This is not clearly a
winning strategy.

The current approach of running lots of threads essentially
simultaneously seems to work rather better in the region of the
speed/complexity tradeoff we're currently able to reach, and I'd
hazard a guess that those processors will do rather well with
lock-free algorithms.


    Jeff Schultz

From dcholmes at optusnet.com.au  Tue Apr 17 05:18:18 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 19:18:18 +1000
Subject: [concurrency-interest] LinkedBlockingQueue does not
	throwClassCastException
In-Reply-To: <c8955b000704170123t44b17aa0r51f0841790f53835@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEFIHGAA.dcholmes@optusnet.com.au>

My apologies, seems someone has (perhaps unintentionally) changed the
specification, as I was looking at the Java 5 documentation:

http://java.sun.com/j2se/1.5.0/docs/api/java/util/AbstractQueue.html#add(E)

where ClassCastException (and IllegalArgumentException) are not redeclared
to be thrown.

Given the use of generics, it is not unreasonable to infer that trying to
add anything other than an E will indeed cause ClassCastException to be
thrown.

Arguably the Java 6 documentation is more correct, as until offer() et al
are defined you don't know whether or not the exceptions will be thrown. But
overall I have to say this is a bit of a mess. The base class is trying to
allow for a range of conditions that a subclass might impose and so
documenting the possible/potential exceptions, but the subclasses are
leaving open the possibility for their own subclasses to strengthen the
conditions, and so still declare exceptions that they themselves will never
throw.

There's really no way to fix this - the existing specifications will never
be changed - even though is a documentation issue more than anything, as
none of the exceptions involved are (or could be) checked exceptions.

David Holmes


> -----Original Message-----
> From: Szabolcs Ferenczi [mailto:szabolcs.ferenczi at gmail.com]
> Sent: Tuesday, 17 April 2007 6:23 PM
> To: dholmes at ieee.org
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not
> throwClassCastException
>
>
> On 17/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > If you check the documentation ...
>
> That is what I did.
>
> > ... you will see that LinkedBlockingQueue.add is
> > inherited from AbstractQueue.add, and the latter does *not* throw
> > ClassCastException.
>
> On the contrary to what you claim, this is what I found:
>
> http://java.sun.com/javase/6/docs/api/java/util/AbstractQueue.html#add(E)
>
> add
>
> public boolean add(E e)
>
>     Inserts the specified element into this queue if it is possible to
> do so immediately without violating capacity restrictions, returning
> true upon success and throwing an IllegalStateException if no space is
> currently available.
>
>     This implementation returns true if offer succeeds, else throws an
> IllegalStateException.
>
>     Specified by:
>         add in interface Collection<E>
>     Specified by:
>         add in interface Queue<E>
>     Overrides:
>         add in class AbstractCollection<E>
>
>     Parameters:
>         e - the element to add
>     Returns:
>         true (as specified by Collection.add(E))
>     Throws:
>         IllegalStateException - if the element cannot be added at this
> time due to capacity restrictions
>         ClassCastException - if the class of the specified element
> prevents it from being added to this queue
>         NullPointerException - if the specified element is null and
> this queue does not permit null elements
>         IllegalArgumentException - if some property of this element
> prevents it from being added to this queue
>
> End of doc
>
> Now, what I can see from the above document is that the inherited
> method can throw four types of exceptions and among them is the
> ClassCastException. Why do you claim that `AbstractQueue.add, and the
> latter does *not* throw
> ClassCastException'? Is is not the right documentation? If this is the
> correct documentation, how can one reproduce a ClassCastException?
> That was all I wanted to know all along.
>
> Besides, I would be interested in creating an
> IllegalArgumentException as well.
>
> Best Regards,
> Szabolcs


From matthias.ernst at coremedia.com  Tue Apr 17 05:21:53 2007
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Tue, 17 Apr 2007 11:21:53 +0200
Subject: [concurrency-interest] LinkedBlockingQueue does
	notthrowClassCastException
References: <c8955b000704161647v2a6f6281kac1c6e92e9c16f9c@mail.gmail.com><NFBBKALFDCPFIDBNKAPCIEFBHGAA.dcholmes@optusnet.com.au>
	<c8955b000704170123t44b17aa0r51f0841790f53835@mail.gmail.com>
Message-ID: <AE2A8E488D9B26438919DF3C9C95528D168E97@hermes.coremedia.com>

Szabolcs,

>        ClassCastException - if the class of the specified element
>        prevents it from being added to this queue


You conflate "carries an <Integer> type parameter" with "prevents Strings from being added".

The combination of the implementations of your test, LinkedBlockingQueue and Java generics does NOT prevent an element of a different class to be added. Thus no ClassCastException is thrown. Thus you need to remove CCE from your test and it will be green. It's as simple as that.

> public class lbqTest {
>   LinkedBlockingQueue q;

Better yet, write LinkedBlockingQueue<Integer> here and put @ExpectDoesNotCompile onto your test.

Matthias
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070417/34fbed96/attachment.html 

From dcholmes at optusnet.com.au  Tue Apr 17 05:24:19 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 17 Apr 2007 19:24:19 +1000
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <b6e8f2e80704170149h7b664a6el6f2b0519391b2bf3@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEFIHGAA.dcholmes@optusnet.com.au>

Peter,

> Gee!!! In the real world, marketing departments, political parties,
> viruses, etc. do this kind of adaptation all the time -- all of them
> are then doing "engineering".

You've encountered marketing departments and political parties that have
come up with solutions? That would be novel ;-)

David


From jseigh_cp00 at xemaps.com  Tue Apr 17 06:08:01 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Tue, 17 Apr 2007 06:08:01 -0400
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <1176782257.643149.28308.nullmailer@riedel.org>
References: <1176782257.643149.28308.nullmailer@riedel.org>
Message-ID: <46249C81.6060605@xemaps.com>

Larry Riedel wrote:

>
>I think if there was a question of will the increasing availability and
>trendiness of lock-free, wait-free, obstruction-free, blahblahblah-free
>tools lead to hordes of "architects" and "principal engineers" choosing
>those tools for no technically justifiable reason to create inferior and
>broken solutions to nonexistent problems, I think it would be safe to
>agree the answer is yes.  But I think the overall net impact of the
>availability and trendiness of those tools is still going to be positive.
>  
>
Trendy?  When did this happen?

--
Joe Seigh

From Martin.Buchholz at Sun.COM  Tue Apr 17 06:05:13 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Tue, 17 Apr 2007 03:05:13 -0700
Subject: [concurrency-interest] LinkedBlockingQueue does not
 throwClassCastException
In-Reply-To: <mailman.1788.1176782262.19110.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.1788.1176782262.19110.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <46249BD9.5050309@sun.com>

> From: "David Holmes" <dcholmes at optusnet.com.au>
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not
> 	throwClassCastException
> To: "Szabolcs Ferenczi" <szabolcs.ferenczi at gmail.com>
> Cc: Concurrency-interest at cs.oswego.edu
> Message-ID: <NFBBKALFDCPFIDBNKAPCIEFBHGAA.dcholmes at optusnet.com.au>
> Content-Type: text/plain;	charset="us-ascii"
> 
> If you check the documentation you will see that LinkedBlockingQueue.add is
> inherited from AbstractQueue.add, and the latter does *not* throw
> ClassCastException.

It's a very interesting point that it is possible to tell from the
javadoc whether a subclass has overridden a method.  But that is
clearly an implementation detail, and its exposure by javadoc
presumably a subtle bug in javadoc.  The spec should not be construed
as guaranteeing that LBQ does not override add().  A compatible
Java implementation could have LBQ override add(), as long as it
had the same spec.

Martin

> 
> David Holmes

From dl at cs.oswego.edu  Tue Apr 17 06:27:18 2007
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 17 Apr 2007 06:27:18 -0400
Subject: [concurrency-interest] Source repository of test/loops
In-Reply-To: <ca53c8f80704161647v339e24f4r78fef028bd81f965@mail.gmail.com>
References: <ca53c8f80704161647v339e24f4r78fef028bd81f965@mail.gmail.com>
Message-ID: <4624A106.6090007@cs.oswego.edu>

Hanson Char wrote:
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
> 
> Any chance there is an anonymous CVS or SVN access to this source
> repository ?  That would be really nice.
> 

See list mail from around March 2004 :-) where I said:

You can also get anonymous read-only CVS access setting CVSROOT to
   :pserver:anonymous at gee.cs.oswego.edu/export/home/jsr166/jsr166
with project also named jsr166 (as in "cvs co jsr166")

-Doug


From gregg at cytetech.com  Tue Apr 17 09:34:59 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 17 Apr 2007 08:34:59 -0500
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <10442.1176800988@blunt.localdomain>
References: <10442.1176800988@blunt.localdomain>
Message-ID: <4624CD03.5010307@cytetech.com>



Jeff Schultz wrote:
>>>Nobody on this list in running Java on a transputer, so its irrelevant.
>
>>Neither do I. However, I would not say that it is irrelevant, since
>>what I said was that context switch is not necessarily an expensive
>>operation. I provided you an example for this. Why would it be
>>irrelevant?
> 
> I don't want to start a flamewar, but from one point of view at least,
> the Transputer made context switching relatively fast in large part by
> making all other operations relatively slow.  This is not clearly a
> winning strategy.

Theres not an SMP version (yet), but the aJile AJ series Java uPs have an 
extremely quick < 1nS context switch, because the OS-like features of the JVM 
are built into the device.  In that kind of environment, locks are relatively 
cheap relative to the speed (100mhz) of the clock and the relative execution 
times of each instruction/operation.

Gregg Wonderly

From hanson.char at gmail.com  Tue Apr 17 11:58:01 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 17 Apr 2007 08:58:01 -0700
Subject: [concurrency-interest] Source repository of test/loops
In-Reply-To: <4624A106.6090007@cs.oswego.edu>
References: <ca53c8f80704161647v339e24f4r78fef028bd81f965@mail.gmail.com>
	<4624A106.6090007@cs.oswego.edu>
Message-ID: <ca53c8f80704170858k228330b0u4ffd47b5cf5026cd@mail.gmail.com>

Nice!  Thanks.  Wouldn't it be nicer if this information is included
at the jsr166 web page,

    http://g.oswego.edu/dl/concurrency-interest/

, in addition to the browsable CVS links ?

Cheers,
Hanson Char

On 4/17/07, Doug Lea <dl at cs.oswego.edu> wrote:
> Hanson Char wrote:
> >> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
> >
> > Any chance there is an anonymous CVS or SVN access to this source
> > repository ?  That would be really nice.
> >
>
> See list mail from around March 2004 :-) where I said:
>
> You can also get anonymous read-only CVS access setting CVSROOT to
>    :pserver:anonymous at gee.cs.oswego.edu/export/home/jsr166/jsr166
> with project also named jsr166 (as in "cvs co jsr166")
>
> -Doug
>
>

From jason_mehrens at hotmail.com  Tue Apr 17 14:37:46 2007
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Tue, 17 Apr 2007 13:37:46 -0500
Subject: [concurrency-interest] LinkedBlockingQueue does not
 throwNullPointerException for the method call contains
Message-ID: <BAY142-F285177B4C26B3B25993D3B83510@phx.gbl>

I think it makes sense to tie the optional behavior of contains to the 
optional behavior of remove.  From what I can tell that detail is not 
specified in the docs but, the concrete implementations in the JDK seem to 
enforce this detail.

For instance, if I wrote a Collection that was a ReadWriteLock wrapper for a 
single thread collection like the synchronizedCollection but mapped writes 
to the write lock and reads to the read lock.
If remove is written like:

public boolean remove(Object o) {
  if(write.tryLock()) {
    try {
       return col.remove(o);
    }
    finally {
       write.unlock();
    }
  }

  read.lock();
  try {
    if(!col.contains(o)) {
      return false;
    }
  }
  finally {
    read.unlock();
  }

  write.lock();
   try {
      return col.remove(o);
   }
   finally {
      write.unlock();
   }
}

If contains and remove do not handle optional exceptions then same way then 
"optional" means "depending of the state of write lock" for the above 
implementation.  Which I don't think was the intended meaning "optional".  
Is this detail worth specifying?

Jason Mehrens


>From: "Joe Bowbeer" <joe.bowbeer at gmail.com>
>To: concurrency-interest <concurrency-interest at cs.oswego.edu>
>Subject: Re: [concurrency-interest] LinkedBlockingQueue does not 
>throwNullPointerException for the method call contains
>Date: Mon, 16 Apr 2007 16:19:13 -0700
>
>Martin Buchholz mentioned off-list that we could link the instances of
>"(optional)" in the Collection method descriptions to the paragraph in
>the Collection class description that covers optional restrictions.
>
>Is this worthwhile?
>
>Here's what the fix would look like:
>
>Collection.java
>
>1. Add "optional-restrictions" anchor.
>
>  * <p><a name="optional-restrictions"/>
>  * Some collection implementations have restrictions on the elements that 
>they
>  * may contain.  For example, some implementations prohibit null elements,
>
>2. Add links to the optional restrictions paragraph.
>
>There are ten instances of "(optional)" -- resulting from five sets of
>ClassCastException and NullPointerException.  In each instance,
>"(optional)" would be replaced by:
>
>  (<a href="#optional-restrictions">optional</a>)
>
>--Joe
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at altair.cs.oswego.edu
>http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

_________________________________________________________________
The average US Credit Score is 675. The cost to see yours: $0 by Experian. 
http://www.freecreditreport.com/pm/default.aspx?sc=660600&bcd=EMAILFOOTERAVERAGE


From szabolcs.ferenczi at gmail.com  Tue Apr 17 16:34:42 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 17 Apr 2007 22:34:42 +0200
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
Message-ID: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>

There is a method defined on LBQ (well already on AbstractQueue)
that throws IllegalStateException. The LinkedBlockingQueue.add method
throws an IllegalStateException when the queue is at the max capacity
(full) at the time the method is called. It is strange, isn't it? But
it is true.

I believe an operation on a queue being full is not illegal in a multi-threaded
environment. It just happens sometimes at non deterministic moments.

I think, throwing the exception might be justified on a data structure, which is
designed to be used in a single threaded environment but it is a
completely mistaken behavior on a shared data structure. I hope the
reason why is obvious to anyone who works with multiple threads.

 I think this method and related ones such as the method remove (throws
NoSuchElementException) should be fixed in forthcoming releases,
if methods like these are needed at all.

Any comment?

Best Regards,
Szabolcs

From joe.bowbeer at gmail.com  Tue Apr 17 17:34:58 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 17 Apr 2007 14:34:58 -0700
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
In-Reply-To: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
References: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
Message-ID: <31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>

Look at the documentation for Queue.

In particular, the distinction between 'add' and 'offer':

http://java.sun.com/javase/6/docs/api/java/util/Queue.html

On 4/17/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> There is a method defined on LBQ (well already on AbstractQueue)
> that throws IllegalStateException. The LinkedBlockingQueue.add method
> throws an IllegalStateException when the queue is at the max capacity
> (full) at the time the method is called. It is strange, isn't it? But
> it is true.
>
> I believe an operation on a queue being full is not illegal in a multi-threaded
> environment. It just happens sometimes at non deterministic moments.
>
> I think, throwing the exception might be justified on a data structure, which is
> designed to be used in a single threaded environment but it is a
> completely mistaken behavior on a shared data structure. I hope the
> reason why is obvious to anyone who works with multiple threads.
>
>  I think this method and related ones such as the method remove (throws
> NoSuchElementException) should be fixed in forthcoming releases,
> if methods like these are needed at all.
>
> Any comment?
>
> Best Regards,
> Szabolcs
>

From janne at savukoski.name  Tue Apr 17 17:40:21 2007
From: janne at savukoski.name (Janne Savukoski)
Date: Wed, 18 Apr 2007 00:40:21 +0300
Subject: [concurrency-interest] Selecting most recently busy worker thread
Message-ID: <bafd4c6b0704171440r728a2a95paeb1cabf09c26906@mail.gmail.com>

Hi everyone,

In "Notes from the Architect" at
http://varnish.projects.linpro.no/wiki/ArchitectNotes was mentioned
that

"The worker threads are used in 'most recently busy' fashion"

which got me thinking if this selection method is used also in
ExecutorService implementations? I guess this is less relevant as
probably in most cases the released workers either get their next job
immediately, or otherwise all caches get flushed anyways and it's not
that big a deal. But still, if this ordering--nor any other
special--wasn't used, could it be a minor optimization worth doing?
Also, could it benefit the use of ThreadLocals in particular? I'm a
big fan of those..

best, Janne

From szabolcs.ferenczi at gmail.com  Tue Apr 17 18:18:48 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 00:18:48 +0200
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
In-Reply-To: <31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>
References: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
	<31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>
Message-ID: <c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>

On 17/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Look at the documentation for Queue.
>
> In particular, the distinction between 'add' and 'offer':
>
> http://java.sun.com/javase/6/docs/api/java/util/Queue.html

Well, I did have a look at it. That is why I made my point. What is
your point? Did you think about it?

Your reference is to an interface definition for a sequential data
structure. I called your attention, well it seems you are not
listening, that there is a big difference between operations on a
sequential data structure and a shared data structure. By sequential
data structure I mean one that is designed to be used in a single
threaded environment.

I am talking about method `add' and not about method `offer.' Do you
think it is a correct behavior throwing an exception if a shared data
structure is not in the expected state?

Besides, method `offer' also smells in multi-threaded environment. But
it at least returns false in case the state is not as expected.

Best Regards,
Szabolcs

From dcholmes at optusnet.com.au  Tue Apr 17 18:54:56 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 18 Apr 2007 08:54:56 +1000
Subject: [concurrency-interest] Method on LinkedBlockingQueue
	throwsIllegalStateException
In-Reply-To: <c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEFOHGAA.dcholmes@optusnet.com.au>

The inherited methods from Collection et al were not intended for
multi-threaded use. Hence the BlockingQueue interface was defined to provide
the desirable semantics for multi-threaded use. It was considered very
important that concurrent collections also support the legacy Collection
methods.

If want blocking behaviour when encountering full/empty conditions then use
the methods from BlockingQueue in place of similar methods from Collection.

David Holmes


> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Szabolcs
> Ferenczi
> Sent: Wednesday, 18 April 2007 8:19 AM
> To: Joe Bowbeer
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] Method on LinkedBlockingQueue
> throwsIllegalStateException
>
>
> On 17/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > Look at the documentation for Queue.
> >
> > In particular, the distinction between 'add' and 'offer':
> >
> > http://java.sun.com/javase/6/docs/api/java/util/Queue.html
>
> Well, I did have a look at it. That is why I made my point. What is
> your point? Did you think about it?
>
> Your reference is to an interface definition for a sequential data
> structure. I called your attention, well it seems you are not
> listening, that there is a big difference between operations on a
> sequential data structure and a shared data structure. By sequential
> data structure I mean one that is designed to be used in a single
> threaded environment.
>
> I am talking about method `add' and not about method `offer.' Do you
> think it is a correct behavior throwing an exception if a shared data
> structure is not in the expected state?
>
> Besides, method `offer' also smells in multi-threaded environment. But
> it at least returns false in case the state is not as expected.
>
> Best Regards,
> Szabolcs
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From joe.bowbeer at gmail.com  Tue Apr 17 19:10:36 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 17 Apr 2007 16:10:36 -0700
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
In-Reply-To: <c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
References: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
	<31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>
	<c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
Message-ID: <31f2a7bd0704171610w638e9ea7xcae031ec7b84e85c@mail.gmail.com>

I guess I didn't understand your question.  AbstractQueue implements
Queue, right?

Have you looked at the BlockingQueue definition, and the 'put' and
'take' methods that it provides for concurrent access?

http://java.sun.com/javase/6/docs/api/java/util/concurrent/BlockingQueue.html

I think you may be confused by some of the history here.
Non-thread-safe collections came first and then concurrent collections
came later and were layered on top of collections.

You can argue that this layering was not done perfectly (wasn't it?),
but given that things are the way they are, namely that BlockingQueue
extends Queue extends Collection, it doesn't make sense to advocate
the removal of a Collection method from AbstractQueue -- or one of the
blocking queues that extend it.

--Joe

On 4/17/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 17/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > Look at the documentation for Queue.
> >
> > In particular, the distinction between 'add' and 'offer':
> >
> > http://java.sun.com/javase/6/docs/api/java/util/Queue.html
>
> Well, I did have a look at it. That is why I made my point. What is
> your point? Did you think about it?
>
> Your reference is to an interface definition for a sequential data
> structure. I called your attention, well it seems you are not
> listening, that there is a big difference between operations on a
> sequential data structure and a shared data structure. By sequential
> data structure I mean one that is designed to be used in a single
> threaded environment.
>
> I am talking about method `add' and not about method `offer.' Do you
> think it is a correct behavior throwing an exception if a shared data
> structure is not in the expected state?
>
> Besides, method `offer' also smells in multi-threaded environment. But
> it at least returns false in case the state is not as expected.
>
> Best Regards,
> Szabolcs
>

From szabolcs.ferenczi at gmail.com  Tue Apr 17 19:21:59 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 01:21:59 +0200
Subject: [concurrency-interest] Method on LinkedBlockingQueue
	throwsIllegalStateException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEFOHGAA.dcholmes@optusnet.com.au>
References: <c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEFOHGAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000704171621w454a135y26902d5f10a46273@mail.gmail.com>

On 18/04/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> The inherited methods from Collection et al were not intended for
> multi-threaded use. Hence the BlockingQueue interface was defined to provide
> the desirable semantics for multi-threaded use. It was considered very
> important that concurrent collections also support the legacy Collection
> methods.
>
> If want blocking behaviour when encountering full/empty conditions then use
> the methods from BlockingQueue in place of similar methods from Collection.

Hm. I was not aware that it is already intentional programming.

Nevertheless, the interface Blocking Queue equally well defines the
dangerous add method that throws an IllegalStateException. See:

http://java.sun.com/javase/6/docs/api/java/util/concurrent/BlockingQueue.html#add(E)

Why do you think a BlockingQueue must have an interface like this? The
problem is there. "I suggest you go and read a lot of literature on
the subject to understand"  that concurrent programming is not a joke.
Defining a method for a blocking queue that throws an exception if the
queue is full more than a mistake, I can tell you.

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Tue Apr 17 19:54:48 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 01:54:48 +0200
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
In-Reply-To: <31f2a7bd0704171610w638e9ea7xcae031ec7b84e85c@mail.gmail.com>
References: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
	<31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>
	<c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
	<31f2a7bd0704171610w638e9ea7xcae031ec7b84e85c@mail.gmail.com>
Message-ID: <c8955b000704171654g46c6d64cw3205a8cabceedde6@mail.gmail.com>

On 18/04/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> I guess I didn't understand your question.  AbstractQueue implements
> Queue, right?
>
> Have you looked at the BlockingQueue definition, and the 'put' and
> 'take' methods that it provides for concurrent access?
>
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/BlockingQueue.html

Of course I have had a look at it (you strange guys keep asking it)
and yes, I am afraid, you really did not understand the point. That is
correct of you. I do not speak about the `put' and `take' methods,
which I think are quite appropriate for a shared queue. I am talking
about the inappropriate `put' and `remove' methods, which throw
exceptions when the operation cannot be carried out on the shared data
structure at the moment. I must ask again: Why do you think it is a
good idea to throw an exception if you are going to add a piece of
data to a shared data structure but there is no room for it at the
very moment?

> I think you may be confused by some of the history here.

No, I am not. Well, I am not concerned about history in this respect.
Your partner just explained to me that it is a kind of "engineering".
He does not want to think in advance and he claims that he simply
engineers the problem when needed. Well, I pointed the problem out for
you.

Note: "If it turns out that lock-free doesn't work as well on future
architectures then we'll replace it with something else as needs be.
That's how the real world works: there's a need, then a solution, and
if the need changes or the solution stops working, we adapt and come
up with a new solution. It's called "engineering".

Cheers,
David Holmes"

So much about history and the restrictions by it. It is called
"engineering", isn't it? Hic Rhodus, hic salta.

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Tue Apr 17 19:57:58 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 01:57:58 +0200
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
In-Reply-To: <c8955b000704171654g46c6d64cw3205a8cabceedde6@mail.gmail.com>
References: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
	<31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>
	<c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
	<31f2a7bd0704171610w638e9ea7xcae031ec7b84e85c@mail.gmail.com>
	<c8955b000704171654g46c6d64cw3205a8cabceedde6@mail.gmail.com>
Message-ID: <c8955b000704171657j5e3c04b6l170e9866b50d40a7@mail.gmail.com>

On 18/04/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> about the inappropriate `put' and `remove' methods, which throw

Of course it is a misspelling: read  "inappropriate `add' and `remove' methods"

From joe.bowbeer at gmail.com  Tue Apr 17 20:12:54 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 17 Apr 2007 17:12:54 -0700
Subject: [concurrency-interest] Method on LinkedBlockingQueue throws
	IllegalStateException
In-Reply-To: <c8955b000704171654g46c6d64cw3205a8cabceedde6@mail.gmail.com>
References: <c8955b000704171334j2befe551nbd6ba65a1716c89e@mail.gmail.com>
	<31f2a7bd0704171434t476a3b59r9be1ab691e9f2df5@mail.gmail.com>
	<c8955b000704171518n68dbc247td36655d7518fbef6@mail.gmail.com>
	<31f2a7bd0704171610w638e9ea7xcae031ec7b84e85c@mail.gmail.com>
	<c8955b000704171654g46c6d64cw3205a8cabceedde6@mail.gmail.com>
Message-ID: <31f2a7bd0704171712p5730cc7ekaa4d5f6b30321d50@mail.gmail.com>

On 4/17/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> I am talking about the inappropriate `add' and `remove' methods, which
> throw exceptions when the operation cannot be carried out on the shared
> data structure at the moment.
>

These are Collection methods.  BlockingQueue is designed so that it
can also be treated as an unshared collection.

> I must ask again: Why do you think it is a good idea to throw an
> exception if you are going to add a piece of data to a shared data
> structure but there is no room for it at the very moment?
>

It's a good idea when a shared data structure is not being shared, as
is sometimes the case, such as during startup and shutdown, or when
the threads have been paused.

This is my final response on this topic, by the way.

--
Joe Bowbeer

From brian at quiotix.com  Tue Apr 17 20:44:57 2007
From: brian at quiotix.com (Brian Goetz)
Date: Tue, 17 Apr 2007 20:44:57 -0400
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <1176782257.643149.28308.nullmailer@riedel.org>
References: <1176782257.643149.28308.nullmailer@riedel.org>
Message-ID: <46256A09.5040209@quiotix.com>

I think that's right.  Just as eight years ago the same crew built
elaborate thread-based mechanisms to solve problems that were entirely
compute-bound and deployed on single-processor systems -- which would
have been more effectively solved with a sequential approach.

But its not productive to try and "outlaw" foo-free algorithms, any more
than it was productive to outlaw threads -- the best we can do is
educate people when NOT to use them.  Of course, teaching people that
they're not as smart as they think is an uphill battle.  Time tends to
be a better teacher of these things than those who actually know better.

Larry Riedel wrote:
> I think if there was a question of will the increasing availability and
> trendiness of lock-free, wait-free, obstruction-free, blahblahblah-free
> tools lead to hordes of "architects" and "principal engineers" choosing
> those tools for no technically justifiable reason to create inferior and
> broken solutions to nonexistent problems, I think it would be safe to
> agree the answer is yes.  But I think the overall net impact of the
> availability and trendiness of those tools is still going to be positive.
> 
> 
> Larry
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From mike.quilleash at subexazure.com  Wed Apr 18 05:23:27 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 18 Apr 2007 05:23:27 -0400
Subject: [concurrency-interest] MRULinkedBlockingQueue
Message-ID: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>

Hi all,
 
Has anyone seen or comes across an collection implementation that has
the following characteristics.
 
1) Concurrent
2) Maintains insertion order (for iteration)
3) Capacity bound
4) An add() that would cause the capacity to exceed the limit would
remove the oldest element and add a new one.
 
I thought of the following extension to LinkedBlockingQueue which simply
loops in add() trying to offer() and removing an element from the queue
if the offer() fails.
 
 
public class MRULinkedBlockingQueue< T > extends LinkedBlockingQueue< T
>
{
    public MRULinkedBlockingQueue( int capacity )
    {
        super( capacity );
    }
 
    @Override
    public boolean add( T o )
    {
        for ( ;; )
        {
            // try and offer the element
            if ( offer( o ) )
                return true;
 
            // remove the head of the queue to make room if the offer
failed.
            poll();
        }
    }
}

 
Any comments appreciated.
 
 
 

 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070418/ca3910e2/attachment.html 

From jseigh_cp00 at xemaps.com  Wed Apr 18 06:33:05 2007
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Wed, 18 Apr 2007 06:33:05 -0400
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <46256A09.5040209@quiotix.com>
References: <1176782257.643149.28308.nullmailer@riedel.org>
	<46256A09.5040209@quiotix.com>
Message-ID: <4625F3E1.7020409@xemaps.com>

Brian Goetz wrote:

>I think that's right.  Just as eight years ago the same crew built
>elaborate thread-based mechanisms to solve problems that were entirely
>compute-bound and deployed on single-processor systems -- which would
>have been more effectively solved with a sequential approach.
>
>But its not productive to try and "outlaw" foo-free algorithms, any more
>than it was productive to outlaw threads -- the best we can do is
>educate people when NOT to use them.  Of course, teaching people that
>they're not as smart as they think is an uphill battle.  Time tends to
>be a better teacher of these things than those who actually know better.
>  
>

Most of the lock-free algorithms are patented or being patented, so you 
could sort of "outlaw"
them with licensing restrictions.

--
Joe Seigh

From szabolcs.ferenczi at gmail.com  Wed Apr 18 06:48:32 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 12:48:32 +0200
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>
Message-ID: <c8955b000704180348o3db19ee8u1d97b241beec69cc@mail.gmail.com>

Hi,

I do not exactly get what do you mean by "concurrent" in case of a
data structure. I guess you mean that lock-free stuff. Right? Is it
really a requirement in this situation?

The other question is what do you mean by maintaining the insertion order.

Anyway, the following problem appears to me in this lock-free
solution: Let us assume there are three threads using an already
filled queue of this kind. Each thread calls method add() very
frequently. Now, it may happen that two of them do not let the third
progress. So, this algorithm is prone to starvation.

Assume T1 starts operation add(item1), the queue is full so
offer(item1) fails and T1 makes some room by poll(). As soon as there
is a slot, T2 sneaks in and fills the queue by operation add(item2)
for which the offer(item2) succeeds. Now, poor T1 makes some room
again. But T3 puts item3 immediately, so that T1 has to make some room
again. And so on and so on.

I hope this helps.

Best Regards,
Szabolcs

On 18/04/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
>
>
> Hi all,
>
> Has anyone seen or comes across an collection implementation that has the
> following characteristics.
>
> 1) Concurrent
> 2) Maintains insertion order (for iteration)
> 3) Capacity bound
> 4) An add() that would cause the capacity to exceed the limit would remove
> the oldest element and add a new one.
>
> I thought of the following extension to LinkedBlockingQueue which simply
> loops in add() trying to offer() and removing an element from the queue if
> the offer() fails.
>
>
> public class MRULinkedBlockingQueue< T > extends LinkedBlockingQueue< T >
> {
>     public MRULinkedBlockingQueue( int capacity )
>     {
>         super( capacity );
>     }
>
>     @Override
>     public boolean add( T o )
>     {
>         for ( ;; )
>         {
>             // try and offer the element
>             if ( offer( o ) )
>                 return true;
>
>             // remove the head of the queue to make room if the offer
> failed.
>             poll();
>         }
>     }
> }
>
>
> Any comments appreciated.
>
>
>   This e-mail is bound by the terms and conditions described at
> http://www.subexazure.com/mail-disclaimer.html
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From chris.purcell.39 at gmail.com  Wed Apr 18 08:11:53 2007
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Wed, 18 Apr 2007 13:11:53 +0100
Subject: [concurrency-interest] Lock-free mania
In-Reply-To: <c8955b000704161621i5de2f191x2660010f93d83ad0@mail.gmail.com>
References: <c8955b000704151238k5c6d5948h4d3262ea8c86af9a@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEBHGAA.dcholmes@optusnet.com.au>
	<c8955b000704151702u28dbcd16gc94921e423eed659@mail.gmail.com>
	<4623545C.9020001@xemaps.com>
	<c8955b000704161621i5de2f191x2660010f93d83ad0@mail.gmail.com>
Message-ID: <4856e16d0704180511j568befbfodb57a5bfb54788f6@mail.gmail.com>

> Very well. Then, I give some support for my statements in the form of
> some working test in the TMC framework:

>             do {
>                 v = value.get();
>                 for (int i = 0; i<10000; ++i) i = i+2-2; // delay for the test
>             } while (!value.compareAndSet(v, v + 1));

>         public synchronized int increment() {
>             for (int i = 0; i<10000; ++i) i = i+2-2; // delay for the test
>             return ++value;
>         }

Wow. That's a really pointless benchmark. In the lock-free case,
you've put a large delay between reading the value and incrementing
it, pretty much guaranteeing that half the work you do is wasted.
Depending on the relative sizes of scheduling quanta, you could waste
up to two-thirds of your effort.

Doing more analysis, in the lock-based system, you've placed each lock
release and subsequent lock obtain right next to each other -- no
delay. That means the processor will still have the lock in exclusive
mode in cache, allowing it to immediately relock it. That prevents
cachelines ping-ponging between the cores, since threads serialize to
a large extent. The lock-free system, on the other hand, is
deliberately *losing* exclusive mode after each update, and then
racing with the other threads to regain it.

> I have inserted some delay into both of the algorithms. If the delay
> is not inserted, there is a slight advantage for the lock-free
> algorithm...Is that some support for the suppositions?

So you deliberately crippled the algorithm, and then it went slower.
How does this lend support to any of your suppositions? Lock-free
systems are useful when they're designed with care to achieve good
performance and scalability, not thrown together in anger by someone
out to prove they don't work. The only position your benchmark
supports is that naively creating lock-free algorithms usually results
in worse performance than naively creating blocking ones, which I
doubt anyone would disagree with. Lock-freedom is a non-trivial
subject. Indeed, from the very publication you cite:

"Nonblocking algorithms can be extremely difficult to design and
implement, but they can offer better throughput and greater resistance
to liveness problems such as deadlock and priority inversion. In this
installment of Java theory and practice, concurrency guru Brian Goetz
illustrates how several of the simpler nonblocking algorithms work."

Notice the keywords: "extremely difficult", "can offer", and "guru".

> What about livelocks?

"Lock-free" by definition means livelocks cannot happen.

> 2: When there are frequent conflicts between threads, i.e. under heavy
> load conditions, it becomes a busy waiting loop and, consequently,
> it becomes very inefficient just at the critical moment.

I think you're getting "lock-free algorithms" and "spinlocks"
confused. Lock-free algorithms don't busy-wait.

Chris

From hanson.char at gmail.com  Wed Apr 18 14:36:21 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 18 Apr 2007 11:36:21 -0700
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>
References: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>
Message-ID: <ca53c8f80704181136o7f852334y479b219d51abe4bc@mail.gmail.com>

Are you trying to have a thread-safe bounded buffer that keeps only
the latest information ?  If so, you can consider the use of an
AtomicReferenceArray for implementing the bounded buffer, together
with an AtomicInteger for the current index pointing to the next slot
to put the latest element.  As long as the nextPosition operation
returns an index modulus the length of the array, you got the effect
of a circular buffer.

For retrieval of the latest info (as a whole), just iterate through
the entire array ignoring the empty (ie null) slots.  Is that good
enough for your use case ?

Thread-safe, concurrent (ie lock free).

See CircularBuffer.java below.

Hanson Char

import java.util.Iterator;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReferenceArray;

public class CircularBuffer<T> implements Iterable<T>
{
    private final AtomicReferenceArray<T> a;
    private final AtomicInteger pos = new AtomicInteger();

    public CircularBuffer(int size)
    {
        a = new AtomicReferenceArray<T>(size);
    }

    public T add(T ele) {
        T ret = a.getAndSet(
                    nextpos(), ele);
        return ret;
    }

    public int size() {
        return a.length();
    }

    public Iterator<T> iterator()
    {
        return new Iterator<T>()
        {
            private int cur;

            public boolean hasNext()
            {
                return cur < a.length()
                    && a.get(cur) != null;
            }

            public T next() {
                if (cur < a.length())
                    return a.get(cur++);
                return null;
            }

            public void remove() {
                throw new UnsupportedOperationException("remove not supported");
            }
        };
    }

    private int nextpos()
    {
        for (;;) {
            final int current = pos.get();
            final int newValue = (current + 1) % a.length();

            if (pos.compareAndSet(current, newValue))
                return current;
        }
    }
}


On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
>
>
> Hi all,
>
> Has anyone seen or comes across an collection implementation that has the
> following characteristics.
>
> 1) Concurrent
> 2) Maintains insertion order (for iteration)
> 3) Capacity bound
> 4) An add() that would cause the capacity to exceed the limit would remove
> the oldest element and add a new one.
>
> I thought of the following extension to LinkedBlockingQueue which simply
> loops in add() trying to offer() and removing an element from the queue if
> the offer() fails.
>
>
> public class MRULinkedBlockingQueue< T > extends LinkedBlockingQueue< T >
> {
>     public MRULinkedBlockingQueue( int capacity )
>     {
>         super( capacity );
>     }
>
>     @Override
>     public boolean add( T o )
>     {
>         for ( ;; )
>         {
>             // try and offer the element
>             if ( offer( o ) )
>                 return true;
>
>             // remove the head of the queue to make room if the offer
> failed.
>             poll();
>         }
>     }
> }
>
>
> Any comments appreciated.
>
>
>   This e-mail is bound by the terms and conditions described at
> http://www.subexazure.com/mail-disclaimer.html
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From szabolcs.ferenczi at gmail.com  Wed Apr 18 15:47:18 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 21:47:18 +0200
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <ca53c8f80704181136o7f852334y479b219d51abe4bc@mail.gmail.com>
References: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>
	<ca53c8f80704181136o7f852334y479b219d51abe4bc@mail.gmail.com>
Message-ID: <c8955b000704181247p63cd0de5wae58deb6bacb63b@mail.gmail.com>

Hi Hanson,

I think it is an unpredictable construction. I will try to explain a
possible scenario.

Lets take a two elements buffer from this type. Thread T1 calls
add(item1) and at the same time, but shortly after T1, T2 calls
add(item2). Both starts nextpos() and obtains the current value 0 from
pos. Now either T1 or T2 can complete compareAndSet(0,1)
successfully. Let us say, T1 wins but it is delayed with the return. In the
meantime T3 comes with add(item3) and competes with T2 the same way
with compareAndSet(1,0). Lets say, T3 wins and T3 is also delayed with
the return. Now, T2 can update the counter with compareAndSet(0,1). At
this moment, T1 is about to return with 0, T3 with 1 and T2 with
0. These return values are array indexes. So the three threads are
competing for the atomic update a.getAndSet(x,y). The possible results
where the buffer can end up are:

[item1, item3] and subsequently [item2, item3] or
[item2, item3] and subsequently [item1, item3]

Remember, the calling sequence was item1, item2, item3. The final
content of the buffer is non deterministic, however.

Do you think this may happen with this buffer?

Just asking.

Best Regards,
Szabolcs

On 18/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> Are you trying to have a thread-safe bounded buffer that keeps only
> the latest information ?  If so, you can consider the use of an
> AtomicReferenceArray for implementing the bounded buffer, together
> with an AtomicInteger for the current index pointing to the next slot
> to put the latest element.  As long as the nextPosition operation
> returns an index modulus the length of the array, you got the effect
> of a circular buffer.
>
> For retrieval of the latest info (as a whole), just iterate through
> the entire array ignoring the empty (ie null) slots.  Is that good
> enough for your use case ?
>
> Thread-safe, concurrent (ie lock free).
>
> See CircularBuffer.java below.
>
> Hanson Char
>
> import java.util.Iterator;
> import java.util.concurrent.atomic.AtomicInteger;
> import java.util.concurrent.atomic.AtomicReferenceArray;
>
> public class CircularBuffer<T> implements Iterable<T>
> {
>     private final AtomicReferenceArray<T> a;
>     private final AtomicInteger pos = new AtomicInteger();
>
>     public CircularBuffer(int size)
>     {
>         a = new AtomicReferenceArray<T>(size);
>     }
>
>     public T add(T ele) {
>         T ret = a.getAndSet(
>                     nextpos(), ele);
>         return ret;
>     }
>
>     public int size() {
>         return a.length();
>     }
>
>     public Iterator<T> iterator()
>     {
>         return new Iterator<T>()
>         {
>             private int cur;
>
>             public boolean hasNext()
>             {
>                 return cur < a.length()
>                     && a.get(cur) != null;
>             }
>
>             public T next() {
>                 if (cur < a.length())
>                     return a.get(cur++);
>                 return null;
>             }
>
>             public void remove() {
>                 throw new UnsupportedOperationException("remove not supported");
>             }
>         };
>     }
>
>     private int nextpos()
>     {
>         for (;;) {
>             final int current = pos.get();
>             final int newValue = (current + 1) % a.length();
>
>             if (pos.compareAndSet(current, newValue))
>                 return current;
>         }
>     }
> }
>
>
> On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> >
> >
> > Hi all,
> >
> > Has anyone seen or comes across an collection implementation that has the
> > following characteristics.
> >
> > 1) Concurrent
> > 2) Maintains insertion order (for iteration)
> > 3) Capacity bound
> > 4) An add() that would cause the capacity to exceed the limit would remove
> > the oldest element and add a new one.
> >
> > I thought of the following extension to LinkedBlockingQueue which simply
> > loops in add() trying to offer() and removing an element from the queue if
> > the offer() fails.
> >
> >
> > public class MRULinkedBlockingQueue< T > extends LinkedBlockingQueue< T >
> > {
> >     public MRULinkedBlockingQueue( int capacity )
> >     {
> >         super( capacity );
> >     }
> >
> >     @Override
> >     public boolean add( T o )
> >     {
> >         for ( ;; )
> >         {
> >             // try and offer the element
> >             if ( offer( o ) )
> >                 return true;
> >
> >             // remove the head of the queue to make room if the offer
> > failed.
> >             poll();
> >         }
> >     }
> > }
> >
> >
> > Any comments appreciated.
> >
> >
> >   This e-mail is bound by the terms and conditions described at
> > http://www.subexazure.com/mail-disclaimer.html
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From brian at quiotix.com  Wed Apr 18 15:57:07 2007
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 18 Apr 2007 15:57:07 -0400
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <c8955b000704180348o3db19ee8u1d97b241beec69cc@mail.gmail.com>
References: <DAE04D9F6FD21448A220918A522FB60E06816000@MI8NYCMAIL15.Mi8.com>
	<c8955b000704180348o3db19ee8u1d97b241beec69cc@mail.gmail.com>
Message-ID: <46267813.6000906@quiotix.com>

> I do not exactly get what do you mean by "concurrent" in case of a
> data structure. I guess you mean that lock-free stuff. Right? Is it
> really a requirement in this situation?

No, lock-free is not a requirement for "concurrent".  Concurrent means 
"designed to perform well under concurrent access".  Tecniques for that 
include fine-grained locking (like CHM does), judicious use of 
immutability (CHM does this too), and nonblocking techniques.


From mike.quilleash at subexazure.com  Wed Apr 18 16:06:05 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 18 Apr 2007 16:06:05 -0400
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <ca53c8f80704181136o7f852334y479b219d51abe4bc@mail.gmail.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E06816712@MI8NYCMAIL15.Mi8.com>

Thanks for the replies.

That's an interesting idea, I hadn't considered using the Atomic stuff,
not much experience with it beyond using AtomicInteger for counting.

The only problem I see for my use case is that I don't think the
iterator returns them in insertion order, it will work for the first
"capacity" inserts and then once the array starts to wrap it will return
them in the array order starting from index 0.  Perhaps changing the
iterator to start at the current position and wrap around at most once
until current position == start position?

@Szabolcs - I don't see any data race problems.  I think your scenario
goes like this...

T1 - Calls add() enters nextPos(), gets current = 0 and newValue = 1
T2 - ditto
T1 - compareAndSet( 0, 1 ), succeeds and returns 0.
T3 - Calls add() enters nextPos(), gets current = 1 and newValue = 2
T3 - compareAndSet( 1, 2 ), succeeds and returns 1.
T2 - compareAndSet( 0, 1 ), fails and loops.
T2 - current = 2 and newValue = 3
T2 - compareAndSet( 2, 3 ), succeeds and return 2.

Unless I'm missing or misunderstanding something.

So:
T1 = 0
T3 = 1
T2 = 2

All distinct values, not in order of calling add(), but this is an
unfair structure (fine for my use-case).  If any thread calls
compareAndSet() all other threads that have stored a current value will
now fail their call to compareAndSet() and be forced to refetch current
and try again.

Cheers.

Mike.

-----Original Message-----
From: Hanson Char [mailto:hanson.char at gmail.com] 
Sent: 18 April 2007 19:36
To: Mike Quilleash 
Cc: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] MRULinkedBlockingQueue

Are you trying to have a thread-safe bounded buffer that keeps only the
latest information ?  If so, you can consider the use of an
AtomicReferenceArray for implementing the bounded buffer, together with
an AtomicInteger for the current index pointing to the next slot to put
the latest element.  As long as the nextPosition operation returns an
index modulus the length of the array, you got the effect of a circular
buffer.

For retrieval of the latest info (as a whole), just iterate through the
entire array ignoring the empty (ie null) slots.  Is that good enough
for your use case ?

Thread-safe, concurrent (ie lock free).

See CircularBuffer.java below.

Hanson Char

import java.util.Iterator;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReferenceArray;

public class CircularBuffer<T> implements Iterable<T> {
    private final AtomicReferenceArray<T> a;
    private final AtomicInteger pos = new AtomicInteger();

    public CircularBuffer(int size)
    {
        a = new AtomicReferenceArray<T>(size);
    }

    public T add(T ele) {
        T ret = a.getAndSet(
                    nextpos(), ele);
        return ret;
    }

    public int size() {
        return a.length();
    }

    public Iterator<T> iterator()
    {
        return new Iterator<T>()
        {
            private int cur;

            public boolean hasNext()
            {
                return cur < a.length()
                    && a.get(cur) != null;
            }

            public T next() {
                if (cur < a.length())
                    return a.get(cur++);
                return null;
            }

            public void remove() {
                throw new UnsupportedOperationException("remove not
supported");
            }
        };
    }

    private int nextpos()
    {
        for (;;) {
            final int current = pos.get();
            final int newValue = (current + 1) % a.length();

            if (pos.compareAndSet(current, newValue))
                return current;
        }
    }
}


On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
>
>
> Hi all,
>
> Has anyone seen or comes across an collection implementation that has 
> the following characteristics.
>
> 1) Concurrent
> 2) Maintains insertion order (for iteration)
> 3) Capacity bound
> 4) An add() that would cause the capacity to exceed the limit would 
> remove the oldest element and add a new one.
>
> I thought of the following extension to LinkedBlockingQueue which 
> simply loops in add() trying to offer() and removing an element from 
> the queue if the offer() fails.
>
>
> public class MRULinkedBlockingQueue< T > extends LinkedBlockingQueue< 
> T > {
>     public MRULinkedBlockingQueue( int capacity )
>     {
>         super( capacity );
>     }
>
>     @Override
>     public boolean add( T o )
>     {
>         for ( ;; )
>         {
>             // try and offer the element
>             if ( offer( o ) )
>                 return true;
>
>             // remove the head of the queue to make room if the offer 
> failed.
>             poll();
>         }
>     }
> }
>
>
> Any comments appreciated.
>
>
>   This e-mail is bound by the terms and conditions described at 
> http://www.subexazure.com/mail-disclaimer.html
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From hanson.char at gmail.com  Wed Apr 18 16:17:34 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 18 Apr 2007 13:17:34 -0700
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E06816712@MI8NYCMAIL15.Mi8.com>
References: <ca53c8f80704181136o7f852334y479b219d51abe4bc@mail.gmail.com>
	<DAE04D9F6FD21448A220918A522FB60E06816712@MI8NYCMAIL15.Mi8.com>
Message-ID: <ca53c8f80704181317i13ac9f7ak455541cef8d37086@mail.gmail.com>

>I don't think the iterator returns them in insertion order,

No the iterator isn't designed to return the elements in insertion
order.  I was just speculating your requirement is probably just about
getting a snapshot of the buffer containing the latest info of some
sort.  In that case you wouldn't care too much about the order among
the latest, as long as they are the latest.   But my speculation is
probably wrong :)

Cheers,
Hanson Char

On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> Thanks for the replies.
>
> That's an interesting idea, I hadn't considered using the Atomic stuff,
> not much experience with it beyond using AtomicInteger for counting.
>
> The only problem I see for my use case is that I don't think the
> iterator returns them in insertion order, it will work for the first
> "capacity" inserts and then once the array starts to wrap it will return
> them in the array order starting from index 0.  Perhaps changing the
> iterator to start at the current position and wrap around at most once
> until current position == start position?
>
> @Szabolcs - I don't see any data race problems.  I think your scenario
> goes like this...
>
> T1 - Calls add() enters nextPos(), gets current = 0 and newValue = 1
> T2 - ditto
> T1 - compareAndSet( 0, 1 ), succeeds and returns 0.
> T3 - Calls add() enters nextPos(), gets current = 1 and newValue = 2
> T3 - compareAndSet( 1, 2 ), succeeds and returns 1.
> T2 - compareAndSet( 0, 1 ), fails and loops.
> T2 - current = 2 and newValue = 3
> T2 - compareAndSet( 2, 3 ), succeeds and return 2.
>
> Unless I'm missing or misunderstanding something.
>
> So:
> T1 = 0
> T3 = 1
> T2 = 2
>
> All distinct values, not in order of calling add(), but this is an
> unfair structure (fine for my use-case).  If any thread calls
> compareAndSet() all other threads that have stored a current value will
> now fail their call to compareAndSet() and be forced to refetch current
> and try again.
>
> Cheers.
>
> Mike.
>
> -----Original Message-----
> From: Hanson Char [mailto:hanson.char at gmail.com]
> Sent: 18 April 2007 19:36
> To: Mike Quilleash
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] MRULinkedBlockingQueue
>
> Are you trying to have a thread-safe bounded buffer that keeps only the
> latest information ?  If so, you can consider the use of an
> AtomicReferenceArray for implementing the bounded buffer, together with
> an AtomicInteger for the current index pointing to the next slot to put
> the latest element.  As long as the nextPosition operation returns an
> index modulus the length of the array, you got the effect of a circular
> buffer.
>
> For retrieval of the latest info (as a whole), just iterate through the
> entire array ignoring the empty (ie null) slots.  Is that good enough
> for your use case ?
>
> Thread-safe, concurrent (ie lock free).
>
> See CircularBuffer.java below.
>
> Hanson Char
>
> import java.util.Iterator;
> import java.util.concurrent.atomic.AtomicInteger;
> import java.util.concurrent.atomic.AtomicReferenceArray;
>
> public class CircularBuffer<T> implements Iterable<T> {
>     private final AtomicReferenceArray<T> a;
>     private final AtomicInteger pos = new AtomicInteger();
>
>     public CircularBuffer(int size)
>     {
>         a = new AtomicReferenceArray<T>(size);
>     }
>
>     public T add(T ele) {
>         T ret = a.getAndSet(
>                     nextpos(), ele);
>         return ret;
>     }
>
>     public int size() {
>         return a.length();
>     }
>
>     public Iterator<T> iterator()
>     {
>         return new Iterator<T>()
>         {
>             private int cur;
>
>             public boolean hasNext()
>             {
>                 return cur < a.length()
>                     && a.get(cur) != null;
>             }
>
>             public T next() {
>                 if (cur < a.length())
>                     return a.get(cur++);
>                 return null;
>             }
>
>             public void remove() {
>                 throw new UnsupportedOperationException("remove not
> supported");
>             }
>         };
>     }
>
>     private int nextpos()
>     {
>         for (;;) {
>             final int current = pos.get();
>             final int newValue = (current + 1) % a.length();
>
>             if (pos.compareAndSet(current, newValue))
>                 return current;
>         }
>     }
> }
>
>
> On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> >
> >
> > Hi all,
> >
> > Has anyone seen or comes across an collection implementation that has
> > the following characteristics.
> >
> > 1) Concurrent
> > 2) Maintains insertion order (for iteration)
> > 3) Capacity bound
> > 4) An add() that would cause the capacity to exceed the limit would
> > remove the oldest element and add a new one.
> >
> > I thought of the following extension to LinkedBlockingQueue which
> > simply loops in add() trying to offer() and removing an element from
> > the queue if the offer() fails.
> >
> >
> > public class MRULinkedBlockingQueue< T > extends LinkedBlockingQueue<
> > T > {
> >     public MRULinkedBlockingQueue( int capacity )
> >     {
> >         super( capacity );
> >     }
> >
> >     @Override
> >     public boolean add( T o )
> >     {
> >         for ( ;; )
> >         {
> >             // try and offer the element
> >             if ( offer( o ) )
> >                 return true;
> >
> >             // remove the head of the queue to make room if the offer
> > failed.
> >             poll();
> >         }
> >     }
> > }
> >
> >
> > Any comments appreciated.
> >
> >
> >   This e-mail is bound by the terms and conditions described at
> > http://www.subexazure.com/mail-disclaimer.html
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
>
>  This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html
>
>

From mike.quilleash at subexazure.com  Wed Apr 18 16:25:23 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 18 Apr 2007 16:25:23 -0400
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <ca53c8f80704181317i13ac9f7ak455541cef8d37086@mail.gmail.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E06816749@MI8NYCMAIL15.Mi8.com>

You're mostly correct, it's about only having the most recent x items
available as this structure will be reasonably heavily travelled over a
period of time so I don't want it to balloon but retrieval order is
important to get the current entries in the order they were inserted.

Appreicate the suggestions though :)

Cheers.

Mike.

-----Original Message-----
From: Hanson Char [mailto:hanson.char at gmail.com] 
Sent: 18 April 2007 21:18
To: Mike Quilleash 
Cc: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] MRULinkedBlockingQueue

>I don't think the iterator returns them in insertion order,

No the iterator isn't designed to return the elements in insertion
order.  I was just speculating your requirement is probably just about
getting a snapshot of the buffer containing the latest info of some
sort.  In that case you wouldn't care too much about the order among
the latest, as long as they are the latest.   But my speculation is
probably wrong :)

Cheers,
Hanson Char

On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> Thanks for the replies.
>
> That's an interesting idea, I hadn't considered using the Atomic 
> stuff, not much experience with it beyond using AtomicInteger for
counting.
>
> The only problem I see for my use case is that I don't think the 
> iterator returns them in insertion order, it will work for the first 
> "capacity" inserts and then once the array starts to wrap it will 
> return them in the array order starting from index 0.  Perhaps 
> changing the iterator to start at the current position and wrap around

> at most once until current position == start position?
>
> @Szabolcs - I don't see any data race problems.  I think your scenario

> goes like this...
>
> T1 - Calls add() enters nextPos(), gets current = 0 and newValue = 1
> T2 - ditto
> T1 - compareAndSet( 0, 1 ), succeeds and returns 0.
> T3 - Calls add() enters nextPos(), gets current = 1 and newValue = 2
> T3 - compareAndSet( 1, 2 ), succeeds and returns 1.
> T2 - compareAndSet( 0, 1 ), fails and loops.
> T2 - current = 2 and newValue = 3
> T2 - compareAndSet( 2, 3 ), succeeds and return 2.
>
> Unless I'm missing or misunderstanding something.
>
> So:
> T1 = 0
> T3 = 1
> T2 = 2
>
> All distinct values, not in order of calling add(), but this is an 
> unfair structure (fine for my use-case).  If any thread calls
> compareAndSet() all other threads that have stored a current value 
> will now fail their call to compareAndSet() and be forced to refetch 
> current and try again.
>
> Cheers.
>
> Mike.
>
> -----Original Message-----
> From: Hanson Char [mailto:hanson.char at gmail.com]
> Sent: 18 April 2007 19:36
> To: Mike Quilleash
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] MRULinkedBlockingQueue
>
> Are you trying to have a thread-safe bounded buffer that keeps only 
> the latest information ?  If so, you can consider the use of an 
> AtomicReferenceArray for implementing the bounded buffer, together 
> with an AtomicInteger for the current index pointing to the next slot 
> to put the latest element.  As long as the nextPosition operation 
> returns an index modulus the length of the array, you got the effect 
> of a circular buffer.
>
> For retrieval of the latest info (as a whole), just iterate through 
> the entire array ignoring the empty (ie null) slots.  Is that good 
> enough for your use case ?
>
> Thread-safe, concurrent (ie lock free).
>
> See CircularBuffer.java below.
>
> Hanson Char
>
> import java.util.Iterator;
> import java.util.concurrent.atomic.AtomicInteger;
> import java.util.concurrent.atomic.AtomicReferenceArray;
>
> public class CircularBuffer<T> implements Iterable<T> {
>     private final AtomicReferenceArray<T> a;
>     private final AtomicInteger pos = new AtomicInteger();
>
>     public CircularBuffer(int size)
>     {
>         a = new AtomicReferenceArray<T>(size);
>     }
>
>     public T add(T ele) {
>         T ret = a.getAndSet(
>                     nextpos(), ele);
>         return ret;
>     }
>
>     public int size() {
>         return a.length();
>     }
>
>     public Iterator<T> iterator()
>     {
>         return new Iterator<T>()
>         {
>             private int cur;
>
>             public boolean hasNext()
>             {
>                 return cur < a.length()
>                     && a.get(cur) != null;
>             }
>
>             public T next() {
>                 if (cur < a.length())
>                     return a.get(cur++);
>                 return null;
>             }
>
>             public void remove() {
>                 throw new UnsupportedOperationException("remove not 
> supported");
>             }
>         };
>     }
>
>     private int nextpos()
>     {
>         for (;;) {
>             final int current = pos.get();
>             final int newValue = (current + 1) % a.length();
>
>             if (pos.compareAndSet(current, newValue))
>                 return current;
>         }
>     }
> }
>
>
> On 4/18/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:
> >
> >
> > Hi all,
> >
> > Has anyone seen or comes across an collection implementation that 
> > has the following characteristics.
> >
> > 1) Concurrent
> > 2) Maintains insertion order (for iteration)
> > 3) Capacity bound
> > 4) An add() that would cause the capacity to exceed the limit would 
> > remove the oldest element and add a new one.
> >
> > I thought of the following extension to LinkedBlockingQueue which 
> > simply loops in add() trying to offer() and removing an element from

> > the queue if the offer() fails.
> >
> >
> > public class MRULinkedBlockingQueue< T > extends 
> > LinkedBlockingQueue< T > {
> >     public MRULinkedBlockingQueue( int capacity )
> >     {
> >         super( capacity );
> >     }
> >
> >     @Override
> >     public boolean add( T o )
> >     {
> >         for ( ;; )
> >         {
> >             // try and offer the element
> >             if ( offer( o ) )
> >                 return true;
> >
> >             // remove the head of the queue to make room if the 
> > offer failed.
> >             poll();
> >         }
> >     }
> > }
> >
> >
> > Any comments appreciated.
> >
> >
> >   This e-mail is bound by the terms and conditions described at 
> > http://www.subexazure.com/mail-disclaimer.html
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
>
>  This e-mail is bound by the terms and conditions described at 
> http://www.subexazure.com/mail-disclaimer.html
>
>


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From szabolcs.ferenczi at gmail.com  Wed Apr 18 16:49:36 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 18 Apr 2007 22:49:36 +0200
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <DAE04D9F6FD21448A220918A522FB60E06816712@MI8NYCMAIL15.Mi8.com>
References: <ca53c8f80704181136o7f852334y479b219d51abe4bc@mail.gmail.com>
	<DAE04D9F6FD21448A220918A522FB60E06816712@MI8NYCMAIL15.Mi8.com>
Message-ID: <c8955b000704181349o211fabe3y160f15c49a620725@mail.gmail.com>

On 18/04/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:

> @Szabolcs - I don't see any data race problems.  I think your scenario
> goes like this...
>
> T1 - Calls add() enters nextPos(), gets current = 0 and newValue = 1
> T2 - ditto
> T1 - compareAndSet( 0, 1 ), succeeds and returns 0.
> T3 - Calls add() enters nextPos(), gets current = 1 and newValue = 2
> T3 - compareAndSet( 1, 2 ), succeeds and returns 1.
> T2 - compareAndSet( 0, 1 ), fails and loops.
> T2 - current = 2 and newValue = 3
> T2 - compareAndSet( 2, 3 ), succeeds and return 2.
>
> Unless I'm missing or misunderstanding something.

I started the story with a limited capacity array of size 2. I hope it
is a legal assumption. Then the story goes a bit different. Also note
that I have assumed an indefinite long delay from the return of
nextpos(). It is again legitimate assumption. That is part of the game
in a concurrent situation just like race conditions, isn't it?  It is
the beauty of the lock-free algorithms that you can legally assume
any long delay between any two atomic operations and the algorithm
should keep the same functionality, if I might remark.

Szabolcs

From Martin.Buchholz at Sun.COM  Wed Apr 18 16:57:42 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Wed, 18 Apr 2007 13:57:42 -0700
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 27,
	Issue 33
In-Reply-To: <mailman.1812.1176816914.19110.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.1812.1176816914.19110.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <46268646.40408@sun.com>

> From: "David Holmes" <dcholmes at optusnet.com.au>
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not
> 	throwClassCastException
> To: "Szabolcs Ferenczi" <szabolcs.ferenczi at gmail.com>
> Cc: Concurrency-interest at cs.oswego.edu
> Message-ID: <NFBBKALFDCPFIDBNKAPCEEFIHGAA.dcholmes at optusnet.com.au>
> Content-Type: text/plain;	charset="iso-8859-1"
> 
> My apologies, seems someone has (perhaps unintentionally) changed the
> specification, as I was looking at the Java 5 documentation:
> 
> http://java.sun.com/j2se/1.5.0/docs/api/java/util/AbstractQueue.html#add(E)
> 
> where ClassCastException (and IllegalArgumentException) are not redeclared
> to be thrown.

There was a significant effort in jdk6 to have more correct exception
specifications in java.util.

6269713: (coll) Unchecked exception specifications of collection classes
are missing or inaccurate
6269739: BlockingQueue.drainTo needs to throw all unchecked exceptions
that Collection.add does
6458306: Executor classes missing unchecked exception specs

A key idea is that all of the AbstractFoo classes are for use only
by Collection Framework class implementers (that is, they provide only
code), and do not participate in the specification of use by clients.

Whether a concrete class
is a subclass of AbstractFoo should play no part in its specification.
Unfortunately, the Java language does not separate subtyping and
implementation inheritance, javadoc provides no way to mark a class or a
method as pure implementation, and javadoc always prefers superclasses
to superinterfaces for the purpose of javadoc inheritance, with the
result that creators of public concrete subclasses of AbstractFoo
need to do a lot of unnecessary specification cut-n-paste from Foo
instead of AbstractFoo.
At least we save some repetition with "@throws @{inheritDoc}"

This is unlikely to improve soon.

Inheritance has always been the most problematic feature of
Object Orientation.

> Given the use of generics, it is not unreasonable to infer that trying to
> add anything other than an E will indeed cause ClassCastException to be
> thrown.

In practice, many generified classes provide only compile-time type
safety, which can be circumvented using raw types and casting,
so programmers can and do add Integers to a List<String>.

> Arguably the Java 6 documentation is more correct,

I've always argued that the most recent spec (i.e. now jdk7) is the
best documentation available for previous releases (like jdk5).

 as until offer() et al
> are defined you don't know whether or not the exceptions will be thrown. But
> overall I have to say this is a bit of a mess. The base class is trying to
> allow for a range of conditions that a subclass might impose and so
> documenting the possible/potential exceptions, but the subclasses are
> leaving open the possibility for their own subclasses to strengthen the
> conditions, and so still declare exceptions that they themselves will never
> throw.
> 
> There's really no way to fix this - the existing specifications will never
> be changed - even though is a documentation issue more than anything, as
> none of the exceptions involved are (or could be) checked exceptions.

Completely agreed.

Martin

> David Holmes

From Martin.Buchholz at Sun.COM  Wed Apr 18 17:12:44 2007
From: Martin.Buchholz at Sun.COM (Martin Buchholz)
Date: Wed, 18 Apr 2007 14:12:44 -0700
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 27,
	Issue 35
In-Reply-To: <mailman.1864.1176854090.19110.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.1864.1176854090.19110.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <462689CC.20002@sun.com>

Collection.contains and Collection.remove are both
spec'ed in the same way to use the phrase "(optional)",
but they are not tied to each other.  Sensible implementations
will likely throw the same exceptions for unsuitable elements,
but there is no guarantee, and it is strictly speaking an
incompatible spec change, and it doesn't seem worth adding
such a guarantee at this time.  (All changes to the Java spec
require a lot of paperwork!)

Martin

> From: "Jason Mehrens" <jason_mehrens at hotmail.com>
> Subject: Re: [concurrency-interest] LinkedBlockingQueue does not
> 	throwNullPointerException for the method call contains
> To: joe.bowbeer at gmail.com, concurrency-interest at cs.oswego.edu
> Message-ID: <BAY142-F285177B4C26B3B25993D3B83510 at phx.gbl>
> Content-Type: text/plain; format=flowed
> 
> I think it makes sense to tie the optional behavior of contains to the 
> optional behavior of remove.  From what I can tell that detail is not 
> specified in the docs but, the concrete implementations in the JDK seem to 
> enforce this detail.
> 
> For instance, if I wrote a Collection that was a ReadWriteLock wrapper for a 
> single thread collection like the synchronizedCollection but mapped writes 
> to the write lock and reads to the read lock.
> If remove is written like:
> 
> public boolean remove(Object o) {
>   if(write.tryLock()) {
>     try {
>        return col.remove(o);
>     }
>     finally {
>        write.unlock();
>     }
>   }
> 
>   read.lock();
>   try {
>     if(!col.contains(o)) {
>       return false;
>     }
>   }
>   finally {
>     read.unlock();
>   }
> 
>   write.lock();
>    try {
>       return col.remove(o);
>    }
>    finally {
>       write.unlock();
>    }
> }
> 
> If contains and remove do not handle optional exceptions then same way then 
> "optional" means "depending of the state of write lock" for the above 
> implementation.  Which I don't think was the intended meaning "optional".  
> Is this detail worth specifying?
> 
> Jason Mehrens

From mike.quilleash at subexazure.com  Wed Apr 18 17:58:29 2007
From: mike.quilleash at subexazure.com (Mike Quilleash )
Date: Wed, 18 Apr 2007 17:58:29 -0400
Subject: [concurrency-interest] MRULinkedBlockingQueue
In-Reply-To: <c8955b000704181349o211fabe3y160f15c49a620725@mail.gmail.com>
Message-ID: <DAE04D9F6FD21448A220918A522FB60E0681681C@MI8NYCMAIL15.Mi8.com>

Ah I see what you mean when there are more threads contending than there
are buffer slots available.  You are correct I believe, if three threads
contend for two slots then one slot will get updated twice, and not
necessarily in the order that add() was called.

I think that's just part-and-parcel of concurrency in situations like
this, if lots of threads arrive at a critical point at the same time, in
the abscense of any fairness logic, then "lost updates" can sometimes
occur (e.g. ConcurrentMap.put()).  I guess we just have to make
judgements on whether this is acceptable or not for a particular
scenario.  In this instance this is ok for me as the size will be 20+
and the concurrent thread count should not be more than 5.

Cheers.

Mike.

-----Original Message-----
From: Szabolcs Ferenczi [mailto:szabolcs.ferenczi at gmail.com] 
Sent: 18 April 2007 21:50
To: Mike Quilleash 
Cc: Hanson Char; Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] MRULinkedBlockingQueue

On 18/04/07, Mike Quilleash <mike.quilleash at subexazure.com> wrote:

> @Szabolcs - I don't see any data race problems.  I think your scenario

> goes like this...
>
> T1 - Calls add() enters nextPos(), gets current = 0 and newValue = 1
> T2 - ditto
> T1 - compareAndSet( 0, 1 ), succeeds and returns 0.
> T3 - Calls add() enters nextPos(), gets current = 1 and newValue = 2
> T3 - compareAndSet( 1, 2 ), succeeds and returns 1.
> T2 - compareAndSet( 0, 1 ), fails and loops.
> T2 - current = 2 and newValue = 3
> T2 - compareAndSet( 2, 3 ), succeeds and return 2.
>
> Unless I'm missing or misunderstanding something.

I started the story with a limited capacity array of size 2. I hope it
is a legal assumption. Then the story goes a bit different. Also note
that I have assumed an indefinite long delay from the return of
nextpos(). It is again legitimate assumption. That is part of the game
in a concurrent situation just like race conditions, isn't it?  It is
the beauty of the lock-free algorithms that you can legally assume any
long delay between any two atomic operations and the algorithm should
keep the same functionality, if I might remark.

Szabolcs


 This e-mail is bound by the terms and conditions described at http://www.subexazure.com/mail-disclaimer.html



From szabolcs.ferenczi at gmail.com  Thu Apr 19 16:11:16 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Thu, 19 Apr 2007 22:11:16 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread safe?
Message-ID: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>

LBQ is meant to be a shared data structure used by concurrent threads.
It has a method: isEmpty() with the following documentation:

"Returns true if this collection contains no elements."

Is it thread safe?

Best Regards,
Szabolcs

From hanson.char at gmail.com  Thu Apr 19 16:50:01 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 19 Apr 2007 13:50:01 -0700
Subject: [concurrency-interest] Pointless synchronized ?
Message-ID: <ca53c8f80704191350t7daed53cw21ba238e35b819cf@mail.gmail.com>

I see code (in some pretty common opensource projects) like:

    private static ThreadLocal registry = new ThreadLocal() {
        protected synchronized Object initialValue() {
            // ...
        }
    };

It seems pointless to have the initialValue method synchronized, since
it's thread safe by nature.

Or am I missing something ?

Hanson Char

From szabolcs.ferenczi at gmail.com  Thu Apr 19 17:31:45 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Thu, 19 Apr 2007 23:31:45 +0200
Subject: [concurrency-interest] Pointless synchronized ?
In-Reply-To: <ca53c8f80704191350t7daed53cw21ba238e35b819cf@mail.gmail.com>
References: <ca53c8f80704191350t7daed53cw21ba238e35b819cf@mail.gmail.com>
Message-ID: <c8955b000704191431j1c93151uebd53026bc4ca5e@mail.gmail.com>

Isn't it so thread safe as a piece of dead code can be?
Szabolcs

On 19/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> I see code (in some pretty common opensource projects) like:
>
>     private static ThreadLocal registry = new ThreadLocal() {
>         protected synchronized Object initialValue() {
>             // ...
>         }
>     };
>
> It seems pointless to have the initialValue method synchronized, since
> it's thread safe by nature.
>
> Or am I missing something ?
>
> Hanson Char
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From kasper at kav.dk  Thu Apr 19 18:07:39 2007
From: kasper at kav.dk (Kasper Nielsen)
Date: Fri, 20 Apr 2007 00:07:39 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
 safe?
In-Reply-To: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
Message-ID: <4627E82B.9050005@kav.dk>

Szabolcs Ferenczi wrote:
> LBQ is meant to be a shared data structure used by concurrent threads.
> It has a method: isEmpty() with the following documentation:
>
> "Returns true if this collection contains no elements."
>
> Is it thread safe?
Yes it is thread safe. And what exactly makes you wonder if it isn't?

- Kasper

From dcholmes at optusnet.com.au  Thu Apr 19 18:59:56 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 20 Apr 2007 08:59:56 +1000
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
	safe?
In-Reply-To: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEGLHGAA.dcholmes@optusnet.com.au>

Szabolcs Ferenczi writes:
> LBQ is meant to be a shared data structure used by concurrent threads.
> It has a method: isEmpty() with the following documentation:
>
> "Returns true if this collection contains no elements."
>
> Is it thread safe?

In the sense that concurrent calls to this method with other methods on the
LBQ won't lead to broken invariants - yes it is "thread-safe".

But like any query method on a potentially concurrently modified data
structure, the answer could have changed the instant after the question has
been asked. So the programmer has to know when asking this question makes
sense. You can't use it as part of a check-then-act sequence:

  if (q.isEmpty()) q...

when concurrent modification is possible.

David Holmes


From dcholmes at optusnet.com.au  Thu Apr 19 19:05:21 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 20 Apr 2007 09:05:21 +1000
Subject: [concurrency-interest] Pointless synchronized ?
In-Reply-To: <ca53c8f80704191350t7daed53cw21ba238e35b819cf@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEGLHGAA.dcholmes@optusnet.com.au>

Hanson,

The value obtained from a ThreadLocal is a per-thread value, but the
ThreadLocal object itself is shared by all threads that access it. So it is
still possible to have state in a ThreadLocal object that is shared  mutable
state and so needs protection from concurrent access. For a contrived
example:

  private static ThreadLocal counter = new ThreadLocal() {
      private int initialCount = 0;

      protected synchronized Object initialValue() {
         return Integer.valueOf(initialCount++);
      }
  };

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson
> Char
> Sent: Friday, 20 April 2007 6:50 AM
> To: concurrency-interest
> Subject: [concurrency-interest] Pointless synchronized ?
>
>
> I see code (in some pretty common opensource projects) like:
>
>     private static ThreadLocal registry = new ThreadLocal() {
>         protected synchronized Object initialValue() {
>             // ...
>         }
>     };
>
> It seems pointless to have the initialValue method synchronized, since
> it's thread safe by nature.
>
> Or am I missing something ?
>
> Hanson Char
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From hanson.char at gmail.com  Thu Apr 19 19:24:10 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 19 Apr 2007 16:24:10 -0700
Subject: [concurrency-interest] Pointless synchronized ?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEGLHGAA.dcholmes@optusnet.com.au>
References: <ca53c8f80704191350t7daed53cw21ba238e35b819cf@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEGLHGAA.dcholmes@optusnet.com.au>
Message-ID: <ca53c8f80704191624iea307f8nca2694c82f4b3a7c@mail.gmail.com>

I see.  Good point.  In this case, however, the code is actually:

     private static ThreadLocal registry = new ThreadLocal() {
         protected synchronized Object initialValue() {
             return new HashMap();
         }
     };

Now, that's pretty pointless.  Right ?

Hanson Char

On 4/19/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> Hanson,
>
> The value obtained from a ThreadLocal is a per-thread value, but the
> ThreadLocal object itself is shared by all threads that access it. So it is
> still possible to have state in a ThreadLocal object that is shared  mutable
> state and so needs protection from concurrent access. For a contrived
> example:
>
>   private static ThreadLocal counter = new ThreadLocal() {
>       private int initialCount = 0;
>
>       protected synchronized Object initialValue() {
>          return Integer.valueOf(initialCount++);
>       }
>   };
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson
> > Char
> > Sent: Friday, 20 April 2007 6:50 AM
> > To: concurrency-interest
> > Subject: [concurrency-interest] Pointless synchronized ?
> >
> >
> > I see code (in some pretty common opensource projects) like:
> >
> >     private static ThreadLocal registry = new ThreadLocal() {
> >         protected synchronized Object initialValue() {
> >             // ...
> >         }
> >     };
> >
> > It seems pointless to have the initialValue method synchronized, since
> > it's thread safe by nature.
> >
> > Or am I missing something ?
> >
> > Hanson Char
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From dcholmes at optusnet.com.au  Thu Apr 19 19:27:37 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 20 Apr 2007 09:27:37 +1000
Subject: [concurrency-interest] Pointless synchronized ?
In-Reply-To: <ca53c8f80704191624iea307f8nca2694c82f4b3a7c@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEGMHGAA.dcholmes@optusnet.com.au>

Yes that synchronization is semantically pointless.

David

> -----Original Message-----
> From: Hanson Char [mailto:hanson.char at gmail.com]
> Sent: Friday, 20 April 2007 9:24 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] Pointless synchronized ?
>
>
> I see.  Good point.  In this case, however, the code is actually:
>
>      private static ThreadLocal registry = new ThreadLocal() {
>          protected synchronized Object initialValue() {
>              return new HashMap();
>          }
>      };
>
> Now, that's pretty pointless.  Right ?
>
> Hanson Char
>
> On 4/19/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > Hanson,
> >
> > The value obtained from a ThreadLocal is a per-thread value, but the
> > ThreadLocal object itself is shared by all threads that access
> it. So it is
> > still possible to have state in a ThreadLocal object that is
> shared  mutable
> > state and so needs protection from concurrent access. For a contrived
> > example:
> >
> >   private static ThreadLocal counter = new ThreadLocal() {
> >       private int initialCount = 0;
> >
> >       protected synchronized Object initialValue() {
> >          return Integer.valueOf(initialCount++);
> >       }
> >   };
> >
> > Cheers,
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson
> > > Char
> > > Sent: Friday, 20 April 2007 6:50 AM
> > > To: concurrency-interest
> > > Subject: [concurrency-interest] Pointless synchronized ?
> > >
> > >
> > > I see code (in some pretty common opensource projects) like:
> > >
> > >     private static ThreadLocal registry = new ThreadLocal() {
> > >         protected synchronized Object initialValue() {
> > >             // ...
> > >         }
> > >     };
> > >
> > > It seems pointless to have the initialValue method synchronized, since
> > > it's thread safe by nature.
> > >
> > > Or am I missing something ?
> > >
> > > Hanson Char
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >


From hanson.char at gmail.com  Fri Apr 20 01:18:13 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 19 Apr 2007 22:18:13 -0700
Subject: [concurrency-interest] Pointless synchronized ?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEGMHGAA.dcholmes@optusnet.com.au>
References: <ca53c8f80704191624iea307f8nca2694c82f4b3a7c@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEGMHGAA.dcholmes@optusnet.com.au>
Message-ID: <ca53c8f80704192218u49174e8er5a9588bb1af8c911@mail.gmail.com>

Just removed some pointless synchronized from some pretty popular classes:

http://svn.apache.org/viewvc/jakarta/commons/proper/lang/trunk/src/java/org/apache/commons/lang/builder/ToStringStyle.java?r1=500497&r2=530645
http://svn.apache.org/viewvc/jakarta/commons/proper/lang/trunk/src/java/org/apache/commons/lang/builder/HashCodeBuilder.java?r1=447989&r2=530648

Thanks,
Hanson Char

On 4/19/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> Yes that synchronization is semantically pointless.
>
> David
>
> > -----Original Message-----
> > From: Hanson Char [mailto:hanson.char at gmail.com]
> > Sent: Friday, 20 April 2007 9:24 AM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest
> > Subject: Re: [concurrency-interest] Pointless synchronized ?
> >
> >
> > I see.  Good point.  In this case, however, the code is actually:
> >
> >      private static ThreadLocal registry = new ThreadLocal() {
> >          protected synchronized Object initialValue() {
> >              return new HashMap();
> >          }
> >      };
> >
> > Now, that's pretty pointless.  Right ?
> >
> > Hanson Char
> >
> > On 4/19/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > > Hanson,
> > >
> > > The value obtained from a ThreadLocal is a per-thread value, but the
> > > ThreadLocal object itself is shared by all threads that access
> > it. So it is
> > > still possible to have state in a ThreadLocal object that is
> > shared  mutable
> > > state and so needs protection from concurrent access. For a contrived
> > > example:
> > >
> > >   private static ThreadLocal counter = new ThreadLocal() {
> > >       private int initialCount = 0;
> > >
> > >       protected synchronized Object initialValue() {
> > >          return Integer.valueOf(initialCount++);
> > >       }
> > >   };
> > >
> > > Cheers,
> > > David Holmes
> > >
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson
> > > > Char
> > > > Sent: Friday, 20 April 2007 6:50 AM
> > > > To: concurrency-interest
> > > > Subject: [concurrency-interest] Pointless synchronized ?
> > > >
> > > >
> > > > I see code (in some pretty common opensource projects) like:
> > > >
> > > >     private static ThreadLocal registry = new ThreadLocal() {
> > > >         protected synchronized Object initialValue() {
> > > >             // ...
> > > >         }
> > > >     };
> > > >
> > > > It seems pointless to have the initialValue method synchronized, since
> > > > it's thread safe by nature.
> > > >
> > > > Or am I missing something ?
> > > >
> > > > Hanson Char
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at altair.cs.oswego.edu
> > > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> > >
>
>

From szabolcs.ferenczi at gmail.com  Fri Apr 20 07:27:07 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 20 Apr 2007 13:27:07 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
	safe?
In-Reply-To: <4627E82B.9050005@kav.dk>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
	<4627E82B.9050005@kav.dk>
Message-ID: <c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>

On 20/04/07, Kasper Nielsen <kasper at kav.dk> wrote:
>
> Yes it is thread safe. And what exactly makes you wonder if it isn't?

I was wondering whether it was planned to be used in a multi-threading
environment. Now, although it is thread safe in the sense that it does
not brake anything in the shared data structure, it is a useless
method for a data structure that is designed to be used by concurrent
threads. You can query whether it is empty, but you cannot do anything
with the result. Either isEmpty() yields true or false, anything can
be the case. The queue can even be full at the very time the isEmpty
returns true.

So we can conclude this method on LBQ is something that can be
classified as YAGNI.

Can anyone show a meaningful use of that query in a multithreading environment?

Best Regards,
Szabolcs

From holger at wizards.de  Fri Apr 20 10:27:38 2007
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Fri, 20 Apr 2007 16:27:38 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
 safe?
In-Reply-To: <c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>	<4627E82B.9050005@kav.dk>
	<c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
Message-ID: <4628CDDA.5050103@wizards.de>

Szabolcs Ferenczi wrote:
> I was wondering whether it was planned to be used in a multi-threading
> environment. Now, although it is thread safe in the sense that it does
> not brake anything in the shared data structure, it is a useless
> method for a data structure that is designed to be used by concurrent

No, it is not. Since Java does not allow one to actually remove methods in
subclasses, the only way is to let the user determine on whether the
method makes sense in a certain context. Should a concurrent class'
isEmpty() throw MightBeStaleStateException instead?
If you want a language with better compositional qualities on the method
level, try Self or try to fix the Java collection classes to not use
inheritance for roles & capabilities - which will never happen.

-h

From sberlin at gmail.com  Fri Apr 20 10:54:32 2007
From: sberlin at gmail.com (Sam Berlin)
Date: Fri, 20 Apr 2007 10:54:32 -0400
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
	safe?
In-Reply-To: <c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
	<4627E82B.9050005@kav.dk>
	<c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
Message-ID: <19196d860704200754l4b77d495y85fbf6e7fd13ebab@mail.gmail.com>

In the context of a bug-report snapshot, it could be useful.  It could
also be useful in a variety of other ways, such as someone handing you
a LBQ that is expected to have some initial data, and then your code
is intended to spawn threads to work on the items in that queue.  Your
code could query the size and throw an exception if it doesn't have
the expected number of elements.

Sam

On 4/20/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
> On 20/04/07, Kasper Nielsen <kasper at kav.dk> wrote:
> >
> > Yes it is thread safe. And what exactly makes you wonder if it isn't?
>
> I was wondering whether it was planned to be used in a multi-threading
> environment. Now, although it is thread safe in the sense that it does
> not brake anything in the shared data structure, it is a useless
> method for a data structure that is designed to be used by concurrent
> threads. You can query whether it is empty, but you cannot do anything
> with the result. Either isEmpty() yields true or false, anything can
> be the case. The queue can even be full at the very time the isEmpty
> returns true.
>
> So we can conclude this method on LBQ is something that can be
> classified as YAGNI.
>
> Can anyone show a meaningful use of that query in a multithreading environment?
>
> Best Regards,
> Szabolcs
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From szabolcs.ferenczi at gmail.com  Fri Apr 20 15:18:54 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 20 Apr 2007 21:18:54 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
	safe?
In-Reply-To: <4628CDDA.5050103@wizards.de>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
	<4627E82B.9050005@kav.dk>
	<c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
	<4628CDDA.5050103@wizards.de>
Message-ID: <c8955b000704201218p290c9000l9352934f049ed2f2@mail.gmail.com>

On 20/04/07, Holger Hoffst?tte <holger at wizards.de> wrote:
> Szabolcs Ferenczi wrote:
> > I was wondering whether it was planned to be used in a multi-threading
> > environment. Now, although it is thread safe in the sense that it does
> > not brake anything in the shared data structure, it is a useless
> > method for a data structure that is designed to be used by concurrent
>
> No, it is not. Since Java does not allow one to actually remove methods in
> subclasses, the only way is to let the user determine on whether the
> method makes sense in a certain context.

You do not have to remove it. There can be other techniques. But first
of all, a shared class should not be derived from a sequential one.
They are simply not compatible just because of the basic and
fundamental difference between the sequential and the concurrent
environment. The isEmpty() method illustrates it well enough.

> Should a concurrent class'
> isEmpty() throw MightBeStaleStateException instead?

If you think it should throw any exception, it is even worse. I am
afraid, it is a very amateur idea in a concurrent environment. The
isEmpty() query is useless, as I have explained earlier. The result of
the query does not tell you anything whatsoever in a concurrent
environment. But throwing an exception, well, that is itself an
exceptionally wrong idea.

I doubt if this query could be used in a concurrent program at all. I
wonder if anyone can show a meaningful application of it. It is a mere
YAGNI. I am afraid, the presence of the isEmpty() call and some other
query method calls on a shared data structure indicate some
incompetence in concurrent programming. It is a bad smell in a
concurrent program, as they would call it in the refactoring arena.

Best Regards,
Szabolcs


From dcholmes at optusnet.com.au  Fri Apr 20 17:02:18 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sat, 21 Apr 2007 07:02:18 +1000
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty()
	threadsafe?
In-Reply-To: <c8955b000704201218p290c9000l9352934f049ed2f2@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEHBHGAA.dcholmes@optusnet.com.au>

Szabolcs,

If you are going to raise this issue every time you come across a query
method on a concurrent collection then it is going to get very tedious for
everyone on this list. As the discussions are going to be the same.

The concurrent collections were defined as extensions of the existing
non-concurrent ones - that is a fact and nothing will change that. Was it
the right choice? You obviously believe not. Fine but that isn't going to
change anything. If you feel the need to argue this then write a blog and
share your views. Other's (such as the expert group that defined these
collections, and the broader Java community that supported their definition)
know that the benefits from maintaining commonality between the concurrent
and non-concurrent collections vastly outweighs the fact that some of the
inherited methods have semantics that are not ideal for a concurrent
environment and have to be used with care and understanding.

You also seem to be under the mistaken impression that a concurrent
collection is always used concurrently 100% of the time it exists. That is
far from true and has been pointed out by a number of people a number of
times, but you seem to ignore it. There are often phases where a concurrent
data structure is not used concurrently and during those times simple query
methods are often used to check application invariants - such as checking
whether a collection is or is not empty.

> > Should a concurrent class'
> > isEmpty() throw MightBeStaleStateException instead?
>
> If you think it should throw any exception, it is even worse. I am
> afraid, it is a very amateur idea in a concurrent environment.

You have misunderstood what Holger meant here. You complained that a method
like isEmpty serves no purpose in a concurrent environment. So Holger was
asking if you thought that all such methods should just throw an exception
(given that we have inherited them and so they already exist) - the
exception basically meaning "this method is not useful in a concurrent
environment so you shouldn't have called it". That would have been one way
to deal with inherited methods that "made no sense".

> The isEmpty() query is useless, as I have explained earlier. The result of
> the query does not tell you anything whatsoever in a concurrent
> environment.

Of course it tells you something. The issue is what inference you draw from
the answer based on the time you ask the question.

Regards,
David Holmes


From brian at quiotix.com  Sun Apr 22 14:28:44 2007
From: brian at quiotix.com (Brian Goetz)
Date: Sun, 22 Apr 2007 14:28:44 -0400
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
 safe?
In-Reply-To: <c8955b000704201218p290c9000l9352934f049ed2f2@mail.gmail.com>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>	<4627E82B.9050005@kav.dk>	<c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>	<4628CDDA.5050103@wizards.de>
	<c8955b000704201218p290c9000l9352934f049ed2f2@mail.gmail.com>
Message-ID: <462BA95C.3020909@quiotix.com>

> I doubt if this query could be used in a concurrent program at all. I
> wonder if anyone can show a meaningful application of it. It is a mere
> YAGNI. I am afraid, the presence of the isEmpty() call and some other
> query method calls on a shared data structure indicate some
> incompetence in concurrent programming. It is a bad smell in a
> concurrent program, as they would call it in the refactoring arena.

To use your words...I think this statement merely reflects your 
incompetence in your analysis of all the ways a concurrent class might 
be intelligently used!

In that light, I offer a credible example: a single-producer, 
multiple-consumer situation.  Since the single producer is the only one 
calling put(), having the producer call isEmpty() and receive "true" 
would allow it to conclude "everything that's been put on the queue has 
been processed, so it is safe to shut down now."

Why might you have only a single-producer?  Perhaps that producer might 
be the GUI event thread, queuing background tasks that would take too 
long to execute in the GUI thread.

Please think a little more before you start using loaded words like 
"incompetence".  It is most unattractive, and, more importantly, makes 
people unreceptive to your ideas -- even when they are sensible.

From szabolcs.ferenczi at gmail.com  Sun Apr 22 14:55:38 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 22 Apr 2007 20:55:38 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
	safe?
In-Reply-To: <462BA95C.3020909@quiotix.com>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
	<4627E82B.9050005@kav.dk>
	<c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
	<4628CDDA.5050103@wizards.de>
	<c8955b000704201218p290c9000l9352934f049ed2f2@mail.gmail.com>
	<462BA95C.3020909@quiotix.com>
Message-ID: <c8955b000704221155k4aae71cft99fac2f1baa83a1f@mail.gmail.com>

On 22/04/07, Brian Goetz <brian at quiotix.com> wrote:

> In that light, I offer a credible example: a single-producer,
> multiple-consumer situation.  Since the single producer is the only one
> calling put(), having the producer call isEmpty() and receive "true"
> would allow it to conclude "everything that's been put on the queue has
> been processed, so it is safe to shut down now."

Hmm... Why should a producer concern about whether the items are
consumed or not? The producer,in fact, can safely shut down as soon as
it has finished its job, can't it. If you cannot shut down the
producer as soon as it has finished, it really indicates something
wrong with your program. You assign too many roles for your producer.

Well, thinking about concurrency needs quite a different attitude to
sequential programming, I must tell you. What seems to be natural to
you in sequential programming, becomes a mistake in a concurrent
environment. Just like what you have pointed out here. Usually queries
on shared data structure are of a bad smell.

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Sun Apr 22 15:36:01 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 22 Apr 2007 21:36:01 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty() thread
	safe?
In-Reply-To: <462BA95C.3020909@quiotix.com>
References: <c8955b000704191311v54157b91v5c394f6cb9620f98@mail.gmail.com>
	<4627E82B.9050005@kav.dk>
	<c8955b000704200427r326b4002x591eac17e30349bb@mail.gmail.com>
	<4628CDDA.5050103@wizards.de>
	<c8955b000704201218p290c9000l9352934f049ed2f2@mail.gmail.com>
	<462BA95C.3020909@quiotix.com>
Message-ID: <c8955b000704221236l1178861cj401fd1313446556c@mail.gmail.com>

On 22/04/07, Brian Goetz <brian at quiotix.com> wrote:

> In that light, I offer a credible example: a single-producer,
> multiple-consumer situation.  Since the single producer is the only one
> calling put(), having the producer call isEmpty() and receive "true"
> would allow it to conclude "everything that's been put on the queue has
> been processed, so it is safe to shut down now."

You really make me wonder: How would your producer look like?

Thread t = new Thread {
  public void run() {
    while (thereAreItemsToProduce()) {
      q.put(item(n));
    }
    while (!q.isEmpty)
      ;
  }
};

Or you would insert a deschedule into your busy loop as well?

    while (!q.isEmpty)
      Thread.yield();

I only hope you would not check the emptiness inside an `if' statement.

Wouldn't you just simply leave out the busy loop? Wouldn't it be simpler?

Thread t = new Thread {
  public void run() {
    while (thereAreItemsToProduce()) {
      q.put(item(n));
    }
  }
};

I am really curious.

After all, concrete examples are I am begging all along.

Best Regards,
Szabolcs

From szabolcs.ferenczi at gmail.com  Sun Apr 22 16:46:10 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Sun, 22 Apr 2007 22:46:10 +0200
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty()
	threadsafe?
In-Reply-To: <E761FA4B9CAA8941B3FAB519E293E78F0178A88A@ATLMSG12.turner.com>
References: <E761FA4B9CAA8941B3FAB519E293E78F0178A88A@ATLMSG12.turner.com>
Message-ID: <c8955b000704221346l3a9fd788m1f6f78b60a5f7966@mail.gmail.com>

On 22/04/07, Griffith, Dave <Dave.Griffith at turner.com> wrote:

> Instead of the producer calling isEmpty(), imagine a separate monitoring
> component making the call.  In high-reliability environments, _every_
> component is shadowed by a monitoring component, and certainly an obvious
> chokepoint like a queue would have health and capacity monitoring.
> Algorithmically uninteresting, but crucial in deployment.

The first guess of the esoteric group was about the producer thread
calling isEmpty() but you changed your mind. No problem. I can imaging
a lot of things but here we should be exact. Some code, please, even
if it is a pseudo code!

Would your monitoring component call isEmpty() in a busy loop or
rather occasionally, inside an `if' statement?

Best Regards,
Szabolcs

From brian at quiotix.com  Sun Apr 22 16:51:36 2007
From: brian at quiotix.com (Brian Goetz)
Date: Sun, 22 Apr 2007 16:51:36 -0400
Subject: [concurrency-interest] Is LinkedBlockingQueue.isEmpty()
	threadsafe?
In-Reply-To: <c8955b000704221346l3a9fd788m1f6f78b60a5f7966@mail.gmail.com>
References: <E761FA4B9CAA8941B3FAB519E293E78F0178A88A@ATLMSG12.turner.com>
	<c8955b000704221346l3a9fd788m1f6f78b60a5f7966@mail.gmail.com>
Message-ID: <462BCAD8.9020608@quiotix.com>

> Would your monitoring component call isEmpty() in a busy loop or
> rather occasionally, inside an `if' statement?

Likely in response to a request by a management agent, which might be 
initiated by a user running jconsole, or a management station 
periodically gathering statistics.  The request would arrive at a 
management entity like a JMX MBean (are you familiar with JMX, jconsole, 
etc?)  The MBean getter (isWorkQueueEmpty(), getWorkQueueSize()) would 
be called from a thread managed by the JMX transport.


From fjanon at gmail.com  Mon Apr 23 09:53:33 2007
From: fjanon at gmail.com (Fred Janon)
Date: Mon, 23 Apr 2007 21:53:33 +0800
Subject: [concurrency-interest] Basic question on making a thread waiting
	for 2 mailboxes...
Message-ID: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>

Hi,

I used to write real time apps using RSX11M+ (and VMS) that had mailboxes
and events. There was a "wait for OR(events)". The task would wait for any
event specified in the OR. Then I would associate an event with a mailbox,
do that for another mailbox and when a message would arrive in one of the 2
mailboxes, the task would awake. I am trying to do that in Java with
threads.

I have been reading "Java Threads",  "JCIP", "Java in a Nutshell" and I
could think about a couple of classes I could use but I would appreciate
some design advice... Or if there is an existing library that does that
already does that, I would appreciate a reference, I did some research and
did not find anything interesting.

Basically I need 1 public mailbox and 1 private mailbox for a thread. The
thread would be blocked until a message arrives in one of the mailboxes. The
mailboxes must have multiple slots. I was thinking about using
LinkedBlockingQueues as mailboxes since I don't want to block the sender (or
avoid it) but I am a bit stuck on making the thread wait for a message in
either queues.

The next step would be to have a ThreadPool for the tasks, sharing a common
public mailbox to process the messages and each have a private mailbox for
system management messages. I guess switching to a single thread to a
ThreadPool would be relatively easy?

Thanks in advance.

Fred
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070423/2b2b9aea/attachment.html 

From alarmnummer at gmail.com  Mon Apr 23 11:29:16 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 23 Apr 2007 17:29:16 +0200
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
Message-ID: <1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>

Hi Fred,

the functionality you are looking for looks a lot like the
http://java.sun.com/j2se/1.4.2/docs/api/java/nio/channels/Selector.html
in non blocking io (nio). Each mailbox can be seen as an
http://java.sun.com/j2se/1.4.2/docs/api/java/nio/channels/SelectableChannel.html
and multiple channels can be handled by a single thread.

But as far as I know there is no synchronization structure in j.u.c
that can provide the same functionality for arbitrary event sources.

On 4/23/07, Fred Janon <fjanon at gmail.com> wrote:
> Hi,
>
> I used to write real time apps using RSX11M+ (and VMS) that had mailboxes
> and events. There was a "wait for OR(events)". The task would wait for any
> event specified in the OR. Then I would associate an event with a mailbox,
> do that for another mailbox and when a message would arrive in one of the 2
> mailboxes, the task would awake. I am trying to do that in Java with
> threads.
>
> I have been reading "Java Threads",  "JCIP", "Java in a Nutshell" and I
> could think about a couple of classes I could use but I would appreciate
> some design advice... Or if there is an existing library that does that
> already does that, I would appreciate a reference, I did some research and
> did not find anything interesting.
>
> Basically I need 1 public mailbox and 1 private mailbox for a thread. The
> thread would be blocked until a message arrives in one of the mailboxes. The
> mailboxes must have multiple slots. I was thinking about using
> LinkedBlockingQueues as mailboxes since I don't want to block the sender (or
> avoid it) but I am a bit stuck on making the thread wait for a message in
> either queues.
>
> The next step would be to have a ThreadPool for the tasks, sharing a common
> public mailbox to process the messages and each have a private mailbox for
> system management messages. I guess switching to a single thread to a
> ThreadPool would be relatively easy?
>
> Thanks in advance.
>
> Fred
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From gregg at cytetech.com  Mon Apr 23 12:43:44 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 23 Apr 2007 11:43:44 -0500
Subject: [concurrency-interest] Basic question on making a thread
 waiting for 2 mailboxes...
In-Reply-To: <1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>
Message-ID: <462CE240.5090502@cytetech.com>



Peter Veentjer wrote:
> But as far as I know there is no synchronization structure in j.u.c
> that can provide the same functionality for arbitrary event sources.
> 
> On 4/23/07, Fred Janon <fjanon at gmail.com> wrote:
> 
>>Hi,
>>
>>I used to write real time apps using RSX11M+ (and VMS) that had mailboxes
>>and events. There was a "wait for OR(events)". The task would wait for any
>>event specified in the OR. Then I would associate an event with a mailbox,
>>do that for another mailbox and when a message would arrive in one of the 2
>>mailboxes, the task would awake. I am trying to do that in Java with
>>threads.

What I would do, is use threads that read from the two queues and put the 
objects into a single queue that you can take from.

Gregg Wonderly

From brian at quiotix.com  Mon Apr 23 12:48:04 2007
From: brian at quiotix.com (Brian Goetz)
Date: Mon, 23 Apr 2007 12:48:04 -0400
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>
Message-ID: <A655FA6F-87A9-4E13-8ABF-257403D88FAF@quiotix.com>

Composing operations on existing blocking operations is difficult;  
one way you can do that is by having an adapter thread that does  
nothing but wait on queue A and move the results to queue T.  If you  
have one adapter thread per source queue (A, B, C), then threads can  
wait on the merged queue T.  But this is ugly, inefficient, and can  
nasty in the edge cases (shutdown, queue full, etc.)  I think you'd  
have to write a "dual headed queue" for the purposes you described  
(which seems entirely doable, as you only need to merge the results  
of two queues.)

Blocking is one of the areas where monitor-based designs do not  
compose well.  The STM guys claim they have the answer.  I hope they do!

On Apr 23, 2007, at 11:29 AM, Peter Veentjer wrote:

> Hi Fred,
>
> the functionality you are looking for looks a lot like the
> http://java.sun.com/j2se/1.4.2/docs/api/java/nio/channels/ 
> Selector.html
> in non blocking io (nio). Each mailbox can be seen as an
> http://java.sun.com/j2se/1.4.2/docs/api/java/nio/channels/ 
> SelectableChannel.html
> and multiple channels can be handled by a single thread.
>
> But as far as I know there is no synchronization structure in j.u.c
> that can provide the same functionality for arbitrary event sources.
>
> On 4/23/07, Fred Janon <fjanon at gmail.com> wrote:
>> Hi,
>>
>> I used to write real time apps using RSX11M+ (and VMS) that had  
>> mailboxes
>> and events. There was a "wait for OR(events)". The task would wait  
>> for any
>> event specified in the OR. Then I would associate an event with a  
>> mailbox,
>> do that for another mailbox and when a message would arrive in one  
>> of the 2
>> mailboxes, the task would awake. I am trying to do that in Java with
>> threads.
>>
>> I have been reading "Java Threads",  "JCIP", "Java in a Nutshell"  
>> and I
>> could think about a couple of classes I could use but I would  
>> appreciate
>> some design advice... Or if there is an existing library that does  
>> that
>> already does that, I would appreciate a reference, I did some  
>> research and
>> did not find anything interesting.
>>
>> Basically I need 1 public mailbox and 1 private mailbox for a  
>> thread. The
>> thread would be blocked until a message arrives in one of the  
>> mailboxes. The
>> mailboxes must have multiple slots. I was thinking about using
>> LinkedBlockingQueues as mailboxes since I don't want to block the  
>> sender (or
>> avoid it) but I am a bit stuck on making the thread wait for a  
>> message in
>> either queues.
>>
>> The next step would be to have a ThreadPool for the tasks, sharing  
>> a common
>> public mailbox to process the messages and each have a private  
>> mailbox for
>> system management messages. I guess switching to a single thread to a
>> ThreadPool would be relatively easy?
>>
>> Thanks in advance.
>>
>> Fred
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at altair.cs.oswego.edu
>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From joe.bowbeer at gmail.com  Mon Apr 23 13:48:11 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 23 Apr 2007 10:48:11 -0700
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
Message-ID: <31f2a7bd0704231048l164c282bmf099bd38b3958513@mail.gmail.com>

I support your intuition to use an Executor.  That gives you a queue
and a pool of threads.  See Executors for a list of prefabbed
configurations.  You'll need to arrange for your producers to package
their events as Runnables so they can be executed by your Executor.

If your mailboxes are prioritized, you can configure your executor to
use a priority queue.

Ignoring Executors for the moment, the basic mechanisms for signaling
threads are Object.notify and Condition.signal.  If you were trying to
build a single-threaded gizmo like you described from scratch, you can
code your thread to await on a Condition, and code your producer or
your queues so that the Condition is signaled whenever an event is
added to either queue.  (If you're using the Object-based mechanism,
then the thread waits on the Object while the producers notify the
Object.)

--Joe

On 4/23/07, Fred Janon <fjanon at gmail.com> wrote:
> Hi,
>
> I used to write real time apps using RSX11M+ (and VMS) that had mailboxes
> and events. There was a "wait for OR(events)". The task would wait for any
> event specified in the OR. Then I would associate an event with a mailbox,
> do that for another mailbox and when a message would arrive in one of the 2
> mailboxes, the task would awake. I am trying to do that in Java with
> threads.
>
> I have been reading "Java Threads",  "JCIP", "Java in a Nutshell" and I
> could think about a couple of classes I could use but I would appreciate
> some design advice... Or if there is an existing library that does that
> already does that, I would appreciate a reference, I did some research and
> did not find anything interesting.
>
> Basically I need 1 public mailbox and 1 private mailbox for a thread. The
> thread would be blocked until a message arrives in one of the mailboxes. The
> mailboxes must have multiple slots. I was thinking about using
> LinkedBlockingQueues as mailboxes since I don't want to block the sender (or
> avoid it) but I am a bit stuck on making the thread wait for a message in
> either queues.
>
> The next step would be to have a ThreadPool for the tasks, sharing a common
> public mailbox to process the messages and each have a private mailbox for
> system management messages. I guess switching to a single thread to a
> ThreadPool would be relatively easy?
>
> Thanks in advance.
>
> Fred
>

From gregg at cytetech.com  Mon Apr 23 15:48:02 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 23 Apr 2007 14:48:02 -0500
Subject: [concurrency-interest] ConcurrentHashMap and null keys
Message-ID: <462D0D72.4080603@cytetech.com>

I'm going though some classloader related code that currently uses a HashMap and 
'synchronized'.  This code has to make use of null keys because it uses return 
values from 'Thread.getContextClassLoader()' and 'ClassLoader.getParent()' as 
real contexts to deal with.  These values, can be null.  Currently 
ConcurrentHashMap doesn't support null keys.  I'd like to create less locking in 
some of this code by removing unnecessary synchronized use.  It's policy related 
code paths, so they are very frequently traveled execution paths in server 
software where multiple threads with different policies will be active.

What are good choices for managing this 'null' key issue?  Should I establish a 
'NULL' value for the times when the key is null?

Gregg Wonderly

From dhanji at gmail.com  Mon Apr 23 23:27:20 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 24 Apr 2007 13:27:20 +1000
Subject: [concurrency-interest] synchronization edge case
Message-ID: <aa067ea10704232027lcc3fe3ag8c932e3ee23de399@mail.gmail.com>

Hi

I cite this puzzle from Josh Bloch and Neal Gafter's "Java Puzzlers:"

synchronized(Thread.class) {
    Thread.sleep(Long.MAX_VALUE);
}

I tested this on a webapp deployed into BEA weblogic and it basically locks
down the entire server so that it is effectively dead (doesnt startup,
doesnt accept new deployments, doesnt service any requests, doesnt
shutdown). Java EE servers are supposed to prevent such malarkey by
installing securitymanagers that restrict (direct) access to threading apis.
But how would one do so in such a case?

I assume that internally synchronized(Thread.class) calls Object.wait(), so
is there a way to lock out wait() without AOP-style interception?

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/cfa80ad4/attachment.html 

From dcholmes at optusnet.com.au  Mon Apr 23 23:55:46 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 24 Apr 2007 13:55:46 +1000
Subject: [concurrency-interest] synchronization edge case
In-Reply-To: <aa067ea10704232027lcc3fe3ag8c932e3ee23de399@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEHMHGAA.dcholmes@optusnet.com.au>

Dhanji,

synchronized(Thread.class) does not call Object.wait(), it simply acquires
the monitor associated with the Thread Class object. This will lock out all
code that also wants to acquire this monitor.

I don't have puzzlers so don't know what the "trick" is with this one. I
couldn't see any explicit acquisitions of this monitor in the JDK library
code. That leaves the implicit ones - the only one of which I'm aware of is
class loading of the Thread class. But as that is done early in the VM
bootstrap it should not be an issue unless your are running newly loaded
classes with unresolved references to the Thread class *and* the VM
explicitly locks the Class object during resolution (which isn't actually
necessary and the next edition of the JVMS will clarify this).

But what you are basically asking is: is there a way to prevent a thread
from acquiring the monitor of a "critical" object? And the answer is no -
not within the language or core API's.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dhanji R.
Prasanna
  Sent: Tuesday, 24 April 2007 1:27 PM
  To: concurrency-interest
  Subject: [concurrency-interest] synchronization edge case


  Hi

  I cite this puzzle from Josh Bloch and Neal Gafter's "Java Puzzlers:"

  synchronized(Thread.class) {
      Thread.sleep(Long.MAX_VALUE);
  }

  I tested this on a webapp deployed into BEA weblogic and it basically
locks down the entire server so that it is effectively dead (doesnt startup,
doesnt accept new deployments, doesnt service any requests, doesnt
shutdown). Java EE servers are supposed to prevent such malarkey by
installing securitymanagers that restrict (direct) access to threading apis.
But how would one do so in such a case?

  I assume that internally synchronized(Thread.class) calls Object.wait(),
so is there a way to lock out wait() without AOP-style interception?

  Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/850819ce/attachment.html 

From dhanji at gmail.com  Tue Apr 24 00:10:18 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 24 Apr 2007 14:10:18 +1000
Subject: [concurrency-interest] synchronization edge case
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEHMHGAA.dcholmes@optusnet.com.au>
References: <aa067ea10704232027lcc3fe3ag8c932e3ee23de399@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEHMHGAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10704232110t223dc9dcud771340f5eb754fa@mail.gmail.com>

On 4/24/07, David Holmes <dcholmes at optusnet.com.au> wrote:

>
> I don't have puzzlers so don't know what the "trick" is with this one. I
> couldn't see any explicit acquisitions of this monitor in the JDK library
> code. That leaves the implicit ones - the only one of which I'm aware of is
> class loading of the Thread class. But as that is done early in the VM
> bootstrap it should not be an issue unless your are running newly loaded
> classes with unresolved references to the Thread class *and* the VM
> explicitly locks the Class object during resolution (which isn't actually
> necessary and the next edition of the JVMS will clarify this).
>

Here is my understanding:
During creation of new threads, the api synchronizes on
Thread.class--butsince it is already locked, they enter the queue
behind it (I assumed it was
Object.wait() style behavior). So no new threads can be created (existing
threads still run ok) and that renders the app server more or less
useless--depending on what stage this code is executed at.

But what you are basically asking is: is there a way to prevent a thread
> from acquiring the monitor of a "critical" object? And the answer is no -
> not within the language or core API's.
>

Ok this is good to know! Somewhat of a serious hole in appserver security,
though a bit of an edge-case. I wonder if this can be mitigated with the EE
app verifier or some such intermediary that ensures against access to
restricted apis?

Thanks David.


Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/3ad5bec1/attachment-0001.html 

From dcholmes at optusnet.com.au  Tue Apr 24 00:26:00 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 24 Apr 2007 14:26:00 +1000
Subject: [concurrency-interest] synchronization edge case
In-Reply-To: <aa067ea10704232110t223dc9dcud771340f5eb754fa@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEHNHGAA.dcholmes@optusnet.com.au>

Ah I see it. Yes Thread creation will be locked-out because it requires
getting the next thread-ID and/or thread-number which is obtained via a
static synchronized method and hence needs the monitor of the Class object.
We probably should have used an AtomicLong/AtomicInteger for those.

Really, as a matter of robustness, no library class should use a publicly
accessible object for its locking - except as part of an explicit protocol.

Cheers,
David Holmes
  -----Original Message-----
  From: Dhanji R. Prasanna [mailto:dhanji at gmail.com]
  Sent: Tuesday, 24 April 2007 2:10 PM
  To: dholmes at ieee.org
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] synchronization edge case





  On 4/24/07, David Holmes <dcholmes at optusnet.com.au> wrote:


    I don't have puzzlers so don't know what the "trick" is with this one. I
couldn't see any explicit acquisitions of this monitor in the JDK library
code. That leaves the implicit ones - the only one of which I'm aware of is
class loading of the Thread class. But as that is done early in the VM
bootstrap it should not be an issue unless your are running newly loaded
classes with unresolved references to the Thread class *and* the VM
explicitly locks the Class object during resolution (which isn't actually
necessary and the next edition of the JVMS will clarify this).

  Here is my understanding:
  During creation of new threads, the api synchronizes on Thread.class--but
since it is already locked, they enter the queue behind it (I assumed it was
Object.wait() style behavior). So no new threads can be created (existing
threads still run ok) and that renders the app server more or less
useless--depending on what stage this code is executed at.



    But what you are basically asking is: is there a way to prevent a thread
from acquiring the monitor of a "critical" object? And the answer is no -
not within the language or core API's.

  Ok this is good to know! Somewhat of a serious hole in appserver security,
though a bit of an edge-case. I wonder if this can be mitigated with the EE
app verifier or some such intermediary that ensures against access to
restricted apis?

  Thanks David.



  Dhanji.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/ec291f2a/attachment.html 

From dhanji at gmail.com  Tue Apr 24 00:43:12 2007
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 24 Apr 2007 14:43:12 +1000
Subject: [concurrency-interest] synchronization edge case
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEHNHGAA.dcholmes@optusnet.com.au>
References: <aa067ea10704232110t223dc9dcud771340f5eb754fa@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEHNHGAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10704232143n78a17659mf90b9e62fd263e40@mail.gmail.com>

On 4/24/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>
> Really, as a matter of robustness, no library class should use a publicly
> accessible object for its locking - except as part of an explicit protocol.
>

That sounds very sensible (and is the common wisdom Ive heard). It looks
like Classloader.loadClassInternal() also synchronizes on the current
classloader, so is it possible to lock out an app (even more severely) by
acquiring the monitor of the system classloader (and never letting go)?

Are these problems that have been discussed before--I am curious whether
this is just water under the bridge or something to be worried about =)

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/6c8f30e9/attachment.html 

From dcholmes at optusnet.com.au  Tue Apr 24 00:51:49 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 24 Apr 2007 14:51:49 +1000
Subject: [concurrency-interest] synchronization edge case
In-Reply-To: <aa067ea10704232143n78a17659mf90b9e62fd263e40@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEHOHGAA.dcholmes@optusnet.com.au>

Dhanji R. Prasanna writes:
> On 4/24/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> > Really, as a matter of robustness, no library class should use
> a publicly accessible
> > object for its locking - except as part of an explicit protocol.
>
> That sounds very sensible (and is the common wisdom Ive heard).
> It looks like Classloader.loadClassInternal() also synchronizes
> on the current classloader, so is it possible to lock out an app
> (even more severely) by acquiring the monitor of the system
> classloader (and never letting go)?

In ClassLoader's case that is an explicit protocol. But yes it does mean
that a thread can lock out further classloading.

> Are these problems that have been discussed before--I am curious
> whether this is just water under the bridge or something to be
> worried about =)

Well the ClassLoader problem is mitigated if the environment runs the
foreign code eg applets/servlets etc, in their own ClassLoader. If they lock
that and stop themselves from running then that's their own silly fault. As
Class.getClassLoader() does have security checks the environment can stop
anyone from getting access to any ClassLoader other than its own. The
bootstrap loader is accessible to any code, implicitly, but can't be locked.

Cheers,
David


From alarmnummer at gmail.com  Tue Apr 24 08:22:48 2007
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 24 Apr 2007 14:22:48 +0200
Subject: [concurrency-interest] Review/Input/Comments asked for threadpool
	structure
Message-ID: <1466c1d60704240522y31b45f5bjf176ce03e659c28b@mail.gmail.com>

I would like to have some comments on the following two structures:

This structure:
https://svn.codehaus.org/prometheus/src/main/org/codehaus/prometheus/blockingexecutor/ThreadPoolBlockingExecutor.java

A structure much like the Executor but with support for blocking
calls. A ThreadPoolBlockingExecutor makes use of a ThreadPool to deal
with the threads:

And this structure:
The standard implementation of the ThreadPool is the StandardThreadPool
https://svn.codehaus.org/prometheus/src/main/org/codehaus/prometheus/threadpool/StandardThreadPool.java

The main problem I see is shutting down: I'm afraid work remains in
the queue after shutdown. I'm afraid I'm missing a possible scenario.

I also use the ThreadPool in the
https://svn.codehaus.org/prometheus/src/main/org/codehaus/prometheus/repeater/ThreadPoolRepeater.java

Help is very much appreciated.

A problem I know about is:
calling shutdown on blockingexecutor with work in the workqueue but
with an empty threadpool. This will lead to unprocessed work. This
issuse is going to be fixed.

From aarong at cs.cmu.edu  Tue Apr 24 09:21:07 2007
From: aarong at cs.cmu.edu (Aaron Greenhouse)
Date: Tue, 24 Apr 2007 09:21:07 -0400
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
Message-ID: <462E0443.1040606@cs.cmu.edu>

The javadoc for the java.util.concurrent.locks package explicitly 
mentions that the locks can be used for hand-over-hand locking.  But it 
doesn't give an example.  How does this interact with the recommendation 
that unlocks occur in finally clauses so as to insure that all locks are 
always unlocked?

The only example I have been able to find (in my 10 minutes of 
searching) is this one that says it is from

   Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
   by Brett McLaughlin and David Flanagan.


I am not convinced, however, that it is correct (or at least it is 
potentially misleading).  Here is the example; the hand-over-hand 
locking is in the append() method:

/*
License for Java 1.5 'Tiger': A Developer's Notebook
      (O'Reilly) example package

Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
by Brett McLaughlin and David Flanagan.
ISBN: 0-596-00738-8

You can use the examples and the source code any way you want, but
please include a reference to where it comes from if you use it in
your own products or services. Also note that this software is
provided by the author "as is", with no expressed or implied warranties.
In no event shall the author be liable for any direct or indirect
damages arising in any way out of the use of this software.
*/
public class LinkList<E>

   // The value of this node
   E value;

   // The rest of the list
   LinkList<E> rest;

   // A lock for this node
   Lock lock;

   // ... methods elided ....

   public void append(E value) {
     // Start the pointer at this node
     LinkList<E> node = this;
     node.lock.lock();

     while (node.rest != null) {
       LinkList<E> next = node.rest;

       // Here's the hand-over-hand locking
       try {
         // Lock the next node
         next.lock.lock();
       } finally {
         // unlock the current node
         node.lock.unlock();
       }

       // Traverse
       node = next;
     }

     // We're at the final node, so append and then unlock
     try {
       node.rest = new LinkList<E>(value);

       // Let any waiting threads know that this node's link has changed
       node.linkChanged.signalAll();
     } finally {
       node.lock.unlock();
     }
   }
}

The book doesn't give a great deal of discussion to the example.  The 
problem I see is if code were inserted between the close of the 
while-loop and the start of the subsequent try-finally block.  In that 
case if there were an exception, the lock of the last node would not be 
released.  This potential future accident could be averted by moving the 
while-loop into the try-block.

But I was trying to figure out how, if at all, you would correctly write 
the following:

lock1.lock();
// If an exception occurs here, only release lock1
lock2.lock();
// If an exception occurs here, release lock2 and lock1
lock1.unlock();
// If an exception occurs here, release lock2
lock2.unlock();

I think it would have to something like this, where we need to use a flag:

boolean doUnlock1 = false;
lock1.lock();
try {
     // If an exception occurs after here, only release lock1
     doUnlock1 = true;

     // do stuff

     lock2.lock();
     try {
         // If an exception occurs after here, release lock2 and lock1

         // do stuff

         lock1.unlock();
         // If an exception occurs after here, release lock2
         doUnlock1 = false;

         // do stuff
     } finally {
         lock2.unlock();
     }
} finally {
     if (doUnlock1) lock1.unlock();
}

This suffers from the same problem as above, where the placement of the 
assignments to doUnlock1 are very important.


I don't have any example of what I am trying to, other than to figure 
out how to do it.  This is coming up in the context of writing test 
cases for an analysis.

--Aaron



From hanson.char at gmail.com  Tue Apr 24 13:08:01 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 24 Apr 2007 10:08:01 -0700
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
Message-ID: <ca53c8f80704241008k4c91a487p6f11eeaf7794b7a2@mail.gmail.com>

How about the use of ExecutorService.invokeAny with two Callables, each
trying to dequeue from a BlockingQueue (representing the mailboxes) ?

See DoubleQueueAccess.java below.  Note conceivably two new messages can
arrive at both queues/mailboxes simultaneously and both gets dequeued.  In
such case the result (in the form of AtomicReferenceArray) will contain both
messages.  Otherwise, only one of the two array elements contains a non-null
message.

Cheers,
Hanson Char

import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicReferenceArray;

public class DoubleQueueAccess<T>
{
    private final ExecutorService es = Executors.newCachedThreadPool();
    private final BlockingQueue<T> q1, q2;

    public DoubleQueueAccess(BlockingQueue<T> q1, BlockingQueue<T> q2) {
        this.q1 = q1;
        this.q2 = q2;
    }

    private static class Dequeue<T> implements Callable<T> {
        final BlockingQueue<T> q;
        final AtomicReferenceArray<T> result;
        final int pos;

        Dequeue(BlockingQueue<T> q, AtomicReferenceArray<T> result, int pos)
{
            this.q = q;
            this.result = result;
            this.pos = pos;
        }

        public T call() throws InterruptedException {
            T element = q.take();
            result.set(pos, element);
            return element;
        }
    }

    public AtomicReferenceArray<T> dequeue() throws InterruptedException,
ExecutionException {
        final Collection<Dequeue<T>> callables = new
ArrayList<Dequeue<T>>();
        final AtomicReferenceArray<T> result;
        callables.add(new Dequeue<T>(q1, result = new
AtomicReferenceArray<T>(2), 0));
        callables.add(new Dequeue<T>(q2, result, 1));
        es.invokeAny(callables);
        return result;
    }
}


On 4/23/07, Fred Janon <fjanon at gmail.com> wrote:
>
> Hi,
>
> I used to write real time apps using RSX11M+ (and VMS) that had mailboxes
> and events. There was a "wait for OR(events)". The task would wait for any
> event specified in the OR. Then I would associate an event with a mailbox,
> do that for another mailbox and when a message would arrive in one of the 2
> mailboxes, the task would awake. I am trying to do that in Java with
> threads.
>
> I have been reading "Java Threads",  "JCIP", "Java in a Nutshell" and I
> could think about a couple of classes I could use but I would appreciate
> some design advice... Or if there is an existing library that does that
> already does that, I would appreciate a reference, I did some research and
> did not find anything interesting.
>
> Basically I need 1 public mailbox and 1 private mailbox for a thread. The
> thread would be blocked until a message arrives in one of the mailboxes. The
> mailboxes must have multiple slots. I was thinking about using
> LinkedBlockingQueues as mailboxes since I don't want to block the sender (or
> avoid it) but I am a bit stuck on making the thread wait for a message in
> either queues.
>
> The next step would be to have a ThreadPool for the tasks, sharing a
> common public mailbox to process the messages and each have a private
> mailbox for system management messages. I guess switching to a single thread
> to a ThreadPool would be relatively easy?
>
> Thanks in advance.
>
> Fred
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/dc66e2c0/attachment.html 

From joe.bowbeer at gmail.com  Tue Apr 24 13:41:06 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 24 Apr 2007 10:41:06 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <462E0443.1040606@cs.cmu.edu>
References: <462E0443.1040606@cs.cmu.edu>
Message-ID: <31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>

I can't locate a good current example either.

There is sample code in the Mutex class of Doug Lea's original
concurrent package:

http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Mutex.java

To migrate this to java.util.concurrent, translate:

class:
  Mutex => Lock

constructor:
  new Mutex() => new ReentrantLock()

methods:
  lock.acquire => lock.lockInterruptibly
  lock.release => lock.unlock

Note: I recommend using interruptible locks whenever possible, and
especially for operations that might take awhile, such as traversing a
long list.

--Joe

On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> The javadoc for the java.util.concurrent.locks package explicitly
> mentions that the locks can be used for hand-over-hand locking.  But it
> doesn't give an example.  How does this interact with the recommendation
> that unlocks occur in finally clauses so as to insure that all locks are
> always unlocked?
>
> The only example I have been able to find (in my 10 minutes of
> searching) is this one that says it is from
>
>    Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
>    by Brett McLaughlin and David Flanagan.
>
>
> I am not convinced, however, that it is correct (or at least it is
> potentially misleading).  Here is the example; the hand-over-hand
> locking is in the append() method:
>
> /*
> License for Java 1.5 'Tiger': A Developer's Notebook
>       (O'Reilly) example package
>
> Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> by Brett McLaughlin and David Flanagan.
> ISBN: 0-596-00738-8
>
> You can use the examples and the source code any way you want, but
> please include a reference to where it comes from if you use it in
> your own products or services. Also note that this software is
> provided by the author "as is", with no expressed or implied warranties.
> In no event shall the author be liable for any direct or indirect
> damages arising in any way out of the use of this software.
> */
> public class LinkList<E>
>
>    // The value of this node
>    E value;
>
>    // The rest of the list
>    LinkList<E> rest;
>
>    // A lock for this node
>    Lock lock;
>
>    // ... methods elided ....
>
>    public void append(E value) {
>      // Start the pointer at this node
>      LinkList<E> node = this;
>      node.lock.lock();
>
>      while (node.rest != null) {
>        LinkList<E> next = node.rest;
>
>        // Here's the hand-over-hand locking
>        try {
>          // Lock the next node
>          next.lock.lock();
>        } finally {
>          // unlock the current node
>          node.lock.unlock();
>        }
>
>        // Traverse
>        node = next;
>      }
>
>      // We're at the final node, so append and then unlock
>      try {
>        node.rest = new LinkList<E>(value);
>
>        // Let any waiting threads know that this node's link has changed
>        node.linkChanged.signalAll();
>      } finally {
>        node.lock.unlock();
>      }
>    }
> }
>
> The book doesn't give a great deal of discussion to the example.  The
> problem I see is if code were inserted between the close of the
> while-loop and the start of the subsequent try-finally block.  In that
> case if there were an exception, the lock of the last node would not be
> released.  This potential future accident could be averted by moving the
> while-loop into the try-block.
>
> But I was trying to figure out how, if at all, you would correctly write
> the following:
>
> lock1.lock();
> // If an exception occurs here, only release lock1
> lock2.lock();
> // If an exception occurs here, release lock2 and lock1
> lock1.unlock();
> // If an exception occurs here, release lock2
> lock2.unlock();
>
> I think it would have to something like this, where we need to use a flag:
>
> boolean doUnlock1 = false;
> lock1.lock();
> try {
>      // If an exception occurs after here, only release lock1
>      doUnlock1 = true;
>
>      // do stuff
>
>      lock2.lock();
>      try {
>          // If an exception occurs after here, release lock2 and lock1
>
>          // do stuff
>
>          lock1.unlock();
>          // If an exception occurs after here, release lock2
>          doUnlock1 = false;
>
>          // do stuff
>      } finally {
>          lock2.unlock();
>      }
> } finally {
>      if (doUnlock1) lock1.unlock();
> }
>
> This suffers from the same problem as above, where the placement of the
> assignments to doUnlock1 are very important.
>
>
> I don't have any example of what I am trying to, other than to figure
> out how to do it.  This is coming up in the context of writing test
> cases for an analysis.
>
> --Aaron
>

From joe.bowbeer at gmail.com  Tue Apr 24 14:18:09 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 24 Apr 2007 11:18:09 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>
References: <462E0443.1040606@cs.cmu.edu>
	<31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>
Message-ID: <31f2a7bd0704241118m42b2abb5gaafb7866c0219b6e@mail.gmail.com>

Btw, the problem with unchecked exceptions that you point out is real,
and also exists in the Mutex sample.  You don't need to use a flag in
this case, though.  I'll post a robust sample soon.

On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> I can't locate a good current example either.
>
> There is sample code in the Mutex class of Doug Lea's original
> concurrent package:
>
> http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Mutex.java
>
> To migrate this to java.util.concurrent, translate:
>
> class:
>   Mutex => Lock
>
> constructor:
>   new Mutex() => new ReentrantLock()
>
> methods:
>   lock.acquire => lock.lockInterruptibly
>   lock.release => lock.unlock
>
> Note: I recommend using interruptible locks whenever possible, and
> especially for operations that might take awhile, such as traversing a
> long list.
>
> --Joe
>
> On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> > The javadoc for the java.util.concurrent.locks package explicitly
> > mentions that the locks can be used for hand-over-hand locking.  But it
> > doesn't give an example.  How does this interact with the recommendation
> > that unlocks occur in finally clauses so as to insure that all locks are
> > always unlocked?
> >
> > The only example I have been able to find (in my 10 minutes of
> > searching) is this one that says it is from
> >
> >    Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> >    by Brett McLaughlin and David Flanagan.
> >
> >
> > I am not convinced, however, that it is correct (or at least it is
> > potentially misleading).  Here is the example; the hand-over-hand
> > locking is in the append() method:
> >
> > /*
> > License for Java 1.5 'Tiger': A Developer's Notebook
> >       (O'Reilly) example package
> >
> > Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > by Brett McLaughlin and David Flanagan.
> > ISBN: 0-596-00738-8
> >
> > You can use the examples and the source code any way you want, but
> > please include a reference to where it comes from if you use it in
> > your own products or services. Also note that this software is
> > provided by the author "as is", with no expressed or implied warranties.
> > In no event shall the author be liable for any direct or indirect
> > damages arising in any way out of the use of this software.
> > */
> > public class LinkList<E>
> >
> >    // The value of this node
> >    E value;
> >
> >    // The rest of the list
> >    LinkList<E> rest;
> >
> >    // A lock for this node
> >    Lock lock;
> >
> >    // ... methods elided ....
> >
> >    public void append(E value) {
> >      // Start the pointer at this node
> >      LinkList<E> node = this;
> >      node.lock.lock();
> >
> >      while (node.rest != null) {
> >        LinkList<E> next = node.rest;
> >
> >        // Here's the hand-over-hand locking
> >        try {
> >          // Lock the next node
> >          next.lock.lock();
> >        } finally {
> >          // unlock the current node
> >          node.lock.unlock();
> >        }
> >
> >        // Traverse
> >        node = next;
> >      }
> >
> >      // We're at the final node, so append and then unlock
> >      try {
> >        node.rest = new LinkList<E>(value);
> >
> >        // Let any waiting threads know that this node's link has changed
> >        node.linkChanged.signalAll();
> >      } finally {
> >        node.lock.unlock();
> >      }
> >    }
> > }
> >
> > The book doesn't give a great deal of discussion to the example.  The
> > problem I see is if code were inserted between the close of the
> > while-loop and the start of the subsequent try-finally block.  In that
> > case if there were an exception, the lock of the last node would not be
> > released.  This potential future accident could be averted by moving the
> > while-loop into the try-block.
> >
> > But I was trying to figure out how, if at all, you would correctly write
> > the following:
> >
> > lock1.lock();
> > // If an exception occurs here, only release lock1
> > lock2.lock();
> > // If an exception occurs here, release lock2 and lock1
> > lock1.unlock();
> > // If an exception occurs here, release lock2
> > lock2.unlock();
> >
> > I think it would have to something like this, where we need to use a flag:
> >
> > boolean doUnlock1 = false;
> > lock1.lock();
> > try {
> >      // If an exception occurs after here, only release lock1
> >      doUnlock1 = true;
> >
> >      // do stuff
> >
> >      lock2.lock();
> >      try {
> >          // If an exception occurs after here, release lock2 and lock1
> >
> >          // do stuff
> >
> >          lock1.unlock();
> >          // If an exception occurs after here, release lock2
> >          doUnlock1 = false;
> >
> >          // do stuff
> >      } finally {
> >          lock2.unlock();
> >      }
> > } finally {
> >      if (doUnlock1) lock1.unlock();
> > }
> >
> > This suffers from the same problem as above, where the placement of the
> > assignments to doUnlock1 are very important.
> >
> >
> > I don't have any example of what I am trying to, other than to figure
> > out how to do it.  This is coming up in the context of writing test
> > cases for an analysis.
> >
> > --Aaron
> >
>

From hanson.char at gmail.com  Tue Apr 24 15:01:32 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 24 Apr 2007 12:01:32 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <462E0443.1040606@cs.cmu.edu>
References: <462E0443.1040606@cs.cmu.edu>
Message-ID: <ca53c8f80704241201g54861dc6h7a10e7250578f05b@mail.gmail.com>

Can the more specific type ReentrantLock be used instead of Lock ?  One can
then query if the lock is held via isLocked() and unlock it in the finally
clause, instead of using the boolean flag and risking the mis-placement.

Hanson Char

On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
>
> The javadoc for the java.util.concurrent.locks package explicitly
> mentions that the locks can be used for hand-over-hand locking.  But it
> doesn't give an example.  How does this interact with the recommendation
> that unlocks occur in finally clauses so as to insure that all locks are
> always unlocked?
>
> The only example I have been able to find (in my 10 minutes of
> searching) is this one that says it is from
>
>    Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
>    by Brett McLaughlin and David Flanagan.
>
>
> I am not convinced, however, that it is correct (or at least it is
> potentially misleading).  Here is the example; the hand-over-hand
> locking is in the append() method:
>
> /*
> License for Java 1.5 'Tiger': A Developer's Notebook
>       (O'Reilly) example package
>
> Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> by Brett McLaughlin and David Flanagan.
> ISBN: 0-596-00738-8
>
> You can use the examples and the source code any way you want, but
> please include a reference to where it comes from if you use it in
> your own products or services. Also note that this software is
> provided by the author "as is", with no expressed or implied warranties.
> In no event shall the author be liable for any direct or indirect
> damages arising in any way out of the use of this software.
> */
> public class LinkList<E>
>
>    // The value of this node
>    E value;
>
>    // The rest of the list
>    LinkList<E> rest;
>
>    // A lock for this node
>    Lock lock;
>
>    // ... methods elided ....
>
>    public void append(E value) {
>      // Start the pointer at this node
>      LinkList<E> node = this;
>      node.lock.lock();
>
>      while (node.rest != null) {
>        LinkList<E> next = node.rest;
>
>        // Here's the hand-over-hand locking
>        try {
>          // Lock the next node
>          next.lock.lock();
>        } finally {
>          // unlock the current node
>          node.lock.unlock();
>        }
>
>        // Traverse
>        node = next;
>      }
>
>      // We're at the final node, so append and then unlock
>      try {
>        node.rest = new LinkList<E>(value);
>
>        // Let any waiting threads know that this node's link has changed
>        node.linkChanged.signalAll();
>      } finally {
>        node.lock.unlock();
>      }
>    }
> }
>
> The book doesn't give a great deal of discussion to the example.  The
> problem I see is if code were inserted between the close of the
> while-loop and the start of the subsequent try-finally block.  In that
> case if there were an exception, the lock of the last node would not be
> released.  This potential future accident could be averted by moving the
> while-loop into the try-block.
>
> But I was trying to figure out how, if at all, you would correctly write
> the following:
>
> lock1.lock();
> // If an exception occurs here, only release lock1
> lock2.lock();
> // If an exception occurs here, release lock2 and lock1
> lock1.unlock();
> // If an exception occurs here, release lock2
> lock2.unlock();
>
> I think it would have to something like this, where we need to use a flag:
>
> boolean doUnlock1 = false;
> lock1.lock();
> try {
>      // If an exception occurs after here, only release lock1
>      doUnlock1 = true;
>
>      // do stuff
>
>      lock2.lock();
>      try {
>          // If an exception occurs after here, release lock2 and lock1
>
>          // do stuff
>
>          lock1.unlock();
>          // If an exception occurs after here, release lock2
>          doUnlock1 = false;
>
>          // do stuff
>      } finally {
>          lock2.unlock();
>      }
> } finally {
>      if (doUnlock1) lock1.unlock();
> }
>
> This suffers from the same problem as above, where the placement of the
> assignments to doUnlock1 are very important.
>
>
> I don't have any example of what I am trying to, other than to figure
> out how to do it.  This is coming up in the context of writing test
> cases for an analysis.
>
> --Aaron
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/7d48d410/attachment-0001.html 

From szabolcs.ferenczi at gmail.com  Tue Apr 24 15:26:31 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 24 Apr 2007 21:26:31 +0200
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <ca53c8f80704241008k4c91a487p6f11eeaf7794b7a2@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<ca53c8f80704241008k4c91a487p6f11eeaf7794b7a2@mail.gmail.com>
Message-ID: <c8955b000704241226t45a725bej1a75e37fdd8fbd1@mail.gmail.com>

On 24/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> See DoubleQueueAccess.java below.  Note conceivably two new messages can
> arrive at both queues/mailboxes simultaneously and both gets dequeued.  In
> such case the result (in the form of AtomicReferenceArray) will contain both
> messages.  Otherwise, only one of the two array elements contains a non-null
> message.

Hi Hanson,
    it is an interesting construction. However, it behaves a bit
different to what you claim. If I prepare a message in both queues and
call dequeue() on DoubleQueueAccess instance, it seems it is quite non
deterministically returns one, the other or both. So the test below
sometimes pass, sometimes fail.

Best Regards,
Szabolcs

public class DoubleQueueAccessTest {

    DoubleQueueAccess<Integer> dq;
    BlockingQueue<Integer> q1;
    BlockingQueue<Integer> q2;
    final Integer token = new Integer(7);
    final Integer token1 = new Integer(8);

    @Before
    public void setUp() {
	q1 = new LinkedBlockingQueue<Integer>();
	q2 = new LinkedBlockingQueue<Integer>();
	dq = new DoubleQueueAccess<Integer>(q1, q2);
    }

    @Test
    public void seqAddQ1Q2() throws Throwable {
	q1.add(token);
	q2.add(token1);
	AtomicReferenceArray<Integer> ret = dq.dequeue();
	assertEquals(token, ret.get(0));
	assertEquals(token1, ret.get(1));
    }
}

From joe.bowbeer at gmail.com  Tue Apr 24 17:21:09 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 24 Apr 2007 14:21:09 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <31f2a7bd0704241118m42b2abb5gaafb7866c0219b6e@mail.gmail.com>
References: <462E0443.1040606@cs.cmu.edu>
	<31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>
	<31f2a7bd0704241118m42b2abb5gaafb7866c0219b6e@mail.gmail.com>
Message-ID: <31f2a7bd0704241421l7c639951l4afceda9f30f85dd@mail.gmail.com>

The Mutex example converted to java.util.concurrent follows.

import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class List {

    /** Holds one item in singly-linked list. */
    private static class Node {
        /* Each node maintains its own lock. */
        final Lock lock = new ReentrantLock();
        Object item;
        Node next;
        Node(Object item, Node next) {
            this.item = item;
            this.next = next;
        }
    }

    /**
     * Points to first node of list.
     * We use synchronized(this) to protect head field.
     */
    private Node head;

    private synchronized Node getHead() {
        return head;
    }

    public synchronized void addFirst(Object x) {
        head = new Node(x, head);
     }

    public boolean contains(Object x) {
        Node p = getHead();
        if (p == null) // empty?
            return false;
        /* Acquire first lock. */
        p.lock.lock();
        try {
            while (true) {
                if (x == p.item || x != null && x.equals(p.item))
                    return true;
                if (p.next == null)
                    return false;
                /* Get next lock before releasing current. */
                p.next.lock.lock();
                /* Advance pointer and release lock on previous node. */
                Node prevp = p;
                p = p.next;
                prevp.lock.unlock();
            }
        } finally {
            /* Release final lock that was held. */
            p.lock.unlock();
        }
    }
}


On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Btw, the problem with unchecked exceptions that you point out is real,
> and also exists in the Mutex sample.  You don't need to use a flag in
> this case, though.  I'll post a robust sample soon.
>
> On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > I can't locate a good current example either.
> >
> > There is sample code in the Mutex class of Doug Lea's original
> > concurrent package:
> >
> > http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Mutex.java
> >
> > To migrate this to java.util.concurrent, translate:
> >
> > class:
> >   Mutex => Lock
> >
> > constructor:
> >   new Mutex() => new ReentrantLock()
> >
> > methods:
> >   lock.acquire => lock.lockInterruptibly
> >   lock.release => lock.unlock
> >
> > Note: I recommend using interruptible locks whenever possible, and
> > especially for operations that might take awhile, such as traversing a
> > long list.
> >
> > --Joe
> >
> > On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> > > The javadoc for the java.util.concurrent.locks package explicitly
> > > mentions that the locks can be used for hand-over-hand locking.  But it
> > > doesn't give an example.  How does this interact with the recommendation
> > > that unlocks occur in finally clauses so as to insure that all locks are
> > > always unlocked?
> > >
> > > The only example I have been able to find (in my 10 minutes of
> > > searching) is this one that says it is from
> > >
> > >    Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > >    by Brett McLaughlin and David Flanagan.
> > >
> > >
> > > I am not convinced, however, that it is correct (or at least it is
> > > potentially misleading).  Here is the example; the hand-over-hand
> > > locking is in the append() method:
> > >
> > > /*
> > > License for Java 1.5 'Tiger': A Developer's Notebook
> > >       (O'Reilly) example package
> > >
> > > Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > > by Brett McLaughlin and David Flanagan.
> > > ISBN: 0-596-00738-8
> > >
> > > You can use the examples and the source code any way you want, but
> > > please include a reference to where it comes from if you use it in
> > > your own products or services. Also note that this software is
> > > provided by the author "as is", with no expressed or implied warranties.
> > > In no event shall the author be liable for any direct or indirect
> > > damages arising in any way out of the use of this software.
> > > */
> > > public class LinkList<E>
> > >
> > >    // The value of this node
> > >    E value;
> > >
> > >    // The rest of the list
> > >    LinkList<E> rest;
> > >
> > >    // A lock for this node
> > >    Lock lock;
> > >
> > >    // ... methods elided ....
> > >
> > >    public void append(E value) {
> > >      // Start the pointer at this node
> > >      LinkList<E> node = this;
> > >      node.lock.lock();
> > >
> > >      while (node.rest != null) {
> > >        LinkList<E> next = node.rest;
> > >
> > >        // Here's the hand-over-hand locking
> > >        try {
> > >          // Lock the next node
> > >          next.lock.lock();
> > >        } finally {
> > >          // unlock the current node
> > >          node.lock.unlock();
> > >        }
> > >
> > >        // Traverse
> > >        node = next;
> > >      }
> > >
> > >      // We're at the final node, so append and then unlock
> > >      try {
> > >        node.rest = new LinkList<E>(value);
> > >
> > >        // Let any waiting threads know that this node's link has changed
> > >        node.linkChanged.signalAll();
> > >      } finally {
> > >        node.lock.unlock();
> > >      }
> > >    }
> > > }
> > >
> > > The book doesn't give a great deal of discussion to the example.  The
> > > problem I see is if code were inserted between the close of the
> > > while-loop and the start of the subsequent try-finally block.  In that
> > > case if there were an exception, the lock of the last node would not be
> > > released.  This potential future accident could be averted by moving the
> > > while-loop into the try-block.
> > >
> > > But I was trying to figure out how, if at all, you would correctly write
> > > the following:
> > >
> > > lock1.lock();
> > > // If an exception occurs here, only release lock1
> > > lock2.lock();
> > > // If an exception occurs here, release lock2 and lock1
> > > lock1.unlock();
> > > // If an exception occurs here, release lock2
> > > lock2.unlock();
> > >
> > > I think it would have to something like this, where we need to use a flag:
> > >
> > > boolean doUnlock1 = false;
> > > lock1.lock();
> > > try {
> > >      // If an exception occurs after here, only release lock1
> > >      doUnlock1 = true;
> > >
> > >      // do stuff
> > >
> > >      lock2.lock();
> > >      try {
> > >          // If an exception occurs after here, release lock2 and lock1
> > >
> > >          // do stuff
> > >
> > >          lock1.unlock();
> > >          // If an exception occurs after here, release lock2
> > >          doUnlock1 = false;
> > >
> > >          // do stuff
> > >      } finally {
> > >          lock2.unlock();
> > >      }
> > > } finally {
> > >      if (doUnlock1) lock1.unlock();
> > > }
> > >
> > > This suffers from the same problem as above, where the placement of the
> > > assignments to doUnlock1 are very important.
> > >
> > >
> > > I don't have any example of what I am trying to, other than to figure
> > > out how to do it.  This is coming up in the context of writing test
> > > cases for an analysis.
> > >
> > > --Aaron
> > >
> >
>

From joe.bowbeer at gmail.com  Tue Apr 24 17:46:29 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 24 Apr 2007 14:46:29 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <31f2a7bd0704241421l7c639951l4afceda9f30f85dd@mail.gmail.com>
References: <462E0443.1040606@cs.cmu.edu>
	<31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>
	<31f2a7bd0704241118m42b2abb5gaafb7866c0219b6e@mail.gmail.com>
	<31f2a7bd0704241421l7c639951l4afceda9f30f85dd@mail.gmail.com>
Message-ID: <31f2a7bd0704241446p16cf1ad2x8db0c6f343cf93c2@mail.gmail.com>

I just noticed that you were asking about an "addLast" implementation,
so here you go:

    public void addLast(Object x) {
        Node p;
        synchronized(this) {
            if ((p = head) == null) {
                head = new Node(x, null);
                return;
            }
        }
        /* Acquire first lock. */
        p.lock.lock();
        try {
            /* Find tail. */
            while (p.next != null) {
                /* Get next lock before releasing current. */
                p.next.lock.lock();
                /* Advance pointer and release lock on previous node. */
                Node prevp = p;
                p = p.next;
                prevp.lock.unlock();
            }
            /* Attach new node. */
            p.next = new Node(x, null);
        } finally {
            /* Release final lock that was held. */
            p.lock.unlock();
        }
     }

--Joe

On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> The Mutex example converted to java.util.concurrent follows.
>
> import java.util.concurrent.locks.Lock;
> import java.util.concurrent.locks.ReentrantLock;
>
> public class List {
>
>     /** Holds one item in singly-linked list. */
>     private static class Node {
>         /* Each node maintains its own lock. */
>         final Lock lock = new ReentrantLock();
>         Object item;
>         Node next;
>         Node(Object item, Node next) {
>             this.item = item;
>             this.next = next;
>         }
>     }
>
>     /**
>      * Points to first node of list.
>      * We use synchronized(this) to protect head field.
>      */
>     private Node head;
>
>     private synchronized Node getHead() {
>         return head;
>     }
>
>     public synchronized void addFirst(Object x) {
>         head = new Node(x, head);
>      }
>
>     public boolean contains(Object x) {
>         Node p = getHead();
>         if (p == null) // empty?
>             return false;
>         /* Acquire first lock. */
>         p.lock.lock();
>         try {
>             while (true) {
>                 if (x == p.item || x != null && x.equals(p.item))
>                     return true;
>                 if (p.next == null)
>                     return false;
>                 /* Get next lock before releasing current. */
>                 p.next.lock.lock();
>                 /* Advance pointer and release lock on previous node. */
>                 Node prevp = p;
>                 p = p.next;
>                 prevp.lock.unlock();
>             }
>         } finally {
>             /* Release final lock that was held. */
>             p.lock.unlock();
>         }
>     }
> }
>
>
> On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > Btw, the problem with unchecked exceptions that you point out is real,
> > and also exists in the Mutex sample.  You don't need to use a flag in
> > this case, though.  I'll post a robust sample soon.
> >
> > On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > > I can't locate a good current example either.
> > >
> > > There is sample code in the Mutex class of Doug Lea's original
> > > concurrent package:
> > >
> > > http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Mutex.java
> > >
> > > To migrate this to java.util.concurrent, translate:
> > >
> > > class:
> > >   Mutex => Lock
> > >
> > > constructor:
> > >   new Mutex() => new ReentrantLock()
> > >
> > > methods:
> > >   lock.acquire => lock.lockInterruptibly
> > >   lock.release => lock.unlock
> > >
> > > Note: I recommend using interruptible locks whenever possible, and
> > > especially for operations that might take awhile, such as traversing a
> > > long list.
> > >
> > > --Joe
> > >
> > > On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> > > > The javadoc for the java.util.concurrent.locks package explicitly
> > > > mentions that the locks can be used for hand-over-hand locking.  But it
> > > > doesn't give an example.  How does this interact with the recommendation
> > > > that unlocks occur in finally clauses so as to insure that all locks are
> > > > always unlocked?
> > > >
> > > > The only example I have been able to find (in my 10 minutes of
> > > > searching) is this one that says it is from
> > > >
> > > >    Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > > >    by Brett McLaughlin and David Flanagan.
> > > >
> > > >
> > > > I am not convinced, however, that it is correct (or at least it is
> > > > potentially misleading).  Here is the example; the hand-over-hand
> > > > locking is in the append() method:
> > > >
> > > > /*
> > > > License for Java 1.5 'Tiger': A Developer's Notebook
> > > >       (O'Reilly) example package
> > > >
> > > > Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > > > by Brett McLaughlin and David Flanagan.
> > > > ISBN: 0-596-00738-8
> > > >
> > > > You can use the examples and the source code any way you want, but
> > > > please include a reference to where it comes from if you use it in
> > > > your own products or services. Also note that this software is
> > > > provided by the author "as is", with no expressed or implied warranties.
> > > > In no event shall the author be liable for any direct or indirect
> > > > damages arising in any way out of the use of this software.
> > > > */
> > > > public class LinkList<E>
> > > >
> > > >    // The value of this node
> > > >    E value;
> > > >
> > > >    // The rest of the list
> > > >    LinkList<E> rest;
> > > >
> > > >    // A lock for this node
> > > >    Lock lock;
> > > >
> > > >    // ... methods elided ....
> > > >
> > > >    public void append(E value) {
> > > >      // Start the pointer at this node
> > > >      LinkList<E> node = this;
> > > >      node.lock.lock();
> > > >
> > > >      while (node.rest != null) {
> > > >        LinkList<E> next = node.rest;
> > > >
> > > >        // Here's the hand-over-hand locking
> > > >        try {
> > > >          // Lock the next node
> > > >          next.lock.lock();
> > > >        } finally {
> > > >          // unlock the current node
> > > >          node.lock.unlock();
> > > >        }
> > > >
> > > >        // Traverse
> > > >        node = next;
> > > >      }
> > > >
> > > >      // We're at the final node, so append and then unlock
> > > >      try {
> > > >        node.rest = new LinkList<E>(value);
> > > >
> > > >        // Let any waiting threads know that this node's link has changed
> > > >        node.linkChanged.signalAll();
> > > >      } finally {
> > > >        node.lock.unlock();
> > > >      }
> > > >    }
> > > > }
> > > >
> > > > The book doesn't give a great deal of discussion to the example.  The
> > > > problem I see is if code were inserted between the close of the
> > > > while-loop and the start of the subsequent try-finally block.  In that
> > > > case if there were an exception, the lock of the last node would not be
> > > > released.  This potential future accident could be averted by moving the
> > > > while-loop into the try-block.
> > > >
> > > > But I was trying to figure out how, if at all, you would correctly write
> > > > the following:
> > > >
> > > > lock1.lock();
> > > > // If an exception occurs here, only release lock1
> > > > lock2.lock();
> > > > // If an exception occurs here, release lock2 and lock1
> > > > lock1.unlock();
> > > > // If an exception occurs here, release lock2
> > > > lock2.unlock();
> > > >
> > > > I think it would have to something like this, where we need to use a flag:
> > > >
> > > > boolean doUnlock1 = false;
> > > > lock1.lock();
> > > > try {
> > > >      // If an exception occurs after here, only release lock1
> > > >      doUnlock1 = true;
> > > >
> > > >      // do stuff
> > > >
> > > >      lock2.lock();
> > > >      try {
> > > >          // If an exception occurs after here, release lock2 and lock1
> > > >
> > > >          // do stuff
> > > >
> > > >          lock1.unlock();
> > > >          // If an exception occurs after here, release lock2
> > > >          doUnlock1 = false;
> > > >
> > > >          // do stuff
> > > >      } finally {
> > > >          lock2.unlock();
> > > >      }
> > > > } finally {
> > > >      if (doUnlock1) lock1.unlock();
> > > > }
> > > >
> > > > This suffers from the same problem as above, where the placement of the
> > > > assignments to doUnlock1 are very important.
> > > >
> > > >
> > > > I don't have any example of what I am trying to, other than to figure
> > > > out how to do it.  This is coming up in the context of writing test
> > > > cases for an analysis.
> > > >
> > > > --Aaron
> > > >
> > >
> >
>

From joe.bowbeer at gmail.com  Tue Apr 24 19:28:36 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 24 Apr 2007 16:28:36 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <31f2a7bd0704241446p16cf1ad2x8db0c6f343cf93c2@mail.gmail.com>
References: <462E0443.1040606@cs.cmu.edu>
	<31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>
	<31f2a7bd0704241118m42b2abb5gaafb7866c0219b6e@mail.gmail.com>
	<31f2a7bd0704241421l7c639951l4afceda9f30f85dd@mail.gmail.com>
	<31f2a7bd0704241446p16cf1ad2x8db0c6f343cf93c2@mail.gmail.com>
Message-ID: <31f2a7bd0704241628k3f48abdaoa427ad32bbadd819@mail.gmail.com>

For completeness, here's the original example with the improved
try-finally nesting:

/*
 * Adapted from com.oreilly.tiger.ch10.LinkedList
 * http://examples.oreilly.com/javaadn/
 */

import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class LinkedList<E> {

    /** The value of this node. */
    private E value;

    /** The rest of the list. */
    private LinkedList<E> rest;

    /** A lock for this node. */
    private final Lock lock = new ReentrantLock();

    public LinkedList(E value) {
        this.value = value;
    }

    public void append(E value) {
        // Start the pointer at this node
        LinkedList<E> node = this;
        // Lock this node
        node.lock.lock();
        try {
            // Traverse the links, using hand-over-hand locking
            while (node.rest != null) {
                // Lock the next node
                node.rest.lock.lock();
                // Advance our pointer
                LinkedList<E> prev = node;
                node = node.rest;
                // Unlock the previous node
                prev.lock.unlock();
            }
            // We're at the final node, so append
            node.rest = new LinkedList<E>(value);
            // node.linkChanged.signalAll();
        } finally {
            // Release final lock
            node.lock.unlock();
        }
    }

    // ...


On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> I just noticed that you were asking about an "addLast" implementation,
> so here you go:
>
>     public void addLast(Object x) {
>         Node p;
>         synchronized(this) {
>             if ((p = head) == null) {
>                 head = new Node(x, null);
>                 return;
>             }
>         }
>         /* Acquire first lock. */
>         p.lock.lock();
>         try {
>             /* Find tail. */
>             while (p.next != null) {
>                 /* Get next lock before releasing current. */
>                 p.next.lock.lock();
>                 /* Advance pointer and release lock on previous node. */
>                 Node prevp = p;
>                 p = p.next;
>                 prevp.lock.unlock();
>             }
>             /* Attach new node. */
>             p.next = new Node(x, null);
>         } finally {
>             /* Release final lock that was held. */
>             p.lock.unlock();
>         }
>      }
>
> --Joe
>
> On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > The Mutex example converted to java.util.concurrent follows.
> >
> > import java.util.concurrent.locks.Lock;
> > import java.util.concurrent.locks.ReentrantLock;
> >
> > public class List {
> >
> >     /** Holds one item in singly-linked list. */
> >     private static class Node {
> >         /* Each node maintains its own lock. */
> >         final Lock lock = new ReentrantLock();
> >         Object item;
> >         Node next;
> >         Node(Object item, Node next) {
> >             this.item = item;
> >             this.next = next;
> >         }
> >     }
> >
> >     /**
> >      * Points to first node of list.
> >      * We use synchronized(this) to protect head field.
> >      */
> >     private Node head;
> >
> >     private synchronized Node getHead() {
> >         return head;
> >     }
> >
> >     public synchronized void addFirst(Object x) {
> >         head = new Node(x, head);
> >      }
> >
> >     public boolean contains(Object x) {
> >         Node p = getHead();
> >         if (p == null) // empty?
> >             return false;
> >         /* Acquire first lock. */
> >         p.lock.lock();
> >         try {
> >             while (true) {
> >                 if (x == p.item || x != null && x.equals(p.item))
> >                     return true;
> >                 if (p.next == null)
> >                     return false;
> >                 /* Get next lock before releasing current. */
> >                 p.next.lock.lock();
> >                 /* Advance pointer and release lock on previous node. */
> >                 Node prevp = p;
> >                 p = p.next;
> >                 prevp.lock.unlock();
> >             }
> >         } finally {
> >             /* Release final lock that was held. */
> >             p.lock.unlock();
> >         }
> >     }
> > }
> >
> >
> > On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > > Btw, the problem with unchecked exceptions that you point out is real,
> > > and also exists in the Mutex sample.  You don't need to use a flag in
> > > this case, though.  I'll post a robust sample soon.
> > >
> > > On 4/24/07, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > > > I can't locate a good current example either.
> > > >
> > > > There is sample code in the Mutex class of Doug Lea's original
> > > > concurrent package:
> > > >
> > > > http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/Mutex.java
> > > >
> > > > To migrate this to java.util.concurrent, translate:
> > > >
> > > > class:
> > > >   Mutex => Lock
> > > >
> > > > constructor:
> > > >   new Mutex() => new ReentrantLock()
> > > >
> > > > methods:
> > > >   lock.acquire => lock.lockInterruptibly
> > > >   lock.release => lock.unlock
> > > >
> > > > Note: I recommend using interruptible locks whenever possible, and
> > > > especially for operations that might take awhile, such as traversing a
> > > > long list.
> > > >
> > > > --Joe
> > > >
> > > > On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> > > > > The javadoc for the java.util.concurrent.locks package explicitly
> > > > > mentions that the locks can be used for hand-over-hand locking.  But it
> > > > > doesn't give an example.  How does this interact with the recommendation
> > > > > that unlocks occur in finally clauses so as to insure that all locks are
> > > > > always unlocked?
> > > > >
> > > > > The only example I have been able to find (in my 10 minutes of
> > > > > searching) is this one that says it is from
> > > > >
> > > > >    Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > > > >    by Brett McLaughlin and David Flanagan.
> > > > >
> > > > >
> > > > > I am not convinced, however, that it is correct (or at least it is
> > > > > potentially misleading).  Here is the example; the hand-over-hand
> > > > > locking is in the append() method:
> > > > >
> > > > > /*
> > > > > License for Java 1.5 'Tiger': A Developer's Notebook
> > > > >       (O'Reilly) example package
> > > > >
> > > > > Java 1.5 'Tiger': A Developer's Notebook (O'Reilly)
> > > > > by Brett McLaughlin and David Flanagan.
> > > > > ISBN: 0-596-00738-8
> > > > >
> > > > > You can use the examples and the source code any way you want, but
> > > > > please include a reference to where it comes from if you use it in
> > > > > your own products or services. Also note that this software is
> > > > > provided by the author "as is", with no expressed or implied warranties.
> > > > > In no event shall the author be liable for any direct or indirect
> > > > > damages arising in any way out of the use of this software.
> > > > > */
> > > > > public class LinkList<E>
> > > > >
> > > > >    // The value of this node
> > > > >    E value;
> > > > >
> > > > >    // The rest of the list
> > > > >    LinkList<E> rest;
> > > > >
> > > > >    // A lock for this node
> > > > >    Lock lock;
> > > > >
> > > > >    // ... methods elided ....
> > > > >
> > > > >    public void append(E value) {
> > > > >      // Start the pointer at this node
> > > > >      LinkList<E> node = this;
> > > > >      node.lock.lock();
> > > > >
> > > > >      while (node.rest != null) {
> > > > >        LinkList<E> next = node.rest;
> > > > >
> > > > >        // Here's the hand-over-hand locking
> > > > >        try {
> > > > >          // Lock the next node
> > > > >          next.lock.lock();
> > > > >        } finally {
> > > > >          // unlock the current node
> > > > >          node.lock.unlock();
> > > > >        }
> > > > >
> > > > >        // Traverse
> > > > >        node = next;
> > > > >      }
> > > > >
> > > > >      // We're at the final node, so append and then unlock
> > > > >      try {
> > > > >        node.rest = new LinkList<E>(value);
> > > > >
> > > > >        // Let any waiting threads know that this node's link has changed
> > > > >        node.linkChanged.signalAll();
> > > > >      } finally {
> > > > >        node.lock.unlock();
> > > > >      }
> > > > >    }
> > > > > }
> > > > >
> > > > > The book doesn't give a great deal of discussion to the example.  The
> > > > > problem I see is if code were inserted between the close of the
> > > > > while-loop and the start of the subsequent try-finally block.  In that
> > > > > case if there were an exception, the lock of the last node would not be
> > > > > released.  This potential future accident could be averted by moving the
> > > > > while-loop into the try-block.
> > > > >
> > > > > But I was trying to figure out how, if at all, you would correctly write
> > > > > the following:
> > > > >
> > > > > lock1.lock();
> > > > > // If an exception occurs here, only release lock1
> > > > > lock2.lock();
> > > > > // If an exception occurs here, release lock2 and lock1
> > > > > lock1.unlock();
> > > > > // If an exception occurs here, release lock2
> > > > > lock2.unlock();
> > > > >
> > > > > I think it would have to something like this, where we need to use a flag:
> > > > >
> > > > > boolean doUnlock1 = false;
> > > > > lock1.lock();
> > > > > try {
> > > > >      // If an exception occurs after here, only release lock1
> > > > >      doUnlock1 = true;
> > > > >
> > > > >      // do stuff
> > > > >
> > > > >      lock2.lock();
> > > > >      try {
> > > > >          // If an exception occurs after here, release lock2 and lock1
> > > > >
> > > > >          // do stuff
> > > > >
> > > > >          lock1.unlock();
> > > > >          // If an exception occurs after here, release lock2
> > > > >          doUnlock1 = false;
> > > > >
> > > > >          // do stuff
> > > > >      } finally {
> > > > >          lock2.unlock();
> > > > >      }
> > > > > } finally {
> > > > >      if (doUnlock1) lock1.unlock();
> > > > > }
> > > > >
> > > > > This suffers from the same problem as above, where the placement of the
> > > > > assignments to doUnlock1 are very important.
> > > > >
> > > > >
> > > > > I don't have any example of what I am trying to, other than to figure
> > > > > out how to do it.  This is coming up in the context of writing test
> > > > > cases for an analysis.
> > > > >
> > > > > --Aaron
> > > > >
> > > >
> > >
> >
>

From hanson.char at gmail.com  Tue Apr 24 23:38:38 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 24 Apr 2007 20:38:38 -0700
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <c8955b000704241226t45a725bej1a75e37fdd8fbd1@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<ca53c8f80704241008k4c91a487p6f11eeaf7794b7a2@mail.gmail.com>
	<c8955b000704241226t45a725bej1a75e37fdd8fbd1@mail.gmail.com>
Message-ID: <ca53c8f80704242038h64dee7ddgcb9421d1da51791c@mail.gmail.com>

In your test case, since both blocking queues are pre-inserted with items,
it is basically a simulation of the case when messages arrive simultaneously
to both queues.  The behavior of which got dequeued first and whether both
would got dequeued, if I understand it correctly, depends on the thread
scheduling policy of the thread pool executor, which in turns depend on the
things like the number of CPU's on which the JVM is run.  It is as
deterministic as how these things pan out.

The assert statements presume the dequeue must happen in a certain order,
which therefore would appear to fail sometimes.

Cheers,
Hanson Char

On 4/24/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> On 24/04/07, Hanson Char <hanson.char at gmail.com> wrote:
> > See DoubleQueueAccess.java below.  Note conceivably two new messages can
> > arrive at both queues/mailboxes simultaneously and both gets
> dequeued.  In
> > such case the result (in the form of AtomicReferenceArray) will contain
> both
> > messages.  Otherwise, only one of the two array elements contains a
> non-null
> > message.
>
> Hi Hanson,
>     it is an interesting construction. However, it behaves a bit
> different to what you claim. If I prepare a message in both queues and
> call dequeue() on DoubleQueueAccess instance, it seems it is quite non
> deterministically returns one, the other or both. So the test below
> sometimes pass, sometimes fail.
>
> Best Regards,
> Szabolcs
>
> public class DoubleQueueAccessTest {
>
>     DoubleQueueAccess<Integer> dq;
>     BlockingQueue<Integer> q1;
>     BlockingQueue<Integer> q2;
>     final Integer token = new Integer(7);
>     final Integer token1 = new Integer(8);
>
>     @Before
>     public void setUp() {
>         q1 = new LinkedBlockingQueue<Integer>();
>         q2 = new LinkedBlockingQueue<Integer>();
>         dq = new DoubleQueueAccess<Integer>(q1, q2);
>     }
>
>     @Test
>     public void seqAddQ1Q2() throws Throwable {
>         q1.add(token);
>         q2.add(token1);
>         AtomicReferenceArray<Integer> ret = dq.dequeue();
>         assertEquals(token, ret.get(0));
>         assertEquals(token1, ret.get(1));
>     }
> }
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070424/f2718c71/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Apr 25 02:44:40 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 25 Apr 2007 08:44:40 +0200
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <ca53c8f80704242038h64dee7ddgcb9421d1da51791c@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<ca53c8f80704241008k4c91a487p6f11eeaf7794b7a2@mail.gmail.com>
	<c8955b000704241226t45a725bej1a75e37fdd8fbd1@mail.gmail.com>
	<ca53c8f80704242038h64dee7ddgcb9421d1da51791c@mail.gmail.com>
Message-ID: <c8955b000704242344q53cfcc8aj86db5a4e70c5e37d@mail.gmail.com>

On 25/04/07, Hanson Char <hanson.char at gmail.com> wrote:

> The assert statements presume the dequeue must happen in a certain order,
> which therefore would appear to fail sometimes.

Hi Hanson,
   just have a look at your algorithm and you see that the certain
order is established by the algorithm so it is quite correct to
presume, isn't it?

        callables.add(new Dequeue<T>(q1, result = new
AtomicReferenceArray<T>(2), 0));
        callables.add(new Dequeue<T>(q2, result, 1));
        es.invokeAny(callables);

So, you assign the first position in the two element
AtomicReferenceArray to the first queue and the second position to the
second queue. That is what the assert statements in the test follow.
No problem with that. The asserts happen after the dequeue() is
returned, so the AtomicReferenceArray is stable. No race condition
applies at that point.

The test sometimes fails and sometimes passes, however, and it is non
deterministic whether one element is received or two. The test also
ensures that one element is there in each queue at the time the
dequeue() is called. The call, on the other hand, returns one or the
other or both. That is no problem if you are aware of it. So you
cannot rely on that if two messages arrive at the two queues
simultaneously, both are returned because it is not the case.

Best Regards,
Szabolcs

From hanson.char at gmail.com  Wed Apr 25 03:43:24 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 25 Apr 2007 00:43:24 -0700
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <c8955b000704242344q53cfcc8aj86db5a4e70c5e37d@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<ca53c8f80704241008k4c91a487p6f11eeaf7794b7a2@mail.gmail.com>
	<c8955b000704241226t45a725bej1a75e37fdd8fbd1@mail.gmail.com>
	<ca53c8f80704242038h64dee7ddgcb9421d1da51791c@mail.gmail.com>
	<c8955b000704242344q53cfcc8aj86db5a4e70c5e37d@mail.gmail.com>
Message-ID: <ca53c8f80704250043w5f0aafedme439b176c86ac788@mail.gmail.com>

>So you
>cannot rely on that if two messages arrive at the two queues
>simultaneously, both are returned because it is not the case.

If two messages arrive at the two queues simultaneously it's not guranteed
the two messages will be returned in the dequeue.  It's however possible.

One can rely on the dequeue returning at least one message, but one cannot
rely on the dequeue returning 2 messages even if they arrive
simultaneously.  Again, it is possible but not necessary.

Hanson Char

On 4/24/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> On 25/04/07, Hanson Char <hanson.char at gmail.com> wrote:
>
> > The assert statements presume the dequeue must happen in a certain
> order,
> > which therefore would appear to fail sometimes.
>
> Hi Hanson,
>    just have a look at your algorithm and you see that the certain
> order is established by the algorithm so it is quite correct to
> presume, isn't it?
>
>         callables.add(new Dequeue<T>(q1, result = new
> AtomicReferenceArray<T>(2), 0));
>         callables.add(new Dequeue<T>(q2, result, 1));
>         es.invokeAny(callables);
>
> So, you assign the first position in the two element
> AtomicReferenceArray to the first queue and the second position to the
> second queue. That is what the assert statements in the test follow.
> No problem with that. The asserts happen after the dequeue() is
> returned, so the AtomicReferenceArray is stable. No race condition
> applies at that point.
>
> The test sometimes fails and sometimes passes, however, and it is non
> deterministic whether one element is received or two. The test also
> ensures that one element is there in each queue at the time the
> dequeue() is called. The call, on the other hand, returns one or the
> other or both. That is no problem if you are aware of it. So you
> cannot rely on that if two messages arrive at the two queues
> simultaneously, both are returned because it is not the case.
>
> Best Regards,
> Szabolcs
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070425/7990a46f/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Apr 25 16:23:29 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 25 Apr 2007 22:23:29 +0200
Subject: [concurrency-interest] Basic question on making a thread
	waiting for 2 mailboxes...
In-Reply-To: <462CE240.5090502@cytetech.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>
	<462CE240.5090502@cytetech.com>
Message-ID: <c8955b000704251323u41b118b2w680c20f601efb907@mail.gmail.com>

On 23/04/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
> Peter Veentjer wrote:
> > But as far as I know there is no synchronization structure in j.u.c
> > that can provide the same functionality for arbitrary event sources.
> >
> > On 4/23/07, Fred Janon <fjanon at gmail.com> wrote:
> >
> >>Hi,
> >>
> >>I used to write real time apps using RSX11M+ (and VMS) that had mailboxes
> >>and events. There was a "wait for OR(events)". The task would wait for any
> >>event specified in the OR. Then I would associate an event with a mailbox,
> >>do that for another mailbox and when a message would arrive in one of the 2
> >>mailboxes, the task would awake. I am trying to do that in Java with
> >>threads.
>
> What I would do, is use threads that read from the two queues and put the
> objects into a single queue that you can take from.

Do you mean something like this, or something simpler? At least this
does not introduce non-determinism but handles it:

import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

public class Mailboxes<T>
{
    private BlockingQueue<T> transfer;

    public Mailboxes(BlockingQueue<T> q1, BlockingQueue<T> q2) {
        transfer = new LinkedBlockingQueue<T>();
        Thread c1 = new Copier<T>(q1, transfer);
        Thread c2 = new Copier<T>(q2, transfer);
	c1.start();
	c2.start();
    }

    private class Copier<T> extends Thread {
        private BlockingQueue<T> inp;
        private BlockingQueue<T> outp;
        public Copier(BlockingQueue<T> from, BlockingQueue<T> to) {
            inp = from;
            outp = to;
        }
        public void run() {
	    try {
		outp.put(inp.take());
	    } catch (Throwable e) {}
        }
    }

    public T wait_for_or() throws Throwable {
        return transfer.take();
    }
}

From gregg at cytetech.com  Wed Apr 25 19:29:21 2007
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 25 Apr 2007 18:29:21 -0500
Subject: [concurrency-interest] Basic question on making a thread
 waiting for 2 mailboxes...
In-Reply-To: <c8955b000704251323u41b118b2w680c20f601efb907@mail.gmail.com>
References: <2fd0c7810704230653k3045d440l7db24ab04da51d96@mail.gmail.com>
	<1466c1d60704230829x13293b10l617175bb68f3db30@mail.gmail.com>
	<462CE240.5090502@cytetech.com>
	<c8955b000704251323u41b118b2w680c20f601efb907@mail.gmail.com>
Message-ID: <462FE451.6040001@cytetech.com>



Szabolcs Ferenczi wrote:
> On 23/04/07, Gregg Wonderly <gregg at cytetech.com> wrote:
>>What I would do, is use threads that read from the two queues and put the
>>objects into a single queue that you can take from.
> 
> Do you mean something like this, or something simpler? At least this
> does not introduce non-determinism but handles it:

Yes, that is what I mean.  It takes care of FIFO etc.  As was mentioned earlier, 
you have to consider the issue of how to dispose of the threads if you dispose 
of the queue.  But, if you don't have that worry, then it works simply.

Gregg Wonderly

From joe.bowbeer at gmail.com  Fri Apr 27 01:50:34 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 26 Apr 2007 22:50:34 -0700
Subject: [concurrency-interest] Canonical example of how to do
	hand-over-hand locking?
In-Reply-To: <31f2a7bd0704241628k3f48abdaoa427ad32bbadd819@mail.gmail.com>
References: <462E0443.1040606@cs.cmu.edu>
	<31f2a7bd0704241041y4b9185bct77f6a0da5ea5385b@mail.gmail.com>
	<31f2a7bd0704241118m42b2abb5gaafb7866c0219b6e@mail.gmail.com>
	<31f2a7bd0704241421l7c639951l4afceda9f30f85dd@mail.gmail.com>
	<31f2a7bd0704241446p16cf1ad2x8db0c6f343cf93c2@mail.gmail.com>
	<31f2a7bd0704241628k3f48abdaoa427ad32bbadd819@mail.gmail.com>
Message-ID: <31f2a7bd0704262250y6cf47d07jd9d19ac16664408b@mail.gmail.com>

On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> The javadoc for the java.util.concurrent.locks package explicitly
> mentions that the locks can be used for hand-over-hand locking.  But it
> doesn't give an example.  How does this interact with the recommendation
> that unlocks occur in finally clauses so as to insure that all locks are
> always unlocked?
>

In case you're still interested, here's one more example.  (I really
like this question:)

The methods are in order of increasing complexity.  The 'remove'
method is the most complex, needing nested try-finally's to handle all
the possible exceptions.

public class List {

    /**
     * Holds one item in a singly-linked list.
     * It's convenient here to subclass ReentrantLock
     * rather than add one as a field.
     */
    private static class Node extends ReentrantLock {
        Object item;
        Node next;
        Node(Object item, Node next) {
            this.item = item;
            this.next = next;
        }
    }

    /**
     * Sentinel node. This node's next field points to
     * the first node in the list. Its item field is ignored.
     */
    private final Node sentinel = new Node(null, null);

    public void addFirst(Object x) {
        Node p = sentinel;
        p.lock();
        try {
            p.next = new Node(x, p.next);
        } finally {
            p.unlock();
        }
     }

    public void addLast(Object x) {
        Node p = sentinel;
        /* Acquire first lock. */
        p.lock();
        try {
            /* Find tail, using hand-over-hand locking. */
            while (p.next != null) {
                Node prevp = p;
                p.next.lock();
                p = p.next;
                prevp.unlock();
            }
            /* Attach new node. */
            p.next = new Node(x, null);
        } finally {
            /* Release final lock that was held. */
            p.unlock();
        }
     }

    public boolean contains(Object x) {
        Node p = sentinel;
        /* Acquire first lock. */
        p.lock();
        try {
            while (p.next != null) {
                /*
                 * Get next lock and release current.
                 * Sentinel is skipped on first iteration.
                 */
                Node prevp = p;
                p.next.lock();
                p = p.next;
                prevp.unlock();
                /* Found? */
                if (x == p.item || x != null && x.equals(p.item))
                    return true;
            }
            return false;
        } finally {
            /* Release final lock that was held. */
            p.unlock();
        }
    }

    public boolean remove(Object x) {
        Node p = sentinel;
        /* Acquire first lock. */
        p.lock();
        try {
            while (p.next != null) {
                /*
                 * Get next lock and release current.
                 * Sentinel is skipped on first iteration.
                 */
                Node prevp = p;
                p.next.lock();
                p = p.next;
                try {
                    /* Found? */
                    if (x == p.item || x != null && x.equals(p.item)) {
                        /* Remove node p. */
                        prevp.next = p.next;
                        return true;
                    }
                } finally {
                    prevp.unlock();
                }
            }
            return false;
        } finally {
            /* Release final lock that was held. */
            p.unlock();
        }
    }
}

--
Joe Bowbeer

From dcholmes at optusnet.com.au  Fri Apr 27 12:55:31 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sat, 28 Apr 2007 02:55:31 +1000
Subject: [concurrency-interest] Canonical example of how to
 dohand-over-hand locking?
In-Reply-To: <31f2a7bd0704262250y6cf47d07jd9d19ac16664408b@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEJHHGAA.dcholmes@optusnet.com.au>

Let me clarify that "all the exceptions" means:
- any exception from Lock.lock()  (OutOfMemoryError most likely one to
encounter)
- any exception from equals()
- OutOfMemoryError from "new Node"

Any other exception, such as NullPointerException would be considered an
inherent programming error and not something the code tries to cope with.
Naturally asynchronous exceptions aren't handled either.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Joe
> Bowbeer
> Sent: Friday, 27 April 2007 3:51 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Canonical example of how to
> dohand-over-hand locking?
>
>
> On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> > The javadoc for the java.util.concurrent.locks package explicitly
> > mentions that the locks can be used for hand-over-hand locking.  But it
> > doesn't give an example.  How does this interact with the recommendation
> > that unlocks occur in finally clauses so as to insure that all locks are
> > always unlocked?
> >
>
> In case you're still interested, here's one more example.  (I really
> like this question:)
>
> The methods are in order of increasing complexity.  The 'remove'
> method is the most complex, needing nested try-finally's to handle all
> the possible exceptions.
>
> public class List {
>
>     /**
>      * Holds one item in a singly-linked list.
>      * It's convenient here to subclass ReentrantLock
>      * rather than add one as a field.
>      */
>     private static class Node extends ReentrantLock {
>         Object item;
>         Node next;
>         Node(Object item, Node next) {
>             this.item = item;
>             this.next = next;
>         }
>     }
>
>     /**
>      * Sentinel node. This node's next field points to
>      * the first node in the list. Its item field is ignored.
>      */
>     private final Node sentinel = new Node(null, null);
>
>     public void addFirst(Object x) {
>         Node p = sentinel;
>         p.lock();
>         try {
>             p.next = new Node(x, p.next);
>         } finally {
>             p.unlock();
>         }
>      }
>
>     public void addLast(Object x) {
>         Node p = sentinel;
>         /* Acquire first lock. */
>         p.lock();
>         try {
>             /* Find tail, using hand-over-hand locking. */
>             while (p.next != null) {
>                 Node prevp = p;
>                 p.next.lock();
>                 p = p.next;
>                 prevp.unlock();
>             }
>             /* Attach new node. */
>             p.next = new Node(x, null);
>         } finally {
>             /* Release final lock that was held. */
>             p.unlock();
>         }
>      }
>
>     public boolean contains(Object x) {
>         Node p = sentinel;
>         /* Acquire first lock. */
>         p.lock();
>         try {
>             while (p.next != null) {
>                 /*
>                  * Get next lock and release current.
>                  * Sentinel is skipped on first iteration.
>                  */
>                 Node prevp = p;
>                 p.next.lock();
>                 p = p.next;
>                 prevp.unlock();
>                 /* Found? */
>                 if (x == p.item || x != null && x.equals(p.item))
>                     return true;
>             }
>             return false;
>         } finally {
>             /* Release final lock that was held. */
>             p.unlock();
>         }
>     }
>
>     public boolean remove(Object x) {
>         Node p = sentinel;
>         /* Acquire first lock. */
>         p.lock();
>         try {
>             while (p.next != null) {
>                 /*
>                  * Get next lock and release current.
>                  * Sentinel is skipped on first iteration.
>                  */
>                 Node prevp = p;
>                 p.next.lock();
>                 p = p.next;
>                 try {
>                     /* Found? */
>                     if (x == p.item || x != null && x.equals(p.item)) {
>                         /* Remove node p. */
>                         prevp.next = p.next;
>                         return true;
>                     }
>                 } finally {
>                     prevp.unlock();
>                 }
>             }
>             return false;
>         } finally {
>             /* Release final lock that was held. */
>             p.unlock();
>         }
>     }
> }
>
> --
> Joe Bowbeer
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From hanson.char at gmail.com  Fri Apr 27 13:47:08 2007
From: hanson.char at gmail.com (Hanson Char)
Date: Fri, 27 Apr 2007 10:47:08 -0700
Subject: [concurrency-interest] Canonical example of how to
	dohand-over-hand locking?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEJHHGAA.dcholmes@optusnet.com.au>
References: <31f2a7bd0704262250y6cf47d07jd9d19ac16664408b@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEJHHGAA.dcholmes@optusnet.com.au>
Message-ID: <ca53c8f80704271047r18517eabt1fb6f7ab3fa3c0b6@mail.gmail.com>

A side question: Shouldn't asynchronous exceptions be removed from the
JDK/JVM ?  Why do we need them ?

Hanson Char

On 4/27/07, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> Let me clarify that "all the exceptions" means:
> - any exception from Lock.lock()  (OutOfMemoryError most likely one to
> encounter)
> - any exception from equals()
> - OutOfMemoryError from "new Node"
>
> Any other exception, such as NullPointerException would be considered an
> inherent programming error and not something the code tries to cope with.
> Naturally asynchronous exceptions aren't handled either.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Joe
> > Bowbeer
> > Sent: Friday, 27 April 2007 3:51 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Canonical example of how to
> > dohand-over-hand locking?
> >
> >
> > On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> > > The javadoc for the java.util.concurrent.locks package explicitly
> > > mentions that the locks can be used for hand-over-hand locking.  But
> it
> > > doesn't give an example.  How does this interact with the
> recommendation
> > > that unlocks occur in finally clauses so as to insure that all locks
> are
> > > always unlocked?
> > >
> >
> > In case you're still interested, here's one more example.  (I really
> > like this question:)
> >
> > The methods are in order of increasing complexity.  The 'remove'
> > method is the most complex, needing nested try-finally's to handle all
> > the possible exceptions.
> >
> > public class List {
> >
> >     /**
> >      * Holds one item in a singly-linked list.
> >      * It's convenient here to subclass ReentrantLock
> >      * rather than add one as a field.
> >      */
> >     private static class Node extends ReentrantLock {
> >         Object item;
> >         Node next;
> >         Node(Object item, Node next) {
> >             this.item = item;
> >             this.next = next;
> >         }
> >     }
> >
> >     /**
> >      * Sentinel node. This node's next field points to
> >      * the first node in the list. Its item field is ignored.
> >      */
> >     private final Node sentinel = new Node(null, null);
> >
> >     public void addFirst(Object x) {
> >         Node p = sentinel;
> >         p.lock();
> >         try {
> >             p.next = new Node(x, p.next);
> >         } finally {
> >             p.unlock();
> >         }
> >      }
> >
> >     public void addLast(Object x) {
> >         Node p = sentinel;
> >         /* Acquire first lock. */
> >         p.lock();
> >         try {
> >             /* Find tail, using hand-over-hand locking. */
> >             while (p.next != null) {
> >                 Node prevp = p;
> >                 p.next.lock();
> >                 p = p.next;
> >                 prevp.unlock();
> >             }
> >             /* Attach new node. */
> >             p.next = new Node(x, null);
> >         } finally {
> >             /* Release final lock that was held. */
> >             p.unlock();
> >         }
> >      }
> >
> >     public boolean contains(Object x) {
> >         Node p = sentinel;
> >         /* Acquire first lock. */
> >         p.lock();
> >         try {
> >             while (p.next != null) {
> >                 /*
> >                  * Get next lock and release current.
> >                  * Sentinel is skipped on first iteration.
> >                  */
> >                 Node prevp = p;
> >                 p.next.lock();
> >                 p = p.next;
> >                 prevp.unlock();
> >                 /* Found? */
> >                 if (x == p.item || x != null && x.equals(p.item))
> >                     return true;
> >             }
> >             return false;
> >         } finally {
> >             /* Release final lock that was held. */
> >             p.unlock();
> >         }
> >     }
> >
> >     public boolean remove(Object x) {
> >         Node p = sentinel;
> >         /* Acquire first lock. */
> >         p.lock();
> >         try {
> >             while (p.next != null) {
> >                 /*
> >                  * Get next lock and release current.
> >                  * Sentinel is skipped on first iteration.
> >                  */
> >                 Node prevp = p;
> >                 p.next.lock();
> >                 p = p.next;
> >                 try {
> >                     /* Found? */
> >                     if (x == p.item || x != null && x.equals(p.item)) {
> >                         /* Remove node p. */
> >                         prevp.next = p.next;
> >                         return true;
> >                     }
> >                 } finally {
> >                     prevp.unlock();
> >                 }
> >             }
> >             return false;
> >         } finally {
> >             /* Release final lock that was held. */
> >             p.unlock();
> >         }
> >     }
> > }
> >
> > --
> > Joe Bowbeer
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070427/9e390bf3/attachment.html 

From dcholmes at optusnet.com.au  Sat Apr 28 00:01:14 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sat, 28 Apr 2007 14:01:14 +1000
Subject: [concurrency-interest] Canonical example of how
 todohand-over-hand locking?
In-Reply-To: <ca53c8f80704271047r18517eabt1fb6f7ab3fa3c0b6@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEJLHGAA.dcholmes@optusnet.com.au>

Well maybe one day we can actually remove Thread.stop, but until then ...

The potential for "async" VM exceptions (they are "async" with respect to
the thread logic but actually synchronous in terms of execution) still
exists, but more often problems in the VM result in a crash rather than an
exception. :(

Actually there's a more real reason why the language/VM has to keep open the
possibility of asynchronous exceptions: the Real-Time Specification for Java
(RTSJ) utilizes a (safer form) of asynchronous exceptions for immediate
cancellation.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson Char
  Sent: Saturday, 28 April 2007 3:47 AM
  To: dholmes at ieee.org
  Cc: Joe Bowbeer; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Canonical example of how
todohand-over-hand locking?


  A side question: Shouldn't asynchronous exceptions be removed from the
JDK/JVM ?  Why do we need them ?

  Hanson Char


  On 4/27/07, David Holmes < dcholmes at optusnet.com.au> wrote:
    Let me clarify that "all the exceptions" means:
    - any exception from Lock.lock()  (OutOfMemoryError most likely one to
    encounter)
    - any exception from equals()
    - OutOfMemoryError from "new Node"

    Any other exception, such as NullPointerException would be considered an
    inherent programming error and not something the code tries to cope
with.
    Naturally asynchronous exceptions aren't handled either.

    Cheers,
    David Holmes

    > -----Original Message-----
    > From: concurrency-interest-bounces at cs.oswego.edu
    > [mailto:concurrency-interest-bounces at cs.oswego.edu ]On Behalf Of Joe
    > Bowbeer
    > Sent: Friday, 27 April 2007 3:51 PM
    > To: concurrency-interest at cs.oswego.edu
    > Subject: Re: [concurrency-interest] Canonical example of how to
    > dohand-over-hand locking?
    >
    >
    > On 4/24/07, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
    > > The javadoc for the java.util.concurrent.locks package explicitly
    > > mentions that the locks can be used for hand-over-hand locking.  But
it
    > > doesn't give an example.  How does this interact with the
recommendation
    > > that unlocks occur in finally clauses so as to insure that all locks
are
    > > always unlocked?
    > >
    >
    > In case you're still interested, here's one more example.  (I really
    > like this question:)
    >
    > The methods are in order of increasing complexity.  The 'remove'
    > method is the most complex, needing nested try-finally's to handle all
    > the possible exceptions.
    >
    > public class List {
    >
    >     /**
    >      * Holds one item in a singly-linked list.
    >      * It's convenient here to subclass ReentrantLock
    >      * rather than add one as a field.
    >      */
    >     private static class Node extends ReentrantLock {
    >         Object item;
    >         Node next;
    >         Node(Object item, Node next) {
    >             this.item = item;
    >             this.next = next;
    >         }
    >     }
    >
    >     /**
    >      * Sentinel node. This node's next field points to
    >      * the first node in the list. Its item field is ignored.
    >      */
    >     private final Node sentinel = new Node(null, null);
    >
    >     public void addFirst(Object x) {
    >         Node p = sentinel;
    >         p.lock();
    >         try {
    >             p.next = new Node(x, p.next);
    >         } finally {
    >             p.unlock();
    >         }
    >      }
    >
    >     public void addLast(Object x) {
    >         Node p = sentinel;
    >         /* Acquire first lock. */
    >         p.lock();
    >         try {
    >             /* Find tail, using hand-over-hand locking. */
    >             while (p.next != null) {
    >                 Node prevp = p;
    >                 p.next.lock();
    >                 p = p.next;
    >                 prevp.unlock();
    >             }
    >             /* Attach new node. */
    >             p.next = new Node(x, null);
    >         } finally {
    >             /* Release final lock that was held. */
    >             p.unlock();
    >         }
    >      }
    >
    >     public boolean contains(Object x) {
    >         Node p = sentinel;
    >         /* Acquire first lock. */
    >         p.lock();
    >         try {
    >             while (p.next != null) {
    >                 /*
    >                  * Get next lock and release current.
    >                  * Sentinel is skipped on first iteration.
    >                  */
    >                 Node prevp = p;
    >                 p.next.lock();
    >                 p = p.next;
    >                 prevp.unlock();
    >                 /* Found? */
    >                 if (x == p.item || x != null && x.equals(p.item))
    >                     return true;
    >             }
    >             return false;
    >         } finally {
    >             /* Release final lock that was held. */
    >             p.unlock();
    >         }
    >     }
    >
    >     public boolean remove(Object x) {
    >         Node p = sentinel;
    >         /* Acquire first lock. */
    >         p.lock();
    >         try {
    >             while (p.next != null) {
    >                 /*
    >                  * Get next lock and release current.
    >                  * Sentinel is skipped on first iteration.
    >                  */
    >                 Node prevp = p;
    >                 p.next.lock();
    >                 p = p.next;
    >                 try {
    >                     /* Found? */
    >                     if (x == p.item || x != null && x.equals(p.item))
{
    >                         /* Remove node p. */
    >                         prevp.next = p.next;
    >                         return true;
    >                     }
    >                 } finally {
    >                     prevp.unlock();
    >                 }
    >             }
    >             return false;
    >         } finally {
    >             /* Release final lock that was held. */
    >             p.unlock();
    >         }
    >     }
    > }
    >
    > --
    > Joe Bowbeer
    > _______________________________________________
    > Concurrency-interest mailing list
    > Concurrency-interest at altair.cs.oswego.edu
    > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at altair.cs.oswego.edu
    http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070428/d5322025/attachment-0001.html 

From the.mindstorm.mailinglist at gmail.com  Sun Apr 29 19:08:58 2007
From: the.mindstorm.mailinglist at gmail.com (=?UTF-8?Q?Alexandru_Popescu_=E2=98=80?=)
Date: Mon, 30 Apr 2007 02:08:58 +0300
Subject: [concurrency-interest] An article example
Message-ID: <c6f400460704291608t1fba2e8ep785d49d12d7e9f13@mail.gmail.com>

Hi all!

I was reading the PrintQueue example in this article:
http://www-128.ibm.com/developerworks/java/library/j-contest.html.
Later in the article there is the following comment:

[quote]
[snip...] and suddenly you'll get a NoSuchElementException thrown by
LinkedList.removeFirst() in line 24. The bug lurks in the following
scenario:

   1. Two consumer threads are started, find the queue to be empty,
and do wait().
   2. A producer enqueues a task and notifies both consumers.
   3. One consumer gets the lock, works the task, and leaves the queue
empty. It then releases the lock.
   4. The second consumer gets the lock (it can proceed because it was
notified) and tries to work a task, but now the queue is empty.
[/quote]

Now this comment kind of confuses me because as far as I can say by
the end of step3, the queue is indeed empty and the 2nd consumer will
see this in the condition queue.isEmpty() so it will wait.

Can you please explain what am I missing?

many thanks in advance,

./alex
--
.w( the_mindstorm )p.

From dcholmes at optusnet.com.au  Sun Apr 29 21:06:41 2007
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 30 Apr 2007 11:06:41 +1000
Subject: [concurrency-interest] An article example
In-Reply-To: <c6f400460704291608t1fba2e8ep785d49d12d7e9f13@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEKFHGAA.dcholmes@optusnet.com.au>

Alex,

They code the wait() in an "if" , instead of a "while" loop.

     synchronized(lock) {
         if (queue.isEmpty()) {
            try {
               lock.wait();
            } catch (InterruptedException e) {
               assert (false);
            }
         }
         current = queue.removeFirst();
      }

So two consumers wait because it was empty. The producer does a notifyAll
and so both consumers think there is work to do when there is only one item
in the queue.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> Alexandru Popescu ?
> Sent: Monday, 30 April 2007 9:09 AM
> To: userConcurrency
> Subject: [concurrency-interest] An article example
>
>
> Hi all!
>
> I was reading the PrintQueue example in this article:
> http://www-128.ibm.com/developerworks/java/library/j-contest.html.
> Later in the article there is the following comment:
>
> [quote]
> [snip...] and suddenly you'll get a NoSuchElementException thrown by
> LinkedList.removeFirst() in line 24. The bug lurks in the following
> scenario:
>
>    1. Two consumer threads are started, find the queue to be empty,
> and do wait().
>    2. A producer enqueues a task and notifies both consumers.
>    3. One consumer gets the lock, works the task, and leaves the queue
> empty. It then releases the lock.
>    4. The second consumer gets the lock (it can proceed because it was
> notified) and tries to work a task, but now the queue is empty.
> [/quote]
>
> Now this comment kind of confuses me because as far as I can say by
> the end of step3, the queue is indeed empty and the 2nd consumer will
> see this in the condition queue.isEmpty() so it will wait.
>
> Can you please explain what am I missing?
>
> many thanks in advance,
>
> ./alex
> --
> .w( the_mindstorm )p.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From the.mindstorm.mailinglist at gmail.com  Sun Apr 29 21:22:23 2007
From: the.mindstorm.mailinglist at gmail.com (=?UTF-8?Q?Alexandru_Popescu_=E2=98=80?=)
Date: Mon, 30 Apr 2007 04:22:23 +0300
Subject: [concurrency-interest] An article example
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEKFHGAA.dcholmes@optusnet.com.au>
References: <c6f400460704291608t1fba2e8ep785d49d12d7e9f13@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEKFHGAA.dcholmes@optusnet.com.au>
Message-ID: <c6f400460704291822s6e7062e9n8b2629747dfe120a@mail.gmail.com>

On 4/30/07, David Holmes <dcholmes at optusnet.com.au> wrote:
> Alex,
>
> They code the wait() in an "if" , instead of a "while" loop.
>
>      synchronized(lock) {
>          if (queue.isEmpty()) {
>             try {
>                lock.wait();
>             } catch (InterruptedException e) {
>                assert (false);
>             }
>          }
>          current = queue.removeFirst();
>       }
>
> So two consumers wait because it was empty. The producer does a notifyAll
> and so both consumers think there is work to do when there is only one item
> in the queue.
>

Darn... I don't know what a hell I was thinking :-). Thanks a lot David.

./alex
--
.w( the_mindstorm )p.

> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > Alexandru Popescu ?
> > Sent: Monday, 30 April 2007 9:09 AM
> > To: userConcurrency
> > Subject: [concurrency-interest] An article example
> >
> >
> > Hi all!
> >
> > I was reading the PrintQueue example in this article:
> > http://www-128.ibm.com/developerworks/java/library/j-contest.html.
> > Later in the article there is the following comment:
> >
> > [quote]
> > [snip...] and suddenly you'll get a NoSuchElementException thrown by
> > LinkedList.removeFirst() in line 24. The bug lurks in the following
> > scenario:
> >
> >    1. Two consumer threads are started, find the queue to be empty,
> > and do wait().
> >    2. A producer enqueues a task and notifies both consumers.
> >    3. One consumer gets the lock, works the task, and leaves the queue
> > empty. It then releases the lock.
> >    4. The second consumer gets the lock (it can proceed because it was
> > notified) and tries to work a task, but now the queue is empty.
> > [/quote]
> >
> > Now this comment kind of confuses me because as far as I can say by
> > the end of step3, the queue is indeed empty and the 2nd consumer will
> > see this in the condition queue.isEmpty() so it will wait.
> >
> > Can you please explain what am I missing?
> >
> > many thanks in advance,
> >
> > ./alex
> > --
> > .w( the_mindstorm )p.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From szabolcs.ferenczi at gmail.com  Mon Apr 30 17:12:19 2007
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Mon, 30 Apr 2007 23:12:19 +0200
Subject: [concurrency-interest] An article example
In-Reply-To: <c6f400460704291822s6e7062e9n8b2629747dfe120a@mail.gmail.com>
References: <c6f400460704291608t1fba2e8ep785d49d12d7e9f13@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEKFHGAA.dcholmes@optusnet.com.au>
	<c6f400460704291822s6e7062e9n8b2629747dfe120a@mail.gmail.com>
Message-ID: <c8955b000704301412t6e86c591md33266cf7216d81a@mail.gmail.com>

On 30/04/07, Alexandru Popescu ? <the.mindstorm.mailinglist at gmail.com> wrote:
> On 4/30/07, David Holmes <dcholmes at optusnet.com.au> wrote:

> > They code the wait() in an "if" , instead of a "while" loop.

This is a mistake that will be made by a lot of people, I am afraid.

On the occasion of this mistake let me have a remark: This indicates
that the Java programming language is not a genuine multi-threaded
language. Unfortunately it does not have proper language means for
dealing with concurrency.

It adapted some form of the monitor construction but unfortunately the
most primitive form. It is something that was proposed by Horare for
operating systems in '72 (http://www.acm.org/classics/feb96/). At the
same time there was a alternative proposal by Per Brinch Hansen
(http://brinch-hansen.net/papers/1973b.pdf), which was at a bit higher
level. In the latter proposal the language primitive for long term
scheduling was

await(condition)

meaning that the thread is suspended until the condition holds. No
question whether it should be applied in an 'if' branch or in a
'while' loop. After all, the 'if' and the 'while' commands are
designed for sequential programming.

However, the best choice could be if a multi-threaded programming
language would take over and adapt the Guarded Commands
(http://www.cs.utexas.edu/users/EWD/ewd04xx/EWD418.PDF) which was
designed to cope with indeterminacy at the language level.

Perhaps Java could be improved with respect to concurrency.

Now, before the Java wrestler guys start to attack me again or to
command me to read some more literature on this subject, let me repeat
that it was only a humble remark. No attack, please.

On the other hand, comments and arguments are welcome. I am open to discussion.

Best Regards,
Szabolcs


From joe.bowbeer at gmail.com  Mon Apr 30 18:39:41 2007
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 30 Apr 2007 15:39:41 -0700
Subject: [concurrency-interest] An article example
In-Reply-To: <c8955b000704301412t6e86c591md33266cf7216d81a@mail.gmail.com>
References: <c6f400460704291608t1fba2e8ep785d49d12d7e9f13@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEKFHGAA.dcholmes@optusnet.com.au>
	<c6f400460704291822s6e7062e9n8b2629747dfe120a@mail.gmail.com>
	<c8955b000704301412t6e86c591md33266cf7216d81a@mail.gmail.com>
Message-ID: <31f2a7bd0704301539u3b054b4en3acaf310d55c7223@mail.gmail.com>

On 4/30/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> On the other hand, comments and arguments are welcome. I am open to discussion.
>

I hope that tap tap tapping I hear ...

is the sound of Peter Welch typing his annual missive

http://en.wikipedia.org/wiki/JCSP

and not a leak in the plumbing ...

From tim at peierls.net  Mon Apr 30 19:47:28 2007
From: tim at peierls.net (Tim Peierls)
Date: Mon, 30 Apr 2007 19:47:28 -0400
Subject: [concurrency-interest] An article example
In-Reply-To: <c8955b000704301412t6e86c591md33266cf7216d81a@mail.gmail.com>
References: <c6f400460704291608t1fba2e8ep785d49d12d7e9f13@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEKFHGAA.dcholmes@optusnet.com.au>
	<c6f400460704291822s6e7062e9n8b2629747dfe120a@mail.gmail.com>
	<c8955b000704301412t6e86c591md33266cf7216d81a@mail.gmail.com>
Message-ID: <63b4e4050704301647h761168d1pd31c7a4c3702796a@mail.gmail.com>

On 4/30/07, Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com> wrote:
>
> On the occasion of this mistake let me have a remark: This indicates
> that the Java programming language is not a genuine multi-threaded
> language. Unfortunately it does not have proper language means for
> dealing with concurrency.


I have a lot of code written in Java that has to run on a multiprocessor.
Can you recommend a language I should port this code to in order to deal
properly with concurrency? The code depends heavily on the standard Java
libraries and several third-party libraries, so a key consideration for me
would be support in the target language for these libraries.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20070430/eca8d554/attachment.html 

