From qiyaoltc at gmail.com  Tue May  4 05:01:41 2010
From: qiyaoltc at gmail.com (Yao Qi)
Date: Tue, 4 May 2010 17:01:41 +0800
Subject: [concurrency-interest] jucprofiler : java.util.concurrent locks
	profiling
Message-ID: <h2hdcbde71d1005040201k5329c079t2a04b76483420bc3@mail.gmail.com>

Dear all,
With the introduction of the java.util.concurrent (JUC) package in
Java 5, a new type of lock was introduced into the Java lanaguage.
There are no tools available to profile JUC locks and provide detailed
contention information like those provided by PerformanceInspector/JLM
for regular Java locks.  Also, usage of the JUC package is becoming
more and more popular as more application are either developed or fine
tuned to run better on multicore systems.  This absence of a JUC lock
profiling tool is the motivation behind the development of our lock
tool : jucprofiler.

Jucprofiler has bee released as part of MulticoreSDK for Java on
alphaWorks (a set of tools for parallel java programs
http://www.alphaworks.ibm.com/tech/msdk/).  You can download
DCInstall.zip, and install jucprofiler in your box.  Now, it supports
Linux/x86 and AIX.  If you need other platform support, such as
Linux/X86_64, let us know.

We've written a blog about using jucprofiler (some of them are out of
date, just for your reference.  Document in DCInstall.zip is the
latest one.)
http://aminoprj.blogspot.com/2010/01/jucprofiler-javautilconcurrent-locks.html

Your feedback and comments are very welcome.

-- 
Yao Qi <qiyaoltc AT gmail DOT com>    GNU/Linux Developer
http://duewayqi.googlepages.com/

From martinrb at google.com  Wed May  5 19:51:51 2010
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 5 May 2010 16:51:51 -0700
Subject: [concurrency-interest] PriorityBlockingQueue uses a fair lock
Message-ID: <AANLkTinH9qzKzD100H1QmZ7YtFjHvWscZQ708F6R978H@mail.gmail.com>

A colleague noticed that PriorityBlockingQueue's
internal lock is a fair ReentrantLock,
when a non-fair lock would be much faster
and usually "fair" enough.  Is there some history here?
Should we add a non-fair option for constructing PBQ?

Martin

From davidcholmes at aapt.net.au  Wed May  5 20:14:37 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 6 May 2010 10:14:37 +1000
Subject: [concurrency-interest] PriorityBlockingQueue uses a fair lock
In-Reply-To: <AANLkTinH9qzKzD100H1QmZ7YtFjHvWscZQ708F6R978H@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEEDIGAA.davidcholmes@aapt.net.au>

Hi Martin,

> A colleague noticed that PriorityBlockingQueue's
> internal lock is a fair ReentrantLock,
> when a non-fair lock would be much faster
> and usually "fair" enough.  Is there some history here?

Yes but even when it was discussed by the EG on January 11 2006 the history
had been lost somewhat.

> Should we add a non-fair option for constructing PBQ?

Yes. This addition was deemed too-late for Java 6 inclusion, but should have
been listed for Java 7.

Cheers,
David

> Martin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From joe.bowbeer at gmail.com  Wed May  5 20:46:42 2010
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 5 May 2010 17:46:42 -0700
Subject: [concurrency-interest] PriorityBlockingQueue uses a fair lock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEEDIGAA.davidcholmes@aapt.net.au>
References: <AANLkTinH9qzKzD100H1QmZ7YtFjHvWscZQ708F6R978H@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEEDIGAA.davidcholmes@aapt.net.au>
Message-ID: <o2k31f2a7bd1005051746s8a8a0f9dl3051ac43d3e23afb@mail.gmail.com>

Switching the lock type was suggested in 2006, but after lengthy discussion
it was decided that adding a non-fair option would be safer.

Doug wrote:

We can't just switch in nonfair lock mainly because people

on uniprocessors may unknowingly rely on it to keep producer-consumer

chains more balanced. I know that this does arise because someone

once asked me why their program using ArrayBlockingQueue was causing

memory retention on uniprocessors but not multiprocessors. I told

him to use fair mode, which was an effective bandaid.  (I hate using

fairness for such purposes, but it was better than him having to

redesign program.)



On Wed, May 5, 2010 at 5:14 PM, David Holmes wrote:

> Hi Martin,
>
> > A colleague noticed that PriorityBlockingQueue's
> > internal lock is a fair ReentrantLock,
> > when a non-fair lock would be much faster
> > and usually "fair" enough.  Is there some history here?
>
> Yes but even when it was discussed by the EG on January 11 2006 the history
> had been lost somewhat.
>
> > Should we add a non-fair option for constructing PBQ?
>
> Yes. This addition was deemed too-late for Java 6 inclusion, but should
> have
> been listed for Java 7.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100505/73e92f72/attachment.html>

From gdenys at yahoo.com  Fri May  7 09:14:26 2010
From: gdenys at yahoo.com (Denys Geert)
Date: Fri, 7 May 2010 06:14:26 -0700 (PDT)
Subject: [concurrency-interest] cancellation of ForkJoinTask
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEEDIGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEEDIGAA.davidcholmes@aapt.net.au>
Message-ID: <593787.22303.qm@web51404.mail.re2.yahoo.com>

Hi,

>From my observations, when canceling a top-level recursive task submitted to FJ, the thread that called FJPool.invoke is unblocked quite rapidly, but the task and its child tasks keep on executing in the FJ pool (even forking and joining new child tasks).

Although the cancellation has the effect of unblocking the invoker, it seem all of the work is still performed, as if cancellation was never requested.

The behavior of the cancellation seems weird and not very helpful. An alternative would be to shut the FJ pool down, but that would prevent reuse of the pool among tasks.

Thanks for any info,
Geert.


      

From dl at cs.oswego.edu  Fri May  7 10:42:47 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 07 May 2010 10:42:47 -0400
Subject: [concurrency-interest] cancellation of ForkJoinTask
In-Reply-To: <593787.22303.qm@web51404.mail.re2.yahoo.com>
References: <NFBBKALFDCPFIDBNKAPCAEEDIGAA.davidcholmes@aapt.net.au>
	<593787.22303.qm@web51404.mail.re2.yahoo.com>
Message-ID: <4BE426E7.7070204@cs.oswego.edu>

On 05/07/10 09:14, Denys Geert wrote:
> Hi,
>
>> From my observations, when canceling a top-level recursive task submitted
>> to FJ, the thread that called FJPool.invoke is unblocked quite rapidly, but
>> the task and its child tasks keep on executing in the FJ pool (even forking
>> and joining new child tasks).
>
> Although the cancellation has the effect of unblocking the invoker, it seem
> all of the work is still performed, as if cancellation was never requested.
>
> The behavior of the cancellation seems weird and not very helpful. An
> alternative would be to shut the FJ pool down, but that would prevent reuse
> of the pool among tasks.
>

If you need to somehow return early from a task that is running
while asynchronously cancelled, then task compute method itself must
check isCancelled and respond appropriately (which may include
propagating cancellation to subtasks). We (the FJ framework)
cannot do this for you because we know nothing about the internals
of compute() methods. And even if we did, we would not always
know the appropriate action.

-Doug



From ashwin.jayaprakash at gmail.com  Sat May  8 14:33:26 2010
From: ashwin.jayaprakash at gmail.com (Ashwin Jayaprakash)
Date: Sat, 8 May 2010 11:33:26 -0700
Subject: [concurrency-interest] java.util.concurrent.ThreadPoolExecutor
	does not execute jobs in some cases
Message-ID: <AANLkTikQTYRs3KfiUzpy7DDP4dSosLSt7Yaohw9NtB53@mail.gmail.com>

This is an old email, but I found out today that there were still strange
problems on JDK 6_18 related to this coreThread count.

Even with coreThreads=maxThreads, some pools would never start and would
never process any job. The solution required calling
prestartAllCoreThreads(). I will investigate more later, but for anyone else
facing this problem it will help. Calling just prestartCoreThread() might
also work, but I haven't tried.

Ashwin.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100508/0037915d/attachment.html>

From martinrb at google.com  Sat May  8 21:38:44 2010
From: martinrb at google.com (Martin Buchholz)
Date: Sat, 8 May 2010 18:38:44 -0700
Subject: [concurrency-interest] java.util.concurrent.ThreadPoolExecutor
	does not execute jobs in some cases
In-Reply-To: <AANLkTikQTYRs3KfiUzpy7DDP4dSosLSt7Yaohw9NtB53@mail.gmail.com>
References: <AANLkTikQTYRs3KfiUzpy7DDP4dSosLSt7Yaohw9NtB53@mail.gmail.com>
Message-ID: <AANLkTin13dzduToJG5vbepDdSgnacxY8nljeiB_LxxIZ@mail.gmail.com>

Unfortunately, I don't think the ThreadPool fixes
were backported to the proprietary JDK 6 code base,
but they are in OpenJDK6 and OpenJDK7.

You can try using the ThreadPoolExecutor from openjdk6,
or from Doug's CVS.

Martin

On Sat, May 8, 2010 at 11:33, Ashwin Jayaprakash
<ashwin.jayaprakash at gmail.com> wrote:
> This is an old email, but I found out today that there were still strange
> problems on JDK 6_18 related to this coreThread count.
>
> Even with coreThreads=maxThreads, some pools would never start and would
> never process any job. The solution required calling
> prestartAllCoreThreads(). I will investigate more later, but for anyone else
> facing this problem it will help. Calling just prestartCoreThread() might
> also work, but I haven't tried.
>
> Ashwin.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From davidcholmes at aapt.net.au  Sun May  9 00:18:03 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 9 May 2010 14:18:03 +1000
Subject: [concurrency-interest]
	java.util.concurrent.ThreadPoolExecutordoes not execute jobs
	in some cases
In-Reply-To: <AANLkTin13dzduToJG5vbepDdSgnacxY8nljeiB_LxxIZ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEFAIGAA.davidcholmes@aapt.net.au>

In this case I can't see that the bug report ever actually became a CR. In
the earlier email exchanges I thought the problem was with setting a zero
coreSize.

Not only do many (most?) OpenJDK6 bugs not get fixed in the Sun/Oracle JDK
releases but many/most fixes that went into OpenJDK7 prior to openJDK6
existing, are also not in OpenJDK6.

David Holmes

Martin Buchholz writes on Sunday, 9 May 2010 11:39 AM:
>
> Unfortunately, I don't think the ThreadPool fixes
> were backported to the proprietary JDK 6 code base,
> but they are in OpenJDK6 and OpenJDK7.
>
> You can try using the ThreadPoolExecutor from openjdk6,
> or from Doug's CVS.
>
> Martin
>
> On Sat, May 8, 2010 at 11:33, Ashwin Jayaprakash
> <ashwin.jayaprakash at gmail.com> wrote:
> > This is an old email, but I found out today that there were
> still strange
> > problems on JDK 6_18 related to this coreThread count.
> >
> > Even with coreThreads=maxThreads, some pools would never start and would
> > never process any job. The solution required calling
> > prestartAllCoreThreads(). I will investigate more later, but
> for anyone else
> > facing this problem it will help. Calling just
> prestartCoreThread() might
> > also work, but I haven't tried.
> >
> > Ashwin.
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Mon May 10 10:30:01 2010
From: aph at redhat.com (Andrew Haley)
Date: Mon, 10 May 2010 15:30:01 +0100
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
Message-ID: <4BE81869.2060704@redhat.com>

Consider a set of identical threads that occasionally need to acquire
a lock.  Contention for this lock is low, because the ratio of
unlocked to locked work is high, 10000:1.

  public void run()
  {
    while (!Main.done)
      {
        mylock.lock();
        try {
          doLockedWork();
        }
        finally {
          mylock.unlock();
        }
        doUnlockedWork();
        counter++;
      }

I've observed that when a fair ReentrantLock is used, the CPU usage
across all cores becomes very low, and much of the time cores are
idling.  This seems to be particularly true on a multi-CPU machine,
whereas single-CPU machines aren't so bad.

What seems to happen is that threads waiting to acquire the lock "pile
up" and are descheduled, and the number of threads doing work falls
dramatically.

I added a logging facility inside park and unpark which tracks when
threads are sleeping waiting for pthread_cond_wait(), when they are
unparked by calling pthread_cond_signal(), and when they actually
return from pthread_cond_wait().  On an 8 core machine with 32
threads, the process eventually stabilizes with, on average, only a
few threads running at any given time.

This is a typical sample of the behaviour of a fair ReentrantLock
after the program has been running for a while.  "r" is the number of
threads running, "s" the number of threads sleeping, and "a" the
number of threads that have been unparked but have not yet returned
from pthread_cond_wait():

pid 29978: 2   r:5, s:28, a:0
pid 29986: 1   r:5, s:27, a:1
pid 29986: 2   r:6, s:27, a:0
pid 29987: 0   r:5, s:28, a:0
pid 29993: 1   r:5, s:27, a:1
pid 29995: 0   r:4, s:28, a:1
pid 29993: 2   r:5, s:28, a:0
pid 29974: 1   r:5, s:27, a:1
pid 29981: 0   r:4, s:28, a:1
pid 29978: 0   r:3, s:29, a:1
pid 29986: 0   r:2, s:30, a:1
pid 29993: 0   r:1, s:31, a:1
pid 29974: 2   r:2, s:31, a:0
pid 29989: 1   r:2, s:30, a:1
pid 29974: 0   r:1, s:31, a:1
pid 29989: 2   r:2, s:31, a:0
pid 29996: 1   r:2, s:30, a:1
pid 29996: 2   r:3, s:30, a:0
pid 29984: 1   r:3, s:29, a:1

As you can see, the number of threads running at any given time is
low, and the machine is on average only about 50% loaded.  Most
threads are sleeping.

With an unfair ReentrantLock, there are no such problems, and the
number of running threads is greater:

pid 32169: 2   r:6, s:27, a:0
pid 32156: 1   r:6, s:26, a:1
pid 32156: 2   r:7, s:26, a:0
pid 32180: 1   r:7, s:25, a:1
pid 32180: 2   r:8, s:25, a:0
pid 32164: 1   r:8, s:24, a:1
pid 32180: 0   r:7, s:25, a:1
pid 32164: 2   r:8, s:25, a:0
pid 32159: 1   r:8, s:24, a:1
pid 32159: 2   r:9, s:24, a:0
pid 32150: 1   r:9, s:23, a:1
pid 32169: 0   r:8, s:24, a:1
pid 32172: 0   r:7, s:25, a:1
pid 32150: 2   r:8, s:25, a:0
pid 32155: 1   r:8, s:24, a:1

This machine has 8 cores, so this load is sufficient to use almost
100% CPU.

Does anyone have any idea why a fair ReentrantLock should result in
such low CPU usage?  This pattern of usage has, apparently, been
observed in more realistic workloads, from which this test case has
been extracted.

To run the example, just run "java Main N" where N is the number of
threads.

I don't think this is the same problem as
http://blogs.sun.com/dave/entry/a_scheduling_and_dispatching_oddity
because tweaking the kernel policies doesn't help.  Also, the kernel
seems from my logs to be waking a thread quickly once it is sent a 
pthread_cond_signal(): there is never more than one thread awakened
but not running.

Andrew.



import java.util.concurrent.locks.*;

class MyThread extends Thread
{
  static int UNLOCKLOOPS = 10000;
  static int LOCKLOOPS = 1;

  public long counter;
  int sum;

  static public ReentrantLock mylock = new ReentrantLock(true);  // shared by all threads

  public void runX()
  {
    while (!Main.done)
      {
	synchronized(mylock)
	  {
	    doLockedWork();
	  }
        doUnlockedWork();
        counter++;
      }
  }
  public void run()
  {
    while (!Main.done)
      {
        mylock.lock();
        try {
          doLockedWork();
        }
        finally {
          mylock.unlock();
        }
        doUnlockedWork();
        counter++;
      }
  }
  void doLockedWork() {
    doComputeWork(LOCKLOOPS); 
  }

  void doUnlockedWork() {
    doComputeWork(UNLOCKLOOPS);
  }

  void doComputeWork(int loopCount) {
    int mysum = sum;
    for (int i=0; i<loopCount; i++) {
      mysum += compute6(mysum);
    }
    sum += mysum;   // write back to field
  }
  


  

  /**
   * Marsaglia xorshift (1, 3, 10)
   */
  public static int compute6(int seed) {
    seed ^= seed << 1;
    seed ^= seed >>> 3;
    seed ^= (seed << 10);
    return seed;
  }


}

public class Main
{
  static volatile boolean done = false;
  static ReentrantLock mylock = new ReentrantLock();  // shared by all threads

  public static Thread[] threads;

  public static void main(String[] args)
    throws Exception
  {
    int threadCount = Integer.parseInt(args[0]);

    MyThread[] threads = new MyThread[threadCount];

    for (int i = 0; i < threads.length; i++)
      {
        threads[i] = new MyThread();
        threads[i].start();
      }

    Thread.sleep(10000);
    done = true;
    
    long total = 0;
    for (int i = 0; i < threads.length; i++)
      {
        total += threads[i].counter;
//      System.out.println(threads[i].counter);
      }
    System.out.println(threadCount + " threads, throughput = " + total);
  }
}

From tim at peierls.net  Mon May 10 12:24:38 2010
From: tim at peierls.net (Tim Peierls)
Date: Mon, 10 May 2010 12:24:38 -0400
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <4BE81869.2060704@redhat.com>
References: <4BE81869.2060704@redhat.com>
Message-ID: <AANLkTinhWD2cRt0Ac6HWsL5jEKXYit3jWwwJS9pafYVg@mail.gmail.com>

Sounds like you observed behavior consistent with the ReentrantLock javadoc.
In particular:

Programs using fair locks accessed by many threads may display lower overall
throughput (i.e., are slower; often much slower) than those using the
default setting, ...


But maybe I missed your point.

--tim

On Mon, May 10, 2010 at 10:30 AM, Andrew Haley <aph at redhat.com> wrote:

> Consider a set of identical threads that occasionally need to acquire
> a lock.  Contention for this lock is low, because the ratio of
> unlocked to locked work is high, 10000:1.
>
>  public void run()
>  {
>    while (!Main.done)
>      {
>        mylock.lock();
>        try {
>          doLockedWork();
>        }
>        finally {
>          mylock.unlock();
>        }
>        doUnlockedWork();
>        counter++;
>      }
>
> I've observed that when a fair ReentrantLock is used, the CPU usage
> across all cores becomes very low, and much of the time cores are
> idling.  This seems to be particularly true on a multi-CPU machine,
> whereas single-CPU machines aren't so bad.
>
> What seems to happen is that threads waiting to acquire the lock "pile
> up" and are descheduled, and the number of threads doing work falls
> dramatically.
>
> I added a logging facility inside park and unpark which tracks when
> threads are sleeping waiting for pthread_cond_wait(), when they are
> unparked by calling pthread_cond_signal(), and when they actually
> return from pthread_cond_wait().  On an 8 core machine with 32
> threads, the process eventually stabilizes with, on average, only a
> few threads running at any given time.
>
> This is a typical sample of the behaviour of a fair ReentrantLock
> after the program has been running for a while.  "r" is the number of
> threads running, "s" the number of threads sleeping, and "a" the
> number of threads that have been unparked but have not yet returned
> from pthread_cond_wait():
>
> pid 29978: 2   r:5, s:28, a:0
> pid 29986: 1   r:5, s:27, a:1
> pid 29986: 2   r:6, s:27, a:0
> pid 29987: 0   r:5, s:28, a:0
> pid 29993: 1   r:5, s:27, a:1
> pid 29995: 0   r:4, s:28, a:1
> pid 29993: 2   r:5, s:28, a:0
> pid 29974: 1   r:5, s:27, a:1
> pid 29981: 0   r:4, s:28, a:1
> pid 29978: 0   r:3, s:29, a:1
> pid 29986: 0   r:2, s:30, a:1
> pid 29993: 0   r:1, s:31, a:1
> pid 29974: 2   r:2, s:31, a:0
> pid 29989: 1   r:2, s:30, a:1
> pid 29974: 0   r:1, s:31, a:1
> pid 29989: 2   r:2, s:31, a:0
> pid 29996: 1   r:2, s:30, a:1
> pid 29996: 2   r:3, s:30, a:0
> pid 29984: 1   r:3, s:29, a:1
>
> As you can see, the number of threads running at any given time is
> low, and the machine is on average only about 50% loaded.  Most
> threads are sleeping.
>
> With an unfair ReentrantLock, there are no such problems, and the
> number of running threads is greater:
>
> pid 32169: 2   r:6, s:27, a:0
> pid 32156: 1   r:6, s:26, a:1
> pid 32156: 2   r:7, s:26, a:0
> pid 32180: 1   r:7, s:25, a:1
> pid 32180: 2   r:8, s:25, a:0
> pid 32164: 1   r:8, s:24, a:1
> pid 32180: 0   r:7, s:25, a:1
> pid 32164: 2   r:8, s:25, a:0
> pid 32159: 1   r:8, s:24, a:1
> pid 32159: 2   r:9, s:24, a:0
> pid 32150: 1   r:9, s:23, a:1
> pid 32169: 0   r:8, s:24, a:1
> pid 32172: 0   r:7, s:25, a:1
> pid 32150: 2   r:8, s:25, a:0
> pid 32155: 1   r:8, s:24, a:1
>
> This machine has 8 cores, so this load is sufficient to use almost
> 100% CPU.
>
> Does anyone have any idea why a fair ReentrantLock should result in
> such low CPU usage?  This pattern of usage has, apparently, been
> observed in more realistic workloads, from which this test case has
> been extracted.
>
> To run the example, just run "java Main N" where N is the number of
> threads.
>
> I don't think this is the same problem as
> http://blogs.sun.com/dave/entry/a_scheduling_and_dispatching_oddity
> because tweaking the kernel policies doesn't help.  Also, the kernel
> seems from my logs to be waking a thread quickly once it is sent a
> pthread_cond_signal(): there is never more than one thread awakened
> but not running.
>
> Andrew.
>
>
>
> import java.util.concurrent.locks.*;
>
> class MyThread extends Thread
> {
>  static int UNLOCKLOOPS = 10000;
>  static int LOCKLOOPS = 1;
>
>  public long counter;
>  int sum;
>
>  static public ReentrantLock mylock = new ReentrantLock(true);  // shared
> by all threads
>
>  public void runX()
>  {
>    while (!Main.done)
>      {
>        synchronized(mylock)
>          {
>            doLockedWork();
>          }
>        doUnlockedWork();
>        counter++;
>      }
>  }
>  public void run()
>  {
>    while (!Main.done)
>      {
>        mylock.lock();
>        try {
>          doLockedWork();
>        }
>        finally {
>          mylock.unlock();
>        }
>        doUnlockedWork();
>        counter++;
>      }
>  }
>  void doLockedWork() {
>    doComputeWork(LOCKLOOPS);
>  }
>
>  void doUnlockedWork() {
>    doComputeWork(UNLOCKLOOPS);
>  }
>
>  void doComputeWork(int loopCount) {
>    int mysum = sum;
>    for (int i=0; i<loopCount; i++) {
>      mysum += compute6(mysum);
>    }
>    sum += mysum;   // write back to field
>  }
>
>
>
>
>
>  /**
>   * Marsaglia xorshift (1, 3, 10)
>   */
>  public static int compute6(int seed) {
>    seed ^= seed << 1;
>    seed ^= seed >>> 3;
>    seed ^= (seed << 10);
>    return seed;
>  }
>
>
> }
>
> public class Main
> {
>  static volatile boolean done = false;
>  static ReentrantLock mylock = new ReentrantLock();  // shared by all
> threads
>
>  public static Thread[] threads;
>
>  public static void main(String[] args)
>    throws Exception
>  {
>    int threadCount = Integer.parseInt(args[0]);
>
>    MyThread[] threads = new MyThread[threadCount];
>
>    for (int i = 0; i < threads.length; i++)
>      {
>        threads[i] = new MyThread();
>        threads[i].start();
>      }
>
>    Thread.sleep(10000);
>    done = true;
>
>    long total = 0;
>    for (int i = 0; i < threads.length; i++)
>      {
>        total += threads[i].counter;
> //      System.out.println(threads[i].counter);
>      }
>    System.out.println(threadCount + " threads, throughput = " + total);
>  }
> }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100510/a00f97df/attachment.html>

From aph at redhat.com  Mon May 10 12:36:28 2010
From: aph at redhat.com (Andrew Haley)
Date: Mon, 10 May 2010 17:36:28 +0100
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <AANLkTinhWD2cRt0Ac6HWsL5jEKXYit3jWwwJS9pafYVg@mail.gmail.com>
References: <4BE81869.2060704@redhat.com>
	<AANLkTinhWD2cRt0Ac6HWsL5jEKXYit3jWwwJS9pafYVg@mail.gmail.com>
Message-ID: <4BE8360C.8040606@redhat.com>

On 05/10/2010 05:24 PM, Tim Peierls wrote:
> Sounds like you observed behavior consistent with the ReentrantLock javadoc.
> In particular:
> 
> Programs using fair locks accessed by many threads may display lower overall
> throughput (i.e., are slower; often much slower) than those using the
> default setting, ...

Perhaps so.  It's hard to tell from that javadoc exactly what is
meant: I thought, from reading that, that "slower; often much slower"
referred to slow operation with high CPU loads when locking rather
than, as we have here, CPUs being starved of work.  But in any case,
given the fact that locking is so rare, I found this result a little
bit surprising.

I'm asking here because I want to know (from the horse's mouth, as it
were) whether this is exactly what people would expect of such a lock.
And if it is, perhaps I can add a litle to that javadoc.

Andrew.


> On Mon, May 10, 2010 at 10:30 AM, Andrew Haley <aph at redhat.com> wrote:
> 
>> Consider a set of identical threads that occasionally need to acquire
>> a lock.  Contention for this lock is low, because the ratio of
>> unlocked to locked work is high, 10000:1.
>>
>>  public void run()
>>  {
>>    while (!Main.done)
>>      {
>>        mylock.lock();
>>        try {
>>          doLockedWork();
>>        }
>>        finally {
>>          mylock.unlock();
>>        }
>>        doUnlockedWork();
>>        counter++;
>>      }
>>
>> I've observed that when a fair ReentrantLock is used, the CPU usage
>> across all cores becomes very low, and much of the time cores are
>> idling.  This seems to be particularly true on a multi-CPU machine,
>> whereas single-CPU machines aren't so bad.
>>
>> What seems to happen is that threads waiting to acquire the lock "pile
>> up" and are descheduled, and the number of threads doing work falls
>> dramatically.
>>
>> I added a logging facility inside park and unpark which tracks when
>> threads are sleeping waiting for pthread_cond_wait(), when they are
>> unparked by calling pthread_cond_signal(), and when they actually
>> return from pthread_cond_wait().  On an 8 core machine with 32
>> threads, the process eventually stabilizes with, on average, only a
>> few threads running at any given time.
>>
>> This is a typical sample of the behaviour of a fair ReentrantLock
>> after the program has been running for a while.  "r" is the number of
>> threads running, "s" the number of threads sleeping, and "a" the
>> number of threads that have been unparked but have not yet returned
>> from pthread_cond_wait():
>>
>> pid 29978: 2   r:5, s:28, a:0
>> pid 29986: 1   r:5, s:27, a:1
>> pid 29986: 2   r:6, s:27, a:0
>> pid 29987: 0   r:5, s:28, a:0
>> pid 29993: 1   r:5, s:27, a:1
>> pid 29995: 0   r:4, s:28, a:1
>> pid 29993: 2   r:5, s:28, a:0
>> pid 29974: 1   r:5, s:27, a:1
>> pid 29981: 0   r:4, s:28, a:1
>> pid 29978: 0   r:3, s:29, a:1
>> pid 29986: 0   r:2, s:30, a:1
>> pid 29993: 0   r:1, s:31, a:1
>> pid 29974: 2   r:2, s:31, a:0
>> pid 29989: 1   r:2, s:30, a:1
>> pid 29974: 0   r:1, s:31, a:1
>> pid 29989: 2   r:2, s:31, a:0
>> pid 29996: 1   r:2, s:30, a:1
>> pid 29996: 2   r:3, s:30, a:0
>> pid 29984: 1   r:3, s:29, a:1
>>
>> As you can see, the number of threads running at any given time is
>> low, and the machine is on average only about 50% loaded.  Most
>> threads are sleeping.
>>
>> With an unfair ReentrantLock, there are no such problems, and the
>> number of running threads is greater:
>>
>> pid 32169: 2   r:6, s:27, a:0
>> pid 32156: 1   r:6, s:26, a:1
>> pid 32156: 2   r:7, s:26, a:0
>> pid 32180: 1   r:7, s:25, a:1
>> pid 32180: 2   r:8, s:25, a:0
>> pid 32164: 1   r:8, s:24, a:1
>> pid 32180: 0   r:7, s:25, a:1
>> pid 32164: 2   r:8, s:25, a:0
>> pid 32159: 1   r:8, s:24, a:1
>> pid 32159: 2   r:9, s:24, a:0
>> pid 32150: 1   r:9, s:23, a:1
>> pid 32169: 0   r:8, s:24, a:1
>> pid 32172: 0   r:7, s:25, a:1
>> pid 32150: 2   r:8, s:25, a:0
>> pid 32155: 1   r:8, s:24, a:1
>>
>> This machine has 8 cores, so this load is sufficient to use almost
>> 100% CPU.
>>
>> Does anyone have any idea why a fair ReentrantLock should result in
>> such low CPU usage?  This pattern of usage has, apparently, been
>> observed in more realistic workloads, from which this test case has
>> been extracted.
>>
>> To run the example, just run "java Main N" where N is the number of
>> threads.
>>
>> I don't think this is the same problem as
>> http://blogs.sun.com/dave/entry/a_scheduling_and_dispatching_oddity
>> because tweaking the kernel policies doesn't help.  Also, the kernel
>> seems from my logs to be waking a thread quickly once it is sent a
>> pthread_cond_signal(): there is never more than one thread awakened
>> but not running.
>>
>> Andrew.
>>
>>
>>
>> import java.util.concurrent.locks.*;
>>
>> class MyThread extends Thread
>> {
>>  static int UNLOCKLOOPS = 10000;
>>  static int LOCKLOOPS = 1;
>>
>>  public long counter;
>>  int sum;
>>
>>  static public ReentrantLock mylock = new ReentrantLock(true);  // shared
>> by all threads
>>
>>  public void runX()
>>  {
>>    while (!Main.done)
>>      {
>>        synchronized(mylock)
>>          {
>>            doLockedWork();
>>          }
>>        doUnlockedWork();
>>        counter++;
>>      }
>>  }
>>  public void run()
>>  {
>>    while (!Main.done)
>>      {
>>        mylock.lock();
>>        try {
>>          doLockedWork();
>>        }
>>        finally {
>>          mylock.unlock();
>>        }
>>        doUnlockedWork();
>>        counter++;
>>      }
>>  }
>>  void doLockedWork() {
>>    doComputeWork(LOCKLOOPS);
>>  }
>>
>>  void doUnlockedWork() {
>>    doComputeWork(UNLOCKLOOPS);
>>  }
>>
>>  void doComputeWork(int loopCount) {
>>    int mysum = sum;
>>    for (int i=0; i<loopCount; i++) {
>>      mysum += compute6(mysum);
>>    }
>>    sum += mysum;   // write back to field
>>  }
>>
>>
>>
>>
>>
>>  /**
>>   * Marsaglia xorshift (1, 3, 10)
>>   */
>>  public static int compute6(int seed) {
>>    seed ^= seed << 1;
>>    seed ^= seed >>> 3;
>>    seed ^= (seed << 10);
>>    return seed;
>>  }
>>
>>
>> }
>>
>> public class Main
>> {
>>  static volatile boolean done = false;
>>  static ReentrantLock mylock = new ReentrantLock();  // shared by all
>> threads
>>
>>  public static Thread[] threads;
>>
>>  public static void main(String[] args)
>>    throws Exception
>>  {
>>    int threadCount = Integer.parseInt(args[0]);
>>
>>    MyThread[] threads = new MyThread[threadCount];
>>
>>    for (int i = 0; i < threads.length; i++)
>>      {
>>        threads[i] = new MyThread();
>>        threads[i].start();
>>      }
>>
>>    Thread.sleep(10000);
>>    done = true;
>>
>>    long total = 0;
>>    for (int i = 0; i < threads.length; i++)
>>      {
>>        total += threads[i].counter;
>> //      System.out.println(threads[i].counter);
>>      }
>>    System.out.println(threadCount + " threads, throughput = " + total);
>>  }
>> }
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> 


From dl at cs.oswego.edu  Mon May 10 12:48:47 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 10 May 2010 12:48:47 -0400
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <4BE81869.2060704@redhat.com>
References: <4BE81869.2060704@redhat.com>
Message-ID: <4BE838EF.5030506@cs.oswego.edu>

On 05/10/10 10:30, Andrew Haley wrote:
> Does anyone have any idea why a fair ReentrantLock should result in
> such low CPU usage?  This pattern of usage has, apparently, been
> observed in more realistic workloads, from which this test case has
> been extracted.

Because blocking and unblocking a thread can be 100X more
expensive than just performing a CAS.

Under fair locks, even if there are on average plenty of
"spaces" where the lock is available, a few collisions
will tend to lead to sustained phases where the lock
is awaiting the first waiter to wake up, causing others
to block until it does. So the entire program can
only run at the rate it takes to block+unblock a thread
(a form of "convoying").

For non-fair locks, other threads are allowed to "barge"
in during these periods where the lock is not actually
held, and grab the lock before head of queue wakes up.
This tends to happen a lot, making them much faster.

-Doug




From martinrb at google.com  Mon May 10 14:46:06 2010
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 10 May 2010 11:46:06 -0700
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <4BE838EF.5030506@cs.oswego.edu>
References: <4BE81869.2060704@redhat.com> <4BE838EF.5030506@cs.oswego.edu>
Message-ID: <AANLkTinrdNkS5F7lRsPXM3qgTSbT41SjPIQX6dMlwren@mail.gmail.com>

It's hard to build a mental model of the costs of
concurrent programming operations:

- a CAS or volatile write may be 100x more expensive than a non-volatile write
- context switch may be 100x more expensive than CAS (measuring CPU time).
- On top of the CPU costs of parking, the parked thread will not get a chance to
run again until the OS gets around to reschedule it, which is probably
1 or 10 ms
on Linux (HZ).
- With fair locks, it is not only the parked thread that will not get
a chance to
run again for a scheduler quantum,
but all of the other threads that tried to acquire during the parked period.
Which will tend to limit throughput on Linux to HZ lock acquisitions per second.

Perhaps with fair locks, we should try harder to spin for a while
before blocking,
because the penalty for blocking is so very high.  But that's a big
engineering project.

Martin

On Mon, May 10, 2010 at 09:48, Doug Lea <dl at cs.oswego.edu> wrote:
> On 05/10/10 10:30, Andrew Haley wrote:
>>
>> Does anyone have any idea why a fair ReentrantLock should result in
>> such low CPU usage? ?This pattern of usage has, apparently, been
>> observed in more realistic workloads, from which this test case has
>> been extracted.
>
> Because blocking and unblocking a thread can be 100X more
> expensive than just performing a CAS.
>
> Under fair locks, even if there are on average plenty of
> "spaces" where the lock is available, a few collisions
> will tend to lead to sustained phases where the lock
> is awaiting the first waiter to wake up, causing others
> to block until it does. So the entire program can
> only run at the rate it takes to block+unblock a thread
> (a form of "convoying").
>
> For non-fair locks, other threads are allowed to "barge"
> in during these periods where the lock is not actually
> held, and grab the lock before head of queue wakes up.
> This tends to happen a lot, making them much faster.
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Mon May 10 18:42:54 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 11 May 2010 08:42:54 +1000
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <4BE8360C.8040606@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEFHIGAA.davidcholmes@aapt.net.au>

Andrew Haley writes on Tuesday, 11 May 2010 2:36 AM:
> Perhaps so.  It's hard to tell from that javadoc exactly what is
> meant: I thought, from reading that, that "slower; often much slower"
> referred to slow operation with high CPU loads when locking rather
> than, as we have here, CPUs being starved of work.  But in any case,
> given the fact that locking is so rare, I found this result a little
> bit surprising.

Just one further comment. Locking may be "rare" from the perspective of
locked-work:unlocked-work, but it would seem that your threads are executing
in-phase, and so contention is actually high.

David Holmes

> I'm asking here because I want to know (from the horse's mouth, as it
> were) whether this is exactly what people would expect of such a lock.
> And if it is, perhaps I can add a litle to that javadoc.
>
> Andrew.
>
>
> > On Mon, May 10, 2010 at 10:30 AM, Andrew Haley <aph at redhat.com> wrote:
> >
> >> Consider a set of identical threads that occasionally need to acquire
> >> a lock.  Contention for this lock is low, because the ratio of
> >> unlocked to locked work is high, 10000:1.
> >>
> >>  public void run()
> >>  {
> >>    while (!Main.done)
> >>      {
> >>        mylock.lock();
> >>        try {
> >>          doLockedWork();
> >>        }
> >>        finally {
> >>          mylock.unlock();
> >>        }
> >>        doUnlockedWork();
> >>        counter++;
> >>      }
> >>
> >> I've observed that when a fair ReentrantLock is used, the CPU usage
> >> across all cores becomes very low, and much of the time cores are
> >> idling.  This seems to be particularly true on a multi-CPU machine,
> >> whereas single-CPU machines aren't so bad.
> >>
> >> What seems to happen is that threads waiting to acquire the lock "pile
> >> up" and are descheduled, and the number of threads doing work falls
> >> dramatically.
> >>
> >> I added a logging facility inside park and unpark which tracks when
> >> threads are sleeping waiting for pthread_cond_wait(), when they are
> >> unparked by calling pthread_cond_signal(), and when they actually
> >> return from pthread_cond_wait().  On an 8 core machine with 32
> >> threads, the process eventually stabilizes with, on average, only a
> >> few threads running at any given time.
> >>
> >> This is a typical sample of the behaviour of a fair ReentrantLock
> >> after the program has been running for a while.  "r" is the number of
> >> threads running, "s" the number of threads sleeping, and "a" the
> >> number of threads that have been unparked but have not yet returned
> >> from pthread_cond_wait():
> >>
> >> pid 29978: 2   r:5, s:28, a:0
> >> pid 29986: 1   r:5, s:27, a:1
> >> pid 29986: 2   r:6, s:27, a:0
> >> pid 29987: 0   r:5, s:28, a:0
> >> pid 29993: 1   r:5, s:27, a:1
> >> pid 29995: 0   r:4, s:28, a:1
> >> pid 29993: 2   r:5, s:28, a:0
> >> pid 29974: 1   r:5, s:27, a:1
> >> pid 29981: 0   r:4, s:28, a:1
> >> pid 29978: 0   r:3, s:29, a:1
> >> pid 29986: 0   r:2, s:30, a:1
> >> pid 29993: 0   r:1, s:31, a:1
> >> pid 29974: 2   r:2, s:31, a:0
> >> pid 29989: 1   r:2, s:30, a:1
> >> pid 29974: 0   r:1, s:31, a:1
> >> pid 29989: 2   r:2, s:31, a:0
> >> pid 29996: 1   r:2, s:30, a:1
> >> pid 29996: 2   r:3, s:30, a:0
> >> pid 29984: 1   r:3, s:29, a:1
> >>
> >> As you can see, the number of threads running at any given time is
> >> low, and the machine is on average only about 50% loaded.  Most
> >> threads are sleeping.
> >>
> >> With an unfair ReentrantLock, there are no such problems, and the
> >> number of running threads is greater:
> >>
> >> pid 32169: 2   r:6, s:27, a:0
> >> pid 32156: 1   r:6, s:26, a:1
> >> pid 32156: 2   r:7, s:26, a:0
> >> pid 32180: 1   r:7, s:25, a:1
> >> pid 32180: 2   r:8, s:25, a:0
> >> pid 32164: 1   r:8, s:24, a:1
> >> pid 32180: 0   r:7, s:25, a:1
> >> pid 32164: 2   r:8, s:25, a:0
> >> pid 32159: 1   r:8, s:24, a:1
> >> pid 32159: 2   r:9, s:24, a:0
> >> pid 32150: 1   r:9, s:23, a:1
> >> pid 32169: 0   r:8, s:24, a:1
> >> pid 32172: 0   r:7, s:25, a:1
> >> pid 32150: 2   r:8, s:25, a:0
> >> pid 32155: 1   r:8, s:24, a:1
> >>
> >> This machine has 8 cores, so this load is sufficient to use almost
> >> 100% CPU.
> >>
> >> Does anyone have any idea why a fair ReentrantLock should result in
> >> such low CPU usage?  This pattern of usage has, apparently, been
> >> observed in more realistic workloads, from which this test case has
> >> been extracted.
> >>
> >> To run the example, just run "java Main N" where N is the number of
> >> threads.
> >>
> >> I don't think this is the same problem as
> >> http://blogs.sun.com/dave/entry/a_scheduling_and_dispatching_oddity
> >> because tweaking the kernel policies doesn't help.  Also, the kernel
> >> seems from my logs to be waking a thread quickly once it is sent a
> >> pthread_cond_signal(): there is never more than one thread awakened
> >> but not running.
> >>
> >> Andrew.
> >>
> >>
> >>
> >> import java.util.concurrent.locks.*;
> >>
> >> class MyThread extends Thread
> >> {
> >>  static int UNLOCKLOOPS = 10000;
> >>  static int LOCKLOOPS = 1;
> >>
> >>  public long counter;
> >>  int sum;
> >>
> >>  static public ReentrantLock mylock = new ReentrantLock(true);
>  // shared
> >> by all threads
> >>
> >>  public void runX()
> >>  {
> >>    while (!Main.done)
> >>      {
> >>        synchronized(mylock)
> >>          {
> >>            doLockedWork();
> >>          }
> >>        doUnlockedWork();
> >>        counter++;
> >>      }
> >>  }
> >>  public void run()
> >>  {
> >>    while (!Main.done)
> >>      {
> >>        mylock.lock();
> >>        try {
> >>          doLockedWork();
> >>        }
> >>        finally {
> >>          mylock.unlock();
> >>        }
> >>        doUnlockedWork();
> >>        counter++;
> >>      }
> >>  }
> >>  void doLockedWork() {
> >>    doComputeWork(LOCKLOOPS);
> >>  }
> >>
> >>  void doUnlockedWork() {
> >>    doComputeWork(UNLOCKLOOPS);
> >>  }
> >>
> >>  void doComputeWork(int loopCount) {
> >>    int mysum = sum;
> >>    for (int i=0; i<loopCount; i++) {
> >>      mysum += compute6(mysum);
> >>    }
> >>    sum += mysum;   // write back to field
> >>  }
> >>
> >>
> >>
> >>
> >>
> >>  /**
> >>   * Marsaglia xorshift (1, 3, 10)
> >>   */
> >>  public static int compute6(int seed) {
> >>    seed ^= seed << 1;
> >>    seed ^= seed >>> 3;
> >>    seed ^= (seed << 10);
> >>    return seed;
> >>  }
> >>
> >>
> >> }
> >>
> >> public class Main
> >> {
> >>  static volatile boolean done = false;
> >>  static ReentrantLock mylock = new ReentrantLock();  // shared by all
> >> threads
> >>
> >>  public static Thread[] threads;
> >>
> >>  public static void main(String[] args)
> >>    throws Exception
> >>  {
> >>    int threadCount = Integer.parseInt(args[0]);
> >>
> >>    MyThread[] threads = new MyThread[threadCount];
> >>
> >>    for (int i = 0; i < threads.length; i++)
> >>      {
> >>        threads[i] = new MyThread();
> >>        threads[i].start();
> >>      }
> >>
> >>    Thread.sleep(10000);
> >>    done = true;
> >>
> >>    long total = 0;
> >>    for (int i = 0; i < threads.length; i++)
> >>      {
> >>        total += threads[i].counter;
> >> //      System.out.println(threads[i].counter);
> >>      }
> >>    System.out.println(threadCount + " threads, throughput = " + total);
> >>  }
> >> }
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Tue May 11 04:31:25 2010
From: aph at redhat.com (Andrew Haley)
Date: Tue, 11 May 2010 09:31:25 +0100
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEFHIGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEFHIGAA.davidcholmes@aapt.net.au>
Message-ID: <4BE915DD.8060705@redhat.com>

On 05/10/2010 11:42 PM, David Holmes wrote:
> Andrew Haley writes on Tuesday, 11 May 2010 2:36 AM:
>> Perhaps so.  It's hard to tell from that javadoc exactly what is
>> meant: I thought, from reading that, that "slower; often much slower"
>> referred to slow operation with high CPU loads when locking rather
>> than, as we have here, CPUs being starved of work.  But in any case,
>> given the fact that locking is so rare, I found this result a little
>> bit surprising.
> 
> Just one further comment. Locking may be "rare" from the perspective of
> locked-work:unlocked-work, but it would seem that your threads are executing
> in-phase, and so contention is actually high.

So it seems.  They don't start in phase, but because of the convoying
effect they eventually move into lock-step.  I wonder how often this
happens  the real world applications.

Andrew.


From crazybob at crazybob.org  Tue May 11 09:44:29 2010
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 11 May 2010 08:44:29 -0500
Subject: [concurrency-interest] some MapMaker design decisions
In-Reply-To: <AANLkTimtVJjfBRguL_OpOmLtqbq6xYwGcmhGZ6GB6KmD@mail.gmail.com>
References: <AANLkTimtVJjfBRguL_OpOmLtqbq6xYwGcmhGZ6GB6KmD@mail.gmail.com>
Message-ID: <AANLkTin4med-iClZ-K14XzWS3jeV7mvYO4TlQ9IQmRXa@mail.gmail.com>

Charles,

See the thread you started "MapMaker listener and removal notification." Ben
is already doing the right thing:

"Yep, that's exactly how my CL implements it, with an internal listener
queue per segment, a Receiver passed to makeXXX(), and invokation on the
clients thread outside of any locks on a mutate."

On Mon, May 10, 2010 at 10:01 PM, Charles Fry <fry at google.com> wrote:

> a) Should eviction notifications be callbacks, or should we simply add
> evicted entries to a queue that users could then poll? Callback
> notifications definitely seem conceptually simpler from the users
> perspective, but they do require the execution of the callback code.
> Using a queue makes the job of performing eviction simpler, but then
> is more complicated for users to integrate with.
>

Queue inside segment, call back in client threads, outside of locks. Best of
both worlds.


> b) If eviction notifications are made using callbacks, where should
> the callback be executed? We could execute them on user threads when
> they make other calls on MapMaker maps, but that implies that
> exceptions and blocking within callbacks could then impact threads
> performing other operations on the map. The other obvious alternative
> would be to require users to provide an ExecutorService for executing
> callbacks, but that feels a bit overkill when all you really want is
> an eviction notification.
>

A user-provided ExecutorService is not viable. The user could just implement
execute() to execute the task in the task immediately in the current thread.


> c) Is it worth doing removal notifications, that include a callback
> when remove is called manually, or is it sufficient to limit
> notifications to eviction events?
>

This was also discussed in the thread. The callback should only be invoked
for automatic evictions. This enables the user to differentiate between
manual and automatic removals. That's harder if you invoke the callback in
both cases.


> d) While there are plenty of algorithms for concurrent
> recency/frequency based eviction policies, it is also simple to
> maintain a mutation queue that records a memento of each modification
> operation, occasionally locking and applying them on a single thread.
> The overhead of such a mechanism is trivial, and it allows the exact
> application of non-concurrent eviction algorithms. It has the minor
> caveat of requiring care to be taken with elements that are removed
> from the cache while one of their mutation mementos is still enqueued.
> Are there other concerns to be aware of, or is this a reasonable
> approach?
>

I still plan to test the LRU algorithm Josh, Jesse and I came up with. It's
incredibly light on memory, CPU and locking. We can experiment with other
algorithms and consider them if they significantly increase retention in
real world code without too much overhead.


> e) With respect to size eviction, our initial thought was to put a
> hard limit on the size of each segment. This has the advantage of
> being very simple conceptually, and the notable disadvantage of
> applying the eviction algorithm at the segment level instead of
> globally. If a mutation queue is used to manage evictions then it can
> very simply be extended to apply them globally instead of per-segment.
> Are there other major considerations to be aware of here? Does it
> sound reasonable to make global eviction decisions?
>

We shouldn't introduce a map-wide lock or CAS. Heavy CAS contention across
cores can actually be slower than grabbing a lock.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100511/5ead3456/attachment.html>

From fry at google.com  Tue May 11 14:52:11 2010
From: fry at google.com (Charles Fry)
Date: Tue, 11 May 2010 14:52:11 -0400
Subject: [concurrency-interest] some MapMaker design decisions
In-Reply-To: <AANLkTimtVJjfBRguL_OpOmLtqbq6xYwGcmhGZ6GB6KmD@mail.gmail.com>
References: <AANLkTimtVJjfBRguL_OpOmLtqbq6xYwGcmhGZ6GB6KmD@mail.gmail.com>
Message-ID: <AANLkTin1JZve8TzaxTpXCIy9bz3eyfubQKs-haT0OKdJ@mail.gmail.com>

[resending, since the original missed the list]

We are currently in the process of implementing several new features
in  com.google.common.collect.MapMaker. We've had plenty of internal
discussions about them, and last week Josh Bloch suggested that we
raise the issues on concurrency-interest to get additional feedback.

One of the new features we're adding is eviction notification. This
will allow users to learn of eviction events that occur due to
expiration, garbage collection of weak/soft keys/values, or due to
size eviction. The other new feature is size eviction, whereby a
maximum size can be specified, with entries being automatically
evicted when the map grows too large.

Here are some of the design decisions we've been discussing. I'll try
to keep this initial summary on the brief end, but would be more than
happy to provide additional details as desired. We'd love feedback on
communal wisdom and best practices in these areas.

a) Should eviction notifications be callbacks, or should we simply add
evicted entries to a queue that users could then poll? Callback
notifications definitely seem conceptually simpler from the users
perspective, but they do require the execution of the callback code.
Using a queue makes the job of performing eviction simpler, but then
is more complicated for users to integrate with.

b) If eviction notifications are made using callbacks, where should
the callback be executed? We could execute them on user threads when
they make other calls on MapMaker maps, but that implies that
exceptions and blocking within callbacks could then impact threads
performing other operations on the map. The other obvious alternative
would be to require users to provide an ExecutorService for executing
callbacks, but that feels a bit overkill when all you really want is
an eviction notification.

c) Is it worth doing removal notifications, that include a callback
when remove is called manually, or is it sufficient to limit
notifications to eviction events?

d) While there are plenty of algorithms for concurrent
recency/frequency based eviction policies, it is also simple to
maintain a mutation queue that records a memento of each modification
operation, occasionally locking and applying them on a single thread.
The overhead of such a mechanism is trivial, and it allows the exact
application of non-concurrent eviction algorithms. It has the minor
caveat of requiring care to be taken with elements that are removed
from the cache while one of their mutation mementos is still enqueued.
Are there other concerns to be aware of, or is this a reasonable
approach?

e) With respect to size eviction, our initial thought was to put a
hard limit on the size of each segment. This has the advantage of
being very simple conceptually, and the notable disadvantage of
applying the eviction algorithm at the segment level instead of
globally. If a mutation queue is used to manage evictions then it can
very simply be extended to apply them globally instead of per-segment.
Are there other major considerations to be aware of here? Does it
sound reasonable to make global eviction decisions?

Ben has already implemented many of these ideas in
http://code.google.com/p/concurrentlinkedhashmap/ and we have pending
internal changes in MapMaker.  We've discussed all issues in great
detail, but would welcome any external feedback on the specific issues
raised here, or other potentially relevant issues we should be
thinking about.

thanks,
Charles

From jnewsham at referentia.com  Tue May 11 22:19:04 2010
From: jnewsham at referentia.com (Jim Newsham)
Date: Tue, 11 May 2010 16:19:04 -1000
Subject: [concurrency-interest] some MapMaker design decisions
In-Reply-To: <AANLkTin1JZve8TzaxTpXCIy9bz3eyfubQKs-haT0OKdJ@mail.gmail.com>
References: <AANLkTimtVJjfBRguL_OpOmLtqbq6xYwGcmhGZ6GB6KmD@mail.gmail.com>
	<AANLkTin1JZve8TzaxTpXCIy9bz3eyfubQKs-haT0OKdJ@mail.gmail.com>
Message-ID: <4BEA1018.30106@referentia.com>

On 5/11/2010 8:52 AM, Charles Fry wrote:
> b) If eviction notifications are made using callbacks, where should
> the callback be executed? We could execute them on user threads when
> they make other calls on MapMaker maps, but that implies that
> exceptions and blocking within callbacks could then impact threads
> performing other operations on the map. The other obvious alternative
> would be to require users to provide an ExecutorService for executing
> callbacks, but that feels a bit overkill when all you really want is
> an eviction notification.
>    

We've occasionally done "both".  In our application, we often have the 
desire for the listener to be able to specify how events should be 
delivered to it (primarily, which thread).  In such cases we extend the 
conventional Java listener approach to also provide an optional Executor 
(not ExecutorService; note that Executor interface is much simpler and 
less burdensome to implement) parameter as follows:

addFooListener(FooListener listener);

addFooListener(FooListener listener, Executor executor);

We have a few executors that we like to use regularly, including a 
SerialExecutor, EdtExecutor, etc.

Jim

From gregg at cytetech.com  Wed May 12 14:54:40 2010
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 12 May 2010 13:54:40 -0500
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <4BE915DD.8060705@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCCEFHIGAA.davidcholmes@aapt.net.au>
	<4BE915DD.8060705@redhat.com>
Message-ID: <4BEAF970.4060407@cytetech.com>

Andrew Haley wrote:
> On 05/10/2010 11:42 PM, David Holmes wrote:
>> Andrew Haley writes on Tuesday, 11 May 2010 2:36 AM:
>>> Perhaps so.  It's hard to tell from that javadoc exactly what is
>>> meant: I thought, from reading that, that "slower; often much slower"
>>> referred to slow operation with high CPU loads when locking rather
>>> than, as we have here, CPUs being starved of work.  But in any case,
>>> given the fact that locking is so rare, I found this result a little
>>> bit surprising.
>> Just one further comment. Locking may be "rare" from the perspective of
>> locked-work:unlocked-work, but it would seem that your threads are executing
>> in-phase, and so contention is actually high.
> 
> So it seems.  They don't start in phase, but because of the convoying
> effect they eventually move into lock-step.  I wonder how often this
> happens  the real world applications.

This happens anytime that an "event" is slower than other events.  On slower 
CPUs and systems with random delays associated with Disk I/O, network activity 
and other places where randomization occurs, these types of things can be 
remedied.  But by and large, there is not a single multi-threaded application 
which won't show this behavior in some form when mostly CPU is involved with 
some form of rendezvous point that takes much longer to execute.

Think about this as you would a highway with tollgates every 5 miles.  With 
significant traffic through the toll gates, eventually backups start, and never 
really disappear until queuing theory things kick in such that the departure 
rate finally outstrips the arrival rate.

One thing you can try, is to use random "sleeps" to distribute the "position" of 
the threads over the time interval between "gates".  Find out what the average 
time is, between gates.  Then do something like

if( contendedLastLockTooLong ) {
	Thread.sleep( (long)(Math.random(gateTime/numberOfThreads)+1) );
}

to make the thread back off it's position relative to the others in the 
"timeline" of work through the gates.

Gregg Wonderly

From martinrb at google.com  Thu May 13 02:37:23 2010
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 12 May 2010 23:37:23 -0700
Subject: [concurrency-interest] Low cpu usage with fair ReentrantLock
In-Reply-To: <4BE915DD.8060705@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCCEFHIGAA.davidcholmes@aapt.net.au>
	<4BE915DD.8060705@redhat.com>
Message-ID: <AANLkTimPrmdcYLvdfWx_7zr3fIv1ZuSaQg7mWrhV7NMP@mail.gmail.com>

On Tue, May 11, 2010 at 01:31, Andrew Haley <aph at redhat.com> wrote:
> On 05/10/2010 11:42 PM, David Holmes wrote:
>> Andrew Haley writes on Tuesday, 11 May 2010 2:36 AM:
>>> Perhaps so. ?It's hard to tell from that javadoc exactly what is
>>> meant: I thought, from reading that, that "slower; often much slower"
>>> referred to slow operation with high CPU loads when locking rather
>>> than, as we have here, CPUs being starved of work. ?But in any case,
>>> given the fact that locking is so rare, I found this result a little
>>> bit surprising.
>>
>> Just one further comment. Locking may be "rare" from the perspective of
>> locked-work:unlocked-work, but it would seem that your threads are executing
>> in-phase, and so contention is actually high.
>
> So it seems. ?They don't start in phase, but because of the convoying
> effect they eventually move into lock-step. ?I wonder how often this
> happens ?the real world applications.

With fair locks, if lock attempts occur more often than
once per time slice, then just one contended lock
will cause throughput to drop to one lock acquisition
per time slice.

Martin


From hanson.char at gmail.com  Thu May 13 12:21:57 2010
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 13 May 2010 09:21:57 -0700
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEHNIFAA.davidcholmes@aapt.net.au>
References: <a55f9dae1003230953j1c0e1338w55f1059481a25e06@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHNIFAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTikXfnnpcHPR5bwYebF_KsRAGGa9RjF5ZVpTA4Wn@mail.gmail.com>

Hi David,

Any recommended way to find out:
a) the default thread stack size used in a running JVM
b) the actual thread stack size of a thread (after it is created with
a requested stack size)

Thanks,
Hanson

On Tue, Mar 23, 2010 at 3:32 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Hi Ramesh,
>
> The default Java thread stack size is platform specific but can be set with
> -Xss parameter on JVM startup (or can be set for individual threads via
> their constructor). This stack size is not related to that seen in ulimit
> because the VM explicitly sets the stack size when native threads are
> created.
>
> As for "Thread Local Data" I'm not sure exactly what you mean by that.
>
> HTH
>
> David Holmes
>

From davidcholmes at aapt.net.au  Thu May 13 18:01:58 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 14 May 2010 08:01:58 +1000
Subject: [concurrency-interest] Thread Stack Size and Thread Local Data
In-Reply-To: <AANLkTikXfnnpcHPR5bwYebF_KsRAGGa9RjF5ZVpTA4Wn@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEGIIGAA.davidcholmes@aapt.net.au>

Hanson,

Hanson Char writes:
> Any recommended way to find out:
> a) the default thread stack size used in a running JVM
> b) the actual thread stack size of a thread (after it is created with
> a requested stack size)

There are no APIs to retrieve either of those pieces of information that I
am aware of.

David

> Thanks,
> Hanson
>
> On Tue, Mar 23, 2010 at 3:32 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Hi Ramesh,
> >
> > The default Java thread stack size is platform specific but can
> be set with
> > -Xss parameter on JVM startup (or can be set for individual threads via
> > their constructor). This stack size is not related to that seen
> in ulimit
> > because the VM explicitly sets the stack size when native threads are
> > created.
> >
> > As for "Thread Local Data" I'm not sure exactly what you mean by that.
> >
> > HTH
> >
> > David Holmes
> >


From fslzdd at gmail.com  Mon May 17 10:15:56 2010
From: fslzdd at gmail.com (=?GB2312?B?tO/X0w==?=)
Date: Mon, 17 May 2010 22:15:56 +0800
Subject: [concurrency-interest] Concurrency and security
Message-ID: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>

I am investigating an interesting topic: if the concurrency can harm
software security.  Is there any software security issue  stemming from
concurrency?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100517/064a77b5/attachment.html>

From stuff at kai.meder.info  Tue May 18 08:01:05 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Tue, 18 May 2010 14:01:05 +0200
Subject: [concurrency-interest] NIO inside RecursiveAction
Message-ID: <4BF28181.2020606@kai.meder.info>

Hello

reading the API-docs of the ForkJoinPool I wonder if it is
allowed/recommended to do NIO, so non-blocking IO, inside
RecursiveActions which are implemented to be short-lived and lightweight.
Is there any problem to process NIO-Selector-Events using
RecursiveActions in an async ForkJoinPool?

Thanks,
Kai

From stuff at kai.meder.info  Tue May 18 08:03:29 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Tue, 18 May 2010 14:03:29 +0200
Subject: [concurrency-interest] Asynchronous-nature of ConcurrentLinkedQueue
Message-ID: <4BF28211.9070001@kai.meder.info>

Hello

reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
"asynchronous nature" mentioned in the size()-doc is?

"Beware that, unlike in most collections, this method is NOT a
constant-time operation. Because of the asynchronous nature of these
queues, determining the current number of elements requires an O(n)
traversal. "

I read the source and there is looping until expectations on the
atomic-references are met, is this asynchronous?

Thanks, Kai

From dl at cs.oswego.edu  Tue May 18 08:08:48 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 18 May 2010 08:08:48 -0400
Subject: [concurrency-interest] NIO inside RecursiveAction
In-Reply-To: <4BF28181.2020606@kai.meder.info>
References: <4BF28181.2020606@kai.meder.info>
Message-ID: <4BF28350.3040801@cs.oswego.edu>

On 05/18/10 08:01, Kai Meder wrote:
> Hello
>
> reading the API-docs of the ForkJoinPool I wonder if it is
> allowed/recommended to do NIO, so non-blocking IO, inside
> RecursiveActions which are implemented to be short-lived and lightweight.
> Is there any problem to process NIO-Selector-Events using
> RecursiveActions in an async ForkJoinPool?
>

This should work well, but I don't know of anyone who has done
it very extensively, so any experiences you have to report would
be welcome.

-Doug


From dl at cs.oswego.edu  Tue May 18 08:17:46 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 18 May 2010 08:17:46 -0400
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <4BF28211.9070001@kai.meder.info>
References: <4BF28211.9070001@kai.meder.info>
Message-ID: <4BF2856A.2020704@cs.oswego.edu>

On 05/18/10 08:03, Kai Meder wrote:
> Hello
>
> reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
> "asynchronous nature" mentioned in the size()-doc is?
>
> "Beware that, unlike in most collections, this method is NOT a
> constant-time operation. Because of the asynchronous nature of these
> queues, determining the current number of elements requires an O(n)
> traversal. "
>

Because insertion and removal operations can occur concurrently
(even while you are asking about the size), you generally
don't want to ask about the size (although isEmpty is usually
still useful). But if you do ask, the queue
will provide an answer by counting up the elements. The
answer it returns might not have much bearing to the actual
number of elements upon return of the method.

-Doug

From gdenys at yahoo.com  Tue May 18 10:46:50 2010
From: gdenys at yahoo.com (Denys Geert)
Date: Tue, 18 May 2010 07:46:50 -0700 (PDT)
Subject: [concurrency-interest] NIO inside RecursiveAction
In-Reply-To: <4BF28181.2020606@kai.meder.info>
References: <4BF28181.2020606@kai.meder.info>
Message-ID: <732667.66211.qm@web51404.mail.re2.yahoo.com>

We are using ForkJoinPool to perform recursive tasks that have a substantial (blocking) IO part. It's working very well for us.


Regards,
Geert.


----- Original Message ----
From: Kai Meder <stuff at kai.meder.info>
To: concurrency-interest at cs.oswego.edu
Sent: Tue, May 18, 2010 2:01:05 PM
Subject: [concurrency-interest] NIO inside RecursiveAction

Hello

reading the API-docs of the ForkJoinPool I wonder if it is
allowed/recommended to do NIO, so non-blocking IO, inside
RecursiveActions which are implemented to be short-lived and lightweight.
Is there any problem to process NIO-Selector-Events using
RecursiveActions in an async ForkJoinPool?

Thanks,
Kai
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      

From gergg at cox.net  Tue May 18 18:28:17 2010
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 18 May 2010 17:28:17 -0500
Subject: [concurrency-interest] Asynchronous-nature
	of	ConcurrentLinkedQueue
In-Reply-To: <4BF2856A.2020704@cs.oswego.edu>
References: <4BF28211.9070001@kai.meder.info> <4BF2856A.2020704@cs.oswego.edu>
Message-ID: <4BF31481.4050204@cox.net>

Doug Lea wrote:
> On 05/18/10 08:03, Kai Meder wrote:
>> Hello
>>
>> reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
>> "asynchronous nature" mentioned in the size()-doc is?
>>
>> "Beware that, unlike in most collections, this method is NOT a
>> constant-time operation. Because of the asynchronous nature of these
>> queues, determining the current number of elements requires an O(n)
>> traversal. "
>>
> 
> Because insertion and removal operations can occur concurrently
> (even while you are asking about the size), you generally
> don't want to ask about the size (although isEmpty is usually
> still useful). But if you do ask, the queue
> will provide an answer by counting up the elements. The
> answer it returns might not have much bearing to the actual
> number of elements upon return of the method.

And I guess I am always curious why there is no "counter" associated with the 
queue length.  It would provide the same "rough" estimate as the "traversal" 
without the repeated overhead would it not?

Gregg Wonderly

From davidcholmes at aapt.net.au  Tue May 18 18:35:34 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 19 May 2010 08:35:34 +1000
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <4BF31481.4050204@cox.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEHIIGAA.davidcholmes@aapt.net.au>

Greg,

Gregg Wonderly writes:
> Doug Lea wrote:
> > On 05/18/10 08:03, Kai Meder wrote:
> >> Hello
> >>
> >> reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
> >> "asynchronous nature" mentioned in the size()-doc is?
> >>
> >> "Beware that, unlike in most collections, this method is NOT a
> >> constant-time operation. Because of the asynchronous nature of these
> >> queues, determining the current number of elements requires an O(n)
> >> traversal. "
> >>
> >
> > Because insertion and removal operations can occur concurrently
> > (even while you are asking about the size), you generally
> > don't want to ask about the size (although isEmpty is usually
> > still useful). But if you do ask, the queue
> > will provide an answer by counting up the elements. The
> > answer it returns might not have much bearing to the actual
> > number of elements upon return of the method.
>
> And I guess I am always curious why there is no "counter"
> associated with the queue length.  It would provide the
> same "rough" estimate as the "traversal" without the
>  repeated overhead would it not?

Yes but at a cost to every queue operation to maintain that counter. This
penalises the main queue operations to support another operation (size())
that is for most intents and purposes completely useless.

The present code only penalises the misguided client that thinks they need
to know the size.

David

>
> Gregg Wonderly
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From martinrb at google.com  Tue May 18 18:40:04 2010
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 18 May 2010 15:40:04 -0700
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <4BF31481.4050204@cox.net>
References: <4BF28211.9070001@kai.meder.info> <4BF2856A.2020704@cs.oswego.edu>
	<4BF31481.4050204@cox.net>
Message-ID: <AANLkTimMjtebXDG1-u0Etr2hEpfDErF6v-Ow3NP730VT@mail.gmail.com>

On Tue, May 18, 2010 at 15:28, Gregg Wonderly <gergg at cox.net> wrote:
> And I guess I am always curious why there is no "counter" associated with
> the queue length. ?It would provide the same "rough" estimate as the
> "traversal" without the repeated overhead would it not?

You could do that, but you would need an AtomicInteger
to keep track of the count.  And that requires expensive CASes,
and unavoidable contention between consumers and producers.
Unless you have super-fancy counters that have not yet
been proven in practice.

Martin


From ben_manes at yahoo.com  Tue May 18 19:06:19 2010
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 18 May 2010 16:06:19 -0700 (PDT)
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <4BF31481.4050204@cox.net>
References: <4BF28211.9070001@kai.meder.info> <4BF2856A.2020704@cs.oswego.edu>
	<4BF31481.4050204@cox.net>
Message-ID: <123942.93966.qm@web38807.mail.mud.yahoo.com>

In the few cases where I've needed a fast count on a CLQ, I didn't need to maintain it as expensively as performing an increment/decrement per queue operation. Generally there was some usage characteristic, such as a single thread draining the queue, that allowed me to reduce the contention on the counter. Its actually quite nice having the flexibility to choose how to manage the performance of the count when it actually matters.


________________________________
From: Gregg Wonderly <gergg at cox.net>
To: Doug Lea <dl at cs.oswego.edu>
Cc: concurrency-interest at cs.oswego.edu
Sent: Tue, May 18, 2010 3:28:17 PM
Subject: Re: [concurrency-interest] Asynchronous-nature of ConcurrentLinkedQueue

Doug Lea wrote:
> On 05/18/10 08:03, Kai Meder wrote:
>> Hello
>>
>> reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
>> "asynchronous nature" mentioned in the size()-doc is?
>>
>> "Beware that, unlike in most collections, this method is NOT a
>> constant-time operation. Because of the asynchronous nature of these
>> queues, determining the current number of elements requires an O(n)
>> traversal. "
>>
> 
> Because insertion and removal operations can occur concurrently
> (even while you are asking about the size), you generally
> don't want to ask about the size (although isEmpty is usually
> still useful). But if you do ask, the queue
> will provide an answer by counting up the elements. The
> answer it returns might not have much bearing to the actual
> number of elements upon return of the method.

And I guess I am always curious why there is no "counter" associated with the 
queue length.  It would provide the same "rough" estimate as the "traversal" 
without the repeated overhead would it not?

Gregg Wonderly
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100518/e8d34c28/attachment.html>

From raimundo.costa at totvs.com.br  Wed May 19 10:06:44 2010
From: raimundo.costa at totvs.com.br (raydacosta)
Date: Wed, 19 May 2010 11:06:44 -0300
Subject: [concurrency-interest] Comparison Plugin
In-Reply-To: <123942.93966.qm@web38807.mail.mud.yahoo.com>
References: <4BF28211.9070001@kai.meder.info>
	<4BF2856A.2020704@cs.oswego.edu>	<4BF31481.4050204@cox.net>
	<123942.93966.qm@web38807.mail.mud.yahoo.com>
Message-ID: <1274278004.4839.0.camel@raydacosta-desktop>

A helping friends. Is there a plugin in Eclipse so I have my own
comparator. An extension plugin for eclipse. There? Could tell which
one?



From kevinb at google.com  Wed May 19 10:20:13 2010
From: kevinb at google.com (Kevin Bourrillion)
Date: Wed, 19 May 2010 07:20:13 -0700
Subject: [concurrency-interest] Comparison Plugin
In-Reply-To: <1274278004.4839.0.camel@raydacosta-desktop>
References: <4BF28211.9070001@kai.meder.info> <4BF2856A.2020704@cs.oswego.edu>
	<4BF31481.4050204@cox.net>
	<123942.93966.qm@web38807.mail.mud.yahoo.com>
	<1274278004.4839.0.camel@raydacosta-desktop>
Message-ID: <AANLkTinAzUDR3FqM6FLhKPwbJuNjQob7PQXajl-Wpf2P@mail.gmail.com>

I recommend joining stackoverflow.com and posting questions like this there.
 Try to say a little more about what you're really trying to do.


On Wed, May 19, 2010 at 7:06 AM, raydacosta <raimundo.costa at totvs.com.br>wrote:

> A helping friends. Is there a plugin in Eclipse so I have my own
> comparator. An extension plugin for eclipse. There? Could tell which
> one?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Kevin Bourrillion @ Google
internal:  http://goto/javalibraries
external: http://guava-libraries.googlecode.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100519/b11d532e/attachment.html>

From gregg at cytetech.com  Wed May 19 16:07:45 2010
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 19 May 2010 15:07:45 -0500
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEHIIGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIEHIIGAA.davidcholmes@aapt.net.au>
Message-ID: <4BF44511.7060400@cytetech.com>

David Holmes wrote:
> Greg,
> 
> Gregg Wonderly writes:
>> Doug Lea wrote:
>>> On 05/18/10 08:03, Kai Meder wrote:
>>>> Hello
>>>>
>>>> reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
>>>> "asynchronous nature" mentioned in the size()-doc is?
>>>>
>>>> "Beware that, unlike in most collections, this method is NOT a
>>>> constant-time operation. Because of the asynchronous nature of these
>>>> queues, determining the current number of elements requires an O(n)
>>>> traversal. "
>>>>
>>> Because insertion and removal operations can occur concurrently
>>> (even while you are asking about the size), you generally
>>> don't want to ask about the size (although isEmpty is usually
>>> still useful). But if you do ask, the queue
>>> will provide an answer by counting up the elements. The
>>> answer it returns might not have much bearing to the actual
>>> number of elements upon return of the method.
>> And I guess I am always curious why there is no "counter"
>> associated with the queue length.  It would provide the
>> same "rough" estimate as the "traversal" without the
>>  repeated overhead would it not?
> 
> Yes but at a cost to every queue operation to maintain that counter. This
> penalises the main queue operations to support another operation (size())
> that is for most intents and purposes completely useless.
> 
> The present code only penalises the misguided client that thinks they need
> to know the size.

I was guessing that it would be sufficient to use a volatile integer, and just 
live with the side effects of the data races, performing explicit zeroing when 
the queue was empty.

However, the very lose management of queue nodes and other optimizations that I 
see now after looking at the code, show that empty is not trivially detectable 
either.

Transactional CAS over multiple values would really be nice to have...

Gregg Wonderly

From hans.boehm at hp.com  Wed May 19 16:34:48 2010
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 19 May 2010 20:34:48 +0000
Subject: [concurrency-interest] Asynchronous-nature
	of	ConcurrentLinkedQueue
In-Reply-To: <4BF44511.7060400@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCIEHIIGAA.davidcholmes@aapt.net.au>
	<4BF44511.7060400@cytetech.com>
Message-ID: <238A96A773B3934685A7269CC8A8D0426DF7324127@GVW0436EXB.americas.hpqcorp.net>

> 
> I was guessing that it would be sufficient to use a volatile 
> integer, and just live with the side effects of the data 
> races, performing explicit zeroing when the queue was empty.
> 
I suspect that, in spite of folklore to the contrary, you rarely
want to do that sort of thing.  You still take the large performance hit
of all the coherence misses as ownership of the counter moves back and forth.
And, based on my own experience at least, the resulting value can easily be
complete junk.

It's not completely clear to me that incrementAndGet has to be more expensive,
at least on X86.  It could even conceivably be cheaper, since it may prevent
the case in which the cache line is stolen by another processor between the
load and the store, and you thus get two misses per operation.

Our garbage collector once had such a counter that kept track of reachable memory.
It was incremented for every traced object.

With two GC threads, the coherence misses had two effects:

1) The collector ran at around half speed, negating any parallel speedup.
2) The count was typically off by a factor of two.  I suspect that as a result
of the regular misses, the timing almost always worked out such that a store
took place between a load and a store in the other thread, losing half the counts.


Hans

From martinrb at google.com  Wed May 19 16:44:28 2010
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 May 2010 13:44:28 -0700
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <4BF44511.7060400@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCIEHIIGAA.davidcholmes@aapt.net.au>
	<4BF44511.7060400@cytetech.com>
Message-ID: <AANLkTik9RBuEyZ3T5CtJ4iXWD08DiRGaUzKOApPnuwPI@mail.gmail.com>

On Wed, May 19, 2010 at 13:07, Gregg Wonderly <gregg at cytetech.com> wrote:

> However, the very lose management of queue nodes and other optimizations
> that I see now after looking at the code, show that empty is not trivially
> detectable either.

It's true that CLQ.isEmpty() can take an unbounded number of node hops,
but it's likely to return after no more than 2 or 3 hops.

Martin

From stuff at kai.meder.info  Wed May 19 17:44:08 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Wed, 19 May 2010 23:44:08 +0200
Subject: [concurrency-interest]
	Asynchronous-nature	of	ConcurrentLinkedQueue
In-Reply-To: <238A96A773B3934685A7269CC8A8D0426DF7324127@GVW0436EXB.americas.hpqcorp.net>
References: <NFBBKALFDCPFIDBNKAPCIEHIIGAA.davidcholmes@aapt.net.au>	<4BF44511.7060400@cytetech.com>
	<238A96A773B3934685A7269CC8A8D0426DF7324127@GVW0436EXB.americas.hpqcorp.net>
Message-ID: <4BF45BA8.7080804@kai.meder.info>

> With two GC threads, the coherence misses had two effects:
>
> 1) The collector ran at around half speed, negating any parallel speedup.
> 2) The count was typically off by a factor of two.  I suspect that as
a result
> of the regular misses, the timing almost always worked out such that a
store
> took place between a load and a store in the other thread, losing half
the counts.

Interesting observation, thanks for mentioning.

From mboyers at yahoo.com  Wed May 19 23:13:11 2010
From: mboyers at yahoo.com (Mike Boyers)
Date: Wed, 19 May 2010 20:13:11 -0700 (PDT)
Subject: [concurrency-interest] ThreadPoolExecutor - Concurrent "Batch"
	Executions
In-Reply-To: <4BF44511.7060400@cytetech.com>
Message-ID: <231839.4100.qm@web110210.mail.gq1.yahoo.com>

I'm building a service where, in order to generate each response, I'll need to go against several remote sources.  In many cases, the remote requests can be made concurrently.

I'm looking for a super simple interface where developers can execute these remote requests in parallel while being blocked as they execute, with the ability to time out after a specified period.

As a (very) rough idea:

Collection batch = new LinkedList();
batch.add(new RemoteRequest1());
batch.add(new RemoteRequest2());
batch.add(new RemoteRequest3());
Batcher.execute(batch, 5, TimeUnit.SECONDS);

The Batcher.execute call blocks until either all of the tasks are complete or until 10 seconds passes.

I can see how to use a ThreadPoolExecutor to accomplish this, by submitting each Callable then waiting on the Future objects returned upon submit, meanwhile keeping track of the overall amount of time I've waited as I wait on each Future.  While this logic isn't overly complicated, I'd still like to keep it housed and supply developers with something like I outlined above.

But before building this "wrapper", I figure I'd ask to see if there's already something existing I should be looking at, either in the concurrent package or elsewhere (or if I should be thinking about this in a completely different way).

Thanks,
Mike


      

From davidcholmes at aapt.net.au  Wed May 19 23:54:22 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 20 May 2010 13:54:22 +1000
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>

An unidentified poster writes:
> I am investigating an interesting topic: if the concurrency can harm
software security.
> Is there any software security issue  stemming from concurrency?

Yes. In poorly constructed systems race conditions could lead to various
invariant violations, including those pertaining to "security".

In a platform like Java, the programming language must ensure there are some
basic guarantees even in the face of race conditions. For Java this is
defined as part of the Java Memory Model, which ensures that you can't see
uninitialized fields (though they may be default initialized), and provides
for correct visibility of final fields.

But even if the language provides basic guarantees, it is up to classes to
use the language facilities correctly to ensure that they can't be
compromised by race conditions induced by client code.

And of course the runtime system (for Java that's the VM) must also be
written correctly to ensure no concurrency related security holes exist.

Hope this gives you enough to do a proper investigation. ;-)

David Holmes


From jwesleysmith at atlassian.com  Thu May 20 00:09:57 2010
From: jwesleysmith at atlassian.com (Jed Wesley-Smith)
Date: Thu, 20 May 2010 14:09:57 +1000
Subject: [concurrency-interest] ThreadPoolExecutor - Concurrent "Batch"
 Executions
In-Reply-To: <231839.4100.qm@web110210.mail.gq1.yahoo.com>
References: <231839.4100.qm@web110210.mail.gq1.yahoo.com>
Message-ID: <4BF4B615.7090907@atlassian.com>

Look at java.util.concurrent.CompletionService and its implementation 
java.util.concurrent.ExecutorCompletionService

For tracking multiple timeouts we have a Timeout class as well:
https://labs.atlassian.com/source/browse/CONCURRENT/trunk/src/main/java/com/atlassian/util/concurrent/Timeout.java?r=2933

cheers,
jed.

Mike Boyers wrote:
> I'm building a service where, in order to generate each response, I'll need to go against several remote sources.  In many cases, the remote requests can be made concurrently.
>
> I'm looking for a super simple interface where developers can execute these remote requests in parallel while being blocked as they execute, with the ability to time out after a specified period.
>
> As a (very) rough idea:
>
> Collection batch = new LinkedList();
> batch.add(new RemoteRequest1());
> batch.add(new RemoteRequest2());
> batch.add(new RemoteRequest3());
> Batcher.execute(batch, 5, TimeUnit.SECONDS);
>
> The Batcher.execute call blocks until either all of the tasks are complete or until 10 seconds passes.
>
> I can see how to use a ThreadPoolExecutor to accomplish this, by submitting each Callable then waiting on the Future objects returned upon submit, meanwhile keeping track of the overall amount of time I've waited as I wait on each Future.  While this logic isn't overly complicated, I'd still like to keep it housed and supply developers with something like I outlined above.
>
> But before building this "wrapper", I figure I'd ask to see if there's already something existing I should be looking at, either in the concurrent package or elsewhere (or if I should be thinking about this in a completely different way).
>   


From eshioji at gmail.com  Thu May 20 00:24:54 2010
From: eshioji at gmail.com (Enno Shioji)
Date: Thu, 20 May 2010 09:54:54 +0530
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>
References: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>

A very silly (but it happens! I've seen one like this before) example would be:


class Auth {
    private boolean clearance = false;

    public void authenticate(){
        this.clearance = true;
    }

    public void deauthenticate(){
        this.clearance = false;
    }

    public String readSecretData(){
         if(clearance){
             return "Company secret";
         }else{
             return "Gotcha, hacker!";
         }
    }

And then Auth is made a singleton because "It will increase
performance!*" and these three methods are called from random number
of threads. Then users without clearance will start to see secret data
occasionally.

*: Making a class a singleton doesn't make things faster in most of the cases..


Regards,
Enno



On Thu, May 20, 2010 at 9:24 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
> An unidentified poster writes:
>> I am investigating an interesting topic: if the concurrency can harm
> software security.
>> Is there any software security issue ?stemming from concurrency?
>
> Yes. In poorly constructed systems race conditions could lead to various
> invariant violations, including those pertaining to "security".
>
> In a platform like Java, the programming language must ensure there are some
> basic guarantees even in the face of race conditions. For Java this is
> defined as part of the Java Memory Model, which ensures that you can't see
> uninitialized fields (though they may be default initialized), and provides
> for correct visibility of final fields.
>
> But even if the language provides basic guarantees, it is up to classes to
> use the language facilities correctly to ensure that they can't be
> compromised by race conditions induced by client code.
>
> And of course the runtime system (for Java that's the VM) must also be
> written correctly to ensure no concurrency related security holes exist.
>
> Hope this gives you enough to do a proper investigation. ;-)
>
> David Holmes
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From ganzhi at gmail.com  Thu May 20 00:48:53 2010
From: ganzhi at gmail.com (James Gan)
Date: Thu, 20 May 2010 12:48:53 +0800
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>
References: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>
	<AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>
Message-ID: <AANLkTini-mo-UO-MpBPkms7U0l5LgWHGWj8_0BwDlQ2x@mail.gmail.com>

A nice example! A follow-up open question: is it possible to detect
such error by atomatic tool? Seems very difficult!

On Thu, May 20, 2010 at 12:24 PM, Enno Shioji <eshioji at gmail.com> wrote:
> A very silly (but it happens! I've seen one like this before) example would be:
>
>
> class Auth {
> ? ?private boolean clearance = false;
>
> ? ?public void authenticate(){
> ? ? ? ?this.clearance = true;
> ? ?}
>
> ? ?public void deauthenticate(){
> ? ? ? ?this.clearance = false;
> ? ?}
>
> ? ?public String readSecretData(){
> ? ? ? ? if(clearance){
> ? ? ? ? ? ? return "Company secret";
> ? ? ? ? }else{
> ? ? ? ? ? ? return "Gotcha, hacker!";
> ? ? ? ? }
> ? ?}
>
> And then Auth is made a singleton because "It will increase
> performance!*" and these three methods are called from random number
> of threads. Then users without clearance will start to see secret data
> occasionally.
>
> *: Making a class a singleton doesn't make things faster in most of the cases..
>
>
> Regards,
> Enno
>
>
>
> On Thu, May 20, 2010 at 9:24 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>> An unidentified poster writes:
>>> I am investigating an interesting topic: if the concurrency can harm
>> software security.
>>> Is there any software security issue ?stemming from concurrency?
>>
>> Yes. In poorly constructed systems race conditions could lead to various
>> invariant violations, including those pertaining to "security".
>>
>> In a platform like Java, the programming language must ensure there are some
>> basic guarantees even in the face of race conditions. For Java this is
>> defined as part of the Java Memory Model, which ensures that you can't see
>> uninitialized fields (though they may be default initialized), and provides
>> for correct visibility of final fields.
>>
>> But even if the language provides basic guarantees, it is up to classes to
>> use the language facilities correctly to ensure that they can't be
>> compromised by race conditions induced by client code.
>>
>> And of course the runtime system (for Java that's the VM) must also be
>> written correctly to ensure no concurrency related security holes exist.
>>
>> Hope this gives you enough to do a proper investigation. ;-)
>>
>> David Holmes
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Best Regards
James Gan
Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com


From davidcholmes at aapt.net.au  Thu May 20 00:54:23 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 20 May 2010 14:54:23 +1000
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTini-mo-UO-MpBPkms7U0l5LgWHGWj8_0BwDlQ2x@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEIAIGAA.davidcholmes@aapt.net.au>

James Gan writes:
> A nice example! A follow-up open question: is it possible to detect
> such error by atomatic tool? Seems very difficult!

I would expect many race-detector tools would flag the below as needing
synchronization.

David Holmes

> On Thu, May 20, 2010 at 12:24 PM, Enno Shioji <eshioji at gmail.com> wrote:
> > A very silly (but it happens! I've seen one like this before)
> example would be:
> >
> >
> > class Auth {
> > ? ?private boolean clearance = false;
> >
> > ? ?public void authenticate(){
> > ? ? ? ?this.clearance = true;
> > ? ?}
> >
> > ? ?public void deauthenticate(){
> > ? ? ? ?this.clearance = false;
> > ? ?}
> >
> > ? ?public String readSecretData(){
> > ? ? ? ? if(clearance){
> > ? ? ? ? ? ? return "Company secret";
> > ? ? ? ? }else{
> > ? ? ? ? ? ? return "Gotcha, hacker!";
> > ? ? ? ? }
> > ? ?}
> >
> > And then Auth is made a singleton because "It will increase
> > performance!*" and these three methods are called from random number
> > of threads. Then users without clearance will start to see secret data
> > occasionally.
> >
> > *: Making a class a singleton doesn't make things faster in
> most of the cases..
> >
> >
> > Regards,
> > Enno
> >
> >
> >
> > On Thu, May 20, 2010 at 9:24 AM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> >> An unidentified poster writes:
> >>> I am investigating an interesting topic: if the concurrency can harm
> >> software security.
> >>> Is there any software security issue ?stemming from concurrency?
> >>
> >> Yes. In poorly constructed systems race conditions could lead
> to various
> >> invariant violations, including those pertaining to "security".
> >>
> >> In a platform like Java, the programming language must ensure
> there are some
> >> basic guarantees even in the face of race conditions. For Java this is
> >> defined as part of the Java Memory Model, which ensures that
> you can't see
> >> uninitialized fields (though they may be default initialized),
> and provides
> >> for correct visibility of final fields.
> >>
> >> But even if the language provides basic guarantees, it is up
> to classes to
> >> use the language facilities correctly to ensure that they can't be
> >> compromised by race conditions induced by client code.
> >>
> >> And of course the runtime system (for Java that's the VM) must also be
> >> written correctly to ensure no concurrency related security
> holes exist.
> >>
> >> Hope this gives you enough to do a proper investigation. ;-)
> >>
> >> David Holmes
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
> --
> Best Regards
> James Gan
> Current Project: Concurrent Building Block at
http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From eshioji at gmail.com  Thu May 20 00:58:57 2010
From: eshioji at gmail.com (Enno Shioji)
Date: Thu, 20 May 2010 10:28:57 +0530
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTini-mo-UO-MpBPkms7U0l5LgWHGWj8_0BwDlQ2x@mail.gmail.com>
References: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>
	<AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>
	<AANLkTini-mo-UO-MpBPkms7U0l5LgWHGWj8_0BwDlQ2x@mail.gmail.com>
Message-ID: <AANLkTilNgW1qKy3G9yY68BAsZb4W7l5FbyEuPclr9vWI@mail.gmail.com>

Hmm.. I know that some IDE and tools provide "race condition
detection". I've never used them though. It might be interesting to
search "static analysis tool java race condition" or "static analysis
tool concurrency" on google and see what you get.

I think intellij IDEA (Java IDE) also has a static analysis tool to
detect race conditions.

Maybe you can reproduce the particular example and code it so that one
instance is accessed from bunch of threads, then analyze the code and
see if it detects it. Since it's a super simple example, I think there
is a very good change they'll do.


Regards,
Enno


On Thu, May 20, 2010 at 10:18 AM, James Gan <ganzhi at gmail.com> wrote:
> A nice example! A follow-up open question: is it possible to detect
> such error by atomatic tool? Seems very difficult!
>
> On Thu, May 20, 2010 at 12:24 PM, Enno Shioji <eshioji at gmail.com> wrote:
>> A very silly (but it happens! I've seen one like this before) example would be:
>>
>>
>> class Auth {
>> ? ?private boolean clearance = false;
>>
>> ? ?public void authenticate(){
>> ? ? ? ?this.clearance = true;
>> ? ?}
>>
>> ? ?public void deauthenticate(){
>> ? ? ? ?this.clearance = false;
>> ? ?}
>>
>> ? ?public String readSecretData(){
>> ? ? ? ? if(clearance){
>> ? ? ? ? ? ? return "Company secret";
>> ? ? ? ? }else{
>> ? ? ? ? ? ? return "Gotcha, hacker!";
>> ? ? ? ? }
>> ? ?}
>>
>> And then Auth is made a singleton because "It will increase
>> performance!*" and these three methods are called from random number
>> of threads. Then users without clearance will start to see secret data
>> occasionally.
>>
>> *: Making a class a singleton doesn't make things faster in most of the cases..
>>
>>
>> Regards,
>> Enno
>>
>>
>>
>> On Thu, May 20, 2010 at 9:24 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>> An unidentified poster writes:
>>>> I am investigating an interesting topic: if the concurrency can harm
>>> software security.
>>>> Is there any software security issue ?stemming from concurrency?
>>>
>>> Yes. In poorly constructed systems race conditions could lead to various
>>> invariant violations, including those pertaining to "security".
>>>
>>> In a platform like Java, the programming language must ensure there are some
>>> basic guarantees even in the face of race conditions. For Java this is
>>> defined as part of the Java Memory Model, which ensures that you can't see
>>> uninitialized fields (though they may be default initialized), and provides
>>> for correct visibility of final fields.
>>>
>>> But even if the language provides basic guarantees, it is up to classes to
>>> use the language facilities correctly to ensure that they can't be
>>> compromised by race conditions induced by client code.
>>>
>>> And of course the runtime system (for Java that's the VM) must also be
>>> written correctly to ensure no concurrency related security holes exist.
>>>
>>> Hope this gives you enough to do a proper investigation. ;-)
>>>
>>> David Holmes
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Best Regards
> James Gan
> Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
> Blog: http://ganzhi.blogspot.com
>


From ganzhi at gmail.com  Thu May 20 01:00:11 2010
From: ganzhi at gmail.com (James Gan)
Date: Thu, 20 May 2010 13:00:11 +0800
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEIAIGAA.davidcholmes@aapt.net.au>
References: <AANLkTini-mo-UO-MpBPkms7U0l5LgWHGWj8_0BwDlQ2x@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEIAIGAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTikfAx6WxE6wJVvfJALQKwVt11bjdKljtwBWSV6U@mail.gmail.com>

Yes, data race tool can detect this problem. On the other hand, even
if we fixed the data race problem by adding synchronization, it's
still a security problem.

On Thu, May 20, 2010 at 12:54 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> James Gan writes:
>> A nice example! A follow-up open question: is it possible to detect
>> such error by atomatic tool? Seems very difficult!
>
> I would expect many race-detector tools would flag the below as needing
> synchronization.
>
> David Holmes
>
>> On Thu, May 20, 2010 at 12:24 PM, Enno Shioji <eshioji at gmail.com> wrote:
>> > A very silly (but it happens! I've seen one like this before)
>> example would be:
>> >
>> >
>> > class Auth {
>> > ? ?private boolean clearance = false;
>> >
>> > ? ?public void authenticate(){
>> > ? ? ? ?this.clearance = true;
>> > ? ?}
>> >
>> > ? ?public void deauthenticate(){
>> > ? ? ? ?this.clearance = false;
>> > ? ?}
>> >
>> > ? ?public String readSecretData(){
>> > ? ? ? ? if(clearance){
>> > ? ? ? ? ? ? return "Company secret";
>> > ? ? ? ? }else{
>> > ? ? ? ? ? ? return "Gotcha, hacker!";
>> > ? ? ? ? }
>> > ? ?}
>> >
>> > And then Auth is made a singleton because "It will increase
>> > performance!*" and these three methods are called from random number
>> > of threads. Then users without clearance will start to see secret data
>> > occasionally.
>> >
>> > *: Making a class a singleton doesn't make things faster in
>> most of the cases..
>> >
>> >
>> > Regards,
>> > Enno
>> >
>> >
>> >
>> > On Thu, May 20, 2010 at 9:24 AM, David Holmes
>> <davidcholmes at aapt.net.au> wrote:
>> >> An unidentified poster writes:
>> >>> I am investigating an interesting topic: if the concurrency can harm
>> >> software security.
>> >>> Is there any software security issue ?stemming from concurrency?
>> >>
>> >> Yes. In poorly constructed systems race conditions could lead
>> to various
>> >> invariant violations, including those pertaining to "security".
>> >>
>> >> In a platform like Java, the programming language must ensure
>> there are some
>> >> basic guarantees even in the face of race conditions. For Java this is
>> >> defined as part of the Java Memory Model, which ensures that
>> you can't see
>> >> uninitialized fields (though they may be default initialized),
>> and provides
>> >> for correct visibility of final fields.
>> >>
>> >> But even if the language provides basic guarantees, it is up
>> to classes to
>> >> use the language facilities correctly to ensure that they can't be
>> >> compromised by race conditions induced by client code.
>> >>
>> >> And of course the runtime system (for Java that's the VM) must also be
>> >> written correctly to ensure no concurrency related security
>> holes exist.
>> >>
>> >> Hope this gives you enough to do a proper investigation. ;-)
>> >>
>> >> David Holmes
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>>
>>
>>
>> --
>> Best Regards
>> James Gan
>> Current Project: Concurrent Building Block at
> http://amino-cbbs.sourceforge.net/
> Blog: http://ganzhi.blogspot.com
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>



-- 
Best Regards
James Gan
Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com


From davidcholmes at aapt.net.au  Thu May 20 01:04:03 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 20 May 2010 15:04:03 +1000
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTikfAx6WxE6wJVvfJALQKwVt11bjdKljtwBWSV6U@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>

James Gan writes:
> Yes, data race tool can detect this problem. On the other hand, even
> if we fixed the data race problem by adding synchronization, it's
> still a security problem.

Oops! Indeed. Even with sync the API is fatally flawed.

I don't know if the tools will be able to detect the inherent check-then-act
sequence.

David

> On Thu, May 20, 2010 at 12:54 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > James Gan writes:
> >> A nice example! A follow-up open question: is it possible to detect
> >> such error by atomatic tool? Seems very difficult!
> >
> > I would expect many race-detector tools would flag the below as needing
> > synchronization.
> >
> > David Holmes
> >
> >> On Thu, May 20, 2010 at 12:24 PM, Enno Shioji
> <eshioji at gmail.com> wrote:
> >> > A very silly (but it happens! I've seen one like this before)
> >> example would be:
> >> >
> >> >
> >> > class Auth {
> >> > ? ?private boolean clearance = false;
> >> >
> >> > ? ?public void authenticate(){
> >> > ? ? ? ?this.clearance = true;
> >> > ? ?}
> >> >
> >> > ? ?public void deauthenticate(){
> >> > ? ? ? ?this.clearance = false;
> >> > ? ?}
> >> >
> >> > ? ?public String readSecretData(){
> >> > ? ? ? ? if(clearance){
> >> > ? ? ? ? ? ? return "Company secret";
> >> > ? ? ? ? }else{
> >> > ? ? ? ? ? ? return "Gotcha, hacker!";
> >> > ? ? ? ? }
> >> > ? ?}
> >> >
> >> > And then Auth is made a singleton because "It will increase
> >> > performance!*" and these three methods are called from random number
> >> > of threads. Then users without clearance will start to see
> secret data
> >> > occasionally.
> >> >
> >> > *: Making a class a singleton doesn't make things faster in
> >> most of the cases..
> >> >
> >> >
> >> > Regards,
> >> > Enno
> >> >
> >> >
> >> >
> >> > On Thu, May 20, 2010 at 9:24 AM, David Holmes
> >> <davidcholmes at aapt.net.au> wrote:
> >> >> An unidentified poster writes:
> >> >>> I am investigating an interesting topic: if the
> concurrency can harm
> >> >> software security.
> >> >>> Is there any software security issue ?stemming from concurrency?
> >> >>
> >> >> Yes. In poorly constructed systems race conditions could lead
> >> to various
> >> >> invariant violations, including those pertaining to "security".
> >> >>
> >> >> In a platform like Java, the programming language must ensure
> >> there are some
> >> >> basic guarantees even in the face of race conditions. For
> Java this is
> >> >> defined as part of the Java Memory Model, which ensures that
> >> you can't see
> >> >> uninitialized fields (though they may be default initialized),
> >> and provides
> >> >> for correct visibility of final fields.
> >> >>
> >> >> But even if the language provides basic guarantees, it is up
> >> to classes to
> >> >> use the language facilities correctly to ensure that they can't be
> >> >> compromised by race conditions induced by client code.
> >> >>
> >> >> And of course the runtime system (for Java that's the VM)
> must also be
> >> >> written correctly to ensure no concurrency related security
> >> holes exist.
> >> >>
> >> >> Hope this gives you enough to do a proper investigation. ;-)
> >> >>
> >> >> David Holmes
> >> >>
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >>
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >>
> >>
> >>
> >> --
> >> Best Regards
> >> James Gan
> >> Current Project: Concurrent Building Block at
> > http://amino-cbbs.sourceforge.net/
> > Blog: http://ganzhi.blogspot.com
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
>
>
> --
> Best Regards
> James Gan
> Current Project: Concurrent Building Block at
http://amino-cbbs.sourceforge.net/
Blog: http://ganzhi.blogspot.com



From jwesleysmith at atlassian.com  Thu May 20 01:15:53 2010
From: jwesleysmith at atlassian.com (Jed Wesley-Smith)
Date: Thu, 20 May 2010 15:15:53 +1000
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>
Message-ID: <4BF4C589.4030005@atlassian.com>

David Holmes wrote:
> James Gan writes:
>   
>> Yes, data race tool can detect this problem. On the other hand, even
>> if we fixed the data race problem by adding synchronization, it's
>> still a security problem.
>>     
>
> Oops! Indeed. Even with sync the API is fatally flawed.
>
> I don't know if the tools will be able to detect the inherent check-then-act
> sequence.
>   

I just thought you were being droll?

cheers,

jed.

From qiyaoltc at gmail.com  Thu May 20 01:41:42 2010
From: qiyaoltc at gmail.com (Yao Qi)
Date: Thu, 20 May 2010 13:41:42 +0800
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTilNgW1qKy3G9yY68BAsZb4W7l5FbyEuPclr9vWI@mail.gmail.com>
References: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>
	<AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>
	<AANLkTini-mo-UO-MpBPkms7U0l5LgWHGWj8_0BwDlQ2x@mail.gmail.com>
	<AANLkTilNgW1qKy3G9yY68BAsZb4W7l5FbyEuPclr9vWI@mail.gmail.com>
Message-ID: <AANLkTilmcv_2Z4sr-dvrVeKb_HR5U5TrzhBdT3mbklBw@mail.gmail.com>

On Thu, May 20, 2010 at 12:58 PM, Enno Shioji <eshioji at gmail.com> wrote:
> Hmm.. I know that some IDE and tools provide "race condition
> detection". I've never used them though. It might be interesting to
> search "static analysis tool java race condition" or "static analysis
> tool concurrency" on google and see what you get.

Beside static analysis, race condition detection can be done in a
dynamic way.  Race detector in MulticoreSDK
(www.alphaworks.ibm.com/tech/msdk/) can detect potential race
conditions in parallel java programs.  you can run it with your
program, and output is easy to understand, shown as below,

Race Detector Version: 2.2.0, Build Time: 20100424-1134.
 Data Race 1 : 1 : Auth : clearance
  Thread "Thread-4" : Tid 13 : Rid 0 : WRITE
        Lock Set : [ ]
        Vector Clock : 2
      [Auth : authenticate()V : 1 : 33]
      [Driver$1 : run()V : 1 : 10]
  Thread "Thread-5" : Tid 14 : Rid 0 : WRITE
        Lock Set : [ ]
        Vector Clock : 2
      [Auth : deauthenticate()V : 1 : 37]
      [Driver$2 : run()V : 1 : 17]

"Auth:clearance" means there is a race on class Auth field clearance.
Two threads (Thread-4 and Thread-5) WRITE this field.  With callchain
information, it is easy to identify the problem.

>
> I think intellij IDEA (Java IDE) also has a static analysis tool to
> detect race conditions.
>
> Maybe you can reproduce the particular example and code it so that one
> instance is accessed from bunch of threads, then analyze the code and
> see if it detects it. Since it's a super simple example, I think there
> is a very good change they'll do.
>
>
> Regards,
> Enno
>
>
> On Thu, May 20, 2010 at 10:18 AM, James Gan <ganzhi at gmail.com> wrote:
>> A nice example! A follow-up open question: is it possible to detect
>> such error by atomatic tool? Seems very difficult!
>>
>> On Thu, May 20, 2010 at 12:24 PM, Enno Shioji <eshioji at gmail.com> wrote:
>>> A very silly (but it happens! I've seen one like this before) example would be:
>>>
>>>
>>> class Auth {
>>> ? ?private boolean clearance = false;
>>>
>>> ? ?public void authenticate(){
>>> ? ? ? ?this.clearance = true;
>>> ? ?}
>>>
>>> ? ?public void deauthenticate(){
>>> ? ? ? ?this.clearance = false;
>>> ? ?}
>>>
>>> ? ?public String readSecretData(){
>>> ? ? ? ? if(clearance){
>>> ? ? ? ? ? ? return "Company secret";
>>> ? ? ? ? }else{
>>> ? ? ? ? ? ? return "Gotcha, hacker!";
>>> ? ? ? ? }
>>> ? ?}
>>>
>>> And then Auth is made a singleton because "It will increase
>>> performance!*" and these three methods are called from random number
>>> of threads. Then users without clearance will start to see secret data
>>> occasionally.
>>>
>>> *: Making a class a singleton doesn't make things faster in most of the cases..
>>>
>>>
>>> Regards,
>>> Enno
>>>
>>>
>>>
>>> On Thu, May 20, 2010 at 9:24 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>> An unidentified poster writes:
>>>>> I am investigating an interesting topic: if the concurrency can harm
>>>> software security.
>>>>> Is there any software security issue ?stemming from concurrency?
>>>>
>>>> Yes. In poorly constructed systems race conditions could lead to various
>>>> invariant violations, including those pertaining to "security".
>>>>
>>>> In a platform like Java, the programming language must ensure there are some
>>>> basic guarantees even in the face of race conditions. For Java this is
>>>> defined as part of the Java Memory Model, which ensures that you can't see
>>>> uninitialized fields (though they may be default initialized), and provides
>>>> for correct visibility of final fields.
>>>>
>>>> But even if the language provides basic guarantees, it is up to classes to
>>>> use the language facilities correctly to ensure that they can't be
>>>> compromised by race conditions induced by client code.
>>>>
>>>> And of course the runtime system (for Java that's the VM) must also be
>>>> written correctly to ensure no concurrency related security holes exist.
>>>>
>>>> Hope this gives you enough to do a proper investigation. ;-)
>>>>
>>>> David Holmes
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>> Best Regards
>> James Gan
>> Current Project: Concurrent Building Block at http://amino-cbbs.sourceforge.net/
>> Blog: http://ganzhi.blogspot.com
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Yao Qi <qiyaoltc AT gmail DOT com>    GNU/Linux Developer
http://duewayqi.googlepages.com/


From martinrb at google.com  Thu May 20 01:47:19 2010
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 May 2010 22:47:19 -0700
Subject: [concurrency-interest] ThreadPoolExecutor - Concurrent "Batch"
	Executions
In-Reply-To: <231839.4100.qm@web110210.mail.gq1.yahoo.com>
References: <4BF44511.7060400@cytetech.com>
	<231839.4100.qm@web110210.mail.gq1.yahoo.com>
Message-ID: <AANLkTikYDRsNs-ueNKSDCyQm1FDW5m18Vt7kFrCsAKCg@mail.gmail.com>

Is this what you're looking for?

http://java.sun.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html#invokeAll(java.util.Collection,
long, java.util.concurrent.TimeUnit)

Martin

On Wed, May 19, 2010 at 20:13, Mike Boyers <mboyers at yahoo.com> wrote:
> I'm building a service where, in order to generate each response, I'll need to go against several remote sources. ?In many cases, the remote requests can be made concurrently.
>
> I'm looking for a super simple interface where developers can execute these remote requests in parallel while being blocked as they execute, with the ability to time out after a specified period.
>
> As a (very) rough idea:
>
> Collection batch = new LinkedList();
> batch.add(new RemoteRequest1());
> batch.add(new RemoteRequest2());
> batch.add(new RemoteRequest3());
> Batcher.execute(batch, 5, TimeUnit.SECONDS);
>
> The Batcher.execute call blocks until either all of the tasks are complete or until 10 seconds passes.
>
> I can see how to use a ThreadPoolExecutor to accomplish this, by submitting each Callable then waiting on the Future objects returned upon submit, meanwhile keeping track of the overall amount of time I've waited as I wait on each Future. ?While this logic isn't overly complicated, I'd still like to keep it housed and supply developers with something like I outlined above.
>
> But before building this "wrapper", I figure I'd ask to see if there's already something existing I should be looking at, either in the concurrent package or elsewhere (or if I should be thinking about this in a completely different way).
>
> Thanks,
> Mike
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From qiyaoltc at gmail.com  Thu May 20 01:47:57 2010
From: qiyaoltc at gmail.com (Yao Qi)
Date: Thu, 20 May 2010 13:47:57 +0800
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>
References: <AANLkTikfAx6WxE6wJVvfJALQKwVt11bjdKljtwBWSV6U@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTinxU3rheL1tgt7GCe7VH5q8z2LPoK8cFKqdQucp@mail.gmail.com>

On Thu, May 20, 2010 at 1:04 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> James Gan writes:
>> Yes, data race tool can detect this problem. On the other hand, even
>> if we fixed the data race problem by adding synchronization, it's
>> still a security problem.
>
> Oops! Indeed. Even with sync the API is fatally flawed.
>
> I don't know if the tools will be able to detect the inherent check-then-act
> sequence.

David, this kind of error is regarded as "atomic violation".  I don't
know either if tools can detect such errors *accurately* and
*efficiently*, even there are a lot of papers on this topic.

>
> David
>
-- 
Yao Qi <qiyaoltc AT gmail DOT com>    GNU/Linux Developer
http://duewayqi.googlepages.com/

From fslzdd at gmail.com  Thu May 20 03:56:43 2010
From: fslzdd at gmail.com (=?GB2312?B?tO/X0w==?=)
Date: Thu, 20 May 2010 15:56:43 +0800
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>
References: <AANLkTinT1W54geTPQT3VE519lxph9fFuvgPgKzlj-TGh@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEHPIGAA.davidcholmes@aapt.net.au>
	<AANLkTilg_JgKG9XOBR17LfOExYPmxswW6KNUw_tP9WoW@mail.gmail.com>
Message-ID: <AANLkTinViuiHIhGpzfCH6XfZueBnrq-e2cewFh9jjj2m@mail.gmail.com>

Good example! But the reason why the race condition in this example can
cause security problem is that it can expose sensitive data to user. What if
the race condition only affects some internal states? In this case, it's not
related to security, but an internal error. I wonder how tools can identify
if the race condition is security related or not.

2010/5/20 Enno Shioji <eshioji at gmail.com>

> A very silly (but it happens! I've seen one like this before) example would
> be:
>
>
> class Auth {
>    private boolean clearance = false;
>
>    public void authenticate(){
>        this.clearance = true;
>    }
>
>    public void deauthenticate(){
>        this.clearance = false;
>    }
>
>    public String readSecretData(){
>         if(clearance){
>             return "Company secret";
>         }else{
>             return "Gotcha, hacker!";
>         }
>    }
>
> And then Auth is made a singleton because "It will increase
> performance!*" and these three methods are called from random number
> of threads. Then users without clearance will start to see secret data
> occasionally.
>
> *: Making a class a singleton doesn't make things faster in most of the
> cases..
>
>
> Regards,
> Enno
>
>
>
> On Thu, May 20, 2010 at 9:24 AM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
> > An unidentified poster writes:
> >> I am investigating an interesting topic: if the concurrency can harm
> > software security.
> >> Is there any software security issue  stemming from concurrency?
> >
> > Yes. In poorly constructed systems race conditions could lead to various
> > invariant violations, including those pertaining to "security".
> >
> > In a platform like Java, the programming language must ensure there are
> some
> > basic guarantees even in the face of race conditions. For Java this is
> > defined as part of the Java Memory Model, which ensures that you can't
> see
> > uninitialized fields (though they may be default initialized), and
> provides
> > for correct visibility of final fields.
> >
> > But even if the language provides basic guarantees, it is up to classes
> to
> > use the language facilities correctly to ensure that they can't be
> > compromised by race conditions induced by client code.
> >
> > And of course the runtime system (for Java that's the VM) must also be
> > written correctly to ensure no concurrency related security holes exist.
> >
> > Hope this gives you enough to do a proper investigation. ;-)
> >
> > David Holmes
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100520/d6014c8c/attachment.html>

From davidcholmes at aapt.net.au  Thu May 20 05:18:03 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 20 May 2010 19:18:03 +1000
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTinViuiHIhGpzfCH6XfZueBnrq-e2cewFh9jjj2m@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEICIGAA.davidcholmes@aapt.net.au>

It is extremely difficult for a general-purpose tool to know the
significance of a race condition or any other coding error (it would need to
understand the semantics of operations involved). But if you have no data
races you've eliminated one source of potential problems.

David Holmes

-----Original Message-----
From: ???? [mailto:fslzdd at gmail.com]
Sent: Thursday, 20 May 2010 5:57 PM
To: Enno Shioji
Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Concurrency and security


  Good example! But the reason why the race condition in this example can
cause security problem is that it can expose sensitive data to user. What if
the race condition only affects some internal states? In this case, it's not
related to security, but an internal error. I wonder how tools can identify
if the race condition is security related or not.


  2010/5/20 Enno Shioji <eshioji at gmail.com>

    A very silly (but it happens! I've seen one like this before) example
would be:


    class Auth {
       private boolean clearance = false;

       public void authenticate(){
           this.clearance = true;
       }

       public void deauthenticate(){
           this.clearance = false;
       }

       public String readSecretData(){
            if(clearance){
                return "Company secret";
            }else{
                return "Gotcha, hacker!";
            }
       }

    And then Auth is made a singleton because "It will increase
    performance!*" and these three methods are called from random number
    of threads. Then users without clearance will start to see secret data
    occasionally.

    *: Making a class a singleton doesn't make things faster in most of the
cases..


    Regards,
    Enno




    On Thu, May 20, 2010 at 9:24 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:
    > An unidentified poster writes:
    >> I am investigating an interesting topic: if the concurrency can harm
    > software security.
    >> Is there any software security issue  stemming from concurrency?
    >
    > Yes. In poorly constructed systems race conditions could lead to
various
    > invariant violations, including those pertaining to "security".
    >
    > In a platform like Java, the programming language must ensure there
are some
    > basic guarantees even in the face of race conditions. For Java this is
    > defined as part of the Java Memory Model, which ensures that you can't
see
    > uninitialized fields (though they may be default initialized), and
provides
    > for correct visibility of final fields.
    >
    > But even if the language provides basic guarantees, it is up to
classes to
    > use the language facilities correctly to ensure that they can't be
    > compromised by race conditions induced by client code.
    >
    > And of course the runtime system (for Java that's the VM) must also be
    > written correctly to ensure no concurrency related security holes
exist.
    >
    > Hope this gives you enough to do a proper investigation. ;-)
    >
    > David Holmes
    >
    > _______________________________________________
    > Concurrency-interest mailing list
    > Concurrency-interest at cs.oswego.edu
    > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    >

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100520/8bb86567/attachment.html>

From stuff at kai.meder.info  Thu May 20 06:19:16 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Thu, 20 May 2010 12:19:16 +0200
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <AANLkTinxU3rheL1tgt7GCe7VH5q8z2LPoK8cFKqdQucp@mail.gmail.com>
References: <AANLkTikfAx6WxE6wJVvfJALQKwVt11bjdKljtwBWSV6U@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>
	<AANLkTinxU3rheL1tgt7GCe7VH5q8z2LPoK8cFKqdQucp@mail.gmail.com>
Message-ID: <4BF50CA4.7030708@kai.meder.info>

On 20.05.2010 07:47, Yao Qi wrote:
>> Oops! Indeed. Even with sync the API is fatally flawed.
>>
>> I don't know if the tools will be able to detect the inherent check-then-act
>> sequence.
> 
> David, this kind of error is regarded as "atomic violation".  I don't
> know either if tools can detect such errors *accurately* and
> *efficiently*, even there are a lot of papers on this topic.

May anyone post a simple yet non-flawed API avoiding check-then-act?

Thanks, Kai

From davidcholmes at aapt.net.au  Thu May 20 06:28:19 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 20 May 2010 20:28:19 +1000
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <4BF50CA4.7030708@kai.meder.info>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEIEIGAA.davidcholmes@aapt.net.au>

Kai Meder writes:
> On 20.05.2010 07:47, Yao Qi wrote:
> >> Oops! Indeed. Even with sync the API is fatally flawed.
> >>
> >> I don't know if the tools will be able to detect the inherent
> >>check-then-act sequence.
> >
> > David, this kind of error is regarded as "atomic violation".  I don't
> > know either if tools can detect such errors *accurately* and
> > *efficiently*, even there are a lot of papers on this topic.
>
> May anyone post a simple yet non-flawed API avoiding check-then-act?

For the authentication example you need to know what it is that is being
authenticated and what authentication means. In that simple example anyone
could call authenticate() so there was no real security anyway.

One simple approach is to associate an authentication token with a thread,
and the methods that need the caller to be authenticated can check that
token - typically stored via a thread-local.

Another is to make the token explicit and pass it around as a "security
context" as a parameter to each method called. That way many threads can
share the same token if appropriate.

Real authentication is much more complicated than these simplistic
suggestions and getting somewhat off-topic.

Cheers,
David Holmes


From mboyers at yahoo.com  Thu May 20 07:48:19 2010
From: mboyers at yahoo.com (Mike Boyers)
Date: Thu, 20 May 2010 04:48:19 -0700 (PDT)
Subject: [concurrency-interest] ThreadPoolExecutor - Concurrent "Batch"
	Executions
In-Reply-To: <AANLkTikYDRsNs-ueNKSDCyQm1FDW5m18Vt7kFrCsAKCg@mail.gmail.com>
Message-ID: <3414.87021.qm@web110206.mail.gq1.yahoo.com>

Yes, thanks.  I had a feeling it was right in front of me, which is what prompted me to ask (even though I'm embarrassed that it's a method in the very class I was looking at).

I notice that when using invokeAll and setting a timeout, it will cancel any tasks that haven't completed if it does indeed time out.  In my case, I'm thinking there may be value in going ahead and letting them complete, because the remote response will be cached and will likely be useful for on a subsequent request -- i.e., letting it complete could save me from having to make the same remote call later on.

Thanks again,
Mike

--- On Thu, 5/20/10, Martin Buchholz <martinrb at google.com> wrote:

> From: Martin Buchholz <martinrb at google.com>
> Subject: Re: [concurrency-interest] ThreadPoolExecutor - Concurrent "Batch"  Executions
> To: "Mike Boyers" <mboyers at yahoo.com>
> Cc: concurrency-interest at cs.oswego.edu
> Date: Thursday, May 20, 2010, 1:47 AM
> Is this what you're looking for?
> 
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html#invokeAll(java.util.Collection,
> long, java.util.concurrent.TimeUnit)
> 
> Martin
> 
> On Wed, May 19, 2010 at 20:13, Mike Boyers <mboyers at yahoo.com>
> wrote:
> > I'm building a service where, in order to generate
> each response, I'll need to go against several remote
> sources. ?In many cases, the remote requests can be made
> concurrently.
> >
> > I'm looking for a super simple interface where
> developers can execute these remote requests in parallel
> while being blocked as they execute, with the ability to
> time out after a specified period.
> >
> > As a (very) rough idea:
> >
> > Collection batch = new LinkedList();
> > batch.add(new RemoteRequest1());
> > batch.add(new RemoteRequest2());
> > batch.add(new RemoteRequest3());
> > Batcher.execute(batch, 5, TimeUnit.SECONDS);
> >
> > The Batcher.execute call blocks until either all of
> the tasks are complete or until 10 seconds passes.
> >
> > I can see how to use a ThreadPoolExecutor to
> accomplish this, by submitting each Callable then waiting on
> the Future objects returned upon submit, meanwhile keeping
> track of the overall amount of time I've waited as I wait on
> each Future. ?While this logic isn't overly complicated,
> I'd still like to keep it housed and supply developers with
> something like I outlined above.
> >
> > But before building this "wrapper", I figure I'd ask
> to see if there's already something existing I should be
> looking at, either in the concurrent package or elsewhere
> (or if I should be thinking about this in a completely
> different way).
> >
> > Thanks,
> > Mike
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> 


      


From vincent.gramoli at epfl.ch  Thu May 20 08:09:39 2010
From: vincent.gramoli at epfl.ch (Vincent Gramoli)
Date: Thu, 20 May 2010 14:09:39 +0200
Subject: [concurrency-interest] Asynchronous-nature of
	ConcurrentLinkedQueue
In-Reply-To: <mailman.1.1274198400.26512.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1274198400.26512.concurrency-interest@cs.oswego.edu>
Message-ID: <CACA7269-B1B1-42E9-B678-FE1F56AA70D5@epfl.ch>


> Date: Tue, 18 May 2010 08:17:46 -0400
> From: Doug Lea <dl at cs.oswego.edu>
> Subject: Re: [concurrency-interest] Asynchronous-nature of
> 	ConcurrentLinkedQueue
> To: concurrency-interest at cs.oswego.edu
> Message-ID: <4BF2856A.2020704 at cs.oswego.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> On 05/18/10 08:03, Kai Meder wrote:
>> Hello
>> 
>> reading the Java-Docs of ConcurrentLinkedQueue I wonder what the
>> "asynchronous nature" mentioned in the size()-doc is?
>> 
>> "Beware that, unlike in most collections, this method is NOT a
>> constant-time operation. Because of the asynchronous nature of these
>> queues, determining the current number of elements requires an O(n)
>> traversal. "
>> 
> 
> Because insertion and removal operations can occur concurrently
> (even while you are asking about the size), you generally
> don't want to ask about the size (although isEmpty is usually
> still useful). But if you do ask, the queue
> will provide an answer by counting up the elements. The
> answer it returns might not have much bearing to the actual
> number of elements upon return of the method.
> 
> -Doug



Hello, 

I am currently working on some Software Transactional Memory solution for high-level Java abstractions that tolerate these issues. I have noticed that j.u.c.ConcurrentLinkedQueue.size() is not atomic. More precisely, even though the retuned value of the size method is not accurate at the time the method returns (as you mentioned), size() does not even provide the atomic snapshot semantics one would expect. I understand that its usage might be quite rare in practice, yet I was rather concerned by its "unexpected" semantics.

Consider the following example. If i threads run concurrently, each subsequently removing and inserting multiple times, say x times, while an (i+1)st tries to compute the size of the data structure, then the size may return in the worst case a value that has an offset error of i(x-1) even though the size experienced actually a variation of (more or less) i. I tested it.

Wouldn't it be clearer to add to the ConcurrentLinkedQueue.size() doc the sentence "Additionally, it is possible for the size to change during execution of this method, in which case the returned result will be inaccurate. Thus, this method is typically not very useful in concurrent applications." taken from ConcurrentSkipListMap.size().
Another reason is that this non-atomicity problem does not arise in ConcurrentHashMap.size() due to the stripping metadata, if I remember correctly.

Vincent Gramoli

From dl at cs.oswego.edu  Thu May 20 08:44:14 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 20 May 2010 08:44:14 -0400
Subject: [concurrency-interest] Asynchronous-nature
	of	ConcurrentLinkedQueue
In-Reply-To: <CACA7269-B1B1-42E9-B678-FE1F56AA70D5@epfl.ch>
References: <mailman.1.1274198400.26512.concurrency-interest@cs.oswego.edu>
	<CACA7269-B1B1-42E9-B678-FE1F56AA70D5@epfl.ch>
Message-ID: <4BF52E9E.30308@cs.oswego.edu>

On 05/20/10 08:09, Vincent Gramoli wrote:
> Wouldn't it be clearer to add to the ConcurrentLinkedQueue.size() doc the
> sentence "Additionally, it is possible for the size to change during
> execution of this method, in which case the returned result will be
> inaccurate. Thus, this method is typically not very useful in concurrent
> applications." taken from ConcurrentSkipListMap.size().

This is a good idea; thanks.

It would be almost equally good to throw some exception if
concurrent data structures were not quiescent when computing size
(BTW, AbstractCollection does this for implementations
that do not override size()). But we decided that providing
SOME answer was a better policy, so that the method is
useful for occasional monitoring purposes and the like.

Also BTW, there have been a few papers on getting accurate
size snapshots for such structures, including one in DISC
last year (see http://www.cs.tau.ac.il/research/moran.tzafrir/).
But none of them seem to be plausible candidates for inclusion
because they add overhead to other methods as well. As David Holmes
mentioned, we don't want to penalize all users of an implementation
for the sake of those very few (perhaps no one!) who truly
need an accurate snapshot value.

-Doug



From gregg at cytetech.com  Thu May 20 17:05:28 2010
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 20 May 2010 16:05:28 -0500
Subject: [concurrency-interest] Concurrency and security
In-Reply-To: <4BF50CA4.7030708@kai.meder.info>
References: <AANLkTikfAx6WxE6wJVvfJALQKwVt11bjdKljtwBWSV6U@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEIBIGAA.davidcholmes@aapt.net.au>
	<AANLkTinxU3rheL1tgt7GCe7VH5q8z2LPoK8cFKqdQucp@mail.gmail.com>
	<4BF50CA4.7030708@kai.meder.info>
Message-ID: <4BF5A418.2040804@cytetech.com>

Kai Meder wrote:
> On 20.05.2010 07:47, Yao Qi wrote:
>>> Oops! Indeed. Even with sync the API is fatally flawed.
>>>
>>> I don't know if the tools will be able to detect the inherent check-then-act
>>> sequence.
>> David, this kind of error is regarded as "atomic violation".  I don't
>> know either if tools can detect such errors *accurately* and
>> *efficiently*, even there are a lot of papers on this topic.
> 
> May anyone post a simple yet non-flawed API avoiding check-then-act?

There are two ways that you really should manage secure execution in Java.

To limit what a user can do, use Subject.doAs() with a JAAS authenticated 
javax.auth.security.Subject to allow permission checks to consider the 
Principal(s) represented in the Subject.

To perform actions on behalf of a user that you want to override their 
permissions with, use AccessController.doPrivileged(), which will use the 
privileges granted to the AccessControlContext of the class making such calls, 
instead of using the AccessControlContext of the thread and classes calling into 
such code.

Examples like this should really no longer be used.  JAAS really makes it 
possible to do things much more securely by using Principal(s) and/or 
AccessControlContext(s) of the threads so that there is no "global" access 
control performed and thus no concurrently mutated access control.

Gregg Wonderly

From lukas.krecan at gmail.com  Tue May 25 03:07:03 2010
From: lukas.krecan at gmail.com (Lukas Krecan)
Date: Tue, 25 May 2010 09:07:03 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an uniform
	array
Message-ID: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>

 Hi,
   I have been playing with extra166y library and found that when I try to
sort an uniform array (full of ones) it takes ages. With older version of
the library it even threw StackOverflowError. After update it runs for
minutes (I always kill the process after while so I do not know if it ends
successfully).

Probably it's nothing new for you, maybe it's expected behaviour. But for me
it's confusing and I just wanted to let you know about the issue in case you
were not aware of it.
      Best regards
        Lukas Krecan

-------------------------------------
package net.krecan.forkjoin;

import java.util.Random;

import jsr166y.ForkJoinPool;
import extra166y.Ops;
import extra166y.ParallelLongArray;


public class SortTest {
    private static final int THREADS = 2;
    private static final int SIZE = 40000000;

    public static void testSort()
    {
        ForkJoinPool fjPool = new ForkJoinPool(THREADS);
        ParallelLongArray pa = ParallelLongArray.createEmpty(SIZE, fjPool);
        createData(pa);
        System.out.println("Sorting "+pa.summary());
        long start = System.currentTimeMillis();
        pa.sort();
        System.out.println("Done in
"+(System.currentTimeMillis()-start)+"ms.");
        System.out.println(pa.summary());


    }
    private static void createData(ParallelLongArray pa) {
        long start = System.currentTimeMillis();
        System.out.println("Creating data using "+THREADS+" threads.");
        pa.setLimit(SIZE);
        final Random rand = new Random();
        pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
            public synchronized long op() {
                return 1L;//rand.nextLong();
            }
        });
        System.out.println("Done in
"+(System.currentTimeMillis()-start)+"ms.");
    }

    public static void main(String[] args) {
        testSort();
    }

}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100525/94d80673/attachment.html>

From kasper at kav.dk  Tue May 25 04:00:15 2010
From: kasper at kav.dk (Kasper Nielsen)
Date: Tue, 25 May 2010 10:00:15 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an
 uniform array
In-Reply-To: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
Message-ID: <4BFB838F.2000100@kav.dk>

Hi Lukas,

try removing the synchronized keyword in your op.

Taken from the extra166y.Ops javadoc:

In addition to stated signatures, implementations of these interfaces 
must work safely in parallel. In general, this means methods should 
operate only on their arguments, and should not rely on ThreadLocals, 
unsafely published globals, or other unsafe constructions. Additionally, 
they should not block waiting for synchronization.

If you want to return random numbers you should use the ThreadLocalRandom.


- Kasper

On 25/5/2010 07:9, Lukas Krecan wrote:
> Hi,
>     I have been playing with extra166y library and found that when I try
> to sort an uniform array (full of ones) it takes ages. With older
> version of the library it even threw StackOverflowError. After update it
> runs for minutes (I always kill the process after while so I do not know
> if it ends successfully).
>
> Probably it's nothing new for you, maybe it's expected behaviour. But
> for me it's confusing and I just wanted to let you know about the issue
> in case you were not aware of it.
>        Best regards
>          Lukas Krecan
>
> -------------------------------------
> package net.krecan.forkjoin;
>
> import java.util.Random;
>
> import jsr166y.ForkJoinPool;
> import extra166y.Ops;
> import extra166y.ParallelLongArray;
>
>
> public class SortTest {
>      private static final int THREADS = 2;
>      private static final int SIZE = 40000000;
>
>      public static void testSort()
>      {
>          ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>          ParallelLongArray pa = ParallelLongArray.createEmpty(SIZE,
> fjPool);
>          createData(pa);
>          System.out.println("Sorting "+pa.summary());
>          long start = System.currentTimeMillis();
>          pa.sort();
>          System.out.println("Done in
> "+(System.currentTimeMillis()-start)+"ms.");
>          System.out.println(pa.summary());
>
>
>      }
>      private static void createData(ParallelLongArray pa) {
>          long start = System.currentTimeMillis();
>          System.out.println("Creating data using "+THREADS+" threads.");
>          pa.setLimit(SIZE);
>          final Random rand = new Random();
>          pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>              public synchronized long op() {
>                  return 1L;//rand.nextLong();
>              }
>          });
>          System.out.println("Done in
> "+(System.currentTimeMillis()-start)+"ms.");
>      }
>
>      public static void main(String[] args) {
>          testSort();
>      }
>
> }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From lukas.krecan at gmail.com  Tue May 25 04:15:25 2010
From: lukas.krecan at gmail.com (Lukas Krecan)
Date: Tue, 25 May 2010 10:15:25 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an
	uniform array
In-Reply-To: <4BFB838F.2000100@kav.dk>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
	<4BFB838F.2000100@kav.dk>
Message-ID: <AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>

Hi,
   I am quite sure that it has nothing to do the synchronization. The
problem remains even if synchronized keyword is removed. Besides, the method
was used only for generating values, which works well. Problem is with
sorting. It works well on random values, but runs for ages on uniform array.


On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen <kasper at kav.dk> wrote:

> Hi Lukas,
>
> try removing the synchronized keyword in your op.
>
> Taken from the extra166y.Ops javadoc:
>
> In addition to stated signatures, implementations of these interfaces must
> work safely in parallel. In general, this means methods should operate only
> on their arguments, and should not rely on ThreadLocals, unsafely published
> globals, or other unsafe constructions. Additionally, they should not block
> waiting for synchronization.
>
> If you want to return random numbers you should use the ThreadLocalRandom.
>
>
> - Kasper
>
>
> On 25/5/2010 07:9, Lukas Krecan wrote:
>
>> Hi,
>>    I have been playing with extra166y library and found that when I try
>> to sort an uniform array (full of ones) it takes ages. With older
>> version of the library it even threw StackOverflowError. After update it
>> runs for minutes (I always kill the process after while so I do not know
>> if it ends successfully).
>>
>> Probably it's nothing new for you, maybe it's expected behaviour. But
>> for me it's confusing and I just wanted to let you know about the issue
>> in case you were not aware of it.
>>       Best regards
>>         Lukas Krecan
>>
>> -------------------------------------
>> package net.krecan.forkjoin;
>>
>> import java.util.Random;
>>
>> import jsr166y.ForkJoinPool;
>> import extra166y.Ops;
>> import extra166y.ParallelLongArray;
>>
>>
>> public class SortTest {
>>     private static final int THREADS = 2;
>>     private static final int SIZE = 40000000;
>>
>>     public static void testSort()
>>     {
>>         ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>>         ParallelLongArray pa = ParallelLongArray.createEmpty(SIZE,
>> fjPool);
>>         createData(pa);
>>         System.out.println("Sorting "+pa.summary());
>>         long start = System.currentTimeMillis();
>>         pa.sort();
>>         System.out.println("Done in
>> "+(System.currentTimeMillis()-start)+"ms.");
>>         System.out.println(pa.summary());
>>
>>
>>     }
>>     private static void createData(ParallelLongArray pa) {
>>         long start = System.currentTimeMillis();
>>         System.out.println("Creating data using "+THREADS+" threads.");
>>         pa.setLimit(SIZE);
>>         final Random rand = new Random();
>>         pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>>             public synchronized long op() {
>>                 return 1L;//rand.nextLong();
>>             }
>>         });
>>         System.out.println("Done in
>> "+(System.currentTimeMillis()-start)+"ms.");
>>     }
>>
>>     public static void main(String[] args) {
>>         testSort();
>>     }
>>
>> }
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100525/c4987fce/attachment.html>

From davidcholmes at aapt.net.au  Tue May 25 04:45:26 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 25 May 2010 18:45:26 +1000
Subject: [concurrency-interest] Strange behaviour when sorting anuniform
	array
In-Reply-To: <AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEJKIGAA.davidcholmes@aapt.net.au>

I'm sure Doug will respond once his timezone is awake :) but some sorting
algorithms exhibit their worst performance when given already sorted data.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Lukas Krecan
  Sent: Tuesday, 25 May 2010 6:15 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Strange behaviour when sorting
anuniform array


  Hi,
     I am quite sure that it has nothing to do the synchronization. The
problem remains even if synchronized keyword is removed. Besides, the method
was used only for generating values, which works well. Problem is with
sorting. It works well on random values, but runs for ages on uniform array.



  On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen <kasper at kav.dk> wrote:

    Hi Lukas,

    try removing the synchronized keyword in your op.

    Taken from the extra166y.Ops javadoc:

    In addition to stated signatures, implementations of these interfaces
must work safely in parallel. In general, this means methods should operate
only on their arguments, and should not rely on ThreadLocals, unsafely
published globals, or other unsafe constructions. Additionally, they should
not block waiting for synchronization.

    If you want to return random numbers you should use the
ThreadLocalRandom.


    - Kasper


    On 25/5/2010 07:9, Lukas Krecan wrote:

      Hi,
         I have been playing with extra166y library and found that when I
try
      to sort an uniform array (full of ones) it takes ages. With older
      version of the library it even threw StackOverflowError. After update
it
      runs for minutes (I always kill the process after while so I do not
know
      if it ends successfully).

      Probably it's nothing new for you, maybe it's expected behaviour. But
      for me it's confusing and I just wanted to let you know about the
issue
      in case you were not aware of it.
            Best regards
              Lukas Krecan

      -------------------------------------
      package net.krecan.forkjoin;

      import java.util.Random;

      import jsr166y.ForkJoinPool;
      import extra166y.Ops;
      import extra166y.ParallelLongArray;


      public class SortTest {
          private static final int THREADS = 2;
          private static final int SIZE = 40000000;

          public static void testSort()
          {
              ForkJoinPool fjPool = new ForkJoinPool(THREADS);
              ParallelLongArray pa = ParallelLongArray.createEmpty(SIZE,
      fjPool);
              createData(pa);
              System.out.println("Sorting "+pa.summary());
              long start = System.currentTimeMillis();
              pa.sort();
              System.out.println("Done in
      "+(System.currentTimeMillis()-start)+"ms.");
              System.out.println(pa.summary());


          }
          private static void createData(ParallelLongArray pa) {
              long start = System.currentTimeMillis();
              System.out.println("Creating data using "+THREADS+"
threads.");
              pa.setLimit(SIZE);
              final Random rand = new Random();
              pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
                  public synchronized long op() {
                      return 1L;//rand.nextLong();
                  }
              });
              System.out.println("Done in
      "+(System.currentTimeMillis()-start)+"ms.");
          }

          public static void main(String[] args) {
              testSort();
          }

      }




      _______________________________________________
      Concurrency-interest mailing list
      Concurrency-interest at cs.oswego.edu
      http://cs.oswego.edu/mailman/listinfo/concurrency-interest


    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100525/2d41b841/attachment-0001.html>

From kasper at kav.dk  Tue May 25 05:44:10 2010
From: kasper at kav.dk (Kasper Nielsen)
Date: Tue, 25 May 2010 11:44:10 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an
 uniform array
In-Reply-To: <AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
	<4BFB838F.2000100@kav.dk>
	<AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>
Message-ID: <4BFB9BEA.8040804@kav.dk>

Ahh, got it. You still want to remove that synchronized statement for 
serious usage though.

What you are seing is the worst case behavior for quicksort which 
ParallelArray is using under the hood. All equal elements will kill most 
quicksort implementations. Instead of the average running time of n*logn 
you are seing worst case behaviour of n*n.

Even large datasets with just a few different values will slow most 
implementations down significantly.
I tried replacing
   return 1L;//rand.nextLong();
with
   return rand.nextInt(20)
and PA was still around 70 times slower compared to using rand.nextLong().

We might want to switch to the dual pivot implementation introduced in 
OpenJDK 7. Don't know about licensing issues though.

- Kasper


On 25/5/2010 15:10, Lukas Krecan wrote:
> Hi,
>     I am quite sure that it has nothing to do the synchronization. The
> problem remains even if synchronized keyword is removed. Besides, the
> method was used only for generating values, which works well. Problem is
> with sorting. It works well on random values, but runs for ages on
> uniform array.
>
>
> On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen <kasper at kav.dk
> <mailto:kasper at kav.dk>> wrote:
>
>     Hi Lukas,
>
>     try removing the synchronized keyword in your op.
>
>     Taken from the extra166y.Ops javadoc:
>
>     In addition to stated signatures, implementations of these
>     interfaces must work safely in parallel. In general, this means
>     methods should operate only on their arguments, and should not rely
>     on ThreadLocals, unsafely published globals, or other unsafe
>     constructions. Additionally, they should not block waiting for
>     synchronization.
>
>     If you want to return random numbers you should use the
>     ThreadLocalRandom.
>
>
>     - Kasper
>
>
>     On 25/5/2010 07:9, Lukas Krecan wrote:
>
>         Hi,
>             I have been playing with extra166y library and found that
>         when I try
>         to sort an uniform array (full of ones) it takes ages. With older
>         version of the library it even threw StackOverflowError. After
>         update it
>         runs for minutes (I always kill the process after while so I do
>         not know
>         if it ends successfully).
>
>         Probably it's nothing new for you, maybe it's expected
>         behaviour. But
>         for me it's confusing and I just wanted to let you know about
>         the issue
>         in case you were not aware of it.
>                Best regards
>                  Lukas Krecan
>
>         -------------------------------------
>         package net.krecan.forkjoin;
>
>         import java.util.Random;
>
>         import jsr166y.ForkJoinPool;
>         import extra166y.Ops;
>         import extra166y.ParallelLongArray;
>
>
>         public class SortTest {
>              private static final int THREADS = 2;
>              private static final int SIZE = 40000000;
>
>              public static void testSort()
>              {
>                  ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>                  ParallelLongArray pa = ParallelLongArray.createEmpty(SIZE,
>         fjPool);
>                  createData(pa);
>                  System.out.println("Sorting "+pa.summary());
>                  long start = System.currentTimeMillis();
>                  pa.sort();
>                  System.out.println("Done in
>         "+(System.currentTimeMillis()-start)+"ms.");
>                  System.out.println(pa.summary());
>
>
>              }
>              private static void createData(ParallelLongArray pa) {
>                  long start = System.currentTimeMillis();
>                  System.out.println("Creating data using "+THREADS+"
>         threads.");
>                  pa.setLimit(SIZE);
>                  final Random rand = new Random();
>                  pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>                      public synchronized long op() {
>                          return 1L;//rand.nextLong();
>                      }
>                  });
>                  System.out.println("Done in
>         "+(System.currentTimeMillis()-start)+"ms.");
>              }
>
>              public static void main(String[] args) {
>                  testSort();
>              }
>
>         }
>
>
>
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From lukas.krecan at gmail.com  Tue May 25 07:00:55 2010
From: lukas.krecan at gmail.com (Lukas Krecan)
Date: Tue, 25 May 2010 13:00:55 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an
 uniform array
In-Reply-To: <4BFB9BEA.8040804@kav.dk>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>	<4BFB838F.2000100@kav.dk>	<AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>
	<4BFB9BEA.8040804@kav.dk>
Message-ID: <4BFBADE7.4050108@gmail.com>

Sure, the synchronized statement is just a leftover from previous 
experiments.

I have tried the same test with standard java.util.Arrays.sort and I am 
getting

1) Uniform array (full of 1L) ~ 200ms
2) rand.nextInt(20) ~ 1400ms
3) rand.nextLong() ~ 7700ms

The reason might be that a modified quicksort algorithm is used there. 
Would it be possible to use the same algorithm for ParallelArray? I am 
afraid that most programmers have already forgotten the details of 
sorting algorithms and would be as surprised as I was.
       Cheers
            Lukas

On 05/25/2010 11:44 AM, Kasper Nielsen wrote:
> Ahh, got it. You still want to remove that synchronized statement for 
> serious usage though.
>
> What you are seing is the worst case behavior for quicksort which 
> ParallelArray is using under the hood. All equal elements will kill 
> most quicksort implementations. Instead of the average running time of 
> n*logn you are seing worst case behaviour of n*n.
>
> Even large datasets with just a few different values will slow most 
> implementations down significantly.
> I tried replacing
>   return 1L;//rand.nextLong();
> with
>   return rand.nextInt(20)
> and PA was still around 70 times slower compared to using 
> rand.nextLong().
>
> We might want to switch to the dual pivot implementation introduced in 
> OpenJDK 7. Don't know about licensing issues though.
>
> - Kasper
>
>
> On 25/5/2010 15:10, Lukas Krecan wrote:
>> Hi,
>>     I am quite sure that it has nothing to do the synchronization. The
>> problem remains even if synchronized keyword is removed. Besides, the
>> method was used only for generating values, which works well. Problem is
>> with sorting. It works well on random values, but runs for ages on
>> uniform array.
>>
>>
>> On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen <kasper at kav.dk
>> <mailto:kasper at kav.dk>> wrote:
>>
>>     Hi Lukas,
>>
>>     try removing the synchronized keyword in your op.
>>
>>     Taken from the extra166y.Ops javadoc:
>>
>>     In addition to stated signatures, implementations of these
>>     interfaces must work safely in parallel. In general, this means
>>     methods should operate only on their arguments, and should not rely
>>     on ThreadLocals, unsafely published globals, or other unsafe
>>     constructions. Additionally, they should not block waiting for
>>     synchronization.
>>
>>     If you want to return random numbers you should use the
>>     ThreadLocalRandom.
>>
>>
>>     - Kasper
>>
>>
>>     On 25/5/2010 07:9, Lukas Krecan wrote:
>>
>>         Hi,
>>             I have been playing with extra166y library and found that
>>         when I try
>>         to sort an uniform array (full of ones) it takes ages. With 
>> older
>>         version of the library it even threw StackOverflowError. After
>>         update it
>>         runs for minutes (I always kill the process after while so I do
>>         not know
>>         if it ends successfully).
>>
>>         Probably it's nothing new for you, maybe it's expected
>>         behaviour. But
>>         for me it's confusing and I just wanted to let you know about
>>         the issue
>>         in case you were not aware of it.
>>                Best regards
>>                  Lukas Krecan
>>
>>         -------------------------------------
>>         package net.krecan.forkjoin;
>>
>>         import java.util.Random;
>>
>>         import jsr166y.ForkJoinPool;
>>         import extra166y.Ops;
>>         import extra166y.ParallelLongArray;
>>
>>
>>         public class SortTest {
>>              private static final int THREADS = 2;
>>              private static final int SIZE = 40000000;
>>
>>              public static void testSort()
>>              {
>>                  ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>>                  ParallelLongArray pa = 
>> ParallelLongArray.createEmpty(SIZE,
>>         fjPool);
>>                  createData(pa);
>>                  System.out.println("Sorting "+pa.summary());
>>                  long start = System.currentTimeMillis();
>>                  pa.sort();
>>                  System.out.println("Done in
>>         "+(System.currentTimeMillis()-start)+"ms.");
>>                  System.out.println(pa.summary());
>>
>>
>>              }
>>              private static void createData(ParallelLongArray pa) {
>>                  long start = System.currentTimeMillis();
>>                  System.out.println("Creating data using "+THREADS+"
>>         threads.");
>>                  pa.setLimit(SIZE);
>>                  final Random rand = new Random();
>>                  pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>>                      public synchronized long op() {
>>                          return 1L;//rand.nextLong();
>>                      }
>>                  });
>>                  System.out.println("Done in
>>         "+(System.currentTimeMillis()-start)+"ms.");
>>              }
>>
>>              public static void main(String[] args) {
>>                  testSort();
>>              }
>>
>>         }
>>
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From michael.m.spiegel at gmail.com  Tue May 25 10:05:17 2010
From: michael.m.spiegel at gmail.com (Michael Spiegel)
Date: Tue, 25 May 2010 10:05:17 -0400
Subject: [concurrency-interest] Strange behaviour when sorting an
	uniform array
In-Reply-To: <4BFBADE7.4050108@gmail.com>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
	<4BFB838F.2000100@kav.dk>
	<AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>
	<4BFB9BEA.8040804@kav.dk> <4BFBADE7.4050108@gmail.com>
Message-ID: <AANLkTik8Hr60mvc9RphGhHFbCDRiUPDEzhSDCPxn2AfK@mail.gmail.com>

I think the benchmark would benefit from a warmup phase.  It would
ensure the methods in question are JIT compiled. Stackoverflow has a
reasonable set of links on how to write a Java microbenchmark:
http://stackoverflow.com/questions/504103/how-do-i-write-a-correct-micro-benchmark-in-java.

--Michael

On Tue, May 25, 2010 at 7:00 AM, Lukas Krecan <lukas.krecan at gmail.com> wrote:
> Sure, the synchronized statement is just a leftover from previous
> experiments.
>
> I have tried the same test with standard java.util.Arrays.sort and I am
> getting
>
> 1) Uniform array (full of 1L) ~ 200ms
> 2) rand.nextInt(20) ~ 1400ms
> 3) rand.nextLong() ~ 7700ms
>
> The reason might be that a modified quicksort algorithm is used there. Would
> it be possible to use the same algorithm for ParallelArray? I am afraid that
> most programmers have already forgotten the details of sorting algorithms
> and would be as surprised as I was.
> ? ? ?Cheers
> ? ? ? ? ? Lukas
>
> On 05/25/2010 11:44 AM, Kasper Nielsen wrote:
>>
>> Ahh, got it. You still want to remove that synchronized statement for
>> serious usage though.
>>
>> What you are seing is the worst case behavior for quicksort which
>> ParallelArray is using under the hood. All equal elements will kill most
>> quicksort implementations. Instead of the average running time of n*logn you
>> are seing worst case behaviour of n*n.
>>
>> Even large datasets with just a few different values will slow most
>> implementations down significantly.
>> I tried replacing
>> ?return 1L;//rand.nextLong();
>> with
>> ?return rand.nextInt(20)
>> and PA was still around 70 times slower compared to using rand.nextLong().
>>
>> We might want to switch to the dual pivot implementation introduced in
>> OpenJDK 7. Don't know about licensing issues though.
>>
>> - Kasper
>>
>>
>> On 25/5/2010 15:10, Lukas Krecan wrote:
>>>
>>> Hi,
>>> ? ?I am quite sure that it has nothing to do the synchronization. The
>>> problem remains even if synchronized keyword is removed. Besides, the
>>> method was used only for generating values, which works well. Problem is
>>> with sorting. It works well on random values, but runs for ages on
>>> uniform array.
>>>
>>>
>>> On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen <kasper at kav.dk
>>> <mailto:kasper at kav.dk>> wrote:
>>>
>>> ? ?Hi Lukas,
>>>
>>> ? ?try removing the synchronized keyword in your op.
>>>
>>> ? ?Taken from the extra166y.Ops javadoc:
>>>
>>> ? ?In addition to stated signatures, implementations of these
>>> ? ?interfaces must work safely in parallel. In general, this means
>>> ? ?methods should operate only on their arguments, and should not rely
>>> ? ?on ThreadLocals, unsafely published globals, or other unsafe
>>> ? ?constructions. Additionally, they should not block waiting for
>>> ? ?synchronization.
>>>
>>> ? ?If you want to return random numbers you should use the
>>> ? ?ThreadLocalRandom.
>>>
>>>
>>> ? ?- Kasper
>>>
>>>
>>> ? ?On 25/5/2010 07:9, Lukas Krecan wrote:
>>>
>>> ? ? ? ?Hi,
>>> ? ? ? ? ? ?I have been playing with extra166y library and found that
>>> ? ? ? ?when I try
>>> ? ? ? ?to sort an uniform array (full of ones) it takes ages. With older
>>> ? ? ? ?version of the library it even threw StackOverflowError. After
>>> ? ? ? ?update it
>>> ? ? ? ?runs for minutes (I always kill the process after while so I do
>>> ? ? ? ?not know
>>> ? ? ? ?if it ends successfully).
>>>
>>> ? ? ? ?Probably it's nothing new for you, maybe it's expected
>>> ? ? ? ?behaviour. But
>>> ? ? ? ?for me it's confusing and I just wanted to let you know about
>>> ? ? ? ?the issue
>>> ? ? ? ?in case you were not aware of it.
>>> ? ? ? ? ? ? ? Best regards
>>> ? ? ? ? ? ? ? ? Lukas Krecan
>>>
>>> ? ? ? ?-------------------------------------
>>> ? ? ? ?package net.krecan.forkjoin;
>>>
>>> ? ? ? ?import java.util.Random;
>>>
>>> ? ? ? ?import jsr166y.ForkJoinPool;
>>> ? ? ? ?import extra166y.Ops;
>>> ? ? ? ?import extra166y.ParallelLongArray;
>>>
>>>
>>> ? ? ? ?public class SortTest {
>>> ? ? ? ? ? ? private static final int THREADS = 2;
>>> ? ? ? ? ? ? private static final int SIZE = 40000000;
>>>
>>> ? ? ? ? ? ? public static void testSort()
>>> ? ? ? ? ? ? {
>>> ? ? ? ? ? ? ? ? ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>>> ? ? ? ? ? ? ? ? ParallelLongArray pa =
>>> ParallelLongArray.createEmpty(SIZE,
>>> ? ? ? ?fjPool);
>>> ? ? ? ? ? ? ? ? createData(pa);
>>> ? ? ? ? ? ? ? ? System.out.println("Sorting "+pa.summary());
>>> ? ? ? ? ? ? ? ? long start = System.currentTimeMillis();
>>> ? ? ? ? ? ? ? ? pa.sort();
>>> ? ? ? ? ? ? ? ? System.out.println("Done in
>>> ? ? ? ?"+(System.currentTimeMillis()-start)+"ms.");
>>> ? ? ? ? ? ? ? ? System.out.println(pa.summary());
>>>
>>>
>>> ? ? ? ? ? ? }
>>> ? ? ? ? ? ? private static void createData(ParallelLongArray pa) {
>>> ? ? ? ? ? ? ? ? long start = System.currentTimeMillis();
>>> ? ? ? ? ? ? ? ? System.out.println("Creating data using "+THREADS+"
>>> ? ? ? ?threads.");
>>> ? ? ? ? ? ? ? ? pa.setLimit(SIZE);
>>> ? ? ? ? ? ? ? ? final Random rand = new Random();
>>> ? ? ? ? ? ? ? ? pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>>> ? ? ? ? ? ? ? ? ? ? public synchronized long op() {
>>> ? ? ? ? ? ? ? ? ? ? ? ? return 1L;//rand.nextLong();
>>> ? ? ? ? ? ? ? ? ? ? }
>>> ? ? ? ? ? ? ? ? });
>>> ? ? ? ? ? ? ? ? System.out.println("Done in
>>> ? ? ? ?"+(System.currentTimeMillis()-start)+"ms.");
>>> ? ? ? ? ? ? }
>>>
>>> ? ? ? ? ? ? public static void main(String[] args) {
>>> ? ? ? ? ? ? ? ? testSort();
>>> ? ? ? ? ? ? }
>>>
>>> ? ? ? ?}
>>>
>>>
>>>
>>> ? ? ? ?_______________________________________________
>>> ? ? ? ?Concurrency-interest mailing list
>>> ? ? ? ?Concurrency-interest at cs.oswego.edu
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>> ? ? ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> ? ?_______________________________________________
>>> ? ?Concurrency-interest mailing list
>>> ? ?Concurrency-interest at cs.oswego.edu
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>> ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From lukas.krecan at gmail.com  Tue May 25 10:24:42 2010
From: lukas.krecan at gmail.com (Lukas Krecan)
Date: Tue, 25 May 2010 16:24:42 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an
 uniform array
In-Reply-To: <AANLkTik8Hr60mvc9RphGhHFbCDRiUPDEzhSDCPxn2AfK@mail.gmail.com>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>	<4BFB838F.2000100@kav.dk>	<AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>	<4BFB9BEA.8040804@kav.dk>
	<4BFBADE7.4050108@gmail.com>
	<AANLkTik8Hr60mvc9RphGhHFbCDRiUPDEzhSDCPxn2AfK@mail.gmail.com>
Message-ID: <4BFBDDAA.1020800@gmail.com>

Thanks for your comment. I did not want to claim that I have done a 
benchmark. I just wanted to illustrate that non-parallel implementation 
does not exhibit the n*n behaviour. That's all.

On 05/25/2010 04:05 PM, Michael Spiegel wrote:
> I think the benchmark would benefit from a warmup phase.  It would
> ensure the methods in question are JIT compiled. Stackoverflow has a
> reasonable set of links on how to write a Java microbenchmark:
> http://stackoverflow.com/questions/504103/how-do-i-write-a-correct-micro-benchmark-in-java.
>
> --Michael
>
> On Tue, May 25, 2010 at 7:00 AM, Lukas Krecan<lukas.krecan at gmail.com>  wrote:
>    
>> Sure, the synchronized statement is just a leftover from previous
>> experiments.
>>
>> I have tried the same test with standard java.util.Arrays.sort and I am
>> getting
>>
>> 1) Uniform array (full of 1L) ~ 200ms
>> 2) rand.nextInt(20) ~ 1400ms
>> 3) rand.nextLong() ~ 7700ms
>>
>> The reason might be that a modified quicksort algorithm is used there. Would
>> it be possible to use the same algorithm for ParallelArray? I am afraid that
>> most programmers have already forgotten the details of sorting algorithms
>> and would be as surprised as I was.
>>       Cheers
>>            Lukas
>>
>> On 05/25/2010 11:44 AM, Kasper Nielsen wrote:
>>      
>>> Ahh, got it. You still want to remove that synchronized statement for
>>> serious usage though.
>>>
>>> What you are seing is the worst case behavior for quicksort which
>>> ParallelArray is using under the hood. All equal elements will kill most
>>> quicksort implementations. Instead of the average running time of n*logn you
>>> are seing worst case behaviour of n*n.
>>>
>>> Even large datasets with just a few different values will slow most
>>> implementations down significantly.
>>> I tried replacing
>>>   return 1L;//rand.nextLong();
>>> with
>>>   return rand.nextInt(20)
>>> and PA was still around 70 times slower compared to using rand.nextLong().
>>>
>>> We might want to switch to the dual pivot implementation introduced in
>>> OpenJDK 7. Don't know about licensing issues though.
>>>
>>> - Kasper
>>>
>>>
>>> On 25/5/2010 15:10, Lukas Krecan wrote:
>>>        
>>>> Hi,
>>>>     I am quite sure that it has nothing to do the synchronization. The
>>>> problem remains even if synchronized keyword is removed. Besides, the
>>>> method was used only for generating values, which works well. Problem is
>>>> with sorting. It works well on random values, but runs for ages on
>>>> uniform array.
>>>>
>>>>
>>>> On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen<kasper at kav.dk
>>>> <mailto:kasper at kav.dk>>  wrote:
>>>>
>>>>     Hi Lukas,
>>>>
>>>>     try removing the synchronized keyword in your op.
>>>>
>>>>     Taken from the extra166y.Ops javadoc:
>>>>
>>>>     In addition to stated signatures, implementations of these
>>>>     interfaces must work safely in parallel. In general, this means
>>>>     methods should operate only on their arguments, and should not rely
>>>>     on ThreadLocals, unsafely published globals, or other unsafe
>>>>     constructions. Additionally, they should not block waiting for
>>>>     synchronization.
>>>>
>>>>     If you want to return random numbers you should use the
>>>>     ThreadLocalRandom.
>>>>
>>>>
>>>>     - Kasper
>>>>
>>>>
>>>>     On 25/5/2010 07:9, Lukas Krecan wrote:
>>>>
>>>>         Hi,
>>>>             I have been playing with extra166y library and found that
>>>>         when I try
>>>>         to sort an uniform array (full of ones) it takes ages. With older
>>>>         version of the library it even threw StackOverflowError. After
>>>>         update it
>>>>         runs for minutes (I always kill the process after while so I do
>>>>         not know
>>>>         if it ends successfully).
>>>>
>>>>         Probably it's nothing new for you, maybe it's expected
>>>>         behaviour. But
>>>>         for me it's confusing and I just wanted to let you know about
>>>>         the issue
>>>>         in case you were not aware of it.
>>>>                Best regards
>>>>                  Lukas Krecan
>>>>
>>>>         -------------------------------------
>>>>         package net.krecan.forkjoin;
>>>>
>>>>         import java.util.Random;
>>>>
>>>>         import jsr166y.ForkJoinPool;
>>>>         import extra166y.Ops;
>>>>         import extra166y.ParallelLongArray;
>>>>
>>>>
>>>>         public class SortTest {
>>>>              private static final int THREADS = 2;
>>>>              private static final int SIZE = 40000000;
>>>>
>>>>              public static void testSort()
>>>>              {
>>>>                  ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>>>>                  ParallelLongArray pa =
>>>> ParallelLongArray.createEmpty(SIZE,
>>>>         fjPool);
>>>>                  createData(pa);
>>>>                  System.out.println("Sorting "+pa.summary());
>>>>                  long start = System.currentTimeMillis();
>>>>                  pa.sort();
>>>>                  System.out.println("Done in
>>>>         "+(System.currentTimeMillis()-start)+"ms.");
>>>>                  System.out.println(pa.summary());
>>>>
>>>>
>>>>              }
>>>>              private static void createData(ParallelLongArray pa) {
>>>>                  long start = System.currentTimeMillis();
>>>>                  System.out.println("Creating data using "+THREADS+"
>>>>         threads.");
>>>>                  pa.setLimit(SIZE);
>>>>                  final Random rand = new Random();
>>>>                  pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>>>>                      public synchronized long op() {
>>>>                          return 1L;//rand.nextLong();
>>>>                      }
>>>>                  });
>>>>                  System.out.println("Done in
>>>>         "+(System.currentTimeMillis()-start)+"ms.");
>>>>              }
>>>>
>>>>              public static void main(String[] args) {
>>>>                  testSort();
>>>>              }
>>>>
>>>>         }
>>>>
>>>>
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu
>>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>     _______________________________________________
>>>>     Concurrency-interest mailing list
>>>>     Concurrency-interest at cs.oswego.edu
>>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>          
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>        
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>      
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>    


From ben_manes at yahoo.com  Tue May 25 13:31:13 2010
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 25 May 2010 10:31:13 -0700 (PDT)
Subject: [concurrency-interest] Strange behaviour when sorting an
	uniform array
In-Reply-To: <4BFBDDAA.1020800@gmail.com>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
	<4BFB838F.2000100@kav.dk>
	<AANLkTiknf6MqKW4FSz0uWAY_cLQOH_GhbaxK9eQU8CpQ@mail.gmail.com>
	<4BFB9BEA.8040804@kav.dk> <4BFBADE7.4050108@gmail.com>
	<AANLkTik8Hr60mvc9RphGhHFbCDRiUPDEzhSDCPxn2AfK@mail.gmail.com>
	<4BFBDDAA.1020800@gmail.com>
Message-ID: <423517.45568.qm@web38801.mail.mud.yahoo.com>

A common approach to resolve quicksort's worse case scenario is to shuffle the input prior to sorting (an O(n) operation). So in practice you might want to do that, though if you knew your data set was so uniform you'd probably optimize with a different sorting strategy (e.g. counting sort).




________________________________
From: Lukas Krecan <lukas.krecan at gmail.com>
To: concurrency-interest at cs.oswego.edu
Sent: Tue, May 25, 2010 7:24:42 AM
Subject: Re: [concurrency-interest] Strange behaviour when sorting an uniform array

Thanks for your comment. I did not want to claim that I have done a 
benchmark. I just wanted to illustrate that non-parallel implementation 
does not exhibit the n*n behaviour. That's all.

On 05/25/2010 04:05 PM, Michael Spiegel wrote:
> I think the benchmark would benefit from a warmup phase.  It would
> ensure the methods in question are JIT compiled. Stackoverflow has a
> reasonable set of links on how to write a Java microbenchmark:
> http://stackoverflow.com/questions/504103/how-do-i-write-a-correct-micro-benchmark-in-java.
>
> --Michael
>
> On Tue, May 25, 2010 at 7:00 AM, Lukas Krecan<lukas.krecan at gmail.com>  wrote:
>    
>> Sure, the synchronized statement is just a leftover from previous
>> experiments.
>>
>> I have tried the same test with standard java.util.Arrays.sort and I am
>> getting
>>
>> 1) Uniform array (full of 1L) ~ 200ms
>> 2) rand.nextInt(20) ~ 1400ms
>> 3) rand.nextLong() ~ 7700ms
>>
>> The reason might be that a modified quicksort algorithm is used there. Would
>> it be possible to use the same algorithm for ParallelArray? I am afraid that
>> most programmers have already forgotten the details of sorting algorithms
>> and would be as surprised as I was.
>>       Cheers
>>            Lukas
>>
>> On 05/25/2010 11:44 AM, Kasper Nielsen wrote:
>>      
>>> Ahh, got it. You still want to remove that synchronized statement for
>>> serious usage though.
>>>
>>> What you are seing is the worst case behavior for quicksort which
>>> ParallelArray is using under the hood. All equal elements will kill most
>>> quicksort implementations. Instead of the average running time of n*logn you
>>> are seing worst case behaviour of n*n.
>>>
>>> Even large datasets with just a few different values will slow most
>>> implementations down significantly.
>>> I tried replacing
>>>   return 1L;//rand.nextLong();
>>> with
>>>   return rand.nextInt(20)
>>> and PA was still around 70 times slower compared to using rand.nextLong().
>>>
>>> We might want to switch to the dual pivot implementation introduced in
>>> OpenJDK 7. Don't know about licensing issues though.
>>>
>>> - Kasper
>>>
>>>
>>> On 25/5/2010 15:10, Lukas Krecan wrote:
>>>        
>>>> Hi,
>>>>     I am quite sure that it has nothing to do the synchronization. The
>>>> problem remains even if synchronized keyword is removed. Besides, the
>>>> method was used only for generating values, which works well. Problem is
>>>> with sorting. It works well on random values, but runs for ages on
>>>> uniform array.
>>>>
>>>>
>>>> On Tue, May 25, 2010 at 10:00 AM, Kasper Nielsen<kasper at kav.dk
>>>> <mailto:kasper at kav.dk>>  wrote:
>>>>
>>>>     Hi Lukas,
>>>>
>>>>     try removing the synchronized keyword in your op.
>>>>
>>>>     Taken from the extra166y.Ops javadoc:
>>>>
>>>>     In addition to stated signatures, implementations of these
>>>>     interfaces must work safely in parallel. In general, this means
>>>>     methods should operate only on their arguments, and should not rely
>>>>     on ThreadLocals, unsafely published globals, or other unsafe
>>>>     constructions. Additionally, they should not block waiting for
>>>>     synchronization.
>>>>
>>>>     If you want to return random numbers you should use the
>>>>     ThreadLocalRandom.
>>>>
>>>>
>>>>     - Kasper
>>>>
>>>>
>>>>     On 25/5/2010 07:9, Lukas Krecan wrote:
>>>>
>>>>         Hi,
>>>>             I have been playing with extra166y library and found that
>>>>         when I try
>>>>         to sort an uniform array (full of ones) it takes ages. With older
>>>>         version of the library it even threw StackOverflowError. After
>>>>         update it
>>>>         runs for minutes (I always kill the process after while so I do
>>>>         not know
>>>>         if it ends successfully).
>>>>
>>>>         Probably it's nothing new for you, maybe it's expected
>>>>         behaviour. But
>>>>         for me it's confusing and I just wanted to let you know about
>>>>         the issue
>>>>         in case you were not aware of it.
>>>>                Best regards
>>>>                  Lukas Krecan
>>>>
>>>>         -------------------------------------
>>>>         package net.krecan.forkjoin;
>>>>
>>>>         import java.util.Random;
>>>>
>>>>         import jsr166y.ForkJoinPool;
>>>>         import extra166y.Ops;
>>>>         import extra166y.ParallelLongArray;
>>>>
>>>>
>>>>         public class SortTest {
>>>>              private static final int THREADS = 2;
>>>>              private static final int SIZE = 40000000;
>>>>
>>>>              public static void testSort()
>>>>              {
>>>>                  ForkJoinPool fjPool = new ForkJoinPool(THREADS);
>>>>                  ParallelLongArray pa =
>>>> ParallelLongArray.createEmpty(SIZE,
>>>>         fjPool);
>>>>                  createData(pa);
>>>>                  System.out.println("Sorting "+pa.summary());
>>>>                  long start = System.currentTimeMillis();
>>>>                  pa.sort();
>>>>                  System.out.println("Done in
>>>>         "+(System.currentTimeMillis()-start)+"ms.");
>>>>                  System.out.println(pa.summary());
>>>>
>>>>
>>>>              }
>>>>              private static void createData(ParallelLongArray pa) {
>>>>                  long start = System.currentTimeMillis();
>>>>                  System.out.println("Creating data using "+THREADS+"
>>>>         threads.");
>>>>                  pa.setLimit(SIZE);
>>>>                  final Random rand = new Random();
>>>>                  pa.replaceWithGeneratedValue(new Ops.LongGenerator(){
>>>>                      public synchronized long op() {
>>>>                          return 1L;//rand.nextLong();
>>>>                      }
>>>>                  });
>>>>                  System.out.println("Done in
>>>>         "+(System.currentTimeMillis()-start)+"ms.");
>>>>              }
>>>>
>>>>              public static void main(String[] args) {
>>>>                  testSort();
>>>>              }
>>>>
>>>>         }
>>>>
>>>>
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>        Concurrency-interest at cs.oswego.edu
>>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>>>        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>     _______________________________________________
>>>>     Concurrency-interest mailing list
>>>>    Concurrency-interest at cs.oswego.edu
>>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>          
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>        
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>      
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>    

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100525/eec25171/attachment.html>

From dl at cs.oswego.edu  Tue May 25 16:38:18 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 25 May 2010 16:38:18 -0400
Subject: [concurrency-interest] Strange behaviour when sorting an
 uniform array
In-Reply-To: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
Message-ID: <4BFC353A.7000105@cs.oswego.edu>

On 05/25/10 03:07, Lukas Krecan wrote:
> Hi,
>     I have been playing with extra166y library and found that when I try
> to sort an uniform array (full of ones) it takes ages.

Thanks for reporting this! As correctly guessed by Kasper, this
was due to a degenerate O(n^2) case in the sequential leaf sort.
Sorry for the problems. I changed a few things to allow
replacement for long and double versions with calls to  Arrays.sort
which as of jdk7 includes much faster base sorts that also
avoid this degeneracy. So if you run these with openjdk7
snapshots, the parallel sorts will also be faster. Also,
the other variants of sort (with comparators and for objects)
are changed to also screen for runs of identical values.

Get replacements at the usual places:

# API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/extra166ydocs/
# jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/extra166y.jar (compiled 
using Java6 javac).
# Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/extra166y/








From lukas.krecan at gmail.com  Wed May 26 03:09:01 2010
From: lukas.krecan at gmail.com (Lukas Krecan)
Date: Wed, 26 May 2010 09:09:01 +0200
Subject: [concurrency-interest] Strange behaviour when sorting an
 uniform array
In-Reply-To: <4BFC353A.7000105@cs.oswego.edu>
References: <AANLkTiljsv5tqcL-1SZPEYWD7oo6yscS3oFBoanC7lN4@mail.gmail.com>
	<4BFC353A.7000105@cs.oswego.edu>
Message-ID: <4BFCC90D.9040503@gmail.com>

Thanks a lot, I really appreciate what you are doing.

On 05/25/2010 10:38 PM, Doug Lea wrote:
> On 05/25/10 03:07, Lukas Krecan wrote:
>> Hi,
>>     I have been playing with extra166y library and found that when I try
>> to sort an uniform array (full of ones) it takes ages.
>
> Thanks for reporting this! As correctly guessed by Kasper, this
> was due to a degenerate O(n^2) case in the sequential leaf sort.
> Sorry for the problems. I changed a few things to allow
> replacement for long and double versions with calls to  Arrays.sort
> which as of jdk7 includes much faster base sorts that also
> avoid this degeneracy. So if you run these with openjdk7
> snapshots, the parallel sorts will also be faster. Also,
> the other variants of sort (with comparators and for objects)
> are changed to also screen for runs of identical values.
>
> Get replacements at the usual places:
>
> # API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/extra166ydocs/
> # jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/extra166y.jar 
> (compiled using Java6 javac).
> # Browsable CVS sources: 
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/extra166y/
>
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From nabiber at gmail.com  Wed May 26 03:37:03 2010
From: nabiber at gmail.com (Nabib El-Rahman)
Date: Wed, 26 May 2010 00:37:03 -0700
Subject: [concurrency-interest] CHM putIfAbsent
Message-ID: <AANLkTil-AAn6nxl76nfMF-TfcMJ59Z4JSr0n146FgYNe@mail.gmail.com>

Hello,

I don't know if this exist, But I need someway of executing an set of
statements atomically under the lock of the appropriate CHM segment.
That way I keep the correctness of the synchronization while still getting
the concurrency benefit of CHM.

Something like this:

 public V putIfAbsent(K key, Callable callable) {
    if (value == null) throw new NullPointerException();
    int hash = hash(key.hashCode());
    Segment seg = segmentFor(hash);
    //grab segment, and then call a function under a segment lock
    seg.put(key, hash, callable, true);
  }

Segment {

   public(K key, int hash, Callable callable, boolean checkIfAbsent) {
     // if absent, then..

     lock();

    try {

     //method executed under segment lock, return value put into map..
      put(key, hash, callable.execute());
   } finally {

     unlock();

  }
}


Thanks

-Nabib
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100526/6c7c7f1d/attachment.html>

From ben_manes at yahoo.com  Wed May 26 04:03:57 2010
From: ben_manes at yahoo.com (Ben Manes)
Date: Wed, 26 May 2010 01:03:57 -0700 (PDT)
Subject: [concurrency-interest] CHM putIfAbsent
In-Reply-To: <AANLkTil-AAn6nxl76nfMF-TfcMJ59Z4JSr0n146FgYNe@mail.gmail.com>
References: <AANLkTil-AAn6nxl76nfMF-TfcMJ59Z4JSr0n146FgYNe@mail.gmail.com>
Message-ID: <188019.14928.qm@web38804.mail.mud.yahoo.com>

The memoization idiom can be easily implemented with futures, as described in JCiP. A mature implementation is provided in Google's MapMaker and Ehcache's SelfPopulatingCache, among others.  Below shows a simple example of rolling this by hand to give you an idea of how this trick can be done and can be easily extended to perform bulk memoization. It will not be performed under the CHM's segment lock, which would provide slightly different semantics by restricting further segment write operations.


FutureTask<V> task = new FutureTask<V>(
              new Callable<V>() {
                    public V call() throws Exception {
                          // compute and return
                }
          });
          Future<V> future = map.putIfAbsent(key, task);
          if (future == null) {
                future = task;
                task.run();
          }
          try {
                return future.get();
          } catch (Exception e) {
                map.remove(key, future);
                throw e;
          }

}


________________________________
From: Nabib El-Rahman <nabiber at gmail.com>
To: concurrency-interest at cs.oswego.edu
Sent: Wed, May 26, 2010 12:37:03 AM
Subject: [concurrency-interest] CHM putIfAbsent

Hello,

I don't know if this exist, But I need someway of executing an set of statements atomically under the lock of the appropriate CHM segment.
That way I keep the correctness of the synchronization while still getting the concurrency benefit of CHM.

Something like this:

 public V putIfAbsent(K key, Callable callable) {
    if (value == null) throw new NullPointerException();
    int hash = hash(key.hashCode());
    Segment seg = segmentFor(hash);
    //grab segment, and then call a function under a segment lock
    seg.put(key, hash, callable, true);
  }

Segment {

   public(K key, int hash, Callable callable, boolean checkIfAbsent) {
     // if absent, then..
     
     lock();

    try {

     //method executed under segment lock, return value put into map..
      put(key, hash, callable.execute());
   } finally {

     unlock();
    
  }
}


Thanks

-Nabib


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100526/ba7a8836/attachment.html>

From dl at cs.oswego.edu  Thu May 27 12:53:05 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 27 May 2010 12:53:05 -0400
Subject: [concurrency-interest] ForkJoin Tweaks
Message-ID: <4BFEA371.8050205@cs.oswego.edu>


Updates to FJ (both jsr166y and openjdk7-ready j.u.c versions) include
a few changes inspired by conversations Cliff Click blogged about
at http://www.azulsystems.com/blogs/cliff/
You'll probably see better performance.

Get them at the usual places:

JSR166y:
# API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
# jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar (compiled using 
Java6 javac).
# Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/

openjdk7-ready java.util.concurrent:
# API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/docs/
# jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar
# Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/

From stuff at kai.meder.info  Sat May 29 14:08:11 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Sat, 29 May 2010 20:08:11 +0200
Subject: [concurrency-interest] throwing RuntimeException vs Exception in
	ThreadPoolExecutor
Message-ID: <4C01580B.6070904@kai.meder.info>

Hello,
I'm hacking in Scala and use the ThreadPoolExecutor. I use an Exception
"TerminatedChannel", using the trait ControlThrowable, inside my tasks
in for ControlFlow (please no discussion about this).

When using TerminatedChannel as a RuntimeException it passes the
attached ThreadPoolExector-CodeBlock. If used just as a Throwable the
ThreadPoolExecutor suspends the thread, as TerminatedChannel broke its neck.

Is this supposed Java-behaviour? Do I need to declare Exceptions as
RuntimeExceptions to get propagated to the normal catch-clause?

Any advice appreciated very much. Thanks!


public void run() {
            try {
                Runnable task = firstTask;
                firstTask = null;
                while (task != null || (task = getTask()) != null) {
                    runTask(task);
                    task = null;
                }
            } finally {
                workerDone(this);
            }
        }

From davidcholmes at aapt.net.au  Sat May 29 19:43:09 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 30 May 2010 09:43:09 +1000
Subject: [concurrency-interest] throwing RuntimeException vs Exception
	inThreadPoolExecutor
In-Reply-To: <4C01580B.6070904@kai.meder.info>
Message-ID: <NFBBKALFDCPFIDBNKAPCEELCIGAA.davidcholmes@aapt.net.au>

Kai Meder writes:
> I'm hacking in Scala and use the ThreadPoolExecutor. I use an Exception
> "TerminatedChannel", using the trait ControlThrowable, inside my tasks
> in for ControlFlow (please no discussion about this).
>
> When using TerminatedChannel as a RuntimeException it passes the
> attached ThreadPoolExector-CodeBlock. If used just as a Throwable the
> ThreadPoolExecutor suspends the thread, as TerminatedChannel
> broke its neck.
>
> Is this supposed Java-behaviour? Do I need to declare Exceptions as
> RuntimeExceptions to get propagated to the normal catch-clause?
>
> Any advice appreciated very much. Thanks!
>
>
> public void run() {
>             try {
>                 Runnable task = firstTask;
>                 firstTask = null;
>                 while (task != null || (task = getTask()) != null) {
>                     runTask(task);
>                     task = null;
>                 }
>             } finally {
>                 workerDone(this);
>             }
>         }

I don't quite understand your description, nor what the "normal
catch-clause" refers to.

In Java, exceptions (any type that extends Throwable) come in two flavours:
 - checked
 - unchecked
Unchecked exceptions are instances of Error or its subclasses, or instances
of RuntimeException or its subclasses. All other exception types are checked
exceptions.

Methods must declare all checked exceptions they throw in their throws
clause. The compiler will not allow methodA to call methodB if methodB
throws a checked exception and either methodA does not declare the same
exception, or methodA does not catch the checked exception thrown by
methodB.

It just occurs to me that perhaps you are mistakenly thinking that if a task
you submit to an executor throws an exception, then that exception will
somehow appear in the thread that did the submission? That will not happen
by itself. Exceptions are always local to a given Thread in Java. If you do
something that results in code executing in another thread, any exceptions
from that code impact only that other thread - unless you explicitly arrange
for it to be reported back to the original thread somehow. For example,
Future.get will throw ExecutionException if the computation (whichever
thread performed it) threw an exception - but that is because the Future
implementation has to catch and store the original exception so it can be
rethrown in the thread doing the get().

In the executor code you show, any uncaught exception from the task will
lead to termination of the executor worker thread and invocation of the
uncaught-exception handler for that thread.

David Holmes



From davidcholmes at aapt.net.au  Sat May 29 19:57:09 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 30 May 2010 09:57:09 +1000
Subject: [concurrency-interest] throwing RuntimeException vs
	ExceptioninThreadPoolExecutor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEELCIGAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCKELCIGAA.davidcholmes@aapt.net.au>

Re-reading this ...

> Kai Meder writes:
> > I'm hacking in Scala and use the ThreadPoolExecutor. I use an Exception
> > "TerminatedChannel", using the trait ControlThrowable, inside my tasks
> > in for ControlFlow (please no discussion about this).
> >
> > When using TerminatedChannel as a RuntimeException it passes the
> > attached ThreadPoolExector-CodeBlock. If used just as a Throwable the
> > ThreadPoolExecutor suspends the thread, as TerminatedChannel
> > broke its neck.

So Throwable is a checked-exception and it should not be possible (under
normal circumstances) for your task to throw it as Runnables do not throw
checked exceptions. You can get around this by using some reflection
techniques or native code to throw "impossible" exceptions. If you did this
there may some internal piece of code that encounters a problem that results
in the behaviour you observe.

That said I don't understand what you mean by "suspends the thread" above.

David Holmes


> > Is this supposed Java-behaviour? Do I need to declare Exceptions as
> > RuntimeExceptions to get propagated to the normal catch-clause?
> >
> > Any advice appreciated very much. Thanks!
> >
> >
> > public void run() {
> >             try {
> >                 Runnable task = firstTask;
> >                 firstTask = null;
> >                 while (task != null || (task = getTask()) != null) {
> >                     runTask(task);
> >                     task = null;
> >                 }
> >             } finally {
> >                 workerDone(this);
> >             }
> >         }
>
> I don't quite understand your description, nor what the "normal
> catch-clause" refers to.
>
> In Java, exceptions (any type that extends Throwable) come in two
> flavours:
>  - checked
>  - unchecked
> Unchecked exceptions are instances of Error or its subclasses, or
> instances
> of RuntimeException or its subclasses. All other exception types
> are checked
> exceptions.
>
> Methods must declare all checked exceptions they throw in their throws
> clause. The compiler will not allow methodA to call methodB if methodB
> throws a checked exception and either methodA does not declare the same
> exception, or methodA does not catch the checked exception thrown by
> methodB.
>
> It just occurs to me that perhaps you are mistakenly thinking
> that if a task
> you submit to an executor throws an exception, then that exception will
> somehow appear in the thread that did the submission? That will not happen
> by itself. Exceptions are always local to a given Thread in Java.
> If you do
> something that results in code executing in another thread, any exceptions
> from that code impact only that other thread - unless you
> explicitly arrange
> for it to be reported back to the original thread somehow. For example,
> Future.get will throw ExecutionException if the computation (whichever
> thread performed it) threw an exception - but that is because the Future
> implementation has to catch and store the original exception so it can be
> rethrown in the thread doing the get().
>
> In the executor code you show, any uncaught exception from the task will
> lead to termination of the executor worker thread and invocation of the
> uncaught-exception handler for that thread.
>
> David Holmes
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From stuff at kai.meder.info  Sun May 30 10:55:43 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Sun, 30 May 2010 16:55:43 +0200
Subject: [concurrency-interest] throwing RuntimeException vs Exception
 inThreadPoolExecutor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEELCIGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEELCIGAA.davidcholmes@aapt.net.au>
Message-ID: <4C027C6F.6010203@kai.meder.info>

On 30.05.2010 01:43, David Holmes wrote:
> It just occurs to me that perhaps you are mistakenly thinking that if a task
> you submit to an executor throws an exception, then that exception will
> somehow appear in the thread that did the submission? That will not happen
> by itself. Exceptions are always local to a given Thread in Java. If you do
> something that results in code executing in another thread, any exceptions
> from that code impact only that other thread - unless you explicitly arrange
> for it to be reported back to the original thread somehow. For example,
> Future.get will throw ExecutionException if the computation (whichever
> thread performed it) threw an exception - but that is because the Future
> implementation has to catch and store the original exception so it can be
> rethrown in the thread doing the get().
> 
> In the executor code you show, any uncaught exception from the task will
> lead to termination of the executor worker thread and invocation of the
> uncaught-exception handler for that thread.

Thanks for describing this en detail. Currently I have the impression
that somehow the Exceptions, occuring inside a submitted task, are
nevertheless propagated to the try-catch clause outside of the task (the
code which submitted the task). But as you stated, this should not be
possible. I will debug this, thanks a lot for your insight.


From stuff at kai.meder.info  Sun May 30 10:59:28 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Sun, 30 May 2010 16:59:28 +0200
Subject: [concurrency-interest] throwing RuntimeException vs
	ExceptioninThreadPoolExecutor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKELCIGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKELCIGAA.davidcholmes@aapt.net.au>
Message-ID: <4C027D50.4000800@kai.meder.info>

On 30.05.2010 01:57, David Holmes wrote:
> Re-reading this ...
> 
>> Kai Meder writes:
>>> I'm hacking in Scala and use the ThreadPoolExecutor. I use an Exception
>>> "TerminatedChannel", using the trait ControlThrowable, inside my tasks
>>> in for ControlFlow (please no discussion about this).
>>>
>>> When using TerminatedChannel as a RuntimeException it passes the
>>> attached ThreadPoolExector-CodeBlock. If used just as a Throwable the
>>> ThreadPoolExecutor suspends the thread, as TerminatedChannel
>>> broke its neck.
> 
> So Throwable is a checked-exception and it should not be possible (under
> normal circumstances) for your task to throw it as Runnables do not throw
> checked exceptions. You can get around this by using some reflection
> techniques or native code to throw "impossible" exceptions. If you did this
> there may some internal piece of code that encounters a problem that results
> in the behaviour you observe.
If declaring the TerminatedChannel as RuntimeException with
ControlThrowable it is an Unchecked Exception and seems to leave the
ThreadPoolExecutor, caught by the "proper" exception-handler outside the
task. The ThreadPoolExecutor's Task#X-Thread does not get "suspended",
the control flow continues normally.

> That said I don't understand what you mean by "suspends the thread" above.
The ThreadPoolExecutor Task#X-Thread encounters the NON-RuntimeException
and enters the JVM-"Suspended" ThreadState, as indicated by the
Debug-View of eclipse.

From davidcholmes at aapt.net.au  Sun May 30 18:03:48 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 31 May 2010 08:03:48 +1000
Subject: [concurrency-interest] throwing RuntimeException vs
	ExceptioninThreadPoolExecutor
In-Reply-To: <4C027D50.4000800@kai.meder.info>
Message-ID: <NFBBKALFDCPFIDBNKAPCIELDIGAA.davidcholmes@aapt.net.au>

Kai Meder writes:
> On 30.05.2010 01:57, David Holmes wrote:
> > Re-reading this ...
> >
> >> Kai Meder writes:
> >>> I'm hacking in Scala and use the ThreadPoolExecutor. I use an
> >>> Exception "TerminatedChannel", using the trait ControlThrowable,
> >>> inside my tasks in for ControlFlow (please no discussion about this).
> >>>
> >>> When using TerminatedChannel as a RuntimeException it passes the
> >>> attached ThreadPoolExector-CodeBlock. If used just as a Throwable the
> >>> ThreadPoolExecutor suspends the thread, as TerminatedChannel
> >>> broke its neck.
> >
> > So Throwable is a checked-exception and it should not be possible (under
> > normal circumstances) for your task to throw it as Runnables do
> > not throw checked exceptions. You can get around this by using some
reflection
> > techniques or native code to throw "impossible" exceptions. If
> > you did this there may some internal piece of code that encounters a
problem
> > that results in the behaviour you observe.
>
> If declaring the TerminatedChannel as RuntimeException with
> ControlThrowable it is an Unchecked Exception and seems to leave the
> ThreadPoolExecutor, caught by the "proper" exception-handler outside the
> task. The ThreadPoolExecutor's Task#X-Thread does not get "suspended",
> the control flow continues normally.

As said previously, exceptions thrown by the executor thread can't be caught
by the thread submitting the task - unless code has been set up explicitly
to do this. Perhaps this is specific to the Scala runtime?

> > That said I don't understand what you mean by "suspends the
> > thread" above.
>
> The ThreadPoolExecutor Task#X-Thread encounters the NON-RuntimeException
> and enters the JVM-"Suspended" ThreadState, as indicated by the
> Debug-View of eclipse.

That sounds like the debugger has "suspended" the thread - possibly because
of the unexpected uncaught checked exception. What happens if you run
outside of the debugger/IDE ?

David Holmes


From stuff at kai.meder.info  Mon May 31 10:51:35 2010
From: stuff at kai.meder.info (Kai Meder)
Date: Mon, 31 May 2010 16:51:35 +0200
Subject: [concurrency-interest] General Question on queue-size
Message-ID: <4C03CCF7.5010306@kai.meder.info>

Hello,

there was a discussion about the ConcurrentLinkedQueue regarding a
proper size implementation. One Point was that offer and poll would
fight for an atomic Counter, resulting in a huge performance penalty.
Another Point was the general "asynchronous" nature of the offer- and
poll-operations, so the size would only be a rough estimate.

However is the following not possible either?
- offer increments an offerCounter
- poll increments a pollCounter
- estimatedSize = offerCounter - pollCounter

Is this practicable?
I am looking for a way to implement a BoundedQueue where the producer is
stopped after the buffer is full (bounded). However I am not able to use
the existing Queues as they are blocking. I experiment with
Continuation-Passing-Style (reset/shift) in Scala and must not use any
traditional Thread-blocking-operations.

Any comment appreciated. Thanks.

From alarmnummer at gmail.com  Mon May 31 13:42:40 2010
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 31 May 2010 19:42:40 +0200
Subject: [concurrency-interest] delaying in the nanosecond range
Message-ID: <AANLkTilJxOgJhTlMItW4KRYAgjv1P6DJs-_Bt_29ZK_n@mail.gmail.com>

Is there any way other than performing some arbitrary calculation (like
calculating pi) to enter 0..1000 ns delay range?

I'm working on an STM and I'm including support for a bug shaker by
inserting delays (delays are removed by the JIT if not enabled)
at strategic positions. A park nanos leads to at least a few thousand
nanoseconds delay and this causes new problems,
like transactions not being able to complete because there always is some
conflict.

Of course the result of calculation need to be 'used' to make sure that the
JIT doesn't compile the calculation away.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100531/2c6c21da/attachment.html>

From dl at cs.oswego.edu  Mon May 31 14:13:23 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 31 May 2010 14:13:23 -0400
Subject: [concurrency-interest] delaying in the nanosecond range
In-Reply-To: <AANLkTilJxOgJhTlMItW4KRYAgjv1P6DJs-_Bt_29ZK_n@mail.gmail.com>
References: <AANLkTilJxOgJhTlMItW4KRYAgjv1P6DJs-_Bt_29ZK_n@mail.gmail.com>
Message-ID: <4C03FC43.9090305@cs.oswego.edu>

On 05/31/10 13:42, Peter Veentjer wrote:
> Is there any way other than performing some arbitrary calculation (like
> calculating pi) to enter 0..1000 ns delay range?

The best other way is figure out something actually useful to do,
and do it! This is always worth exploring.

>
> I'm working on an STM and I'm including support for a bug shaker by
> inserting delays (delays are removed by the JIT if not enabled)
> at strategic positions. A park nanos leads to at least a few thousand
> nanoseconds delay and this causes new problems,
> like transactions not being able to complete because there always is
> some conflict.
>

Yes. Whenever there are no productive alternatives,
several j.u.c internals skip timed park calls below
a threshold (1-10 microsecs is reasonable) and instead spin more
on volatiles indicating completion, mixed with occasional
calls to Thread.yield, to heuristically nudge OS/VM to
try doing something else if it knows of anything.
See for example Exchanger.
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/Exchanger.java?view=log

-Doug

From dl at cs.oswego.edu  Mon May 31 14:21:42 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 31 May 2010 14:21:42 -0400
Subject: [concurrency-interest] General Question on queue-size
In-Reply-To: <4C03CCF7.5010306@kai.meder.info>
References: <4C03CCF7.5010306@kai.meder.info>
Message-ID: <4C03FE36.50603@cs.oswego.edu>

On 05/31/10 10:51, Kai Meder wrote:
> Hello,
>
> there was a discussion about the ConcurrentLinkedQueue regarding a
> proper size implementation. One Point was that offer and poll would
> fight for an atomic Counter, resulting in a huge performance penalty.
> Another Point was the general "asynchronous" nature of the offer- and
> poll-operations, so the size would only be a rough estimate.
>
> However is the following not possible either?
> - offer increments an offerCounter
> - poll increments a pollCounter
> - estimatedSize = offerCounter - pollCounter
>
> Is this practicable?

Not especially, although it depends on expected producer and
consumer loads.

Usually the best solution along these lines is to include a
serial number in each node, and arrange serial for each node is
one plus its predecessor (recomputing on missed attempts to link). You
can then determine length as last.serial - head.serial.

We don't do it by default for the usual reason that we
don't want to waste time and space overhead for an operation
that is of dubious utility.


> I am looking for a way to implement a BoundedQueue where the producer is
> stopped after the buffer is full (bounded). However I am not able to use
> the existing Queues as they are blocking. I experiment with
> Continuation-Passing-Style (reset/shift) in Scala and must not use any
> traditional Thread-blocking-operations.
>

You might however need to make the decision to create continuation
atomically, requiring locks at some level.

-Doug

